Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,408.87354
Policy Entropy: 1.13501
Value Function Loss: 3.66697

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.03018

Collected Steps per Second: 8,377.70026
Overall Steps per Second: 6,618.61544

Timestep Collection Time: 5.96918
Timestep Consumption Time: 1.58648
PPO Batch Consumption Time: 0.72573
Total Iteration Time: 7.55566

Cumulative Model Updates: 50,150
Cumulative Timesteps: 836,524,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,299.22839
Policy Entropy: 1.12497
Value Function Loss: 4.28269

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.05733

Collected Steps per Second: 10,356.74910
Overall Steps per Second: 8,916.87013

Timestep Collection Time: 4.83047
Timestep Consumption Time: 0.78002
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.61049

Cumulative Model Updates: 50,152
Cumulative Timesteps: 836,574,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836574162...
Checkpoint 836574162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,548.06650
Policy Entropy: 1.13528
Value Function Loss: 4.29371

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 12,015.38044
Overall Steps per Second: 10,166.13075

Timestep Collection Time: 4.16266
Timestep Consumption Time: 0.75720
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 4.91987

Cumulative Model Updates: 50,154
Cumulative Timesteps: 836,624,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,630.52722
Policy Entropy: 1.13596
Value Function Loss: 4.49070

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.07281
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 11,641.77114
Overall Steps per Second: 9,815.43890

Timestep Collection Time: 4.29625
Timestep Consumption Time: 0.79939
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.09565

Cumulative Model Updates: 50,157
Cumulative Timesteps: 836,674,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 836674194...
Checkpoint 836674194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,934.65392
Policy Entropy: 1.13020
Value Function Loss: 4.29510

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.07806
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 10,586.60452
Overall Steps per Second: 8,968.10349

Timestep Collection Time: 4.72465
Timestep Consumption Time: 0.85267
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.57732

Cumulative Model Updates: 50,160
Cumulative Timesteps: 836,724,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,496.31742
Policy Entropy: 1.12676
Value Function Loss: 4.24521

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 9,725.83704
Overall Steps per Second: 8,421.34463

Timestep Collection Time: 5.14156
Timestep Consumption Time: 0.79644
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.93801

Cumulative Model Updates: 50,163
Cumulative Timesteps: 836,774,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 836774218...
Checkpoint 836774218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,759.64374
Policy Entropy: 1.12792
Value Function Loss: 4.18016

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 10,243.01483
Overall Steps per Second: 8,715.06335

Timestep Collection Time: 4.88372
Timestep Consumption Time: 0.85623
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 5.73995

Cumulative Model Updates: 50,166
Cumulative Timesteps: 836,824,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,949.57206
Policy Entropy: 1.13514
Value Function Loss: 4.12778

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 11,396.55010
Overall Steps per Second: 9,639.31585

Timestep Collection Time: 4.38747
Timestep Consumption Time: 0.79983
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.18730

Cumulative Model Updates: 50,169
Cumulative Timesteps: 836,874,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 836874244...
Checkpoint 836874244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,748.15639
Policy Entropy: 1.10527
Value Function Loss: 4.26055

Mean KL Divergence: 0.07155
SB3 Clip Fraction: 0.23776
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.14662

Collected Steps per Second: 12,241.38058
Overall Steps per Second: 10,298.86685

Timestep Collection Time: 4.08630
Timestep Consumption Time: 0.77074
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.85704

Cumulative Model Updates: 50,172
Cumulative Timesteps: 836,924,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,932.10178
Policy Entropy: 1.13368
Value Function Loss: 4.34798

Mean KL Divergence: 0.03425
SB3 Clip Fraction: 0.18919
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 10,922.99290
Overall Steps per Second: 9,421.77754

Timestep Collection Time: 4.57842
Timestep Consumption Time: 0.72950
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.30792

Cumulative Model Updates: 50,175
Cumulative Timesteps: 836,974,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836974276...
Checkpoint 836974276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,154.47471
Policy Entropy: 1.11313
Value Function Loss: 4.40740

Mean KL Divergence: 0.03996
SB3 Clip Fraction: 0.19439
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 12,365.47258
Overall Steps per Second: 10,324.15502

Timestep Collection Time: 4.04465
Timestep Consumption Time: 0.79972
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.84437

Cumulative Model Updates: 50,178
Cumulative Timesteps: 837,024,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,987.35042
Policy Entropy: 1.12701
Value Function Loss: 4.41148

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.10813

Collected Steps per Second: 12,474.39306
Overall Steps per Second: 10,611.79849

Timestep Collection Time: 4.00853
Timestep Consumption Time: 0.70358
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.71211

Cumulative Model Updates: 50,181
Cumulative Timesteps: 837,074,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837074294...
Checkpoint 837074294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557,021.30265
Policy Entropy: 1.12888
Value Function Loss: 4.19351

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.09986

Collected Steps per Second: 11,658.18283
Overall Steps per Second: 9,842.60955

Timestep Collection Time: 4.29055
Timestep Consumption Time: 0.79144
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.08199

Cumulative Model Updates: 50,184
Cumulative Timesteps: 837,124,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,814.72479
Policy Entropy: 1.11206
Value Function Loss: 4.00997

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.09674

Collected Steps per Second: 11,693.32563
Overall Steps per Second: 9,833.17350

Timestep Collection Time: 4.27629
Timestep Consumption Time: 0.80895
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 5.08524

Cumulative Model Updates: 50,187
Cumulative Timesteps: 837,174,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837174318...
Checkpoint 837174318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,380.98381
Policy Entropy: 1.09983
Value Function Loss: 3.85337

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.18321
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 11,701.93317
Overall Steps per Second: 10,070.08235

Timestep Collection Time: 4.27297
Timestep Consumption Time: 0.69243
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.96540

Cumulative Model Updates: 50,190
Cumulative Timesteps: 837,224,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,242.00591
Policy Entropy: 1.11051
Value Function Loss: 3.76705

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 11,145.68101
Overall Steps per Second: 9,506.47002

Timestep Collection Time: 4.48855
Timestep Consumption Time: 0.77397
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.26252

Cumulative Model Updates: 50,193
Cumulative Timesteps: 837,274,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 837274348...
Checkpoint 837274348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,885.08929
Policy Entropy: 1.12169
Value Function Loss: 3.77259

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.09040

Collected Steps per Second: 11,588.08122
Overall Steps per Second: 9,875.26891

Timestep Collection Time: 4.31633
Timestep Consumption Time: 0.74864
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.06498

Cumulative Model Updates: 50,196
Cumulative Timesteps: 837,324,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,904.05324
Policy Entropy: 1.11206
Value Function Loss: 3.74105

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 12,060.25351
Overall Steps per Second: 10,154.06773

Timestep Collection Time: 4.14618
Timestep Consumption Time: 0.77835
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.92453

Cumulative Model Updates: 50,199
Cumulative Timesteps: 837,374,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837374370...
Checkpoint 837374370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,037.95257
Policy Entropy: 1.10226
Value Function Loss: 3.73958

Mean KL Divergence: 0.02951
SB3 Clip Fraction: 0.18051
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 11,290.19194
Overall Steps per Second: 9,712.25626

Timestep Collection Time: 4.43110
Timestep Consumption Time: 0.71991
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.15102

Cumulative Model Updates: 50,202
Cumulative Timesteps: 837,424,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,071.93851
Policy Entropy: 1.11360
Value Function Loss: 3.49463

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.07545

Collected Steps per Second: 11,419.72195
Overall Steps per Second: 9,855.31159

Timestep Collection Time: 4.37979
Timestep Consumption Time: 0.69524
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.07503

Cumulative Model Updates: 50,205
Cumulative Timesteps: 837,474,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 837474414...
Checkpoint 837474414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,498.67638
Policy Entropy: 1.11056
Value Function Loss: 3.42715

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.07701

Collected Steps per Second: 12,067.45470
Overall Steps per Second: 10,193.56628

Timestep Collection Time: 4.14470
Timestep Consumption Time: 0.76192
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.90662

Cumulative Model Updates: 50,208
Cumulative Timesteps: 837,524,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,183.29728
Policy Entropy: 1.09861
Value Function Loss: 3.42818

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.07767

Collected Steps per Second: 11,323.73677
Overall Steps per Second: 9,655.79962

Timestep Collection Time: 4.41762
Timestep Consumption Time: 0.76310
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.18072

Cumulative Model Updates: 50,211
Cumulative Timesteps: 837,574,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 837574454...
Checkpoint 837574454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,027.40800
Policy Entropy: 1.11145
Value Function Loss: 3.50907

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07606

Collected Steps per Second: 12,053.93768
Overall Steps per Second: 10,184.72217

Timestep Collection Time: 4.15034
Timestep Consumption Time: 0.76172
PPO Batch Consumption Time: 0.03332
Total Iteration Time: 4.91206

Cumulative Model Updates: 50,214
Cumulative Timesteps: 837,624,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,909.91168
Policy Entropy: 1.11757
Value Function Loss: 3.48200

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.07351

Collected Steps per Second: 11,883.87199
Overall Steps per Second: 9,994.96994

Timestep Collection Time: 4.20806
Timestep Consumption Time: 0.79526
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.00332

Cumulative Model Updates: 50,217
Cumulative Timesteps: 837,674,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 837674490...
Checkpoint 837674490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,049.30965
Policy Entropy: 1.10061
Value Function Loss: 3.43036

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.07466

Collected Steps per Second: 11,321.16994
Overall Steps per Second: 9,768.18900

Timestep Collection Time: 4.41774
Timestep Consumption Time: 0.70235
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.12009

Cumulative Model Updates: 50,220
Cumulative Timesteps: 837,724,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,999.44728
Policy Entropy: 1.09394
Value Function Loss: 3.52258

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.07177

Collected Steps per Second: 11,565.06371
Overall Steps per Second: 9,815.41864

Timestep Collection Time: 4.32527
Timestep Consumption Time: 0.77100
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.09627

Cumulative Model Updates: 50,223
Cumulative Timesteps: 837,774,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837774526...
Checkpoint 837774526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,725.72143
Policy Entropy: 1.09896
Value Function Loss: 3.55751

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 11,639.54334
Overall Steps per Second: 10,027.23347

Timestep Collection Time: 4.29708
Timestep Consumption Time: 0.69094
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 4.98802

Cumulative Model Updates: 50,226
Cumulative Timesteps: 837,824,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,533.91285
Policy Entropy: 1.10983
Value Function Loss: 3.84024

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 11,261.17249
Overall Steps per Second: 9,469.18979

Timestep Collection Time: 4.44004
Timestep Consumption Time: 0.84025
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 5.28028

Cumulative Model Updates: 50,229
Cumulative Timesteps: 837,874,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 837874542...
Checkpoint 837874542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,754.40514
Policy Entropy: 1.08075
Value Function Loss: 3.82020

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.17477
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 11,764.63035
Overall Steps per Second: 9,850.49999

Timestep Collection Time: 4.25207
Timestep Consumption Time: 0.82625
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.07832

Cumulative Model Updates: 50,232
Cumulative Timesteps: 837,924,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,046.25971
Policy Entropy: 1.09866
Value Function Loss: 3.82869

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.07537

Collected Steps per Second: 11,731.43889
Overall Steps per Second: 10,120.90987

Timestep Collection Time: 4.26376
Timestep Consumption Time: 0.67849
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 4.94224

Cumulative Model Updates: 50,235
Cumulative Timesteps: 837,974,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 837974586...
Checkpoint 837974586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,975.70397
Policy Entropy: 1.09179
Value Function Loss: 3.56272

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 11,988.05136
Overall Steps per Second: 10,068.17887

Timestep Collection Time: 4.17115
Timestep Consumption Time: 0.79539
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.96654

Cumulative Model Updates: 50,238
Cumulative Timesteps: 838,024,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,955.22956
Policy Entropy: 1.07962
Value Function Loss: 3.60102

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 12,260.50416
Overall Steps per Second: 10,362.63933

Timestep Collection Time: 4.07928
Timestep Consumption Time: 0.74710
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.82638

Cumulative Model Updates: 50,241
Cumulative Timesteps: 838,074,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 838074604...
Checkpoint 838074604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,735.66963
Policy Entropy: 1.07993
Value Function Loss: 3.47979

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.07618

Collected Steps per Second: 11,373.30755
Overall Steps per Second: 9,662.88550

Timestep Collection Time: 4.39626
Timestep Consumption Time: 0.77818
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.17444

Cumulative Model Updates: 50,244
Cumulative Timesteps: 838,124,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742,026.17216
Policy Entropy: 1.08701
Value Function Loss: 3.41443

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.08323

Collected Steps per Second: 10,878.17159
Overall Steps per Second: 9,303.71888

Timestep Collection Time: 4.59783
Timestep Consumption Time: 0.77808
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.37591

Cumulative Model Updates: 50,247
Cumulative Timesteps: 838,174,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838174620...
Checkpoint 838174620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,878.36763
Policy Entropy: 1.10225
Value Function Loss: 3.42936

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 11,769.12500
Overall Steps per Second: 10,128.71268

Timestep Collection Time: 4.25078
Timestep Consumption Time: 0.68844
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.93923

Cumulative Model Updates: 50,250
Cumulative Timesteps: 838,224,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,511.38343
Policy Entropy: 1.06628
Value Function Loss: 3.45477

Mean KL Divergence: 0.06511
SB3 Clip Fraction: 0.23074
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 11,598.87436
Overall Steps per Second: 9,832.73133

Timestep Collection Time: 4.31283
Timestep Consumption Time: 0.77467
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.08750

Cumulative Model Updates: 50,253
Cumulative Timesteps: 838,274,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 838274672...
Checkpoint 838274672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,650.34388
Policy Entropy: 1.09758
Value Function Loss: 3.63451

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.20083
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.09071

Collected Steps per Second: 11,538.40669
Overall Steps per Second: 9,814.69435

Timestep Collection Time: 4.33370
Timestep Consumption Time: 0.76111
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.09481

Cumulative Model Updates: 50,256
Cumulative Timesteps: 838,324,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,405.24686
Policy Entropy: 1.05947
Value Function Loss: 3.62423

Mean KL Divergence: 0.05932
SB3 Clip Fraction: 0.26801
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.09888

Collected Steps per Second: 11,960.25025
Overall Steps per Second: 9,998.65501

Timestep Collection Time: 4.18185
Timestep Consumption Time: 0.82042
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.00227

Cumulative Model Updates: 50,259
Cumulative Timesteps: 838,374,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838374692...
Checkpoint 838374692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,489.10170
Policy Entropy: 1.09395
Value Function Loss: 3.67441

Mean KL Divergence: 0.04164
SB3 Clip Fraction: 0.23079
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 11,784.81863
Overall Steps per Second: 9,941.21101

Timestep Collection Time: 4.24495
Timestep Consumption Time: 0.78723
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.03218

Cumulative Model Updates: 50,262
Cumulative Timesteps: 838,424,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,083.04475
Policy Entropy: 1.06022
Value Function Loss: 3.67965

Mean KL Divergence: 0.04860
SB3 Clip Fraction: 0.23734
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.10663

Collected Steps per Second: 11,255.94072
Overall Steps per Second: 9,781.08016

Timestep Collection Time: 4.44245
Timestep Consumption Time: 0.66986
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 5.11232

Cumulative Model Updates: 50,265
Cumulative Timesteps: 838,474,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 838474722...
Checkpoint 838474722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,076.47485
Policy Entropy: 1.08171
Value Function Loss: 3.53836

Mean KL Divergence: 0.03696
SB3 Clip Fraction: 0.20617
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.11366

Collected Steps per Second: 11,688.09468
Overall Steps per Second: 9,908.19948

Timestep Collection Time: 4.27905
Timestep Consumption Time: 0.76868
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.04774

Cumulative Model Updates: 50,268
Cumulative Timesteps: 838,524,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,968.73466
Policy Entropy: 1.06886
Value Function Loss: 3.70408

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.12204

Collected Steps per Second: 11,618.61000
Overall Steps per Second: 9,867.62903

Timestep Collection Time: 4.30585
Timestep Consumption Time: 0.76406
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.06991

Cumulative Model Updates: 50,271
Cumulative Timesteps: 838,574,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 838574764...
Checkpoint 838574764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,676.16189
Policy Entropy: 1.08194
Value Function Loss: 3.60336

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 11,765.86493
Overall Steps per Second: 9,996.34043

Timestep Collection Time: 4.24992
Timestep Consumption Time: 0.75231
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.00223

Cumulative Model Updates: 50,274
Cumulative Timesteps: 838,624,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,978.40378
Policy Entropy: 1.08747
Value Function Loss: 3.76870

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.10450

Collected Steps per Second: 11,697.54501
Overall Steps per Second: 9,968.61645

Timestep Collection Time: 4.27628
Timestep Consumption Time: 0.74167
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.01795

Cumulative Model Updates: 50,277
Cumulative Timesteps: 838,674,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 838674790...
Checkpoint 838674790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,224.98269
Policy Entropy: 1.06472
Value Function Loss: 3.55669

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 11,545.40583
Overall Steps per Second: 9,996.96187

Timestep Collection Time: 4.33350
Timestep Consumption Time: 0.67122
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.00472

Cumulative Model Updates: 50,280
Cumulative Timesteps: 838,724,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,798.40570
Policy Entropy: 1.07599
Value Function Loss: 3.52041

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.09735

Collected Steps per Second: 11,228.49507
Overall Steps per Second: 9,563.94149

Timestep Collection Time: 4.45403
Timestep Consumption Time: 0.77520
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.22922

Cumulative Model Updates: 50,283
Cumulative Timesteps: 838,774,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 838774834...
Checkpoint 838774834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,475.88654
Policy Entropy: 1.07940
Value Function Loss: 3.51601

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.09944

Collected Steps per Second: 11,779.68232
Overall Steps per Second: 10,054.36916

Timestep Collection Time: 4.24714
Timestep Consumption Time: 0.72880
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.97595

Cumulative Model Updates: 50,286
Cumulative Timesteps: 838,824,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,240.60978
Policy Entropy: 1.09301
Value Function Loss: 3.51064

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 11,498.67109
Overall Steps per Second: 9,703.82270

Timestep Collection Time: 4.34955
Timestep Consumption Time: 0.80451
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.15405

Cumulative Model Updates: 50,289
Cumulative Timesteps: 838,874,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 838874878...
Checkpoint 838874878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,120.67875
Policy Entropy: 1.07647
Value Function Loss: 3.59493

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 11,463.44941
Overall Steps per Second: 9,786.01458

Timestep Collection Time: 4.36274
Timestep Consumption Time: 0.74782
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.11056

Cumulative Model Updates: 50,292
Cumulative Timesteps: 838,924,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,448.85496
Policy Entropy: 1.05885
Value Function Loss: 3.41456

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 11,725.15756
Overall Steps per Second: 10,091.93192

Timestep Collection Time: 4.26638
Timestep Consumption Time: 0.69045
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 4.95683

Cumulative Model Updates: 50,295
Cumulative Timesteps: 838,974,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 838974914...
Checkpoint 838974914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,744.22470
Policy Entropy: 1.07995
Value Function Loss: 3.55902

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 10,897.29032
Overall Steps per Second: 9,284.57482

Timestep Collection Time: 4.59123
Timestep Consumption Time: 0.79749
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.38872

Cumulative Model Updates: 50,298
Cumulative Timesteps: 839,024,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,562.78576
Policy Entropy: 1.07347
Value Function Loss: 3.54846

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.09249

Collected Steps per Second: 10,970.13361
Overall Steps per Second: 9,519.40605

Timestep Collection Time: 4.56020
Timestep Consumption Time: 0.69496
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.25516

Cumulative Model Updates: 50,301
Cumulative Timesteps: 839,074,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 839074972...
Checkpoint 839074972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,123.28143
Policy Entropy: 1.06887
Value Function Loss: 3.69895

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.09118

Collected Steps per Second: 11,728.08528
Overall Steps per Second: 9,918.10712

Timestep Collection Time: 4.26549
Timestep Consumption Time: 0.77842
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.04391

Cumulative Model Updates: 50,304
Cumulative Timesteps: 839,124,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,061.31192
Policy Entropy: 1.05795
Value Function Loss: 3.50089

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 11,834.71678
Overall Steps per Second: 10,005.71006

Timestep Collection Time: 4.22722
Timestep Consumption Time: 0.77272
PPO Batch Consumption Time: 0.03327
Total Iteration Time: 4.99994

Cumulative Model Updates: 50,307
Cumulative Timesteps: 839,175,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 839175026...
Checkpoint 839175026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,650.33444
Policy Entropy: 1.07502
Value Function Loss: 3.53665

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 12,934.79560
Overall Steps per Second: 10,715.88938

Timestep Collection Time: 3.86601
Timestep Consumption Time: 0.80052
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.66653

Cumulative Model Updates: 50,310
Cumulative Timesteps: 839,225,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,080.63016
Policy Entropy: 1.07710
Value Function Loss: 3.53150

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.09234

Collected Steps per Second: 11,492.20696
Overall Steps per Second: 9,628.11548

Timestep Collection Time: 4.35182
Timestep Consumption Time: 0.84255
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.19437

Cumulative Model Updates: 50,313
Cumulative Timesteps: 839,275,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839275044...
Checkpoint 839275044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,275.27935
Policy Entropy: 1.06201
Value Function Loss: 3.49198

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 11,637.81021
Overall Steps per Second: 9,929.44277

Timestep Collection Time: 4.29634
Timestep Consumption Time: 0.73919
PPO Batch Consumption Time: 0.03875
Total Iteration Time: 5.03553

Cumulative Model Updates: 50,316
Cumulative Timesteps: 839,325,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,062.60496
Policy Entropy: 1.07661
Value Function Loss: 3.37567

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.09552

Collected Steps per Second: 11,283.80750
Overall Steps per Second: 9,464.86866

Timestep Collection Time: 4.43148
Timestep Consumption Time: 0.85163
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 5.28312

Cumulative Model Updates: 50,319
Cumulative Timesteps: 839,375,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 839375048...
Checkpoint 839375048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,574.71238
Policy Entropy: 1.08690
Value Function Loss: 3.30351

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08543

Collected Steps per Second: 11,506.91997
Overall Steps per Second: 9,660.01685

Timestep Collection Time: 4.34695
Timestep Consumption Time: 0.83110
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.17804

Cumulative Model Updates: 50,322
Cumulative Timesteps: 839,425,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,876.59304
Policy Entropy: 1.06746
Value Function Loss: 3.45285

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 11,224.72467
Overall Steps per Second: 9,420.28581

Timestep Collection Time: 4.45481
Timestep Consumption Time: 0.85331
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 5.30812

Cumulative Model Updates: 50,325
Cumulative Timesteps: 839,475,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 839475072...
Checkpoint 839475072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,833.97832
Policy Entropy: 1.07147
Value Function Loss: 3.57191

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.09378

Collected Steps per Second: 10,552.99513
Overall Steps per Second: 9,066.93200

Timestep Collection Time: 4.74008
Timestep Consumption Time: 0.77689
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.51697

Cumulative Model Updates: 50,328
Cumulative Timesteps: 839,525,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,579.77208
Policy Entropy: 1.07422
Value Function Loss: 3.51031

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.08501

Collected Steps per Second: 10,586.00100
Overall Steps per Second: 9,169.63756

Timestep Collection Time: 4.72454
Timestep Consumption Time: 0.72976
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 5.45430

Cumulative Model Updates: 50,331
Cumulative Timesteps: 839,575,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 839575108...
Checkpoint 839575108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,096.09736
Policy Entropy: 1.08614
Value Function Loss: 3.46802

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.09041

Collected Steps per Second: 10,481.93353
Overall Steps per Second: 8,934.12249

Timestep Collection Time: 4.77030
Timestep Consumption Time: 0.82644
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.59674

Cumulative Model Updates: 50,334
Cumulative Timesteps: 839,625,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,209.56879
Policy Entropy: 1.06572
Value Function Loss: 3.38364

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 11,216.37984
Overall Steps per Second: 9,582.25946

Timestep Collection Time: 4.45955
Timestep Consumption Time: 0.76051
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.22006

Cumulative Model Updates: 50,337
Cumulative Timesteps: 839,675,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 839675130...
Checkpoint 839675130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,945.43393
Policy Entropy: 1.06675
Value Function Loss: 3.47052

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.10745

Collected Steps per Second: 10,063.44264
Overall Steps per Second: 8,609.67135

Timestep Collection Time: 4.96868
Timestep Consumption Time: 0.83898
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.80765

Cumulative Model Updates: 50,340
Cumulative Timesteps: 839,725,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,976.45923
Policy Entropy: 1.07502
Value Function Loss: 3.54966

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.09331

Collected Steps per Second: 10,177.38155
Overall Steps per Second: 8,805.80737

Timestep Collection Time: 4.91403
Timestep Consumption Time: 0.76540
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.67943

Cumulative Model Updates: 50,343
Cumulative Timesteps: 839,775,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839775144...
Checkpoint 839775144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,106.29636
Policy Entropy: 1.08517
Value Function Loss: 3.51827

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.15409
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 10,295.50894
Overall Steps per Second: 9,015.11996

Timestep Collection Time: 4.85687
Timestep Consumption Time: 0.68981
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.54668

Cumulative Model Updates: 50,346
Cumulative Timesteps: 839,825,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,656.56630
Policy Entropy: 1.06052
Value Function Loss: 3.46081

Mean KL Divergence: 0.03167
SB3 Clip Fraction: 0.18108
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,592.49716
Overall Steps per Second: 9,858.05831

Timestep Collection Time: 4.31417
Timestep Consumption Time: 0.75904
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.07321

Cumulative Model Updates: 50,349
Cumulative Timesteps: 839,875,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839875160...
Checkpoint 839875160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,831.96155
Policy Entropy: 1.07953
Value Function Loss: 3.39866

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 11,138.68757
Overall Steps per Second: 9,564.62170

Timestep Collection Time: 4.48958
Timestep Consumption Time: 0.73886
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.22843

Cumulative Model Updates: 50,352
Cumulative Timesteps: 839,925,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,617.98475
Policy Entropy: 1.08387
Value Function Loss: 3.52395

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 11,921.34335
Overall Steps per Second: 10,095.94824

Timestep Collection Time: 4.19617
Timestep Consumption Time: 0.75869
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.95486

Cumulative Model Updates: 50,355
Cumulative Timesteps: 839,975,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 839975192...
Checkpoint 839975192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,046.82904
Policy Entropy: 1.07355
Value Function Loss: 3.47671

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 11,489.52466
Overall Steps per Second: 9,725.96138

Timestep Collection Time: 4.35196
Timestep Consumption Time: 0.78912
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.14109

Cumulative Model Updates: 50,358
Cumulative Timesteps: 840,025,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,589.68003
Policy Entropy: 1.05674
Value Function Loss: 3.52682

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 11,411.46431
Overall Steps per Second: 9,826.71382

Timestep Collection Time: 4.38173
Timestep Consumption Time: 0.70664
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 5.08837

Cumulative Model Updates: 50,361
Cumulative Timesteps: 840,075,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 840075196...
Checkpoint 840075196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,897.07406
Policy Entropy: 1.07650
Value Function Loss: 3.55437

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.08560

Collected Steps per Second: 11,649.40881
Overall Steps per Second: 9,883.20581

Timestep Collection Time: 4.29206
Timestep Consumption Time: 0.76702
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.05909

Cumulative Model Updates: 50,364
Cumulative Timesteps: 840,125,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,590.61647
Policy Entropy: 1.06980
Value Function Loss: 3.53000

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.08927

Collected Steps per Second: 11,572.53226
Overall Steps per Second: 9,780.78553

Timestep Collection Time: 4.32092
Timestep Consumption Time: 0.79155
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.11247

Cumulative Model Updates: 50,367
Cumulative Timesteps: 840,175,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 840175200...
Checkpoint 840175200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,661.37679
Policy Entropy: 1.06044
Value Function Loss: 3.62135

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09546

Collected Steps per Second: 11,446.76858
Overall Steps per Second: 9,879.18907

Timestep Collection Time: 4.36822
Timestep Consumption Time: 0.69313
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.06135

Cumulative Model Updates: 50,370
Cumulative Timesteps: 840,225,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,926.03699
Policy Entropy: 1.04515
Value Function Loss: 3.55958

Mean KL Divergence: 0.03104
SB3 Clip Fraction: 0.19781
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.09163

Collected Steps per Second: 11,569.24269
Overall Steps per Second: 9,804.82008

Timestep Collection Time: 4.32215
Timestep Consumption Time: 0.77779
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 5.09994

Cumulative Model Updates: 50,373
Cumulative Timesteps: 840,275,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 840275206...
Checkpoint 840275206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,028.25281
Policy Entropy: 1.06054
Value Function Loss: 3.51099

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.08638

Collected Steps per Second: 11,794.70619
Overall Steps per Second: 10,028.67438

Timestep Collection Time: 4.24156
Timestep Consumption Time: 0.74693
PPO Batch Consumption Time: 0.03350
Total Iteration Time: 4.98850

Cumulative Model Updates: 50,376
Cumulative Timesteps: 840,325,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727,082.03532
Policy Entropy: 1.07004
Value Function Loss: 3.48954

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 12,135.70505
Overall Steps per Second: 10,212.28233

Timestep Collection Time: 4.12205
Timestep Consumption Time: 0.77636
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.89842

Cumulative Model Updates: 50,379
Cumulative Timesteps: 840,375,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 840375258...
Checkpoint 840375258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,389.03137
Policy Entropy: 1.05906
Value Function Loss: 3.46272

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.09134

Collected Steps per Second: 12,033.06069
Overall Steps per Second: 10,111.29257

Timestep Collection Time: 4.15522
Timestep Consumption Time: 0.78975
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.94497

Cumulative Model Updates: 50,382
Cumulative Timesteps: 840,425,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,228.58371
Policy Entropy: 1.05911
Value Function Loss: 3.57653

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 11,927.43171
Overall Steps per Second: 10,086.11245

Timestep Collection Time: 4.19369
Timestep Consumption Time: 0.76560
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 4.95929

Cumulative Model Updates: 50,385
Cumulative Timesteps: 840,475,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 840475278...
Checkpoint 840475278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,701.96496
Policy Entropy: 1.06532
Value Function Loss: 3.58956

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.09031

Collected Steps per Second: 11,998.95733
Overall Steps per Second: 10,095.21856

Timestep Collection Time: 4.16736
Timestep Consumption Time: 0.78587
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.95324

Cumulative Model Updates: 50,388
Cumulative Timesteps: 840,525,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,409.13016
Policy Entropy: 1.06644
Value Function Loss: 3.68153

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.09349

Collected Steps per Second: 11,833.11386
Overall Steps per Second: 10,069.65628

Timestep Collection Time: 4.22560
Timestep Consumption Time: 0.74001
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.96561

Cumulative Model Updates: 50,391
Cumulative Timesteps: 840,575,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 840575284...
Checkpoint 840575284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,875.33325
Policy Entropy: 1.05340
Value Function Loss: 3.56591

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.09702

Collected Steps per Second: 11,958.58274
Overall Steps per Second: 10,281.33893

Timestep Collection Time: 4.18160
Timestep Consumption Time: 0.68216
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.86376

Cumulative Model Updates: 50,394
Cumulative Timesteps: 840,625,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,776.11231
Policy Entropy: 1.05517
Value Function Loss: 3.47488

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.17152
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.09019

Collected Steps per Second: 11,424.99897
Overall Steps per Second: 9,659.23140

Timestep Collection Time: 4.37794
Timestep Consumption Time: 0.80032
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.17826

Cumulative Model Updates: 50,397
Cumulative Timesteps: 840,675,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 840675308...
Checkpoint 840675308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,050.19806
Policy Entropy: 1.06232
Value Function Loss: 3.43017

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 11,749.16188
Overall Steps per Second: 9,986.94215

Timestep Collection Time: 4.25767
Timestep Consumption Time: 0.75128
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 5.00894

Cumulative Model Updates: 50,400
Cumulative Timesteps: 840,725,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,905.83365
Policy Entropy: 1.06233
Value Function Loss: 3.48216

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.08363

Collected Steps per Second: 12,012.84735
Overall Steps per Second: 9,987.63215

Timestep Collection Time: 4.16437
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.00879

Cumulative Model Updates: 50,403
Cumulative Timesteps: 840,775,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 840775358...
Checkpoint 840775358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,207.93583
Policy Entropy: 1.06416
Value Function Loss: 3.59377

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 11,652.07223
Overall Steps per Second: 9,883.37315

Timestep Collection Time: 4.29297
Timestep Consumption Time: 0.76826
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.06123

Cumulative Model Updates: 50,406
Cumulative Timesteps: 840,825,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,422.78591
Policy Entropy: 1.06401
Value Function Loss: 3.47107

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.09155

Collected Steps per Second: 11,718.54844
Overall Steps per Second: 10,117.79636

Timestep Collection Time: 4.26759
Timestep Consumption Time: 0.67518
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 4.94278

Cumulative Model Updates: 50,409
Cumulative Timesteps: 840,875,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840875390...
Checkpoint 840875390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,396.74347
Policy Entropy: 1.06931
Value Function Loss: 3.39773

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.08989

Collected Steps per Second: 11,642.76320
Overall Steps per Second: 9,797.70813

Timestep Collection Time: 4.29520
Timestep Consumption Time: 0.80885
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.10405

Cumulative Model Updates: 50,412
Cumulative Timesteps: 840,925,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,903.49940
Policy Entropy: 1.06603
Value Function Loss: 3.21460

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.06918
Value Function Update Magnitude: 0.08618

Collected Steps per Second: 11,722.79844
Overall Steps per Second: 10,007.39343

Timestep Collection Time: 4.26775
Timestep Consumption Time: 0.73155
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.99930

Cumulative Model Updates: 50,415
Cumulative Timesteps: 840,975,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 840975428...
Checkpoint 840975428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,092.97593
Policy Entropy: 1.07014
Value Function Loss: 3.35283

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.08068

Collected Steps per Second: 11,974.52045
Overall Steps per Second: 10,129.01428

Timestep Collection Time: 4.17587
Timestep Consumption Time: 0.76084
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.93671

Cumulative Model Updates: 50,418
Cumulative Timesteps: 841,025,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,713.30631
Policy Entropy: 1.07653
Value Function Loss: 3.42731

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 11,822.45985
Overall Steps per Second: 9,948.60788

Timestep Collection Time: 4.22924
Timestep Consumption Time: 0.79659
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.02583

Cumulative Model Updates: 50,421
Cumulative Timesteps: 841,075,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841075432...
Checkpoint 841075432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,523.57880
Policy Entropy: 1.08095
Value Function Loss: 3.60654

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.09444

Collected Steps per Second: 11,578.37125
Overall Steps per Second: 10,070.39632

Timestep Collection Time: 4.31943
Timestep Consumption Time: 0.64681
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.96624

Cumulative Model Updates: 50,424
Cumulative Timesteps: 841,125,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,786.41052
Policy Entropy: 1.08330
Value Function Loss: 3.71689

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.07205
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 11,707.16779
Overall Steps per Second: 9,945.78270

Timestep Collection Time: 4.27140
Timestep Consumption Time: 0.75646
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.02786

Cumulative Model Updates: 50,427
Cumulative Timesteps: 841,175,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 841175450...
Checkpoint 841175450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,801.44274
Policy Entropy: 1.07995
Value Function Loss: 3.81126

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.07144
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 11,634.10640
Overall Steps per Second: 9,989.27361

Timestep Collection Time: 4.29822
Timestep Consumption Time: 0.70775
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.00597

Cumulative Model Updates: 50,430
Cumulative Timesteps: 841,225,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,386.93062
Policy Entropy: 1.07310
Value Function Loss: 3.81443

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 11,559.93792
Overall Steps per Second: 9,769.08632

Timestep Collection Time: 4.32770
Timestep Consumption Time: 0.79335
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.12105

Cumulative Model Updates: 50,433
Cumulative Timesteps: 841,275,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 841275484...
Checkpoint 841275484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,922.74369
Policy Entropy: 1.08427
Value Function Loss: 3.74424

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.08331

Collected Steps per Second: 11,546.20159
Overall Steps per Second: 9,801.25898

Timestep Collection Time: 4.33181
Timestep Consumption Time: 0.77120
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.10302

Cumulative Model Updates: 50,436
Cumulative Timesteps: 841,325,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,675.43304
Policy Entropy: 1.08708
Value Function Loss: 3.64891

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.07671

Collected Steps per Second: 11,562.31533
Overall Steps per Second: 9,828.64088

Timestep Collection Time: 4.32647
Timestep Consumption Time: 0.76315
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.08962

Cumulative Model Updates: 50,439
Cumulative Timesteps: 841,375,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 841375524...
Checkpoint 841375524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,067.49467
Policy Entropy: 1.06886
Value Function Loss: 3.52998

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 11,604.29332
Overall Steps per Second: 9,746.73761

Timestep Collection Time: 4.30978
Timestep Consumption Time: 0.82137
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 5.13115

Cumulative Model Updates: 50,442
Cumulative Timesteps: 841,425,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,279.19999
Policy Entropy: 1.05947
Value Function Loss: 3.50742

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.15727
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 11,397.23363
Overall Steps per Second: 9,715.99856

Timestep Collection Time: 4.38878
Timestep Consumption Time: 0.75943
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.14821

Cumulative Model Updates: 50,445
Cumulative Timesteps: 841,475,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 841475556...
Checkpoint 841475556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,898.19760
Policy Entropy: 1.07566
Value Function Loss: 3.56660

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 12,622.44959
Overall Steps per Second: 10,409.84199

Timestep Collection Time: 3.96135
Timestep Consumption Time: 0.84198
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.80334

Cumulative Model Updates: 50,448
Cumulative Timesteps: 841,525,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,662.16245
Policy Entropy: 1.07773
Value Function Loss: 3.60371

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 12,497.38753
Overall Steps per Second: 10,468.65454

Timestep Collection Time: 4.00100
Timestep Consumption Time: 0.77536
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.77635

Cumulative Model Updates: 50,451
Cumulative Timesteps: 841,575,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841575560...
Checkpoint 841575560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760,558.02814
Policy Entropy: 1.06404
Value Function Loss: 3.46450

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 12,254.05716
Overall Steps per Second: 10,482.33933

Timestep Collection Time: 4.08208
Timestep Consumption Time: 0.68995
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.77203

Cumulative Model Updates: 50,454
Cumulative Timesteps: 841,625,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,722.15140
Policy Entropy: 1.06005
Value Function Loss: 3.53051

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 12,236.11864
Overall Steps per Second: 10,106.30039

Timestep Collection Time: 4.08855
Timestep Consumption Time: 0.86163
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.95018

Cumulative Model Updates: 50,457
Cumulative Timesteps: 841,675,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 841675610...
Checkpoint 841675610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,169.35367
Policy Entropy: 1.07191
Value Function Loss: 3.34569

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 12,214.25016
Overall Steps per Second: 10,277.07631

Timestep Collection Time: 4.09522
Timestep Consumption Time: 0.77193
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.86714

Cumulative Model Updates: 50,460
Cumulative Timesteps: 841,725,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,255.03387
Policy Entropy: 1.08072
Value Function Loss: 3.54467

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 12,591.16135
Overall Steps per Second: 10,511.66164

Timestep Collection Time: 3.97152
Timestep Consumption Time: 0.78568
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.75719

Cumulative Model Updates: 50,463
Cumulative Timesteps: 841,775,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 841775636...
Checkpoint 841775636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,906.34712
Policy Entropy: 1.05853
Value Function Loss: 3.55529

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.09803

Collected Steps per Second: 11,918.66536
Overall Steps per Second: 10,139.85037

Timestep Collection Time: 4.19577
Timestep Consumption Time: 0.73606
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.93183

Cumulative Model Updates: 50,466
Cumulative Timesteps: 841,825,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,285.49644
Policy Entropy: 1.05767
Value Function Loss: 3.80659

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 11,539.48200
Overall Steps per Second: 9,955.49055

Timestep Collection Time: 4.33364
Timestep Consumption Time: 0.68951
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.02316

Cumulative Model Updates: 50,469
Cumulative Timesteps: 841,875,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 841875652...
Checkpoint 841875652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,236.57178
Policy Entropy: 1.06973
Value Function Loss: 3.63130

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.10213

Collected Steps per Second: 11,659.50850
Overall Steps per Second: 9,854.01361

Timestep Collection Time: 4.28920
Timestep Consumption Time: 0.78589
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.07509

Cumulative Model Updates: 50,472
Cumulative Timesteps: 841,925,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,302.15967
Policy Entropy: 1.07307
Value Function Loss: 3.58670

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 10,676.19838
Overall Steps per Second: 9,145.36023

Timestep Collection Time: 4.68332
Timestep Consumption Time: 0.78394
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.46725

Cumulative Model Updates: 50,475
Cumulative Timesteps: 841,975,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841975662...
Checkpoint 841975662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783,908.95253
Policy Entropy: 1.04336
Value Function Loss: 3.54107

Mean KL Divergence: 0.03531
SB3 Clip Fraction: 0.19901
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.10152

Collected Steps per Second: 11,554.89020
Overall Steps per Second: 9,802.90785

Timestep Collection Time: 4.32890
Timestep Consumption Time: 0.77366
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.10257

Cumulative Model Updates: 50,478
Cumulative Timesteps: 842,025,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,429.62671
Policy Entropy: 1.06464
Value Function Loss: 3.57324

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.09357

Collected Steps per Second: 11,700.41454
Overall Steps per Second: 9,973.45452

Timestep Collection Time: 4.27352
Timestep Consumption Time: 0.73998
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.01351

Cumulative Model Updates: 50,481
Cumulative Timesteps: 842,075,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 842075684...
Checkpoint 842075684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,365.24734
Policy Entropy: 1.06461
Value Function Loss: 3.40763

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.09384

Collected Steps per Second: 11,474.29745
Overall Steps per Second: 9,938.22203

Timestep Collection Time: 4.36001
Timestep Consumption Time: 0.67389
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.03390

Cumulative Model Updates: 50,484
Cumulative Timesteps: 842,125,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,801.19764
Policy Entropy: 1.06312
Value Function Loss: 3.32062

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.16350
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.09480

Collected Steps per Second: 11,575.92733
Overall Steps per Second: 9,852.64323

Timestep Collection Time: 4.32173
Timestep Consumption Time: 0.75590
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.07762

Cumulative Model Updates: 50,487
Cumulative Timesteps: 842,175,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 842175740...
Checkpoint 842175740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,586.52473
Policy Entropy: 1.05623
Value Function Loss: 3.37243

Mean KL Divergence: 0.02665
SB3 Clip Fraction: 0.19990
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 10,769.78489
Overall Steps per Second: 9,227.85955

Timestep Collection Time: 4.64410
Timestep Consumption Time: 0.77600
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.42011

Cumulative Model Updates: 50,490
Cumulative Timesteps: 842,225,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,197.96696
Policy Entropy: 1.06432
Value Function Loss: 3.47074

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.08325

Collected Steps per Second: 10,538.85863
Overall Steps per Second: 9,059.67656

Timestep Collection Time: 4.74492
Timestep Consumption Time: 0.77471
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.51962

Cumulative Model Updates: 50,493
Cumulative Timesteps: 842,275,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 842275762...
Checkpoint 842275762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,165.85138
Policy Entropy: 1.07175
Value Function Loss: 3.57337

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.15880
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 10,660.87173
Overall Steps per Second: 9,180.58051

Timestep Collection Time: 4.69117
Timestep Consumption Time: 0.75641
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.44759

Cumulative Model Updates: 50,496
Cumulative Timesteps: 842,325,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,173.44498
Policy Entropy: 1.04886
Value Function Loss: 3.68419

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.09394

Collected Steps per Second: 10,536.50347
Overall Steps per Second: 9,193.39778

Timestep Collection Time: 4.74825
Timestep Consumption Time: 0.69369
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.44195

Cumulative Model Updates: 50,499
Cumulative Timesteps: 842,375,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 842375804...
Checkpoint 842375804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,043.95726
Policy Entropy: 1.06378
Value Function Loss: 3.77938

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 10,612.53756
Overall Steps per Second: 8,985.87615

Timestep Collection Time: 4.71197
Timestep Consumption Time: 0.85298
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 5.56496

Cumulative Model Updates: 50,502
Cumulative Timesteps: 842,425,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,931.35758
Policy Entropy: 1.05993
Value Function Loss: 3.62700

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.17875
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.13105

Collected Steps per Second: 10,542.88770
Overall Steps per Second: 9,084.75984

Timestep Collection Time: 4.74557
Timestep Consumption Time: 0.76168
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.50725

Cumulative Model Updates: 50,505
Cumulative Timesteps: 842,475,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 842475842...
Checkpoint 842475842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,374.55847
Policy Entropy: 1.05705
Value Function Loss: 3.53397

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10,894.96747
Overall Steps per Second: 9,275.73353

Timestep Collection Time: 4.59074
Timestep Consumption Time: 0.80139
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.39213

Cumulative Model Updates: 50,508
Cumulative Timesteps: 842,525,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,362.30723
Policy Entropy: 1.04081
Value Function Loss: 3.33834

Mean KL Divergence: 0.03401
SB3 Clip Fraction: 0.20295
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.11158

Collected Steps per Second: 10,084.30950
Overall Steps per Second: 8,707.30737

Timestep Collection Time: 4.96117
Timestep Consumption Time: 0.78458
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.74575

Cumulative Model Updates: 50,511
Cumulative Timesteps: 842,575,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 842575888...
Checkpoint 842575888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,539.54597
Policy Entropy: 1.07091
Value Function Loss: 3.46043

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.10953

Collected Steps per Second: 10,796.99369
Overall Steps per Second: 9,162.88388

Timestep Collection Time: 4.63092
Timestep Consumption Time: 0.82588
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 5.45680

Cumulative Model Updates: 50,514
Cumulative Timesteps: 842,625,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,726.57741
Policy Entropy: 1.04337
Value Function Loss: 3.50736

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.17941
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.09854

Collected Steps per Second: 10,920.57484
Overall Steps per Second: 9,329.05386

Timestep Collection Time: 4.57870
Timestep Consumption Time: 0.78112
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.35981

Cumulative Model Updates: 50,517
Cumulative Timesteps: 842,675,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 842675890...
Checkpoint 842675890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,546.09343
Policy Entropy: 1.04873
Value Function Loss: 3.79283

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.08800

Collected Steps per Second: 11,041.85732
Overall Steps per Second: 9,637.25506

Timestep Collection Time: 4.52949
Timestep Consumption Time: 0.66016
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.18965

Cumulative Model Updates: 50,520
Cumulative Timesteps: 842,725,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,889.48026
Policy Entropy: 1.05300
Value Function Loss: 3.61892

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.09423

Collected Steps per Second: 11,086.93644
Overall Steps per Second: 9,368.10411

Timestep Collection Time: 4.51198
Timestep Consumption Time: 0.82784
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 5.33982

Cumulative Model Updates: 50,523
Cumulative Timesteps: 842,775,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 842775928...
Checkpoint 842775928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,934.83979
Policy Entropy: 1.06056
Value Function Loss: 3.58427

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 10,341.53746
Overall Steps per Second: 8,921.78890

Timestep Collection Time: 4.83642
Timestep Consumption Time: 0.76963
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.60605

Cumulative Model Updates: 50,526
Cumulative Timesteps: 842,825,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,951.66110
Policy Entropy: 1.03839
Value Function Loss: 3.40771

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 11,364.58175
Overall Steps per Second: 9,643.63488

Timestep Collection Time: 4.40175
Timestep Consumption Time: 0.78551
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.18726

Cumulative Model Updates: 50,529
Cumulative Timesteps: 842,875,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 842875968...
Checkpoint 842875968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,586.53124
Policy Entropy: 1.03746
Value Function Loss: 3.34334

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.16968
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.09599

Collected Steps per Second: 11,020.90073
Overall Steps per Second: 9,386.64069

Timestep Collection Time: 4.53792
Timestep Consumption Time: 0.79007
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.32800

Cumulative Model Updates: 50,532
Cumulative Timesteps: 842,925,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,054.97639
Policy Entropy: 1.04386
Value Function Loss: 3.39610

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.08602

Collected Steps per Second: 10,848.32162
Overall Steps per Second: 9,374.23882

Timestep Collection Time: 4.61085
Timestep Consumption Time: 0.72505
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.33590

Cumulative Model Updates: 50,535
Cumulative Timesteps: 842,976,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 842976000...
Checkpoint 842976000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,876.48594
Policy Entropy: 1.05487
Value Function Loss: 3.49629

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.16363
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 10,526.11288
Overall Steps per Second: 9,034.17940

Timestep Collection Time: 4.75199
Timestep Consumption Time: 0.78476
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.53675

Cumulative Model Updates: 50,538
Cumulative Timesteps: 843,026,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,949.27624
Policy Entropy: 1.04090
Value Function Loss: 3.73870

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 10,924.52905
Overall Steps per Second: 9,394.56034

Timestep Collection Time: 4.57924
Timestep Consumption Time: 0.74576
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.32500

Cumulative Model Updates: 50,541
Cumulative Timesteps: 843,076,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 843076046...
Checkpoint 843076046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,211.51932
Policy Entropy: 1.02360
Value Function Loss: 3.51735

Mean KL Divergence: 0.02920
SB3 Clip Fraction: 0.18465
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 10,594.40625
Overall Steps per Second: 9,112.16303

Timestep Collection Time: 4.72174
Timestep Consumption Time: 0.76807
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.48981

Cumulative Model Updates: 50,544
Cumulative Timesteps: 843,126,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,465.73307
Policy Entropy: 1.06317
Value Function Loss: 3.63844

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.17852
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.09282

Collected Steps per Second: 10,982.40852
Overall Steps per Second: 9,374.73540

Timestep Collection Time: 4.55474
Timestep Consumption Time: 0.78109
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.33583

Cumulative Model Updates: 50,547
Cumulative Timesteps: 843,176,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 843176092...
Checkpoint 843176092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,330.06479
Policy Entropy: 1.04108
Value Function Loss: 3.54067

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 10,364.53905
Overall Steps per Second: 9,086.63200

Timestep Collection Time: 4.82646
Timestep Consumption Time: 0.67877
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.50523

Cumulative Model Updates: 50,550
Cumulative Timesteps: 843,226,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,761.49449
Policy Entropy: 1.06056
Value Function Loss: 3.72428

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 10,647.74816
Overall Steps per Second: 9,142.69030

Timestep Collection Time: 4.69827
Timestep Consumption Time: 0.77342
PPO Batch Consumption Time: 0.03766
Total Iteration Time: 5.47169

Cumulative Model Updates: 50,553
Cumulative Timesteps: 843,276,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 843276142...
Checkpoint 843276142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,515.01152
Policy Entropy: 1.05460
Value Function Loss: 3.36563

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 10,376.27221
Overall Steps per Second: 8,967.73828

Timestep Collection Time: 4.82100
Timestep Consumption Time: 0.75722
PPO Batch Consumption Time: 0.03819
Total Iteration Time: 5.57822

Cumulative Model Updates: 50,556
Cumulative Timesteps: 843,326,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,373.51487
Policy Entropy: 1.03948
Value Function Loss: 3.60172

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.08523

Collected Steps per Second: 10,039.25203
Overall Steps per Second: 8,842.10137

Timestep Collection Time: 4.98244
Timestep Consumption Time: 0.67458
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.65703

Cumulative Model Updates: 50,559
Cumulative Timesteps: 843,376,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 843376186...
Checkpoint 843376186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,951.05703
Policy Entropy: 1.01966
Value Function Loss: 3.56434

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.20998
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.07553

Collected Steps per Second: 10,506.36888
Overall Steps per Second: 9,052.66688

Timestep Collection Time: 4.76111
Timestep Consumption Time: 0.76455
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 5.52566

Cumulative Model Updates: 50,562
Cumulative Timesteps: 843,426,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750,031.64977
Policy Entropy: 1.04164
Value Function Loss: 3.63944

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 10,708.46600
Overall Steps per Second: 9,182.07461

Timestep Collection Time: 4.67070
Timestep Consumption Time: 0.77644
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 5.44713

Cumulative Model Updates: 50,565
Cumulative Timesteps: 843,476,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 843476224...
Checkpoint 843476224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,404.25041
Policy Entropy: 1.03908
Value Function Loss: 3.45782

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 10,994.77938
Overall Steps per Second: 9,364.95839

Timestep Collection Time: 4.54961
Timestep Consumption Time: 0.79179
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.34140

Cumulative Model Updates: 50,568
Cumulative Timesteps: 843,526,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,327.24968
Policy Entropy: 1.02756
Value Function Loss: 3.47302

Mean KL Divergence: 0.02825
SB3 Clip Fraction: 0.19639
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.08126

Collected Steps per Second: 10,460.35276
Overall Steps per Second: 8,981.64931

Timestep Collection Time: 4.78225
Timestep Consumption Time: 0.78733
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.56958

Cumulative Model Updates: 50,571
Cumulative Timesteps: 843,576,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843576270...
Checkpoint 843576270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,107.19953
Policy Entropy: 1.04623
Value Function Loss: 3.61874

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.08930

Collected Steps per Second: 10,743.46049
Overall Steps per Second: 9,337.12831

Timestep Collection Time: 4.65418
Timestep Consumption Time: 0.70100
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.35518

Cumulative Model Updates: 50,574
Cumulative Timesteps: 843,626,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,772.37576
Policy Entropy: 1.04612
Value Function Loss: 3.42219

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 10,070.92851
Overall Steps per Second: 8,690.80113

Timestep Collection Time: 4.96518
Timestep Consumption Time: 0.78849
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.75367

Cumulative Model Updates: 50,577
Cumulative Timesteps: 843,676,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 843676276...
Checkpoint 843676276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,188.72412
Policy Entropy: 1.03328
Value Function Loss: 3.46402

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.07479

Collected Steps per Second: 10,485.79985
Overall Steps per Second: 8,991.14286

Timestep Collection Time: 4.76969
Timestep Consumption Time: 0.79290
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.56259

Cumulative Model Updates: 50,580
Cumulative Timesteps: 843,726,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,184.27268
Policy Entropy: 1.01846
Value Function Loss: 3.33888

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.19335
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.07502

Collected Steps per Second: 12,036.96289
Overall Steps per Second: 10,143.95210

Timestep Collection Time: 4.15587
Timestep Consumption Time: 0.77555
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.93141

Cumulative Model Updates: 50,583
Cumulative Timesteps: 843,776,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843776314...
Checkpoint 843776314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,681.94313
Policy Entropy: 1.03674
Value Function Loss: 3.55433

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 11,635.04378
Overall Steps per Second: 9,918.17653

Timestep Collection Time: 4.29822
Timestep Consumption Time: 0.74404
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 5.04226

Cumulative Model Updates: 50,586
Cumulative Timesteps: 843,826,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,834.00453
Policy Entropy: 1.04211
Value Function Loss: 3.41256

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 11,818.75334
Overall Steps per Second: 10,203.71898

Timestep Collection Time: 4.23175
Timestep Consumption Time: 0.66980
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.90155

Cumulative Model Updates: 50,589
Cumulative Timesteps: 843,876,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 843876338...
Checkpoint 843876338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,451.63810
Policy Entropy: 1.02562
Value Function Loss: 3.50289

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.07401

Collected Steps per Second: 11,442.88523
Overall Steps per Second: 9,592.05866

Timestep Collection Time: 4.37093
Timestep Consumption Time: 0.84339
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.21431

Cumulative Model Updates: 50,592
Cumulative Timesteps: 843,926,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,985.36512
Policy Entropy: 1.03150
Value Function Loss: 3.56028

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 11,890.32664
Overall Steps per Second: 10,001.56977

Timestep Collection Time: 4.20745
Timestep Consumption Time: 0.79456
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 5.00201

Cumulative Model Updates: 50,595
Cumulative Timesteps: 843,976,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 843976382...
Checkpoint 843976382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,810.06311
Policy Entropy: 1.03644
Value Function Loss: 3.51305

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.06746

Collected Steps per Second: 11,600.78436
Overall Steps per Second: 10,013.40975

Timestep Collection Time: 4.31057
Timestep Consumption Time: 0.68333
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.99390

Cumulative Model Updates: 50,598
Cumulative Timesteps: 844,026,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,514.84797
Policy Entropy: 1.03991
Value Function Loss: 3.30345

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 10,807.28263
Overall Steps per Second: 9,236.34361

Timestep Collection Time: 4.62929
Timestep Consumption Time: 0.78736
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.41665

Cumulative Model Updates: 50,601
Cumulative Timesteps: 844,076,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 844076418...
Checkpoint 844076418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,812.53842
Policy Entropy: 1.04361
Value Function Loss: 3.16440

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 10,450.23664
Overall Steps per Second: 9,065.16990

Timestep Collection Time: 4.78515
Timestep Consumption Time: 0.73112
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.51628

Cumulative Model Updates: 50,604
Cumulative Timesteps: 844,126,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,117.14643
Policy Entropy: 1.04178
Value Function Loss: 3.31170

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 11,049.01056
Overall Steps per Second: 9,359.11382

Timestep Collection Time: 4.52710
Timestep Consumption Time: 0.81742
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 5.34452

Cumulative Model Updates: 50,607
Cumulative Timesteps: 844,176,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 844176444...
Checkpoint 844176444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,353.48342
Policy Entropy: 1.04632
Value Function Loss: 3.47954

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 10,218.83956
Overall Steps per Second: 8,763.88016

Timestep Collection Time: 4.89547
Timestep Consumption Time: 0.81273
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.70820

Cumulative Model Updates: 50,610
Cumulative Timesteps: 844,226,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,755.15278
Policy Entropy: 1.04869
Value Function Loss: 3.55761

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.07919

Collected Steps per Second: 10,802.45240
Overall Steps per Second: 9,260.42727

Timestep Collection Time: 4.62858
Timestep Consumption Time: 0.77074
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.39932

Cumulative Model Updates: 50,613
Cumulative Timesteps: 844,276,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 844276470...
Checkpoint 844276470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,484.99148
Policy Entropy: 1.05338
Value Function Loss: 3.69094

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 10,574.29384
Overall Steps per Second: 9,086.37065

Timestep Collection Time: 4.72977
Timestep Consumption Time: 0.77452
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.50429

Cumulative Model Updates: 50,616
Cumulative Timesteps: 844,326,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,835.88862
Policy Entropy: 1.05728
Value Function Loss: 3.56220

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.07090

Collected Steps per Second: 10,711.90317
Overall Steps per Second: 9,274.27698

Timestep Collection Time: 4.66939
Timestep Consumption Time: 0.72381
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.39320

Cumulative Model Updates: 50,619
Cumulative Timesteps: 844,376,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 844376502...
Checkpoint 844376502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,553.47450
Policy Entropy: 1.05780
Value Function Loss: 3.52619

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 10,603.93738
Overall Steps per Second: 9,247.05405

Timestep Collection Time: 4.71617
Timestep Consumption Time: 0.69204
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.40821

Cumulative Model Updates: 50,622
Cumulative Timesteps: 844,426,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,981.18514
Policy Entropy: 1.05514
Value Function Loss: 3.40292

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 10,789.41620
Overall Steps per Second: 9,191.49484

Timestep Collection Time: 4.63602
Timestep Consumption Time: 0.80596
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 5.44199

Cumulative Model Updates: 50,625
Cumulative Timesteps: 844,476,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 844476532...
Checkpoint 844476532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,057.51188
Policy Entropy: 1.05812
Value Function Loss: 3.49761

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.07759
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 10,513.26362
Overall Steps per Second: 9,084.00086

Timestep Collection Time: 4.75799
Timestep Consumption Time: 0.74861
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.50660

Cumulative Model Updates: 50,628
Cumulative Timesteps: 844,526,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,111.17648
Policy Entropy: 1.05925
Value Function Loss: 3.58047

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 10,369.68617
Overall Steps per Second: 8,906.47863

Timestep Collection Time: 4.82425
Timestep Consumption Time: 0.79256
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.61681

Cumulative Model Updates: 50,631
Cumulative Timesteps: 844,576,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 844576580...
Checkpoint 844576580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,842.03204
Policy Entropy: 1.05858
Value Function Loss: 3.64216

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.07851
Value Function Update Magnitude: 0.09095

Collected Steps per Second: 10,618.85555
Overall Steps per Second: 9,071.19972

Timestep Collection Time: 4.71011
Timestep Consumption Time: 0.80360
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.51371

Cumulative Model Updates: 50,634
Cumulative Timesteps: 844,626,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,824.35269
Policy Entropy: 1.04591
Value Function Loss: 3.69619

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.09273

Collected Steps per Second: 10,387.22086
Overall Steps per Second: 9,087.84123

Timestep Collection Time: 4.81495
Timestep Consumption Time: 0.68844
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.50340

Cumulative Model Updates: 50,637
Cumulative Timesteps: 844,676,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 844676610...
Checkpoint 844676610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,940.27303
Policy Entropy: 1.06309
Value Function Loss: 3.59492

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 10,798.54441
Overall Steps per Second: 9,222.44756

Timestep Collection Time: 4.63062
Timestep Consumption Time: 0.79136
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 5.42199

Cumulative Model Updates: 50,640
Cumulative Timesteps: 844,726,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,878.21928
Policy Entropy: 1.06078
Value Function Loss: 3.61202

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.09092

Collected Steps per Second: 9,699.78122
Overall Steps per Second: 8,411.09888

Timestep Collection Time: 5.15558
Timestep Consumption Time: 0.78990
PPO Batch Consumption Time: 0.03935
Total Iteration Time: 5.94548

Cumulative Model Updates: 50,643
Cumulative Timesteps: 844,776,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 844776622...
Checkpoint 844776622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,196.50118
Policy Entropy: 1.04810
Value Function Loss: 3.61894

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 10,577.63596
Overall Steps per Second: 9,227.35990

Timestep Collection Time: 4.72809
Timestep Consumption Time: 0.69188
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.41997

Cumulative Model Updates: 50,646
Cumulative Timesteps: 844,826,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,337.28317
Policy Entropy: 1.05970
Value Function Loss: 3.65177

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.08648

Collected Steps per Second: 10,925.37412
Overall Steps per Second: 9,320.99420

Timestep Collection Time: 4.57797
Timestep Consumption Time: 0.78798
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.36595

Cumulative Model Updates: 50,649
Cumulative Timesteps: 844,876,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 844876650...
Checkpoint 844876650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,955.11335
Policy Entropy: 1.06069
Value Function Loss: 3.57894

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.07676

Collected Steps per Second: 11,147.96954
Overall Steps per Second: 9,649.48689

Timestep Collection Time: 4.48548
Timestep Consumption Time: 0.69656
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.18204

Cumulative Model Updates: 50,652
Cumulative Timesteps: 844,926,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,346.99357
Policy Entropy: 1.06142
Value Function Loss: 3.48549

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.06688

Collected Steps per Second: 10,974.10751
Overall Steps per Second: 9,335.16751

Timestep Collection Time: 4.55709
Timestep Consumption Time: 0.80007
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 5.35716

Cumulative Model Updates: 50,655
Cumulative Timesteps: 844,976,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 844976664...
Checkpoint 844976664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,535.67878
Policy Entropy: 1.05655
Value Function Loss: 3.34765

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.07153

Collected Steps per Second: 10,942.45187
Overall Steps per Second: 9,391.32646

Timestep Collection Time: 4.57100
Timestep Consumption Time: 0.75497
PPO Batch Consumption Time: 0.03927
Total Iteration Time: 5.32598

Cumulative Model Updates: 50,658
Cumulative Timesteps: 845,026,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,001.52766
Policy Entropy: 1.04948
Value Function Loss: 3.37176

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 11,009.66537
Overall Steps per Second: 9,307.08039

Timestep Collection Time: 4.54364
Timestep Consumption Time: 0.83119
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.37483

Cumulative Model Updates: 50,661
Cumulative Timesteps: 845,076,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845076706...
Checkpoint 845076706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,662.98732
Policy Entropy: 1.03861
Value Function Loss: 3.46067

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 10,543.60211
Overall Steps per Second: 9,080.67134

Timestep Collection Time: 4.74449
Timestep Consumption Time: 0.76436
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.50884

Cumulative Model Updates: 50,664
Cumulative Timesteps: 845,126,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,212.92153
Policy Entropy: 1.06229
Value Function Loss: 3.73312

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 10,909.18958
Overall Steps per Second: 9,478.67101

Timestep Collection Time: 4.58458
Timestep Consumption Time: 0.69190
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.27648

Cumulative Model Updates: 50,667
Cumulative Timesteps: 845,176,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 845176744...
Checkpoint 845176744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,649.44139
Policy Entropy: 1.05902
Value Function Loss: 3.65122

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.09226

Collected Steps per Second: 10,618.84287
Overall Steps per Second: 9,105.86483

Timestep Collection Time: 4.71087
Timestep Consumption Time: 0.78273
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.49360

Cumulative Model Updates: 50,670
Cumulative Timesteps: 845,226,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,600.52437
Policy Entropy: 1.05134
Value Function Loss: 3.61237

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.08515

Collected Steps per Second: 11,018.29256
Overall Steps per Second: 9,433.20995

Timestep Collection Time: 4.53918
Timestep Consumption Time: 0.76273
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 5.30191

Cumulative Model Updates: 50,673
Cumulative Timesteps: 845,276,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 845276782...
Checkpoint 845276782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,039.62264
Policy Entropy: 1.04545
Value Function Loss: 3.50643

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.18263
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 10,579.93725
Overall Steps per Second: 9,065.59113

Timestep Collection Time: 4.72668
Timestep Consumption Time: 0.78956
PPO Batch Consumption Time: 0.03939
Total Iteration Time: 5.51624

Cumulative Model Updates: 50,676
Cumulative Timesteps: 845,326,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,373.68101
Policy Entropy: 1.06174
Value Function Loss: 3.51123

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07716

Collected Steps per Second: 10,754.80774
Overall Steps per Second: 9,207.09297

Timestep Collection Time: 4.64946
Timestep Consumption Time: 0.78157
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.43103

Cumulative Model Updates: 50,679
Cumulative Timesteps: 845,376,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 845376794...
Checkpoint 845376794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,835.59724
Policy Entropy: 1.06004
Value Function Loss: 3.32062

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.07816

Collected Steps per Second: 10,702.94887
Overall Steps per Second: 9,356.35190

Timestep Collection Time: 4.67329
Timestep Consumption Time: 0.67260
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.34589

Cumulative Model Updates: 50,682
Cumulative Timesteps: 845,426,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,585.91190
Policy Entropy: 1.07095
Value Function Loss: 3.45282

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.07330
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 10,691.85925
Overall Steps per Second: 9,152.02425

Timestep Collection Time: 4.67926
Timestep Consumption Time: 0.78729
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.46655

Cumulative Model Updates: 50,685
Cumulative Timesteps: 845,476,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 845476842...
Checkpoint 845476842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,895.76647
Policy Entropy: 1.07334
Value Function Loss: 3.44897

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.07708
Value Function Update Magnitude: 0.07858

Collected Steps per Second: 10,486.77835
Overall Steps per Second: 9,073.00696

Timestep Collection Time: 4.76982
Timestep Consumption Time: 0.74324
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.51306

Cumulative Model Updates: 50,688
Cumulative Timesteps: 845,526,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,196.96222
Policy Entropy: 1.07477
Value Function Loss: 3.58953

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.07049
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 10,605.01655
Overall Steps per Second: 9,062.68584

Timestep Collection Time: 4.71532
Timestep Consumption Time: 0.80247
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.51779

Cumulative Model Updates: 50,691
Cumulative Timesteps: 845,576,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 845576868...
Checkpoint 845576868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,533.70403
Policy Entropy: 1.07219
Value Function Loss: 3.53381

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.08852

Collected Steps per Second: 10,640.28857
Overall Steps per Second: 9,141.01894

Timestep Collection Time: 4.70006
Timestep Consumption Time: 0.77088
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.47094

Cumulative Model Updates: 50,694
Cumulative Timesteps: 845,626,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752,818.06573
Policy Entropy: 1.06691
Value Function Loss: 3.58043

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 10,499.05218
Overall Steps per Second: 9,175.55722

Timestep Collection Time: 4.76386
Timestep Consumption Time: 0.68715
PPO Batch Consumption Time: 0.03808
Total Iteration Time: 5.45100

Cumulative Model Updates: 50,697
Cumulative Timesteps: 845,676,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845676894...
Checkpoint 845676894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,714.25882
Policy Entropy: 1.08178
Value Function Loss: 3.46472

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.09261

Collected Steps per Second: 10,542.44864
Overall Steps per Second: 9,001.03911

Timestep Collection Time: 4.74292
Timestep Consumption Time: 0.81222
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 5.55514

Cumulative Model Updates: 50,700
Cumulative Timesteps: 845,726,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,573.38286
Policy Entropy: 1.07726
Value Function Loss: 3.43169

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.09297

Collected Steps per Second: 10,569.08286
Overall Steps per Second: 9,051.41805

Timestep Collection Time: 4.73229
Timestep Consumption Time: 0.79347
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.52576

Cumulative Model Updates: 50,703
Cumulative Timesteps: 845,776,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845776912...
Checkpoint 845776912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551,175.66370
Policy Entropy: 1.07176
Value Function Loss: 3.40845

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 10,565.15577
Overall Steps per Second: 9,152.37403

Timestep Collection Time: 4.73386
Timestep Consumption Time: 0.73073
PPO Batch Consumption Time: 0.03933
Total Iteration Time: 5.46459

Cumulative Model Updates: 50,706
Cumulative Timesteps: 845,826,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,011.77244
Policy Entropy: 1.05390
Value Function Loss: 3.63627

Mean KL Divergence: 0.03197
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.09345

Collected Steps per Second: 10,231.97551
Overall Steps per Second: 8,743.02528

Timestep Collection Time: 4.88821
Timestep Consumption Time: 0.83247
PPO Batch Consumption Time: 0.03837
Total Iteration Time: 5.72067

Cumulative Model Updates: 50,709
Cumulative Timesteps: 845,876,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845876942...
Checkpoint 845876942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,200.29460
Policy Entropy: 1.06900
Value Function Loss: 3.61927

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 10,602.66161
Overall Steps per Second: 9,097.01108

Timestep Collection Time: 4.71806
Timestep Consumption Time: 0.78089
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.49895

Cumulative Model Updates: 50,712
Cumulative Timesteps: 845,926,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,464.14274
Policy Entropy: 1.06418
Value Function Loss: 3.61700

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 11,624.65987
Overall Steps per Second: 9,801.62181

Timestep Collection Time: 4.30258
Timestep Consumption Time: 0.80025
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.10283

Cumulative Model Updates: 50,715
Cumulative Timesteps: 845,976,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845976982...
Checkpoint 845976982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,496.51472
Policy Entropy: 1.05952
Value Function Loss: 3.53619

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 11,674.57051
Overall Steps per Second: 9,831.62980

Timestep Collection Time: 4.28281
Timestep Consumption Time: 0.80281
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 5.08563

Cumulative Model Updates: 50,718
Cumulative Timesteps: 846,026,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,823.93665
Policy Entropy: 1.07433
Value Function Loss: 3.40391

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 11,584.02312
Overall Steps per Second: 9,960.62120

Timestep Collection Time: 4.31888
Timestep Consumption Time: 0.70390
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.02278

Cumulative Model Updates: 50,721
Cumulative Timesteps: 846,077,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846077012...
Checkpoint 846077012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,210.06704
Policy Entropy: 1.09186
Value Function Loss: 3.23127

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09525

Collected Steps per Second: 11,516.75396
Overall Steps per Second: 9,698.50359

Timestep Collection Time: 4.34150
Timestep Consumption Time: 0.81393
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.15543

Cumulative Model Updates: 50,724
Cumulative Timesteps: 846,127,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,979.23469
Policy Entropy: 1.07243
Value Function Loss: 3.20975

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.08118

Collected Steps per Second: 11,050.29426
Overall Steps per Second: 9,459.59246

Timestep Collection Time: 4.52640
Timestep Consumption Time: 0.76115
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 5.28754

Cumulative Model Updates: 50,727
Cumulative Timesteps: 846,177,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 846177030...
Checkpoint 846177030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,088.26740
Policy Entropy: 1.07852
Value Function Loss: 3.27435

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.07570

Collected Steps per Second: 11,854.07098
Overall Steps per Second: 10,005.66817

Timestep Collection Time: 4.21948
Timestep Consumption Time: 0.77949
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.99897

Cumulative Model Updates: 50,730
Cumulative Timesteps: 846,227,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,375.14141
Policy Entropy: 1.07321
Value Function Loss: 3.28142

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.07068

Collected Steps per Second: 11,198.98911
Overall Steps per Second: 9,448.57276

Timestep Collection Time: 4.46737
Timestep Consumption Time: 0.82761
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.29498

Cumulative Model Updates: 50,733
Cumulative Timesteps: 846,277,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846277078...
Checkpoint 846277078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581,879.58905
Policy Entropy: 1.07889
Value Function Loss: 3.35069

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 10,968.29211
Overall Steps per Second: 9,418.76401

Timestep Collection Time: 4.55878
Timestep Consumption Time: 0.74999
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.30876

Cumulative Model Updates: 50,736
Cumulative Timesteps: 846,327,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,612.58697
Policy Entropy: 1.08755
Value Function Loss: 3.45047

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.07060

Collected Steps per Second: 10,967.45972
Overall Steps per Second: 9,398.00508

Timestep Collection Time: 4.56168
Timestep Consumption Time: 0.76179
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.32347

Cumulative Model Updates: 50,739
Cumulative Timesteps: 846,377,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846377110...
Checkpoint 846377110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,387.82371
Policy Entropy: 1.09071
Value Function Loss: 3.38064

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 10,723.76928
Overall Steps per Second: 9,112.59570

Timestep Collection Time: 4.66273
Timestep Consumption Time: 0.82440
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.48713

Cumulative Model Updates: 50,742
Cumulative Timesteps: 846,427,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,171.14581
Policy Entropy: 1.08364
Value Function Loss: 3.42140

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.07642
Value Function Update Magnitude: 0.10249

Collected Steps per Second: 11,003.99416
Overall Steps per Second: 9,523.99372

Timestep Collection Time: 4.54671
Timestep Consumption Time: 0.70655
PPO Batch Consumption Time: 0.04444
Total Iteration Time: 5.25326

Cumulative Model Updates: 50,745
Cumulative Timesteps: 846,477,144

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 846477144...
Checkpoint 846477144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,582.03717
Policy Entropy: 1.08289
Value Function Loss: 3.43103

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.07893
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 10,750.37705
Overall Steps per Second: 9,175.37883

Timestep Collection Time: 4.65305
Timestep Consumption Time: 0.79872
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.45176

Cumulative Model Updates: 50,748
Cumulative Timesteps: 846,527,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,637.17526
Policy Entropy: 1.07905
Value Function Loss: 3.57695

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.07328
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 10,462.76156
Overall Steps per Second: 9,035.70280

Timestep Collection Time: 4.78115
Timestep Consumption Time: 0.75511
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.53626

Cumulative Model Updates: 50,751
Cumulative Timesteps: 846,577,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 846577190...
Checkpoint 846577190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,795.96010
Policy Entropy: 1.07071
Value Function Loss: 3.68641

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.07310
Value Function Update Magnitude: 0.10313

Collected Steps per Second: 10,778.18681
Overall Steps per Second: 9,104.46850

Timestep Collection Time: 4.64085
Timestep Consumption Time: 0.85315
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.49401

Cumulative Model Updates: 50,754
Cumulative Timesteps: 846,627,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,894.80771
Policy Entropy: 1.06110
Value Function Loss: 3.62436

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 10,345.17188
Overall Steps per Second: 8,844.85088

Timestep Collection Time: 4.83549
Timestep Consumption Time: 0.82023
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.65572

Cumulative Model Updates: 50,757
Cumulative Timesteps: 846,677,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 846677234...
Checkpoint 846677234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,325.15984
Policy Entropy: 1.07539
Value Function Loss: 3.63244

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.09035

Collected Steps per Second: 10,379.67934
Overall Steps per Second: 9,094.85779

Timestep Collection Time: 4.81826
Timestep Consumption Time: 0.68067
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 5.49893

Cumulative Model Updates: 50,760
Cumulative Timesteps: 846,727,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,434.51506
Policy Entropy: 1.07760
Value Function Loss: 3.38741

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 10,340.46909
Overall Steps per Second: 8,877.97954

Timestep Collection Time: 4.83827
Timestep Consumption Time: 0.79702
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.63529

Cumulative Model Updates: 50,763
Cumulative Timesteps: 846,777,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846777276...
Checkpoint 846777276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,115.08580
Policy Entropy: 1.07748
Value Function Loss: 3.34703

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.07055
Value Function Update Magnitude: 0.08430

Collected Steps per Second: 10,433.52030
Overall Steps per Second: 8,906.82069

Timestep Collection Time: 4.79397
Timestep Consumption Time: 0.82172
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.61570

Cumulative Model Updates: 50,766
Cumulative Timesteps: 846,827,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,327.29804
Policy Entropy: 1.07158
Value Function Loss: 3.38760

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 10,612.32626
Overall Steps per Second: 9,098.47491

Timestep Collection Time: 4.71169
Timestep Consumption Time: 0.78396
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.49565

Cumulative Model Updates: 50,769
Cumulative Timesteps: 846,877,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 846877296...
Checkpoint 846877296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,297.84948
Policy Entropy: 1.06084
Value Function Loss: 3.55883

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.08256

Collected Steps per Second: 10,473.92051
Overall Steps per Second: 9,020.45361

Timestep Collection Time: 4.77586
Timestep Consumption Time: 0.76954
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.54540

Cumulative Model Updates: 50,772
Cumulative Timesteps: 846,927,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,157.32644
Policy Entropy: 1.07884
Value Function Loss: 3.73554

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 10,399.36563
Overall Steps per Second: 9,063.22501

Timestep Collection Time: 4.80818
Timestep Consumption Time: 0.70884
PPO Batch Consumption Time: 0.03822
Total Iteration Time: 5.51702

Cumulative Model Updates: 50,775
Cumulative Timesteps: 846,977,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 846977320...
Checkpoint 846977320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,233.10169
Policy Entropy: 1.07199
Value Function Loss: 3.55777

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.07822

Collected Steps per Second: 10,628.93535
Overall Steps per Second: 9,055.26034

Timestep Collection Time: 4.70527
Timestep Consumption Time: 0.81771
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 5.52298

Cumulative Model Updates: 50,778
Cumulative Timesteps: 847,027,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,726.92558
Policy Entropy: 1.07395
Value Function Loss: 3.65014

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.07264

Collected Steps per Second: 10,826.51013
Overall Steps per Second: 9,302.58515

Timestep Collection Time: 4.61903
Timestep Consumption Time: 0.75668
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 5.37571

Cumulative Model Updates: 50,781
Cumulative Timesteps: 847,077,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 847077340...
Checkpoint 847077340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,548.00697
Policy Entropy: 1.06839
Value Function Loss: 3.61535

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.08340

Collected Steps per Second: 11,223.11420
Overall Steps per Second: 9,742.13428

Timestep Collection Time: 4.45794
Timestep Consumption Time: 0.67769
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.13563

Cumulative Model Updates: 50,784
Cumulative Timesteps: 847,127,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,348.21274
Policy Entropy: 1.07073
Value Function Loss: 3.64272

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.09170

Collected Steps per Second: 11,063.06976
Overall Steps per Second: 9,413.55194

Timestep Collection Time: 4.51990
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 5.31192

Cumulative Model Updates: 50,787
Cumulative Timesteps: 847,177,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 847177376...
Checkpoint 847177376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,185.29726
Policy Entropy: 1.06627
Value Function Loss: 3.50805

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.17016
Policy Update Magnitude: 0.06260
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 11,156.53499
Overall Steps per Second: 9,494.75539

Timestep Collection Time: 4.48293
Timestep Consumption Time: 0.78461
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.26754

Cumulative Model Updates: 50,790
Cumulative Timesteps: 847,227,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,105.60324
Policy Entropy: 1.08310
Value Function Loss: 3.38961

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.08788

Collected Steps per Second: 11,002.19411
Overall Steps per Second: 9,369.69098

Timestep Collection Time: 4.54727
Timestep Consumption Time: 0.79228
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.33956

Cumulative Model Updates: 50,793
Cumulative Timesteps: 847,277,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 847277420...
Checkpoint 847277420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,738.20877
Policy Entropy: 1.08320
Value Function Loss: 3.46682

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 10,890.94199
Overall Steps per Second: 9,345.15660

Timestep Collection Time: 4.59189
Timestep Consumption Time: 0.75955
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.35144

Cumulative Model Updates: 50,796
Cumulative Timesteps: 847,327,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,909.00124
Policy Entropy: 1.06808
Value Function Loss: 3.34293

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.08737

Collected Steps per Second: 11,180.43308
Overall Steps per Second: 9,719.13507

Timestep Collection Time: 4.47299
Timestep Consumption Time: 0.67253
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 5.14552

Cumulative Model Updates: 50,799
Cumulative Timesteps: 847,377,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 847377440...
Checkpoint 847377440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,525.53470
Policy Entropy: 1.05329
Value Function Loss: 3.46628

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.20318
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.08022

Collected Steps per Second: 10,855.57214
Overall Steps per Second: 9,261.59837

Timestep Collection Time: 4.60888
Timestep Consumption Time: 0.79321
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 5.40209

Cumulative Model Updates: 50,802
Cumulative Timesteps: 847,427,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,012.35682
Policy Entropy: 1.06516
Value Function Loss: 3.36490

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.07548

Collected Steps per Second: 10,616.31027
Overall Steps per Second: 9,147.24896

Timestep Collection Time: 4.71049
Timestep Consumption Time: 0.75651
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.46700

Cumulative Model Updates: 50,805
Cumulative Timesteps: 847,477,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 847477480...
Checkpoint 847477480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,570.58949
Policy Entropy: 1.06726
Value Function Loss: 3.59656

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.07025

Collected Steps per Second: 10,486.06445
Overall Steps per Second: 9,114.41134

Timestep Collection Time: 4.76995
Timestep Consumption Time: 0.71784
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.48779

Cumulative Model Updates: 50,808
Cumulative Timesteps: 847,527,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722,680.90472
Policy Entropy: 1.06817
Value Function Loss: 3.43117

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.06995

Collected Steps per Second: 10,871.57558
Overall Steps per Second: 9,228.25681

Timestep Collection Time: 4.60007
Timestep Consumption Time: 0.81916
PPO Batch Consumption Time: 0.03924
Total Iteration Time: 5.41922

Cumulative Model Updates: 50,811
Cumulative Timesteps: 847,577,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 847577508...
Checkpoint 847577508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,605.20139
Policy Entropy: 1.05958
Value Function Loss: 3.47556

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.07368

Collected Steps per Second: 10,649.76424
Overall Steps per Second: 9,093.13200

Timestep Collection Time: 4.69588
Timestep Consumption Time: 0.80388
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.49976

Cumulative Model Updates: 50,814
Cumulative Timesteps: 847,627,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,021.30065
Policy Entropy: 1.06696
Value Function Loss: 3.36852

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 10,802.43487
Overall Steps per Second: 9,301.15293

Timestep Collection Time: 4.63025
Timestep Consumption Time: 0.74736
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.37761

Cumulative Model Updates: 50,817
Cumulative Timesteps: 847,677,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847677536...
Checkpoint 847677536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,963.47051
Policy Entropy: 1.06299
Value Function Loss: 3.49345

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.06115

Collected Steps per Second: 10,613.00433
Overall Steps per Second: 9,133.24484

Timestep Collection Time: 4.71309
Timestep Consumption Time: 0.76361
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.47670

Cumulative Model Updates: 50,820
Cumulative Timesteps: 847,727,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557,021.45654
Policy Entropy: 1.07418
Value Function Loss: 3.69211

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 10,969.08373
Overall Steps per Second: 9,549.13547

Timestep Collection Time: 4.56082
Timestep Consumption Time: 0.67819
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.23901

Cumulative Model Updates: 50,823
Cumulative Timesteps: 847,777,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 847777584...
Checkpoint 847777584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,244.15654
Policy Entropy: 1.08050
Value Function Loss: 3.53839

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.08025

Collected Steps per Second: 10,333.48571
Overall Steps per Second: 8,892.17591

Timestep Collection Time: 4.83980
Timestep Consumption Time: 0.78447
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 5.62427

Cumulative Model Updates: 50,826
Cumulative Timesteps: 847,827,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,061.65986
Policy Entropy: 1.08301
Value Function Loss: 3.51332

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.09012

Collected Steps per Second: 10,750.39771
Overall Steps per Second: 9,273.52619

Timestep Collection Time: 4.65229
Timestep Consumption Time: 0.74091
PPO Batch Consumption Time: 0.03738
Total Iteration Time: 5.39320

Cumulative Model Updates: 50,829
Cumulative Timesteps: 847,877,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 847877610...
Checkpoint 847877610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560,499.72023
Policy Entropy: 1.08258
Value Function Loss: 3.43221

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 10,499.39674
Overall Steps per Second: 9,179.37052

Timestep Collection Time: 4.76313
Timestep Consumption Time: 0.68496
PPO Batch Consumption Time: 0.03320
Total Iteration Time: 5.44809

Cumulative Model Updates: 50,832
Cumulative Timesteps: 847,927,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,805.80383
Policy Entropy: 1.07976
Value Function Loss: 3.42908

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.09051

Collected Steps per Second: 10,606.51918
Overall Steps per Second: 9,040.93496

Timestep Collection Time: 4.71559
Timestep Consumption Time: 0.81658
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.53217

Cumulative Model Updates: 50,835
Cumulative Timesteps: 847,977,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 847977636...
Checkpoint 847977636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,915.06027
Policy Entropy: 1.08008
Value Function Loss: 3.49971

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 10,422.29290
Overall Steps per Second: 8,934.02742

Timestep Collection Time: 4.79894
Timestep Consumption Time: 0.79943
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.59837

Cumulative Model Updates: 50,838
Cumulative Timesteps: 848,027,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,143.31828
Policy Entropy: 1.07596
Value Function Loss: 3.47257

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 10,322.58959
Overall Steps per Second: 8,829.85138

Timestep Collection Time: 4.84530
Timestep Consumption Time: 0.81913
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.66442

Cumulative Model Updates: 50,841
Cumulative Timesteps: 848,077,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848077668...
Checkpoint 848077668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,944.56021
Policy Entropy: 1.08450
Value Function Loss: 3.69371

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.08672

Collected Steps per Second: 10,374.00540
Overall Steps per Second: 8,903.32078

Timestep Collection Time: 4.82070
Timestep Consumption Time: 0.79630
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.61701

Cumulative Model Updates: 50,844
Cumulative Timesteps: 848,127,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,362.65504
Policy Entropy: 1.08464
Value Function Loss: 3.60693

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.08336

Collected Steps per Second: 10,739.21004
Overall Steps per Second: 9,346.87942

Timestep Collection Time: 4.65844
Timestep Consumption Time: 0.69393
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.35237

Cumulative Model Updates: 50,847
Cumulative Timesteps: 848,177,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 848177706...
Checkpoint 848177706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,742.88087
Policy Entropy: 1.06943
Value Function Loss: 3.70045

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.09400

Collected Steps per Second: 11,009.29565
Overall Steps per Second: 9,187.88719

Timestep Collection Time: 4.54271
Timestep Consumption Time: 0.90055
PPO Batch Consumption Time: 0.04712
Total Iteration Time: 5.44325

Cumulative Model Updates: 50,850
Cumulative Timesteps: 848,227,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,934.43761
Policy Entropy: 1.05893
Value Function Loss: 3.72787

Mean KL Divergence: 0.02898
SB3 Clip Fraction: 0.19698
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.09611

Collected Steps per Second: 11,255.83799
Overall Steps per Second: 9,635.63140

Timestep Collection Time: 4.44427
Timestep Consumption Time: 0.74729
PPO Batch Consumption Time: 0.03855
Total Iteration Time: 5.19156

Cumulative Model Updates: 50,853
Cumulative Timesteps: 848,277,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 848277742...
Checkpoint 848277742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,230.52769
Policy Entropy: 1.07379
Value Function Loss: 3.87967

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 11,391.88895
Overall Steps per Second: 9,645.22213

Timestep Collection Time: 4.39067
Timestep Consumption Time: 0.79511
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.18578

Cumulative Model Updates: 50,856
Cumulative Timesteps: 848,327,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,590.21951
Policy Entropy: 1.07748
Value Function Loss: 3.67756

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 10,867.83350
Overall Steps per Second: 9,378.20892

Timestep Collection Time: 4.60276
Timestep Consumption Time: 0.73110
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.33385

Cumulative Model Updates: 50,859
Cumulative Timesteps: 848,377,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 848377782...
Checkpoint 848377782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,756.63570
Policy Entropy: 1.07553
Value Function Loss: 3.60743

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.07086

Collected Steps per Second: 11,541.17555
Overall Steps per Second: 9,765.78493

Timestep Collection Time: 4.33491
Timestep Consumption Time: 0.78807
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.12299

Cumulative Model Updates: 50,862
Cumulative Timesteps: 848,427,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715,819.43788
Policy Entropy: 1.06434
Value Function Loss: 3.46790

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.16986
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.08244

Collected Steps per Second: 11,488.55965
Overall Steps per Second: 9,670.88383

Timestep Collection Time: 4.35303
Timestep Consumption Time: 0.81817
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.17119

Cumulative Model Updates: 50,865
Cumulative Timesteps: 848,477,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 848477822...
Checkpoint 848477822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,379.13554
Policy Entropy: 1.07343
Value Function Loss: 3.53177

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.07885

Collected Steps per Second: 10,724.64260
Overall Steps per Second: 9,353.95650

Timestep Collection Time: 4.66384
Timestep Consumption Time: 0.68342
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.34726

Cumulative Model Updates: 50,868
Cumulative Timesteps: 848,527,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,301.40550
Policy Entropy: 1.07955
Value Function Loss: 3.45744

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.17011
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 10,759.95292
Overall Steps per Second: 9,203.96300

Timestep Collection Time: 4.64891
Timestep Consumption Time: 0.78593
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.43483

Cumulative Model Updates: 50,871
Cumulative Timesteps: 848,577,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 848577862...
Checkpoint 848577862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,407.09636
Policy Entropy: 1.06031
Value Function Loss: 3.52738

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.07212

Collected Steps per Second: 11,027.25633
Overall Steps per Second: 9,337.87438

Timestep Collection Time: 4.53676
Timestep Consumption Time: 0.82078
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.35754

Cumulative Model Updates: 50,874
Cumulative Timesteps: 848,627,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,668.83033
Policy Entropy: 1.05571
Value Function Loss: 3.46330

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.17893
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 10,912.61029
Overall Steps per Second: 9,352.47334

Timestep Collection Time: 4.58314
Timestep Consumption Time: 0.76454
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.34768

Cumulative Model Updates: 50,877
Cumulative Timesteps: 848,677,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 848677904...
Checkpoint 848677904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,142.39982
Policy Entropy: 1.06764
Value Function Loss: 3.47837

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.08116

Collected Steps per Second: 10,938.35220
Overall Steps per Second: 9,356.46637

Timestep Collection Time: 4.57272
Timestep Consumption Time: 0.77310
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.34582

Cumulative Model Updates: 50,880
Cumulative Timesteps: 848,727,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,774.01509
Policy Entropy: 1.08416
Value Function Loss: 3.54113

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.08835

Collected Steps per Second: 10,701.97761
Overall Steps per Second: 9,335.98223

Timestep Collection Time: 4.67297
Timestep Consumption Time: 0.68373
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.35669

Cumulative Model Updates: 50,883
Cumulative Timesteps: 848,777,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 848777932...
Checkpoint 848777932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,191.51346
Policy Entropy: 1.06161
Value Function Loss: 3.82812

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08695

Collected Steps per Second: 10,591.66764
Overall Steps per Second: 9,024.65514

Timestep Collection Time: 4.72182
Timestep Consumption Time: 0.81988
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.54171

Cumulative Model Updates: 50,886
Cumulative Timesteps: 848,827,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,893.82746
Policy Entropy: 1.07861
Value Function Loss: 3.89492

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08512

Collected Steps per Second: 10,617.00194
Overall Steps per Second: 9,159.67903

Timestep Collection Time: 4.71037
Timestep Consumption Time: 0.74943
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.45980

Cumulative Model Updates: 50,889
Cumulative Timesteps: 848,877,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 848877954...
Checkpoint 848877954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,420.76088
Policy Entropy: 1.07908
Value Function Loss: 3.77587

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.08235

Collected Steps per Second: 10,299.38558
Overall Steps per Second: 9,046.39318

Timestep Collection Time: 4.85641
Timestep Consumption Time: 0.67265
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.52905

Cumulative Model Updates: 50,892
Cumulative Timesteps: 848,927,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,070.05108
Policy Entropy: 1.06047
Value Function Loss: 3.52195

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.15763
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 10,576.68485
Overall Steps per Second: 9,082.04026

Timestep Collection Time: 4.72757
Timestep Consumption Time: 0.77802
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.50559

Cumulative Model Updates: 50,895
Cumulative Timesteps: 848,977,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 848977974...
Checkpoint 848977974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,888.34521
Policy Entropy: 1.05502
Value Function Loss: 3.39510

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 10,438.41358
Overall Steps per Second: 9,009.43440

Timestep Collection Time: 4.79096
Timestep Consumption Time: 0.75989
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.55085

Cumulative Model Updates: 50,898
Cumulative Timesteps: 849,027,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,528.79120
Policy Entropy: 1.07048
Value Function Loss: 3.37082

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.06977

Collected Steps per Second: 10,763.21021
Overall Steps per Second: 9,186.64469

Timestep Collection Time: 4.64657
Timestep Consumption Time: 0.79742
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.44399

Cumulative Model Updates: 50,901
Cumulative Timesteps: 849,077,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849077996...
Checkpoint 849077996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,160.01985
Policy Entropy: 1.07865
Value Function Loss: 3.32952

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.07002

Collected Steps per Second: 10,313.66590
Overall Steps per Second: 8,937.16656

Timestep Collection Time: 4.85065
Timestep Consumption Time: 0.74710
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.59775

Cumulative Model Updates: 50,904
Cumulative Timesteps: 849,128,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,069.70551
Policy Entropy: 1.05728
Value Function Loss: 3.17960

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.08360

Collected Steps per Second: 10,286.58432
Overall Steps per Second: 8,872.04688

Timestep Collection Time: 4.86167
Timestep Consumption Time: 0.77513
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.63681

Cumulative Model Updates: 50,907
Cumulative Timesteps: 849,178,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 849178034...
Checkpoint 849178034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,906.82750
Policy Entropy: 1.06589
Value Function Loss: 3.05954

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 10,566.99968
Overall Steps per Second: 9,075.93669

Timestep Collection Time: 4.73398
Timestep Consumption Time: 0.77773
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.51172

Cumulative Model Updates: 50,910
Cumulative Timesteps: 849,228,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,092.72038
Policy Entropy: 1.06252
Value Function Loss: 3.19446

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 10,464.73809
Overall Steps per Second: 9,090.46222

Timestep Collection Time: 4.77852
Timestep Consumption Time: 0.72241
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 5.50093

Cumulative Model Updates: 50,913
Cumulative Timesteps: 849,278,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 849278064...
Checkpoint 849278064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,739.45622
Policy Entropy: 1.04428
Value Function Loss: 3.31546

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 11,055.90602
Overall Steps per Second: 9,587.08911

Timestep Collection Time: 4.52283
Timestep Consumption Time: 0.69293
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 5.21576

Cumulative Model Updates: 50,916
Cumulative Timesteps: 849,328,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,040.47347
Policy Entropy: 1.03582
Value Function Loss: 3.56413

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.19655
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.09087

Collected Steps per Second: 11,002.74633
Overall Steps per Second: 9,387.61429

Timestep Collection Time: 4.54686
Timestep Consumption Time: 0.78228
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.32915

Cumulative Model Updates: 50,919
Cumulative Timesteps: 849,378,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 849378096...
Checkpoint 849378096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,171.01732
Policy Entropy: 1.05117
Value Function Loss: 3.39475

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.10294

Collected Steps per Second: 10,857.57446
Overall Steps per Second: 9,297.00760

Timestep Collection Time: 4.60545
Timestep Consumption Time: 0.77306
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.37850

Cumulative Model Updates: 50,922
Cumulative Timesteps: 849,428,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,369.85535
Policy Entropy: 1.06796
Value Function Loss: 3.51794

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.17595
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.10724

Collected Steps per Second: 10,672.48883
Overall Steps per Second: 9,168.45070

Timestep Collection Time: 4.68738
Timestep Consumption Time: 0.76894
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.45632

Cumulative Model Updates: 50,925
Cumulative Timesteps: 849,478,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 849478126...
Checkpoint 849478126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,987.61738
Policy Entropy: 1.03964
Value Function Loss: 3.37366

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.19953
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.10824

Collected Steps per Second: 10,945.35629
Overall Steps per Second: 9,222.00510

Timestep Collection Time: 4.56943
Timestep Consumption Time: 0.85391
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 5.42333

Cumulative Model Updates: 50,928
Cumulative Timesteps: 849,528,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,369.03707
Policy Entropy: 1.05958
Value Function Loss: 3.40225

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.09833

Collected Steps per Second: 11,004.82342
Overall Steps per Second: 9,578.79668

Timestep Collection Time: 4.54455
Timestep Consumption Time: 0.67656
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.22112

Cumulative Model Updates: 50,931
Cumulative Timesteps: 849,578,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849578152...
Checkpoint 849578152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,442.81576
Policy Entropy: 1.05808
Value Function Loss: 3.33252

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.08820

Collected Steps per Second: 10,756.79648
Overall Steps per Second: 9,233.94966

Timestep Collection Time: 4.64860
Timestep Consumption Time: 0.76664
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.41523

Cumulative Model Updates: 50,934
Cumulative Timesteps: 849,628,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,378.21301
Policy Entropy: 1.05316
Value Function Loss: 3.33260

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.07817

Collected Steps per Second: 10,895.80919
Overall Steps per Second: 9,294.32899

Timestep Collection Time: 4.59021
Timestep Consumption Time: 0.79093
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 5.38113

Cumulative Model Updates: 50,937
Cumulative Timesteps: 849,678,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 849678170...
Checkpoint 849678170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,580.80785
Policy Entropy: 1.03699
Value Function Loss: 3.52502

Mean KL Divergence: 0.02959
SB3 Clip Fraction: 0.17678
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 10,967.73196
Overall Steps per Second: 9,301.30856

Timestep Collection Time: 4.56029
Timestep Consumption Time: 0.81702
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 5.37731

Cumulative Model Updates: 50,940
Cumulative Timesteps: 849,728,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,748.93574
Policy Entropy: 1.05658
Value Function Loss: 3.55344

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.07503

Collected Steps per Second: 10,552.05602
Overall Steps per Second: 9,071.94467

Timestep Collection Time: 4.73917
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.51238

Cumulative Model Updates: 50,943
Cumulative Timesteps: 849,778,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849778194...
Checkpoint 849778194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,360.94915
Policy Entropy: 1.04835
Value Function Loss: 3.47166

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 10,821.31257
Overall Steps per Second: 9,392.57217

Timestep Collection Time: 4.62254
Timestep Consumption Time: 0.70315
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.32570

Cumulative Model Updates: 50,946
Cumulative Timesteps: 849,828,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,006.42705
Policy Entropy: 1.04342
Value Function Loss: 3.18146

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07003

Collected Steps per Second: 10,562.92135
Overall Steps per Second: 8,999.10730

Timestep Collection Time: 4.73543
Timestep Consumption Time: 0.82290
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 5.55833

Cumulative Model Updates: 50,949
Cumulative Timesteps: 849,878,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 849878236...
Checkpoint 849878236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,688.29257
Policy Entropy: 1.02172
Value Function Loss: 3.13761

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.16786
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 10,567.72831
Overall Steps per Second: 9,121.68744

Timestep Collection Time: 4.73195
Timestep Consumption Time: 0.75015
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.48210

Cumulative Model Updates: 50,952
Cumulative Timesteps: 849,928,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,708.92597
Policy Entropy: 1.04340
Value Function Loss: 3.14550

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.09553

Collected Steps per Second: 10,871.25080
Overall Steps per Second: 9,313.88109

Timestep Collection Time: 4.60168
Timestep Consumption Time: 0.76944
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.37112

Cumulative Model Updates: 50,955
Cumulative Timesteps: 849,978,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 849978268...
Checkpoint 849978268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,733.08742
Policy Entropy: 1.03990
Value Function Loss: 3.19222

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 10,286.88718
Overall Steps per Second: 8,884.99386

Timestep Collection Time: 4.86095
Timestep Consumption Time: 0.76697
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.62792

Cumulative Model Updates: 50,958
Cumulative Timesteps: 850,028,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,555.65849
Policy Entropy: 1.05102
Value Function Loss: 3.27256

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 10,693.90215
Overall Steps per Second: 9,348.17647

Timestep Collection Time: 4.67668
Timestep Consumption Time: 0.67324
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.34992

Cumulative Model Updates: 50,961
Cumulative Timesteps: 850,078,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 850078284...
Checkpoint 850078284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,526.24163
Policy Entropy: 1.04369
Value Function Loss: 3.23211

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.08882

Collected Steps per Second: 10,231.05560
Overall Steps per Second: 8,826.78964

Timestep Collection Time: 4.88767
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.66525

Cumulative Model Updates: 50,964
Cumulative Timesteps: 850,128,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,531.76962
Policy Entropy: 1.04328
Value Function Loss: 3.37572

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.08060

Collected Steps per Second: 10,620.10267
Overall Steps per Second: 9,121.09076

Timestep Collection Time: 4.70881
Timestep Consumption Time: 0.77387
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.48268

Cumulative Model Updates: 50,967
Cumulative Timesteps: 850,178,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 850178298...
Checkpoint 850178298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,890.25424
Policy Entropy: 1.04751
Value Function Loss: 3.25535

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 10,512.33284
Overall Steps per Second: 9,225.34927

Timestep Collection Time: 4.75632
Timestep Consumption Time: 0.66353
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.41985

Cumulative Model Updates: 50,970
Cumulative Timesteps: 850,228,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,304.91343
Policy Entropy: 1.05258
Value Function Loss: 3.49153

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08590

Collected Steps per Second: 10,610.88094
Overall Steps per Second: 8,943.84660

Timestep Collection Time: 4.71346
Timestep Consumption Time: 0.87854
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 5.59200

Cumulative Model Updates: 50,973
Cumulative Timesteps: 850,278,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 850278312...
Checkpoint 850278312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,566.25759
Policy Entropy: 1.05181
Value Function Loss: 3.46585

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.08013

Collected Steps per Second: 10,672.60925
Overall Steps per Second: 9,181.73946

Timestep Collection Time: 4.68770
Timestep Consumption Time: 0.76116
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.44886

Cumulative Model Updates: 50,976
Cumulative Timesteps: 850,328,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,598.94230
Policy Entropy: 1.05180
Value Function Loss: 3.47757

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 10,845.74429
Overall Steps per Second: 9,255.68354

Timestep Collection Time: 4.61195
Timestep Consumption Time: 0.79230
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.40425

Cumulative Model Updates: 50,979
Cumulative Timesteps: 850,378,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850378362...
Checkpoint 850378362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,270.35314
Policy Entropy: 1.04866
Value Function Loss: 3.41797

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 11,530.02410
Overall Steps per Second: 9,835.28338

Timestep Collection Time: 4.33859
Timestep Consumption Time: 0.74759
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.08618

Cumulative Model Updates: 50,982
Cumulative Timesteps: 850,428,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,304.13048
Policy Entropy: 1.04983
Value Function Loss: 3.40204

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.06990
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 11,528.61549
Overall Steps per Second: 9,931.56170

Timestep Collection Time: 4.33825
Timestep Consumption Time: 0.69762
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.03586

Cumulative Model Updates: 50,985
Cumulative Timesteps: 850,478,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 850478400...
Checkpoint 850478400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,217.37702
Policy Entropy: 1.04972
Value Function Loss: 3.45029

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.06564
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 11,446.49586
Overall Steps per Second: 9,702.47885

Timestep Collection Time: 4.36850
Timestep Consumption Time: 0.78524
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 5.15373

Cumulative Model Updates: 50,988
Cumulative Timesteps: 850,528,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,860.40094
Policy Entropy: 1.05933
Value Function Loss: 3.32431

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.07538

Collected Steps per Second: 10,905.88706
Overall Steps per Second: 9,384.68153

Timestep Collection Time: 4.58743
Timestep Consumption Time: 0.74360
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.33103

Cumulative Model Updates: 50,991
Cumulative Timesteps: 850,578,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 850578434...
Checkpoint 850578434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,584.90310
Policy Entropy: 1.06508
Value Function Loss: 3.39881

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 11,879.27860
Overall Steps per Second: 9,999.65235

Timestep Collection Time: 4.21069
Timestep Consumption Time: 0.79148
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.00217

Cumulative Model Updates: 50,994
Cumulative Timesteps: 850,628,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,899.60318
Policy Entropy: 1.06225
Value Function Loss: 3.49927

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.07373
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 11,590.67103
Overall Steps per Second: 9,780.90943

Timestep Collection Time: 4.31450
Timestep Consumption Time: 0.79831
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.11282

Cumulative Model Updates: 50,997
Cumulative Timesteps: 850,678,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 850678462...
Checkpoint 850678462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741,058.73903
Policy Entropy: 1.05174
Value Function Loss: 3.57533

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.15481
Policy Update Magnitude: 0.07107
Value Function Update Magnitude: 0.08946

Collected Steps per Second: 10,818.27098
Overall Steps per Second: 9,397.51922

Timestep Collection Time: 4.62347
Timestep Consumption Time: 0.69899
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.32247

Cumulative Model Updates: 51,000
Cumulative Timesteps: 850,728,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,736.30470
Policy Entropy: 1.06788
Value Function Loss: 3.54038

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.09226

Collected Steps per Second: 10,858.63939
Overall Steps per Second: 9,303.17677

Timestep Collection Time: 4.60665
Timestep Consumption Time: 0.77022
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.37687

Cumulative Model Updates: 51,003
Cumulative Timesteps: 850,778,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 850778502...
Checkpoint 850778502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,600.64224
Policy Entropy: 1.07429
Value Function Loss: 3.40589

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.09285

Collected Steps per Second: 10,644.13423
Overall Steps per Second: 9,160.82196

Timestep Collection Time: 4.69817
Timestep Consumption Time: 0.76072
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.45890

Cumulative Model Updates: 51,006
Cumulative Timesteps: 850,828,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,723.34703
Policy Entropy: 1.06485
Value Function Loss: 3.31897

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.09235

Collected Steps per Second: 10,509.12281
Overall Steps per Second: 9,114.45873

Timestep Collection Time: 4.75910
Timestep Consumption Time: 0.72822
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.48733

Cumulative Model Updates: 51,009
Cumulative Timesteps: 850,878,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 850878524...
Checkpoint 850878524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,072.03840
Policy Entropy: 1.03688
Value Function Loss: 3.26951

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 10,844.94248
Overall Steps per Second: 9,186.96415

Timestep Collection Time: 4.61044
Timestep Consumption Time: 0.83205
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 5.44249

Cumulative Model Updates: 51,012
Cumulative Timesteps: 850,928,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,194.08746
Policy Entropy: 1.05936
Value Function Loss: 3.44079

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 10,654.01184
Overall Steps per Second: 9,305.68981

Timestep Collection Time: 4.69382
Timestep Consumption Time: 0.68010
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.37392

Cumulative Model Updates: 51,015
Cumulative Timesteps: 850,978,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 850978532...
Checkpoint 850978532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746,858.37375
Policy Entropy: 1.05847
Value Function Loss: 3.50759

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 10,644.87796
Overall Steps per Second: 9,101.86067

Timestep Collection Time: 4.69728
Timestep Consumption Time: 0.79632
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.49360

Cumulative Model Updates: 51,018
Cumulative Timesteps: 851,028,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,039.91264
Policy Entropy: 1.04619
Value Function Loss: 3.55978

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.09670

Collected Steps per Second: 10,727.32117
Overall Steps per Second: 9,221.19651

Timestep Collection Time: 4.66379
Timestep Consumption Time: 0.76175
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.42554

Cumulative Model Updates: 51,021
Cumulative Timesteps: 851,078,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 851078564...
Checkpoint 851078564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,844.48139
Policy Entropy: 1.02885
Value Function Loss: 3.49434

Mean KL Divergence: 0.03371
SB3 Clip Fraction: 0.21000
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.10223

Collected Steps per Second: 10,326.40242
Overall Steps per Second: 8,799.81126

Timestep Collection Time: 4.84409
Timestep Consumption Time: 0.84035
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.68444

Cumulative Model Updates: 51,024
Cumulative Timesteps: 851,128,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,053.91116
Policy Entropy: 1.04337
Value Function Loss: 3.52333

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.10917

Collected Steps per Second: 10,573.57446
Overall Steps per Second: 9,042.25996

Timestep Collection Time: 4.73085
Timestep Consumption Time: 0.80117
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.53202

Cumulative Model Updates: 51,027
Cumulative Timesteps: 851,178,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851178608...
Checkpoint 851178608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,813.42315
Policy Entropy: 1.05052
Value Function Loss: 3.42521

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.11130

Collected Steps per Second: 10,635.80991
Overall Steps per Second: 9,242.09347

Timestep Collection Time: 4.70392
Timestep Consumption Time: 0.70936
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.41328

Cumulative Model Updates: 51,030
Cumulative Timesteps: 851,228,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,473.95876
Policy Entropy: 1.03566
Value Function Loss: 3.37246

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.11033

Collected Steps per Second: 10,612.33558
Overall Steps per Second: 9,035.20799

Timestep Collection Time: 4.71244
Timestep Consumption Time: 0.82257
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.53501

Cumulative Model Updates: 51,033
Cumulative Timesteps: 851,278,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 851278648...
Checkpoint 851278648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,481.85878
Policy Entropy: 1.02355
Value Function Loss: 3.27201

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.18019
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 10,397.85634
Overall Steps per Second: 8,964.25041

Timestep Collection Time: 4.81080
Timestep Consumption Time: 0.76937
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.58017

Cumulative Model Updates: 51,036
Cumulative Timesteps: 851,328,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,057.22888
Policy Entropy: 1.03260
Value Function Loss: 3.48293

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10,543.37335
Overall Steps per Second: 9,033.84910

Timestep Collection Time: 4.74307
Timestep Consumption Time: 0.79255
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.53562

Cumulative Model Updates: 51,039
Cumulative Timesteps: 851,378,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 851378678...
Checkpoint 851378678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,375.30374
Policy Entropy: 1.04679
Value Function Loss: 3.52700

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 10,292.14874
Overall Steps per Second: 8,865.69516

Timestep Collection Time: 4.85943
Timestep Consumption Time: 0.78186
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.64129

Cumulative Model Updates: 51,042
Cumulative Timesteps: 851,428,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,715.64725
Policy Entropy: 1.00743
Value Function Loss: 3.52285

Mean KL Divergence: 0.04822
SB3 Clip Fraction: 0.23733
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.09846

Collected Steps per Second: 10,623.42071
Overall Steps per Second: 9,264.31446

Timestep Collection Time: 4.70677
Timestep Consumption Time: 0.69050
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.39727

Cumulative Model Updates: 51,045
Cumulative Timesteps: 851,478,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 851478694...
Checkpoint 851478694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,516.41578
Policy Entropy: 1.03826
Value Function Loss: 3.27191

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.17589
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 11,130.31090
Overall Steps per Second: 9,469.34707

Timestep Collection Time: 4.49224
Timestep Consumption Time: 0.78796
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.28020

Cumulative Model Updates: 51,048
Cumulative Timesteps: 851,528,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,588.92232
Policy Entropy: 1.03044
Value Function Loss: 3.21910

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 10,966.81578
Overall Steps per Second: 9,562.40834

Timestep Collection Time: 4.55994
Timestep Consumption Time: 0.66971
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.22964

Cumulative Model Updates: 51,051
Cumulative Timesteps: 851,578,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 851578702...
Checkpoint 851578702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,178.65483
Policy Entropy: 1.02696
Value Function Loss: 3.29246

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 10,780.66810
Overall Steps per Second: 9,207.80859

Timestep Collection Time: 4.63812
Timestep Consumption Time: 0.79227
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.43039

Cumulative Model Updates: 51,054
Cumulative Timesteps: 851,628,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,908.21175
Policy Entropy: 1.04724
Value Function Loss: 3.27209

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.15303
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 10,428.72887
Overall Steps per Second: 9,055.51277

Timestep Collection Time: 4.79675
Timestep Consumption Time: 0.72740
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.52415

Cumulative Model Updates: 51,057
Cumulative Timesteps: 851,678,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 851678728...
Checkpoint 851678728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,468.65230
Policy Entropy: 1.04724
Value Function Loss: 3.08536

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.09998

Collected Steps per Second: 11,028.99432
Overall Steps per Second: 9,401.13913

Timestep Collection Time: 4.53387
Timestep Consumption Time: 0.78506
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.31893

Cumulative Model Updates: 51,060
Cumulative Timesteps: 851,728,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,546.81971
Policy Entropy: 1.05007
Value Function Loss: 3.13478

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.10110

Collected Steps per Second: 10,863.10595
Overall Steps per Second: 9,293.80686

Timestep Collection Time: 4.60494
Timestep Consumption Time: 0.77756
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.38251

Cumulative Model Updates: 51,063
Cumulative Timesteps: 851,778,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 851778756...
Checkpoint 851778756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,439.22918
Policy Entropy: 1.04587
Value Function Loss: 3.37721

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 11,010.04192
Overall Steps per Second: 9,563.14330

Timestep Collection Time: 4.54313
Timestep Consumption Time: 0.68737
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 5.23050

Cumulative Model Updates: 51,066
Cumulative Timesteps: 851,828,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,014.46478
Policy Entropy: 1.05893
Value Function Loss: 3.66808

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.16231
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.10441

Collected Steps per Second: 10,928.91542
Overall Steps per Second: 9,277.36399

Timestep Collection Time: 4.57612
Timestep Consumption Time: 0.81464
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.39076

Cumulative Model Updates: 51,069
Cumulative Timesteps: 851,878,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 851878788...
Checkpoint 851878788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,285.38275
Policy Entropy: 1.05591
Value Function Loss: 3.55944

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.16563
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.10579

Collected Steps per Second: 10,504.26015
Overall Steps per Second: 9,067.27667

Timestep Collection Time: 4.76054
Timestep Consumption Time: 0.75445
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.51500

Cumulative Model Updates: 51,072
Cumulative Timesteps: 851,928,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,237.36934
Policy Entropy: 1.04316
Value Function Loss: 3.45150

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 10,463.72523
Overall Steps per Second: 9,045.95846

Timestep Collection Time: 4.78032
Timestep Consumption Time: 0.74922
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.52954

Cumulative Model Updates: 51,075
Cumulative Timesteps: 851,978,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 851978814...
Checkpoint 851978814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,994.71153
Policy Entropy: 1.02698
Value Function Loss: 3.40151

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.19047
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 11,061.01174
Overall Steps per Second: 9,496.56997

Timestep Collection Time: 4.52219
Timestep Consumption Time: 0.74497
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 5.26716

Cumulative Model Updates: 51,078
Cumulative Timesteps: 852,028,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,879.49155
Policy Entropy: 1.05096
Value Function Loss: 3.57258

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.10129

Collected Steps per Second: 10,668.39525
Overall Steps per Second: 9,325.00405

Timestep Collection Time: 4.68730
Timestep Consumption Time: 0.67527
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.36257

Cumulative Model Updates: 51,081
Cumulative Timesteps: 852,078,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 852078840...
Checkpoint 852078840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,330.56951
Policy Entropy: 1.04693
Value Function Loss: 3.49861

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.10389

Collected Steps per Second: 10,787.16082
Overall Steps per Second: 9,268.76263

Timestep Collection Time: 4.63699
Timestep Consumption Time: 0.75963
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.39662

Cumulative Model Updates: 51,084
Cumulative Timesteps: 852,128,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,010.26887
Policy Entropy: 1.04521
Value Function Loss: 3.42608

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 10,673.17225
Overall Steps per Second: 9,223.05634

Timestep Collection Time: 4.68652
Timestep Consumption Time: 0.73685
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.42336

Cumulative Model Updates: 51,087
Cumulative Timesteps: 852,178,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 852178880...
Checkpoint 852178880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,919.31533
Policy Entropy: 1.02817
Value Function Loss: 3.09947

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 10,391.08170
Overall Steps per Second: 9,024.33090

Timestep Collection Time: 4.81451
Timestep Consumption Time: 0.72917
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 5.54368

Cumulative Model Updates: 51,090
Cumulative Timesteps: 852,228,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,417.55810
Policy Entropy: 1.04699
Value Function Loss: 3.40147

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.09294

Collected Steps per Second: 10,696.31377
Overall Steps per Second: 9,144.91347

Timestep Collection Time: 4.67544
Timestep Consumption Time: 0.79317
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.46861

Cumulative Model Updates: 51,093
Cumulative Timesteps: 852,278,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 852278918...
Checkpoint 852278918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,398.45892
Policy Entropy: 1.05135
Value Function Loss: 3.40349

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.17749
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.08621

Collected Steps per Second: 10,765.41475
Overall Steps per Second: 9,238.91513

Timestep Collection Time: 4.64543
Timestep Consumption Time: 0.76754
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.41297

Cumulative Model Updates: 51,096
Cumulative Timesteps: 852,328,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,950.76709
Policy Entropy: 1.03665
Value Function Loss: 3.59945

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 10,906.19843
Overall Steps per Second: 9,294.07625

Timestep Collection Time: 4.58455
Timestep Consumption Time: 0.79522
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.37977

Cumulative Model Updates: 51,099
Cumulative Timesteps: 852,378,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 852378928...
Checkpoint 852378928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,498.68976
Policy Entropy: 1.02234
Value Function Loss: 3.47101

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.21268
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 10,612.67181
Overall Steps per Second: 9,113.50391

Timestep Collection Time: 4.71229
Timestep Consumption Time: 0.77517
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.48746

Cumulative Model Updates: 51,102
Cumulative Timesteps: 852,428,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,639.90769
Policy Entropy: 1.03612
Value Function Loss: 3.55164

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 10,532.98123
Overall Steps per Second: 9,180.26317

Timestep Collection Time: 4.74908
Timestep Consumption Time: 0.69978
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.44886

Cumulative Model Updates: 51,105
Cumulative Timesteps: 852,478,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 852478960...
Checkpoint 852478960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,652.54544
Policy Entropy: 1.04479
Value Function Loss: 3.36356

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.07120
Value Function Update Magnitude: 0.07768

Collected Steps per Second: 10,055.92543
Overall Steps per Second: 8,671.98414

Timestep Collection Time: 4.97219
Timestep Consumption Time: 0.79350
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.76569

Cumulative Model Updates: 51,108
Cumulative Timesteps: 852,528,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,242.34894
Policy Entropy: 1.04183
Value Function Loss: 3.32979

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.08514

Collected Steps per Second: 10,602.68713
Overall Steps per Second: 9,173.89600

Timestep Collection Time: 4.71597
Timestep Consumption Time: 0.73449
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.45047

Cumulative Model Updates: 51,111
Cumulative Timesteps: 852,578,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 852578962...
Checkpoint 852578962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,771.91744
Policy Entropy: 1.04458
Value Function Loss: 3.17224

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.08974

Collected Steps per Second: 11,706.48437
Overall Steps per Second: 9,904.33677

Timestep Collection Time: 4.27216
Timestep Consumption Time: 0.77734
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.04951

Cumulative Model Updates: 51,114
Cumulative Timesteps: 852,628,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,903.21154
Policy Entropy: 1.03541
Value Function Loss: 3.37323

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.15577
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 11,802.46725
Overall Steps per Second: 9,906.50282

Timestep Collection Time: 4.23776
Timestep Consumption Time: 0.81105
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 5.04880

Cumulative Model Updates: 51,117
Cumulative Timesteps: 852,678,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 852678990...
Checkpoint 852678990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,502.65987
Policy Entropy: 1.05025
Value Function Loss: 3.31280

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.08556

Collected Steps per Second: 11,349.53508
Overall Steps per Second: 9,870.16410

Timestep Collection Time: 4.40829
Timestep Consumption Time: 0.66073
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.06901

Cumulative Model Updates: 51,120
Cumulative Timesteps: 852,729,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,057.10731
Policy Entropy: 1.05175
Value Function Loss: 3.40645

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 11,675.24392
Overall Steps per Second: 9,819.66654

Timestep Collection Time: 4.28445
Timestep Consumption Time: 0.80961
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.09406

Cumulative Model Updates: 51,123
Cumulative Timesteps: 852,779,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 852779044...
Checkpoint 852779044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,502.84410
Policy Entropy: 1.04510
Value Function Loss: 3.41681

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.07338

Collected Steps per Second: 11,331.92639
Overall Steps per Second: 9,696.13917

Timestep Collection Time: 4.41372
Timestep Consumption Time: 0.74462
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.15834

Cumulative Model Updates: 51,126
Cumulative Timesteps: 852,829,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,694.55813
Policy Entropy: 1.03934
Value Function Loss: 3.43268

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.18243
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 11,695.85911
Overall Steps per Second: 9,852.10534

Timestep Collection Time: 4.27604
Timestep Consumption Time: 0.80023
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.07628

Cumulative Model Updates: 51,129
Cumulative Timesteps: 852,879,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 852879072...
Checkpoint 852879072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,705.63790
Policy Entropy: 1.04739
Value Function Loss: 3.41821

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.07446

Collected Steps per Second: 10,919.74891
Overall Steps per Second: 9,279.66576

Timestep Collection Time: 4.58033
Timestep Consumption Time: 0.80952
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.38985

Cumulative Model Updates: 51,132
Cumulative Timesteps: 852,929,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,621.96539
Policy Entropy: 1.06025
Value Function Loss: 3.27072

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 10,667.34596
Overall Steps per Second: 9,285.31437

Timestep Collection Time: 4.68720
Timestep Consumption Time: 0.69765
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.38485

Cumulative Model Updates: 51,135
Cumulative Timesteps: 852,979,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 852979088...
Checkpoint 852979088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,038.24609
Policy Entropy: 1.03508
Value Function Loss: 3.33714

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.06995

Collected Steps per Second: 11,044.68760
Overall Steps per Second: 9,378.01845

Timestep Collection Time: 4.52924
Timestep Consumption Time: 0.80494
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.33418

Cumulative Model Updates: 51,138
Cumulative Timesteps: 853,029,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,414.64921
Policy Entropy: 1.04015
Value Function Loss: 3.22934

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.08522

Collected Steps per Second: 10,360.02259
Overall Steps per Second: 8,911.49315

Timestep Collection Time: 4.82740
Timestep Consumption Time: 0.78468
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.61208

Cumulative Model Updates: 51,141
Cumulative Timesteps: 853,079,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 853079124...
Checkpoint 853079124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,195.28847
Policy Entropy: 1.05788
Value Function Loss: 3.40992

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 11,178.05649
Overall Steps per Second: 9,457.75226

Timestep Collection Time: 4.47466
Timestep Consumption Time: 0.81391
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.28857

Cumulative Model Updates: 51,144
Cumulative Timesteps: 853,129,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,346.55438
Policy Entropy: 1.06257
Value Function Loss: 3.50096

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 10,888.87793
Overall Steps per Second: 9,347.83610

Timestep Collection Time: 4.59294
Timestep Consumption Time: 0.75717
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 5.35012

Cumulative Model Updates: 51,147
Cumulative Timesteps: 853,179,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 853179154...
Checkpoint 853179154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,576.53503
Policy Entropy: 1.05884
Value Function Loss: 3.43097

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.09536

Collected Steps per Second: 10,750.45432
Overall Steps per Second: 9,401.47737

Timestep Collection Time: 4.65227
Timestep Consumption Time: 0.66753
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.31980

Cumulative Model Updates: 51,150
Cumulative Timesteps: 853,229,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,700.53963
Policy Entropy: 1.05144
Value Function Loss: 3.34612

Mean KL Divergence: 0.03375
SB3 Clip Fraction: 0.19240
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 10,482.67967
Overall Steps per Second: 9,016.51677

Timestep Collection Time: 4.77111
Timestep Consumption Time: 0.77582
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.54693

Cumulative Model Updates: 51,153
Cumulative Timesteps: 853,279,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853279182...
Checkpoint 853279182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,751.00383
Policy Entropy: 1.06375
Value Function Loss: 3.30602

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 10,734.22733
Overall Steps per Second: 9,187.08932

Timestep Collection Time: 4.66061
Timestep Consumption Time: 0.78486
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 5.44547

Cumulative Model Updates: 51,156
Cumulative Timesteps: 853,329,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,867.79087
Policy Entropy: 1.06546
Value Function Loss: 3.51302

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 10,607.60057
Overall Steps per Second: 9,092.63444

Timestep Collection Time: 4.71568
Timestep Consumption Time: 0.78570
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.50138

Cumulative Model Updates: 51,159
Cumulative Timesteps: 853,379,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 853379232...
Checkpoint 853379232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,142.12753
Policy Entropy: 1.05012
Value Function Loss: 3.73164

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 10,496.13406
Overall Steps per Second: 9,025.11570

Timestep Collection Time: 4.76461
Timestep Consumption Time: 0.77659
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.54120

Cumulative Model Updates: 51,162
Cumulative Timesteps: 853,429,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,569.54301
Policy Entropy: 1.06844
Value Function Loss: 3.69689

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.08476

Collected Steps per Second: 10,593.79090
Overall Steps per Second: 9,208.88976

Timestep Collection Time: 4.72144
Timestep Consumption Time: 0.71005
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.43149

Cumulative Model Updates: 51,165
Cumulative Timesteps: 853,479,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 853479260...
Checkpoint 853479260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,654.75078
Policy Entropy: 1.06983
Value Function Loss: 3.51347

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.15653
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.08964

Collected Steps per Second: 10,470.48344
Overall Steps per Second: 8,991.35677

Timestep Collection Time: 4.77686
Timestep Consumption Time: 0.78582
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.56268

Cumulative Model Updates: 51,168
Cumulative Timesteps: 853,529,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,779.26837
Policy Entropy: 1.05656
Value Function Loss: 3.44228

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.09297

Collected Steps per Second: 10,874.83294
Overall Steps per Second: 9,280.26983

Timestep Collection Time: 4.59979
Timestep Consumption Time: 0.79035
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.39014

Cumulative Model Updates: 51,171
Cumulative Timesteps: 853,579,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 853579298...
Checkpoint 853579298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,491.20358
Policy Entropy: 1.03742
Value Function Loss: 3.45503

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.20293
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 10,246.29049
Overall Steps per Second: 8,785.18760

Timestep Collection Time: 4.87981
Timestep Consumption Time: 0.81158
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.69140

Cumulative Model Updates: 51,174
Cumulative Timesteps: 853,629,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,705.07446
Policy Entropy: 1.04905
Value Function Loss: 3.59113

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 10,631.48234
Overall Steps per Second: 9,124.17363

Timestep Collection Time: 4.70546
Timestep Consumption Time: 0.77734
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.48280

Cumulative Model Updates: 51,177
Cumulative Timesteps: 853,679,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 853679324...
Checkpoint 853679324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749,333.41981
Policy Entropy: 1.05856
Value Function Loss: 3.44959

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 10,678.54799
Overall Steps per Second: 9,246.92346

Timestep Collection Time: 4.68285
Timestep Consumption Time: 0.72501
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.40785

Cumulative Model Updates: 51,180
Cumulative Timesteps: 853,729,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,330.66569
Policy Entropy: 1.03792
Value Function Loss: 3.55571

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 11,336.50977
Overall Steps per Second: 9,639.68149

Timestep Collection Time: 4.41176
Timestep Consumption Time: 0.77658
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.18835

Cumulative Model Updates: 51,183
Cumulative Timesteps: 853,779,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853779344...
Checkpoint 853779344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,656.24139
Policy Entropy: 1.04637
Value Function Loss: 3.39827

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.16249
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.07415

Collected Steps per Second: 11,036.14672
Overall Steps per Second: 9,549.39332

Timestep Collection Time: 4.53292
Timestep Consumption Time: 0.70573
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 5.23866

Cumulative Model Updates: 51,186
Cumulative Timesteps: 853,829,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,858.65126
Policy Entropy: 1.05444
Value Function Loss: 3.30449

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 10,783.41443
Overall Steps per Second: 9,238.06089

Timestep Collection Time: 4.63916
Timestep Consumption Time: 0.77604
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.41521

Cumulative Model Updates: 51,189
Cumulative Timesteps: 853,879,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 853879396...
Checkpoint 853879396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,036.10347
Policy Entropy: 1.03742
Value Function Loss: 3.19198

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.08323

Collected Steps per Second: 10,527.79580
Overall Steps per Second: 9,007.64975

Timestep Collection Time: 4.75104
Timestep Consumption Time: 0.80179
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.55284

Cumulative Model Updates: 51,192
Cumulative Timesteps: 853,929,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,916.02430
Policy Entropy: 1.04040
Value Function Loss: 3.31663

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 11,011.40712
Overall Steps per Second: 9,583.34279

Timestep Collection Time: 4.54293
Timestep Consumption Time: 0.67697
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.21989

Cumulative Model Updates: 51,195
Cumulative Timesteps: 853,979,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 853979438...
Checkpoint 853979438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,370.21335
Policy Entropy: 1.06170
Value Function Loss: 3.41446

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 10,740.84902
Overall Steps per Second: 9,207.91476

Timestep Collection Time: 4.65568
Timestep Consumption Time: 0.77508
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.43076

Cumulative Model Updates: 51,198
Cumulative Timesteps: 854,029,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777,809.52313
Policy Entropy: 1.05965
Value Function Loss: 3.49106

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07732

Collected Steps per Second: 11,025.83900
Overall Steps per Second: 9,449.01748

Timestep Collection Time: 4.53698
Timestep Consumption Time: 0.75712
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.29410

Cumulative Model Updates: 51,201
Cumulative Timesteps: 854,079,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 854079468...
Checkpoint 854079468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,988.28642
Policy Entropy: 1.06530
Value Function Loss: 3.34628

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 11,174.55291
Overall Steps per Second: 9,539.36471

Timestep Collection Time: 4.47481
Timestep Consumption Time: 0.76705
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.24186

Cumulative Model Updates: 51,204
Cumulative Timesteps: 854,129,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,464.18201
Policy Entropy: 1.05216
Value Function Loss: 3.39872

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.07973

Collected Steps per Second: 10,502.23656
Overall Steps per Second: 8,901.70440

Timestep Collection Time: 4.76375
Timestep Consumption Time: 0.85652
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.62027

Cumulative Model Updates: 51,207
Cumulative Timesteps: 854,179,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 854179502...
Checkpoint 854179502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,006.39197
Policy Entropy: 1.04582
Value Function Loss: 3.24153

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.07986

Collected Steps per Second: 10,725.47570
Overall Steps per Second: 9,362.16306

Timestep Collection Time: 4.66441
Timestep Consumption Time: 0.67923
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.34364

Cumulative Model Updates: 51,210
Cumulative Timesteps: 854,229,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,698.20517
Policy Entropy: 1.05016
Value Function Loss: 3.25043

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.07865

Collected Steps per Second: 11,049.43787
Overall Steps per Second: 9,346.78408

Timestep Collection Time: 4.52602
Timestep Consumption Time: 0.82448
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.35050

Cumulative Model Updates: 51,213
Cumulative Timesteps: 854,279,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 854279540...
Checkpoint 854279540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,475.81447
Policy Entropy: 1.05034
Value Function Loss: 3.35497

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 10,340.20357
Overall Steps per Second: 8,971.36943

Timestep Collection Time: 4.83704
Timestep Consumption Time: 0.73803
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.57507

Cumulative Model Updates: 51,216
Cumulative Timesteps: 854,329,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,596.43988
Policy Entropy: 1.05470
Value Function Loss: 3.42769

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.08228

Collected Steps per Second: 10,751.39220
Overall Steps per Second: 9,274.47419

Timestep Collection Time: 4.65298
Timestep Consumption Time: 0.74097
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.39394

Cumulative Model Updates: 51,219
Cumulative Timesteps: 854,379,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 854379582...
Checkpoint 854379582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,019.52964
Policy Entropy: 1.05426
Value Function Loss: 3.44274

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.07657
Value Function Update Magnitude: 0.10352

Collected Steps per Second: 10,766.51720
Overall Steps per Second: 9,228.48629

Timestep Collection Time: 4.64458
Timestep Consumption Time: 0.77407
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.41866

Cumulative Model Updates: 51,222
Cumulative Timesteps: 854,429,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,015.59202
Policy Entropy: 1.04989
Value Function Loss: 3.25563

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.07742
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 10,453.17240
Overall Steps per Second: 9,037.07002

Timestep Collection Time: 4.78515
Timestep Consumption Time: 0.74983
PPO Batch Consumption Time: 0.03771
Total Iteration Time: 5.53498

Cumulative Model Updates: 51,225
Cumulative Timesteps: 854,479,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 854479608...
Checkpoint 854479608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,564.86697
Policy Entropy: 1.04915
Value Function Loss: 3.24299

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 10,790.72932
Overall Steps per Second: 9,273.08629

Timestep Collection Time: 4.63361
Timestep Consumption Time: 0.75834
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.39195

Cumulative Model Updates: 51,228
Cumulative Timesteps: 854,529,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,534.15013
Policy Entropy: 1.05718
Value Function Loss: 3.49909

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.08989

Collected Steps per Second: 10,556.84475
Overall Steps per Second: 9,028.14967

Timestep Collection Time: 4.73759
Timestep Consumption Time: 0.80219
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 5.53978

Cumulative Model Updates: 51,231
Cumulative Timesteps: 854,579,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 854579622...
Checkpoint 854579622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,814.89813
Policy Entropy: 1.07009
Value Function Loss: 3.49216

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.09973

Collected Steps per Second: 10,552.97638
Overall Steps per Second: 9,200.71429

Timestep Collection Time: 4.74084
Timestep Consumption Time: 0.69678
PPO Batch Consumption Time: 0.03853
Total Iteration Time: 5.43762

Cumulative Model Updates: 51,234
Cumulative Timesteps: 854,629,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,162.36247
Policy Entropy: 1.07307
Value Function Loss: 3.56976

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 10,596.95307
Overall Steps per Second: 9,086.93100

Timestep Collection Time: 4.71834
Timestep Consumption Time: 0.78407
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.50241

Cumulative Model Updates: 51,237
Cumulative Timesteps: 854,679,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 854679652...
Checkpoint 854679652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,801.69076
Policy Entropy: 1.05324
Value Function Loss: 3.35076

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.10897

Collected Steps per Second: 10,051.21445
Overall Steps per Second: 8,690.27061

Timestep Collection Time: 4.97612
Timestep Consumption Time: 0.77929
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 5.75540

Cumulative Model Updates: 51,240
Cumulative Timesteps: 854,729,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,982.08424
Policy Entropy: 1.03447
Value Function Loss: 3.35082

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.19246
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 10,907.59944
Overall Steps per Second: 9,297.09624

Timestep Collection Time: 4.58414
Timestep Consumption Time: 0.79410
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.37824

Cumulative Model Updates: 51,243
Cumulative Timesteps: 854,779,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 854779670...
Checkpoint 854779670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,045.73755
Policy Entropy: 1.04746
Value Function Loss: 3.24925

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.11988

Collected Steps per Second: 10,995.01332
Overall Steps per Second: 9,347.14136

Timestep Collection Time: 4.54952
Timestep Consumption Time: 0.80207
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 5.35158

Cumulative Model Updates: 51,246
Cumulative Timesteps: 854,829,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,402.50623
Policy Entropy: 1.05409
Value Function Loss: 3.28079

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.13175

Collected Steps per Second: 11,740.70233
Overall Steps per Second: 10,091.91680

Timestep Collection Time: 4.25937
Timestep Consumption Time: 0.69588
PPO Batch Consumption Time: 0.03825
Total Iteration Time: 4.95525

Cumulative Model Updates: 51,249
Cumulative Timesteps: 854,879,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 854879700...
Checkpoint 854879700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,385.58298
Policy Entropy: 1.03689
Value Function Loss: 3.35310

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 11,824.38341
Overall Steps per Second: 9,974.03281

Timestep Collection Time: 4.22855
Timestep Consumption Time: 0.78447
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.01302

Cumulative Model Updates: 51,252
Cumulative Timesteps: 854,929,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,878.30234
Policy Entropy: 1.02980
Value Function Loss: 3.32851

Mean KL Divergence: 0.03062
SB3 Clip Fraction: 0.19420
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11,625.76997
Overall Steps per Second: 9,886.46225

Timestep Collection Time: 4.30182
Timestep Consumption Time: 0.75681
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.05863

Cumulative Model Updates: 51,255
Cumulative Timesteps: 854,979,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 854979712...
Checkpoint 854979712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,503.84919
Policy Entropy: 1.04293
Value Function Loss: 3.40338

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.09463

Collected Steps per Second: 10,971.85281
Overall Steps per Second: 9,379.37086

Timestep Collection Time: 4.55894
Timestep Consumption Time: 0.77404
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.33298

Cumulative Model Updates: 51,258
Cumulative Timesteps: 855,029,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,511.76992
Policy Entropy: 1.05563
Value Function Loss: 3.43954

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.09039

Collected Steps per Second: 11,973.05383
Overall Steps per Second: 9,983.57924

Timestep Collection Time: 4.17671
Timestep Consumption Time: 0.83231
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.00903

Cumulative Model Updates: 51,261
Cumulative Timesteps: 855,079,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 855079740...
Checkpoint 855079740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,888.61970
Policy Entropy: 1.02787
Value Function Loss: 3.48177

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.09313

Collected Steps per Second: 11,650.90388
Overall Steps per Second: 9,989.18145

Timestep Collection Time: 4.29426
Timestep Consumption Time: 0.71436
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.00862

Cumulative Model Updates: 51,264
Cumulative Timesteps: 855,129,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,472.55847
Policy Entropy: 1.04532
Value Function Loss: 3.48024

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.08742

Collected Steps per Second: 10,727.04835
Overall Steps per Second: 9,212.98700

Timestep Collection Time: 4.66261
Timestep Consumption Time: 0.76625
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 5.42886

Cumulative Model Updates: 51,267
Cumulative Timesteps: 855,179,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 855179788...
Checkpoint 855179788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,368.00940
Policy Entropy: 1.04282
Value Function Loss: 3.50331

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 10,620.22514
Overall Steps per Second: 9,259.39727

Timestep Collection Time: 4.70875
Timestep Consumption Time: 0.69203
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.40078

Cumulative Model Updates: 51,270
Cumulative Timesteps: 855,229,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,074.16688
Policy Entropy: 1.02967
Value Function Loss: 3.55250

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 11,148.15846
Overall Steps per Second: 9,464.92140

Timestep Collection Time: 4.48648
Timestep Consumption Time: 0.79787
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 5.28435

Cumulative Model Updates: 51,273
Cumulative Timesteps: 855,279,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 855279812...
Checkpoint 855279812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,197.91903
Policy Entropy: 1.01982
Value Function Loss: 3.47040

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.19349
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.05850

Collected Steps per Second: 10,225.45841
Overall Steps per Second: 8,828.17372

Timestep Collection Time: 4.89034
Timestep Consumption Time: 0.77402
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.66437

Cumulative Model Updates: 51,276
Cumulative Timesteps: 855,329,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,399.95953
Policy Entropy: 1.03512
Value Function Loss: 3.31310

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.06217

Collected Steps per Second: 10,934.60220
Overall Steps per Second: 9,480.12410

Timestep Collection Time: 4.57410
Timestep Consumption Time: 0.70178
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.27588

Cumulative Model Updates: 51,279
Cumulative Timesteps: 855,379,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 855379834...
Checkpoint 855379834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,379.80550
Policy Entropy: 1.04740
Value Function Loss: 3.18828

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 10,581.14711
Overall Steps per Second: 9,120.02901

Timestep Collection Time: 4.72557
Timestep Consumption Time: 0.75708
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.48266

Cumulative Model Updates: 51,282
Cumulative Timesteps: 855,429,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765,683.63529
Policy Entropy: 1.02739
Value Function Loss: 3.27358

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 10,759.01600
Overall Steps per Second: 9,258.43267

Timestep Collection Time: 4.65005
Timestep Consumption Time: 0.75367
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.40372

Cumulative Model Updates: 51,285
Cumulative Timesteps: 855,479,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 855479866...
Checkpoint 855479866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,287.21140
Policy Entropy: 1.04097
Value Function Loss: 3.51743

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.16425
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 11,128.33896
Overall Steps per Second: 9,446.70834

Timestep Collection Time: 4.49537
Timestep Consumption Time: 0.80023
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.29560

Cumulative Model Updates: 51,288
Cumulative Timesteps: 855,529,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,651.63427
Policy Entropy: 1.03613
Value Function Loss: 3.48335

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 10,385.08001
Overall Steps per Second: 8,898.04256

Timestep Collection Time: 4.81460
Timestep Consumption Time: 0.80461
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.61921

Cumulative Model Updates: 51,291
Cumulative Timesteps: 855,579,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 855579892...
Checkpoint 855579892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,725.51574
Policy Entropy: 1.04594
Value Function Loss: 3.43508

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.10928

Collected Steps per Second: 10,447.40268
Overall Steps per Second: 9,108.33627

Timestep Collection Time: 4.78798
Timestep Consumption Time: 0.70391
PPO Batch Consumption Time: 0.03754
Total Iteration Time: 5.49189

Cumulative Model Updates: 51,294
Cumulative Timesteps: 855,629,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,151.74419
Policy Entropy: 1.03225
Value Function Loss: 3.20680

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 10,587.44601
Overall Steps per Second: 9,074.21282

Timestep Collection Time: 4.72522
Timestep Consumption Time: 0.78799
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.51321

Cumulative Model Updates: 51,297
Cumulative Timesteps: 855,679,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 855679942...
Checkpoint 855679942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.24031
Policy Entropy: 1.05131
Value Function Loss: 3.24104

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.15879
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 10,632.78624
Overall Steps per Second: 9,073.09580

Timestep Collection Time: 4.70244
Timestep Consumption Time: 0.80836
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.51080

Cumulative Model Updates: 51,300
Cumulative Timesteps: 855,729,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,910.01130
Policy Entropy: 1.05417
Value Function Loss: 3.36653

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.09792

Collected Steps per Second: 10,628.87157
Overall Steps per Second: 9,319.91544

Timestep Collection Time: 4.70549
Timestep Consumption Time: 0.66087
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.36636

Cumulative Model Updates: 51,303
Cumulative Timesteps: 855,779,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 855779956...
Checkpoint 855779956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,888.06077
Policy Entropy: 1.04152
Value Function Loss: 3.44703

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 10,656.15657
Overall Steps per Second: 9,134.22970

Timestep Collection Time: 4.69400
Timestep Consumption Time: 0.78210
PPO Batch Consumption Time: 0.03836
Total Iteration Time: 5.47610

Cumulative Model Updates: 51,306
Cumulative Timesteps: 855,829,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,289.96652
Policy Entropy: 1.03832
Value Function Loss: 3.40789

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 10,150.64761
Overall Steps per Second: 8,835.08630

Timestep Collection Time: 4.92836
Timestep Consumption Time: 0.73384
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.66220

Cumulative Model Updates: 51,309
Cumulative Timesteps: 855,880,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 855880002...
Checkpoint 855880002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,843.39612
Policy Entropy: 1.03089
Value Function Loss: 3.37606

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 10,795.91959
Overall Steps per Second: 9,184.93928

Timestep Collection Time: 4.63360
Timestep Consumption Time: 0.81270
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.44631

Cumulative Model Updates: 51,312
Cumulative Timesteps: 855,930,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,915.92223
Policy Entropy: 1.05001
Value Function Loss: 3.48559

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 11,042.12317
Overall Steps per Second: 9,428.15621

Timestep Collection Time: 4.52902
Timestep Consumption Time: 0.77530
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.30432

Cumulative Model Updates: 51,315
Cumulative Timesteps: 855,980,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855980036...
Checkpoint 855980036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,807.80470
Policy Entropy: 1.05483
Value Function Loss: 3.48945

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 11,167.69838
Overall Steps per Second: 9,661.24728

Timestep Collection Time: 4.47988
Timestep Consumption Time: 0.69854
PPO Batch Consumption Time: 0.03919
Total Iteration Time: 5.17842

Cumulative Model Updates: 51,318
Cumulative Timesteps: 856,030,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,948.60663
Policy Entropy: 1.04251
Value Function Loss: 3.51003

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 11,232.17645
Overall Steps per Second: 9,511.22341

Timestep Collection Time: 4.45292
Timestep Consumption Time: 0.80571
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.25863

Cumulative Model Updates: 51,321
Cumulative Timesteps: 856,080,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856080082...
Checkpoint 856080082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,594.99462
Policy Entropy: 1.02924
Value Function Loss: 3.44510

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.19819
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 10,522.88672
Overall Steps per Second: 9,010.22393

Timestep Collection Time: 4.75440
Timestep Consumption Time: 0.79818
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.55258

Cumulative Model Updates: 51,324
Cumulative Timesteps: 856,130,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,255.01742
Policy Entropy: 1.03485
Value Function Loss: 3.46551

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 11,117.64541
Overall Steps per Second: 9,565.34749

Timestep Collection Time: 4.49933
Timestep Consumption Time: 0.73017
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.22950

Cumulative Model Updates: 51,327
Cumulative Timesteps: 856,180,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856180134...
Checkpoint 856180134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,940.08483
Policy Entropy: 1.05279
Value Function Loss: 3.37963

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.06312

Collected Steps per Second: 11,095.54809
Overall Steps per Second: 9,449.39322

Timestep Collection Time: 4.50884
Timestep Consumption Time: 0.78547
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.29431

Cumulative Model Updates: 51,330
Cumulative Timesteps: 856,230,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,557.42659
Policy Entropy: 1.02001
Value Function Loss: 3.40614

Mean KL Divergence: 0.04148
SB3 Clip Fraction: 0.17203
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 10,843.24420
Overall Steps per Second: 9,266.07417

Timestep Collection Time: 4.61356
Timestep Consumption Time: 0.78527
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.39883

Cumulative Model Updates: 51,333
Cumulative Timesteps: 856,280,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 856280188...
Checkpoint 856280188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,047.51233
Policy Entropy: 1.03572
Value Function Loss: 3.49554

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 11,224.07902
Overall Steps per Second: 9,564.95738

Timestep Collection Time: 4.45596
Timestep Consumption Time: 0.77292
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.22888

Cumulative Model Updates: 51,336
Cumulative Timesteps: 856,330,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,908.52164
Policy Entropy: 1.04107
Value Function Loss: 3.50905

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.06440

Collected Steps per Second: 10,766.34502
Overall Steps per Second: 9,283.33976

Timestep Collection Time: 4.64559
Timestep Consumption Time: 0.74213
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.38772

Cumulative Model Updates: 51,339
Cumulative Timesteps: 856,380,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856380218...
Checkpoint 856380218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,821.02166
Policy Entropy: 1.03946
Value Function Loss: 3.36709

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 10,017.69463
Overall Steps per Second: 8,783.82800

Timestep Collection Time: 4.99197
Timestep Consumption Time: 0.70122
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.69319

Cumulative Model Updates: 51,342
Cumulative Timesteps: 856,430,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,393.75827
Policy Entropy: 1.04431
Value Function Loss: 3.22347

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.07310

Collected Steps per Second: 10,829.61449
Overall Steps per Second: 9,254.88244

Timestep Collection Time: 4.61974
Timestep Consumption Time: 0.78606
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.40580

Cumulative Model Updates: 51,345
Cumulative Timesteps: 856,480,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 856480256...
Checkpoint 856480256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,140.25207
Policy Entropy: 1.04160
Value Function Loss: 3.17826

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.06705
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 10,180.24254
Overall Steps per Second: 8,816.90709

Timestep Collection Time: 4.91167
Timestep Consumption Time: 0.75948
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.67115

Cumulative Model Updates: 51,348
Cumulative Timesteps: 856,530,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,918.55574
Policy Entropy: 1.03554
Value Function Loss: 3.27916

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.15727
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.07783

Collected Steps per Second: 11,231.86874
Overall Steps per Second: 9,535.79662

Timestep Collection Time: 4.45251
Timestep Consumption Time: 0.79194
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.24445

Cumulative Model Updates: 51,351
Cumulative Timesteps: 856,580,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 856580268...
Checkpoint 856580268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,012.83112
Policy Entropy: 1.04577
Value Function Loss: 3.38914

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 9,793.30556
Overall Steps per Second: 8,345.11104

Timestep Collection Time: 5.10614
Timestep Consumption Time: 0.88611
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 5.99225

Cumulative Model Updates: 51,354
Cumulative Timesteps: 856,630,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,191.96544
Policy Entropy: 1.05602
Value Function Loss: 3.40302

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.07578

Collected Steps per Second: 9,187.87046
Overall Steps per Second: 8,133.06145

Timestep Collection Time: 5.44435
Timestep Consumption Time: 0.70610
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 6.15045

Cumulative Model Updates: 51,357
Cumulative Timesteps: 856,680,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856680296...
Checkpoint 856680296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,678.66526
Policy Entropy: 1.04793
Value Function Loss: 3.37719

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 9,864.02498
Overall Steps per Second: 8,522.11857

Timestep Collection Time: 5.07136
Timestep Consumption Time: 0.79854
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 5.86990

Cumulative Model Updates: 51,360
Cumulative Timesteps: 856,730,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,631.35478
Policy Entropy: 1.03228
Value Function Loss: 3.43911

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.05640

Collected Steps per Second: 10,170.31082
Overall Steps per Second: 8,740.28005

Timestep Collection Time: 4.91784
Timestep Consumption Time: 0.80463
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.72247

Cumulative Model Updates: 51,363
Cumulative Timesteps: 856,780,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 856780336...
Checkpoint 856780336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,624.69686
Policy Entropy: 1.04547
Value Function Loss: 3.47251

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15727
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.05613

Collected Steps per Second: 10,368.49610
Overall Steps per Second: 8,828.72750

Timestep Collection Time: 4.82519
Timestep Consumption Time: 0.84153
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 5.66673

Cumulative Model Updates: 51,366
Cumulative Timesteps: 856,830,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,957.33636
Policy Entropy: 1.04922
Value Function Loss: 3.37586

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.17997
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.05573

Collected Steps per Second: 10,418.65874
Overall Steps per Second: 8,858.14966

Timestep Collection Time: 4.80081
Timestep Consumption Time: 0.84574
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 5.64655

Cumulative Model Updates: 51,369
Cumulative Timesteps: 856,880,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 856880384...
Checkpoint 856880384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,065.64883
Policy Entropy: 1.04180
Value Function Loss: 3.32272

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.06655

Collected Steps per Second: 9,906.03193
Overall Steps per Second: 8,569.21269

Timestep Collection Time: 5.04925
Timestep Consumption Time: 0.78770
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 5.83694

Cumulative Model Updates: 51,372
Cumulative Timesteps: 856,930,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,569.41384
Policy Entropy: 1.03665
Value Function Loss: 3.43899

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 10,149.88570
Overall Steps per Second: 8,695.74815

Timestep Collection Time: 4.92892
Timestep Consumption Time: 0.82423
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 5.75316

Cumulative Model Updates: 51,375
Cumulative Timesteps: 856,980,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 856980430...
Checkpoint 856980430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,444.87502
Policy Entropy: 1.04520
Value Function Loss: 3.47638

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.08433

Collected Steps per Second: 10,242.09205
Overall Steps per Second: 8,843.29834

Timestep Collection Time: 4.88279
Timestep Consumption Time: 0.77234
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 5.65513

Cumulative Model Updates: 51,378
Cumulative Timesteps: 857,030,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835,734.50588
Policy Entropy: 1.05301
Value Function Loss: 3.37211

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 11,223.58330
Overall Steps per Second: 9,594.97312

Timestep Collection Time: 4.45651
Timestep Consumption Time: 0.75643
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 5.21294

Cumulative Model Updates: 51,381
Cumulative Timesteps: 857,080,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 857080458...
Checkpoint 857080458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,241.00228
Policy Entropy: 1.02680
Value Function Loss: 3.26600

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 10,710.89107
Overall Steps per Second: 9,082.83324

Timestep Collection Time: 4.66964
Timestep Consumption Time: 0.83701
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 5.50665

Cumulative Model Updates: 51,384
Cumulative Timesteps: 857,130,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,601.67039
Policy Entropy: 1.03686
Value Function Loss: 3.18601

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 11,218.15779
Overall Steps per Second: 9,526.57041

Timestep Collection Time: 4.45795
Timestep Consumption Time: 0.79158
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 5.24953

Cumulative Model Updates: 51,387
Cumulative Timesteps: 857,180,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857180484...
Checkpoint 857180484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,464.81029
Policy Entropy: 1.04070
Value Function Loss: 3.32024

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.09368

Collected Steps per Second: 10,849.07444
Overall Steps per Second: 9,157.20003

Timestep Collection Time: 4.61072
Timestep Consumption Time: 0.85187
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 5.46259

Cumulative Model Updates: 51,390
Cumulative Timesteps: 857,230,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,310.70616
Policy Entropy: 1.05343
Value Function Loss: 3.24704

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 11,257.11639
Overall Steps per Second: 9,505.35455

Timestep Collection Time: 4.44270
Timestep Consumption Time: 0.81875
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 5.26146

Cumulative Model Updates: 51,393
Cumulative Timesteps: 857,280,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857280518...
Checkpoint 857280518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,423.35949
Policy Entropy: 1.03366
Value Function Loss: 3.42616

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.09358

Collected Steps per Second: 10,346.03397
Overall Steps per Second: 8,984.69079

Timestep Collection Time: 4.83548
Timestep Consumption Time: 0.73266
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 5.56814

Cumulative Model Updates: 51,396
Cumulative Timesteps: 857,330,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771,660.88143
Policy Entropy: 1.03476
Value Function Loss: 3.21057

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 9,948.91350
Overall Steps per Second: 8,517.62790

Timestep Collection Time: 5.02708
Timestep Consumption Time: 0.84474
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.87182

Cumulative Model Updates: 51,399
Cumulative Timesteps: 857,380,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 857380560...
Checkpoint 857380560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,218.33988
Policy Entropy: 1.04639
Value Function Loss: 3.40895

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.09098

Collected Steps per Second: 10,132.21282
Overall Steps per Second: 8,706.38853

Timestep Collection Time: 4.93673
Timestep Consumption Time: 0.80848
PPO Batch Consumption Time: 0.04643
Total Iteration Time: 5.74521

Cumulative Model Updates: 51,402
Cumulative Timesteps: 857,430,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,793.49645
Policy Entropy: 1.04684
Value Function Loss: 3.47729

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 10,042.86983
Overall Steps per Second: 8,560.25666

Timestep Collection Time: 4.98045
Timestep Consumption Time: 0.86260
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.84305

Cumulative Model Updates: 51,405
Cumulative Timesteps: 857,480,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 857480598...
Checkpoint 857480598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,755.49572
Policy Entropy: 1.03537
Value Function Loss: 3.68039

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 10,203.78368
Overall Steps per Second: 8,777.34233

Timestep Collection Time: 4.90073
Timestep Consumption Time: 0.79644
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 5.69717

Cumulative Model Updates: 51,408
Cumulative Timesteps: 857,530,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,121.04449
Policy Entropy: 1.03277
Value Function Loss: 3.59311

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.16823
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 9,959.90652
Overall Steps per Second: 8,681.51006

Timestep Collection Time: 5.02254
Timestep Consumption Time: 0.73959
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 5.76213

Cumulative Model Updates: 51,411
Cumulative Timesteps: 857,580,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 857580628...
Checkpoint 857580628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,424.24152
Policy Entropy: 1.04413
Value Function Loss: 3.32719

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.09070

Collected Steps per Second: 10,236.86047
Overall Steps per Second: 8,759.04755

Timestep Collection Time: 4.88646
Timestep Consumption Time: 0.82444
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 5.71089

Cumulative Model Updates: 51,414
Cumulative Timesteps: 857,630,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,154.83815
Policy Entropy: 1.06605
Value Function Loss: 3.24636

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.08737

Collected Steps per Second: 10,113.30739
Overall Steps per Second: 8,834.43342

Timestep Collection Time: 4.94418
Timestep Consumption Time: 0.71572
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 5.65990

Cumulative Model Updates: 51,417
Cumulative Timesteps: 857,680,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 857680652...
Checkpoint 857680652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,058.20923
Policy Entropy: 1.02574
Value Function Loss: 2.97272

Mean KL Divergence: 0.03671
SB3 Clip Fraction: 0.19360
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 8,942.36112
Overall Steps per Second: 7,667.14642

Timestep Collection Time: 5.59159
Timestep Consumption Time: 0.93000
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.52159

Cumulative Model Updates: 51,420
Cumulative Timesteps: 857,730,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,952.23974
Policy Entropy: 1.04889
Value Function Loss: 3.07872

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 10,063.73066
Overall Steps per Second: 8,556.78921

Timestep Collection Time: 4.97152
Timestep Consumption Time: 0.87554
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 5.84705

Cumulative Model Updates: 51,423
Cumulative Timesteps: 857,780,686

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 857780686...
Checkpoint 857780686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,413.08864
Policy Entropy: 1.03806
Value Function Loss: 3.01571

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.08563

Collected Steps per Second: 10,331.48454
Overall Steps per Second: 8,957.77796

Timestep Collection Time: 4.84016
Timestep Consumption Time: 0.74225
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 5.58241

Cumulative Model Updates: 51,426
Cumulative Timesteps: 857,830,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521,623.92368
Policy Entropy: 1.03938
Value Function Loss: 3.35511

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 10,313.85712
Overall Steps per Second: 8,759.27293

Timestep Collection Time: 4.84959
Timestep Consumption Time: 0.86070
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 5.71029

Cumulative Model Updates: 51,429
Cumulative Timesteps: 857,880,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 857880710...
Checkpoint 857880710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,055.00603
Policy Entropy: 1.02628
Value Function Loss: 3.47626

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.16167
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 9,987.24010
Overall Steps per Second: 8,663.60437

Timestep Collection Time: 5.00639
Timestep Consumption Time: 0.76488
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 5.77127

Cumulative Model Updates: 51,432
Cumulative Timesteps: 857,930,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,116.49276
Policy Entropy: 1.04163
Value Function Loss: 3.55002

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 10,165.05653
Overall Steps per Second: 8,606.91696

Timestep Collection Time: 4.91881
Timestep Consumption Time: 0.89047
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.80928

Cumulative Model Updates: 51,435
Cumulative Timesteps: 857,980,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 857980710...
Checkpoint 857980710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,791.17392
Policy Entropy: 1.04172
Value Function Loss: 3.45338

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 9,503.13904
Overall Steps per Second: 8,201.15455

Timestep Collection Time: 5.26184
Timestep Consumption Time: 0.83535
PPO Batch Consumption Time: 0.04028
Total Iteration Time: 6.09719

Cumulative Model Updates: 51,438
Cumulative Timesteps: 858,030,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,706.35747
Policy Entropy: 1.02165
Value Function Loss: 3.23685

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.09535

Collected Steps per Second: 10,029.77146
Overall Steps per Second: 8,747.34057

Timestep Collection Time: 4.98655
Timestep Consumption Time: 0.73107
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 5.71762

Cumulative Model Updates: 51,441
Cumulative Timesteps: 858,080,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 858080728...
Checkpoint 858080728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,417.50535
Policy Entropy: 1.00702
Value Function Loss: 3.05298

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.19504
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.09157

Collected Steps per Second: 10,182.96198
Overall Steps per Second: 8,605.39581

Timestep Collection Time: 4.91036
Timestep Consumption Time: 0.90018
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 5.81054

Cumulative Model Updates: 51,444
Cumulative Timesteps: 858,130,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,834.36604
Policy Entropy: 1.02142
Value Function Loss: 2.97599

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 9,808.28187
Overall Steps per Second: 8,345.95586

Timestep Collection Time: 5.09814
Timestep Consumption Time: 0.89326
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.99140

Cumulative Model Updates: 51,447
Cumulative Timesteps: 858,180,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 858180734...
Checkpoint 858180734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,248.94337
Policy Entropy: 1.03110
Value Function Loss: 2.95021

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.09536

Collected Steps per Second: 8,950.89659
Overall Steps per Second: 7,746.36599

Timestep Collection Time: 5.58938
Timestep Consumption Time: 0.86913
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 6.45851

Cumulative Model Updates: 51,450
Cumulative Timesteps: 858,230,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,171.69765
Policy Entropy: 1.00979
Value Function Loss: 3.35367

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 10,363.64702
Overall Steps per Second: 8,688.88426

Timestep Collection Time: 4.82610
Timestep Consumption Time: 0.93022
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 5.75632

Cumulative Model Updates: 51,453
Cumulative Timesteps: 858,280,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 858280780...
Checkpoint 858280780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575,759.61375
Policy Entropy: 1.02219
Value Function Loss: 3.41402

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.18168
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.09625

Collected Steps per Second: 9,793.76321
Overall Steps per Second: 8,632.96118

Timestep Collection Time: 5.10774
Timestep Consumption Time: 0.68680
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.79454

Cumulative Model Updates: 51,456
Cumulative Timesteps: 858,330,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788,314.08811
Policy Entropy: 1.02164
Value Function Loss: 3.57801

Mean KL Divergence: 0.02553
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.09618

Collected Steps per Second: 10,808.27680
Overall Steps per Second: 9,235.75758

Timestep Collection Time: 4.62849
Timestep Consumption Time: 0.78807
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.41656

Cumulative Model Updates: 51,459
Cumulative Timesteps: 858,380,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 858380830...
Checkpoint 858380830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,506.00070
Policy Entropy: 1.00330
Value Function Loss: 3.29368

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.17249
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.10733

Collected Steps per Second: 10,824.45564
Overall Steps per Second: 9,262.50712

Timestep Collection Time: 4.62213
Timestep Consumption Time: 0.77944
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.40156

Cumulative Model Updates: 51,462
Cumulative Timesteps: 858,430,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,430.46408
Policy Entropy: 0.99792
Value Function Loss: 3.31613

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.18095
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 11,120.11134
Overall Steps per Second: 9,452.55514

Timestep Collection Time: 4.49816
Timestep Consumption Time: 0.79353
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.29169

Cumulative Model Updates: 51,465
Cumulative Timesteps: 858,480,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858480882...
Checkpoint 858480882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,558.47441
Policy Entropy: 1.01266
Value Function Loss: 3.10613

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 10,298.23352
Overall Steps per Second: 8,799.38417

Timestep Collection Time: 4.85734
Timestep Consumption Time: 0.82738
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.68472

Cumulative Model Updates: 51,468
Cumulative Timesteps: 858,530,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,563.05009
Policy Entropy: 1.01510
Value Function Loss: 3.19100

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.08597

Collected Steps per Second: 10,744.76324
Overall Steps per Second: 9,359.72618

Timestep Collection Time: 4.65362
Timestep Consumption Time: 0.68863
PPO Batch Consumption Time: 0.03828
Total Iteration Time: 5.34225

Cumulative Model Updates: 51,471
Cumulative Timesteps: 858,580,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 858580906...
Checkpoint 858580906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,219.93105
Policy Entropy: 1.01549
Value Function Loss: 3.31517

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 10,678.36136
Overall Steps per Second: 9,176.58823

Timestep Collection Time: 4.68443
Timestep Consumption Time: 0.76662
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.45105

Cumulative Model Updates: 51,474
Cumulative Timesteps: 858,630,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,128.39552
Policy Entropy: 1.01590
Value Function Loss: 3.52529

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 10,725.22343
Overall Steps per Second: 9,271.33880

Timestep Collection Time: 4.66303
Timestep Consumption Time: 0.73123
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.39426

Cumulative Model Updates: 51,477
Cumulative Timesteps: 858,680,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 858680940...
Checkpoint 858680940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,519.33295
Policy Entropy: 1.01100
Value Function Loss: 3.57146

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 10,530.02760
Overall Steps per Second: 9,208.76847

Timestep Collection Time: 4.74928
Timestep Consumption Time: 0.68142
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.43069

Cumulative Model Updates: 51,480
Cumulative Timesteps: 858,730,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,962.50146
Policy Entropy: 1.02176
Value Function Loss: 3.37049

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 10,386.14973
Overall Steps per Second: 8,993.03519

Timestep Collection Time: 4.81584
Timestep Consumption Time: 0.74602
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.56186

Cumulative Model Updates: 51,483
Cumulative Timesteps: 858,780,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 858780968...
Checkpoint 858780968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,690.77233
Policy Entropy: 1.01676
Value Function Loss: 3.35362

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 10,509.23678
Overall Steps per Second: 8,994.82425

Timestep Collection Time: 4.75924
Timestep Consumption Time: 0.80129
PPO Batch Consumption Time: 0.03790
Total Iteration Time: 5.56053

Cumulative Model Updates: 51,486
Cumulative Timesteps: 858,830,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,647.20844
Policy Entropy: 1.00971
Value Function Loss: 3.20755

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.07410
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 10,805.02747
Overall Steps per Second: 9,242.06187

Timestep Collection Time: 4.62933
Timestep Consumption Time: 0.78289
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 5.41221

Cumulative Model Updates: 51,489
Cumulative Timesteps: 858,881,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858881004...
Checkpoint 858881004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,718.01248
Policy Entropy: 1.02675
Value Function Loss: 3.06282

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 10,461.20215
Overall Steps per Second: 8,956.33287

Timestep Collection Time: 4.77976
Timestep Consumption Time: 0.80311
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 5.58287

Cumulative Model Updates: 51,492
Cumulative Timesteps: 858,931,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,014.06032
Policy Entropy: 1.03159
Value Function Loss: 3.04926

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.10254

Collected Steps per Second: 10,512.03851
Overall Steps per Second: 9,220.32608

Timestep Collection Time: 4.75950
Timestep Consumption Time: 0.66678
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.42627

Cumulative Model Updates: 51,495
Cumulative Timesteps: 858,981,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 858981038...
Checkpoint 858981038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,006.96106
Policy Entropy: 1.03498
Value Function Loss: 3.11853

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.10413

Collected Steps per Second: 10,532.14232
Overall Steps per Second: 9,009.34885

Timestep Collection Time: 4.74851
Timestep Consumption Time: 0.80261
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.55112

Cumulative Model Updates: 51,498
Cumulative Timesteps: 859,031,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,147.22785
Policy Entropy: 1.02910
Value Function Loss: 3.45645

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.07194
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 10,222.55993
Overall Steps per Second: 8,707.15356

Timestep Collection Time: 4.89388
Timestep Consumption Time: 0.85174
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.74562

Cumulative Model Updates: 51,501
Cumulative Timesteps: 859,081,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859081078...
Checkpoint 859081078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,853.33696
Policy Entropy: 1.02814
Value Function Loss: 3.41290

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.07660
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 10,591.37200
Overall Steps per Second: 9,181.90281

Timestep Collection Time: 4.72309
Timestep Consumption Time: 0.72502
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.44811

Cumulative Model Updates: 51,504
Cumulative Timesteps: 859,131,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,303.35795
Policy Entropy: 1.02268
Value Function Loss: 3.48129

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.08289
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 11,795.72690
Overall Steps per Second: 9,944.87904

Timestep Collection Time: 4.24001
Timestep Consumption Time: 0.78911
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.02912

Cumulative Model Updates: 51,507
Cumulative Timesteps: 859,181,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859181116...
Checkpoint 859181116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,744.52458
Policy Entropy: 1.01370
Value Function Loss: 3.38463

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.07619
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 11,581.71372
Overall Steps per Second: 9,840.61428

Timestep Collection Time: 4.31836
Timestep Consumption Time: 0.76405
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.08241

Cumulative Model Updates: 51,510
Cumulative Timesteps: 859,231,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,714.03458
Policy Entropy: 1.03216
Value Function Loss: 3.37731

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 11,530.99591
Overall Steps per Second: 9,834.96308

Timestep Collection Time: 4.33839
Timestep Consumption Time: 0.74815
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.08655

Cumulative Model Updates: 51,513
Cumulative Timesteps: 859,281,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 859281156...
Checkpoint 859281156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,871.33007
Policy Entropy: 1.04183
Value Function Loss: 3.21378

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.09373

Collected Steps per Second: 10,799.72012
Overall Steps per Second: 9,195.23218

Timestep Collection Time: 4.62993
Timestep Consumption Time: 0.80788
PPO Batch Consumption Time: 0.03777
Total Iteration Time: 5.43782

Cumulative Model Updates: 51,516
Cumulative Timesteps: 859,331,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,101.07100
Policy Entropy: 1.02409
Value Function Loss: 3.16440

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.08488

Collected Steps per Second: 11,659.84388
Overall Steps per Second: 9,976.96037

Timestep Collection Time: 4.29011
Timestep Consumption Time: 0.72364
PPO Batch Consumption Time: 0.03809
Total Iteration Time: 5.01375

Cumulative Model Updates: 51,519
Cumulative Timesteps: 859,381,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 859381180...
Checkpoint 859381180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,896.23739
Policy Entropy: 1.02059
Value Function Loss: 3.11914

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.18084
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.08080

Collected Steps per Second: 11,412.68132
Overall Steps per Second: 9,715.49759

Timestep Collection Time: 4.38109
Timestep Consumption Time: 0.76533
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 5.14642

Cumulative Model Updates: 51,522
Cumulative Timesteps: 859,431,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,702.77155
Policy Entropy: 1.03498
Value Function Loss: 3.37401

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 10,835.13231
Overall Steps per Second: 9,338.25000

Timestep Collection Time: 4.61720
Timestep Consumption Time: 0.74012
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.35732

Cumulative Model Updates: 51,525
Cumulative Timesteps: 859,481,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859481208...
Checkpoint 859481208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,804.82093
Policy Entropy: 1.04497
Value Function Loss: 3.54354

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.09190

Collected Steps per Second: 10,952.83224
Overall Steps per Second: 9,388.25562

Timestep Collection Time: 4.56612
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.32708

Cumulative Model Updates: 51,528
Cumulative Timesteps: 859,531,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,923.45489
Policy Entropy: 1.02640
Value Function Loss: 3.47648

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 10,769.51985
Overall Steps per Second: 9,171.23453

Timestep Collection Time: 4.64440
Timestep Consumption Time: 0.80939
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.45379

Cumulative Model Updates: 51,531
Cumulative Timesteps: 859,581,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 859581238...
Checkpoint 859581238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,791.79313
Policy Entropy: 1.01214
Value Function Loss: 3.29262

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.16635
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.10995

Collected Steps per Second: 10,166.69625
Overall Steps per Second: 8,812.12977

Timestep Collection Time: 4.91920
Timestep Consumption Time: 0.75616
PPO Batch Consumption Time: 0.03899
Total Iteration Time: 5.67536

Cumulative Model Updates: 51,534
Cumulative Timesteps: 859,631,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,821.69612
Policy Entropy: 1.03046
Value Function Loss: 3.18383

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 10,827.66661
Overall Steps per Second: 9,197.93834

Timestep Collection Time: 4.61928
Timestep Consumption Time: 0.81846
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.43774

Cumulative Model Updates: 51,537
Cumulative Timesteps: 859,681,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 859681266...
Checkpoint 859681266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,307.84972
Policy Entropy: 1.04760
Value Function Loss: 3.39992

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.16286
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 10,622.36527
Overall Steps per Second: 9,184.06015

Timestep Collection Time: 4.70893
Timestep Consumption Time: 0.73746
PPO Batch Consumption Time: 0.03824
Total Iteration Time: 5.44639

Cumulative Model Updates: 51,540
Cumulative Timesteps: 859,731,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,201.40058
Policy Entropy: 1.03091
Value Function Loss: 3.49163

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10,452.27745
Overall Steps per Second: 9,116.81435

Timestep Collection Time: 4.78633
Timestep Consumption Time: 0.70112
PPO Batch Consumption Time: 0.03857
Total Iteration Time: 5.48744

Cumulative Model Updates: 51,543
Cumulative Timesteps: 859,781,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859781314...
Checkpoint 859781314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,523.48459
Policy Entropy: 1.02222
Value Function Loss: 3.47497

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.10215

Collected Steps per Second: 10,387.70124
Overall Steps per Second: 8,910.57781

Timestep Collection Time: 4.81454
Timestep Consumption Time: 0.79812
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.61266

Cumulative Model Updates: 51,546
Cumulative Timesteps: 859,831,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,784.25645
Policy Entropy: 1.03984
Value Function Loss: 3.50883

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.10394

Collected Steps per Second: 10,608.58905
Overall Steps per Second: 9,047.80017

Timestep Collection Time: 4.71448
Timestep Consumption Time: 0.81327
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.52775

Cumulative Model Updates: 51,549
Cumulative Timesteps: 859,881,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859881340...
Checkpoint 859881340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,633.28430
Policy Entropy: 1.04986
Value Function Loss: 3.58043

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 10,746.85461
Overall Steps per Second: 9,183.30638

Timestep Collection Time: 4.65364
Timestep Consumption Time: 0.79233
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.44597

Cumulative Model Updates: 51,552
Cumulative Timesteps: 859,931,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,867.43397
Policy Entropy: 1.03847
Value Function Loss: 3.63602

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.09468

Collected Steps per Second: 10,632.28283
Overall Steps per Second: 9,077.63523

Timestep Collection Time: 4.70416
Timestep Consumption Time: 0.80564
PPO Batch Consumption Time: 0.03780
Total Iteration Time: 5.50981

Cumulative Model Updates: 51,555
Cumulative Timesteps: 859,981,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 859981368...
Checkpoint 859981368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,710.35092
Policy Entropy: 1.02035
Value Function Loss: 3.63583

Mean KL Divergence: 0.03670
SB3 Clip Fraction: 0.19565
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.09164

Collected Steps per Second: 10,539.33106
Overall Steps per Second: 9,082.57412

Timestep Collection Time: 4.74584
Timestep Consumption Time: 0.76119
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.50703

Cumulative Model Updates: 51,558
Cumulative Timesteps: 860,031,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,150.96243
Policy Entropy: 1.04386
Value Function Loss: 3.50764

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.08580

Collected Steps per Second: 10,794.35028
Overall Steps per Second: 9,205.80285

Timestep Collection Time: 4.63372
Timestep Consumption Time: 0.79959
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.43331

Cumulative Model Updates: 51,561
Cumulative Timesteps: 860,081,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 860081404...
Checkpoint 860081404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,480.08597
Policy Entropy: 1.04130
Value Function Loss: 3.41410

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.08577

Collected Steps per Second: 10,572.89047
Overall Steps per Second: 9,022.56187

Timestep Collection Time: 4.73191
Timestep Consumption Time: 0.81308
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.54499

Cumulative Model Updates: 51,564
Cumulative Timesteps: 860,131,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,448.56879
Policy Entropy: 1.01999
Value Function Loss: 3.27767

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.09089

Collected Steps per Second: 10,147.53583
Overall Steps per Second: 8,900.23368

Timestep Collection Time: 4.92987
Timestep Consumption Time: 0.69088
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.62075

Cumulative Model Updates: 51,567
Cumulative Timesteps: 860,181,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 860181460...
Checkpoint 860181460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,083.87061
Policy Entropy: 1.04374
Value Function Loss: 3.20991

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 10,561.01122
Overall Steps per Second: 9,072.56523

Timestep Collection Time: 4.73534
Timestep Consumption Time: 0.77688
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.51222

Cumulative Model Updates: 51,570
Cumulative Timesteps: 860,231,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,615.81201
Policy Entropy: 1.03492
Value Function Loss: 3.09592

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 11,009.29814
Overall Steps per Second: 9,416.51248

Timestep Collection Time: 4.54307
Timestep Consumption Time: 0.76845
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 5.31152

Cumulative Model Updates: 51,573
Cumulative Timesteps: 860,281,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 860281486...
Checkpoint 860281486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,284.93738
Policy Entropy: 1.02238
Value Function Loss: 3.11464

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.16779
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.08313

Collected Steps per Second: 11,220.48003
Overall Steps per Second: 9,576.49219

Timestep Collection Time: 4.45756
Timestep Consumption Time: 0.76523
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.22279

Cumulative Model Updates: 51,576
Cumulative Timesteps: 860,331,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,150.24127
Policy Entropy: 1.02414
Value Function Loss: 3.22920

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.16864
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 10,969.86182
Overall Steps per Second: 9,374.40623

Timestep Collection Time: 4.56049
Timestep Consumption Time: 0.77616
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.33666

Cumulative Model Updates: 51,579
Cumulative Timesteps: 860,381,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 860381530...
Checkpoint 860381530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,371.87835
Policy Entropy: 1.03593
Value Function Loss: 3.47174

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 10,805.96035
Overall Steps per Second: 9,337.17952

Timestep Collection Time: 4.62948
Timestep Consumption Time: 0.72824
PPO Batch Consumption Time: 0.03835
Total Iteration Time: 5.35772

Cumulative Model Updates: 51,582
Cumulative Timesteps: 860,431,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,326.21053
Policy Entropy: 1.04501
Value Function Loss: 3.47713

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 10,989.86071
Overall Steps per Second: 9,385.46808

Timestep Collection Time: 4.54965
Timestep Consumption Time: 0.77774
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.32738

Cumulative Model Updates: 51,585
Cumulative Timesteps: 860,481,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 860481556...
Checkpoint 860481556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,950.45158
Policy Entropy: 1.02611
Value Function Loss: 3.29537

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 10,851.99065
Overall Steps per Second: 9,303.08627

Timestep Collection Time: 4.60745
Timestep Consumption Time: 0.76711
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.37456

Cumulative Model Updates: 51,588
Cumulative Timesteps: 860,531,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,000.09259
Policy Entropy: 1.00980
Value Function Loss: 3.17148

Mean KL Divergence: 0.03190
SB3 Clip Fraction: 0.19267
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 11,044.30869
Overall Steps per Second: 9,391.50159

Timestep Collection Time: 4.52921
Timestep Consumption Time: 0.79709
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 5.32630

Cumulative Model Updates: 51,591
Cumulative Timesteps: 860,581,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 860581578...
Checkpoint 860581578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,651.89831
Policy Entropy: 1.02888
Value Function Loss: 3.28908

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.08394

Collected Steps per Second: 10,821.99091
Overall Steps per Second: 9,286.93084

Timestep Collection Time: 4.62115
Timestep Consumption Time: 0.76384
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.38499

Cumulative Model Updates: 51,594
Cumulative Timesteps: 860,631,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,965.47718
Policy Entropy: 1.03113
Value Function Loss: 3.40409

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 10,970.02268
Overall Steps per Second: 9,523.48189

Timestep Collection Time: 4.56006
Timestep Consumption Time: 0.69264
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.25270

Cumulative Model Updates: 51,597
Cumulative Timesteps: 860,681,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 860681612...
Checkpoint 860681612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,521.20690
Policy Entropy: 1.02767
Value Function Loss: 3.30388

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.07018
Value Function Update Magnitude: 0.09001

Collected Steps per Second: 10,207.06025
Overall Steps per Second: 8,821.33676

Timestep Collection Time: 4.89955
Timestep Consumption Time: 0.76966
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.66921

Cumulative Model Updates: 51,600
Cumulative Timesteps: 860,731,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,223.64628
Policy Entropy: 1.02413
Value Function Loss: 3.17482

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 10,759.51558
Overall Steps per Second: 9,264.32828

Timestep Collection Time: 4.64872
Timestep Consumption Time: 0.75027
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.39899

Cumulative Model Updates: 51,603
Cumulative Timesteps: 860,781,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 860781640...
Checkpoint 860781640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,053.77386
Policy Entropy: 1.02933
Value Function Loss: 3.18704

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 10,749.85250
Overall Steps per Second: 9,201.71448

Timestep Collection Time: 4.65346
Timestep Consumption Time: 0.78292
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.43638

Cumulative Model Updates: 51,606
Cumulative Timesteps: 860,831,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,967.44051
Policy Entropy: 1.02799
Value Function Loss: 3.22445

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 10,824.84801
Overall Steps per Second: 9,221.25982

Timestep Collection Time: 4.62085
Timestep Consumption Time: 0.80357
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.42442

Cumulative Model Updates: 51,609
Cumulative Timesteps: 860,881,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 860881684...
Checkpoint 860881684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,795.16241
Policy Entropy: 1.02528
Value Function Loss: 3.27309

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 10,484.57045
Overall Steps per Second: 9,204.61684

Timestep Collection Time: 4.76929
Timestep Consumption Time: 0.66320
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.43249

Cumulative Model Updates: 51,612
Cumulative Timesteps: 860,931,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,894.54671
Policy Entropy: 1.02764
Value Function Loss: 3.09911

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.15458
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.08943

Collected Steps per Second: 10,926.72180
Overall Steps per Second: 9,248.71421

Timestep Collection Time: 4.57759
Timestep Consumption Time: 0.83052
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 5.40810

Cumulative Model Updates: 51,615
Cumulative Timesteps: 860,981,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 860981706...
Checkpoint 860981706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,837.29157
Policy Entropy: 1.03808
Value Function Loss: 3.17683

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.07739

Collected Steps per Second: 10,741.68970
Overall Steps per Second: 9,236.16856

Timestep Collection Time: 4.65588
Timestep Consumption Time: 0.75892
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.41480

Cumulative Model Updates: 51,618
Cumulative Timesteps: 861,031,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,060.14259
Policy Entropy: 1.05013
Value Function Loss: 3.04165

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 10,741.61374
Overall Steps per Second: 9,141.55418

Timestep Collection Time: 4.65647
Timestep Consumption Time: 0.81503
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.47150

Cumulative Model Updates: 51,621
Cumulative Timesteps: 861,081,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 861081736...
Checkpoint 861081736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,031.88645
Policy Entropy: 1.02264
Value Function Loss: 3.12538

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.17881
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 10,350.10208
Overall Steps per Second: 8,821.89038

Timestep Collection Time: 4.83126
Timestep Consumption Time: 0.83692
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 5.66817

Cumulative Model Updates: 51,624
Cumulative Timesteps: 861,131,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,304.15729
Policy Entropy: 1.02954
Value Function Loss: 3.20496

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.17426
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 10,695.64290
Overall Steps per Second: 9,278.43486

Timestep Collection Time: 4.67480
Timestep Consumption Time: 0.71404
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.38884

Cumulative Model Updates: 51,627
Cumulative Timesteps: 861,181,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 861181740...
Checkpoint 861181740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,816.86613
Policy Entropy: 1.03515
Value Function Loss: 3.36499

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 10,661.92106
Overall Steps per Second: 9,084.70061

Timestep Collection Time: 4.68959
Timestep Consumption Time: 0.81417
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.50376

Cumulative Model Updates: 51,630
Cumulative Timesteps: 861,231,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,272.16912
Policy Entropy: 1.04895
Value Function Loss: 3.35260

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.17716
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 10,109.68368
Overall Steps per Second: 8,855.79596

Timestep Collection Time: 4.94734
Timestep Consumption Time: 0.70049
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 5.64783

Cumulative Model Updates: 51,633
Cumulative Timesteps: 861,281,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 861281756...
Checkpoint 861281756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749,445.98572
Policy Entropy: 1.02234
Value Function Loss: 3.12266

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.15846
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.09852

Collected Steps per Second: 10,192.07350
Overall Steps per Second: 8,783.88834

Timestep Collection Time: 4.90832
Timestep Consumption Time: 0.78688
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.69520

Cumulative Model Updates: 51,636
Cumulative Timesteps: 861,331,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,410.91535
Policy Entropy: 1.03897
Value Function Loss: 2.99673

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.16449
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 11,373.01953
Overall Steps per Second: 9,622.27797

Timestep Collection Time: 4.39690
Timestep Consumption Time: 0.80000
PPO Batch Consumption Time: 0.03846
Total Iteration Time: 5.19690

Cumulative Model Updates: 51,639
Cumulative Timesteps: 861,381,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 861381788...
Checkpoint 861381788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,262.68133
Policy Entropy: 1.04568
Value Function Loss: 3.00126

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.09025

Collected Steps per Second: 10,759.90611
Overall Steps per Second: 9,119.11494

Timestep Collection Time: 4.64837
Timestep Consumption Time: 0.83638
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.48474

Cumulative Model Updates: 51,642
Cumulative Timesteps: 861,431,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,226.96671
Policy Entropy: 1.03171
Value Function Loss: 3.12906

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 10,169.95926
Overall Steps per Second: 8,611.44949

Timestep Collection Time: 4.91664
Timestep Consumption Time: 0.88982
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 5.80646

Cumulative Model Updates: 51,645
Cumulative Timesteps: 861,481,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 861481806...
Checkpoint 861481806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,551.63663
Policy Entropy: 1.01135
Value Function Loss: 2.95309

Mean KL Divergence: 0.04140
SB3 Clip Fraction: 0.21544
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.09620

Collected Steps per Second: 7,762.88083
Overall Steps per Second: 6,674.77951

Timestep Collection Time: 6.44348
Timestep Consumption Time: 1.05040
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 7.49388

Cumulative Model Updates: 51,648
Cumulative Timesteps: 861,531,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,730.26098
Policy Entropy: 1.03702
Value Function Loss: 2.92218

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 4,653.03433
Overall Steps per Second: 3,710.70671

Timestep Collection Time: 10.74826
Timestep Consumption Time: 2.72950
PPO Batch Consumption Time: 0.05891
Total Iteration Time: 13.47776

Cumulative Model Updates: 51,651
Cumulative Timesteps: 861,581,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 861581838...
Checkpoint 861581838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,137.51057
Policy Entropy: 1.03088
Value Function Loss: 2.91821

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 3,959.47408
Overall Steps per Second: 3,240.72632

Timestep Collection Time: 12.63047
Timestep Consumption Time: 2.80126
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 15.43173

Cumulative Model Updates: 51,654
Cumulative Timesteps: 861,631,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,262.41004
Policy Entropy: 1.01564
Value Function Loss: 3.18971

Mean KL Divergence: 0.04237
SB3 Clip Fraction: 0.22463
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 3,830.88011
Overall Steps per Second: 3,163.18959

Timestep Collection Time: 13.05496
Timestep Consumption Time: 2.75566
PPO Batch Consumption Time: 0.06882
Total Iteration Time: 15.81062

Cumulative Model Updates: 51,657
Cumulative Timesteps: 861,681,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 861681860...
Checkpoint 861681860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,391.62127
Policy Entropy: 1.04413
Value Function Loss: 3.40456

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 3,764.78750
Overall Steps per Second: 3,078.90547

Timestep Collection Time: 13.28681
Timestep Consumption Time: 2.95988
PPO Batch Consumption Time: 0.07050
Total Iteration Time: 16.24668

Cumulative Model Updates: 51,660
Cumulative Timesteps: 861,731,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,524.67808
Policy Entropy: 1.03126
Value Function Loss: 3.41253

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.15979
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.10062

Collected Steps per Second: 3,647.07258
Overall Steps per Second: 3,045.18415

Timestep Collection Time: 13.71730
Timestep Consumption Time: 2.71126
PPO Batch Consumption Time: 0.06344
Total Iteration Time: 16.42856

Cumulative Model Updates: 51,663
Cumulative Timesteps: 861,781,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 861781910...
Checkpoint 861781910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,890.37606
Policy Entropy: 1.00644
Value Function Loss: 3.55031

Mean KL Divergence: 0.04428
SB3 Clip Fraction: 0.22719
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 3,772.90799
Overall Steps per Second: 3,082.79940

Timestep Collection Time: 13.25662
Timestep Consumption Time: 2.96760
PPO Batch Consumption Time: 0.06491
Total Iteration Time: 16.22421

Cumulative Model Updates: 51,666
Cumulative Timesteps: 861,831,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,513.99987
Policy Entropy: 1.01890
Value Function Loss: 3.56210

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.10604

Collected Steps per Second: 3,708.87828
Overall Steps per Second: 3,042.34202

Timestep Collection Time: 13.48116
Timestep Consumption Time: 2.95354
PPO Batch Consumption Time: 0.07174
Total Iteration Time: 16.43471

Cumulative Model Updates: 51,669
Cumulative Timesteps: 861,881,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 861881926...
Checkpoint 861881926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,303.18234
Policy Entropy: 1.01751
Value Function Loss: 3.60392

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.10283

Collected Steps per Second: 3,739.90482
Overall Steps per Second: 3,111.88376

Timestep Collection Time: 13.37307
Timestep Consumption Time: 2.69887
PPO Batch Consumption Time: 0.05906
Total Iteration Time: 16.07194

Cumulative Model Updates: 51,672
Cumulative Timesteps: 861,931,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,881.44157
Policy Entropy: 1.01344
Value Function Loss: 3.50230

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.09895

Collected Steps per Second: 3,672.92399
Overall Steps per Second: 3,036.75504

Timestep Collection Time: 13.62076
Timestep Consumption Time: 2.85341
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 16.47416

Cumulative Model Updates: 51,675
Cumulative Timesteps: 861,981,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 861981968...
Checkpoint 861981968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,806.67500
Policy Entropy: 1.01058
Value Function Loss: 3.41595

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 3,721.87650
Overall Steps per Second: 3,114.89768

Timestep Collection Time: 13.43516
Timestep Consumption Time: 2.61802
PPO Batch Consumption Time: 0.06470
Total Iteration Time: 16.05318

Cumulative Model Updates: 51,678
Cumulative Timesteps: 862,031,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,393.08429
Policy Entropy: 1.02280
Value Function Loss: 3.57523

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.10931

Collected Steps per Second: 3,618.10321
Overall Steps per Second: 2,992.56041

Timestep Collection Time: 13.82879
Timestep Consumption Time: 2.89067
PPO Batch Consumption Time: 0.06570
Total Iteration Time: 16.71946

Cumulative Model Updates: 51,681
Cumulative Timesteps: 862,082,006

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 862082006...
Checkpoint 862082006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,207.58857
Policy Entropy: 1.02217
Value Function Loss: 3.60339

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 3,713.09368
Overall Steps per Second: 3,044.18080

Timestep Collection Time: 13.46748
Timestep Consumption Time: 2.95928
PPO Batch Consumption Time: 0.06848
Total Iteration Time: 16.42675

Cumulative Model Updates: 51,684
Cumulative Timesteps: 862,132,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,603.63454
Policy Entropy: 1.01996
Value Function Loss: 3.57092

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 3,775.09940
Overall Steps per Second: 3,074.67990

Timestep Collection Time: 13.24680
Timestep Consumption Time: 3.01765
PPO Batch Consumption Time: 0.06760
Total Iteration Time: 16.26446

Cumulative Model Updates: 51,687
Cumulative Timesteps: 862,182,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 862182020...
Checkpoint 862182020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,487.29637
Policy Entropy: 1.01565
Value Function Loss: 3.51550

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.08656

Collected Steps per Second: 3,699.45725
Overall Steps per Second: 3,048.53411

Timestep Collection Time: 13.52361
Timestep Consumption Time: 2.88756
PPO Batch Consumption Time: 0.06124
Total Iteration Time: 16.41117

Cumulative Model Updates: 51,690
Cumulative Timesteps: 862,232,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,914.87746
Policy Entropy: 1.00635
Value Function Loss: 3.57366

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.16406
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 3,772.05509
Overall Steps per Second: 3,136.68072

Timestep Collection Time: 13.26121
Timestep Consumption Time: 2.68623
PPO Batch Consumption Time: 0.06199
Total Iteration Time: 15.94743

Cumulative Model Updates: 51,693
Cumulative Timesteps: 862,282,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 862282072...
Checkpoint 862282072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,379.61385
Policy Entropy: 1.02283
Value Function Loss: 3.63116

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.15967
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.10528

Collected Steps per Second: 3,691.30304
Overall Steps per Second: 3,022.56339

Timestep Collection Time: 13.55781
Timestep Consumption Time: 2.99966
PPO Batch Consumption Time: 0.06501
Total Iteration Time: 16.55747

Cumulative Model Updates: 51,696
Cumulative Timesteps: 862,332,118

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,878.41584
Policy Entropy: 1.03158
Value Function Loss: 3.72653

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.17749
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 3,689.90865
Overall Steps per Second: 3,096.06416

Timestep Collection Time: 13.56023
Timestep Consumption Time: 2.60094
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 16.16116

Cumulative Model Updates: 51,699
Cumulative Timesteps: 862,382,154

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 862382154...
Checkpoint 862382154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,500.22805
Policy Entropy: 1.01156
Value Function Loss: 3.76162

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.17075
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.12713

Collected Steps per Second: 3,678.84546
Overall Steps per Second: 3,011.78607

Timestep Collection Time: 13.59394
Timestep Consumption Time: 3.01083
PPO Batch Consumption Time: 0.06662
Total Iteration Time: 16.60476

Cumulative Model Updates: 51,702
Cumulative Timesteps: 862,432,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,307.65977
Policy Entropy: 1.03599
Value Function Loss: 3.89229

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.18605
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 3,786.45901
Overall Steps per Second: 3,101.73832

Timestep Collection Time: 13.20706
Timestep Consumption Time: 2.91551
PPO Batch Consumption Time: 0.06579
Total Iteration Time: 16.12257

Cumulative Model Updates: 51,705
Cumulative Timesteps: 862,482,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 862482172...
Checkpoint 862482172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,157.64838
Policy Entropy: 1.03127
Value Function Loss: 3.69625

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 3,795.19075
Overall Steps per Second: 3,122.60804

Timestep Collection Time: 13.17668
Timestep Consumption Time: 2.83814
PPO Batch Consumption Time: 0.06559
Total Iteration Time: 16.01482

Cumulative Model Updates: 51,708
Cumulative Timesteps: 862,532,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792,657.64209
Policy Entropy: 1.01964
Value Function Loss: 3.61509

Mean KL Divergence: 0.02955
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 3,797.98069
Overall Steps per Second: 3,153.85211

Timestep Collection Time: 13.16752
Timestep Consumption Time: 2.68928
PPO Batch Consumption Time: 0.06800
Total Iteration Time: 15.85680

Cumulative Model Updates: 51,711
Cumulative Timesteps: 862,582,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 862582190...
Checkpoint 862582190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,508.21556
Policy Entropy: 1.01567
Value Function Loss: 3.60205

Mean KL Divergence: 0.02997
SB3 Clip Fraction: 0.20663
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.08532

Collected Steps per Second: 3,803.39963
Overall Steps per Second: 3,150.19290

Timestep Collection Time: 13.14613
Timestep Consumption Time: 2.72591
PPO Batch Consumption Time: 0.06178
Total Iteration Time: 15.87204

Cumulative Model Updates: 51,714
Cumulative Timesteps: 862,632,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,193.55256
Policy Entropy: 1.02888
Value Function Loss: 3.78816

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 3,705.70507
Overall Steps per Second: 3,055.17631

Timestep Collection Time: 13.49595
Timestep Consumption Time: 2.87365
PPO Batch Consumption Time: 0.06341
Total Iteration Time: 16.36960

Cumulative Model Updates: 51,717
Cumulative Timesteps: 862,682,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 862682202...
Checkpoint 862682202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,299.87114
Policy Entropy: 1.03965
Value Function Loss: 3.90191

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.16598
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 3,768.69410
Overall Steps per Second: 3,099.79090

Timestep Collection Time: 13.27250
Timestep Consumption Time: 2.86407
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 16.13657

Cumulative Model Updates: 51,720
Cumulative Timesteps: 862,732,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,677.33498
Policy Entropy: 1.01152
Value Function Loss: 3.92271

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 4,019.71531
Overall Steps per Second: 3,273.93849

Timestep Collection Time: 12.44665
Timestep Consumption Time: 2.83525
PPO Batch Consumption Time: 0.05794
Total Iteration Time: 15.28190

Cumulative Model Updates: 51,723
Cumulative Timesteps: 862,782,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 862782254...
Checkpoint 862782254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,960.14495
Policy Entropy: 1.03255
Value Function Loss: 3.83785

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.16987
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 3,903.49133
Overall Steps per Second: 3,297.56293

Timestep Collection Time: 12.81571
Timestep Consumption Time: 2.35489
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 15.17060

Cumulative Model Updates: 51,726
Cumulative Timesteps: 862,832,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,944.72015
Policy Entropy: 1.02881
Value Function Loss: 3.82231

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.09817

Collected Steps per Second: 11,908.76975
Overall Steps per Second: 10,212.46138

Timestep Collection Time: 4.20010
Timestep Consumption Time: 0.69764
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.89774

Cumulative Model Updates: 51,729
Cumulative Timesteps: 862,882,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 862882298...
Checkpoint 862882298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,441.13259
Policy Entropy: 1.02226
Value Function Loss: 3.86422

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.08587

Collected Steps per Second: 9,889.33980
Overall Steps per Second: 8,363.49942

Timestep Collection Time: 5.05736
Timestep Consumption Time: 0.92267
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.98003

Cumulative Model Updates: 51,732
Cumulative Timesteps: 862,932,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794,082.74009
Policy Entropy: 1.01248
Value Function Loss: 3.84198

Mean KL Divergence: 0.03056
SB3 Clip Fraction: 0.19643
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.08170

Collected Steps per Second: 10,480.86691
Overall Steps per Second: 9,186.88890

Timestep Collection Time: 4.77346
Timestep Consumption Time: 0.67234
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.44580

Cumulative Model Updates: 51,735
Cumulative Timesteps: 862,982,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 862982342...
Checkpoint 862982342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,199.73102
Policy Entropy: 1.01959
Value Function Loss: 3.67585

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.09389

Collected Steps per Second: 10,116.64973
Overall Steps per Second: 8,758.50411

Timestep Collection Time: 4.94393
Timestep Consumption Time: 0.76664
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 5.71056

Cumulative Model Updates: 51,738
Cumulative Timesteps: 863,032,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,448.80120
Policy Entropy: 1.03442
Value Function Loss: 3.62654

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.16576
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.09445

Collected Steps per Second: 11,430.50610
Overall Steps per Second: 9,641.27178

Timestep Collection Time: 4.37548
Timestep Consumption Time: 0.81201
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.18749

Cumulative Model Updates: 51,741
Cumulative Timesteps: 863,082,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 863082372...
Checkpoint 863082372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,935.89206
Policy Entropy: 1.00561
Value Function Loss: 3.74897

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 11,635.32824
Overall Steps per Second: 10,068.44688

Timestep Collection Time: 4.29846
Timestep Consumption Time: 0.66894
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.96740

Cumulative Model Updates: 51,744
Cumulative Timesteps: 863,132,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,711.11081
Policy Entropy: 1.02569
Value Function Loss: 3.85514

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.10583

Collected Steps per Second: 12,217.12147
Overall Steps per Second: 10,294.48574

Timestep Collection Time: 4.09327
Timestep Consumption Time: 0.76447
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.85775

Cumulative Model Updates: 51,747
Cumulative Timesteps: 863,182,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 863182394...
Checkpoint 863182394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,954.23999
Policy Entropy: 1.02486
Value Function Loss: 3.75474

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.17645
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 12,427.71648
Overall Steps per Second: 10,487.20557

Timestep Collection Time: 4.02504
Timestep Consumption Time: 0.74478
PPO Batch Consumption Time: 0.03318
Total Iteration Time: 4.76981

Cumulative Model Updates: 51,750
Cumulative Timesteps: 863,232,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773,282.11272
Policy Entropy: 1.01423
Value Function Loss: 3.74530

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.16769
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.12801

Collected Steps per Second: 13,221.97394
Overall Steps per Second: 11,035.03819

Timestep Collection Time: 3.78370
Timestep Consumption Time: 0.74986
PPO Batch Consumption Time: 0.03314
Total Iteration Time: 4.53356

Cumulative Model Updates: 51,753
Cumulative Timesteps: 863,282,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 863282444...
Checkpoint 863282444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720,597.67450
Policy Entropy: 1.00933
Value Function Loss: 3.52954

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.19683
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 12,844.94958
Overall Steps per Second: 10,760.38683

Timestep Collection Time: 3.89351
Timestep Consumption Time: 0.75427
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.64779

Cumulative Model Updates: 51,756
Cumulative Timesteps: 863,332,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,276.20847
Policy Entropy: 1.02409
Value Function Loss: 3.50512

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.10455

Collected Steps per Second: 12,938.87138
Overall Steps per Second: 11,029.19778

Timestep Collection Time: 3.86479
Timestep Consumption Time: 0.66918
PPO Batch Consumption Time: 0.03307
Total Iteration Time: 4.53397

Cumulative Model Updates: 51,759
Cumulative Timesteps: 863,382,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 863382462...
Checkpoint 863382462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,375.19122
Policy Entropy: 1.02986
Value Function Loss: 3.25764

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.10410

Collected Steps per Second: 11,944.53546
Overall Steps per Second: 10,182.20642

Timestep Collection Time: 4.18802
Timestep Consumption Time: 0.72486
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.91288

Cumulative Model Updates: 51,762
Cumulative Timesteps: 863,432,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,430.11586
Policy Entropy: 1.02183
Value Function Loss: 3.35474

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.07054
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 12,843.29849
Overall Steps per Second: 10,798.96146

Timestep Collection Time: 3.89511
Timestep Consumption Time: 0.73738
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.63248

Cumulative Model Updates: 51,765
Cumulative Timesteps: 863,482,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 863482512...
Checkpoint 863482512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,162.74212
Policy Entropy: 1.02595
Value Function Loss: 3.33114

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.07067
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 12,967.97550
Overall Steps per Second: 10,904.56108

Timestep Collection Time: 3.85596
Timestep Consumption Time: 0.72964
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.58560

Cumulative Model Updates: 51,768
Cumulative Timesteps: 863,532,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,241.89868
Policy Entropy: 1.02006
Value Function Loss: 3.37489

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.07050
Value Function Update Magnitude: 0.09832

Collected Steps per Second: 11,177.66216
Overall Steps per Second: 9,447.26976

Timestep Collection Time: 4.47571
Timestep Consumption Time: 0.81979
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 5.29550

Cumulative Model Updates: 51,771
Cumulative Timesteps: 863,582,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 863582544...
Checkpoint 863582544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,637.99990
Policy Entropy: 1.03133
Value Function Loss: 3.14685

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.09923

Collected Steps per Second: 11,197.49623
Overall Steps per Second: 9,754.00110

Timestep Collection Time: 4.46636
Timestep Consumption Time: 0.66098
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.12733

Cumulative Model Updates: 51,774
Cumulative Timesteps: 863,632,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,228.06617
Policy Entropy: 1.03813
Value Function Loss: 3.07443

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 12,071.47040
Overall Steps per Second: 10,187.36559

Timestep Collection Time: 4.14266
Timestep Consumption Time: 0.76617
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 4.90883

Cumulative Model Updates: 51,777
Cumulative Timesteps: 863,682,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 863682564...
Checkpoint 863682564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,600.23497
Policy Entropy: 1.04231
Value Function Loss: 3.14933

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.10497

Collected Steps per Second: 11,643.37483
Overall Steps per Second: 9,948.24091

Timestep Collection Time: 4.29601
Timestep Consumption Time: 0.73202
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.02802

Cumulative Model Updates: 51,780
Cumulative Timesteps: 863,732,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,414.05778
Policy Entropy: 1.03167
Value Function Loss: 3.34175

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.06925
Value Function Update Magnitude: 0.11109

Collected Steps per Second: 12,231.40239
Overall Steps per Second: 10,294.44351

Timestep Collection Time: 4.09029
Timestep Consumption Time: 0.76961
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.85990

Cumulative Model Updates: 51,783
Cumulative Timesteps: 863,782,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 863782614...
Checkpoint 863782614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,792.67303
Policy Entropy: 1.03415
Value Function Loss: 3.36684

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 11,940.83355
Overall Steps per Second: 10,143.80092

Timestep Collection Time: 4.18882
Timestep Consumption Time: 0.74207
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.93089

Cumulative Model Updates: 51,786
Cumulative Timesteps: 863,832,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,650.06522
Policy Entropy: 1.03007
Value Function Loss: 3.42242

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 11,817.96888
Overall Steps per Second: 10,211.47142

Timestep Collection Time: 4.23203
Timestep Consumption Time: 0.66579
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.89783

Cumulative Model Updates: 51,789
Cumulative Timesteps: 863,882,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 863882646...
Checkpoint 863882646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,865.79557
Policy Entropy: 1.05079
Value Function Loss: 3.59373

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 12,195.94853
Overall Steps per Second: 10,287.38646

Timestep Collection Time: 4.10153
Timestep Consumption Time: 0.76093
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.86246

Cumulative Model Updates: 51,792
Cumulative Timesteps: 863,932,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,169.28605
Policy Entropy: 1.04550
Value Function Loss: 3.82277

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.10008

Collected Steps per Second: 11,904.30289
Overall Steps per Second: 10,122.42209

Timestep Collection Time: 4.20151
Timestep Consumption Time: 0.73960
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.94111

Cumulative Model Updates: 51,795
Cumulative Timesteps: 863,982,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 863982684...
Checkpoint 863982684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,016.12342
Policy Entropy: 1.05334
Value Function Loss: 3.85313

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.11364

Collected Steps per Second: 11,781.51651
Overall Steps per Second: 9,957.85827

Timestep Collection Time: 4.24563
Timestep Consumption Time: 0.77754
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 5.02317

Cumulative Model Updates: 51,798
Cumulative Timesteps: 864,032,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526,787.05557
Policy Entropy: 1.05187
Value Function Loss: 3.68080

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.11646

Collected Steps per Second: 11,939.76514
Overall Steps per Second: 10,073.05554

Timestep Collection Time: 4.18852
Timestep Consumption Time: 0.77621
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.96473

Cumulative Model Updates: 51,801
Cumulative Timesteps: 864,082,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 864082714...
Checkpoint 864082714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,607.37898
Policy Entropy: 1.05321
Value Function Loss: 3.58505

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.10351

Collected Steps per Second: 11,899.18975
Overall Steps per Second: 10,229.72905

Timestep Collection Time: 4.20415
Timestep Consumption Time: 0.68610
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.89026

Cumulative Model Updates: 51,804
Cumulative Timesteps: 864,132,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,236.71478
Policy Entropy: 1.04432
Value Function Loss: 3.44944

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.09854

Collected Steps per Second: 11,982.34832
Overall Steps per Second: 10,183.13910

Timestep Collection Time: 4.17347
Timestep Consumption Time: 0.73739
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 4.91086

Cumulative Model Updates: 51,807
Cumulative Timesteps: 864,182,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 864182748...
Checkpoint 864182748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,914.98100
Policy Entropy: 1.06075
Value Function Loss: 3.44630

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 11,703.10641
Overall Steps per Second: 9,983.86321

Timestep Collection Time: 4.27357
Timestep Consumption Time: 0.73592
PPO Batch Consumption Time: 0.03724
Total Iteration Time: 5.00948

Cumulative Model Updates: 51,810
Cumulative Timesteps: 864,232,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,787.42019
Policy Entropy: 1.06757
Value Function Loss: 3.36619

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.08870

Collected Steps per Second: 11,819.94759
Overall Steps per Second: 10,213.35974

Timestep Collection Time: 4.23014
Timestep Consumption Time: 0.66541
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.89555

Cumulative Model Updates: 51,813
Cumulative Timesteps: 864,282,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 864282762...
Checkpoint 864282762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720,634.34112
Policy Entropy: 1.05597
Value Function Loss: 3.32033

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 11,693.96455
Overall Steps per Second: 9,766.10993

Timestep Collection Time: 4.27691
Timestep Consumption Time: 0.84427
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.12118

Cumulative Model Updates: 51,816
Cumulative Timesteps: 864,332,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,279.29443
Policy Entropy: 1.04692
Value Function Loss: 3.40246

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.08478

Collected Steps per Second: 10,912.44514
Overall Steps per Second: 9,482.98807

Timestep Collection Time: 4.58211
Timestep Consumption Time: 0.69070
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.27281

Cumulative Model Updates: 51,819
Cumulative Timesteps: 864,382,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 864382778...
Checkpoint 864382778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,090.50089
Policy Entropy: 1.05192
Value Function Loss: 3.50580

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.08423

Collected Steps per Second: 11,826.36561
Overall Steps per Second: 10,001.57526

Timestep Collection Time: 4.22835
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.99981

Cumulative Model Updates: 51,822
Cumulative Timesteps: 864,432,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,734.73725
Policy Entropy: 1.06120
Value Function Loss: 3.54636

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11,649.27259
Overall Steps per Second: 9,866.67679

Timestep Collection Time: 4.29417
Timestep Consumption Time: 0.77582
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 5.06999

Cumulative Model Updates: 51,825
Cumulative Timesteps: 864,482,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 864482808...
Checkpoint 864482808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,248.41219
Policy Entropy: 1.03940
Value Function Loss: 3.47974

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 11,805.60002
Overall Steps per Second: 10,168.90228

Timestep Collection Time: 4.23579
Timestep Consumption Time: 0.68176
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.91754

Cumulative Model Updates: 51,828
Cumulative Timesteps: 864,532,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,674.65197
Policy Entropy: 1.03019
Value Function Loss: 3.26974

Mean KL Divergence: 0.03194
SB3 Clip Fraction: 0.18486
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.11375

Collected Steps per Second: 12,025.67413
Overall Steps per Second: 10,175.34716

Timestep Collection Time: 4.15977
Timestep Consumption Time: 0.75643
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.91620

Cumulative Model Updates: 51,831
Cumulative Timesteps: 864,582,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 864582838...
Checkpoint 864582838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,606.00494
Policy Entropy: 1.04214
Value Function Loss: 3.16743

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 11,789.70987
Overall Steps per Second: 10,019.54033

Timestep Collection Time: 4.24285
Timestep Consumption Time: 0.74959
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 4.99244

Cumulative Model Updates: 51,834
Cumulative Timesteps: 864,632,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,317.30391
Policy Entropy: 1.05210
Value Function Loss: 3.26179

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.11286

Collected Steps per Second: 12,514.14630
Overall Steps per Second: 10,446.41326

Timestep Collection Time: 3.99548
Timestep Consumption Time: 0.79085
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.78633

Cumulative Model Updates: 51,837
Cumulative Timesteps: 864,682,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 864682860...
Checkpoint 864682860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,184.73221
Policy Entropy: 1.03128
Value Function Loss: 3.39723

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.16020
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 11,831.68026
Overall Steps per Second: 10,028.06607

Timestep Collection Time: 4.22746
Timestep Consumption Time: 0.76034
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.98780

Cumulative Model Updates: 51,840
Cumulative Timesteps: 864,732,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,667.60427
Policy Entropy: 1.02952
Value Function Loss: 3.52326

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.18231
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 11,730.88698
Overall Steps per Second: 10,115.75134

Timestep Collection Time: 4.26396
Timestep Consumption Time: 0.68081
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.94476

Cumulative Model Updates: 51,843
Cumulative Timesteps: 864,782,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 864782898...
Checkpoint 864782898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,548.24716
Policy Entropy: 1.04417
Value Function Loss: 3.38448

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.09390

Collected Steps per Second: 11,818.32756
Overall Steps per Second: 9,916.27263

Timestep Collection Time: 4.23156
Timestep Consumption Time: 0.81166
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.04323

Cumulative Model Updates: 51,846
Cumulative Timesteps: 864,832,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760,063.10617
Policy Entropy: 1.05891
Value Function Loss: 3.37835

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.18098
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 9,178.15861
Overall Steps per Second: 7,496.70212

Timestep Collection Time: 5.45186
Timestep Consumption Time: 1.22281
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.67467

Cumulative Model Updates: 51,849
Cumulative Timesteps: 864,882,946

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 864882946...
Checkpoint 864882946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,081.87519
Policy Entropy: 1.01939
Value Function Loss: 3.23135

Mean KL Divergence: 0.04763
SB3 Clip Fraction: 0.22332
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 8,628.92716
Overall Steps per Second: 7,465.23767

Timestep Collection Time: 5.79446
Timestep Consumption Time: 0.90325
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 6.69771

Cumulative Model Updates: 51,852
Cumulative Timesteps: 864,932,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,316.71775
Policy Entropy: 1.04555
Value Function Loss: 3.38006

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.18009
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 10,753.02282
Overall Steps per Second: 9,054.63822

Timestep Collection Time: 4.65265
Timestep Consumption Time: 0.87270
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 5.52535

Cumulative Model Updates: 51,855
Cumulative Timesteps: 864,982,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 864982976...
Checkpoint 864982976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795,858.58621
Policy Entropy: 1.03123
Value Function Loss: 3.41563

Mean KL Divergence: 0.03011
SB3 Clip Fraction: 0.19441
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.07830

Collected Steps per Second: 11,128.79872
Overall Steps per Second: 9,648.40688

Timestep Collection Time: 4.49411
Timestep Consumption Time: 0.68955
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.18365

Cumulative Model Updates: 51,858
Cumulative Timesteps: 865,032,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,977.41374
Policy Entropy: 1.02580
Value Function Loss: 3.58313

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.20129
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 10,663.92528
Overall Steps per Second: 9,166.07297

Timestep Collection Time: 4.69096
Timestep Consumption Time: 0.76656
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 5.45752

Cumulative Model Updates: 51,861
Cumulative Timesteps: 865,083,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 865083014...
Checkpoint 865083014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,129.45692
Policy Entropy: 1.03473
Value Function Loss: 3.48003

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 11,313.32279
Overall Steps per Second: 9,631.00252

Timestep Collection Time: 4.42116
Timestep Consumption Time: 0.77228
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.19344

Cumulative Model Updates: 51,864
Cumulative Timesteps: 865,133,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,880.60942
Policy Entropy: 1.04276
Value Function Loss: 3.39359

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.09048

Collected Steps per Second: 10,931.69312
Overall Steps per Second: 9,222.53785

Timestep Collection Time: 4.57386
Timestep Consumption Time: 0.84764
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.42150

Cumulative Model Updates: 51,867
Cumulative Timesteps: 865,183,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 865183032...
Checkpoint 865183032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,482.40452
Policy Entropy: 1.03264
Value Function Loss: 3.38953

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 11,396.92776
Overall Steps per Second: 9,675.56469

Timestep Collection Time: 4.38873
Timestep Consumption Time: 0.78079
PPO Batch Consumption Time: 0.03881
Total Iteration Time: 5.16952

Cumulative Model Updates: 51,870
Cumulative Timesteps: 865,233,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,764.02479
Policy Entropy: 1.01829
Value Function Loss: 3.40952

Mean KL Divergence: 0.03297
SB3 Clip Fraction: 0.20792
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 6,799.20498
Overall Steps per Second: 6,118.52021

Timestep Collection Time: 7.35468
Timestep Consumption Time: 0.81821
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 8.17289

Cumulative Model Updates: 51,873
Cumulative Timesteps: 865,283,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865283056...
Checkpoint 865283056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,762.48587
Policy Entropy: 1.04110
Value Function Loss: 3.30020

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.06928

Collected Steps per Second: 9,172.60775
Overall Steps per Second: 8,034.30726

Timestep Collection Time: 5.45232
Timestep Consumption Time: 0.77248
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 6.22481

Cumulative Model Updates: 51,876
Cumulative Timesteps: 865,333,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,732.53175
Policy Entropy: 1.03695
Value Function Loss: 3.34062

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 11,144.49330
Overall Steps per Second: 9,511.01001

Timestep Collection Time: 4.48885
Timestep Consumption Time: 0.77095
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.25980

Cumulative Model Updates: 51,879
Cumulative Timesteps: 865,383,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865383094...
Checkpoint 865383094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,806.44675
Policy Entropy: 1.04000
Value Function Loss: 3.44913

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.07256
Value Function Update Magnitude: 0.07616

Collected Steps per Second: 11,022.44723
Overall Steps per Second: 9,316.58040

Timestep Collection Time: 4.53801
Timestep Consumption Time: 0.83091
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.36892

Cumulative Model Updates: 51,882
Cumulative Timesteps: 865,433,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,516.04344
Policy Entropy: 1.03455
Value Function Loss: 3.71814

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 10,980.94840
Overall Steps per Second: 9,409.56194

Timestep Collection Time: 4.55352
Timestep Consumption Time: 0.76043
PPO Batch Consumption Time: 0.03328
Total Iteration Time: 5.31396

Cumulative Model Updates: 51,885
Cumulative Timesteps: 865,483,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 865483116...
Checkpoint 865483116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,821.17734
Policy Entropy: 1.05057
Value Function Loss: 3.81962

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.16220
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.09274

Collected Steps per Second: 11,401.66800
Overall Steps per Second: 9,872.96366

Timestep Collection Time: 4.38708
Timestep Consumption Time: 0.67928
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.06636

Cumulative Model Updates: 51,888
Cumulative Timesteps: 865,533,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,772.20522
Policy Entropy: 1.04432
Value Function Loss: 3.63013

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.08811

Collected Steps per Second: 11,725.74834
Overall Steps per Second: 9,962.00496

Timestep Collection Time: 4.26446
Timestep Consumption Time: 0.75501
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 5.01947

Cumulative Model Updates: 51,891
Cumulative Timesteps: 865,583,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 865583140...
Checkpoint 865583140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,760.26000
Policy Entropy: 1.04392
Value Function Loss: 3.39142

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.08697

Collected Steps per Second: 11,851.78262
Overall Steps per Second: 10,082.74464

Timestep Collection Time: 4.21962
Timestep Consumption Time: 0.74034
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.95996

Cumulative Model Updates: 51,894
Cumulative Timesteps: 865,633,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,384.15066
Policy Entropy: 1.02059
Value Function Loss: 3.20421

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.08837

Collected Steps per Second: 12,496.61240
Overall Steps per Second: 10,414.81464

Timestep Collection Time: 4.00172
Timestep Consumption Time: 0.79990
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.80162

Cumulative Model Updates: 51,897
Cumulative Timesteps: 865,683,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865683158...
Checkpoint 865683158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,432.19031
Policy Entropy: 1.01745
Value Function Loss: 3.28656

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 11,427.27219
Overall Steps per Second: 9,660.49720

Timestep Collection Time: 4.37707
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 5.17758

Cumulative Model Updates: 51,900
Cumulative Timesteps: 865,733,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,366.52492
Policy Entropy: 1.03499
Value Function Loss: 3.45338

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 12,271.97273
Overall Steps per Second: 10,615.75631

Timestep Collection Time: 4.07595
Timestep Consumption Time: 0.63591
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.71186

Cumulative Model Updates: 51,903
Cumulative Timesteps: 865,783,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 865783196...
Checkpoint 865783196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,822.31926
Policy Entropy: 1.03560
Value Function Loss: 3.37570

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 11,640.80611
Overall Steps per Second: 9,910.75565

Timestep Collection Time: 4.29730
Timestep Consumption Time: 0.75015
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.04745

Cumulative Model Updates: 51,906
Cumulative Timesteps: 865,833,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,387.32887
Policy Entropy: 1.04148
Value Function Loss: 3.39727

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 11,461.50377
Overall Steps per Second: 9,793.63855

Timestep Collection Time: 4.36313
Timestep Consumption Time: 0.74304
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.10617

Cumulative Model Updates: 51,909
Cumulative Timesteps: 865,883,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865883228...
Checkpoint 865883228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,447.37793
Policy Entropy: 1.04221
Value Function Loss: 3.20311

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 11,649.19532
Overall Steps per Second: 9,845.56338

Timestep Collection Time: 4.29283
Timestep Consumption Time: 0.78641
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.07924

Cumulative Model Updates: 51,912
Cumulative Timesteps: 865,933,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,926.35591
Policy Entropy: 1.04536
Value Function Loss: 3.34113

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.07617
Value Function Update Magnitude: 0.10260

Collected Steps per Second: 11,823.80768
Overall Steps per Second: 9,962.34023

Timestep Collection Time: 4.22977
Timestep Consumption Time: 0.79033
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.02011

Cumulative Model Updates: 51,915
Cumulative Timesteps: 865,983,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 865983248...
Checkpoint 865983248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,423.37851
Policy Entropy: 1.04850
Value Function Loss: 3.30708

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.06856
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 10,771.61986
Overall Steps per Second: 9,360.75616

Timestep Collection Time: 4.64238
Timestep Consumption Time: 0.69971
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.34209

Cumulative Model Updates: 51,918
Cumulative Timesteps: 866,033,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,515.84820
Policy Entropy: 1.04448
Value Function Loss: 3.37158

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.09170

Collected Steps per Second: 11,520.88644
Overall Steps per Second: 9,798.38199

Timestep Collection Time: 4.34203
Timestep Consumption Time: 0.76331
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.10533

Cumulative Model Updates: 51,921
Cumulative Timesteps: 866,083,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 866083278...
Checkpoint 866083278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,513.29461
Policy Entropy: 1.04966
Value Function Loss: 3.43985

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11,657.18036
Overall Steps per Second: 9,982.67452

Timestep Collection Time: 4.29075
Timestep Consumption Time: 0.71973
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.01048

Cumulative Model Updates: 51,924
Cumulative Timesteps: 866,133,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,375.44014
Policy Entropy: 1.06114
Value Function Loss: 3.59474

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.07828

Collected Steps per Second: 11,326.02025
Overall Steps per Second: 9,861.85631

Timestep Collection Time: 4.41497
Timestep Consumption Time: 0.65548
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.07045

Cumulative Model Updates: 51,927
Cumulative Timesteps: 866,183,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 866183300...
Checkpoint 866183300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,761.85652
Policy Entropy: 1.06392
Value Function Loss: 3.66647

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.06519
Value Function Update Magnitude: 0.08203

Collected Steps per Second: 11,405.41258
Overall Steps per Second: 9,720.42937

Timestep Collection Time: 4.38388
Timestep Consumption Time: 0.75992
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.14381

Cumulative Model Updates: 51,930
Cumulative Timesteps: 866,233,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,825.36938
Policy Entropy: 1.06713
Value Function Loss: 3.65783

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.07156
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 11,545.30720
Overall Steps per Second: 10,029.40836

Timestep Collection Time: 4.33284
Timestep Consumption Time: 0.65489
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.98773

Cumulative Model Updates: 51,933
Cumulative Timesteps: 866,283,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 866283324...
Checkpoint 866283324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,585.43972
Policy Entropy: 1.05688
Value Function Loss: 3.55098

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.10571

Collected Steps per Second: 11,052.10741
Overall Steps per Second: 9,458.49698

Timestep Collection Time: 4.52529
Timestep Consumption Time: 0.76244
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 5.28773

Cumulative Model Updates: 51,936
Cumulative Timesteps: 866,333,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,095.52270
Policy Entropy: 1.05897
Value Function Loss: 3.37105

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 11,602.79910
Overall Steps per Second: 9,888.44307

Timestep Collection Time: 4.30982
Timestep Consumption Time: 0.74719
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.05701

Cumulative Model Updates: 51,939
Cumulative Timesteps: 866,383,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 866383344...
Checkpoint 866383344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,353.32307
Policy Entropy: 1.05577
Value Function Loss: 3.35261

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.07394
Value Function Update Magnitude: 0.10837

Collected Steps per Second: 11,906.64287
Overall Steps per Second: 10,076.85557

Timestep Collection Time: 4.19934
Timestep Consumption Time: 0.76253
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.96187

Cumulative Model Updates: 51,942
Cumulative Timesteps: 866,433,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,164.74268
Policy Entropy: 1.06417
Value Function Loss: 3.31407

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 11,633.99675
Overall Steps per Second: 9,863.18198

Timestep Collection Time: 4.29809
Timestep Consumption Time: 0.77167
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.06976

Cumulative Model Updates: 51,945
Cumulative Timesteps: 866,483,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 866483348...
Checkpoint 866483348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,850.97739
Policy Entropy: 1.04571
Value Function Loss: 3.46759

Mean KL Divergence: 0.03588
SB3 Clip Fraction: 0.18481
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.10130

Collected Steps per Second: 11,562.17105
Overall Steps per Second: 10,023.39426

Timestep Collection Time: 4.32722
Timestep Consumption Time: 0.66431
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.99152

Cumulative Model Updates: 51,948
Cumulative Timesteps: 866,533,380

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,893.82667
Policy Entropy: 1.06976
Value Function Loss: 3.42659

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.10382

Collected Steps per Second: 11,697.28854
Overall Steps per Second: 9,808.68611

Timestep Collection Time: 4.27603
Timestep Consumption Time: 0.82332
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.09936

Cumulative Model Updates: 51,951
Cumulative Timesteps: 866,583,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 866583398...
Checkpoint 866583398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,604.96617
Policy Entropy: 1.05800
Value Function Loss: 3.43242

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.10116

Collected Steps per Second: 11,133.96043
Overall Steps per Second: 9,515.16892

Timestep Collection Time: 4.49184
Timestep Consumption Time: 0.76419
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.25603

Cumulative Model Updates: 51,954
Cumulative Timesteps: 866,633,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,016.99642
Policy Entropy: 1.05038
Value Function Loss: 3.31053

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14702
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.08772

Collected Steps per Second: 11,865.40255
Overall Steps per Second: 10,200.60143

Timestep Collection Time: 4.21528
Timestep Consumption Time: 0.68796
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.90324

Cumulative Model Updates: 51,957
Cumulative Timesteps: 866,683,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 866683426...
Checkpoint 866683426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,970.09173
Policy Entropy: 1.06168
Value Function Loss: 3.25030

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 11,600.41964
Overall Steps per Second: 9,874.13586

Timestep Collection Time: 4.31243
Timestep Consumption Time: 0.75394
PPO Batch Consumption Time: 0.03344
Total Iteration Time: 5.06637

Cumulative Model Updates: 51,960
Cumulative Timesteps: 866,733,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,788.51004
Policy Entropy: 1.06557
Value Function Loss: 3.25524

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.09206

Collected Steps per Second: 11,684.45176
Overall Steps per Second: 9,938.00918

Timestep Collection Time: 4.27936
Timestep Consumption Time: 0.75203
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.03139

Cumulative Model Updates: 51,963
Cumulative Timesteps: 866,783,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 866783454...
Checkpoint 866783454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,001.65484
Policy Entropy: 1.06208
Value Function Loss: 3.40814

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.06910
Value Function Update Magnitude: 0.09848

Collected Steps per Second: 12,056.35449
Overall Steps per Second: 10,185.14374

Timestep Collection Time: 4.14852
Timestep Consumption Time: 0.76216
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.91068

Cumulative Model Updates: 51,966
Cumulative Timesteps: 866,833,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,664.93306
Policy Entropy: 1.06072
Value Function Loss: 3.43983

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 12,073.12775
Overall Steps per Second: 10,189.91670

Timestep Collection Time: 4.14176
Timestep Consumption Time: 0.76544
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.90720

Cumulative Model Updates: 51,969
Cumulative Timesteps: 866,883,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 866883474...
Checkpoint 866883474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,576.99732
Policy Entropy: 1.07544
Value Function Loss: 3.36733

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 11,164.97678
Overall Steps per Second: 9,708.34329

Timestep Collection Time: 4.48026
Timestep Consumption Time: 0.67222
PPO Batch Consumption Time: 0.03334
Total Iteration Time: 5.15248

Cumulative Model Updates: 51,972
Cumulative Timesteps: 866,933,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,932.57274
Policy Entropy: 1.07227
Value Function Loss: 3.28258

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.08932

Collected Steps per Second: 12,097.81758
Overall Steps per Second: 10,174.27136

Timestep Collection Time: 4.13513
Timestep Consumption Time: 0.78179
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.91691

Cumulative Model Updates: 51,975
Cumulative Timesteps: 866,983,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 866983522...
Checkpoint 866983522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,787.38203
Policy Entropy: 1.07240
Value Function Loss: 3.17754

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 11,868.71380
Overall Steps per Second: 10,087.04861

Timestep Collection Time: 4.21276
Timestep Consumption Time: 0.74409
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.95685

Cumulative Model Updates: 51,978
Cumulative Timesteps: 867,033,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,146.25843
Policy Entropy: 1.06485
Value Function Loss: 3.02263

Mean KL Divergence: 0.03428
SB3 Clip Fraction: 0.16615
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.08881

Collected Steps per Second: 11,190.19597
Overall Steps per Second: 9,684.25668

Timestep Collection Time: 4.47016
Timestep Consumption Time: 0.69513
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.16529

Cumulative Model Updates: 51,981
Cumulative Timesteps: 867,083,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 867083544...
Checkpoint 867083544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,338.76118
Policy Entropy: 1.07151
Value Function Loss: 3.11479

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.16210
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 11,770.87609
Overall Steps per Second: 9,927.05829

Timestep Collection Time: 4.24964
Timestep Consumption Time: 0.78931
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.03896

Cumulative Model Updates: 51,984
Cumulative Timesteps: 867,133,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,803.49045
Policy Entropy: 1.08303
Value Function Loss: 3.37655

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 11,553.35847
Overall Steps per Second: 9,785.79774

Timestep Collection Time: 4.32913
Timestep Consumption Time: 0.78195
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.11108

Cumulative Model Updates: 51,987
Cumulative Timesteps: 867,183,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 867183582...
Checkpoint 867183582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,700.00256
Policy Entropy: 1.06408
Value Function Loss: 3.60826

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.07611

Collected Steps per Second: 10,573.51587
Overall Steps per Second: 8,988.47823

Timestep Collection Time: 4.72936
Timestep Consumption Time: 0.83398
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.56334

Cumulative Model Updates: 51,990
Cumulative Timesteps: 867,233,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,409.38686
Policy Entropy: 1.05595
Value Function Loss: 3.56537

Mean KL Divergence: 0.02797
SB3 Clip Fraction: 0.18679
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.08511

Collected Steps per Second: 11,378.52412
Overall Steps per Second: 9,475.51921

Timestep Collection Time: 4.39600
Timestep Consumption Time: 0.88287
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.27887

Cumulative Model Updates: 51,993
Cumulative Timesteps: 867,283,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867283608...
Checkpoint 867283608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,022.06005
Policy Entropy: 1.06703
Value Function Loss: 3.50067

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 10,816.01190
Overall Steps per Second: 9,414.56879

Timestep Collection Time: 4.62481
Timestep Consumption Time: 0.68844
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 5.31325

Cumulative Model Updates: 51,996
Cumulative Timesteps: 867,333,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,168.79959
Policy Entropy: 1.07617
Value Function Loss: 3.45459

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 10,579.62491
Overall Steps per Second: 8,601.88678

Timestep Collection Time: 4.72796
Timestep Consumption Time: 1.08705
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 5.81500

Cumulative Model Updates: 51,999
Cumulative Timesteps: 867,383,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867383650...
Checkpoint 867383650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,061.70072
Policy Entropy: 1.05988
Value Function Loss: 3.20767

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.09263

Collected Steps per Second: 8,520.42868
Overall Steps per Second: 7,396.33750

Timestep Collection Time: 5.87107
Timestep Consumption Time: 0.89228
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 6.76335

Cumulative Model Updates: 52,002
Cumulative Timesteps: 867,433,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,294.15168
Policy Entropy: 1.07395
Value Function Loss: 3.06440

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.17572
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.09981

Collected Steps per Second: 9,788.53262
Overall Steps per Second: 8,440.52022

Timestep Collection Time: 5.10884
Timestep Consumption Time: 0.81592
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.92475

Cumulative Model Updates: 52,005
Cumulative Timesteps: 867,483,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 867483682...
Checkpoint 867483682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,850.94209
Policy Entropy: 1.07706
Value Function Loss: 2.94046

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.17900
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 9,972.27038
Overall Steps per Second: 8,619.79549

Timestep Collection Time: 5.01511
Timestep Consumption Time: 0.78689
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.80199

Cumulative Model Updates: 52,008
Cumulative Timesteps: 867,533,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,119.25805
Policy Entropy: 1.06091
Value Function Loss: 3.14919

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 10,387.61204
Overall Steps per Second: 8,963.47594

Timestep Collection Time: 4.81593
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.58109

Cumulative Model Updates: 52,011
Cumulative Timesteps: 867,583,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 867583720...
Checkpoint 867583720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,288.72911
Policy Entropy: 1.05245
Value Function Loss: 3.34877

Mean KL Divergence: 0.03138
SB3 Clip Fraction: 0.18741
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.10345

Collected Steps per Second: 10,488.08358
Overall Steps per Second: 9,045.40048

Timestep Collection Time: 4.76922
Timestep Consumption Time: 0.76066
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 5.52988

Cumulative Model Updates: 52,014
Cumulative Timesteps: 867,633,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,970.15109
Policy Entropy: 1.06324
Value Function Loss: 3.56677

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08979

Collected Steps per Second: 10,992.75577
Overall Steps per Second: 9,458.21527

Timestep Collection Time: 4.54845
Timestep Consumption Time: 0.73796
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.28641

Cumulative Model Updates: 52,017
Cumulative Timesteps: 867,683,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867683740...
Checkpoint 867683740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,504.18562
Policy Entropy: 1.07263
Value Function Loss: 3.53806

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 7,317.14920
Overall Steps per Second: 6,496.59587

Timestep Collection Time: 6.83654
Timestep Consumption Time: 0.86349
PPO Batch Consumption Time: 0.04722
Total Iteration Time: 7.70003

Cumulative Model Updates: 52,020
Cumulative Timesteps: 867,733,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,003.17139
Policy Entropy: 1.04736
Value Function Loss: 3.50164

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 9,686.03035
Overall Steps per Second: 8,187.79638

Timestep Collection Time: 5.16496
Timestep Consumption Time: 0.94510
PPO Batch Consumption Time: 0.03934
Total Iteration Time: 6.11007

Cumulative Model Updates: 52,023
Cumulative Timesteps: 867,783,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 867783792...
Checkpoint 867783792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,549.29989
Policy Entropy: 1.03847
Value Function Loss: 3.45571

Mean KL Divergence: 0.03440
SB3 Clip Fraction: 0.18980
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.08550

Collected Steps per Second: 9,345.13186
Overall Steps per Second: 8,035.64824

Timestep Collection Time: 5.35188
Timestep Consumption Time: 0.87214
PPO Batch Consumption Time: 0.03859
Total Iteration Time: 6.22402

Cumulative Model Updates: 52,026
Cumulative Timesteps: 867,833,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,746.10857
Policy Entropy: 1.05507
Value Function Loss: 3.44105

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.08978

Collected Steps per Second: 10,206.03473
Overall Steps per Second: 8,646.68956

Timestep Collection Time: 4.90220
Timestep Consumption Time: 0.88406
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 5.78626

Cumulative Model Updates: 52,029
Cumulative Timesteps: 867,883,838

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 867883838...
Checkpoint 867883838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,903.93120
Policy Entropy: 1.06968
Value Function Loss: 3.29103

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.16074
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 10,123.42807
Overall Steps per Second: 8,666.45808

Timestep Collection Time: 4.94161
Timestep Consumption Time: 0.83076
PPO Batch Consumption Time: 0.03892
Total Iteration Time: 5.77237

Cumulative Model Updates: 52,032
Cumulative Timesteps: 867,933,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,834.31921
Policy Entropy: 1.03889
Value Function Loss: 3.33087

Mean KL Divergence: 0.03530
SB3 Clip Fraction: 0.18410
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 9,651.79776
Overall Steps per Second: 8,385.31053

Timestep Collection Time: 5.18225
Timestep Consumption Time: 0.78271
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 5.96495

Cumulative Model Updates: 52,035
Cumulative Timesteps: 867,983,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 867983882...
Checkpoint 867983882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,884.79881
Policy Entropy: 1.05798
Value Function Loss: 3.33494

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 10,255.31551
Overall Steps per Second: 8,766.50689

Timestep Collection Time: 4.87552
Timestep Consumption Time: 0.82801
PPO Batch Consumption Time: 0.03954
Total Iteration Time: 5.70353

Cumulative Model Updates: 52,038
Cumulative Timesteps: 868,033,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,915.60733
Policy Entropy: 1.05452
Value Function Loss: 3.25227

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 10,001.22081
Overall Steps per Second: 8,511.24963

Timestep Collection Time: 5.00079
Timestep Consumption Time: 0.87543
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 5.87622

Cumulative Model Updates: 52,041
Cumulative Timesteps: 868,083,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 868083896...
Checkpoint 868083896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,247.92681
Policy Entropy: 1.04782
Value Function Loss: 3.13322

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.08691

Collected Steps per Second: 7,376.82536
Overall Steps per Second: 6,447.50628

Timestep Collection Time: 6.78042
Timestep Consumption Time: 0.97730
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 7.75773

Cumulative Model Updates: 52,044
Cumulative Timesteps: 868,133,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,370.60814
Policy Entropy: 1.03024
Value Function Loss: 3.15721

Mean KL Divergence: 0.03942
SB3 Clip Fraction: 0.22593
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.08308

Collected Steps per Second: 8,654.36032
Overall Steps per Second: 7,344.30619

Timestep Collection Time: 5.77836
Timestep Consumption Time: 1.03073
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 6.80908

Cumulative Model Updates: 52,047
Cumulative Timesteps: 868,183,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 868183922...
Checkpoint 868183922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,198.81996
Policy Entropy: 1.05857
Value Function Loss: 3.36319

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.16886
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.09741

Collected Steps per Second: 10,247.89221
Overall Steps per Second: 8,999.18352

Timestep Collection Time: 4.87905
Timestep Consumption Time: 0.67701
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.55606

Cumulative Model Updates: 52,050
Cumulative Timesteps: 868,233,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,279.40461
Policy Entropy: 1.03011
Value Function Loss: 3.44928

Mean KL Divergence: 0.03115
SB3 Clip Fraction: 0.19744
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.11172

Collected Steps per Second: 11,589.50692
Overall Steps per Second: 9,827.95845

Timestep Collection Time: 4.31477
Timestep Consumption Time: 0.77337
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 5.08814

Cumulative Model Updates: 52,053
Cumulative Timesteps: 868,283,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 868283928...
Checkpoint 868283928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,958.40355
Policy Entropy: 1.04104
Value Function Loss: 3.40799

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.18819
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 11,314.11209
Overall Steps per Second: 9,657.94321

Timestep Collection Time: 4.42067
Timestep Consumption Time: 0.75807
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.17874

Cumulative Model Updates: 52,056
Cumulative Timesteps: 868,333,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,576.61133
Policy Entropy: 1.04092
Value Function Loss: 3.30815

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.16175
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 11,523.95740
Overall Steps per Second: 9,805.01157

Timestep Collection Time: 4.33913
Timestep Consumption Time: 0.76071
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 5.09984

Cumulative Model Updates: 52,059
Cumulative Timesteps: 868,383,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 868383948...
Checkpoint 868383948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,920.84261
Policy Entropy: 1.04893
Value Function Loss: 3.30065

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.08964

Collected Steps per Second: 11,480.26859
Overall Steps per Second: 9,784.37182

Timestep Collection Time: 4.35530
Timestep Consumption Time: 0.75489
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.11019

Cumulative Model Updates: 52,062
Cumulative Timesteps: 868,433,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,860.79152
Policy Entropy: 1.04633
Value Function Loss: 3.21977

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.16649
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 11,551.80253
Overall Steps per Second: 9,887.65585

Timestep Collection Time: 4.33023
Timestep Consumption Time: 0.72880
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.05904

Cumulative Model Updates: 52,065
Cumulative Timesteps: 868,483,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 868483970...
Checkpoint 868483970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,139.50850
Policy Entropy: 1.05933
Value Function Loss: 3.22474

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.15354
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 11,697.86870
Overall Steps per Second: 9,928.19702

Timestep Collection Time: 4.27599
Timestep Consumption Time: 0.76218
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.03818

Cumulative Model Updates: 52,068
Cumulative Timesteps: 868,533,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,281.29688
Policy Entropy: 1.05986
Value Function Loss: 3.41209

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.08661

Collected Steps per Second: 11,853.48269
Overall Steps per Second: 10,065.30964

Timestep Collection Time: 4.22087
Timestep Consumption Time: 0.74987
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.97074

Cumulative Model Updates: 52,071
Cumulative Timesteps: 868,584,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 868584022...
Checkpoint 868584022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,292.63629
Policy Entropy: 1.06207
Value Function Loss: 3.57526

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.07972

Collected Steps per Second: 11,913.12753
Overall Steps per Second: 10,064.73423

Timestep Collection Time: 4.19873
Timestep Consumption Time: 0.77110
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.96983

Cumulative Model Updates: 52,074
Cumulative Timesteps: 868,634,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,060.04343
Policy Entropy: 1.06208
Value Function Loss: 3.56082

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.08836

Collected Steps per Second: 11,729.97005
Overall Steps per Second: 9,906.67693

Timestep Collection Time: 4.26361
Timestep Consumption Time: 0.78470
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.04831

Cumulative Model Updates: 52,077
Cumulative Timesteps: 868,684,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 868684054...
Checkpoint 868684054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,673.30621
Policy Entropy: 1.05509
Value Function Loss: 3.40271

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.10114

Collected Steps per Second: 11,740.41199
Overall Steps per Second: 10,048.39469

Timestep Collection Time: 4.26067
Timestep Consumption Time: 0.71744
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 4.97811

Cumulative Model Updates: 52,080
Cumulative Timesteps: 868,734,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,130.30699
Policy Entropy: 1.06669
Value Function Loss: 3.37696

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 11,912.07837
Overall Steps per Second: 9,881.96344

Timestep Collection Time: 4.19944
Timestep Consumption Time: 0.86272
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.06215

Cumulative Model Updates: 52,083
Cumulative Timesteps: 868,784,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 868784100...
Checkpoint 868784100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782,845.61981
Policy Entropy: 1.06646
Value Function Loss: 3.31712

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.11265
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.08935

Collected Steps per Second: 11,869.50014
Overall Steps per Second: 10,100.72413

Timestep Collection Time: 4.21416
Timestep Consumption Time: 0.73796
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 4.95212

Cumulative Model Updates: 52,086
Cumulative Timesteps: 868,834,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,656.01122
Policy Entropy: 1.07105
Value Function Loss: 3.36210

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 11,988.50900
Overall Steps per Second: 10,342.02837

Timestep Collection Time: 4.17116
Timestep Consumption Time: 0.66406
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 4.83522

Cumulative Model Updates: 52,089
Cumulative Timesteps: 868,884,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 868884126...
Checkpoint 868884126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,967.21719
Policy Entropy: 1.07109
Value Function Loss: 3.38257

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 12,202.44944
Overall Steps per Second: 10,348.70960

Timestep Collection Time: 4.09983
Timestep Consumption Time: 0.73439
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.83423

Cumulative Model Updates: 52,092
Cumulative Timesteps: 868,934,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,884.00438
Policy Entropy: 1.06898
Value Function Loss: 3.43447

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 12,423.18798
Overall Steps per Second: 10,429.22332

Timestep Collection Time: 4.02505
Timestep Consumption Time: 0.76955
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.79460

Cumulative Model Updates: 52,095
Cumulative Timesteps: 868,984,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 868984158...
Checkpoint 868984158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,991.64708
Policy Entropy: 1.06376
Value Function Loss: 3.26662

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 12,180.95072
Overall Steps per Second: 10,300.35647

Timestep Collection Time: 4.10493
Timestep Consumption Time: 0.74946
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.85440

Cumulative Model Updates: 52,098
Cumulative Timesteps: 869,034,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509,043.04656
Policy Entropy: 1.07745
Value Function Loss: 3.16536

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.06390

Collected Steps per Second: 12,423.30566
Overall Steps per Second: 10,403.76536

Timestep Collection Time: 4.02598
Timestep Consumption Time: 0.78151
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.80749

Cumulative Model Updates: 52,101
Cumulative Timesteps: 869,084,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869084176...
Checkpoint 869084176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,566.52649
Policy Entropy: 1.09020
Value Function Loss: 3.27450

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 11,649.55398
Overall Steps per Second: 10,039.21841

Timestep Collection Time: 4.29476
Timestep Consumption Time: 0.68890
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.98365

Cumulative Model Updates: 52,104
Cumulative Timesteps: 869,134,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,679.05153
Policy Entropy: 1.06259
Value Function Loss: 3.57622

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.16485
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.08505

Collected Steps per Second: 12,118.01541
Overall Steps per Second: 10,289.84264

Timestep Collection Time: 4.12658
Timestep Consumption Time: 0.73316
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.85974

Cumulative Model Updates: 52,107
Cumulative Timesteps: 869,184,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 869184214...
Checkpoint 869184214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,546.72376
Policy Entropy: 1.08204
Value Function Loss: 3.65899

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.19814
Policy Update Magnitude: 0.06889
Value Function Update Magnitude: 0.08975

Collected Steps per Second: 12,185.36747
Overall Steps per Second: 10,313.97319

Timestep Collection Time: 4.10443
Timestep Consumption Time: 0.74472
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.84915

Cumulative Model Updates: 52,110
Cumulative Timesteps: 869,234,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,173.85498
Policy Entropy: 1.07078
Value Function Loss: 3.59497

Mean KL Divergence: 0.02920
SB3 Clip Fraction: 0.19263
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.09303

Collected Steps per Second: 12,139.77107
Overall Steps per Second: 10,405.04247

Timestep Collection Time: 4.11968
Timestep Consumption Time: 0.68683
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.80652

Cumulative Model Updates: 52,113
Cumulative Timesteps: 869,284,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869284240...
Checkpoint 869284240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,884.41450
Policy Entropy: 1.06511
Value Function Loss: 3.37177

Mean KL Divergence: 0.03319
SB3 Clip Fraction: 0.17183
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.10690

Collected Steps per Second: 12,057.35750
Overall Steps per Second: 10,181.18213

Timestep Collection Time: 4.14817
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.91259

Cumulative Model Updates: 52,116
Cumulative Timesteps: 869,334,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585,422.18868
Policy Entropy: 1.06156
Value Function Loss: 3.36916

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.18635
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.10568

Collected Steps per Second: 12,070.39165
Overall Steps per Second: 10,224.27508

Timestep Collection Time: 4.14419
Timestep Consumption Time: 0.74828
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 4.89247

Cumulative Model Updates: 52,119
Cumulative Timesteps: 869,384,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 869384278...
Checkpoint 869384278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,256.55523
Policy Entropy: 1.07401
Value Function Loss: 3.38600

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 11,772.27763
Overall Steps per Second: 9,954.13127

Timestep Collection Time: 4.24846
Timestep Consumption Time: 0.77599
PPO Batch Consumption Time: 0.03943
Total Iteration Time: 5.02445

Cumulative Model Updates: 52,122
Cumulative Timesteps: 869,434,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,989.09681
Policy Entropy: 1.08351
Value Function Loss: 3.38875

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.08135

Collected Steps per Second: 12,126.24974
Overall Steps per Second: 10,250.93118

Timestep Collection Time: 4.12461
Timestep Consumption Time: 0.75456
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 4.87917

Cumulative Model Updates: 52,125
Cumulative Timesteps: 869,484,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869484308...
Checkpoint 869484308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,060.14843
Policy Entropy: 1.05742
Value Function Loss: 3.21655

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 12,051.91923
Overall Steps per Second: 10,421.97630

Timestep Collection Time: 4.15104
Timestep Consumption Time: 0.64920
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 4.80024

Cumulative Model Updates: 52,128
Cumulative Timesteps: 869,534,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,332.00348
Policy Entropy: 1.07022
Value Function Loss: 3.15080

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 12,224.32248
Overall Steps per Second: 10,327.51346

Timestep Collection Time: 4.09152
Timestep Consumption Time: 0.75147
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.84299

Cumulative Model Updates: 52,131
Cumulative Timesteps: 869,584,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869584352...
Checkpoint 869584352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,897.32228
Policy Entropy: 1.06868
Value Function Loss: 3.14741

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 12,047.86157
Overall Steps per Second: 10,367.98037

Timestep Collection Time: 4.15061
Timestep Consumption Time: 0.67251
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.82312

Cumulative Model Updates: 52,134
Cumulative Timesteps: 869,634,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,957.72467
Policy Entropy: 1.07781
Value Function Loss: 3.27644

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08432

Collected Steps per Second: 12,000.48687
Overall Steps per Second: 10,186.58439

Timestep Collection Time: 4.16783
Timestep Consumption Time: 0.74216
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.90999

Cumulative Model Updates: 52,137
Cumulative Timesteps: 869,684,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 869684374...
Checkpoint 869684374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,411.31597
Policy Entropy: 1.06795
Value Function Loss: 3.26294

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 11,522.24234
Overall Steps per Second: 9,862.00701

Timestep Collection Time: 4.34186
Timestep Consumption Time: 0.73094
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.07280

Cumulative Model Updates: 52,140
Cumulative Timesteps: 869,734,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,005.51836
Policy Entropy: 1.05232
Value Function Loss: 3.32985

Mean KL Divergence: 0.03716
SB3 Clip Fraction: 0.20303
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.09519

Collected Steps per Second: 12,257.11492
Overall Steps per Second: 10,532.87631

Timestep Collection Time: 4.08024
Timestep Consumption Time: 0.66794
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 4.74818

Cumulative Model Updates: 52,143
Cumulative Timesteps: 869,784,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869784414...
Checkpoint 869784414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,271.53611
Policy Entropy: 1.07714
Value Function Loss: 3.45065

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.09148

Collected Steps per Second: 12,042.51583
Overall Steps per Second: 10,154.64944

Timestep Collection Time: 4.15229
Timestep Consumption Time: 0.77196
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.92425

Cumulative Model Updates: 52,146
Cumulative Timesteps: 869,834,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,647.95880
Policy Entropy: 1.07894
Value Function Loss: 3.48941

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 12,189.66170
Overall Steps per Second: 10,259.90557

Timestep Collection Time: 4.10282
Timestep Consumption Time: 0.77169
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 4.87451

Cumulative Model Updates: 52,149
Cumulative Timesteps: 869,884,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869884430...
Checkpoint 869884430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,858.13683
Policy Entropy: 1.05976
Value Function Loss: 3.44389

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 12,407.91866
Overall Steps per Second: 10,402.13142

Timestep Collection Time: 4.02968
Timestep Consumption Time: 0.77702
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.80671

Cumulative Model Updates: 52,152
Cumulative Timesteps: 869,934,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,518.46917
Policy Entropy: 1.04258
Value Function Loss: 3.32480

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.19427
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.08251

Collected Steps per Second: 12,019.67461
Overall Steps per Second: 10,165.94253

Timestep Collection Time: 4.16218
Timestep Consumption Time: 0.75896
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.92114

Cumulative Model Updates: 52,155
Cumulative Timesteps: 869,984,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 869984458...
Checkpoint 869984458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,092.30092
Policy Entropy: 1.06220
Value Function Loss: 3.26093

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11,689.23929
Overall Steps per Second: 9,985.86444

Timestep Collection Time: 4.27829
Timestep Consumption Time: 0.72979
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.00808

Cumulative Model Updates: 52,158
Cumulative Timesteps: 870,034,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,844.18603
Policy Entropy: 1.07259
Value Function Loss: 3.26376

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 11,797.45049
Overall Steps per Second: 9,982.08100

Timestep Collection Time: 4.23854
Timestep Consumption Time: 0.77083
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.00938

Cumulative Model Updates: 52,161
Cumulative Timesteps: 870,084,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 870084472...
Checkpoint 870084472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,252.85147
Policy Entropy: 1.04664
Value Function Loss: 3.16817

Mean KL Divergence: 0.03048
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 12,008.52643
Overall Steps per Second: 10,149.96428

Timestep Collection Time: 4.16404
Timestep Consumption Time: 0.76248
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.92652

Cumulative Model Updates: 52,164
Cumulative Timesteps: 870,134,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,640.17050
Policy Entropy: 1.06563
Value Function Loss: 3.38701

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.17276
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 13,042.24037
Overall Steps per Second: 10,882.23396

Timestep Collection Time: 3.83508
Timestep Consumption Time: 0.76122
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.59630

Cumulative Model Updates: 52,167
Cumulative Timesteps: 870,184,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 870184494...
Checkpoint 870184494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,154.30603
Policy Entropy: 1.05790
Value Function Loss: 3.46612

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 12,388.68772
Overall Steps per Second: 10,385.86322

Timestep Collection Time: 4.03820
Timestep Consumption Time: 0.77873
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.81693

Cumulative Model Updates: 52,170
Cumulative Timesteps: 870,234,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,343.34362
Policy Entropy: 1.05253
Value Function Loss: 3.46655

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 12,660.98938
Overall Steps per Second: 10,805.40573

Timestep Collection Time: 3.95167
Timestep Consumption Time: 0.67861
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.63027

Cumulative Model Updates: 52,173
Cumulative Timesteps: 870,284,554

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 870284554...
Checkpoint 870284554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,905.33344
Policy Entropy: 1.03501
Value Function Loss: 3.28194

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.17857
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 12,181.56177
Overall Steps per Second: 10,180.22068

Timestep Collection Time: 4.10653
Timestep Consumption Time: 0.80731
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.91384

Cumulative Model Updates: 52,176
Cumulative Timesteps: 870,334,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,725.88865
Policy Entropy: 1.04882
Value Function Loss: 3.36715

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.10458

Collected Steps per Second: 12,779.11718
Overall Steps per Second: 10,762.18148

Timestep Collection Time: 3.91420
Timestep Consumption Time: 0.73356
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.64776

Cumulative Model Updates: 52,179
Cumulative Timesteps: 870,384,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870384598...
Checkpoint 870384598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,754.74609
Policy Entropy: 1.05818
Value Function Loss: 3.29370

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.11339

Collected Steps per Second: 12,567.66807
Overall Steps per Second: 10,722.00585

Timestep Collection Time: 3.97926
Timestep Consumption Time: 0.68498
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.66424

Cumulative Model Updates: 52,182
Cumulative Timesteps: 870,434,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,694.17113
Policy Entropy: 1.04571
Value Function Loss: 3.23399

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 12,122.84434
Overall Steps per Second: 10,234.71720

Timestep Collection Time: 4.12527
Timestep Consumption Time: 0.76104
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.88631

Cumulative Model Updates: 52,185
Cumulative Timesteps: 870,484,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 870484618...
Checkpoint 870484618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,121.53353
Policy Entropy: 1.03121
Value Function Loss: 3.04046

Mean KL Divergence: 0.04431
SB3 Clip Fraction: 0.21034
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 11,983.50312
Overall Steps per Second: 10,310.90816

Timestep Collection Time: 4.17390
Timestep Consumption Time: 0.67707
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.85098

Cumulative Model Updates: 52,188
Cumulative Timesteps: 870,534,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,750.67500
Policy Entropy: 1.05758
Value Function Loss: 3.18619

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 12,153.43113
Overall Steps per Second: 10,171.03269

Timestep Collection Time: 4.11555
Timestep Consumption Time: 0.80215
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.91769

Cumulative Model Updates: 52,191
Cumulative Timesteps: 870,584,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 870584654...
Checkpoint 870584654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,877.69241
Policy Entropy: 1.03105
Value Function Loss: 3.11098

Mean KL Divergence: 0.03632
SB3 Clip Fraction: 0.19190
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.12621

Collected Steps per Second: 11,825.12670
Overall Steps per Second: 9,904.96553

Timestep Collection Time: 4.22879
Timestep Consumption Time: 0.81979
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.04858

Cumulative Model Updates: 52,194
Cumulative Timesteps: 870,634,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,984.16764
Policy Entropy: 1.05253
Value Function Loss: 3.11461

Mean KL Divergence: 0.02778
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 12,431.45969
Overall Steps per Second: 10,360.64143

Timestep Collection Time: 4.02318
Timestep Consumption Time: 0.80413
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.82731

Cumulative Model Updates: 52,197
Cumulative Timesteps: 870,684,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 870684674...
Checkpoint 870684674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,943.15731
Policy Entropy: 1.05501
Value Function Loss: 3.23389

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.12642

Collected Steps per Second: 12,428.76289
Overall Steps per Second: 10,481.83096

Timestep Collection Time: 4.02357
Timestep Consumption Time: 0.74735
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.77092

Cumulative Model Updates: 52,200
Cumulative Timesteps: 870,734,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,691.19240
Policy Entropy: 1.04780
Value Function Loss: 3.40606

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.11804

Collected Steps per Second: 12,359.03959
Overall Steps per Second: 10,636.67340

Timestep Collection Time: 4.04562
Timestep Consumption Time: 0.65510
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 4.70072

Cumulative Model Updates: 52,203
Cumulative Timesteps: 870,784,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 870784682...
Checkpoint 870784682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,859.90655
Policy Entropy: 1.03998
Value Function Loss: 3.41130

Mean KL Divergence: 0.02926
SB3 Clip Fraction: 0.18487
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.09805

Collected Steps per Second: 12,211.20716
Overall Steps per Second: 10,367.15290

Timestep Collection Time: 4.09640
Timestep Consumption Time: 0.72865
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.82505

Cumulative Model Updates: 52,206
Cumulative Timesteps: 870,834,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,883.22806
Policy Entropy: 1.04972
Value Function Loss: 3.16722

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 11,860.57556
Overall Steps per Second: 10,123.47506

Timestep Collection Time: 4.21683
Timestep Consumption Time: 0.72357
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.94040

Cumulative Model Updates: 52,209
Cumulative Timesteps: 870,884,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 870884718...
Checkpoint 870884718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,909.31694
Policy Entropy: 1.05364
Value Function Loss: 3.24442

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 12,088.13301
Overall Steps per Second: 10,388.41420

Timestep Collection Time: 4.13745
Timestep Consumption Time: 0.67696
PPO Batch Consumption Time: 0.03782
Total Iteration Time: 4.81440

Cumulative Model Updates: 52,212
Cumulative Timesteps: 870,934,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,996.42856
Policy Entropy: 1.02502
Value Function Loss: 3.35409

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 11,462.91413
Overall Steps per Second: 9,678.28930

Timestep Collection Time: 4.36242
Timestep Consumption Time: 0.80441
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.16682

Cumulative Model Updates: 52,215
Cumulative Timesteps: 870,984,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 870984738...
Checkpoint 870984738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,985.06996
Policy Entropy: 1.04033
Value Function Loss: 3.37982

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 12,373.13927
Overall Steps per Second: 10,508.30121

Timestep Collection Time: 4.04279
Timestep Consumption Time: 0.71745
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.76024

Cumulative Model Updates: 52,218
Cumulative Timesteps: 871,034,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,211.59962
Policy Entropy: 1.04040
Value Function Loss: 3.27317

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 12,104.21856
Overall Steps per Second: 10,181.20862

Timestep Collection Time: 4.13162
Timestep Consumption Time: 0.78037
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.91199

Cumulative Model Updates: 52,221
Cumulative Timesteps: 871,084,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 871084770...
Checkpoint 871084770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,496.63065
Policy Entropy: 1.04101
Value Function Loss: 3.25255

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.10539

Collected Steps per Second: 11,916.93530
Overall Steps per Second: 9,946.90007

Timestep Collection Time: 4.19621
Timestep Consumption Time: 0.83108
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 5.02729

Cumulative Model Updates: 52,224
Cumulative Timesteps: 871,134,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,635.80316
Policy Entropy: 1.03875
Value Function Loss: 3.37564

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.09596

Collected Steps per Second: 12,273.77256
Overall Steps per Second: 10,542.29946

Timestep Collection Time: 4.07503
Timestep Consumption Time: 0.66929
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.74432

Cumulative Model Updates: 52,227
Cumulative Timesteps: 871,184,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 871184792...
Checkpoint 871184792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,813.64372
Policy Entropy: 1.03119
Value Function Loss: 3.24968

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.18157
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.10068

Collected Steps per Second: 12,193.88838
Overall Steps per Second: 10,311.58770

Timestep Collection Time: 4.10271
Timestep Consumption Time: 0.74892
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.85163

Cumulative Model Updates: 52,230
Cumulative Timesteps: 871,234,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,607.25779
Policy Entropy: 1.04431
Value Function Loss: 3.39012

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.15334
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.09905

Collected Steps per Second: 11,803.21129
Overall Steps per Second: 10,040.35249

Timestep Collection Time: 4.23800
Timestep Consumption Time: 0.74410
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 4.98210

Cumulative Model Updates: 52,233
Cumulative Timesteps: 871,284,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871284842...
Checkpoint 871284842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,750.95600
Policy Entropy: 1.04579
Value Function Loss: 3.40583

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.16510
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 12,594.65153
Overall Steps per Second: 10,635.23608

Timestep Collection Time: 3.97232
Timestep Consumption Time: 0.73185
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.70417

Cumulative Model Updates: 52,236
Cumulative Timesteps: 871,334,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,423.38682
Policy Entropy: 1.03489
Value Function Loss: 3.54584

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 12,633.64049
Overall Steps per Second: 10,714.04957

Timestep Collection Time: 3.95943
Timestep Consumption Time: 0.70939
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.66882

Cumulative Model Updates: 52,239
Cumulative Timesteps: 871,384,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871384894...
Checkpoint 871384894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,740.96169
Policy Entropy: 1.02261
Value Function Loss: 3.36337

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.19469
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 12,371.58120
Overall Steps per Second: 10,639.07175

Timestep Collection Time: 4.04184
Timestep Consumption Time: 0.65819
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.70003

Cumulative Model Updates: 52,242
Cumulative Timesteps: 871,434,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,234.94671
Policy Entropy: 1.03047
Value Function Loss: 3.29469

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 12,142.32259
Overall Steps per Second: 10,269.33313

Timestep Collection Time: 4.11865
Timestep Consumption Time: 0.75119
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.86984

Cumulative Model Updates: 52,245
Cumulative Timesteps: 871,484,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 871484908...
Checkpoint 871484908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,844.56119
Policy Entropy: 1.04581
Value Function Loss: 3.24297

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 12,442.83900
Overall Steps per Second: 10,497.38067

Timestep Collection Time: 4.01998
Timestep Consumption Time: 0.74502
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 4.76500

Cumulative Model Updates: 52,248
Cumulative Timesteps: 871,534,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,974.92495
Policy Entropy: 1.02126
Value Function Loss: 3.18030

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07900

Collected Steps per Second: 11,502.98698
Overall Steps per Second: 9,969.57351

Timestep Collection Time: 4.34878
Timestep Consumption Time: 0.66888
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.01767

Cumulative Model Updates: 52,251
Cumulative Timesteps: 871,584,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 871584952...
Checkpoint 871584952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,316.89916
Policy Entropy: 1.03710
Value Function Loss: 3.21218

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.16090
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.09044

Collected Steps per Second: 11,767.43565
Overall Steps per Second: 10,025.13663

Timestep Collection Time: 4.24901
Timestep Consumption Time: 0.73845
PPO Batch Consumption Time: 0.03186
Total Iteration Time: 4.98746

Cumulative Model Updates: 52,254
Cumulative Timesteps: 871,634,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,000.58169
Policy Entropy: 1.02495
Value Function Loss: 3.36625

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.10589

Collected Steps per Second: 12,360.44295
Overall Steps per Second: 10,432.98995

Timestep Collection Time: 4.04581
Timestep Consumption Time: 0.74745
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.79326

Cumulative Model Updates: 52,257
Cumulative Timesteps: 871,684,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 871684960...
Checkpoint 871684960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,675.16654
Policy Entropy: 1.03436
Value Function Loss: 3.51579

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 12,544.89236
Overall Steps per Second: 10,513.18766

Timestep Collection Time: 3.98712
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.75764

Cumulative Model Updates: 52,260
Cumulative Timesteps: 871,734,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,264.65224
Policy Entropy: 1.02891
Value Function Loss: 3.54222

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.11991

Collected Steps per Second: 12,596.02448
Overall Steps per Second: 10,670.53572

Timestep Collection Time: 3.97125
Timestep Consumption Time: 0.71661
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.68786

Cumulative Model Updates: 52,263
Cumulative Timesteps: 871,785,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871785000...
Checkpoint 871785000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,334.66014
Policy Entropy: 1.03856
Value Function Loss: 3.36055

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.11049

Collected Steps per Second: 12,268.69086
Overall Steps per Second: 10,530.51264

Timestep Collection Time: 4.07590
Timestep Consumption Time: 0.67277
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.74868

Cumulative Model Updates: 52,266
Cumulative Timesteps: 871,835,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,771.71445
Policy Entropy: 1.02873
Value Function Loss: 3.34854

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.17485
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 12,020.99645
Overall Steps per Second: 10,164.64304

Timestep Collection Time: 4.16188
Timestep Consumption Time: 0.76008
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 4.92196

Cumulative Model Updates: 52,269
Cumulative Timesteps: 871,885,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 871885036...
Checkpoint 871885036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,744.65865
Policy Entropy: 1.04067
Value Function Loss: 3.28340

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 12,424.43922
Overall Steps per Second: 10,451.21424

Timestep Collection Time: 4.02433
Timestep Consumption Time: 0.75981
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.78413

Cumulative Model Updates: 52,272
Cumulative Timesteps: 871,935,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,869.74440
Policy Entropy: 1.04555
Value Function Loss: 3.30261

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 12,457.29755
Overall Steps per Second: 10,702.06826

Timestep Collection Time: 4.01628
Timestep Consumption Time: 0.65870
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.67498

Cumulative Model Updates: 52,275
Cumulative Timesteps: 871,985,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 871985068...
Checkpoint 871985068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,367.10846
Policy Entropy: 1.04509
Value Function Loss: 3.25782

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 12,416.00275
Overall Steps per Second: 10,450.69374

Timestep Collection Time: 4.02948
Timestep Consumption Time: 0.75776
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.78724

Cumulative Model Updates: 52,278
Cumulative Timesteps: 872,035,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,468.84884
Policy Entropy: 1.04293
Value Function Loss: 3.38920

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.09473

Collected Steps per Second: 12,221.14690
Overall Steps per Second: 10,382.64482

Timestep Collection Time: 4.09274
Timestep Consumption Time: 0.72472
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.81746

Cumulative Model Updates: 52,281
Cumulative Timesteps: 872,085,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 872085116...
Checkpoint 872085116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,706.95134
Policy Entropy: 1.03273
Value Function Loss: 3.53837

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.08236

Collected Steps per Second: 12,412.82198
Overall Steps per Second: 10,471.01614

Timestep Collection Time: 4.03019
Timestep Consumption Time: 0.74738
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.77757

Cumulative Model Updates: 52,284
Cumulative Timesteps: 872,135,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,181.85640
Policy Entropy: 1.03749
Value Function Loss: 3.53540

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.09733

Collected Steps per Second: 12,059.66319
Overall Steps per Second: 10,122.61080

Timestep Collection Time: 4.14655
Timestep Consumption Time: 0.79348
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.94003

Cumulative Model Updates: 52,287
Cumulative Timesteps: 872,185,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 872185148...
Checkpoint 872185148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,184.44750
Policy Entropy: 1.04629
Value Function Loss: 3.42996

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.09752

Collected Steps per Second: 11,916.87677
Overall Steps per Second: 10,168.60046

Timestep Collection Time: 4.19791
Timestep Consumption Time: 0.72174
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.91965

Cumulative Model Updates: 52,290
Cumulative Timesteps: 872,235,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,154.26321
Policy Entropy: 1.04368
Value Function Loss: 3.28607

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.10567

Collected Steps per Second: 12,350.29069
Overall Steps per Second: 10,407.41784

Timestep Collection Time: 4.04930
Timestep Consumption Time: 0.75593
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 4.80523

Cumulative Model Updates: 52,293
Cumulative Timesteps: 872,285,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 872285184...
Checkpoint 872285184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,390.31564
Policy Entropy: 1.04669
Value Function Loss: 3.17824

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 12,256.49336
Overall Steps per Second: 10,402.47906

Timestep Collection Time: 4.08061
Timestep Consumption Time: 0.72728
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.80789

Cumulative Model Updates: 52,296
Cumulative Timesteps: 872,335,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,525.41697
Policy Entropy: 1.03507
Value Function Loss: 3.30913

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.09658

Collected Steps per Second: 12,524.47180
Overall Steps per Second: 10,464.62036

Timestep Collection Time: 3.99378
Timestep Consumption Time: 0.78613
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.77992

Cumulative Model Updates: 52,299
Cumulative Timesteps: 872,385,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 872385218...
Checkpoint 872385218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,521.22759
Policy Entropy: 1.02900
Value Function Loss: 3.38101

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.09359

Collected Steps per Second: 12,325.21173
Overall Steps per Second: 10,409.74355

Timestep Collection Time: 4.05851
Timestep Consumption Time: 0.74680
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.80531

Cumulative Model Updates: 52,302
Cumulative Timesteps: 872,435,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,809.28204
Policy Entropy: 1.04410
Value Function Loss: 3.52948

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.16136
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.09483

Collected Steps per Second: 12,496.05828
Overall Steps per Second: 10,641.45552

Timestep Collection Time: 4.00174
Timestep Consumption Time: 0.69743
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 4.69917

Cumulative Model Updates: 52,305
Cumulative Timesteps: 872,485,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 872485246...
Checkpoint 872485246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,491.96425
Policy Entropy: 1.06020
Value Function Loss: 3.44006

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.08933

Collected Steps per Second: 12,171.50109
Overall Steps per Second: 10,219.87549

Timestep Collection Time: 4.10845
Timestep Consumption Time: 0.78456
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.89301

Cumulative Model Updates: 52,308
Cumulative Timesteps: 872,535,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,634.20546
Policy Entropy: 1.03250
Value Function Loss: 3.40825

Mean KL Divergence: 0.02888
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 12,328.24945
Overall Steps per Second: 10,426.14535

Timestep Collection Time: 4.05767
Timestep Consumption Time: 0.74027
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 4.79794

Cumulative Model Updates: 52,311
Cumulative Timesteps: 872,585,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 872585276...
Checkpoint 872585276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,223.88263
Policy Entropy: 1.04400
Value Function Loss: 3.18087

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.16828
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.09374

Collected Steps per Second: 13,181.46823
Overall Steps per Second: 11,002.64748

Timestep Collection Time: 3.79563
Timestep Consumption Time: 0.75164
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.54727

Cumulative Model Updates: 52,314
Cumulative Timesteps: 872,635,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,174.77540
Policy Entropy: 1.04779
Value Function Loss: 3.20306

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.16697
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09483

Collected Steps per Second: 13,119.07126
Overall Steps per Second: 10,878.92255

Timestep Collection Time: 3.81277
Timestep Consumption Time: 0.78511
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 4.59788

Cumulative Model Updates: 52,317
Cumulative Timesteps: 872,685,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 872685328...
Checkpoint 872685328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650,754.47256
Policy Entropy: 1.06077
Value Function Loss: 3.19389

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.15087
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 12,934.50988
Overall Steps per Second: 11,059.38700

Timestep Collection Time: 3.86733
Timestep Consumption Time: 0.65571
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.52304

Cumulative Model Updates: 52,320
Cumulative Timesteps: 872,735,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,946.98919
Policy Entropy: 1.04619
Value Function Loss: 3.37712

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.15617
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.09621

Collected Steps per Second: 13,386.07952
Overall Steps per Second: 11,169.18034

Timestep Collection Time: 3.73537
Timestep Consumption Time: 0.74141
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.47678

Cumulative Model Updates: 52,323
Cumulative Timesteps: 872,785,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872785352...
Checkpoint 872785352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,896.82967
Policy Entropy: 1.03860
Value Function Loss: 3.33031

Mean KL Divergence: 0.03002
SB3 Clip Fraction: 0.18737
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 12,027.98691
Overall Steps per Second: 10,180.75296

Timestep Collection Time: 4.15697
Timestep Consumption Time: 0.75426
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 4.91123

Cumulative Model Updates: 52,326
Cumulative Timesteps: 872,835,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,399.88993
Policy Entropy: 1.04808
Value Function Loss: 3.40348

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.08705

Collected Steps per Second: 13,196.93266
Overall Steps per Second: 10,984.87482

Timestep Collection Time: 3.78937
Timestep Consumption Time: 0.76308
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.55244

Cumulative Model Updates: 52,329
Cumulative Timesteps: 872,885,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 872885360...
Checkpoint 872885360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,199.16498
Policy Entropy: 1.05954
Value Function Loss: 3.37076

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.08172

Collected Steps per Second: 12,777.60920
Overall Steps per Second: 10,621.27582

Timestep Collection Time: 3.91372
Timestep Consumption Time: 0.79456
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.70829

Cumulative Model Updates: 52,332
Cumulative Timesteps: 872,935,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,937.95007
Policy Entropy: 1.04443
Value Function Loss: 3.35562

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.08816

Collected Steps per Second: 12,439.77686
Overall Steps per Second: 10,614.79280

Timestep Collection Time: 4.02001
Timestep Consumption Time: 0.69115
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.71116

Cumulative Model Updates: 52,335
Cumulative Timesteps: 872,985,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 872985376...
Checkpoint 872985376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,672.55043
Policy Entropy: 1.03219
Value Function Loss: 3.26530

Mean KL Divergence: 0.02882
SB3 Clip Fraction: 0.18591
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 12,270.79270
Overall Steps per Second: 10,286.00308

Timestep Collection Time: 4.07586
Timestep Consumption Time: 0.78648
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 4.86234

Cumulative Model Updates: 52,338
Cumulative Timesteps: 873,035,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,443.37299
Policy Entropy: 1.04718
Value Function Loss: 3.28258

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.08776

Collected Steps per Second: 12,041.40396
Overall Steps per Second: 10,220.89900

Timestep Collection Time: 4.15300
Timestep Consumption Time: 0.73972
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 4.89272

Cumulative Model Updates: 52,341
Cumulative Timesteps: 873,085,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873085398...
Checkpoint 873085398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,520.30815
Policy Entropy: 1.05045
Value Function Loss: 3.21922

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.08502

Collected Steps per Second: 11,652.47843
Overall Steps per Second: 10,056.35229

Timestep Collection Time: 4.29213
Timestep Consumption Time: 0.68124
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 4.97337

Cumulative Model Updates: 52,344
Cumulative Timesteps: 873,135,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,123.84784
Policy Entropy: 1.04962
Value Function Loss: 3.23540

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 12,101.67360
Overall Steps per Second: 10,114.72262

Timestep Collection Time: 4.13381
Timestep Consumption Time: 0.81205
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 4.94586

Cumulative Model Updates: 52,347
Cumulative Timesteps: 873,185,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 873185438...
Checkpoint 873185438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,322.85058
Policy Entropy: 1.02942
Value Function Loss: 3.12757

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.15992
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 12,291.14085
Overall Steps per Second: 10,412.36574

Timestep Collection Time: 4.06944
Timestep Consumption Time: 0.73428
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.80371

Cumulative Model Updates: 52,350
Cumulative Timesteps: 873,235,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,640.78681
Policy Entropy: 1.05238
Value Function Loss: 3.27552

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11106

Collected Steps per Second: 12,523.07985
Overall Steps per Second: 10,523.27764

Timestep Collection Time: 3.99391
Timestep Consumption Time: 0.75899
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.75289

Cumulative Model Updates: 52,353
Cumulative Timesteps: 873,285,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 873285472...
Checkpoint 873285472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,265.24119
Policy Entropy: 1.04245
Value Function Loss: 3.32983

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 12,026.48279
Overall Steps per Second: 10,120.47690

Timestep Collection Time: 4.15799
Timestep Consumption Time: 0.78308
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.94107

Cumulative Model Updates: 52,356
Cumulative Timesteps: 873,335,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,367.76628
Policy Entropy: 1.03069
Value Function Loss: 3.37692

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.10359

Collected Steps per Second: 12,245.49065
Overall Steps per Second: 10,467.22881

Timestep Collection Time: 4.08379
Timestep Consumption Time: 0.69379
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.77758

Cumulative Model Updates: 52,359
Cumulative Timesteps: 873,385,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873385486...
Checkpoint 873385486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,383.43030
Policy Entropy: 1.02526
Value Function Loss: 3.35612

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.19241
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.09601

Collected Steps per Second: 12,153.58562
Overall Steps per Second: 10,227.10966

Timestep Collection Time: 4.11418
Timestep Consumption Time: 0.77499
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.88916

Cumulative Model Updates: 52,362
Cumulative Timesteps: 873,435,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,412.07428
Policy Entropy: 1.03654
Value Function Loss: 3.50384

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.08571

Collected Steps per Second: 12,276.79248
Overall Steps per Second: 10,384.79899

Timestep Collection Time: 4.07403
Timestep Consumption Time: 0.74224
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.81627

Cumulative Model Updates: 52,365
Cumulative Timesteps: 873,485,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 873485504...
Checkpoint 873485504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,491.42051
Policy Entropy: 1.04970
Value Function Loss: 3.62021

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.16985
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 12,258.60645
Overall Steps per Second: 10,491.90359

Timestep Collection Time: 4.07991
Timestep Consumption Time: 0.68700
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.76691

Cumulative Model Updates: 52,368
Cumulative Timesteps: 873,535,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,499.88289
Policy Entropy: 1.02982
Value Function Loss: 3.53653

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.09625

Collected Steps per Second: 12,071.39639
Overall Steps per Second: 10,162.82013

Timestep Collection Time: 4.14269
Timestep Consumption Time: 0.77800
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.92068

Cumulative Model Updates: 52,371
Cumulative Timesteps: 873,585,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873585526...
Checkpoint 873585526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,138.19056
Policy Entropy: 1.02995
Value Function Loss: 3.36340

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 11,578.09982
Overall Steps per Second: 9,852.69556

Timestep Collection Time: 4.31971
Timestep Consumption Time: 0.75647
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.07617

Cumulative Model Updates: 52,374
Cumulative Timesteps: 873,635,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,379.22253
Policy Entropy: 1.04187
Value Function Loss: 3.24255

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 12,396.23562
Overall Steps per Second: 10,412.17456

Timestep Collection Time: 4.03493
Timestep Consumption Time: 0.76886
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.80380

Cumulative Model Updates: 52,377
Cumulative Timesteps: 873,685,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 873685558...
Checkpoint 873685558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,277.95128
Policy Entropy: 1.04796
Value Function Loss: 3.22487

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 12,290.88869
Overall Steps per Second: 10,259.70940

Timestep Collection Time: 4.07033
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.87616

Cumulative Model Updates: 52,380
Cumulative Timesteps: 873,735,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,534.07393
Policy Entropy: 1.03928
Value Function Loss: 3.35400

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.06875
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 11,868.31683
Overall Steps per Second: 10,182.61207

Timestep Collection Time: 4.21391
Timestep Consumption Time: 0.69760
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 4.91151

Cumulative Model Updates: 52,383
Cumulative Timesteps: 873,785,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 873785598...
Checkpoint 873785598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,016.60776
Policy Entropy: 1.03884
Value Function Loss: 3.32634

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16134
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 12,127.00389
Overall Steps per Second: 10,181.85345

Timestep Collection Time: 4.12435
Timestep Consumption Time: 0.78792
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 4.91227

Cumulative Model Updates: 52,386
Cumulative Timesteps: 873,835,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,161.48653
Policy Entropy: 1.03462
Value Function Loss: 3.33281

Mean KL Divergence: 0.02888
SB3 Clip Fraction: 0.19259
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.11494

Collected Steps per Second: 12,196.45794
Overall Steps per Second: 10,384.16812

Timestep Collection Time: 4.10037
Timestep Consumption Time: 0.71561
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.81599

Cumulative Model Updates: 52,389
Cumulative Timesteps: 873,885,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 873885624...
Checkpoint 873885624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,321.55178
Policy Entropy: 1.05376
Value Function Loss: 3.29250

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.10549

Collected Steps per Second: 12,671.36337
Overall Steps per Second: 10,567.70057

Timestep Collection Time: 3.94717
Timestep Consumption Time: 0.78574
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 4.73291

Cumulative Model Updates: 52,392
Cumulative Timesteps: 873,935,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,120.45081
Policy Entropy: 1.06333
Value Function Loss: 3.33645

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 12,173.27827
Overall Steps per Second: 10,263.44322

Timestep Collection Time: 4.10801
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 4.87244

Cumulative Model Updates: 52,395
Cumulative Timesteps: 873,985,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873985648...
Checkpoint 873985648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,193.27650
Policy Entropy: 1.03978
Value Function Loss: 3.25795

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 11,857.14684
Overall Steps per Second: 10,253.57236

Timestep Collection Time: 4.21855
Timestep Consumption Time: 0.65975
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.87830

Cumulative Model Updates: 52,398
Cumulative Timesteps: 874,035,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,368.12388
Policy Entropy: 1.03511
Value Function Loss: 3.21332

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.09070

Collected Steps per Second: 11,979.32926
Overall Steps per Second: 10,063.29568

Timestep Collection Time: 4.17419
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.96895

Cumulative Model Updates: 52,401
Cumulative Timesteps: 874,085,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 874085672...
Checkpoint 874085672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,562.37004
Policy Entropy: 1.03680
Value Function Loss: 3.31803

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.10057

Collected Steps per Second: 12,461.78894
Overall Steps per Second: 10,495.27005

Timestep Collection Time: 4.01451
Timestep Consumption Time: 0.75221
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.76672

Cumulative Model Updates: 52,404
Cumulative Timesteps: 874,135,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,050.41594
Policy Entropy: 1.04436
Value Function Loss: 3.40975

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.18191
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.09671

Collected Steps per Second: 12,526.08025
Overall Steps per Second: 10,394.11911

Timestep Collection Time: 3.99407
Timestep Consumption Time: 0.81923
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.81330

Cumulative Model Updates: 52,407
Cumulative Timesteps: 874,185,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 874185730...
Checkpoint 874185730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,470.03098
Policy Entropy: 1.01868
Value Function Loss: 3.27323

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 12,249.30841
Overall Steps per Second: 10,320.51090

Timestep Collection Time: 4.08186
Timestep Consumption Time: 0.76286
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 4.84472

Cumulative Model Updates: 52,410
Cumulative Timesteps: 874,235,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,508.69144
Policy Entropy: 1.02946
Value Function Loss: 3.10394

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.16503
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.09763

Collected Steps per Second: 12,419.90247
Overall Steps per Second: 10,627.33445

Timestep Collection Time: 4.02676
Timestep Consumption Time: 0.67922
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.70598

Cumulative Model Updates: 52,413
Cumulative Timesteps: 874,285,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 874285742...
Checkpoint 874285742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,750.82752
Policy Entropy: 1.03711
Value Function Loss: 3.02415

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.15658
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.10352

Collected Steps per Second: 12,069.04655
Overall Steps per Second: 10,202.46944

Timestep Collection Time: 4.14498
Timestep Consumption Time: 0.75834
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.90332

Cumulative Model Updates: 52,416
Cumulative Timesteps: 874,335,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,230.27710
Policy Entropy: 1.02674
Value Function Loss: 3.15949

Mean KL Divergence: 0.03334
SB3 Clip Fraction: 0.16824
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 11,693.54358
Overall Steps per Second: 9,975.31941

Timestep Collection Time: 4.27672
Timestep Consumption Time: 0.73665
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.01337

Cumulative Model Updates: 52,419
Cumulative Timesteps: 874,385,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 874385778...
Checkpoint 874385778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,070.91691
Policy Entropy: 1.03520
Value Function Loss: 3.15558

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.18134
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08226

Collected Steps per Second: 12,341.81833
Overall Steps per Second: 10,390.00773

Timestep Collection Time: 4.05256
Timestep Consumption Time: 0.76129
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.81386

Cumulative Model Updates: 52,422
Cumulative Timesteps: 874,435,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,395.82289
Policy Entropy: 1.04342
Value Function Loss: 3.21043

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.08398

Collected Steps per Second: 12,442.68498
Overall Steps per Second: 10,475.61680

Timestep Collection Time: 4.01891
Timestep Consumption Time: 0.75465
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.77356

Cumulative Model Updates: 52,425
Cumulative Timesteps: 874,485,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874485800...
Checkpoint 874485800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,254.69472
Policy Entropy: 1.04651
Value Function Loss: 3.13622

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.16698
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.08466

Collected Steps per Second: 11,990.76221
Overall Steps per Second: 10,359.85785

Timestep Collection Time: 4.17004
Timestep Consumption Time: 0.65647
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.82651

Cumulative Model Updates: 52,428
Cumulative Timesteps: 874,535,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,287.77753
Policy Entropy: 1.02771
Value Function Loss: 3.12057

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.16613
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.08091

Collected Steps per Second: 12,168.91690
Overall Steps per Second: 10,262.33659

Timestep Collection Time: 4.11097
Timestep Consumption Time: 0.76375
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.87472

Cumulative Model Updates: 52,431
Cumulative Timesteps: 874,585,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 874585828...
Checkpoint 874585828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,594.20070
Policy Entropy: 1.05057
Value Function Loss: 3.09004

Mean KL Divergence: 0.03294
SB3 Clip Fraction: 0.20385
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 12,127.86084
Overall Steps per Second: 10,270.55497

Timestep Collection Time: 4.12274
Timestep Consumption Time: 0.74555
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.86829

Cumulative Model Updates: 52,434
Cumulative Timesteps: 874,635,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,292.24200
Policy Entropy: 1.04633
Value Function Loss: 3.25859

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.17865
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 11,732.28023
Overall Steps per Second: 10,134.59502

Timestep Collection Time: 4.26311
Timestep Consumption Time: 0.67207
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.93517

Cumulative Model Updates: 52,437
Cumulative Timesteps: 874,685,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874685844...
Checkpoint 874685844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,701.81622
Policy Entropy: 1.03663
Value Function Loss: 3.40914

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.09584

Collected Steps per Second: 12,466.53613
Overall Steps per Second: 10,502.34531

Timestep Collection Time: 4.01138
Timestep Consumption Time: 0.75022
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.76160

Cumulative Model Updates: 52,440
Cumulative Timesteps: 874,735,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,768.03634
Policy Entropy: 1.01451
Value Function Loss: 3.49192

Mean KL Divergence: 0.03975
SB3 Clip Fraction: 0.21643
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 12,357.28248
Overall Steps per Second: 10,563.14517

Timestep Collection Time: 4.04668
Timestep Consumption Time: 0.68732
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.73401

Cumulative Model Updates: 52,443
Cumulative Timesteps: 874,785,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874785858...
Checkpoint 874785858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,281.91651
Policy Entropy: 1.04982
Value Function Loss: 3.30771

Mean KL Divergence: 0.03036
SB3 Clip Fraction: 0.19239
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 12,205.40047
Overall Steps per Second: 10,296.34774

Timestep Collection Time: 4.09901
Timestep Consumption Time: 0.76000
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.85900

Cumulative Model Updates: 52,446
Cumulative Timesteps: 874,835,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,464.47305
Policy Entropy: 1.02495
Value Function Loss: 3.39468

Mean KL Divergence: 0.03390
SB3 Clip Fraction: 0.18104
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 12,166.27232
Overall Steps per Second: 10,296.61066

Timestep Collection Time: 4.11038
Timestep Consumption Time: 0.74636
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.85674

Cumulative Model Updates: 52,449
Cumulative Timesteps: 874,885,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 874885896...
Checkpoint 874885896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,937.58798
Policy Entropy: 1.05045
Value Function Loss: 3.54904

Mean KL Divergence: 0.03010
SB3 Clip Fraction: 0.17491
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.08710

Collected Steps per Second: 12,127.58975
Overall Steps per Second: 10,401.18157

Timestep Collection Time: 4.12464
Timestep Consumption Time: 0.68462
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.80926

Cumulative Model Updates: 52,452
Cumulative Timesteps: 874,935,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,277.24694
Policy Entropy: 1.05377
Value Function Loss: 3.65786

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.09030

Collected Steps per Second: 11,300.83010
Overall Steps per Second: 9,569.25699

Timestep Collection Time: 4.42640
Timestep Consumption Time: 0.80096
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.22737

Cumulative Model Updates: 52,455
Cumulative Timesteps: 874,985,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 874985940...
Checkpoint 874985940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,349.99758
Policy Entropy: 1.03787
Value Function Loss: 3.52870

Mean KL Divergence: 0.03009
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 11,799.48044
Overall Steps per Second: 10,047.79219

Timestep Collection Time: 4.23968
Timestep Consumption Time: 0.73913
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.97881

Cumulative Model Updates: 52,458
Cumulative Timesteps: 875,035,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,936.20787
Policy Entropy: 1.03327
Value Function Loss: 3.42574

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.08651

Collected Steps per Second: 12,404.05771
Overall Steps per Second: 10,442.86695

Timestep Collection Time: 4.03094
Timestep Consumption Time: 0.75702
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 4.78796

Cumulative Model Updates: 52,461
Cumulative Timesteps: 875,085,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875085966...
Checkpoint 875085966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,290.63879
Policy Entropy: 1.04876
Value Function Loss: 3.61324

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.08819

Collected Steps per Second: 12,921.71654
Overall Steps per Second: 10,856.19517

Timestep Collection Time: 3.87193
Timestep Consumption Time: 0.73668
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.60861

Cumulative Model Updates: 52,464
Cumulative Timesteps: 875,135,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,067.36199
Policy Entropy: 1.05511
Value Function Loss: 3.68588

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 12,647.30881
Overall Steps per Second: 10,773.55476

Timestep Collection Time: 3.95373
Timestep Consumption Time: 0.68764
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.64137

Cumulative Model Updates: 52,467
Cumulative Timesteps: 875,186,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 875186002...
Checkpoint 875186002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,131.38072
Policy Entropy: 1.03944
Value Function Loss: 3.72648

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 12,776.80664
Overall Steps per Second: 10,634.58912

Timestep Collection Time: 3.91334
Timestep Consumption Time: 0.78830
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 4.70164

Cumulative Model Updates: 52,470
Cumulative Timesteps: 875,236,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,825.41996
Policy Entropy: 1.03519
Value Function Loss: 3.54121

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.17233
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.09623

Collected Steps per Second: 12,406.17458
Overall Steps per Second: 10,267.07348

Timestep Collection Time: 4.03025
Timestep Consumption Time: 0.83969
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.86994

Cumulative Model Updates: 52,473
Cumulative Timesteps: 875,286,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875286002...
Checkpoint 875286002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,308.73642
Policy Entropy: 1.04987
Value Function Loss: 3.50707

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 12,623.32282
Overall Steps per Second: 10,768.27996

Timestep Collection Time: 3.96251
Timestep Consumption Time: 0.68262
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.64512

Cumulative Model Updates: 52,476
Cumulative Timesteps: 875,336,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703,474.54154
Policy Entropy: 1.05499
Value Function Loss: 3.41950

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.16784
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 12,777.39032
Overall Steps per Second: 10,726.41389

Timestep Collection Time: 3.91473
Timestep Consumption Time: 0.74853
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.66325

Cumulative Model Updates: 52,479
Cumulative Timesteps: 875,386,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 875386042...
Checkpoint 875386042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,454.99584
Policy Entropy: 1.03181
Value Function Loss: 3.41895

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.09545

Collected Steps per Second: 12,269.75621
Overall Steps per Second: 10,499.75941

Timestep Collection Time: 4.07571
Timestep Consumption Time: 0.68706
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.76278

Cumulative Model Updates: 52,482
Cumulative Timesteps: 875,436,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727,384.43382
Policy Entropy: 1.02874
Value Function Loss: 3.29764

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.08742

Collected Steps per Second: 11,995.28882
Overall Steps per Second: 10,145.05600

Timestep Collection Time: 4.16864
Timestep Consumption Time: 0.76027
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.92890

Cumulative Model Updates: 52,485
Cumulative Timesteps: 875,486,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 875486054...
Checkpoint 875486054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,550.66511
Policy Entropy: 1.03689
Value Function Loss: 3.12754

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.08655

Collected Steps per Second: 12,000.48198
Overall Steps per Second: 10,208.96516

Timestep Collection Time: 4.16783
Timestep Consumption Time: 0.73139
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.89922

Cumulative Model Updates: 52,488
Cumulative Timesteps: 875,536,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,587.86402
Policy Entropy: 1.05186
Value Function Loss: 2.98871

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.09452

Collected Steps per Second: 12,073.10427
Overall Steps per Second: 10,365.78436

Timestep Collection Time: 4.14276
Timestep Consumption Time: 0.68234
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.82511

Cumulative Model Updates: 52,491
Cumulative Timesteps: 875,586,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 875586086...
Checkpoint 875586086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,082.24974
Policy Entropy: 1.02946
Value Function Loss: 3.02728

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.06136
Value Function Update Magnitude: 0.11006

Collected Steps per Second: 11,361.98191
Overall Steps per Second: 9,624.05469

Timestep Collection Time: 4.40134
Timestep Consumption Time: 0.79480
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.19615

Cumulative Model Updates: 52,494
Cumulative Timesteps: 875,636,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,763.07321
Policy Entropy: 1.04397
Value Function Loss: 3.12281

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 12,110.46862
Overall Steps per Second: 10,322.69067

Timestep Collection Time: 4.13048
Timestep Consumption Time: 0.71535
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.84583

Cumulative Model Updates: 52,497
Cumulative Timesteps: 875,686,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 875686116...
Checkpoint 875686116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,874.44582
Policy Entropy: 1.04941
Value Function Loss: 3.23463

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.09346

Collected Steps per Second: 12,306.27275
Overall Steps per Second: 10,338.22613

Timestep Collection Time: 4.06541
Timestep Consumption Time: 0.77392
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.83932

Cumulative Model Updates: 52,500
Cumulative Timesteps: 875,736,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,126.10322
Policy Entropy: 1.05256
Value Function Loss: 3.26974

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.06868
Value Function Update Magnitude: 0.08515

Collected Steps per Second: 12,067.38993
Overall Steps per Second: 10,201.85382

Timestep Collection Time: 4.14406
Timestep Consumption Time: 0.75779
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.90185

Cumulative Model Updates: 52,503
Cumulative Timesteps: 875,786,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 875786154...
Checkpoint 875786154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,812.11678
Policy Entropy: 1.05589
Value Function Loss: 3.29116

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 11,824.73215
Overall Steps per Second: 10,179.79307

Timestep Collection Time: 4.22893
Timestep Consumption Time: 0.68335
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.91228

Cumulative Model Updates: 52,506
Cumulative Timesteps: 875,836,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,362.08458
Policy Entropy: 1.05051
Value Function Loss: 3.35388

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15765
Policy Update Magnitude: 0.06429
Value Function Update Magnitude: 0.09616

Collected Steps per Second: 11,960.92837
Overall Steps per Second: 10,092.78851

Timestep Collection Time: 4.18145
Timestep Consumption Time: 0.77397
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.95542

Cumulative Model Updates: 52,509
Cumulative Timesteps: 875,886,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 875886174...
Checkpoint 875886174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,551.30641
Policy Entropy: 1.06322
Value Function Loss: 3.46015

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.10557

Collected Steps per Second: 11,740.13178
Overall Steps per Second: 10,048.01197

Timestep Collection Time: 4.25958
Timestep Consumption Time: 0.71733
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.97690

Cumulative Model Updates: 52,512
Cumulative Timesteps: 875,936,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,035.13582
Policy Entropy: 1.06715
Value Function Loss: 3.60034

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 12,340.16562
Overall Steps per Second: 10,570.44521

Timestep Collection Time: 4.05343
Timestep Consumption Time: 0.67863
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.73206

Cumulative Model Updates: 52,515
Cumulative Timesteps: 875,986,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 875986202...
Checkpoint 875986202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766,489.14600
Policy Entropy: 1.05635
Value Function Loss: 3.47444

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 11,988.57820
Overall Steps per Second: 10,112.93294

Timestep Collection Time: 4.17164
Timestep Consumption Time: 0.77371
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 4.94535

Cumulative Model Updates: 52,518
Cumulative Timesteps: 876,036,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,325.76186
Policy Entropy: 1.04098
Value Function Loss: 3.40009

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 12,228.00117
Overall Steps per Second: 10,275.32260

Timestep Collection Time: 4.09028
Timestep Consumption Time: 0.77730
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 4.86758

Cumulative Model Updates: 52,521
Cumulative Timesteps: 876,086,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 876086230...
Checkpoint 876086230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,406.00035
Policy Entropy: 1.05879
Value Function Loss: 3.31945

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.09119

Collected Steps per Second: 12,424.81601
Overall Steps per Second: 10,397.81984

Timestep Collection Time: 4.02501
Timestep Consumption Time: 0.78465
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 4.80966

Cumulative Model Updates: 52,524
Cumulative Timesteps: 876,136,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,157.91707
Policy Entropy: 1.06819
Value Function Loss: 3.39295

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 12,397.57030
Overall Steps per Second: 10,366.82814

Timestep Collection Time: 4.03515
Timestep Consumption Time: 0.79044
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 4.82558

Cumulative Model Updates: 52,527
Cumulative Timesteps: 876,186,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876186266...
Checkpoint 876186266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,094.69079
Policy Entropy: 1.05859
Value Function Loss: 3.34323

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.09219

Collected Steps per Second: 11,491.18813
Overall Steps per Second: 9,909.25814

Timestep Collection Time: 4.35168
Timestep Consumption Time: 0.69471
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 5.04639

Cumulative Model Updates: 52,530
Cumulative Timesteps: 876,236,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,263.67934
Policy Entropy: 1.05186
Value Function Loss: 3.39055

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.15785
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 11,821.18173
Overall Steps per Second: 10,013.69748

Timestep Collection Time: 4.23206
Timestep Consumption Time: 0.76389
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.99596

Cumulative Model Updates: 52,533
Cumulative Timesteps: 876,286,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 876286300...
Checkpoint 876286300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,729.10693
Policy Entropy: 1.05707
Value Function Loss: 3.34679

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.08047

Collected Steps per Second: 11,808.18659
Overall Steps per Second: 10,083.19249

Timestep Collection Time: 4.23587
Timestep Consumption Time: 0.72466
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 4.96053

Cumulative Model Updates: 52,536
Cumulative Timesteps: 876,336,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,733.68216
Policy Entropy: 1.07085
Value Function Loss: 3.38145

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.16161
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.07015

Collected Steps per Second: 12,562.51061
Overall Steps per Second: 10,534.00898

Timestep Collection Time: 3.98248
Timestep Consumption Time: 0.76689
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.74938

Cumulative Model Updates: 52,539
Cumulative Timesteps: 876,386,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 876386348...
Checkpoint 876386348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,769.98329
Policy Entropy: 1.03236
Value Function Loss: 3.28878

Mean KL Divergence: 0.05890
SB3 Clip Fraction: 0.20759
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 12,330.85287
Overall Steps per Second: 10,398.08035

Timestep Collection Time: 4.05682
Timestep Consumption Time: 0.75407
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.81089

Cumulative Model Updates: 52,542
Cumulative Timesteps: 876,436,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750,720.08909
Policy Entropy: 1.05985
Value Function Loss: 3.19317

Mean KL Divergence: 0.03069
SB3 Clip Fraction: 0.16827
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 12,059.19695
Overall Steps per Second: 10,347.52082

Timestep Collection Time: 4.14837
Timestep Consumption Time: 0.68622
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.83459

Cumulative Model Updates: 52,545
Cumulative Timesteps: 876,486,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876486398...
Checkpoint 876486398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,843.62399
Policy Entropy: 1.04745
Value Function Loss: 2.98500

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.16690
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.09235

Collected Steps per Second: 11,511.59860
Overall Steps per Second: 9,774.73154

Timestep Collection Time: 4.34345
Timestep Consumption Time: 0.77178
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.11523

Cumulative Model Updates: 52,548
Cumulative Timesteps: 876,536,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,469.57905
Policy Entropy: 1.04563
Value Function Loss: 2.89017

Mean KL Divergence: 0.02972
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 12,196.63790
Overall Steps per Second: 10,245.39336

Timestep Collection Time: 4.09949
Timestep Consumption Time: 0.78075
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.88024

Cumulative Model Updates: 52,551
Cumulative Timesteps: 876,586,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 876586398...
Checkpoint 876586398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,279.05461
Policy Entropy: 1.05953
Value Function Loss: 2.91935

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.15945
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.09857

Collected Steps per Second: 12,231.68382
Overall Steps per Second: 10,475.97899

Timestep Collection Time: 4.08873
Timestep Consumption Time: 0.68524
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.77397

Cumulative Model Updates: 52,554
Cumulative Timesteps: 876,636,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,815.65881
Policy Entropy: 1.05915
Value Function Loss: 3.17540

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.10732

Collected Steps per Second: 12,330.82506
Overall Steps per Second: 10,347.15444

Timestep Collection Time: 4.05520
Timestep Consumption Time: 0.77743
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 4.83263

Cumulative Model Updates: 52,557
Cumulative Timesteps: 876,686,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 876686414...
Checkpoint 876686414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716,967.61748
Policy Entropy: 1.05946
Value Function Loss: 3.28714

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.07980
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 11,914.13400
Overall Steps per Second: 10,072.96444

Timestep Collection Time: 4.19787
Timestep Consumption Time: 0.76730
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 4.96517

Cumulative Model Updates: 52,560
Cumulative Timesteps: 876,736,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,457.50829
Policy Entropy: 1.05584
Value Function Loss: 3.33557

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.07854
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 11,634.69054
Overall Steps per Second: 9,886.84869

Timestep Collection Time: 4.29818
Timestep Consumption Time: 0.75985
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.05803

Cumulative Model Updates: 52,563
Cumulative Timesteps: 876,786,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 876786436...
Checkpoint 876786436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,010.95740
Policy Entropy: 1.04454
Value Function Loss: 3.38281

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.08185
Value Function Update Magnitude: 0.10055

Collected Steps per Second: 11,547.34491
Overall Steps per Second: 9,750.56469

Timestep Collection Time: 4.33173
Timestep Consumption Time: 0.79823
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.12996

Cumulative Model Updates: 52,566
Cumulative Timesteps: 876,836,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,692.40758
Policy Entropy: 1.05426
Value Function Loss: 3.33081

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 12,054.19049
Overall Steps per Second: 10,372.68232

Timestep Collection Time: 4.14876
Timestep Consumption Time: 0.67255
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.82132

Cumulative Model Updates: 52,569
Cumulative Timesteps: 876,886,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 876886466...
Checkpoint 876886466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,302.45289
Policy Entropy: 1.05623
Value Function Loss: 3.34967

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 12,228.68058
Overall Steps per Second: 10,330.82115

Timestep Collection Time: 4.08957
Timestep Consumption Time: 0.75129
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 4.84085

Cumulative Model Updates: 52,572
Cumulative Timesteps: 876,936,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,223.40743
Policy Entropy: 1.06485
Value Function Loss: 3.29045

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.10394

Collected Steps per Second: 11,918.51365
Overall Steps per Second: 10,145.66226

Timestep Collection Time: 4.19566
Timestep Consumption Time: 0.73315
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.92881

Cumulative Model Updates: 52,575
Cumulative Timesteps: 876,986,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 876986482...
Checkpoint 876986482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,699.75637
Policy Entropy: 1.04834
Value Function Loss: 3.52689

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 12,193.42800
Overall Steps per Second: 10,479.29873

Timestep Collection Time: 4.10139
Timestep Consumption Time: 0.67088
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.77227

Cumulative Model Updates: 52,578
Cumulative Timesteps: 877,036,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,420.53641
Policy Entropy: 1.03927
Value Function Loss: 3.61000

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.09009

Collected Steps per Second: 11,827.76735
Overall Steps per Second: 10,046.94246

Timestep Collection Time: 4.22751
Timestep Consumption Time: 0.74933
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.97684

Cumulative Model Updates: 52,581
Cumulative Timesteps: 877,086,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 877086494...
Checkpoint 877086494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,194.17194
Policy Entropy: 1.05749
Value Function Loss: 3.64294

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.08368

Collected Steps per Second: 11,564.41431
Overall Steps per Second: 9,928.04578

Timestep Collection Time: 4.32516
Timestep Consumption Time: 0.71289
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.03805

Cumulative Model Updates: 52,584
Cumulative Timesteps: 877,136,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,205.24051
Policy Entropy: 1.05836
Value Function Loss: 3.45095

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.08433

Collected Steps per Second: 12,484.66196
Overall Steps per Second: 10,482.82792

Timestep Collection Time: 4.00507
Timestep Consumption Time: 0.76482
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.76990

Cumulative Model Updates: 52,587
Cumulative Timesteps: 877,186,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 877186514...
Checkpoint 877186514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,519.05810
Policy Entropy: 1.04230
Value Function Loss: 3.17030

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 12,078.23478
Overall Steps per Second: 10,210.33857

Timestep Collection Time: 4.14183
Timestep Consumption Time: 0.75771
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.89954

Cumulative Model Updates: 52,590
Cumulative Timesteps: 877,236,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520,037.07668
Policy Entropy: 1.04053
Value Function Loss: 2.97896

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 12,019.43904
Overall Steps per Second: 10,303.96406

Timestep Collection Time: 4.16093
Timestep Consumption Time: 0.69274
PPO Batch Consumption Time: 0.03295
Total Iteration Time: 4.85367

Cumulative Model Updates: 52,593
Cumulative Timesteps: 877,286,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 877286552...
Checkpoint 877286552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,244.82410
Policy Entropy: 1.05578
Value Function Loss: 3.04454

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.08606

Collected Steps per Second: 12,182.46233
Overall Steps per Second: 10,293.74239

Timestep Collection Time: 4.10475
Timestep Consumption Time: 0.75315
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.85790

Cumulative Model Updates: 52,596
Cumulative Timesteps: 877,336,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,745.66399
Policy Entropy: 1.06403
Value Function Loss: 3.23692

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.16745
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.08833

Collected Steps per Second: 12,192.34224
Overall Steps per Second: 10,298.12016

Timestep Collection Time: 4.10159
Timestep Consumption Time: 0.75444
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.85603

Cumulative Model Updates: 52,599
Cumulative Timesteps: 877,386,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 877386566...
Checkpoint 877386566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,090.09347
Policy Entropy: 1.04116
Value Function Loss: 3.44886

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 11,661.38428
Overall Steps per Second: 10,021.05821

Timestep Collection Time: 4.28954
Timestep Consumption Time: 0.70215
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.99169

Cumulative Model Updates: 52,602
Cumulative Timesteps: 877,436,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,528.74319
Policy Entropy: 1.04984
Value Function Loss: 3.47284

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 12,019.39453
Overall Steps per Second: 10,138.85393

Timestep Collection Time: 4.16144
Timestep Consumption Time: 0.77186
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.93330

Cumulative Model Updates: 52,605
Cumulative Timesteps: 877,486,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 877486606...
Checkpoint 877486606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,389.93116
Policy Entropy: 1.05057
Value Function Loss: 3.52201

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 12,029.38252
Overall Steps per Second: 10,205.70528

Timestep Collection Time: 4.15782
Timestep Consumption Time: 0.74297
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.90079

Cumulative Model Updates: 52,608
Cumulative Timesteps: 877,536,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,257.07340
Policy Entropy: 1.06095
Value Function Loss: 3.43138

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 13,149.80708
Overall Steps per Second: 10,880.24241

Timestep Collection Time: 3.80355
Timestep Consumption Time: 0.79340
PPO Batch Consumption Time: 0.03358
Total Iteration Time: 4.59696

Cumulative Model Updates: 52,611
Cumulative Timesteps: 877,586,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 877586638...
Checkpoint 877586638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,706.44539
Policy Entropy: 1.04986
Value Function Loss: 3.28155

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.16417
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 12,705.74805
Overall Steps per Second: 10,625.77719

Timestep Collection Time: 3.93554
Timestep Consumption Time: 0.77037
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.70591

Cumulative Model Updates: 52,614
Cumulative Timesteps: 877,636,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,777.64244
Policy Entropy: 1.04812
Value Function Loss: 3.25562

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.17042
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 12,758.76213
Overall Steps per Second: 10,845.14811

Timestep Collection Time: 3.92123
Timestep Consumption Time: 0.69190
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.61312

Cumulative Model Updates: 52,617
Cumulative Timesteps: 877,686,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 877686672...
Checkpoint 877686672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,503.58731
Policy Entropy: 1.05556
Value Function Loss: 3.31529

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.10698

Collected Steps per Second: 12,410.44121
Overall Steps per Second: 10,416.82484

Timestep Collection Time: 4.02967
Timestep Consumption Time: 0.77122
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.80089

Cumulative Model Updates: 52,620
Cumulative Timesteps: 877,736,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,933.62806
Policy Entropy: 1.05978
Value Function Loss: 3.22532

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.10018

Collected Steps per Second: 12,202.04348
Overall Steps per Second: 10,385.24531

Timestep Collection Time: 4.09997
Timestep Consumption Time: 0.71725
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 4.81722

Cumulative Model Updates: 52,623
Cumulative Timesteps: 877,786,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 877786710...
Checkpoint 877786710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741,965.14731
Policy Entropy: 1.04405
Value Function Loss: 3.23142

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.10313

Collected Steps per Second: 13,190.82022
Overall Steps per Second: 11,018.37218

Timestep Collection Time: 3.79158
Timestep Consumption Time: 0.74757
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.53915

Cumulative Model Updates: 52,626
Cumulative Timesteps: 877,836,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,370.44030
Policy Entropy: 1.03980
Value Function Loss: 3.19016

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 12,340.07051
Overall Steps per Second: 10,376.24964

Timestep Collection Time: 4.05249
Timestep Consumption Time: 0.76698
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.81947

Cumulative Model Updates: 52,629
Cumulative Timesteps: 877,886,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 877886732...
Checkpoint 877886732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,821.38814
Policy Entropy: 1.04427
Value Function Loss: 3.19353

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.09614

Collected Steps per Second: 12,118.00063
Overall Steps per Second: 10,341.33885

Timestep Collection Time: 4.12609
Timestep Consumption Time: 0.70887
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.83496

Cumulative Model Updates: 52,632
Cumulative Timesteps: 877,936,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,280.26227
Policy Entropy: 1.05396
Value Function Loss: 3.33509

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.09278

Collected Steps per Second: 12,117.41287
Overall Steps per Second: 10,192.42414

Timestep Collection Time: 4.12745
Timestep Consumption Time: 0.77953
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.90698

Cumulative Model Updates: 52,635
Cumulative Timesteps: 877,986,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 877986746...
Checkpoint 877986746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,110.35360
Policy Entropy: 1.03488
Value Function Loss: 3.26251

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.09124

Collected Steps per Second: 12,108.82139
Overall Steps per Second: 10,204.89195

Timestep Collection Time: 4.13153
Timestep Consumption Time: 0.77082
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.90235

Cumulative Model Updates: 52,638
Cumulative Timesteps: 878,036,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,164.30233
Policy Entropy: 1.03209
Value Function Loss: 3.32659

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.08417

Collected Steps per Second: 11,564.75260
Overall Steps per Second: 9,956.27512

Timestep Collection Time: 4.32469
Timestep Consumption Time: 0.69867
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.02336

Cumulative Model Updates: 52,641
Cumulative Timesteps: 878,086,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 878086788...
Checkpoint 878086788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,711.45796
Policy Entropy: 1.04674
Value Function Loss: 3.11183

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 11,721.27049
Overall Steps per Second: 9,974.67158

Timestep Collection Time: 4.26643
Timestep Consumption Time: 0.74707
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 5.01350

Cumulative Model Updates: 52,644
Cumulative Timesteps: 878,136,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,466.52293
Policy Entropy: 1.05241
Value Function Loss: 3.35733

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.08035

Collected Steps per Second: 12,033.53045
Overall Steps per Second: 10,366.87330

Timestep Collection Time: 4.15589
Timestep Consumption Time: 0.66813
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 4.82402

Cumulative Model Updates: 52,647
Cumulative Timesteps: 878,186,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 878186806...
Checkpoint 878186806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,003.84904
Policy Entropy: 1.03858
Value Function Loss: 3.24323

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 12,011.31065
Overall Steps per Second: 10,152.11142

Timestep Collection Time: 4.16524
Timestep Consumption Time: 0.76280
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.92804

Cumulative Model Updates: 52,650
Cumulative Timesteps: 878,236,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,069.82174
Policy Entropy: 1.02019
Value Function Loss: 3.36865

Mean KL Divergence: 0.03462
SB3 Clip Fraction: 0.20850
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 11,879.14237
Overall Steps per Second: 10,106.97318

Timestep Collection Time: 4.21024
Timestep Consumption Time: 0.73823
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 4.94846

Cumulative Model Updates: 52,653
Cumulative Timesteps: 878,286,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 878286850...
Checkpoint 878286850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,165.42719
Policy Entropy: 1.04324
Value Function Loss: 3.18062

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.08882

Collected Steps per Second: 11,977.98251
Overall Steps per Second: 10,317.19186

Timestep Collection Time: 4.17483
Timestep Consumption Time: 0.67203
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.84686

Cumulative Model Updates: 52,656
Cumulative Timesteps: 878,336,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,871.26563
Policy Entropy: 1.03123
Value Function Loss: 3.27550

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.09511

Collected Steps per Second: 11,606.92959
Overall Steps per Second: 9,832.21148

Timestep Collection Time: 4.31001
Timestep Consumption Time: 0.77796
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.08797

Cumulative Model Updates: 52,659
Cumulative Timesteps: 878,386,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878386882...
Checkpoint 878386882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,115.82779
Policy Entropy: 1.02372
Value Function Loss: 3.21635

Mean KL Divergence: 0.03488
SB3 Clip Fraction: 0.20347
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 11,915.87796
Overall Steps per Second: 10,140.54893

Timestep Collection Time: 4.19642
Timestep Consumption Time: 0.73468
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.93109

Cumulative Model Updates: 52,662
Cumulative Timesteps: 878,436,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,257.08603
Policy Entropy: 1.03680
Value Function Loss: 3.17988

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.09034

Collected Steps per Second: 12,397.50027
Overall Steps per Second: 10,422.07074

Timestep Collection Time: 4.03452
Timestep Consumption Time: 0.76472
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.79924

Cumulative Model Updates: 52,665
Cumulative Timesteps: 878,486,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 878486904...
Checkpoint 878486904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765,425.75926
Policy Entropy: 1.04239
Value Function Loss: 3.24695

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.08722

Collected Steps per Second: 11,972.22599
Overall Steps per Second: 10,104.34917

Timestep Collection Time: 4.17667
Timestep Consumption Time: 0.77209
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 4.94876

Cumulative Model Updates: 52,668
Cumulative Timesteps: 878,536,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,313.32267
Policy Entropy: 1.03281
Value Function Loss: 3.28816

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.09426

Collected Steps per Second: 11,969.83525
Overall Steps per Second: 10,278.23038

Timestep Collection Time: 4.17884
Timestep Consumption Time: 0.68776
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.86660

Cumulative Model Updates: 52,671
Cumulative Timesteps: 878,586,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 878586928...
Checkpoint 878586928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,132.08156
Policy Entropy: 1.03132
Value Function Loss: 3.32728

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.10733

Collected Steps per Second: 12,277.78967
Overall Steps per Second: 10,328.36294

Timestep Collection Time: 4.07419
Timestep Consumption Time: 0.76898
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.84317

Cumulative Model Updates: 52,674
Cumulative Timesteps: 878,636,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,711.84361
Policy Entropy: 1.03976
Value Function Loss: 3.13728

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 11,614.77207
Overall Steps per Second: 9,830.62094

Timestep Collection Time: 4.30745
Timestep Consumption Time: 0.78175
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.08920

Cumulative Model Updates: 52,677
Cumulative Timesteps: 878,686,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 878686980...
Checkpoint 878686980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,528.56602
Policy Entropy: 1.04089
Value Function Loss: 3.12807

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 12,013.88098
Overall Steps per Second: 10,366.94473

Timestep Collection Time: 4.16219
Timestep Consumption Time: 0.66122
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.82341

Cumulative Model Updates: 52,680
Cumulative Timesteps: 878,736,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,435.65530
Policy Entropy: 1.04234
Value Function Loss: 3.14995

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 12,312.88205
Overall Steps per Second: 10,393.53520

Timestep Collection Time: 4.06079
Timestep Consumption Time: 0.74990
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.81068

Cumulative Model Updates: 52,683
Cumulative Timesteps: 878,786,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 878786984...
Checkpoint 878786984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,755.27450
Policy Entropy: 1.03851
Value Function Loss: 3.31147

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.07355
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 12,366.22856
Overall Steps per Second: 10,452.88594

Timestep Collection Time: 4.04473
Timestep Consumption Time: 0.74036
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.78509

Cumulative Model Updates: 52,686
Cumulative Timesteps: 878,837,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,084.21435
Policy Entropy: 1.04018
Value Function Loss: 3.23915

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.08534

Collected Steps per Second: 12,305.78275
Overall Steps per Second: 10,353.75231

Timestep Collection Time: 4.06313
Timestep Consumption Time: 0.76604
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.82917

Cumulative Model Updates: 52,689
Cumulative Timesteps: 878,887,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 878887002...
Checkpoint 878887002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,067.88165
Policy Entropy: 1.03585
Value Function Loss: 3.19475

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.07590

Collected Steps per Second: 12,001.45267
Overall Steps per Second: 10,182.21640

Timestep Collection Time: 4.16750
Timestep Consumption Time: 0.74460
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.91209

Cumulative Model Updates: 52,692
Cumulative Timesteps: 878,937,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,796.23696
Policy Entropy: 1.05762
Value Function Loss: 3.07452

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.16680
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 11,447.53601
Overall Steps per Second: 9,906.31297

Timestep Collection Time: 4.37037
Timestep Consumption Time: 0.67994
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 5.05031

Cumulative Model Updates: 52,695
Cumulative Timesteps: 878,987,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 878987048...
Checkpoint 878987048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,526.06550
Policy Entropy: 1.06304
Value Function Loss: 3.08543

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.18005
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 12,258.75022
Overall Steps per Second: 10,410.48590

Timestep Collection Time: 4.08002
Timestep Consumption Time: 0.72436
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.80439

Cumulative Model Updates: 52,698
Cumulative Timesteps: 879,037,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,031.60059
Policy Entropy: 1.05264
Value Function Loss: 3.24606

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.16684
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.07538

Collected Steps per Second: 12,270.72231
Overall Steps per Second: 10,342.77649

Timestep Collection Time: 4.07555
Timestep Consumption Time: 0.75970
PPO Batch Consumption Time: 0.03936
Total Iteration Time: 4.83526

Cumulative Model Updates: 52,701
Cumulative Timesteps: 879,087,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 879087074...
Checkpoint 879087074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,183.44945
Policy Entropy: 1.04697
Value Function Loss: 3.41286

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.08990

Collected Steps per Second: 12,318.38714
Overall Steps per Second: 10,330.57382

Timestep Collection Time: 4.06108
Timestep Consumption Time: 0.78144
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 4.84252

Cumulative Model Updates: 52,704
Cumulative Timesteps: 879,137,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,103.95489
Policy Entropy: 1.05603
Value Function Loss: 3.42157

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.10730

Collected Steps per Second: 12,040.57744
Overall Steps per Second: 10,159.87379

Timestep Collection Time: 4.15395
Timestep Consumption Time: 0.76894
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.92290

Cumulative Model Updates: 52,707
Cumulative Timesteps: 879,187,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 879187116...
Checkpoint 879187116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,348.45226
Policy Entropy: 1.05597
Value Function Loss: 3.34743

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.17113
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 12,228.34729
Overall Steps per Second: 10,419.15577

Timestep Collection Time: 4.09099
Timestep Consumption Time: 0.71036
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.80135

Cumulative Model Updates: 52,710
Cumulative Timesteps: 879,237,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,186.58493
Policy Entropy: 1.04020
Value Function Loss: 3.34869

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 11,395.14421
Overall Steps per Second: 9,673.11838

Timestep Collection Time: 4.38924
Timestep Consumption Time: 0.78138
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.17062

Cumulative Model Updates: 52,713
Cumulative Timesteps: 879,287,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 879287158...
Checkpoint 879287158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,545.90848
Policy Entropy: 1.03933
Value Function Loss: 3.36592

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.18087
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 11,892.38907
Overall Steps per Second: 10,055.85914

Timestep Collection Time: 4.20555
Timestep Consumption Time: 0.76807
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.97362

Cumulative Model Updates: 52,716
Cumulative Timesteps: 879,337,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,880.43314
Policy Entropy: 1.05806
Value Function Loss: 3.29722

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.09614

Collected Steps per Second: 12,161.16960
Overall Steps per Second: 10,271.71484

Timestep Collection Time: 4.11358
Timestep Consumption Time: 0.75668
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.87027

Cumulative Model Updates: 52,719
Cumulative Timesteps: 879,387,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 879387198...
Checkpoint 879387198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,545.08209
Policy Entropy: 1.05926
Value Function Loss: 3.21073

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.09045

Collected Steps per Second: 12,121.87238
Overall Steps per Second: 10,232.53332

Timestep Collection Time: 4.12511
Timestep Consumption Time: 0.76166
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 4.88677

Cumulative Model Updates: 52,722
Cumulative Timesteps: 879,437,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769,872.46527
Policy Entropy: 1.04947
Value Function Loss: 3.08876

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.09676

Collected Steps per Second: 11,976.97062
Overall Steps per Second: 10,313.85380

Timestep Collection Time: 4.17668
Timestep Consumption Time: 0.67349
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.85018

Cumulative Model Updates: 52,725
Cumulative Timesteps: 879,487,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879487226...
Checkpoint 879487226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,194.64702
Policy Entropy: 1.03742
Value Function Loss: 3.15050

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.10112

Collected Steps per Second: 12,123.92627
Overall Steps per Second: 10,205.84488

Timestep Collection Time: 4.12474
Timestep Consumption Time: 0.77520
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.89994

Cumulative Model Updates: 52,728
Cumulative Timesteps: 879,537,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,213.23120
Policy Entropy: 1.02542
Value Function Loss: 3.15311

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.16792
Policy Update Magnitude: 0.06592
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 11,451.75559
Overall Steps per Second: 9,690.54337

Timestep Collection Time: 4.36737
Timestep Consumption Time: 0.79375
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.16111

Cumulative Model Updates: 52,731
Cumulative Timesteps: 879,587,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 879587248...
Checkpoint 879587248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,126.94242
Policy Entropy: 1.04473
Value Function Loss: 3.30071

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.10640

Collected Steps per Second: 12,247.95167
Overall Steps per Second: 10,331.13779

Timestep Collection Time: 4.08362
Timestep Consumption Time: 0.75767
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.84129

Cumulative Model Updates: 52,734
Cumulative Timesteps: 879,637,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,878.84085
Policy Entropy: 1.05942
Value Function Loss: 3.24170

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16745
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.10285

Collected Steps per Second: 12,078.12193
Overall Steps per Second: 10,100.75700

Timestep Collection Time: 4.14187
Timestep Consumption Time: 0.81083
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 4.95270

Cumulative Model Updates: 52,737
Cumulative Timesteps: 879,687,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 879687290...
Checkpoint 879687290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,033.38566
Policy Entropy: 1.03740
Value Function Loss: 3.24079

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.09362

Collected Steps per Second: 12,056.96751
Overall Steps per Second: 10,273.52996

Timestep Collection Time: 4.14731
Timestep Consumption Time: 0.71995
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.86727

Cumulative Model Updates: 52,740
Cumulative Timesteps: 879,737,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,571.99661
Policy Entropy: 1.03057
Value Function Loss: 3.03449

Mean KL Divergence: 0.03016
SB3 Clip Fraction: 0.18717
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.08816

Collected Steps per Second: 12,185.52004
Overall Steps per Second: 10,278.96625

Timestep Collection Time: 4.10487
Timestep Consumption Time: 0.76138
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 4.86625

Cumulative Model Updates: 52,743
Cumulative Timesteps: 879,787,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 879787314...
Checkpoint 879787314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,419.07553
Policy Entropy: 1.04941
Value Function Loss: 3.05397

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.07941

Collected Steps per Second: 12,302.38628
Overall Steps per Second: 10,318.94313

Timestep Collection Time: 4.06458
Timestep Consumption Time: 0.78127
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.84585

Cumulative Model Updates: 52,746
Cumulative Timesteps: 879,837,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,821.49579
Policy Entropy: 1.05827
Value Function Loss: 3.04827

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 11,851.36923
Overall Steps per Second: 9,936.92497

Timestep Collection Time: 4.21892
Timestep Consumption Time: 0.81282
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.03174

Cumulative Model Updates: 52,749
Cumulative Timesteps: 879,887,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 879887318...
Checkpoint 879887318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,890.39377
Policy Entropy: 1.03593
Value Function Loss: 3.11741

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 12,092.89561
Overall Steps per Second: 10,228.33399

Timestep Collection Time: 4.13499
Timestep Consumption Time: 0.75378
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.88877

Cumulative Model Updates: 52,752
Cumulative Timesteps: 879,937,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,375.71164
Policy Entropy: 1.04065
Value Function Loss: 3.19721

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 12,166.44402
Overall Steps per Second: 10,448.08831

Timestep Collection Time: 4.11147
Timestep Consumption Time: 0.67620
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.78767

Cumulative Model Updates: 52,755
Cumulative Timesteps: 879,987,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 879987344...
Checkpoint 879987344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,352.60213
Policy Entropy: 1.04875
Value Function Loss: 3.24661

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 13,087.53519
Overall Steps per Second: 10,937.60286

Timestep Collection Time: 3.82242
Timestep Consumption Time: 0.75135
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.57376

Cumulative Model Updates: 52,758
Cumulative Timesteps: 880,037,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,608.92932
Policy Entropy: 1.05741
Value Function Loss: 3.30630

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 12,872.49642
Overall Steps per Second: 10,838.45165

Timestep Collection Time: 3.88503
Timestep Consumption Time: 0.72910
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.61413

Cumulative Model Updates: 52,761
Cumulative Timesteps: 880,087,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 880087380...
Checkpoint 880087380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,463.46292
Policy Entropy: 1.05984
Value Function Loss: 3.26932

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.08755

Collected Steps per Second: 12,795.03745
Overall Steps per Second: 10,590.93980

Timestep Collection Time: 3.90870
Timestep Consumption Time: 0.81345
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.72215

Cumulative Model Updates: 52,764
Cumulative Timesteps: 880,137,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,758.93218
Policy Entropy: 1.05733
Value Function Loss: 3.08308

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 12,089.30343
Overall Steps per Second: 10,135.63372

Timestep Collection Time: 4.13688
Timestep Consumption Time: 0.79739
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 4.93427

Cumulative Model Updates: 52,767
Cumulative Timesteps: 880,187,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 880187404...
Checkpoint 880187404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,708.90212
Policy Entropy: 1.05887
Value Function Loss: 2.92920

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 12,221.14242
Overall Steps per Second: 10,320.11337

Timestep Collection Time: 4.09209
Timestep Consumption Time: 0.75379
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.84588

Cumulative Model Updates: 52,770
Cumulative Timesteps: 880,237,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,606.56755
Policy Entropy: 1.06441
Value Function Loss: 2.93469

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 12,064.95481
Overall Steps per Second: 10,047.58633

Timestep Collection Time: 4.14606
Timestep Consumption Time: 0.83245
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 4.97851

Cumulative Model Updates: 52,773
Cumulative Timesteps: 880,287,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 880287436...
Checkpoint 880287436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,195.76366
Policy Entropy: 1.06587
Value Function Loss: 3.07837

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 11,898.99138
Overall Steps per Second: 10,173.53139

Timestep Collection Time: 4.20321
Timestep Consumption Time: 0.71288
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.91609

Cumulative Model Updates: 52,776
Cumulative Timesteps: 880,337,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,956.84862
Policy Entropy: 1.06484
Value Function Loss: 3.30266

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 11,732.45307
Overall Steps per Second: 9,855.16035

Timestep Collection Time: 4.26356
Timestep Consumption Time: 0.81216
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.07572

Cumulative Model Updates: 52,779
Cumulative Timesteps: 880,387,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 880387472...
Checkpoint 880387472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,176.81868
Policy Entropy: 1.07283
Value Function Loss: 3.37039

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 12,178.19400
Overall Steps per Second: 10,316.93974

Timestep Collection Time: 4.10636
Timestep Consumption Time: 0.74082
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.84717

Cumulative Model Updates: 52,782
Cumulative Timesteps: 880,437,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,144.40114
Policy Entropy: 1.06839
Value Function Loss: 3.29124

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.09212

Collected Steps per Second: 12,217.14327
Overall Steps per Second: 10,467.20378

Timestep Collection Time: 4.09343
Timestep Consumption Time: 0.68435
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.77778

Cumulative Model Updates: 52,785
Cumulative Timesteps: 880,487,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 880487490...
Checkpoint 880487490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,412.92183
Policy Entropy: 1.07206
Value Function Loss: 3.35698

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.09248

Collected Steps per Second: 11,383.01519
Overall Steps per Second: 9,708.71036

Timestep Collection Time: 4.39532
Timestep Consumption Time: 0.75799
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.15331

Cumulative Model Updates: 52,788
Cumulative Timesteps: 880,537,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,011.00136
Policy Entropy: 1.06898
Value Function Loss: 3.35610

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.07237
Value Function Update Magnitude: 0.10619

Collected Steps per Second: 11,942.53506
Overall Steps per Second: 10,097.45830

Timestep Collection Time: 4.18822
Timestep Consumption Time: 0.76530
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.95352

Cumulative Model Updates: 52,791
Cumulative Timesteps: 880,587,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 880587540...
Checkpoint 880587540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,178.75788
Policy Entropy: 1.07222
Value Function Loss: 3.32948

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 12,039.29382
Overall Steps per Second: 10,176.16934

Timestep Collection Time: 4.15373
Timestep Consumption Time: 0.76049
PPO Batch Consumption Time: 0.03355
Total Iteration Time: 4.91423

Cumulative Model Updates: 52,794
Cumulative Timesteps: 880,637,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762,960.70499
Policy Entropy: 1.06006
Value Function Loss: 3.31002

Mean KL Divergence: 0.02738
SB3 Clip Fraction: 0.16154
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 11,956.76894
Overall Steps per Second: 10,160.15470

Timestep Collection Time: 4.18240
Timestep Consumption Time: 0.73957
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.92197

Cumulative Model Updates: 52,797
Cumulative Timesteps: 880,687,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 880687556...
Checkpoint 880687556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,711.19148
Policy Entropy: 1.08218
Value Function Loss: 3.24779

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 11,777.84492
Overall Steps per Second: 10,178.22600

Timestep Collection Time: 4.24662
Timestep Consumption Time: 0.66740
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.91402

Cumulative Model Updates: 52,800
Cumulative Timesteps: 880,737,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,192.50712
Policy Entropy: 1.09044
Value Function Loss: 3.30961

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 11,959.86464
Overall Steps per Second: 10,083.17460

Timestep Collection Time: 4.18115
Timestep Consumption Time: 0.77820
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.95935

Cumulative Model Updates: 52,803
Cumulative Timesteps: 880,787,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 880787578...
Checkpoint 880787578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,086.96599
Policy Entropy: 1.07714
Value Function Loss: 3.27867

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 11,364.74502
Overall Steps per Second: 9,739.96070

Timestep Collection Time: 4.40027
Timestep Consumption Time: 0.73404
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.13431

Cumulative Model Updates: 52,806
Cumulative Timesteps: 880,837,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,246.98502
Policy Entropy: 1.06135
Value Function Loss: 3.27990

Mean KL Divergence: 0.03052
SB3 Clip Fraction: 0.17573
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.09377

Collected Steps per Second: 12,267.94715
Overall Steps per Second: 10,370.27470

Timestep Collection Time: 4.07745
Timestep Consumption Time: 0.74614
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.82359

Cumulative Model Updates: 52,809
Cumulative Timesteps: 880,887,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 880887608...
Checkpoint 880887608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,033.43623
Policy Entropy: 1.06962
Value Function Loss: 3.26054

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 11,844.41403
Overall Steps per Second: 10,038.86583

Timestep Collection Time: 4.22258
Timestep Consumption Time: 0.75946
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 4.98204

Cumulative Model Updates: 52,812
Cumulative Timesteps: 880,937,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633,532.12261
Policy Entropy: 1.07136
Value Function Loss: 3.36787

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 11,954.09368
Overall Steps per Second: 10,282.04948

Timestep Collection Time: 4.18334
Timestep Consumption Time: 0.68029
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.86362

Cumulative Model Updates: 52,815
Cumulative Timesteps: 880,987,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 880987630...
Checkpoint 880987630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,239.38540
Policy Entropy: 1.05876
Value Function Loss: 3.32471

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 12,048.24676
Overall Steps per Second: 10,204.21011

Timestep Collection Time: 4.15048
Timestep Consumption Time: 0.75005
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.90053

Cumulative Model Updates: 52,818
Cumulative Timesteps: 881,037,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,688.38824
Policy Entropy: 1.05577
Value Function Loss: 3.47764

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.16111
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.12930

Collected Steps per Second: 11,800.06500
Overall Steps per Second: 10,058.49148

Timestep Collection Time: 4.23896
Timestep Consumption Time: 0.73395
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 4.97291

Cumulative Model Updates: 52,821
Cumulative Timesteps: 881,087,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 881087656...
Checkpoint 881087656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,091.54179
Policy Entropy: 1.07106
Value Function Loss: 3.40204

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 11,486.71891
Overall Steps per Second: 9,811.64603

Timestep Collection Time: 4.35285
Timestep Consumption Time: 0.74313
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.09598

Cumulative Model Updates: 52,824
Cumulative Timesteps: 881,137,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,290.10827
Policy Entropy: 1.07407
Value Function Loss: 3.41873

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 12,019.34286
Overall Steps per Second: 10,052.18678

Timestep Collection Time: 4.16029
Timestep Consumption Time: 0.81415
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.97444

Cumulative Model Updates: 52,827
Cumulative Timesteps: 881,187,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 881187660...
Checkpoint 881187660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,673.92810
Policy Entropy: 1.04441
Value Function Loss: 3.24951

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.18551
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.09049

Collected Steps per Second: 12,324.95497
Overall Steps per Second: 10,591.09354

Timestep Collection Time: 4.05713
Timestep Consumption Time: 0.66419
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.72133

Cumulative Model Updates: 52,830
Cumulative Timesteps: 881,237,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,858.30770
Policy Entropy: 1.06270
Value Function Loss: 3.18363

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.16627
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.09274

Collected Steps per Second: 12,391.67840
Overall Steps per Second: 10,418.27697

Timestep Collection Time: 4.03706
Timestep Consumption Time: 0.76469
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.80175

Cumulative Model Updates: 52,833
Cumulative Timesteps: 881,287,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 881287690...
Checkpoint 881287690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,447.11628
Policy Entropy: 1.06929
Value Function Loss: 3.14273

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.09083

Collected Steps per Second: 12,190.71360
Overall Steps per Second: 10,360.35132

Timestep Collection Time: 4.10197
Timestep Consumption Time: 0.72470
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.82667

Cumulative Model Updates: 52,836
Cumulative Timesteps: 881,337,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,942.71035
Policy Entropy: 1.06229
Value Function Loss: 3.12812

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.10509

Collected Steps per Second: 12,364.36538
Overall Steps per Second: 10,607.58845

Timestep Collection Time: 4.04388
Timestep Consumption Time: 0.66973
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.71361

Cumulative Model Updates: 52,839
Cumulative Timesteps: 881,387,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 881387696...
Checkpoint 881387696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,371.91300
Policy Entropy: 1.04346
Value Function Loss: 3.04280

Mean KL Divergence: 0.03546
SB3 Clip Fraction: 0.21688
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 11,391.71885
Overall Steps per Second: 9,700.52980

Timestep Collection Time: 4.38950
Timestep Consumption Time: 0.76527
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.15477

Cumulative Model Updates: 52,842
Cumulative Timesteps: 881,437,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,699.25266
Policy Entropy: 1.05648
Value Function Loss: 3.07546

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.10420

Collected Steps per Second: 12,212.77150
Overall Steps per Second: 10,297.34744

Timestep Collection Time: 4.09538
Timestep Consumption Time: 0.76179
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 4.85717

Cumulative Model Updates: 52,845
Cumulative Timesteps: 881,487,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 881487716...
Checkpoint 881487716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,306.12572
Policy Entropy: 1.05613
Value Function Loss: 3.06704

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 12,463.96776
Overall Steps per Second: 10,505.72935

Timestep Collection Time: 4.01349
Timestep Consumption Time: 0.74810
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 4.76159

Cumulative Model Updates: 52,848
Cumulative Timesteps: 881,537,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,936.65319
Policy Entropy: 1.05449
Value Function Loss: 3.18302

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 11,988.27899
Overall Steps per Second: 10,038.03912

Timestep Collection Time: 4.17107
Timestep Consumption Time: 0.81038
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.98145

Cumulative Model Updates: 52,851
Cumulative Timesteps: 881,587,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 881587744...
Checkpoint 881587744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,106.51316
Policy Entropy: 1.04885
Value Function Loss: 3.14199

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.12551

Collected Steps per Second: 12,098.23484
Overall Steps per Second: 10,343.45293

Timestep Collection Time: 4.13399
Timestep Consumption Time: 0.70134
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.83533

Cumulative Model Updates: 52,854
Cumulative Timesteps: 881,637,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,619.40294
Policy Entropy: 1.03417
Value Function Loss: 3.21924

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 12,281.46514
Overall Steps per Second: 10,344.07818

Timestep Collection Time: 4.07118
Timestep Consumption Time: 0.76251
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.83368

Cumulative Model Updates: 52,857
Cumulative Timesteps: 881,687,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 881687758...
Checkpoint 881687758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,771.56920
Policy Entropy: 1.05742
Value Function Loss: 3.29254

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15979
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 11,642.03419
Overall Steps per Second: 9,940.14274

Timestep Collection Time: 4.29667
Timestep Consumption Time: 0.73565
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.03232

Cumulative Model Updates: 52,860
Cumulative Timesteps: 881,737,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,081.68592
Policy Entropy: 1.05125
Value Function Loss: 3.30564

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.10733

Collected Steps per Second: 12,199.29601
Overall Steps per Second: 10,504.54052

Timestep Collection Time: 4.10024
Timestep Consumption Time: 0.66151
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 4.76175

Cumulative Model Updates: 52,863
Cumulative Timesteps: 881,787,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 881787800...
Checkpoint 881787800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,262.15497
Policy Entropy: 1.04763
Value Function Loss: 3.16352

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 11,625.89979
Overall Steps per Second: 9,929.51174

Timestep Collection Time: 4.30315
Timestep Consumption Time: 0.73516
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.03831

Cumulative Model Updates: 52,866
Cumulative Timesteps: 881,837,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,417.23856
Policy Entropy: 1.03740
Value Function Loss: 3.04283

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 11,722.60522
Overall Steps per Second: 10,118.53403

Timestep Collection Time: 4.26714
Timestep Consumption Time: 0.67646
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.94360

Cumulative Model Updates: 52,869
Cumulative Timesteps: 881,887,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 881887850...
Checkpoint 881887850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,842.16050
Policy Entropy: 1.04695
Value Function Loss: 3.01827

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 12,002.42823
Overall Steps per Second: 10,182.64055

Timestep Collection Time: 4.16732
Timestep Consumption Time: 0.74476
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.91209

Cumulative Model Updates: 52,872
Cumulative Timesteps: 881,937,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,389.04535
Policy Entropy: 1.06399
Value Function Loss: 3.29369

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.08665

Collected Steps per Second: 12,100.58479
Overall Steps per Second: 10,291.61383

Timestep Collection Time: 4.13385
Timestep Consumption Time: 0.72661
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.86046

Cumulative Model Updates: 52,875
Cumulative Timesteps: 881,987,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 881987890...
Checkpoint 881987890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,281.54714
Policy Entropy: 1.03250
Value Function Loss: 3.31623

Mean KL Divergence: 0.03443
SB3 Clip Fraction: 0.20241
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 11,596.39095
Overall Steps per Second: 9,863.72786

Timestep Collection Time: 4.31169
Timestep Consumption Time: 0.75739
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.06908

Cumulative Model Updates: 52,878
Cumulative Timesteps: 882,037,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,427.45696
Policy Entropy: 1.05705
Value Function Loss: 3.33340

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.08046

Collected Steps per Second: 11,992.58198
Overall Steps per Second: 10,178.94518

Timestep Collection Time: 4.16958
Timestep Consumption Time: 0.74292
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.91249

Cumulative Model Updates: 52,881
Cumulative Timesteps: 882,087,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 882087894...
Checkpoint 882087894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,489.46195
Policy Entropy: 1.04903
Value Function Loss: 3.25630

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 12,159.09248
Overall Steps per Second: 10,407.41404

Timestep Collection Time: 4.11215
Timestep Consumption Time: 0.69212
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.80427

Cumulative Model Updates: 52,884
Cumulative Timesteps: 882,137,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,080.08997
Policy Entropy: 1.04323
Value Function Loss: 3.23501

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.06648

Collected Steps per Second: 12,147.95114
Overall Steps per Second: 10,249.68777

Timestep Collection Time: 4.11724
Timestep Consumption Time: 0.76252
PPO Batch Consumption Time: 0.03283
Total Iteration Time: 4.87976

Cumulative Model Updates: 52,887
Cumulative Timesteps: 882,187,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 882187910...
Checkpoint 882187910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,371.43892
Policy Entropy: 1.03521
Value Function Loss: 3.10946

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 12,027.86084
Overall Steps per Second: 10,201.99972

Timestep Collection Time: 4.15934
Timestep Consumption Time: 0.74440
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.90374

Cumulative Model Updates: 52,890
Cumulative Timesteps: 882,237,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,569.21981
Policy Entropy: 1.04864
Value Function Loss: 3.08724

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 12,122.55951
Overall Steps per Second: 10,268.52495

Timestep Collection Time: 4.12471
Timestep Consumption Time: 0.74474
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.86944

Cumulative Model Updates: 52,893
Cumulative Timesteps: 882,287,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 882287940...
Checkpoint 882287940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,618.18879
Policy Entropy: 1.05375
Value Function Loss: 3.23349

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15756
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 11,666.14418
Overall Steps per Second: 9,900.80767

Timestep Collection Time: 4.28813
Timestep Consumption Time: 0.76458
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.05272

Cumulative Model Updates: 52,896
Cumulative Timesteps: 882,337,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,427.50037
Policy Entropy: 1.04150
Value Function Loss: 3.38001

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 11,867.87623
Overall Steps per Second: 10,114.28254

Timestep Collection Time: 4.21524
Timestep Consumption Time: 0.73083
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.94607

Cumulative Model Updates: 52,899
Cumulative Timesteps: 882,387,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 882387992...
Checkpoint 882387992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,309.45628
Policy Entropy: 1.03657
Value Function Loss: 3.40455

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.17865
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.08567

Collected Steps per Second: 12,409.81355
Overall Steps per Second: 10,205.38480

Timestep Collection Time: 4.03036
Timestep Consumption Time: 0.87058
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.90094

Cumulative Model Updates: 52,902
Cumulative Timesteps: 882,438,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,197.76356
Policy Entropy: 1.04526
Value Function Loss: 3.40219

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.08191

Collected Steps per Second: 13,035.68604
Overall Steps per Second: 10,853.50400

Timestep Collection Time: 3.83655
Timestep Consumption Time: 0.77137
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.60791

Cumulative Model Updates: 52,905
Cumulative Timesteps: 882,488,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 882488020...
Checkpoint 882488020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795,225.37602
Policy Entropy: 1.05404
Value Function Loss: 3.35551

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 12,733.34432
Overall Steps per Second: 10,847.66372

Timestep Collection Time: 3.92905
Timestep Consumption Time: 0.68300
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.61205

Cumulative Model Updates: 52,908
Cumulative Timesteps: 882,538,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,123.09917
Policy Entropy: 1.01250
Value Function Loss: 3.31815

Mean KL Divergence: 0.03861
SB3 Clip Fraction: 0.22823
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 12,874.17784
Overall Steps per Second: 10,707.02944

Timestep Collection Time: 3.88421
Timestep Consumption Time: 0.78618
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 4.67039

Cumulative Model Updates: 52,911
Cumulative Timesteps: 882,588,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 882588056...
Checkpoint 882588056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,395.41189
Policy Entropy: 1.04147
Value Function Loss: 3.22876

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.16185
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.10288

Collected Steps per Second: 12,789.62172
Overall Steps per Second: 10,642.74148

Timestep Collection Time: 3.90989
Timestep Consumption Time: 0.78871
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.69860

Cumulative Model Updates: 52,914
Cumulative Timesteps: 882,638,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,753.17701
Policy Entropy: 1.03884
Value Function Loss: 3.23847

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 12,606.86642
Overall Steps per Second: 10,550.81248

Timestep Collection Time: 3.96815
Timestep Consumption Time: 0.77328
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.74144

Cumulative Model Updates: 52,917
Cumulative Timesteps: 882,688,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 882688088...
Checkpoint 882688088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,889.10349
Policy Entropy: 1.04154
Value Function Loss: 3.11145

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.09223

Collected Steps per Second: 12,656.30729
Overall Steps per Second: 10,552.45923

Timestep Collection Time: 3.95060
Timestep Consumption Time: 0.78763
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.73823

Cumulative Model Updates: 52,920
Cumulative Timesteps: 882,738,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,201.44209
Policy Entropy: 1.03064
Value Function Loss: 3.10297

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 12,136.44974
Overall Steps per Second: 10,177.59927

Timestep Collection Time: 4.12114
Timestep Consumption Time: 0.79318
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.91432

Cumulative Model Updates: 52,923
Cumulative Timesteps: 882,788,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 882788104...
Checkpoint 882788104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,653.24519
Policy Entropy: 1.02938
Value Function Loss: 3.07032

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 12,007.23170
Overall Steps per Second: 10,120.58114

Timestep Collection Time: 4.16649
Timestep Consumption Time: 0.77671
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.94319

Cumulative Model Updates: 52,926
Cumulative Timesteps: 882,838,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,986.43428
Policy Entropy: 1.04420
Value Function Loss: 3.25371

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.10685

Collected Steps per Second: 12,265.88874
Overall Steps per Second: 10,315.28418

Timestep Collection Time: 4.07765
Timestep Consumption Time: 0.77108
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.84873

Cumulative Model Updates: 52,929
Cumulative Timesteps: 882,888,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 882888148...
Checkpoint 882888148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,343.75677
Policy Entropy: 1.04600
Value Function Loss: 3.27522

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.06850
Value Function Update Magnitude: 0.11878

Collected Steps per Second: 11,842.90846
Overall Steps per Second: 10,179.71474

Timestep Collection Time: 4.22244
Timestep Consumption Time: 0.68988
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.91232

Cumulative Model Updates: 52,932
Cumulative Timesteps: 882,938,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,972.74940
Policy Entropy: 1.04216
Value Function Loss: 3.39594

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.07811
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 11,484.39516
Overall Steps per Second: 9,730.99331

Timestep Collection Time: 4.35495
Timestep Consumption Time: 0.78471
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.13966

Cumulative Model Updates: 52,935
Cumulative Timesteps: 882,988,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 882988168...
Checkpoint 882988168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,108.10593
Policy Entropy: 1.04527
Value Function Loss: 3.47197

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.09364

Collected Steps per Second: 12,093.30132
Overall Steps per Second: 10,183.81820

Timestep Collection Time: 4.13551
Timestep Consumption Time: 0.77542
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.91093

Cumulative Model Updates: 52,938
Cumulative Timesteps: 883,038,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,034.08455
Policy Entropy: 1.03855
Value Function Loss: 3.35994

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.08594

Collected Steps per Second: 12,395.26269
Overall Steps per Second: 10,422.66545

Timestep Collection Time: 4.03461
Timestep Consumption Time: 0.76359
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.79820

Cumulative Model Updates: 52,941
Cumulative Timesteps: 883,088,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 883088190...
Checkpoint 883088190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,191.25507
Policy Entropy: 1.03583
Value Function Loss: 3.38937

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.07726
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 12,008.75051
Overall Steps per Second: 10,169.10830

Timestep Collection Time: 4.16396
Timestep Consumption Time: 0.75328
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.91725

Cumulative Model Updates: 52,944
Cumulative Timesteps: 883,138,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,822.95554
Policy Entropy: 1.03894
Value Function Loss: 3.32719

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.07333
Value Function Update Magnitude: 0.08206

Collected Steps per Second: 11,943.36660
Overall Steps per Second: 10,314.16487

Timestep Collection Time: 4.18793
Timestep Consumption Time: 0.66152
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.84945

Cumulative Model Updates: 52,947
Cumulative Timesteps: 883,188,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 883188212...
Checkpoint 883188212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,421.90810
Policy Entropy: 1.04206
Value Function Loss: 3.57256

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 11,710.43464
Overall Steps per Second: 9,971.55464

Timestep Collection Time: 4.27175
Timestep Consumption Time: 0.74492
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.01667

Cumulative Model Updates: 52,950
Cumulative Timesteps: 883,238,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,632.96139
Policy Entropy: 1.05744
Value Function Loss: 3.52480

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.07942

Collected Steps per Second: 11,336.15049
Overall Steps per Second: 9,694.20350

Timestep Collection Time: 4.41243
Timestep Consumption Time: 0.74735
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.15978

Cumulative Model Updates: 52,953
Cumulative Timesteps: 883,288,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883288256...
Checkpoint 883288256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,657.25839
Policy Entropy: 1.05157
Value Function Loss: 3.44579

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.08366

Collected Steps per Second: 12,066.91505
Overall Steps per Second: 10,148.96103

Timestep Collection Time: 4.14389
Timestep Consumption Time: 0.78311
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.92701

Cumulative Model Updates: 52,956
Cumulative Timesteps: 883,338,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,541.45726
Policy Entropy: 1.05084
Value Function Loss: 3.47853

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 12,182.79798
Overall Steps per Second: 10,277.29677

Timestep Collection Time: 4.10612
Timestep Consumption Time: 0.76131
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.86743

Cumulative Model Updates: 52,959
Cumulative Timesteps: 883,388,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883388284...
Checkpoint 883388284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,106.25236
Policy Entropy: 1.06756
Value Function Loss: 3.46626

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 11,997.16593
Overall Steps per Second: 10,326.09727

Timestep Collection Time: 4.16898
Timestep Consumption Time: 0.67467
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.84365

Cumulative Model Updates: 52,962
Cumulative Timesteps: 883,438,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,764.68722
Policy Entropy: 1.07435
Value Function Loss: 3.49755

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.17392
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.10607

Collected Steps per Second: 12,157.88126
Overall Steps per Second: 10,267.52123

Timestep Collection Time: 4.11453
Timestep Consumption Time: 0.75753
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.87206

Cumulative Model Updates: 52,965
Cumulative Timesteps: 883,488,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883488324...
Checkpoint 883488324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,011.47235
Policy Entropy: 1.06376
Value Function Loss: 3.33987

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.10823

Collected Steps per Second: 11,754.68025
Overall Steps per Second: 10,010.21434

Timestep Collection Time: 4.25533
Timestep Consumption Time: 0.74157
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.99690

Cumulative Model Updates: 52,968
Cumulative Timesteps: 883,538,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,510.96779
Policy Entropy: 1.05619
Value Function Loss: 3.25095

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.11963

Collected Steps per Second: 11,683.66242
Overall Steps per Second: 9,892.78505

Timestep Collection Time: 4.28136
Timestep Consumption Time: 0.77505
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.05641

Cumulative Model Updates: 52,971
Cumulative Timesteps: 883,588,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 883588366...
Checkpoint 883588366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,669.36761
Policy Entropy: 1.07418
Value Function Loss: 3.23438

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.10242

Collected Steps per Second: 11,895.36409
Overall Steps per Second: 10,021.55974

Timestep Collection Time: 4.20399
Timestep Consumption Time: 0.78605
PPO Batch Consumption Time: 0.03930
Total Iteration Time: 4.99004

Cumulative Model Updates: 52,974
Cumulative Timesteps: 883,638,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,993.18681
Policy Entropy: 1.08379
Value Function Loss: 3.19682

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.09114

Collected Steps per Second: 12,190.71759
Overall Steps per Second: 10,493.35515

Timestep Collection Time: 4.10181
Timestep Consumption Time: 0.66349
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.76530

Cumulative Model Updates: 52,977
Cumulative Timesteps: 883,688,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 883688378...
Checkpoint 883688378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,488.51881
Policy Entropy: 1.06328
Value Function Loss: 3.38850

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.10206

Collected Steps per Second: 12,311.27731
Overall Steps per Second: 10,375.54534

Timestep Collection Time: 4.06343
Timestep Consumption Time: 0.75810
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 4.82153

Cumulative Model Updates: 52,980
Cumulative Timesteps: 883,738,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,308.59068
Policy Entropy: 1.08448
Value Function Loss: 3.52497

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.12091

Collected Steps per Second: 12,177.57506
Overall Steps per Second: 10,344.45608

Timestep Collection Time: 4.10788
Timestep Consumption Time: 0.72795
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 4.83583

Cumulative Model Updates: 52,983
Cumulative Timesteps: 883,788,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883788428...
Checkpoint 883788428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,336.40662
Policy Entropy: 1.08401
Value Function Loss: 3.68991

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 12,287.98072
Overall Steps per Second: 10,400.94391

Timestep Collection Time: 4.06902
Timestep Consumption Time: 0.73824
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 4.80726

Cumulative Model Updates: 52,986
Cumulative Timesteps: 883,838,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,611.00651
Policy Entropy: 1.07465
Value Function Loss: 3.44527

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.09121

Collected Steps per Second: 11,499.50866
Overall Steps per Second: 9,761.47772

Timestep Collection Time: 4.34923
Timestep Consumption Time: 0.77438
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.12361

Cumulative Model Updates: 52,989
Cumulative Timesteps: 883,888,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 883888442...
Checkpoint 883888442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,715.63110
Policy Entropy: 1.05594
Value Function Loss: 3.23224

Mean KL Divergence: 0.03059
SB3 Clip Fraction: 0.19285
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 12,100.24595
Overall Steps per Second: 10,434.02820

Timestep Collection Time: 4.13231
Timestep Consumption Time: 0.65989
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.79220

Cumulative Model Updates: 52,992
Cumulative Timesteps: 883,938,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,760.62450
Policy Entropy: 1.07170
Value Function Loss: 3.20484

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 12,139.75543
Overall Steps per Second: 10,213.73976

Timestep Collection Time: 4.12035
Timestep Consumption Time: 0.77698
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.89732

Cumulative Model Updates: 52,995
Cumulative Timesteps: 883,988,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883988464...
Checkpoint 883988464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,815.89611
Policy Entropy: 1.07256
Value Function Loss: 3.32944

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.08951

Collected Steps per Second: 11,855.10626
Overall Steps per Second: 10,018.61897

Timestep Collection Time: 4.21810
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.99131

Cumulative Model Updates: 52,998
Cumulative Timesteps: 884,038,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,328.95612
Policy Entropy: 1.06387
Value Function Loss: 3.45995

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 12,425.60662
Overall Steps per Second: 10,325.48292

Timestep Collection Time: 4.02475
Timestep Consumption Time: 0.81860
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.84336

Cumulative Model Updates: 53,001
Cumulative Timesteps: 884,088,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 884088480...
Checkpoint 884088480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,281.22528
Policy Entropy: 1.04952
Value Function Loss: 3.44284

Mean KL Divergence: 0.03652
SB3 Clip Fraction: 0.19911
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 12,060.06307
Overall Steps per Second: 10,110.70780

Timestep Collection Time: 4.14592
Timestep Consumption Time: 0.79934
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.94525

Cumulative Model Updates: 53,004
Cumulative Timesteps: 884,138,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,942.74766
Policy Entropy: 1.07103
Value Function Loss: 3.40582

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.09298

Collected Steps per Second: 11,455.64387
Overall Steps per Second: 9,894.24700

Timestep Collection Time: 4.36623
Timestep Consumption Time: 0.68903
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.05526

Cumulative Model Updates: 53,007
Cumulative Timesteps: 884,188,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884188498...
Checkpoint 884188498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,832.25138
Policy Entropy: 1.06601
Value Function Loss: 3.42570

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.09625

Collected Steps per Second: 12,024.19003
Overall Steps per Second: 10,137.04447

Timestep Collection Time: 4.15961
Timestep Consumption Time: 0.77437
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.93398

Cumulative Model Updates: 53,010
Cumulative Timesteps: 884,238,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,578.68543
Policy Entropy: 1.05881
Value Function Loss: 3.33544

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 11,997.02596
Overall Steps per Second: 10,181.16243

Timestep Collection Time: 4.16820
Timestep Consumption Time: 0.74342
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.91162

Cumulative Model Updates: 53,013
Cumulative Timesteps: 884,288,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 884288520...
Checkpoint 884288520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,180.74869
Policy Entropy: 1.06077
Value Function Loss: 3.31438

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.10931

Collected Steps per Second: 12,478.11888
Overall Steps per Second: 10,513.46021

Timestep Collection Time: 4.00814
Timestep Consumption Time: 0.74900
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.75714

Cumulative Model Updates: 53,016
Cumulative Timesteps: 884,338,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,915.97889
Policy Entropy: 1.05386
Value Function Loss: 3.18649

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.10880

Collected Steps per Second: 12,148.78973
Overall Steps per Second: 10,239.89389

Timestep Collection Time: 4.11564
Timestep Consumption Time: 0.76723
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.88286

Cumulative Model Updates: 53,019
Cumulative Timesteps: 884,388,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 884388534...
Checkpoint 884388534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,121.66301
Policy Entropy: 1.06712
Value Function Loss: 3.31025

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 12,172.13158
Overall Steps per Second: 10,306.14534

Timestep Collection Time: 4.11004
Timestep Consumption Time: 0.74415
PPO Batch Consumption Time: 0.03390
Total Iteration Time: 4.85419

Cumulative Model Updates: 53,022
Cumulative Timesteps: 884,438,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,429.60364
Policy Entropy: 1.07094
Value Function Loss: 3.26641

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 11,097.74117
Overall Steps per Second: 9,404.12885

Timestep Collection Time: 4.50596
Timestep Consumption Time: 0.81149
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 5.31745

Cumulative Model Updates: 53,025
Cumulative Timesteps: 884,488,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 884488568...
Checkpoint 884488568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,756.06886
Policy Entropy: 1.06561
Value Function Loss: 3.41181

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.06230
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 11,633.93176
Overall Steps per Second: 10,081.29371

Timestep Collection Time: 4.29795
Timestep Consumption Time: 0.66193
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 4.95988

Cumulative Model Updates: 53,028
Cumulative Timesteps: 884,538,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,520.73269
Policy Entropy: 1.04511
Value Function Loss: 3.31493

Mean KL Divergence: 0.03130
SB3 Clip Fraction: 0.17833
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 12,017.85788
Overall Steps per Second: 10,119.51459

Timestep Collection Time: 4.16197
Timestep Consumption Time: 0.78075
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.94273

Cumulative Model Updates: 53,031
Cumulative Timesteps: 884,588,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884588588...
Checkpoint 884588588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,062.09464
Policy Entropy: 1.06346
Value Function Loss: 3.37047

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 12,062.47856
Overall Steps per Second: 10,197.47244

Timestep Collection Time: 4.14575
Timestep Consumption Time: 0.75821
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.90396

Cumulative Model Updates: 53,034
Cumulative Timesteps: 884,638,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,789.20046
Policy Entropy: 1.07305
Value Function Loss: 3.15326

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 12,443.41589
Overall Steps per Second: 10,434.07052

Timestep Collection Time: 4.01964
Timestep Consumption Time: 0.77408
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.79372

Cumulative Model Updates: 53,037
Cumulative Timesteps: 884,688,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884688614...
Checkpoint 884688614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,222.46362
Policy Entropy: 1.04990
Value Function Loss: 3.07826

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.09045

Collected Steps per Second: 12,084.03291
Overall Steps per Second: 10,157.28497

Timestep Collection Time: 4.13819
Timestep Consumption Time: 0.78498
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 4.92317

Cumulative Model Updates: 53,040
Cumulative Timesteps: 884,738,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,061.38692
Policy Entropy: 1.05864
Value Function Loss: 3.02801

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.15785
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.08570

Collected Steps per Second: 11,321.56978
Overall Steps per Second: 9,806.03679

Timestep Collection Time: 4.41635
Timestep Consumption Time: 0.68255
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.09890

Cumulative Model Updates: 53,043
Cumulative Timesteps: 884,788,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 884788620...
Checkpoint 884788620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,908.81847
Policy Entropy: 1.04767
Value Function Loss: 3.05091

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 11,991.74413
Overall Steps per Second: 10,081.04533

Timestep Collection Time: 4.17187
Timestep Consumption Time: 0.79071
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.96258

Cumulative Model Updates: 53,046
Cumulative Timesteps: 884,838,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,292.14970
Policy Entropy: 1.03735
Value Function Loss: 3.11547

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 12,214.42582
Overall Steps per Second: 10,336.87955

Timestep Collection Time: 4.09434
Timestep Consumption Time: 0.74368
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.83802

Cumulative Model Updates: 53,049
Cumulative Timesteps: 884,888,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 884888658...
Checkpoint 884888658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,537.14546
Policy Entropy: 1.03297
Value Function Loss: 3.22100

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.18270
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 13,121.90544
Overall Steps per Second: 10,964.13389

Timestep Collection Time: 3.81118
Timestep Consumption Time: 0.75005
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.56124

Cumulative Model Updates: 53,052
Cumulative Timesteps: 884,938,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,485.79582
Policy Entropy: 1.03957
Value Function Loss: 3.48877

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15545
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 12,567.45872
Overall Steps per Second: 10,505.42805

Timestep Collection Time: 3.98092
Timestep Consumption Time: 0.78138
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 4.76230

Cumulative Model Updates: 53,055
Cumulative Timesteps: 884,988,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 884988698...
Checkpoint 884988698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,505.70476
Policy Entropy: 1.04607
Value Function Loss: 3.64099

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 12,691.53368
Overall Steps per Second: 10,796.66532

Timestep Collection Time: 3.94058
Timestep Consumption Time: 0.69159
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 4.63217

Cumulative Model Updates: 53,058
Cumulative Timesteps: 885,038,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,222.65153
Policy Entropy: 1.01180
Value Function Loss: 3.55013

Mean KL Divergence: 0.04777
SB3 Clip Fraction: 0.23376
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 12,446.93122
Overall Steps per Second: 10,385.77085

Timestep Collection Time: 4.01898
Timestep Consumption Time: 0.79761
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.81659

Cumulative Model Updates: 53,061
Cumulative Timesteps: 885,088,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885088734...
Checkpoint 885088734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,897.00381
Policy Entropy: 1.03048
Value Function Loss: 3.39292

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.08571

Collected Steps per Second: 12,475.94892
Overall Steps per Second: 10,520.87151

Timestep Collection Time: 4.00803
Timestep Consumption Time: 0.74481
PPO Batch Consumption Time: 0.03327
Total Iteration Time: 4.75284

Cumulative Model Updates: 53,064
Cumulative Timesteps: 885,138,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,459.93314
Policy Entropy: 1.03075
Value Function Loss: 3.20857

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.16672
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 12,968.98850
Overall Steps per Second: 10,769.12630

Timestep Collection Time: 3.85550
Timestep Consumption Time: 0.78758
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.64309

Cumulative Model Updates: 53,067
Cumulative Timesteps: 885,188,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885188740...
Checkpoint 885188740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,301.27988
Policy Entropy: 1.02810
Value Function Loss: 3.07036

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.09176

Collected Steps per Second: 11,942.78726
Overall Steps per Second: 10,033.51226

Timestep Collection Time: 4.18696
Timestep Consumption Time: 0.79674
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 4.98370

Cumulative Model Updates: 53,070
Cumulative Timesteps: 885,238,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,586.48563
Policy Entropy: 1.00744
Value Function Loss: 2.97272

Mean KL Divergence: 0.03711
SB3 Clip Fraction: 0.20641
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.08866

Collected Steps per Second: 11,970.08961
Overall Steps per Second: 10,270.63067

Timestep Collection Time: 4.17975
Timestep Consumption Time: 0.69161
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 4.87137

Cumulative Model Updates: 53,073
Cumulative Timesteps: 885,288,776

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 885288776...
Checkpoint 885288776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,129.37017
Policy Entropy: 1.03218
Value Function Loss: 3.09930

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 12,158.50103
Overall Steps per Second: 10,251.06059

Timestep Collection Time: 4.11334
Timestep Consumption Time: 0.76538
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.87871

Cumulative Model Updates: 53,076
Cumulative Timesteps: 885,338,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,027.46698
Policy Entropy: 1.04044
Value Function Loss: 3.29160

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.08142

Collected Steps per Second: 12,051.68878
Overall Steps per Second: 10,148.44037

Timestep Collection Time: 4.14896
Timestep Consumption Time: 0.77810
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 4.92706

Cumulative Model Updates: 53,079
Cumulative Timesteps: 885,388,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885388790...
Checkpoint 885388790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,790.57791
Policy Entropy: 1.02105
Value Function Loss: 3.45593

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 11,660.47625
Overall Steps per Second: 10,102.96325

Timestep Collection Time: 4.28953
Timestep Consumption Time: 0.66129
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 4.95082

Cumulative Model Updates: 53,082
Cumulative Timesteps: 885,438,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,557.28527
Policy Entropy: 1.02290
Value Function Loss: 3.36484

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08733

Collected Steps per Second: 11,963.46950
Overall Steps per Second: 10,077.58865

Timestep Collection Time: 4.18006
Timestep Consumption Time: 0.78224
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.96230

Cumulative Model Updates: 53,085
Cumulative Timesteps: 885,488,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 885488816...
Checkpoint 885488816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,929.96332
Policy Entropy: 1.02085
Value Function Loss: 3.32122

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.07825

Collected Steps per Second: 11,982.97288
Overall Steps per Second: 10,337.93443

Timestep Collection Time: 4.17442
Timestep Consumption Time: 0.66426
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 4.83868

Cumulative Model Updates: 53,088
Cumulative Timesteps: 885,538,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,803.77447
Policy Entropy: 1.03111
Value Function Loss: 3.32411

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.08133

Collected Steps per Second: 12,073.57074
Overall Steps per Second: 10,179.91551

Timestep Collection Time: 4.14376
Timestep Consumption Time: 0.77082
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.91458

Cumulative Model Updates: 53,091
Cumulative Timesteps: 885,588,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 885588868...
Checkpoint 885588868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,718.80921
Policy Entropy: 1.01097
Value Function Loss: 3.31361

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07255

Collected Steps per Second: 12,048.44590
Overall Steps per Second: 10,151.38074

Timestep Collection Time: 4.15041
Timestep Consumption Time: 0.77562
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.92603

Cumulative Model Updates: 53,094
Cumulative Timesteps: 885,638,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,016.12951
Policy Entropy: 1.01017
Value Function Loss: 3.23731

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.06073

Collected Steps per Second: 12,339.07222
Overall Steps per Second: 10,344.60173

Timestep Collection Time: 4.05363
Timestep Consumption Time: 0.78155
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.83518

Cumulative Model Updates: 53,097
Cumulative Timesteps: 885,688,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885688892...
Checkpoint 885688892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,489.60198
Policy Entropy: 1.02410
Value Function Loss: 3.18712

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.05741

Collected Steps per Second: 11,291.29867
Overall Steps per Second: 9,624.33557

Timestep Collection Time: 4.43014
Timestep Consumption Time: 0.76731
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.19745

Cumulative Model Updates: 53,100
Cumulative Timesteps: 885,738,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,811.53948
Policy Entropy: 1.03517
Value Function Loss: 3.12021

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 11,933.76918
Overall Steps per Second: 10,268.31154

Timestep Collection Time: 4.18996
Timestep Consumption Time: 0.67959
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.86954

Cumulative Model Updates: 53,103
Cumulative Timesteps: 885,788,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885788916...
Checkpoint 885788916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,145.44580
Policy Entropy: 1.00702
Value Function Loss: 3.01805

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 11,769.41788
Overall Steps per Second: 9,975.66049

Timestep Collection Time: 4.24898
Timestep Consumption Time: 0.76402
PPO Batch Consumption Time: 0.03351
Total Iteration Time: 5.01300

Cumulative Model Updates: 53,106
Cumulative Timesteps: 885,838,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,719.03478
Policy Entropy: 1.00581
Value Function Loss: 3.08349

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.16023
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.07783

Collected Steps per Second: 11,799.53637
Overall Steps per Second: 10,018.58701

Timestep Collection Time: 4.24017
Timestep Consumption Time: 0.75375
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.99392

Cumulative Model Updates: 53,109
Cumulative Timesteps: 885,888,956

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 885888956...
Checkpoint 885888956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,915.06485
Policy Entropy: 1.01956
Value Function Loss: 3.22796

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.07587

Collected Steps per Second: 12,021.08903
Overall Steps per Second: 10,314.04257

Timestep Collection Time: 4.16085
Timestep Consumption Time: 0.68865
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.84950

Cumulative Model Updates: 53,112
Cumulative Timesteps: 885,938,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824,149.02470
Policy Entropy: 1.03714
Value Function Loss: 3.32708

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.16449
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 11,974.93240
Overall Steps per Second: 10,099.86681

Timestep Collection Time: 4.17739
Timestep Consumption Time: 0.77554
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 4.95294

Cumulative Model Updates: 53,115
Cumulative Timesteps: 885,988,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885988998...
Checkpoint 885988998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756,615.78006
Policy Entropy: 1.01498
Value Function Loss: 3.26778

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 11,276.65176
Overall Steps per Second: 9,597.86213

Timestep Collection Time: 4.43536
Timestep Consumption Time: 0.77580
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.21116

Cumulative Model Updates: 53,118
Cumulative Timesteps: 886,039,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,810.15877
Policy Entropy: 1.01803
Value Function Loss: 3.16946

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 12,031.19540
Overall Steps per Second: 10,106.71220

Timestep Collection Time: 4.15819
Timestep Consumption Time: 0.79179
PPO Batch Consumption Time: 0.03725
Total Iteration Time: 4.94998

Cumulative Model Updates: 53,121
Cumulative Timesteps: 886,089,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 886089042...
Checkpoint 886089042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,957.19357
Policy Entropy: 1.03152
Value Function Loss: 3.22768

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.08025

Collected Steps per Second: 12,388.65676
Overall Steps per Second: 10,444.59570

Timestep Collection Time: 4.03611
Timestep Consumption Time: 0.75124
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 4.78736

Cumulative Model Updates: 53,124
Cumulative Timesteps: 886,139,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,634.55759
Policy Entropy: 1.03471
Value Function Loss: 3.21197

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 12,250.87109
Overall Steps per Second: 10,513.02799

Timestep Collection Time: 4.08216
Timestep Consumption Time: 0.67480
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.75695

Cumulative Model Updates: 53,127
Cumulative Timesteps: 886,189,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 886189054...
Checkpoint 886189054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,275.49075
Policy Entropy: 1.01485
Value Function Loss: 3.21332

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 11,851.85550
Overall Steps per Second: 10,019.40388

Timestep Collection Time: 4.22077
Timestep Consumption Time: 0.77194
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.99271

Cumulative Model Updates: 53,130
Cumulative Timesteps: 886,239,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,628.42737
Policy Entropy: 1.00737
Value Function Loss: 3.07625

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.08511

Collected Steps per Second: 11,558.33433
Overall Steps per Second: 9,907.94080

Timestep Collection Time: 4.32623
Timestep Consumption Time: 0.72063
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 5.04686

Cumulative Model Updates: 53,133
Cumulative Timesteps: 886,289,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 886289082...
Checkpoint 886289082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,042.04690
Policy Entropy: 1.02049
Value Function Loss: 3.19448

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 11,476.00118
Overall Steps per Second: 9,968.32567

Timestep Collection Time: 4.35796
Timestep Consumption Time: 0.65913
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.01709

Cumulative Model Updates: 53,136
Cumulative Timesteps: 886,339,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,792.87013
Policy Entropy: 1.03000
Value Function Loss: 3.21973

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.09744

Collected Steps per Second: 12,180.38959
Overall Steps per Second: 10,280.18034

Timestep Collection Time: 4.10594
Timestep Consumption Time: 0.75895
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.86490

Cumulative Model Updates: 53,139
Cumulative Timesteps: 886,389,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 886389106...
Checkpoint 886389106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,125.33199
Policy Entropy: 1.00408
Value Function Loss: 3.13986

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.10525

Collected Steps per Second: 12,048.43537
Overall Steps per Second: 10,263.77820

Timestep Collection Time: 4.15174
Timestep Consumption Time: 0.72190
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.87364

Cumulative Model Updates: 53,142
Cumulative Timesteps: 886,439,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,279.75632
Policy Entropy: 1.03016
Value Function Loss: 3.06826

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.17193
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.10459

Collected Steps per Second: 12,054.72896
Overall Steps per Second: 10,182.17261

Timestep Collection Time: 4.14891
Timestep Consumption Time: 0.76301
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.91192

Cumulative Model Updates: 53,145
Cumulative Timesteps: 886,489,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 886489142...
Checkpoint 886489142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759,012.15378
Policy Entropy: 1.03239
Value Function Loss: 3.12372

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.10322

Collected Steps per Second: 12,117.32352
Overall Steps per Second: 10,289.15838

Timestep Collection Time: 4.12830
Timestep Consumption Time: 0.73351
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.86182

Cumulative Model Updates: 53,148
Cumulative Timesteps: 886,539,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,556.92188
Policy Entropy: 1.02489
Value Function Loss: 3.34074

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.10579

Collected Steps per Second: 11,989.78726
Overall Steps per Second: 10,312.05063

Timestep Collection Time: 4.17255
Timestep Consumption Time: 0.67886
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.85141

Cumulative Model Updates: 53,151
Cumulative Timesteps: 886,589,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 886589194...
Checkpoint 886589194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,462.81105
Policy Entropy: 1.00965
Value Function Loss: 3.30961

Mean KL Divergence: 0.03422
SB3 Clip Fraction: 0.21070
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.09484

Collected Steps per Second: 11,521.75644
Overall Steps per Second: 9,793.21122

Timestep Collection Time: 4.34100
Timestep Consumption Time: 0.76621
PPO Batch Consumption Time: 0.03800
Total Iteration Time: 5.10721

Cumulative Model Updates: 53,154
Cumulative Timesteps: 886,639,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,117.59702
Policy Entropy: 1.03452
Value Function Loss: 3.24949

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.16273
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.09124

Collected Steps per Second: 11,998.92029
Overall Steps per Second: 10,122.59556

Timestep Collection Time: 4.16704
Timestep Consumption Time: 0.77240
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.93944

Cumulative Model Updates: 53,157
Cumulative Timesteps: 886,689,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 886689210...
Checkpoint 886689210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,826.37668
Policy Entropy: 1.01562
Value Function Loss: 3.05456

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.15977
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 11,873.91066
Overall Steps per Second: 10,084.13517

Timestep Collection Time: 4.21091
Timestep Consumption Time: 0.74737
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.95828

Cumulative Model Updates: 53,160
Cumulative Timesteps: 886,739,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,607.42893
Policy Entropy: 1.00765
Value Function Loss: 3.10086

Mean KL Divergence: 0.02656
SB3 Clip Fraction: 0.17372
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 11,920.30720
Overall Steps per Second: 10,022.76533

Timestep Collection Time: 4.19603
Timestep Consumption Time: 0.79441
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.99044

Cumulative Model Updates: 53,163
Cumulative Timesteps: 886,789,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 886789228...
Checkpoint 886789228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509,195.91437
Policy Entropy: 1.02742
Value Function Loss: 3.19263

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.11985

Collected Steps per Second: 12,038.19075
Overall Steps per Second: 10,244.17587

Timestep Collection Time: 4.15494
Timestep Consumption Time: 0.72764
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.88258

Cumulative Model Updates: 53,166
Cumulative Timesteps: 886,839,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,013.27552
Policy Entropy: 1.03374
Value Function Loss: 3.33571

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.16185
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 12,242.80708
Overall Steps per Second: 10,334.88084

Timestep Collection Time: 4.08615
Timestep Consumption Time: 0.75435
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.84050

Cumulative Model Updates: 53,169
Cumulative Timesteps: 886,889,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 886889272...
Checkpoint 886889272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821,257.07532
Policy Entropy: 1.01406
Value Function Loss: 3.31582

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 11,371.53266
Overall Steps per Second: 9,759.82643

Timestep Collection Time: 4.39835
Timestep Consumption Time: 0.72633
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.12468

Cumulative Model Updates: 53,172
Cumulative Timesteps: 886,939,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,108.23242
Policy Entropy: 1.00759
Value Function Loss: 3.24083

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.18033
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10724

Collected Steps per Second: 12,094.14220
Overall Steps per Second: 10,142.95543

Timestep Collection Time: 4.13506
Timestep Consumption Time: 0.79546
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.93052

Cumulative Model Updates: 53,175
Cumulative Timesteps: 886,989,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 886989298...
Checkpoint 886989298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,007.47536
Policy Entropy: 1.02130
Value Function Loss: 3.17738

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 12,189.05161
Overall Steps per Second: 10,340.89262

Timestep Collection Time: 4.10352
Timestep Consumption Time: 0.73339
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.83691

Cumulative Model Updates: 53,178
Cumulative Timesteps: 887,039,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,440.35361
Policy Entropy: 1.02876
Value Function Loss: 3.11838

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 12,085.60845
Overall Steps per Second: 10,353.46922

Timestep Collection Time: 4.13798
Timestep Consumption Time: 0.69229
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.83026

Cumulative Model Updates: 53,181
Cumulative Timesteps: 887,089,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 887089326...
Checkpoint 887089326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836,984.77528
Policy Entropy: 1.02908
Value Function Loss: 3.09163

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.07322
Value Function Update Magnitude: 0.08788

Collected Steps per Second: 12,114.62432
Overall Steps per Second: 10,168.27782

Timestep Collection Time: 4.12774
Timestep Consumption Time: 0.79011
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 4.91784

Cumulative Model Updates: 53,184
Cumulative Timesteps: 887,139,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,350.26936
Policy Entropy: 1.01816
Value Function Loss: 3.04497

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.07007
Value Function Update Magnitude: 0.09158

Collected Steps per Second: 11,953.98228
Overall Steps per Second: 10,170.31888

Timestep Collection Time: 4.18371
Timestep Consumption Time: 0.73374
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.91745

Cumulative Model Updates: 53,187
Cumulative Timesteps: 887,189,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 887189344...
Checkpoint 887189344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,249.43514
Policy Entropy: 1.01600
Value Function Loss: 2.99908

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.06903
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 11,449.79918
Overall Steps per Second: 9,839.07528

Timestep Collection Time: 4.36916
Timestep Consumption Time: 0.71526
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 5.08442

Cumulative Model Updates: 53,190
Cumulative Timesteps: 887,239,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,490.17649
Policy Entropy: 1.02851
Value Function Loss: 3.02788

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,940.54673
Overall Steps per Second: 9,969.37289

Timestep Collection Time: 4.18976
Timestep Consumption Time: 0.82841
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.01817

Cumulative Model Updates: 53,193
Cumulative Timesteps: 887,289,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887289398...
Checkpoint 887289398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,993.03274
Policy Entropy: 1.03842
Value Function Loss: 2.97195

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.07807

Collected Steps per Second: 12,547.07064
Overall Steps per Second: 10,556.11930

Timestep Collection Time: 3.98691
Timestep Consumption Time: 0.75196
PPO Batch Consumption Time: 0.03301
Total Iteration Time: 4.73886

Cumulative Model Updates: 53,196
Cumulative Timesteps: 887,339,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,388.67979
Policy Entropy: 1.02482
Value Function Loss: 3.21792

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.07710

Collected Steps per Second: 13,249.15752
Overall Steps per Second: 11,057.09331

Timestep Collection Time: 3.77594
Timestep Consumption Time: 0.74858
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.52452

Cumulative Model Updates: 53,199
Cumulative Timesteps: 887,389,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887389450...
Checkpoint 887389450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,871.45823
Policy Entropy: 1.01847
Value Function Loss: 3.31926

Mean KL Divergence: 0.03111
SB3 Clip Fraction: 0.19779
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 12,779.22327
Overall Steps per Second: 10,717.99143

Timestep Collection Time: 3.91401
Timestep Consumption Time: 0.75272
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.66673

Cumulative Model Updates: 53,202
Cumulative Timesteps: 887,439,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,075.53806
Policy Entropy: 1.02893
Value Function Loss: 3.32628

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 12,757.16213
Overall Steps per Second: 10,873.03305

Timestep Collection Time: 3.92172
Timestep Consumption Time: 0.67957
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 4.60129

Cumulative Model Updates: 53,205
Cumulative Timesteps: 887,489,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 887489498...
Checkpoint 887489498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,990.82594
Policy Entropy: 1.03483
Value Function Loss: 3.22582

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.07631

Collected Steps per Second: 11,917.96051
Overall Steps per Second: 10,114.26945

Timestep Collection Time: 4.19669
Timestep Consumption Time: 0.74840
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 4.94509

Cumulative Model Updates: 53,208
Cumulative Timesteps: 887,539,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,434.80049
Policy Entropy: 1.01486
Value Function Loss: 3.22346

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.07587

Collected Steps per Second: 12,776.63722
Overall Steps per Second: 10,631.73119

Timestep Collection Time: 3.91386
Timestep Consumption Time: 0.78960
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.70347

Cumulative Model Updates: 53,211
Cumulative Timesteps: 887,589,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 887589520...
Checkpoint 887589520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,494.35779
Policy Entropy: 1.00877
Value Function Loss: 3.21878

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 12,721.83810
Overall Steps per Second: 10,750.52416

Timestep Collection Time: 3.93229
Timestep Consumption Time: 0.72106
PPO Batch Consumption Time: 0.03869
Total Iteration Time: 4.65335

Cumulative Model Updates: 53,214
Cumulative Timesteps: 887,639,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746,646.26777
Policy Entropy: 1.02472
Value Function Loss: 3.03461

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.07728

Collected Steps per Second: 12,014.06959
Overall Steps per Second: 10,120.08740

Timestep Collection Time: 4.16245
Timestep Consumption Time: 0.77901
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.94146

Cumulative Model Updates: 53,217
Cumulative Timesteps: 887,689,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 887689554...
Checkpoint 887689554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,843.50828
Policy Entropy: 1.03584
Value Function Loss: 2.85176

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 12,008.41684
Overall Steps per Second: 10,183.58948

Timestep Collection Time: 4.16475
Timestep Consumption Time: 0.74629
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.91104

Cumulative Model Updates: 53,220
Cumulative Timesteps: 887,739,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,372.62185
Policy Entropy: 1.01427
Value Function Loss: 2.99751

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 12,317.47495
Overall Steps per Second: 10,343.33171

Timestep Collection Time: 4.05944
Timestep Consumption Time: 0.77479
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.83423

Cumulative Model Updates: 53,223
Cumulative Timesteps: 887,789,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 887789568...
Checkpoint 887789568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,840.64953
Policy Entropy: 1.00799
Value Function Loss: 3.29489

Mean KL Divergence: 0.02762
SB3 Clip Fraction: 0.17382
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.07931

Collected Steps per Second: 11,870.17695
Overall Steps per Second: 10,006.91943

Timestep Collection Time: 4.21257
Timestep Consumption Time: 0.78437
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 4.99694

Cumulative Model Updates: 53,226
Cumulative Timesteps: 887,839,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,710.11431
Policy Entropy: 1.02272
Value Function Loss: 3.31206

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 12,066.34434
Overall Steps per Second: 10,240.72039

Timestep Collection Time: 4.14608
Timestep Consumption Time: 0.73913
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 4.88520

Cumulative Model Updates: 53,229
Cumulative Timesteps: 887,889,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887889600...
Checkpoint 887889600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789,349.80180
Policy Entropy: 1.03428
Value Function Loss: 3.32285

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.16038
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 11,966.97311
Overall Steps per Second: 10,133.03313

Timestep Collection Time: 4.17950
Timestep Consumption Time: 0.75643
PPO Batch Consumption Time: 0.03370
Total Iteration Time: 4.93594

Cumulative Model Updates: 53,232
Cumulative Timesteps: 887,939,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,194.27967
Policy Entropy: 1.00290
Value Function Loss: 3.22456

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 12,148.13723
Overall Steps per Second: 10,265.29192

Timestep Collection Time: 4.11750
Timestep Consumption Time: 0.75523
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.87273

Cumulative Model Updates: 53,235
Cumulative Timesteps: 887,989,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 887989636...
Checkpoint 887989636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,644.16515
Policy Entropy: 1.02501
Value Function Loss: 3.26238

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 12,033.45428
Overall Steps per Second: 10,339.92862

Timestep Collection Time: 4.15558
Timestep Consumption Time: 0.68062
PPO Batch Consumption Time: 0.03370
Total Iteration Time: 4.83620

Cumulative Model Updates: 53,238
Cumulative Timesteps: 888,039,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,851.26847
Policy Entropy: 1.02723
Value Function Loss: 3.22869

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 12,048.36405
Overall Steps per Second: 10,153.34260

Timestep Collection Time: 4.15027
Timestep Consumption Time: 0.77461
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.92488

Cumulative Model Updates: 53,241
Cumulative Timesteps: 888,089,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 888089646...
Checkpoint 888089646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,856.33941
Policy Entropy: 1.01497
Value Function Loss: 3.07370

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.15432
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 11,796.61882
Overall Steps per Second: 9,866.33083

Timestep Collection Time: 4.23918
Timestep Consumption Time: 0.82937
PPO Batch Consumption Time: 0.03343
Total Iteration Time: 5.06855

Cumulative Model Updates: 53,244
Cumulative Timesteps: 888,139,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,456.29661
Policy Entropy: 1.00248
Value Function Loss: 2.97170

Mean KL Divergence: 0.03454
SB3 Clip Fraction: 0.18862
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.10322

Collected Steps per Second: 12,153.15050
Overall Steps per Second: 10,205.73594

Timestep Collection Time: 4.11432
Timestep Consumption Time: 0.78508
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.89940

Cumulative Model Updates: 53,247
Cumulative Timesteps: 888,189,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 888189656...
Checkpoint 888189656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775,594.54204
Policy Entropy: 1.01174
Value Function Loss: 2.90612

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 11,755.96432
Overall Steps per Second: 9,897.21988

Timestep Collection Time: 4.25486
Timestep Consumption Time: 0.79908
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.05394

Cumulative Model Updates: 53,250
Cumulative Timesteps: 888,239,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,950.72134
Policy Entropy: 1.01680
Value Function Loss: 2.93483

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.07385
Value Function Update Magnitude: 0.09965

Collected Steps per Second: 12,017.20050
Overall Steps per Second: 10,298.60965

Timestep Collection Time: 4.16237
Timestep Consumption Time: 0.69460
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 4.85697

Cumulative Model Updates: 53,253
Cumulative Timesteps: 888,289,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 888289696...
Checkpoint 888289696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,484.04870
Policy Entropy: 1.01785
Value Function Loss: 3.03279

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.07957
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 12,040.90615
Overall Steps per Second: 10,194.13868

Timestep Collection Time: 4.15367
Timestep Consumption Time: 0.75248
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 4.90615

Cumulative Model Updates: 53,256
Cumulative Timesteps: 888,339,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,089.23303
Policy Entropy: 1.01684
Value Function Loss: 3.07529

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.10799

Collected Steps per Second: 11,987.14590
Overall Steps per Second: 10,161.10328

Timestep Collection Time: 4.17230
Timestep Consumption Time: 0.74980
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.92210

Cumulative Model Updates: 53,259
Cumulative Timesteps: 888,389,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 888389724...
Checkpoint 888389724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766,270.53654
Policy Entropy: 1.02213
Value Function Loss: 3.14109

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.06573
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 12,082.69834
Overall Steps per Second: 10,069.58973

Timestep Collection Time: 4.13815
Timestep Consumption Time: 0.82730
PPO Batch Consumption Time: 0.03801
Total Iteration Time: 4.96545

Cumulative Model Updates: 53,262
Cumulative Timesteps: 888,439,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,154.78910
Policy Entropy: 1.03059
Value Function Loss: 3.19376

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 11,974.58641
Overall Steps per Second: 9,922.41179

Timestep Collection Time: 4.17668
Timestep Consumption Time: 0.86383
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.04051

Cumulative Model Updates: 53,265
Cumulative Timesteps: 888,489,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 888489738...
Checkpoint 888489738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,442.93500
Policy Entropy: 1.03132
Value Function Loss: 3.14135

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 11,948.41639
Overall Steps per Second: 10,220.86866

Timestep Collection Time: 4.18549
Timestep Consumption Time: 0.70744
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 4.89293

Cumulative Model Updates: 53,268
Cumulative Timesteps: 888,539,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794,718.60607
Policy Entropy: 1.03644
Value Function Loss: 3.11075

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.10543

Collected Steps per Second: 12,241.19709
Overall Steps per Second: 10,314.25554

Timestep Collection Time: 4.08686
Timestep Consumption Time: 0.76352
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.85037

Cumulative Model Updates: 53,271
Cumulative Timesteps: 888,589,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 888589776...
Checkpoint 888589776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,328.45467
Policy Entropy: 1.04200
Value Function Loss: 2.98224

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.06925
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 11,953.96366
Overall Steps per Second: 9,999.05244

Timestep Collection Time: 4.18338
Timestep Consumption Time: 0.81789
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.00127

Cumulative Model Updates: 53,274
Cumulative Timesteps: 888,639,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,736.68937
Policy Entropy: 1.04369
Value Function Loss: 3.18361

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.07291
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 12,522.88892
Overall Steps per Second: 10,496.42169

Timestep Collection Time: 3.99413
Timestep Consumption Time: 0.77112
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.76524

Cumulative Model Updates: 53,277
Cumulative Timesteps: 888,689,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 888689802...
Checkpoint 888689802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,666.32693
Policy Entropy: 1.04756
Value Function Loss: 3.40035

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.07253
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 12,204.61768
Overall Steps per Second: 10,303.26275

Timestep Collection Time: 4.09812
Timestep Consumption Time: 0.75626
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 4.85438

Cumulative Model Updates: 53,280
Cumulative Timesteps: 888,739,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,596.02224
Policy Entropy: 1.05255
Value Function Loss: 3.48508

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.10435

Collected Steps per Second: 11,499.34919
Overall Steps per Second: 9,973.89164

Timestep Collection Time: 4.34842
Timestep Consumption Time: 0.66507
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.01349

Cumulative Model Updates: 53,283
Cumulative Timesteps: 888,789,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 888789822...
Checkpoint 888789822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,212.10453
Policy Entropy: 1.05563
Value Function Loss: 3.35881

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 12,050.27906
Overall Steps per Second: 10,209.26587

Timestep Collection Time: 4.15161
Timestep Consumption Time: 0.74865
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.90025

Cumulative Model Updates: 53,286
Cumulative Timesteps: 888,839,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,132.77579
Policy Entropy: 1.05785
Value Function Loss: 3.21530

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.07621
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 11,979.37704
Overall Steps per Second: 10,164.56159

Timestep Collection Time: 4.17651
Timestep Consumption Time: 0.74569
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 4.92220

Cumulative Model Updates: 53,289
Cumulative Timesteps: 888,889,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 888889882...
Checkpoint 888889882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,965.36140
Policy Entropy: 1.06120
Value Function Loss: 3.31951

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.07349
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 12,279.91470
Overall Steps per Second: 10,303.97403

Timestep Collection Time: 4.07381
Timestep Consumption Time: 0.78121
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.85502

Cumulative Model Updates: 53,292
Cumulative Timesteps: 888,939,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,125.28260
Policy Entropy: 1.06559
Value Function Loss: 3.34865

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.07299
Value Function Update Magnitude: 0.11508

Collected Steps per Second: 12,132.04524
Overall Steps per Second: 10,197.13870

Timestep Collection Time: 4.12148
Timestep Consumption Time: 0.78205
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.90353

Cumulative Model Updates: 53,295
Cumulative Timesteps: 888,989,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 888989910...
Checkpoint 888989910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,074.39713
Policy Entropy: 1.06359
Value Function Loss: 3.26538

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.07504
Value Function Update Magnitude: 0.10881

Collected Steps per Second: 12,053.44092
Overall Steps per Second: 10,375.44290

Timestep Collection Time: 4.14902
Timestep Consumption Time: 0.67101
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.82004

Cumulative Model Updates: 53,298
Cumulative Timesteps: 889,039,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,553.94459
Policy Entropy: 1.05620
Value Function Loss: 2.94477

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.07768
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 11,431.63454
Overall Steps per Second: 9,673.06128

Timestep Collection Time: 4.37575
Timestep Consumption Time: 0.79552
PPO Batch Consumption Time: 0.03821
Total Iteration Time: 5.17127

Cumulative Model Updates: 53,301
Cumulative Timesteps: 889,089,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 889089942...
Checkpoint 889089942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,786.22460
Policy Entropy: 1.03966
Value Function Loss: 2.98485

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.07779
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 11,689.85578
Overall Steps per Second: 9,923.18353

Timestep Collection Time: 4.27773
Timestep Consumption Time: 0.76158
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.03931

Cumulative Model Updates: 53,304
Cumulative Timesteps: 889,139,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,184.70603
Policy Entropy: 1.06071
Value Function Loss: 3.11385

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 11,662.07891
Overall Steps per Second: 9,940.87836

Timestep Collection Time: 4.28946
Timestep Consumption Time: 0.74269
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.03215

Cumulative Model Updates: 53,307
Cumulative Timesteps: 889,189,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 889189972...
Checkpoint 889189972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,847.04364
Policy Entropy: 1.05125
Value Function Loss: 3.45521

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.07605
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 11,873.70283
Overall Steps per Second: 10,045.78173

Timestep Collection Time: 4.21183
Timestep Consumption Time: 0.76638
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 4.97821

Cumulative Model Updates: 53,310
Cumulative Timesteps: 889,239,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,420.58340
Policy Entropy: 1.05630
Value Function Loss: 3.47623

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 11,760.05490
Overall Steps per Second: 10,053.30556

Timestep Collection Time: 4.25236
Timestep Consumption Time: 0.72192
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.97428

Cumulative Model Updates: 53,313
Cumulative Timesteps: 889,289,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 889289990...
Checkpoint 889289990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,364.90562
Policy Entropy: 1.04790
Value Function Loss: 3.41152

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.09789

Collected Steps per Second: 11,911.94933
Overall Steps per Second: 10,086.68339

Timestep Collection Time: 4.19814
Timestep Consumption Time: 0.75969
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.95782

Cumulative Model Updates: 53,316
Cumulative Timesteps: 889,339,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577,469.68597
Policy Entropy: 1.04271
Value Function Loss: 3.16891

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 11,524.62881
Overall Steps per Second: 9,834.01091

Timestep Collection Time: 4.34010
Timestep Consumption Time: 0.74613
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.08623

Cumulative Model Updates: 53,319
Cumulative Timesteps: 889,390,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 889390016...
Checkpoint 889390016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,857.44527
Policy Entropy: 1.06295
Value Function Loss: 3.06362

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 11,626.93487
Overall Steps per Second: 10,060.27171

Timestep Collection Time: 4.30139
Timestep Consumption Time: 0.66985
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.97124

Cumulative Model Updates: 53,322
Cumulative Timesteps: 889,440,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,584.49478
Policy Entropy: 1.07050
Value Function Loss: 3.11691

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.09222

Collected Steps per Second: 11,653.49673
Overall Steps per Second: 9,902.03109

Timestep Collection Time: 4.29296
Timestep Consumption Time: 0.75934
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.05230

Cumulative Model Updates: 53,325
Cumulative Timesteps: 889,490,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 889490056...
Checkpoint 889490056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,635.21010
Policy Entropy: 1.05572
Value Function Loss: 3.09399

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 11,883.63420
Overall Steps per Second: 10,031.81100

Timestep Collection Time: 4.20814
Timestep Consumption Time: 0.77680
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 4.98494

Cumulative Model Updates: 53,328
Cumulative Timesteps: 889,540,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,931.40858
Policy Entropy: 1.04672
Value Function Loss: 3.08866

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.17475
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 12,107.49354
Overall Steps per Second: 10,175.78646

Timestep Collection Time: 4.13215
Timestep Consumption Time: 0.78442
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.91657

Cumulative Model Updates: 53,331
Cumulative Timesteps: 889,590,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 889590094...
Checkpoint 889590094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,976.85993
Policy Entropy: 1.06499
Value Function Loss: 3.03485

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.08562

Collected Steps per Second: 11,842.36432
Overall Steps per Second: 9,957.43004

Timestep Collection Time: 4.22281
Timestep Consumption Time: 0.79937
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.02218

Cumulative Model Updates: 53,334
Cumulative Timesteps: 889,640,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,963.77506
Policy Entropy: 1.06059
Value Function Loss: 3.08324

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.08255

Collected Steps per Second: 11,387.32459
Overall Steps per Second: 9,847.86933

Timestep Collection Time: 4.39085
Timestep Consumption Time: 0.68639
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.07724

Cumulative Model Updates: 53,337
Cumulative Timesteps: 889,690,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 889690102...
Checkpoint 889690102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,212.64410
Policy Entropy: 1.06179
Value Function Loss: 2.95069

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 12,060.30180
Overall Steps per Second: 10,128.16744

Timestep Collection Time: 4.14815
Timestep Consumption Time: 0.79134
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.93949

Cumulative Model Updates: 53,340
Cumulative Timesteps: 889,740,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,082.99043
Policy Entropy: 1.05228
Value Function Loss: 3.03473

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.08156

Collected Steps per Second: 12,394.36251
Overall Steps per Second: 10,441.55722

Timestep Collection Time: 4.03458
Timestep Consumption Time: 0.75456
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.78913

Cumulative Model Updates: 53,343
Cumulative Timesteps: 889,790,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 889790136...
Checkpoint 889790136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,425.43436
Policy Entropy: 1.05587
Value Function Loss: 3.10057

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.07948

Collected Steps per Second: 12,768.62680
Overall Steps per Second: 10,666.45258

Timestep Collection Time: 3.91647
Timestep Consumption Time: 0.77187
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 4.68834

Cumulative Model Updates: 53,346
Cumulative Timesteps: 889,840,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,603.14461
Policy Entropy: 1.06648
Value Function Loss: 3.29388

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 12,011.80605
Overall Steps per Second: 10,157.80336

Timestep Collection Time: 4.16424
Timestep Consumption Time: 0.76006
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 4.92429

Cumulative Model Updates: 53,349
Cumulative Timesteps: 889,890,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 889890164...
Checkpoint 889890164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,237.99853
Policy Entropy: 1.06386
Value Function Loss: 3.29103

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 12,560.00087
Overall Steps per Second: 10,713.10239

Timestep Collection Time: 3.98248
Timestep Consumption Time: 0.68657
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.66905

Cumulative Model Updates: 53,352
Cumulative Timesteps: 889,940,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,933.90218
Policy Entropy: 1.05658
Value Function Loss: 3.19301

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 12,100.79308
Overall Steps per Second: 10,243.45687

Timestep Collection Time: 4.13411
Timestep Consumption Time: 0.74959
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.88370

Cumulative Model Updates: 53,355
Cumulative Timesteps: 889,990,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 889990210...
Checkpoint 889990210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776,365.00666
Policy Entropy: 1.05802
Value Function Loss: 3.10006

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.08603

Collected Steps per Second: 12,670.18612
Overall Steps per Second: 10,832.68754

Timestep Collection Time: 3.94769
Timestep Consumption Time: 0.66963
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.61732

Cumulative Model Updates: 53,358
Cumulative Timesteps: 890,040,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,662.25666
Policy Entropy: 1.04820
Value Function Loss: 3.00937

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.17319
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.08545

Collected Steps per Second: 12,038.63919
Overall Steps per Second: 10,141.97693

Timestep Collection Time: 4.15412
Timestep Consumption Time: 0.77687
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.93099

Cumulative Model Updates: 53,361
Cumulative Timesteps: 890,090,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 890090238...
Checkpoint 890090238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,448.68634
Policy Entropy: 1.06798
Value Function Loss: 2.96468

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 11,925.64396
Overall Steps per Second: 10,081.54667

Timestep Collection Time: 4.19516
Timestep Consumption Time: 0.76737
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 4.96253

Cumulative Model Updates: 53,364
Cumulative Timesteps: 890,140,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,357.95539
Policy Entropy: 1.07363
Value Function Loss: 2.89459

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.08524

Collected Steps per Second: 12,156.29945
Overall Steps per Second: 10,187.08794

Timestep Collection Time: 4.11441
Timestep Consumption Time: 0.79533
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.90974

Cumulative Model Updates: 53,367
Cumulative Timesteps: 890,190,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 890190284...
Checkpoint 890190284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798,890.63245
Policy Entropy: 1.05711
Value Function Loss: 2.92085

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 11,981.23054
Overall Steps per Second: 10,062.42271

Timestep Collection Time: 4.17470
Timestep Consumption Time: 0.79607
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.97077

Cumulative Model Updates: 53,370
Cumulative Timesteps: 890,240,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,410.81869
Policy Entropy: 1.05608
Value Function Loss: 2.95310

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.09870

Collected Steps per Second: 11,212.62188
Overall Steps per Second: 9,668.75319

Timestep Collection Time: 4.46069
Timestep Consumption Time: 0.71227
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.17295

Cumulative Model Updates: 53,373
Cumulative Timesteps: 890,290,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 890290318...
Checkpoint 890290318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,161.34222
Policy Entropy: 1.06554
Value Function Loss: 3.16318

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 11,755.68847
Overall Steps per Second: 9,974.96524

Timestep Collection Time: 4.25360
Timestep Consumption Time: 0.75935
PPO Batch Consumption Time: 0.03365
Total Iteration Time: 5.01295

Cumulative Model Updates: 53,376
Cumulative Timesteps: 890,340,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,089.86036
Policy Entropy: 1.06245
Value Function Loss: 3.34128

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 12,000.99758
Overall Steps per Second: 10,218.62331

Timestep Collection Time: 4.16849
Timestep Consumption Time: 0.72708
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.89557

Cumulative Model Updates: 53,379
Cumulative Timesteps: 890,390,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 890390348...
Checkpoint 890390348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,777.94796
Policy Entropy: 1.04737
Value Function Loss: 3.39597

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 12,226.68285
Overall Steps per Second: 10,463.78657

Timestep Collection Time: 4.09023
Timestep Consumption Time: 0.68911
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.77934

Cumulative Model Updates: 53,382
Cumulative Timesteps: 890,440,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,815.11199
Policy Entropy: 1.03193
Value Function Loss: 3.29874

Mean KL Divergence: 0.03197
SB3 Clip Fraction: 0.19263
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 12,172.21835
Overall Steps per Second: 10,225.34742

Timestep Collection Time: 4.11001
Timestep Consumption Time: 0.78253
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.89255

Cumulative Model Updates: 53,385
Cumulative Timesteps: 890,490,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 890490386...
Checkpoint 890490386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,869.08500
Policy Entropy: 1.04147
Value Function Loss: 3.14370

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11,786.91886
Overall Steps per Second: 10,028.07753

Timestep Collection Time: 4.24437
Timestep Consumption Time: 0.74443
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.98879

Cumulative Model Updates: 53,388
Cumulative Timesteps: 890,540,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,726.08328
Policy Entropy: 1.05114
Value Function Loss: 3.01361

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 11,591.41043
Overall Steps per Second: 9,847.91887

Timestep Collection Time: 4.31595
Timestep Consumption Time: 0.76410
PPO Batch Consumption Time: 0.03329
Total Iteration Time: 5.08006

Cumulative Model Updates: 53,391
Cumulative Timesteps: 890,590,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 890590442...
Checkpoint 890590442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,578.30918
Policy Entropy: 1.03251
Value Function Loss: 3.01832

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 11,840.95850
Overall Steps per Second: 9,993.26784

Timestep Collection Time: 4.22483
Timestep Consumption Time: 0.78114
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 5.00597

Cumulative Model Updates: 53,394
Cumulative Timesteps: 890,640,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,556.60941
Policy Entropy: 1.03559
Value Function Loss: 2.94743

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.16157
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 12,047.23698
Overall Steps per Second: 10,334.09496

Timestep Collection Time: 4.15099
Timestep Consumption Time: 0.68813
PPO Batch Consumption Time: 0.03362
Total Iteration Time: 4.83913

Cumulative Model Updates: 53,397
Cumulative Timesteps: 890,690,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890690476...
Checkpoint 890690476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720,790.54477
Policy Entropy: 1.05115
Value Function Loss: 3.06065

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.08693

Collected Steps per Second: 11,987.81157
Overall Steps per Second: 10,106.88636

Timestep Collection Time: 4.17107
Timestep Consumption Time: 0.77625
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.94732

Cumulative Model Updates: 53,400
Cumulative Timesteps: 890,740,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,468.79549
Policy Entropy: 1.05098
Value Function Loss: 3.14255

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 12,073.15276
Overall Steps per Second: 10,341.29519

Timestep Collection Time: 4.14374
Timestep Consumption Time: 0.69395
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.83769

Cumulative Model Updates: 53,403
Cumulative Timesteps: 890,790,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 890790506...
Checkpoint 890790506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,107.96834
Policy Entropy: 1.05659
Value Function Loss: 3.22450

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.08481

Collected Steps per Second: 12,025.27361
Overall Steps per Second: 10,122.12805

Timestep Collection Time: 4.15841
Timestep Consumption Time: 0.78186
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.94027

Cumulative Model Updates: 53,406
Cumulative Timesteps: 890,840,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,816.87205
Policy Entropy: 1.05134
Value Function Loss: 3.28325

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 11,668.17359
Overall Steps per Second: 9,804.37082

Timestep Collection Time: 4.28533
Timestep Consumption Time: 0.81464
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.09997

Cumulative Model Updates: 53,409
Cumulative Timesteps: 890,890,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 890890514...
Checkpoint 890890514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,176.00353
Policy Entropy: 1.05205
Value Function Loss: 3.24679

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.09204

Collected Steps per Second: 12,207.85866
Overall Steps per Second: 10,349.11393

Timestep Collection Time: 4.09638
Timestep Consumption Time: 0.73573
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 4.83210

Cumulative Model Updates: 53,412
Cumulative Timesteps: 890,940,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762,964.30292
Policy Entropy: 1.03829
Value Function Loss: 3.31084

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 12,338.06232
Overall Steps per Second: 10,431.80640

Timestep Collection Time: 4.05299
Timestep Consumption Time: 0.74062
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.79361

Cumulative Model Updates: 53,415
Cumulative Timesteps: 890,990,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890990528...
Checkpoint 890990528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,280.90581
Policy Entropy: 1.05213
Value Function Loss: 3.36719

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.08511

Collected Steps per Second: 12,244.22036
Overall Steps per Second: 10,387.74714

Timestep Collection Time: 4.08585
Timestep Consumption Time: 0.73021
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 4.81606

Cumulative Model Updates: 53,418
Cumulative Timesteps: 891,040,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,596.31452
Policy Entropy: 1.05616
Value Function Loss: 3.23968

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 12,530.15611
Overall Steps per Second: 10,506.51779

Timestep Collection Time: 3.99069
Timestep Consumption Time: 0.76864
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.75933

Cumulative Model Updates: 53,421
Cumulative Timesteps: 891,090,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891090560...
Checkpoint 891090560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,301.54180
Policy Entropy: 1.06407
Value Function Loss: 3.07755

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 12,273.91296
Overall Steps per Second: 10,259.36743

Timestep Collection Time: 4.07433
Timestep Consumption Time: 0.80004
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.87437

Cumulative Model Updates: 53,424
Cumulative Timesteps: 891,140,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,244.03705
Policy Entropy: 1.04756
Value Function Loss: 3.03144

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 11,589.26497
Overall Steps per Second: 10,049.29907

Timestep Collection Time: 4.31537
Timestep Consumption Time: 0.66129
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.97667

Cumulative Model Updates: 53,427
Cumulative Timesteps: 891,190,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 891190580...
Checkpoint 891190580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,683.70583
Policy Entropy: 1.04377
Value Function Loss: 3.10684

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 12,345.32701
Overall Steps per Second: 10,370.89545

Timestep Collection Time: 4.05093
Timestep Consumption Time: 0.77122
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.82215

Cumulative Model Updates: 53,430
Cumulative Timesteps: 891,240,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,138.33936
Policy Entropy: 1.06937
Value Function Loss: 3.16050

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.10688

Collected Steps per Second: 11,801.80061
Overall Steps per Second: 10,011.92478

Timestep Collection Time: 4.23935
Timestep Consumption Time: 0.75789
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.99724

Cumulative Model Updates: 53,433
Cumulative Timesteps: 891,290,622

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 891290622...
Checkpoint 891290622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,662.06361
Policy Entropy: 1.06112
Value Function Loss: 3.27047

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.09427

Collected Steps per Second: 12,281.73370
Overall Steps per Second: 10,344.15789

Timestep Collection Time: 4.07304
Timestep Consumption Time: 0.76293
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.83597

Cumulative Model Updates: 53,436
Cumulative Timesteps: 891,340,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,486.43499
Policy Entropy: 1.05161
Value Function Loss: 3.28964

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 12,047.93794
Overall Steps per Second: 10,198.93116

Timestep Collection Time: 4.15108
Timestep Consumption Time: 0.75257
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.90365

Cumulative Model Updates: 53,439
Cumulative Timesteps: 891,390,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 891390658...
Checkpoint 891390658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,887.76113
Policy Entropy: 1.03714
Value Function Loss: 3.30085

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 12,184.77883
Overall Steps per Second: 10,352.54621

Timestep Collection Time: 4.10512
Timestep Consumption Time: 0.72654
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 4.83166

Cumulative Model Updates: 53,442
Cumulative Timesteps: 891,440,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,319.14956
Policy Entropy: 1.05764
Value Function Loss: 3.11901

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 11,779.71065
Overall Steps per Second: 9,983.20281

Timestep Collection Time: 4.24493
Timestep Consumption Time: 0.76389
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.00881

Cumulative Model Updates: 53,445
Cumulative Timesteps: 891,490,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891490682...
Checkpoint 891490682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,143.28285
Policy Entropy: 1.06218
Value Function Loss: 3.13098

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 11,949.06923
Overall Steps per Second: 10,308.61514

Timestep Collection Time: 4.18543
Timestep Consumption Time: 0.66605
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.85148

Cumulative Model Updates: 53,448
Cumulative Timesteps: 891,540,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,642.50905
Policy Entropy: 1.05139
Value Function Loss: 3.19801

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.08579

Collected Steps per Second: 11,732.54023
Overall Steps per Second: 9,939.13947

Timestep Collection Time: 4.26165
Timestep Consumption Time: 0.76896
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 5.03062

Cumulative Model Updates: 53,451
Cumulative Timesteps: 891,590,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 891590694...
Checkpoint 891590694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,492.86178
Policy Entropy: 1.04529
Value Function Loss: 3.20074

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 11,996.85745
Overall Steps per Second: 10,164.25651

Timestep Collection Time: 4.16909
Timestep Consumption Time: 0.75168
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.92077

Cumulative Model Updates: 53,454
Cumulative Timesteps: 891,640,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,098.98317
Policy Entropy: 1.05543
Value Function Loss: 3.23487

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.09136

Collected Steps per Second: 12,128.76220
Overall Steps per Second: 10,392.31455

Timestep Collection Time: 4.12326
Timestep Consumption Time: 0.68895
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 4.81221

Cumulative Model Updates: 53,457
Cumulative Timesteps: 891,690,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 891690720...
Checkpoint 891690720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,783.57616
Policy Entropy: 1.05169
Value Function Loss: 3.26519

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 12,115.26649
Overall Steps per Second: 10,165.76219

Timestep Collection Time: 4.12934
Timestep Consumption Time: 0.79189
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.92122

Cumulative Model Updates: 53,460
Cumulative Timesteps: 891,740,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,255.94645
Policy Entropy: 1.04536
Value Function Loss: 3.21713

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.08401

Collected Steps per Second: 11,854.26137
Overall Steps per Second: 9,989.98525

Timestep Collection Time: 4.21907
Timestep Consumption Time: 0.78734
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.00641

Cumulative Model Updates: 53,463
Cumulative Timesteps: 891,790,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 891790762...
Checkpoint 891790762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,926.62239
Policy Entropy: 1.03939
Value Function Loss: 3.11466

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 12,294.81129
Overall Steps per Second: 10,332.71508

Timestep Collection Time: 4.06838
Timestep Consumption Time: 0.77255
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.84093

Cumulative Model Updates: 53,466
Cumulative Timesteps: 891,840,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,277.94153
Policy Entropy: 1.02696
Value Function Loss: 2.94866

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.17381
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.08773

Collected Steps per Second: 11,887.67349
Overall Steps per Second: 9,965.11651

Timestep Collection Time: 4.20822
Timestep Consumption Time: 0.81189
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.02011

Cumulative Model Updates: 53,469
Cumulative Timesteps: 891,890,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 891890808...
Checkpoint 891890808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,011.21083
Policy Entropy: 1.04535
Value Function Loss: 3.03371

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.09875

Collected Steps per Second: 11,214.66386
Overall Steps per Second: 9,638.98135

Timestep Collection Time: 4.45898
Timestep Consumption Time: 0.72891
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.18789

Cumulative Model Updates: 53,472
Cumulative Timesteps: 891,940,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,512.62424
Policy Entropy: 1.05318
Value Function Loss: 3.23885

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.08924

Collected Steps per Second: 11,988.37149
Overall Steps per Second: 10,009.01880

Timestep Collection Time: 4.17271
Timestep Consumption Time: 0.82518
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.99789

Cumulative Model Updates: 53,475
Cumulative Timesteps: 891,990,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 891990838...
Checkpoint 891990838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,106.13162
Policy Entropy: 1.04275
Value Function Loss: 3.17298

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 11,797.67031
Overall Steps per Second: 10,062.54700

Timestep Collection Time: 4.23965
Timestep Consumption Time: 0.73106
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.97071

Cumulative Model Updates: 53,478
Cumulative Timesteps: 892,040,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,707.61936
Policy Entropy: 1.03023
Value Function Loss: 3.14093

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.17508
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.08229

Collected Steps per Second: 12,038.20947
Overall Steps per Second: 10,015.11521

Timestep Collection Time: 4.15344
Timestep Consumption Time: 0.83901
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.99245

Cumulative Model Updates: 53,481
Cumulative Timesteps: 892,090,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 892090856...
Checkpoint 892090856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,594.02241
Policy Entropy: 1.04894
Value Function Loss: 3.06021

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.08931

Collected Steps per Second: 12,072.10535
Overall Steps per Second: 10,173.26783

Timestep Collection Time: 4.14195
Timestep Consumption Time: 0.77309
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.91504

Cumulative Model Updates: 53,484
Cumulative Timesteps: 892,140,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,820.44347
Policy Entropy: 1.05755
Value Function Loss: 3.29838

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 12,106.86696
Overall Steps per Second: 10,393.83684

Timestep Collection Time: 4.13071
Timestep Consumption Time: 0.68079
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.81151

Cumulative Model Updates: 53,487
Cumulative Timesteps: 892,190,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 892190868...
Checkpoint 892190868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,656.26859
Policy Entropy: 1.04271
Value Function Loss: 3.36184

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 11,950.56445
Overall Steps per Second: 9,997.77969

Timestep Collection Time: 4.18541
Timestep Consumption Time: 0.81750
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.00291

Cumulative Model Updates: 53,490
Cumulative Timesteps: 892,240,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,551.97974
Policy Entropy: 1.04144
Value Function Loss: 3.45143

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 12,858.05174
Overall Steps per Second: 10,780.12161

Timestep Collection Time: 3.88861
Timestep Consumption Time: 0.74955
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.63817

Cumulative Model Updates: 53,493
Cumulative Timesteps: 892,290,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 892290886...
Checkpoint 892290886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,207.93833
Policy Entropy: 1.04619
Value Function Loss: 3.31084

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 12,825.50079
Overall Steps per Second: 10,783.91877

Timestep Collection Time: 3.90067
Timestep Consumption Time: 0.73846
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.63913

Cumulative Model Updates: 53,496
Cumulative Timesteps: 892,340,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,263.97284
Policy Entropy: 1.05040
Value Function Loss: 3.17094

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 12,202.80959
Overall Steps per Second: 10,357.37799

Timestep Collection Time: 4.09955
Timestep Consumption Time: 0.73044
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.82999

Cumulative Model Updates: 53,499
Cumulative Timesteps: 892,390,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 892390940...
Checkpoint 892390940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,971.50324
Policy Entropy: 1.02613
Value Function Loss: 3.02805

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 12,426.06771
Overall Steps per Second: 10,617.70862

Timestep Collection Time: 4.02412
Timestep Consumption Time: 0.68537
PPO Batch Consumption Time: 0.03305
Total Iteration Time: 4.70949

Cumulative Model Updates: 53,502
Cumulative Timesteps: 892,440,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,787.38764
Policy Entropy: 1.02955
Value Function Loss: 2.95502

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.09631

Collected Steps per Second: 12,923.87766
Overall Steps per Second: 10,779.70443

Timestep Collection Time: 3.86881
Timestep Consumption Time: 0.76954
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.63835

Cumulative Model Updates: 53,505
Cumulative Timesteps: 892,490,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 892490944...
Checkpoint 892490944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,947.95839
Policy Entropy: 1.03997
Value Function Loss: 3.04497

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 11,875.95366
Overall Steps per Second: 9,971.01338

Timestep Collection Time: 4.21238
Timestep Consumption Time: 0.80477
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.01714

Cumulative Model Updates: 53,508
Cumulative Timesteps: 892,540,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,296.16323
Policy Entropy: 1.03994
Value Function Loss: 3.11849

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.09086

Collected Steps per Second: 12,195.48761
Overall Steps per Second: 10,203.23441

Timestep Collection Time: 4.10217
Timestep Consumption Time: 0.80098
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.90315

Cumulative Model Updates: 53,511
Cumulative Timesteps: 892,590,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 892590998...
Checkpoint 892590998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,477.63380
Policy Entropy: 1.03833
Value Function Loss: 3.15404

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.10085

Collected Steps per Second: 11,950.56249
Overall Steps per Second: 10,159.25736

Timestep Collection Time: 4.18574
Timestep Consumption Time: 0.73804
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.92379

Cumulative Model Updates: 53,514
Cumulative Timesteps: 892,641,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,731.11681
Policy Entropy: 1.03630
Value Function Loss: 3.06675

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 12,048.22005
Overall Steps per Second: 10,385.30533

Timestep Collection Time: 4.15115
Timestep Consumption Time: 0.66469
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.81584

Cumulative Model Updates: 53,517
Cumulative Timesteps: 892,691,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 892691034...
Checkpoint 892691034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,829.72932
Policy Entropy: 1.03811
Value Function Loss: 3.04348

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 11,242.63748
Overall Steps per Second: 9,551.24853

Timestep Collection Time: 4.44735
Timestep Consumption Time: 0.78756
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.23492

Cumulative Model Updates: 53,520
Cumulative Timesteps: 892,741,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,340.61751
Policy Entropy: 1.04584
Value Function Loss: 3.07634

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.16195
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.09519

Collected Steps per Second: 11,854.27868
Overall Steps per Second: 10,058.94705

Timestep Collection Time: 4.21974
Timestep Consumption Time: 0.75314
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.97289

Cumulative Model Updates: 53,523
Cumulative Timesteps: 892,791,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 892791056...
Checkpoint 892791056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,234.10413
Policy Entropy: 1.05131
Value Function Loss: 3.08193

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.10749

Collected Steps per Second: 12,116.19953
Overall Steps per Second: 10,154.71443

Timestep Collection Time: 4.12803
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 4.92540

Cumulative Model Updates: 53,526
Cumulative Timesteps: 892,841,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,019.50417
Policy Entropy: 1.05186
Value Function Loss: 2.97946

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 11,837.26235
Overall Steps per Second: 10,008.52474

Timestep Collection Time: 4.22530
Timestep Consumption Time: 0.77204
PPO Batch Consumption Time: 0.03817
Total Iteration Time: 4.99734

Cumulative Model Updates: 53,529
Cumulative Timesteps: 892,891,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 892891088...
Checkpoint 892891088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,898.10705
Policy Entropy: 1.05453
Value Function Loss: 3.13705

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.11660

Collected Steps per Second: 12,128.12667
Overall Steps per Second: 10,414.25011

Timestep Collection Time: 4.12446
Timestep Consumption Time: 0.67876
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.80323

Cumulative Model Updates: 53,532
Cumulative Timesteps: 892,941,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,293.18883
Policy Entropy: 1.05953
Value Function Loss: 3.21271

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11,881.16968
Overall Steps per Second: 10,006.17320

Timestep Collection Time: 4.21053
Timestep Consumption Time: 0.78899
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.99951

Cumulative Model Updates: 53,535
Cumulative Timesteps: 892,991,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 892991136...
Checkpoint 892991136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,368.72642
Policy Entropy: 1.05475
Value Function Loss: 3.45325

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.10078

Collected Steps per Second: 11,285.79348
Overall Steps per Second: 9,709.02835

Timestep Collection Time: 4.43088
Timestep Consumption Time: 0.71958
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.15046

Cumulative Model Updates: 53,538
Cumulative Timesteps: 893,041,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,191.82359
Policy Entropy: 1.05958
Value Function Loss: 3.40103

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.10009

Collected Steps per Second: 12,025.68689
Overall Steps per Second: 10,162.25096

Timestep Collection Time: 4.15843
Timestep Consumption Time: 0.76253
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.92096

Cumulative Model Updates: 53,541
Cumulative Timesteps: 893,091,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 893091150...
Checkpoint 893091150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,705.15203
Policy Entropy: 1.05705
Value Function Loss: 3.37844

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.09195

Collected Steps per Second: 11,750.73440
Overall Steps per Second: 9,915.12023

Timestep Collection Time: 4.25505
Timestep Consumption Time: 0.78775
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.04280

Cumulative Model Updates: 53,544
Cumulative Timesteps: 893,141,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,238.12606
Policy Entropy: 1.06418
Value Function Loss: 3.34567

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 11,883.13669
Overall Steps per Second: 10,174.04443

Timestep Collection Time: 4.20882
Timestep Consumption Time: 0.70702
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 4.91584

Cumulative Model Updates: 53,547
Cumulative Timesteps: 893,191,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 893191164...
Checkpoint 893191164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,382.34278
Policy Entropy: 1.06405
Value Function Loss: 3.22973

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 12,005.15181
Overall Steps per Second: 10,117.98816

Timestep Collection Time: 4.16521
Timestep Consumption Time: 0.77688
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.94209

Cumulative Model Updates: 53,550
Cumulative Timesteps: 893,241,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,491.82680
Policy Entropy: 1.05758
Value Function Loss: 3.16067

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.08633

Collected Steps per Second: 11,904.13923
Overall Steps per Second: 10,089.21190

Timestep Collection Time: 4.20039
Timestep Consumption Time: 0.75560
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.95599

Cumulative Model Updates: 53,553
Cumulative Timesteps: 893,291,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 893291170...
Checkpoint 893291170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,659.64010
Policy Entropy: 1.07251
Value Function Loss: 3.14441

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.09272

Collected Steps per Second: 11,695.12051
Overall Steps per Second: 9,805.12500

Timestep Collection Time: 4.27700
Timestep Consumption Time: 0.82442
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.10141

Cumulative Model Updates: 53,556
Cumulative Timesteps: 893,341,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,116.15365
Policy Entropy: 1.07564
Value Function Loss: 3.17435

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.09418

Collected Steps per Second: 12,106.28317
Overall Steps per Second: 10,212.57828

Timestep Collection Time: 4.13141
Timestep Consumption Time: 0.76608
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.89749

Cumulative Model Updates: 53,559
Cumulative Timesteps: 893,391,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 893391206...
Checkpoint 893391206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,341.70060
Policy Entropy: 1.06916
Value Function Loss: 3.20339

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 11,762.92492
Overall Steps per Second: 10,163.22761

Timestep Collection Time: 4.25149
Timestep Consumption Time: 0.66919
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.92068

Cumulative Model Updates: 53,562
Cumulative Timesteps: 893,441,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,044.79182
Policy Entropy: 1.05766
Value Function Loss: 3.22376

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.17063
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 11,621.73905
Overall Steps per Second: 9,906.45746

Timestep Collection Time: 4.30245
Timestep Consumption Time: 0.74496
PPO Batch Consumption Time: 0.03381
Total Iteration Time: 5.04741

Cumulative Model Updates: 53,565
Cumulative Timesteps: 893,491,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 893491218...
Checkpoint 893491218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,113.21361
Policy Entropy: 1.06159
Value Function Loss: 3.21887

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 11,111.89215
Overall Steps per Second: 9,603.43506

Timestep Collection Time: 4.50256
Timestep Consumption Time: 0.70724
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.20980

Cumulative Model Updates: 53,568
Cumulative Timesteps: 893,541,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747,396.47327
Policy Entropy: 1.06555
Value Function Loss: 3.28338

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 11,760.25912
Overall Steps per Second: 9,971.01545

Timestep Collection Time: 4.25161
Timestep Consumption Time: 0.76293
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.01453

Cumulative Model Updates: 53,571
Cumulative Timesteps: 893,591,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893591250...
Checkpoint 893591250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,379.12844
Policy Entropy: 1.04424
Value Function Loss: 3.29486

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.09885

Collected Steps per Second: 11,101.74780
Overall Steps per Second: 9,488.45010

Timestep Collection Time: 4.50506
Timestep Consumption Time: 0.76598
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.27104

Cumulative Model Updates: 53,574
Cumulative Timesteps: 893,641,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,147.84652
Policy Entropy: 1.03829
Value Function Loss: 3.18561

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.19195
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.10457

Collected Steps per Second: 11,579.60146
Overall Steps per Second: 10,016.00197

Timestep Collection Time: 4.31794
Timestep Consumption Time: 0.67407
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.99201

Cumulative Model Updates: 53,577
Cumulative Timesteps: 893,691,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893691264...
Checkpoint 893691264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,709.56964
Policy Entropy: 1.05606
Value Function Loss: 3.11969

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.10198

Collected Steps per Second: 11,291.48314
Overall Steps per Second: 9,602.99769

Timestep Collection Time: 4.42918
Timestep Consumption Time: 0.77878
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.20796

Cumulative Model Updates: 53,580
Cumulative Timesteps: 893,741,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,920.05601
Policy Entropy: 1.06491
Value Function Loss: 2.99597

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 11,926.42362
Overall Steps per Second: 10,069.85370

Timestep Collection Time: 4.19321
Timestep Consumption Time: 0.77310
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.96631

Cumulative Model Updates: 53,583
Cumulative Timesteps: 893,791,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 893791286...
Checkpoint 893791286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,183.64662
Policy Entropy: 1.04303
Value Function Loss: 3.07707

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 12,359.98489
Overall Steps per Second: 10,332.72375

Timestep Collection Time: 4.04547
Timestep Consumption Time: 0.79371
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.83919

Cumulative Model Updates: 53,586
Cumulative Timesteps: 893,841,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,695.15034
Policy Entropy: 1.04899
Value Function Loss: 3.05184

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.15139
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.08522

Collected Steps per Second: 12,137.04145
Overall Steps per Second: 10,303.78256

Timestep Collection Time: 4.12077
Timestep Consumption Time: 0.73317
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.85395

Cumulative Model Updates: 53,589
Cumulative Timesteps: 893,891,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 893891302...
Checkpoint 893891302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,535.67724
Policy Entropy: 1.05103
Value Function Loss: 3.20544

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.08114

Collected Steps per Second: 11,297.04685
Overall Steps per Second: 9,774.67966

Timestep Collection Time: 4.42859
Timestep Consumption Time: 0.68974
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.11833

Cumulative Model Updates: 53,592
Cumulative Timesteps: 893,941,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,418.76470
Policy Entropy: 1.05258
Value Function Loss: 3.15089

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07345

Collected Steps per Second: 11,970.10594
Overall Steps per Second: 10,148.63366

Timestep Collection Time: 4.17874
Timestep Consumption Time: 0.75000
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.92874

Cumulative Model Updates: 53,595
Cumulative Timesteps: 893,991,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 893991352...
Checkpoint 893991352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,908.89875
Policy Entropy: 1.06112
Value Function Loss: 3.21408

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 12,011.52838
Overall Steps per Second: 10,100.86440

Timestep Collection Time: 4.16267
Timestep Consumption Time: 0.78740
PPO Batch Consumption Time: 0.04804
Total Iteration Time: 4.95007

Cumulative Model Updates: 53,598
Cumulative Timesteps: 894,041,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,021.46621
Policy Entropy: 1.06244
Value Function Loss: 3.10631

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.06742
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 12,030.27915
Overall Steps per Second: 10,366.92283

Timestep Collection Time: 4.15817
Timestep Consumption Time: 0.66717
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 4.82535

Cumulative Model Updates: 53,601
Cumulative Timesteps: 894,091,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 894091376...
Checkpoint 894091376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,152.24135
Policy Entropy: 1.06248
Value Function Loss: 3.16991

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.07346
Value Function Update Magnitude: 0.08242

Collected Steps per Second: 11,968.69101
Overall Steps per Second: 10,102.44057

Timestep Collection Time: 4.17874
Timestep Consumption Time: 0.77195
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.95068

Cumulative Model Updates: 53,604
Cumulative Timesteps: 894,141,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,776.87444
Policy Entropy: 1.05352
Value Function Loss: 3.16450

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 11,775.23747
Overall Steps per Second: 10,027.77576

Timestep Collection Time: 4.24773
Timestep Consumption Time: 0.74022
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.98795

Cumulative Model Updates: 53,607
Cumulative Timesteps: 894,191,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 894191408...
Checkpoint 894191408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,901.40357
Policy Entropy: 1.06389
Value Function Loss: 3.20094

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.09369

Collected Steps per Second: 11,609.34909
Overall Steps per Second: 9,858.67200

Timestep Collection Time: 4.30739
Timestep Consumption Time: 0.76490
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.07229

Cumulative Model Updates: 53,610
Cumulative Timesteps: 894,241,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,722.92796
Policy Entropy: 1.06415
Value Function Loss: 3.16484

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.09155

Collected Steps per Second: 11,983.53707
Overall Steps per Second: 10,198.04927

Timestep Collection Time: 4.17289
Timestep Consumption Time: 0.73060
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.90349

Cumulative Model Updates: 53,613
Cumulative Timesteps: 894,291,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 894291420...
Checkpoint 894291420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,697.21752
Policy Entropy: 1.06177
Value Function Loss: 3.17770

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 11,751.49005
Overall Steps per Second: 10,163.87160

Timestep Collection Time: 4.25648
Timestep Consumption Time: 0.66487
PPO Batch Consumption Time: 0.03332
Total Iteration Time: 4.92135

Cumulative Model Updates: 53,616
Cumulative Timesteps: 894,341,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,947.17656
Policy Entropy: 1.06609
Value Function Loss: 3.24280

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.07239
Value Function Update Magnitude: 0.08401

Collected Steps per Second: 11,929.22252
Overall Steps per Second: 10,001.74276

Timestep Collection Time: 4.19172
Timestep Consumption Time: 0.80781
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.99953

Cumulative Model Updates: 53,619
Cumulative Timesteps: 894,391,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 894391444...
Checkpoint 894391444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,084.96326
Policy Entropy: 1.06977
Value Function Loss: 3.22466

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 11,958.79608
Overall Steps per Second: 10,179.41281

Timestep Collection Time: 4.18152
Timestep Consumption Time: 0.73094
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.91246

Cumulative Model Updates: 53,622
Cumulative Timesteps: 894,441,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751,361.80367
Policy Entropy: 1.07998
Value Function Loss: 3.25895

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.08443

Collected Steps per Second: 12,049.22556
Overall Steps per Second: 10,320.52954

Timestep Collection Time: 4.15180
Timestep Consumption Time: 0.69543
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.84723

Cumulative Model Updates: 53,625
Cumulative Timesteps: 894,491,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 894491476...
Checkpoint 894491476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,736.11597
Policy Entropy: 1.08021
Value Function Loss: 3.08227

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.10530

Collected Steps per Second: 11,441.92120
Overall Steps per Second: 9,645.76515

Timestep Collection Time: 4.37007
Timestep Consumption Time: 0.81376
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.18383

Cumulative Model Updates: 53,628
Cumulative Timesteps: 894,541,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,025.28837
Policy Entropy: 1.08023
Value Function Loss: 3.20862

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.07947
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 11,706.21911
Overall Steps per Second: 9,858.38359

Timestep Collection Time: 4.27294
Timestep Consumption Time: 0.80091
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.07385

Cumulative Model Updates: 53,631
Cumulative Timesteps: 894,591,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 894591498...
Checkpoint 894591498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,687.92707
Policy Entropy: 1.07593
Value Function Loss: 3.14162

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.07748
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 12,631.71755
Overall Steps per Second: 10,626.92164

Timestep Collection Time: 3.95829
Timestep Consumption Time: 0.74674
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.70503

Cumulative Model Updates: 53,634
Cumulative Timesteps: 894,641,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,952.68500
Policy Entropy: 1.08467
Value Function Loss: 3.11898

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.11278

Collected Steps per Second: 12,400.30450
Overall Steps per Second: 10,375.85886

Timestep Collection Time: 4.03393
Timestep Consumption Time: 0.78707
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.82100

Cumulative Model Updates: 53,637
Cumulative Timesteps: 894,691,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 894691520...
Checkpoint 894691520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,237.07969
Policy Entropy: 1.08987
Value Function Loss: 3.03098

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 12,592.17867
Overall Steps per Second: 10,724.16980

Timestep Collection Time: 3.97262
Timestep Consumption Time: 0.69198
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.66460

Cumulative Model Updates: 53,640
Cumulative Timesteps: 894,741,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,152.33378
Policy Entropy: 1.09502
Value Function Loss: 3.13785

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 12,733.17512
Overall Steps per Second: 10,533.96288

Timestep Collection Time: 3.92864
Timestep Consumption Time: 0.82019
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.74883

Cumulative Model Updates: 53,643
Cumulative Timesteps: 894,791,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 894791568...
Checkpoint 894791568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,988.64964
Policy Entropy: 1.08929
Value Function Loss: 3.34851

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11,895.87888
Overall Steps per Second: 10,021.45603

Timestep Collection Time: 4.20465
Timestep Consumption Time: 0.78644
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.99109

Cumulative Model Updates: 53,646
Cumulative Timesteps: 894,841,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,614.27411
Policy Entropy: 1.09271
Value Function Loss: 3.41435

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 12,847.12017
Overall Steps per Second: 10,663.87198

Timestep Collection Time: 3.89332
Timestep Consumption Time: 0.79709
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.69042

Cumulative Model Updates: 53,649
Cumulative Timesteps: 894,891,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 894891604...
Checkpoint 894891604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,516.10689
Policy Entropy: 1.09087
Value Function Loss: 3.29650

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.07194
Value Function Update Magnitude: 0.11135

Collected Steps per Second: 12,138.41541
Overall Steps per Second: 10,239.41885

Timestep Collection Time: 4.11965
Timestep Consumption Time: 0.76403
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.88368

Cumulative Model Updates: 53,652
Cumulative Timesteps: 894,941,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,017.38739
Policy Entropy: 1.09718
Value Function Loss: 3.26730

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.06408
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 11,849.36615
Overall Steps per Second: 10,183.31888

Timestep Collection Time: 4.22065
Timestep Consumption Time: 0.69052
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.91117

Cumulative Model Updates: 53,655
Cumulative Timesteps: 894,991,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 894991622...
Checkpoint 894991622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,813.44842
Policy Entropy: 1.11091
Value Function Loss: 3.10163

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.11202

Collected Steps per Second: 11,923.20949
Overall Steps per Second: 10,040.89029

Timestep Collection Time: 4.19367
Timestep Consumption Time: 0.78617
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.97984

Cumulative Model Updates: 53,658
Cumulative Timesteps: 895,041,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,877.90919
Policy Entropy: 1.10975
Value Function Loss: 3.03379

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.10997

Collected Steps per Second: 12,048.45682
Overall Steps per Second: 10,297.63792

Timestep Collection Time: 4.15223
Timestep Consumption Time: 0.70597
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 4.85820

Cumulative Model Updates: 53,661
Cumulative Timesteps: 895,091,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 895091652...
Checkpoint 895091652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,133.60765
Policy Entropy: 1.09607
Value Function Loss: 3.00379

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 11,276.63193
Overall Steps per Second: 9,541.86550

Timestep Collection Time: 4.43537
Timestep Consumption Time: 0.80638
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.24174

Cumulative Model Updates: 53,664
Cumulative Timesteps: 895,141,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,879.09259
Policy Entropy: 1.07819
Value Function Loss: 3.04944

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.18697
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.09142

Collected Steps per Second: 11,627.12630
Overall Steps per Second: 9,834.50563

Timestep Collection Time: 4.30304
Timestep Consumption Time: 0.78435
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.08739

Cumulative Model Updates: 53,667
Cumulative Timesteps: 895,191,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 895191700...
Checkpoint 895191700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,544.21585
Policy Entropy: 1.09208
Value Function Loss: 3.17795

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.08721

Collected Steps per Second: 11,761.74003
Overall Steps per Second: 10,130.26988

Timestep Collection Time: 4.25192
Timestep Consumption Time: 0.68477
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.93669

Cumulative Model Updates: 53,670
Cumulative Timesteps: 895,241,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,495.17239
Policy Entropy: 1.08613
Value Function Loss: 3.20200

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.09007

Collected Steps per Second: 12,020.52537
Overall Steps per Second: 10,101.28045

Timestep Collection Time: 4.16022
Timestep Consumption Time: 0.79044
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.95066

Cumulative Model Updates: 53,673
Cumulative Timesteps: 895,291,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 895291718...
Checkpoint 895291718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,609.76911
Policy Entropy: 1.07778
Value Function Loss: 3.15450

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 11,949.75806
Overall Steps per Second: 10,073.06741

Timestep Collection Time: 4.18485
Timestep Consumption Time: 0.77967
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.96453

Cumulative Model Updates: 53,676
Cumulative Timesteps: 895,341,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,688.47900
Policy Entropy: 1.06309
Value Function Loss: 3.07712

Mean KL Divergence: 0.03015
SB3 Clip Fraction: 0.17495
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 11,732.72282
Overall Steps per Second: 9,912.64425

Timestep Collection Time: 4.26380
Timestep Consumption Time: 0.78288
PPO Batch Consumption Time: 0.03365
Total Iteration Time: 5.04669

Cumulative Model Updates: 53,679
Cumulative Timesteps: 895,391,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 895391752...
Checkpoint 895391752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,626.21671
Policy Entropy: 1.07823
Value Function Loss: 2.99950

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.07899

Collected Steps per Second: 11,403.41931
Overall Steps per Second: 9,683.18828

Timestep Collection Time: 4.38570
Timestep Consumption Time: 0.77913
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.16483

Cumulative Model Updates: 53,682
Cumulative Timesteps: 895,441,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,632.93872
Policy Entropy: 1.08892
Value Function Loss: 3.09447

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.09158

Collected Steps per Second: 11,962.05579
Overall Steps per Second: 10,275.63412

Timestep Collection Time: 4.18105
Timestep Consumption Time: 0.68619
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.86724

Cumulative Model Updates: 53,685
Cumulative Timesteps: 895,491,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 895491778...
Checkpoint 895491778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,917.83863
Policy Entropy: 1.07082
Value Function Loss: 3.01969

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.10100

Collected Steps per Second: 11,935.57025
Overall Steps per Second: 10,030.80762

Timestep Collection Time: 4.19150
Timestep Consumption Time: 0.79593
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.98743

Cumulative Model Updates: 53,688
Cumulative Timesteps: 895,541,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,521.34528
Policy Entropy: 1.07797
Value Function Loss: 3.15668

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 12,015.31510
Overall Steps per Second: 10,130.50596

Timestep Collection Time: 4.16319
Timestep Consumption Time: 0.77457
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 4.93776

Cumulative Model Updates: 53,691
Cumulative Timesteps: 895,591,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 895591828...
Checkpoint 895591828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,969.39708
Policy Entropy: 1.08381
Value Function Loss: 3.04258

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 11,620.33908
Overall Steps per Second: 9,964.97836

Timestep Collection Time: 4.30521
Timestep Consumption Time: 0.71517
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.02038

Cumulative Model Updates: 53,694
Cumulative Timesteps: 895,641,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,442.42199
Policy Entropy: 1.08988
Value Function Loss: 3.08292

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.09206

Collected Steps per Second: 11,860.41049
Overall Steps per Second: 9,954.54980

Timestep Collection Time: 4.21756
Timestep Consumption Time: 0.80748
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.02504

Cumulative Model Updates: 53,697
Cumulative Timesteps: 895,691,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 895691878...
Checkpoint 895691878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,944.23546
Policy Entropy: 1.07503
Value Function Loss: 3.00166

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.18049
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 11,246.06003
Overall Steps per Second: 9,622.75691

Timestep Collection Time: 4.44636
Timestep Consumption Time: 0.75007
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.19643

Cumulative Model Updates: 53,700
Cumulative Timesteps: 895,741,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,427.46145
Policy Entropy: 1.08894
Value Function Loss: 3.16336

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 12,000.06393
Overall Steps per Second: 10,111.50132

Timestep Collection Time: 4.16698
Timestep Consumption Time: 0.77828
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.94526

Cumulative Model Updates: 53,703
Cumulative Timesteps: 895,791,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895791886...
Checkpoint 895791886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,268.00590
Policy Entropy: 1.09338
Value Function Loss: 3.20705

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.09914

Collected Steps per Second: 12,160.64142
Overall Steps per Second: 10,280.90165

Timestep Collection Time: 4.11409
Timestep Consumption Time: 0.75221
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.86630

Cumulative Model Updates: 53,706
Cumulative Timesteps: 895,841,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,164.40769
Policy Entropy: 1.08546
Value Function Loss: 3.16649

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 12,065.73076
Overall Steps per Second: 10,394.52986

Timestep Collection Time: 4.14645
Timestep Consumption Time: 0.66665
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 4.81311

Cumulative Model Updates: 53,709
Cumulative Timesteps: 895,891,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 895891946...
Checkpoint 895891946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,171.90752
Policy Entropy: 1.08117
Value Function Loss: 3.13743

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 11,972.56322
Overall Steps per Second: 10,078.62659

Timestep Collection Time: 4.17705
Timestep Consumption Time: 0.78494
PPO Batch Consumption Time: 0.03341
Total Iteration Time: 4.96199

Cumulative Model Updates: 53,712
Cumulative Timesteps: 895,941,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,968.27387
Policy Entropy: 1.08656
Value Function Loss: 2.99095

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 12,133.94042
Overall Steps per Second: 10,253.60951

Timestep Collection Time: 4.12100
Timestep Consumption Time: 0.75572
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.87672

Cumulative Model Updates: 53,715
Cumulative Timesteps: 895,991,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895991960...
Checkpoint 895991960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,595.33537
Policy Entropy: 1.09519
Value Function Loss: 2.92238

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.09431

Collected Steps per Second: 11,717.65282
Overall Steps per Second: 9,888.98536

Timestep Collection Time: 4.26877
Timestep Consumption Time: 0.78938
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.05815

Cumulative Model Updates: 53,718
Cumulative Timesteps: 896,041,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,188.88166
Policy Entropy: 1.07430
Value Function Loss: 2.88707

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 12,125.54688
Overall Steps per Second: 10,200.03486

Timestep Collection Time: 4.12452
Timestep Consumption Time: 0.77861
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.90312

Cumulative Model Updates: 53,721
Cumulative Timesteps: 896,091,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 896091992...
Checkpoint 896091992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,990.35797
Policy Entropy: 1.07398
Value Function Loss: 3.12328

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.11116

Collected Steps per Second: 11,823.00930
Overall Steps per Second: 10,157.40773

Timestep Collection Time: 4.22972
Timestep Consumption Time: 0.69359
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.92330

Cumulative Model Updates: 53,724
Cumulative Timesteps: 896,142,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,215.44464
Policy Entropy: 1.08269
Value Function Loss: 3.29795

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 11,781.66636
Overall Steps per Second: 9,978.32457

Timestep Collection Time: 4.24558
Timestep Consumption Time: 0.76729
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.01287

Cumulative Model Updates: 53,727
Cumulative Timesteps: 896,192,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 896192020...
Checkpoint 896192020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,873.80090
Policy Entropy: 1.08771
Value Function Loss: 3.37466

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.09269

Collected Steps per Second: 11,891.20699
Overall Steps per Second: 10,093.95843

Timestep Collection Time: 4.20529
Timestep Consumption Time: 0.74876
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.95405

Cumulative Model Updates: 53,730
Cumulative Timesteps: 896,242,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,581.60898
Policy Entropy: 1.04820
Value Function Loss: 3.40561

Mean KL Divergence: 0.06453
SB3 Clip Fraction: 0.27108
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.09370

Collected Steps per Second: 12,312.04645
Overall Steps per Second: 10,374.86981

Timestep Collection Time: 4.06220
Timestep Consumption Time: 0.75849
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.82069

Cumulative Model Updates: 53,733
Cumulative Timesteps: 896,292,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 896292040...
Checkpoint 896292040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,343.69697
Policy Entropy: 1.07909
Value Function Loss: 3.37982

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.17359
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.09944

Collected Steps per Second: 11,068.29247
Overall Steps per Second: 9,449.39712

Timestep Collection Time: 4.51922
Timestep Consumption Time: 0.77424
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.29346

Cumulative Model Updates: 53,736
Cumulative Timesteps: 896,342,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,463.28102
Policy Entropy: 1.05284
Value Function Loss: 3.38248

Mean KL Divergence: 0.03689
SB3 Clip Fraction: 0.21321
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.09286

Collected Steps per Second: 11,834.24699
Overall Steps per Second: 10,200.46916

Timestep Collection Time: 4.22570
Timestep Consumption Time: 0.67682
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 4.90252

Cumulative Model Updates: 53,739
Cumulative Timesteps: 896,392,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 896392068...
Checkpoint 896392068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,793.50218
Policy Entropy: 1.06999
Value Function Loss: 3.31136

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 12,066.91355
Overall Steps per Second: 10,202.13430

Timestep Collection Time: 4.14538
Timestep Consumption Time: 0.75771
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.90309

Cumulative Model Updates: 53,742
Cumulative Timesteps: 896,442,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,267.34644
Policy Entropy: 1.06562
Value Function Loss: 3.27330

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 12,071.38737
Overall Steps per Second: 10,229.04676

Timestep Collection Time: 4.14352
Timestep Consumption Time: 0.74628
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.88980

Cumulative Model Updates: 53,745
Cumulative Timesteps: 896,492,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 896492108...
Checkpoint 896492108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,650.59185
Policy Entropy: 1.06048
Value Function Loss: 3.14164

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.08784

Collected Steps per Second: 12,111.14255
Overall Steps per Second: 10,164.12249

Timestep Collection Time: 4.12909
Timestep Consumption Time: 0.79096
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.92005

Cumulative Model Updates: 53,748
Cumulative Timesteps: 896,542,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,084.79807
Policy Entropy: 1.04850
Value Function Loss: 3.06605

Mean KL Divergence: 0.03364
SB3 Clip Fraction: 0.20097
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 11,883.20671
Overall Steps per Second: 10,060.62303

Timestep Collection Time: 4.20880
Timestep Consumption Time: 0.76247
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.97126

Cumulative Model Updates: 53,751
Cumulative Timesteps: 896,592,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 896592130...
Checkpoint 896592130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,685.68773
Policy Entropy: 1.06405
Value Function Loss: 3.05617

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 11,364.38853
Overall Steps per Second: 9,815.65492

Timestep Collection Time: 4.40094
Timestep Consumption Time: 0.69439
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.09533

Cumulative Model Updates: 53,754
Cumulative Timesteps: 896,642,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,169.91314
Policy Entropy: 1.07267
Value Function Loss: 3.19172

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11,918.71817
Overall Steps per Second: 10,089.67409

Timestep Collection Time: 4.19542
Timestep Consumption Time: 0.76054
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.95596

Cumulative Model Updates: 53,757
Cumulative Timesteps: 896,692,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 896692148...
Checkpoint 896692148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,171.57016
Policy Entropy: 1.06068
Value Function Loss: 3.18389

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.08205

Collected Steps per Second: 11,850.35655
Overall Steps per Second: 10,079.15632

Timestep Collection Time: 4.22063
Timestep Consumption Time: 0.74169
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.96232

Cumulative Model Updates: 53,760
Cumulative Timesteps: 896,742,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,845.38855
Policy Entropy: 1.05339
Value Function Loss: 3.12462

Mean KL Divergence: 0.03055
SB3 Clip Fraction: 0.17605
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.08872

Collected Steps per Second: 11,763.36851
Overall Steps per Second: 10,081.55267

Timestep Collection Time: 4.25065
Timestep Consumption Time: 0.70910
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.95975

Cumulative Model Updates: 53,763
Cumulative Timesteps: 896,792,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 896792166...
Checkpoint 896792166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,020.34384
Policy Entropy: 1.06500
Value Function Loss: 3.04390

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.08618

Collected Steps per Second: 11,791.96178
Overall Steps per Second: 9,974.63360

Timestep Collection Time: 4.24102
Timestep Consumption Time: 0.77269
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.01372

Cumulative Model Updates: 53,766
Cumulative Timesteps: 896,842,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,021.96174
Policy Entropy: 1.07340
Value Function Loss: 2.93085

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08885

Collected Steps per Second: 11,976.00003
Overall Steps per Second: 10,110.91061

Timestep Collection Time: 4.17752
Timestep Consumption Time: 0.77060
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.94812

Cumulative Model Updates: 53,769
Cumulative Timesteps: 896,892,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 896892206...
Checkpoint 896892206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,857.15404
Policy Entropy: 1.05206
Value Function Loss: 2.93437

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 11,411.39536
Overall Steps per Second: 9,613.10825

Timestep Collection Time: 4.38211
Timestep Consumption Time: 0.81974
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.20186

Cumulative Model Updates: 53,772
Cumulative Timesteps: 896,942,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,141.31756
Policy Entropy: 1.05510
Value Function Loss: 3.08047

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.08103

Collected Steps per Second: 11,946.83672
Overall Steps per Second: 10,025.18279

Timestep Collection Time: 4.18755
Timestep Consumption Time: 0.80268
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.99023

Cumulative Model Updates: 53,775
Cumulative Timesteps: 896,992,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 896992240...
Checkpoint 896992240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,605.31271
Policy Entropy: 1.06413
Value Function Loss: 3.32200

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.08000

Collected Steps per Second: 11,940.28254
Overall Steps per Second: 10,273.46575

Timestep Collection Time: 4.18801
Timestep Consumption Time: 0.67948
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 4.86749

Cumulative Model Updates: 53,778
Cumulative Timesteps: 897,042,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,575.80371
Policy Entropy: 1.08275
Value Function Loss: 3.38622

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 12,731.60063
Overall Steps per Second: 10,657.21821

Timestep Collection Time: 3.92834
Timestep Consumption Time: 0.76463
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.69297

Cumulative Model Updates: 53,781
Cumulative Timesteps: 897,092,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 897092260...
Checkpoint 897092260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,939.73101
Policy Entropy: 1.06052
Value Function Loss: 3.29250

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 12,430.66061
Overall Steps per Second: 10,480.15472

Timestep Collection Time: 4.02392
Timestep Consumption Time: 0.74891
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.77283

Cumulative Model Updates: 53,784
Cumulative Timesteps: 897,142,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,725.54022
Policy Entropy: 1.05206
Value Function Loss: 3.22492

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.08606

Collected Steps per Second: 12,925.16205
Overall Steps per Second: 10,725.45679

Timestep Collection Time: 3.86904
Timestep Consumption Time: 0.79351
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.66255

Cumulative Model Updates: 53,787
Cumulative Timesteps: 897,192,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 897192288...
Checkpoint 897192288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,523.50810
Policy Entropy: 1.05361
Value Function Loss: 3.19442

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 11,935.53133
Overall Steps per Second: 10,015.67908

Timestep Collection Time: 4.19085
Timestep Consumption Time: 0.80332
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.99417

Cumulative Model Updates: 53,790
Cumulative Timesteps: 897,242,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,791.23224
Policy Entropy: 1.05860
Value Function Loss: 3.04279

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.16851
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.10874

Collected Steps per Second: 11,364.68628
Overall Steps per Second: 9,800.99413

Timestep Collection Time: 4.40188
Timestep Consumption Time: 0.70229
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.10418

Cumulative Model Updates: 53,793
Cumulative Timesteps: 897,292,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 897292334...
Checkpoint 897292334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,254.98834
Policy Entropy: 1.03050
Value Function Loss: 2.86100

Mean KL Divergence: 0.05034
SB3 Clip Fraction: 0.19301
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 11,588.19312
Overall Steps per Second: 9,788.99742

Timestep Collection Time: 4.31664
Timestep Consumption Time: 0.79339
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.11002

Cumulative Model Updates: 53,796
Cumulative Timesteps: 897,342,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,790.55244
Policy Entropy: 1.04842
Value Function Loss: 2.73856

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 11,835.15562
Overall Steps per Second: 9,989.06165

Timestep Collection Time: 4.22504
Timestep Consumption Time: 0.78084
PPO Batch Consumption Time: 0.03837
Total Iteration Time: 5.00588

Cumulative Model Updates: 53,799
Cumulative Timesteps: 897,392,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 897392360...
Checkpoint 897392360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,183.58630
Policy Entropy: 1.05158
Value Function Loss: 2.78354

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.09757

Collected Steps per Second: 11,785.11618
Overall Steps per Second: 10,094.19663

Timestep Collection Time: 4.24417
Timestep Consumption Time: 0.71096
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.95512

Cumulative Model Updates: 53,802
Cumulative Timesteps: 897,442,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,904.71710
Policy Entropy: 1.05336
Value Function Loss: 2.87778

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 12,149.32632
Overall Steps per Second: 10,232.13154

Timestep Collection Time: 4.11792
Timestep Consumption Time: 0.77158
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.88950

Cumulative Model Updates: 53,805
Cumulative Timesteps: 897,492,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 897492408...
Checkpoint 897492408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,242.46378
Policy Entropy: 1.04566
Value Function Loss: 2.85539

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 11,286.59590
Overall Steps per Second: 9,578.33352

Timestep Collection Time: 4.43234
Timestep Consumption Time: 0.79049
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.22283

Cumulative Model Updates: 53,808
Cumulative Timesteps: 897,542,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,793.62990
Policy Entropy: 1.05469
Value Function Loss: 2.88460

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 12,166.26483
Overall Steps per Second: 10,134.61218

Timestep Collection Time: 4.11088
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.93497

Cumulative Model Updates: 53,811
Cumulative Timesteps: 897,592,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 897592448...
Checkpoint 897592448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,478.59414
Policy Entropy: 1.05823
Value Function Loss: 2.99416

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 11,386.51718
Overall Steps per Second: 9,647.68069

Timestep Collection Time: 4.39362
Timestep Consumption Time: 0.79188
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 5.18549

Cumulative Model Updates: 53,814
Cumulative Timesteps: 897,642,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,605.15495
Policy Entropy: 1.06081
Value Function Loss: 3.03209

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 11,798.45297
Overall Steps per Second: 10,165.64015

Timestep Collection Time: 4.23988
Timestep Consumption Time: 0.68101
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.92089

Cumulative Model Updates: 53,817
Cumulative Timesteps: 897,692,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 897692500...
Checkpoint 897692500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,065.38474
Policy Entropy: 1.06006
Value Function Loss: 3.13779

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 11,813.00233
Overall Steps per Second: 9,955.10174

Timestep Collection Time: 4.23466
Timestep Consumption Time: 0.79031
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.02496

Cumulative Model Updates: 53,820
Cumulative Timesteps: 897,742,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,816.03436
Policy Entropy: 1.06577
Value Function Loss: 3.17302

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.10859

Collected Steps per Second: 11,298.11807
Overall Steps per Second: 9,773.13106

Timestep Collection Time: 4.42640
Timestep Consumption Time: 0.69069
PPO Batch Consumption Time: 0.03369
Total Iteration Time: 5.11709

Cumulative Model Updates: 53,823
Cumulative Timesteps: 897,792,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 897792534...
Checkpoint 897792534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,265.11882
Policy Entropy: 1.06413
Value Function Loss: 3.33982

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.10275

Collected Steps per Second: 11,247.69732
Overall Steps per Second: 9,557.95052

Timestep Collection Time: 4.44749
Timestep Consumption Time: 0.78627
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.23376

Cumulative Model Updates: 53,826
Cumulative Timesteps: 897,842,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,209.49518
Policy Entropy: 1.07768
Value Function Loss: 3.32735

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.10098

Collected Steps per Second: 11,833.22392
Overall Steps per Second: 10,009.91968

Timestep Collection Time: 4.22776
Timestep Consumption Time: 0.77008
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.99784

Cumulative Model Updates: 53,829
Cumulative Timesteps: 897,892,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 897892586...
Checkpoint 897892586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,340.91546
Policy Entropy: 1.07556
Value Function Loss: 3.28524

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11,731.01405
Overall Steps per Second: 10,096.57833

Timestep Collection Time: 4.26408
Timestep Consumption Time: 0.69027
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.95435

Cumulative Model Updates: 53,832
Cumulative Timesteps: 897,942,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,533.04086
Policy Entropy: 1.07031
Value Function Loss: 3.21068

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.11666

Collected Steps per Second: 11,788.02830
Overall Steps per Second: 9,914.29279

Timestep Collection Time: 4.24414
Timestep Consumption Time: 0.80211
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.04625

Cumulative Model Updates: 53,835
Cumulative Timesteps: 897,992,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 897992638...
Checkpoint 897992638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,305.54527
Policy Entropy: 1.08591
Value Function Loss: 3.12408

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 11,691.13808
Overall Steps per Second: 9,917.47538

Timestep Collection Time: 4.27845
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.04362

Cumulative Model Updates: 53,838
Cumulative Timesteps: 898,042,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,943.12195
Policy Entropy: 1.08452
Value Function Loss: 3.14011

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.09461

Collected Steps per Second: 12,371.17124
Overall Steps per Second: 10,299.13061

Timestep Collection Time: 4.04359
Timestep Consumption Time: 0.81351
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.85711

Cumulative Model Updates: 53,841
Cumulative Timesteps: 898,092,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 898092682...
Checkpoint 898092682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,768.12934
Policy Entropy: 1.07161
Value Function Loss: 3.03856

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.09038

Collected Steps per Second: 11,467.76155
Overall Steps per Second: 9,785.29746

Timestep Collection Time: 4.36005
Timestep Consumption Time: 0.74966
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.10971

Cumulative Model Updates: 53,844
Cumulative Timesteps: 898,142,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,706.02675
Policy Entropy: 1.07032
Value Function Loss: 3.14729

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.08399

Collected Steps per Second: 11,834.06912
Overall Steps per Second: 10,125.77878

Timestep Collection Time: 4.22509
Timestep Consumption Time: 0.71280
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.93789

Cumulative Model Updates: 53,847
Cumulative Timesteps: 898,192,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 898192682...
Checkpoint 898192682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,413.78484
Policy Entropy: 1.07817
Value Function Loss: 3.07028

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.07921

Collected Steps per Second: 12,017.70383
Overall Steps per Second: 10,100.91094

Timestep Collection Time: 4.16086
Timestep Consumption Time: 0.78958
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.95044

Cumulative Model Updates: 53,850
Cumulative Timesteps: 898,242,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,852.65781
Policy Entropy: 1.09116
Value Function Loss: 3.18642

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.14918
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08054

Collected Steps per Second: 12,096.80512
Overall Steps per Second: 10,245.76811

Timestep Collection Time: 4.13349
Timestep Consumption Time: 0.74677
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.88026

Cumulative Model Updates: 53,853
Cumulative Timesteps: 898,292,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 898292688...
Checkpoint 898292688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,768.82288
Policy Entropy: 1.06397
Value Function Loss: 3.18997

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.08301

Collected Steps per Second: 11,944.18680
Overall Steps per Second: 10,094.69105

Timestep Collection Time: 4.18831
Timestep Consumption Time: 0.76736
PPO Batch Consumption Time: 0.03311
Total Iteration Time: 4.95567

Cumulative Model Updates: 53,856
Cumulative Timesteps: 898,342,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,364.05283
Policy Entropy: 1.08924
Value Function Loss: 3.23233

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.16975
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.08132

Collected Steps per Second: 11,885.25904
Overall Steps per Second: 10,085.87029

Timestep Collection Time: 4.20689
Timestep Consumption Time: 0.75054
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.95743

Cumulative Model Updates: 53,859
Cumulative Timesteps: 898,392,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 898392714...
Checkpoint 898392714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,714.17576
Policy Entropy: 1.08736
Value Function Loss: 3.29329

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 11,518.76615
Overall Steps per Second: 9,959.86759

Timestep Collection Time: 4.34196
Timestep Consumption Time: 0.67959
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.02155

Cumulative Model Updates: 53,862
Cumulative Timesteps: 898,442,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,908.85459
Policy Entropy: 1.08094
Value Function Loss: 3.20078

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.15868
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 11,888.87369
Overall Steps per Second: 10,044.94597

Timestep Collection Time: 4.20662
Timestep Consumption Time: 0.77220
PPO Batch Consumption Time: 0.03323
Total Iteration Time: 4.97882

Cumulative Model Updates: 53,865
Cumulative Timesteps: 898,492,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 898492740...
Checkpoint 898492740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,299.70233
Policy Entropy: 1.07532
Value Function Loss: 3.33174

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.16377
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.08142

Collected Steps per Second: 12,022.22350
Overall Steps per Second: 10,195.95594

Timestep Collection Time: 4.16113
Timestep Consumption Time: 0.74533
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.90646

Cumulative Model Updates: 53,868
Cumulative Timesteps: 898,542,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,358.34038
Policy Entropy: 1.08009
Value Function Loss: 3.19375

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.08268

Collected Steps per Second: 11,636.22536
Overall Steps per Second: 9,986.23643

Timestep Collection Time: 4.29813
Timestep Consumption Time: 0.71016
PPO Batch Consumption Time: 0.03327
Total Iteration Time: 5.00829

Cumulative Model Updates: 53,871
Cumulative Timesteps: 898,592,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 898592780...
Checkpoint 898592780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,953.11369
Policy Entropy: 1.08974
Value Function Loss: 3.25069

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 11,776.47222
Overall Steps per Second: 9,954.57112

Timestep Collection Time: 4.24711
Timestep Consumption Time: 0.77731
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.02443

Cumulative Model Updates: 53,874
Cumulative Timesteps: 898,642,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571,345.86779
Policy Entropy: 1.05618
Value Function Loss: 3.11717

Mean KL Divergence: 0.03728
SB3 Clip Fraction: 0.18668
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.08612

Collected Steps per Second: 12,042.40933
Overall Steps per Second: 10,205.06830

Timestep Collection Time: 4.15415
Timestep Consumption Time: 0.74792
PPO Batch Consumption Time: 0.03830
Total Iteration Time: 4.90207

Cumulative Model Updates: 53,877
Cumulative Timesteps: 898,692,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 898692822...
Checkpoint 898692822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,134.36891
Policy Entropy: 1.07395
Value Function Loss: 3.19737

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 11,391.18822
Overall Steps per Second: 9,718.71151

Timestep Collection Time: 4.38953
Timestep Consumption Time: 0.75539
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.14492

Cumulative Model Updates: 53,880
Cumulative Timesteps: 898,742,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,638.64875
Policy Entropy: 1.07478
Value Function Loss: 3.23023

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 12,064.90368
Overall Steps per Second: 10,139.93475

Timestep Collection Time: 4.14425
Timestep Consumption Time: 0.78675
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 4.93100

Cumulative Model Updates: 53,883
Cumulative Timesteps: 898,792,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 898792824...
Checkpoint 898792824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,878.05170
Policy Entropy: 1.06230
Value Function Loss: 3.24658

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.10701

Collected Steps per Second: 11,752.15497
Overall Steps per Second: 10,130.65729

Timestep Collection Time: 4.25692
Timestep Consumption Time: 0.68136
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.93828

Cumulative Model Updates: 53,886
Cumulative Timesteps: 898,842,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,398.74864
Policy Entropy: 1.05436
Value Function Loss: 3.33455

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.18355
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.10088

Collected Steps per Second: 11,994.23979
Overall Steps per Second: 10,073.31662

Timestep Collection Time: 4.16867
Timestep Consumption Time: 0.79494
PPO Batch Consumption Time: 0.04034
Total Iteration Time: 4.96361

Cumulative Model Updates: 53,889
Cumulative Timesteps: 898,892,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 898892852...
Checkpoint 898892852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755,901.47257
Policy Entropy: 1.06400
Value Function Loss: 3.32537

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.10528

Collected Steps per Second: 11,601.18045
Overall Steps per Second: 10,023.51498

Timestep Collection Time: 4.31163
Timestep Consumption Time: 0.67864
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.99027

Cumulative Model Updates: 53,892
Cumulative Timesteps: 898,942,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,261.55884
Policy Entropy: 1.07740
Value Function Loss: 3.28921

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 12,068.08604
Overall Steps per Second: 10,189.61616

Timestep Collection Time: 4.14531
Timestep Consumption Time: 0.76419
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.90951

Cumulative Model Updates: 53,895
Cumulative Timesteps: 898,992,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 898992898...
Checkpoint 898992898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,588.26330
Policy Entropy: 1.03950
Value Function Loss: 3.18356

Mean KL Divergence: 0.06472
SB3 Clip Fraction: 0.19973
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 11,467.98536
Overall Steps per Second: 9,806.16300

Timestep Collection Time: 4.36136
Timestep Consumption Time: 0.73911
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 5.10047

Cumulative Model Updates: 53,898
Cumulative Timesteps: 899,042,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,850.05724
Policy Entropy: 1.07262
Value Function Loss: 3.19551

Mean KL Divergence: 0.03217
SB3 Clip Fraction: 0.16899
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 12,069.42519
Overall Steps per Second: 10,271.24866

Timestep Collection Time: 4.14353
Timestep Consumption Time: 0.72540
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.86893

Cumulative Model Updates: 53,901
Cumulative Timesteps: 899,092,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 899092924...
Checkpoint 899092924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,988.61509
Policy Entropy: 1.05172
Value Function Loss: 3.18874

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.08367

Collected Steps per Second: 12,042.34967
Overall Steps per Second: 10,010.67366

Timestep Collection Time: 4.15401
Timestep Consumption Time: 0.84306
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.99707

Cumulative Model Updates: 53,904
Cumulative Timesteps: 899,142,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,580.14156
Policy Entropy: 1.06377
Value Function Loss: 3.12555

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 11,027.28956
Overall Steps per Second: 9,422.07359

Timestep Collection Time: 4.53693
Timestep Consumption Time: 0.77295
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.30987

Cumulative Model Updates: 53,907
Cumulative Timesteps: 899,192,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 899192978...
Checkpoint 899192978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,723.67716
Policy Entropy: 1.06185
Value Function Loss: 3.01261

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 11,893.40338
Overall Steps per Second: 9,978.61497

Timestep Collection Time: 4.20620
Timestep Consumption Time: 0.80712
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.01332

Cumulative Model Updates: 53,910
Cumulative Timesteps: 899,243,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,843.82734
Policy Entropy: 1.06533
Value Function Loss: 3.03894

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 11,851.96952
Overall Steps per Second: 9,923.17987

Timestep Collection Time: 4.22040
Timestep Consumption Time: 0.82033
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 5.04072

Cumulative Model Updates: 53,913
Cumulative Timesteps: 899,293,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 899293024...
Checkpoint 899293024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,880.95137
Policy Entropy: 1.06181
Value Function Loss: 3.06867

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.06417
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 11,308.70446
Overall Steps per Second: 9,793.56393

Timestep Collection Time: 4.42314
Timestep Consumption Time: 0.68429
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.10744

Cumulative Model Updates: 53,916
Cumulative Timesteps: 899,343,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764,646.74832
Policy Entropy: 1.04730
Value Function Loss: 3.17427

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 11,967.20820
Overall Steps per Second: 10,083.51017

Timestep Collection Time: 4.17875
Timestep Consumption Time: 0.78063
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.95938

Cumulative Model Updates: 53,919
Cumulative Timesteps: 899,393,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 899393052...
Checkpoint 899393052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,856.35650
Policy Entropy: 1.06908
Value Function Loss: 3.15632

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.17099
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.11318

Collected Steps per Second: 12,174.93771
Overall Steps per Second: 10,291.63860

Timestep Collection Time: 4.10910
Timestep Consumption Time: 0.75194
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.86103

Cumulative Model Updates: 53,922
Cumulative Timesteps: 899,443,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,256.10242
Policy Entropy: 1.06683
Value Function Loss: 3.14107

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 12,912.42154
Overall Steps per Second: 10,752.25312

Timestep Collection Time: 3.87332
Timestep Consumption Time: 0.77817
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.65149

Cumulative Model Updates: 53,925
Cumulative Timesteps: 899,493,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 899493094...
Checkpoint 899493094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,903.87842
Policy Entropy: 1.05532
Value Function Loss: 3.11844

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 12,593.91658
Overall Steps per Second: 10,457.76829

Timestep Collection Time: 3.97224
Timestep Consumption Time: 0.81139
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.78362

Cumulative Model Updates: 53,928
Cumulative Timesteps: 899,543,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,485.44776
Policy Entropy: 1.04223
Value Function Loss: 3.24836

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.17877
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.09517

Collected Steps per Second: 12,375.88456
Overall Steps per Second: 10,619.08794

Timestep Collection Time: 4.04173
Timestep Consumption Time: 0.66865
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.71039

Cumulative Model Updates: 53,931
Cumulative Timesteps: 899,593,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 899593140...
Checkpoint 899593140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,507.75280
Policy Entropy: 1.05384
Value Function Loss: 3.31377

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 12,061.72107
Overall Steps per Second: 10,127.26326

Timestep Collection Time: 4.14651
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.93855

Cumulative Model Updates: 53,934
Cumulative Timesteps: 899,643,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730,875.72794
Policy Entropy: 1.04992
Value Function Loss: 3.36586

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.10414

Collected Steps per Second: 12,247.01961
Overall Steps per Second: 10,286.58150

Timestep Collection Time: 4.08442
Timestep Consumption Time: 0.77842
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.86284

Cumulative Model Updates: 53,937
Cumulative Timesteps: 899,693,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 899693176...
Checkpoint 899693176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,744.49760
Policy Entropy: 1.05434
Value Function Loss: 3.18749

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.10502

Collected Steps per Second: 12,369.45074
Overall Steps per Second: 10,583.31496

Timestep Collection Time: 4.04464
Timestep Consumption Time: 0.68261
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.72725

Cumulative Model Updates: 53,940
Cumulative Timesteps: 899,743,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,320.75202
Policy Entropy: 1.05483
Value Function Loss: 3.16222

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.10667

Collected Steps per Second: 12,004.15139
Overall Steps per Second: 10,057.83415

Timestep Collection Time: 4.16689
Timestep Consumption Time: 0.80635
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 4.97324

Cumulative Model Updates: 53,943
Cumulative Timesteps: 899,793,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 899793226...
Checkpoint 899793226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,152.93691
Policy Entropy: 1.05888
Value Function Loss: 3.09472

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 11,912.75192
Overall Steps per Second: 10,231.20577

Timestep Collection Time: 4.19735
Timestep Consumption Time: 0.68985
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.88721

Cumulative Model Updates: 53,946
Cumulative Timesteps: 899,843,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,972.39849
Policy Entropy: 1.06488
Value Function Loss: 3.12183

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 11,922.49051
Overall Steps per Second: 10,056.71924

Timestep Collection Time: 4.19392
Timestep Consumption Time: 0.77808
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.97200

Cumulative Model Updates: 53,949
Cumulative Timesteps: 899,893,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 899893230...
Checkpoint 899893230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,745.68914
Policy Entropy: 1.07125
Value Function Loss: 3.01622

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11495

Collected Steps per Second: 11,412.71099
Overall Steps per Second: 9,735.65435

Timestep Collection Time: 4.38266
Timestep Consumption Time: 0.75495
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.13761

Cumulative Model Updates: 53,952
Cumulative Timesteps: 899,943,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727,193.92203
Policy Entropy: 1.04878
Value Function Loss: 2.95337

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 11,892.68508
Overall Steps per Second: 10,243.23389

Timestep Collection Time: 4.20443
Timestep Consumption Time: 0.67703
PPO Batch Consumption Time: 0.03384
Total Iteration Time: 4.88147

Cumulative Model Updates: 53,955
Cumulative Timesteps: 899,993,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 899993250...
Checkpoint 899993250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,569.63967
Policy Entropy: 1.04574
Value Function Loss: 3.02175

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 12,130.11836
Overall Steps per Second: 10,253.40650

Timestep Collection Time: 4.12214
Timestep Consumption Time: 0.75449
PPO Batch Consumption Time: 0.03378
Total Iteration Time: 4.87662

Cumulative Model Updates: 53,958
Cumulative Timesteps: 900,043,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,938.55351
Policy Entropy: 1.06090
Value Function Loss: 3.07079

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.08982

Collected Steps per Second: 11,818.79453
Overall Steps per Second: 10,079.47484

Timestep Collection Time: 4.23055
Timestep Consumption Time: 0.73003
PPO Batch Consumption Time: 0.03257
Total Iteration Time: 4.96058

Cumulative Model Updates: 53,961
Cumulative Timesteps: 900,093,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900093252...
Checkpoint 900093252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,108.93559
Policy Entropy: 1.07119
Value Function Loss: 3.04304

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.09664

Collected Steps per Second: 12,265.23696
Overall Steps per Second: 10,308.37126

Timestep Collection Time: 4.07868
Timestep Consumption Time: 0.77427
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.85295

Cumulative Model Updates: 53,964
Cumulative Timesteps: 900,143,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,027.92891
Policy Entropy: 1.04975
Value Function Loss: 3.15377

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.09749

Collected Steps per Second: 11,832.00427
Overall Steps per Second: 10,007.79104

Timestep Collection Time: 4.22769
Timestep Consumption Time: 0.77062
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.99831

Cumulative Model Updates: 53,967
Cumulative Timesteps: 900,193,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 900193300...
Checkpoint 900193300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,988.00180
Policy Entropy: 1.04124
Value Function Loss: 3.27759

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.17454
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.08922

Collected Steps per Second: 11,650.26117
Overall Steps per Second: 10,032.60396

Timestep Collection Time: 4.29450
Timestep Consumption Time: 0.69244
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 4.98694

Cumulative Model Updates: 53,970
Cumulative Timesteps: 900,243,332

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,340.56859
Policy Entropy: 1.05251
Value Function Loss: 3.26613

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.09452

Collected Steps per Second: 11,846.73801
Overall Steps per Second: 9,973.51330

Timestep Collection Time: 4.22209
Timestep Consumption Time: 0.79299
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.01508

Cumulative Model Updates: 53,973
Cumulative Timesteps: 900,293,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 900293350...
Checkpoint 900293350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,568.11067
Policy Entropy: 1.06063
Value Function Loss: 3.16472

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.09978

Collected Steps per Second: 12,015.06705
Overall Steps per Second: 10,169.69316

Timestep Collection Time: 4.16227
Timestep Consumption Time: 0.75528
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.91755

Cumulative Model Updates: 53,976
Cumulative Timesteps: 900,343,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,711.99826
Policy Entropy: 1.05479
Value Function Loss: 3.08337

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 12,102.98618
Overall Steps per Second: 10,170.85350

Timestep Collection Time: 4.13171
Timestep Consumption Time: 0.78489
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.91660

Cumulative Model Updates: 53,979
Cumulative Timesteps: 900,393,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 900393366...
Checkpoint 900393366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,596.34410
Policy Entropy: 1.04661
Value Function Loss: 3.18604

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 11,774.95901
Overall Steps per Second: 9,981.18092

Timestep Collection Time: 4.24766
Timestep Consumption Time: 0.76337
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 5.01103

Cumulative Model Updates: 53,982
Cumulative Timesteps: 900,443,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,490.83402
Policy Entropy: 1.05394
Value Function Loss: 3.16071

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.06617

Collected Steps per Second: 11,912.05055
Overall Steps per Second: 10,256.83208

Timestep Collection Time: 4.19978
Timestep Consumption Time: 0.67775
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 4.87753

Cumulative Model Updates: 53,985
Cumulative Timesteps: 900,493,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 900493410...
Checkpoint 900493410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,042.87453
Policy Entropy: 1.05705
Value Function Loss: 3.13118

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.06867

Collected Steps per Second: 11,634.05497
Overall Steps per Second: 9,832.77328

Timestep Collection Time: 4.30013
Timestep Consumption Time: 0.78775
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.08788

Cumulative Model Updates: 53,988
Cumulative Timesteps: 900,543,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,981.46091
Policy Entropy: 1.05957
Value Function Loss: 3.07810

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 12,013.14937
Overall Steps per Second: 10,237.96440

Timestep Collection Time: 4.16327
Timestep Consumption Time: 0.72188
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 4.88515

Cumulative Model Updates: 53,991
Cumulative Timesteps: 900,593,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 900593452...
Checkpoint 900593452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,258.66650
Policy Entropy: 1.05392
Value Function Loss: 3.07359

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.08131

Collected Steps per Second: 11,925.75423
Overall Steps per Second: 10,028.16249

Timestep Collection Time: 4.19479
Timestep Consumption Time: 0.79376
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.98855

Cumulative Model Updates: 53,994
Cumulative Timesteps: 900,643,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,076.27399
Policy Entropy: 1.04815
Value Function Loss: 3.08612

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.06976
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 11,704.18745
Overall Steps per Second: 9,918.65186

Timestep Collection Time: 4.27300
Timestep Consumption Time: 0.76922
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 5.04222

Cumulative Model Updates: 53,997
Cumulative Timesteps: 900,693,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 900693490...
Checkpoint 900693490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,163.87715
Policy Entropy: 1.05896
Value Function Loss: 3.11227

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.09432

Collected Steps per Second: 12,008.22419
Overall Steps per Second: 10,342.29522

Timestep Collection Time: 4.16381
Timestep Consumption Time: 0.67070
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.83452

Cumulative Model Updates: 54,000
Cumulative Timesteps: 900,743,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,716.41066
Policy Entropy: 1.06362
Value Function Loss: 3.10204

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.09551

Collected Steps per Second: 12,222.36054
Overall Steps per Second: 10,266.48979

Timestep Collection Time: 4.09135
Timestep Consumption Time: 0.77944
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 4.87080

Cumulative Model Updates: 54,003
Cumulative Timesteps: 900,793,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 900793496...
Checkpoint 900793496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,020.88602
Policy Entropy: 1.07024
Value Function Loss: 3.10576

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 12,004.87566
Overall Steps per Second: 10,161.60180

Timestep Collection Time: 4.16764
Timestep Consumption Time: 0.75599
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 4.92363

Cumulative Model Updates: 54,006
Cumulative Timesteps: 900,843,528

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,939.29002
Policy Entropy: 1.06745
Value Function Loss: 3.09385

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 11,947.47353
Overall Steps per Second: 10,078.30216

Timestep Collection Time: 4.18716
Timestep Consumption Time: 0.77657
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.96373

Cumulative Model Updates: 54,009
Cumulative Timesteps: 900,893,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 900893554...
Checkpoint 900893554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,785.37266
Policy Entropy: 1.06382
Value Function Loss: 2.98027

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.10320

Collected Steps per Second: 12,104.53121
Overall Steps per Second: 10,191.43383

Timestep Collection Time: 4.13101
Timestep Consumption Time: 0.77546
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.90647

Cumulative Model Updates: 54,012
Cumulative Timesteps: 900,943,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,705.75939
Policy Entropy: 1.05653
Value Function Loss: 2.99493

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.11878

Collected Steps per Second: 12,042.54355
Overall Steps per Second: 10,305.76051

Timestep Collection Time: 4.15261
Timestep Consumption Time: 0.69982
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.85243

Cumulative Model Updates: 54,015
Cumulative Timesteps: 900,993,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 900993566...
Checkpoint 900993566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,817.74029
Policy Entropy: 1.07266
Value Function Loss: 2.95030

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 11,871.57249
Overall Steps per Second: 9,938.64412

Timestep Collection Time: 4.21208
Timestep Consumption Time: 0.81919
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 5.03127

Cumulative Model Updates: 54,018
Cumulative Timesteps: 901,043,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,481.38039
Policy Entropy: 1.07540
Value Function Loss: 2.94532

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 11,843.70252
Overall Steps per Second: 10,078.94536

Timestep Collection Time: 4.22368
Timestep Consumption Time: 0.73954
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.96322

Cumulative Model Updates: 54,021
Cumulative Timesteps: 901,093,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 901093594...
Checkpoint 901093594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,421.10439
Policy Entropy: 1.07023
Value Function Loss: 2.94298

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.09208

Collected Steps per Second: 12,033.93733
Overall Steps per Second: 10,026.27541

Timestep Collection Time: 4.15508
Timestep Consumption Time: 0.83201
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.98710

Cumulative Model Updates: 54,024
Cumulative Timesteps: 901,143,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,005.85115
Policy Entropy: 1.06403
Value Function Loss: 2.97397

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 11,800.12622
Overall Steps per Second: 9,959.06292

Timestep Collection Time: 4.23741
Timestep Consumption Time: 0.78334
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 5.02075

Cumulative Model Updates: 54,027
Cumulative Timesteps: 901,193,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 901193598...
Checkpoint 901193598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,883.68849
Policy Entropy: 1.05295
Value Function Loss: 3.14371

Mean KL Divergence: 0.02974
SB3 Clip Fraction: 0.16623
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.10229

Collected Steps per Second: 11,902.03791
Overall Steps per Second: 10,240.26431

Timestep Collection Time: 4.20163
Timestep Consumption Time: 0.68183
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.88347

Cumulative Model Updates: 54,030
Cumulative Timesteps: 901,243,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,808.61637
Policy Entropy: 1.07118
Value Function Loss: 3.29180

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 11,911.74477
Overall Steps per Second: 10,071.36298

Timestep Collection Time: 4.19888
Timestep Consumption Time: 0.76728
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.96616

Cumulative Model Updates: 54,033
Cumulative Timesteps: 901,293,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 901293622...
Checkpoint 901293622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,699.26297
Policy Entropy: 1.07058
Value Function Loss: 3.34580

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.10882

Collected Steps per Second: 11,937.80571
Overall Steps per Second: 10,122.99678

Timestep Collection Time: 4.19022
Timestep Consumption Time: 0.75120
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 4.94142

Cumulative Model Updates: 54,036
Cumulative Timesteps: 901,343,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,365.99086
Policy Entropy: 1.05272
Value Function Loss: 3.25806

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 11,657.26350
Overall Steps per Second: 9,993.96946

Timestep Collection Time: 4.29174
Timestep Consumption Time: 0.71427
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.00602

Cumulative Model Updates: 54,039
Cumulative Timesteps: 901,393,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 901393674...
Checkpoint 901393674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,335.04012
Policy Entropy: 1.04458
Value Function Loss: 3.12145

Mean KL Divergence: 0.03374
SB3 Clip Fraction: 0.19469
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 11,379.87207
Overall Steps per Second: 9,547.27862

Timestep Collection Time: 4.39443
Timestep Consumption Time: 0.84351
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.23793

Cumulative Model Updates: 54,042
Cumulative Timesteps: 901,443,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,157.74811
Policy Entropy: 1.05971
Value Function Loss: 3.09556

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.09317

Collected Steps per Second: 11,593.58155
Overall Steps per Second: 9,796.52449

Timestep Collection Time: 4.31411
Timestep Consumption Time: 0.79137
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 5.10548

Cumulative Model Updates: 54,045
Cumulative Timesteps: 901,493,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 901493698...
Checkpoint 901493698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,352.62654
Policy Entropy: 1.07151
Value Function Loss: 3.04639

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.15600
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.09130

Collected Steps per Second: 12,270.02562
Overall Steps per Second: 10,288.71263

Timestep Collection Time: 4.07742
Timestep Consumption Time: 0.78519
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.86261

Cumulative Model Updates: 54,048
Cumulative Timesteps: 901,543,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,929.96485
Policy Entropy: 1.05021
Value Function Loss: 3.15507

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.09140

Collected Steps per Second: 12,054.10723
Overall Steps per Second: 10,146.54415

Timestep Collection Time: 4.14830
Timestep Consumption Time: 0.77988
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 4.92818

Cumulative Model Updates: 54,051
Cumulative Timesteps: 901,593,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 901593732...
Checkpoint 901593732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,801.63729
Policy Entropy: 1.03790
Value Function Loss: 3.06596

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.18157
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 11,806.20100
Overall Steps per Second: 10,197.75573

Timestep Collection Time: 4.23676
Timestep Consumption Time: 0.66824
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.90500

Cumulative Model Updates: 54,054
Cumulative Timesteps: 901,643,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,654.32228
Policy Entropy: 1.05680
Value Function Loss: 3.15385

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.08389

Collected Steps per Second: 11,896.72620
Overall Steps per Second: 10,004.97229

Timestep Collection Time: 4.20519
Timestep Consumption Time: 0.79512
PPO Batch Consumption Time: 0.03357
Total Iteration Time: 5.00031

Cumulative Model Updates: 54,057
Cumulative Timesteps: 901,693,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 901693780...
Checkpoint 901693780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,792.81092
Policy Entropy: 1.05370
Value Function Loss: 3.11529

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.08113

Collected Steps per Second: 11,731.15024
Overall Steps per Second: 9,849.84626

Timestep Collection Time: 4.26403
Timestep Consumption Time: 0.81442
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.07845

Cumulative Model Updates: 54,060
Cumulative Timesteps: 901,743,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,877.29201
Policy Entropy: 1.04266
Value Function Loss: 3.27126

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.07567

Collected Steps per Second: 11,982.51476
Overall Steps per Second: 10,109.35083

Timestep Collection Time: 4.17458
Timestep Consumption Time: 0.77351
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.94809

Cumulative Model Updates: 54,063
Cumulative Timesteps: 901,793,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 901793824...
Checkpoint 901793824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,278.71846
Policy Entropy: 1.03200
Value Function Loss: 3.17698

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.18553
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 11,824.17591
Overall Steps per Second: 10,048.21867

Timestep Collection Time: 4.23049
Timestep Consumption Time: 0.74771
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.97820

Cumulative Model Updates: 54,066
Cumulative Timesteps: 901,843,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,839.39190
Policy Entropy: 1.04488
Value Function Loss: 3.19823

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.06373

Collected Steps per Second: 12,612.44097
Overall Steps per Second: 10,752.40780

Timestep Collection Time: 3.96593
Timestep Consumption Time: 0.68606
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 4.65198

Cumulative Model Updates: 54,069
Cumulative Timesteps: 901,893,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 901893866...
Checkpoint 901893866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,179.29042
Policy Entropy: 1.04725
Value Function Loss: 3.01934

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.07117

Collected Steps per Second: 12,409.70723
Overall Steps per Second: 10,314.74173

Timestep Collection Time: 4.03007
Timestep Consumption Time: 0.81852
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.84859

Cumulative Model Updates: 54,072
Cumulative Timesteps: 901,943,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,413.53987
Policy Entropy: 1.02709
Value Function Loss: 3.10358

Mean KL Divergence: 0.02678
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 12,628.98464
Overall Steps per Second: 10,564.84066

Timestep Collection Time: 3.96041
Timestep Consumption Time: 0.77378
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 4.73419

Cumulative Model Updates: 54,075
Cumulative Timesteps: 901,993,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 901993894...
Checkpoint 901993894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,942.94727
Policy Entropy: 1.03844
Value Function Loss: 3.03417

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.16641
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.09071

Collected Steps per Second: 12,959.56472
Overall Steps per Second: 10,793.43769

Timestep Collection Time: 3.85831
Timestep Consumption Time: 0.77432
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.63263

Cumulative Model Updates: 54,078
Cumulative Timesteps: 902,043,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,881.75713
Policy Entropy: 1.04116
Value Function Loss: 3.14336

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.18048
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 11,855.54858
Overall Steps per Second: 9,857.64719

Timestep Collection Time: 4.21963
Timestep Consumption Time: 0.85521
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.07484

Cumulative Model Updates: 54,081
Cumulative Timesteps: 902,093,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902093922...
Checkpoint 902093922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,082.61220
Policy Entropy: 1.03274
Value Function Loss: 3.06644

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.15773
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 12,680.51527
Overall Steps per Second: 10,825.21489

Timestep Collection Time: 3.94495
Timestep Consumption Time: 0.67611
PPO Batch Consumption Time: 0.03301
Total Iteration Time: 4.62106

Cumulative Model Updates: 54,084
Cumulative Timesteps: 902,143,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,687.44291
Policy Entropy: 1.01758
Value Function Loss: 3.06585

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.18560
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 11,851.20026
Overall Steps per Second: 10,002.08610

Timestep Collection Time: 4.22168
Timestep Consumption Time: 0.78047
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.00216

Cumulative Model Updates: 54,087
Cumulative Timesteps: 902,193,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 902193978...
Checkpoint 902193978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,657.42746
Policy Entropy: 1.02961
Value Function Loss: 2.92140

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.10259

Collected Steps per Second: 12,067.54147
Overall Steps per Second: 10,311.55689

Timestep Collection Time: 4.14567
Timestep Consumption Time: 0.70598
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.85164

Cumulative Model Updates: 54,090
Cumulative Timesteps: 902,244,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769,496.46887
Policy Entropy: 1.04069
Value Function Loss: 3.01758

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10376

Collected Steps per Second: 12,077.20926
Overall Steps per Second: 10,042.95529

Timestep Collection Time: 4.14218
Timestep Consumption Time: 0.83902
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.98120

Cumulative Model Updates: 54,093
Cumulative Timesteps: 902,294,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902294032...
Checkpoint 902294032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,667.93326
Policy Entropy: 1.01873
Value Function Loss: 3.07951

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 11,812.46486
Overall Steps per Second: 10,036.88795

Timestep Collection Time: 4.23383
Timestep Consumption Time: 0.74899
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.98282

Cumulative Model Updates: 54,096
Cumulative Timesteps: 902,344,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,224.20686
Policy Entropy: 1.03788
Value Function Loss: 3.27354

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16967
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 11,367.83768
Overall Steps per Second: 9,815.98039

Timestep Collection Time: 4.40013
Timestep Consumption Time: 0.69564
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 5.09577

Cumulative Model Updates: 54,099
Cumulative Timesteps: 902,394,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 902394064...
Checkpoint 902394064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,723.42355
Policy Entropy: 1.03522
Value Function Loss: 3.18088

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.17199
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.10887

Collected Steps per Second: 11,803.97685
Overall Steps per Second: 9,953.96807

Timestep Collection Time: 4.23654
Timestep Consumption Time: 0.78739
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.02393

Cumulative Model Updates: 54,102
Cumulative Timesteps: 902,444,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,456.56710
Policy Entropy: 1.02366
Value Function Loss: 3.21728

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.11701

Collected Steps per Second: 11,963.18564
Overall Steps per Second: 10,150.66903

Timestep Collection Time: 4.18166
Timestep Consumption Time: 0.74668
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 4.92835

Cumulative Model Updates: 54,105
Cumulative Timesteps: 902,494,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902494098...
Checkpoint 902494098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,085.28048
Policy Entropy: 1.01291
Value Function Loss: 3.04210

Mean KL Divergence: 0.03289
SB3 Clip Fraction: 0.19705
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 12,037.24875
Overall Steps per Second: 10,055.37069

Timestep Collection Time: 4.15477
Timestep Consumption Time: 0.81889
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.97366

Cumulative Model Updates: 54,108
Cumulative Timesteps: 902,544,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744,927.78364
Policy Entropy: 1.03712
Value Function Loss: 3.05298

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.12055

Collected Steps per Second: 11,775.28322
Overall Steps per Second: 9,851.46359

Timestep Collection Time: 4.24737
Timestep Consumption Time: 0.82944
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.07681

Cumulative Model Updates: 54,111
Cumulative Timesteps: 902,594,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 902594124...
Checkpoint 902594124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,343.66802
Policy Entropy: 1.03988
Value Function Loss: 2.85671

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.06976
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 11,428.69183
Overall Steps per Second: 9,908.97160

Timestep Collection Time: 4.37583
Timestep Consumption Time: 0.67111
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.04694

Cumulative Model Updates: 54,114
Cumulative Timesteps: 902,644,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,591.27031
Policy Entropy: 1.03096
Value Function Loss: 3.05274

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.10779

Collected Steps per Second: 11,444.39460
Overall Steps per Second: 9,724.31032

Timestep Collection Time: 4.36965
Timestep Consumption Time: 0.77293
PPO Batch Consumption Time: 0.03430
Total Iteration Time: 5.14258

Cumulative Model Updates: 54,117
Cumulative Timesteps: 902,694,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 902694142...
Checkpoint 902694142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,511.21543
Policy Entropy: 1.03686
Value Function Loss: 3.05451

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.11221

Collected Steps per Second: 12,024.11843
Overall Steps per Second: 10,090.78397

Timestep Collection Time: 4.15981
Timestep Consumption Time: 0.79699
PPO Batch Consumption Time: 0.03302
Total Iteration Time: 4.95680

Cumulative Model Updates: 54,120
Cumulative Timesteps: 902,744,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,011.14637
Policy Entropy: 1.03497
Value Function Loss: 3.20487

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.11385

Collected Steps per Second: 12,062.02052
Overall Steps per Second: 10,365.87206

Timestep Collection Time: 4.14707
Timestep Consumption Time: 0.67858
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.82564

Cumulative Model Updates: 54,123
Cumulative Timesteps: 902,794,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902794182...
Checkpoint 902794182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,696.12681
Policy Entropy: 1.03821
Value Function Loss: 3.05661

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.10984

Collected Steps per Second: 11,922.74568
Overall Steps per Second: 10,074.38341

Timestep Collection Time: 4.19585
Timestep Consumption Time: 0.76982
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.96566

Cumulative Model Updates: 54,126
Cumulative Timesteps: 902,844,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,794.18471
Policy Entropy: 1.03975
Value Function Loss: 3.11435

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.07264
Value Function Update Magnitude: 0.09336

Collected Steps per Second: 11,850.44317
Overall Steps per Second: 9,936.24169

Timestep Collection Time: 4.22145
Timestep Consumption Time: 0.81325
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.03470

Cumulative Model Updates: 54,129
Cumulative Timesteps: 902,894,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902894234...
Checkpoint 902894234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,141.35506
Policy Entropy: 1.04892
Value Function Loss: 3.11871

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 12,017.43681
Overall Steps per Second: 10,161.61584

Timestep Collection Time: 4.16328
Timestep Consumption Time: 0.76034
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.92363

Cumulative Model Updates: 54,132
Cumulative Timesteps: 902,944,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,285.09004
Policy Entropy: 1.05029
Value Function Loss: 3.20073

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.10220

Collected Steps per Second: 11,565.86517
Overall Steps per Second: 9,875.70410

Timestep Collection Time: 4.32358
Timestep Consumption Time: 0.73995
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.06354

Cumulative Model Updates: 54,135
Cumulative Timesteps: 902,994,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 902994272...
Checkpoint 902994272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781,600.95177
Policy Entropy: 1.05293
Value Function Loss: 3.25887

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.16065
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 12,052.22951
Overall Steps per Second: 10,324.99663

Timestep Collection Time: 4.14894
Timestep Consumption Time: 0.69406
PPO Batch Consumption Time: 0.03890
Total Iteration Time: 4.84300

Cumulative Model Updates: 54,138
Cumulative Timesteps: 903,044,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,897.06449
Policy Entropy: 1.05122
Value Function Loss: 3.18172

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.17095
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 12,266.53409
Overall Steps per Second: 10,359.98751

Timestep Collection Time: 4.07825
Timestep Consumption Time: 0.75052
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.82877

Cumulative Model Updates: 54,141
Cumulative Timesteps: 903,094,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903094302...
Checkpoint 903094302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,251.86454
Policy Entropy: 1.05783
Value Function Loss: 3.19508

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 12,200.54018
Overall Steps per Second: 10,185.04039

Timestep Collection Time: 4.09818
Timestep Consumption Time: 0.81098
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.90916

Cumulative Model Updates: 54,144
Cumulative Timesteps: 903,144,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552,739.03614
Policy Entropy: 1.06723
Value Function Loss: 3.05660

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.10263

Collected Steps per Second: 12,380.31259
Overall Steps per Second: 10,423.82071

Timestep Collection Time: 4.04061
Timestep Consumption Time: 0.75840
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.79901

Cumulative Model Updates: 54,147
Cumulative Timesteps: 903,194,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 903194326...
Checkpoint 903194326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,629.62967
Policy Entropy: 1.06830
Value Function Loss: 3.10827

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 12,161.90596
Overall Steps per Second: 10,138.45736

Timestep Collection Time: 4.11251
Timestep Consumption Time: 0.82078
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.93329

Cumulative Model Updates: 54,150
Cumulative Timesteps: 903,244,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,095.93913
Policy Entropy: 1.06935
Value Function Loss: 3.05515

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.08043

Collected Steps per Second: 11,860.49067
Overall Steps per Second: 10,069.58419

Timestep Collection Time: 4.21635
Timestep Consumption Time: 0.74989
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.96624

Cumulative Model Updates: 54,153
Cumulative Timesteps: 903,294,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 903294350...
Checkpoint 903294350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,911.62854
Policy Entropy: 1.08106
Value Function Loss: 3.08474

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08691

Collected Steps per Second: 12,151.24878
Overall Steps per Second: 10,250.03178

Timestep Collection Time: 4.11513
Timestep Consumption Time: 0.76329
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.87842

Cumulative Model Updates: 54,156
Cumulative Timesteps: 903,344,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,059.37799
Policy Entropy: 1.08904
Value Function Loss: 3.13357

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.10067

Collected Steps per Second: 11,952.34961
Overall Steps per Second: 10,274.06550

Timestep Collection Time: 4.18596
Timestep Consumption Time: 0.68378
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.86974

Cumulative Model Updates: 54,159
Cumulative Timesteps: 903,394,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 903394386...
Checkpoint 903394386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,728.79618
Policy Entropy: 1.06953
Value Function Loss: 3.24950

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 12,082.94070
Overall Steps per Second: 10,094.64400

Timestep Collection Time: 4.13956
Timestep Consumption Time: 0.81535
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.95490

Cumulative Model Updates: 54,162
Cumulative Timesteps: 903,444,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,809.44918
Policy Entropy: 1.07103
Value Function Loss: 3.23614

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 12,054.73056
Overall Steps per Second: 10,315.88968

Timestep Collection Time: 4.14974
Timestep Consumption Time: 0.69948
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 4.84922

Cumulative Model Updates: 54,165
Cumulative Timesteps: 903,494,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 903494428...
Checkpoint 903494428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,617.54791
Policy Entropy: 1.07939
Value Function Loss: 3.13680

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.09802

Collected Steps per Second: 11,856.47151
Overall Steps per Second: 10,026.39481

Timestep Collection Time: 4.21862
Timestep Consumption Time: 0.77001
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.98863

Cumulative Model Updates: 54,168
Cumulative Timesteps: 903,544,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,659.77527
Policy Entropy: 1.08879
Value Function Loss: 3.00476

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 11,507.92836
Overall Steps per Second: 9,801.34647

Timestep Collection Time: 4.34639
Timestep Consumption Time: 0.75678
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.10318

Cumulative Model Updates: 54,171
Cumulative Timesteps: 903,594,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 903594464...
Checkpoint 903594464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,281.79152
Policy Entropy: 1.08108
Value Function Loss: 2.99468

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 12,016.81412
Overall Steps per Second: 10,159.24863

Timestep Collection Time: 4.16233
Timestep Consumption Time: 0.76106
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.92340

Cumulative Model Updates: 54,174
Cumulative Timesteps: 903,644,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,836.91929
Policy Entropy: 1.07386
Value Function Loss: 3.05232

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.08945

Collected Steps per Second: 12,035.29596
Overall Steps per Second: 10,146.98827

Timestep Collection Time: 4.15495
Timestep Consumption Time: 0.77322
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.92816

Cumulative Model Updates: 54,177
Cumulative Timesteps: 903,694,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 903694488...
Checkpoint 903694488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,199.62280
Policy Entropy: 1.06334
Value Function Loss: 3.19401

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.08820

Collected Steps per Second: 11,991.59601
Overall Steps per Second: 10,173.05850

Timestep Collection Time: 4.17226
Timestep Consumption Time: 0.74583
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.91809

Cumulative Model Updates: 54,180
Cumulative Timesteps: 903,744,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,965.25505
Policy Entropy: 1.07928
Value Function Loss: 3.34601

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11,990.67989
Overall Steps per Second: 10,141.35096

Timestep Collection Time: 4.17124
Timestep Consumption Time: 0.76065
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.93189

Cumulative Model Updates: 54,183
Cumulative Timesteps: 903,794,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 903794536...
Checkpoint 903794536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,093.69145
Policy Entropy: 1.08800
Value Function Loss: 3.35763

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.08878

Collected Steps per Second: 11,915.64575
Overall Steps per Second: 10,080.45461

Timestep Collection Time: 4.19801
Timestep Consumption Time: 0.76427
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.96228

Cumulative Model Updates: 54,186
Cumulative Timesteps: 903,844,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,382.62973
Policy Entropy: 1.06924
Value Function Loss: 3.26113

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.09701

Collected Steps per Second: 11,413.51344
Overall Steps per Second: 9,849.75462

Timestep Collection Time: 4.38252
Timestep Consumption Time: 0.69577
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.07830

Cumulative Model Updates: 54,189
Cumulative Timesteps: 903,894,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 903894578...
Checkpoint 903894578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,109.17060
Policy Entropy: 1.05533
Value Function Loss: 3.12524

Mean KL Divergence: 0.02959
SB3 Clip Fraction: 0.18202
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 11,856.93639
Overall Steps per Second: 10,050.98624

Timestep Collection Time: 4.21694
Timestep Consumption Time: 0.75770
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.97464

Cumulative Model Updates: 54,192
Cumulative Timesteps: 903,944,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,653.03862
Policy Entropy: 1.06364
Value Function Loss: 3.06563

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08658

Collected Steps per Second: 11,791.05059
Overall Steps per Second: 9,996.54399

Timestep Collection Time: 4.24271
Timestep Consumption Time: 0.76162
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.00433

Cumulative Model Updates: 54,195
Cumulative Timesteps: 903,994,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903994604...
Checkpoint 903994604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,000.62892
Policy Entropy: 1.07895
Value Function Loss: 2.94531

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 11,932.40100
Overall Steps per Second: 10,221.61569

Timestep Collection Time: 4.19161
Timestep Consumption Time: 0.70155
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.89316

Cumulative Model Updates: 54,198
Cumulative Timesteps: 904,044,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,860.58717
Policy Entropy: 1.05593
Value Function Loss: 2.93714

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 11,738.49885
Overall Steps per Second: 9,863.75528

Timestep Collection Time: 4.26136
Timestep Consumption Time: 0.80993
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.07129

Cumulative Model Updates: 54,201
Cumulative Timesteps: 904,094,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904094642...
Checkpoint 904094642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,845.10489
Policy Entropy: 1.06475
Value Function Loss: 2.93654

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 11,963.49548
Overall Steps per Second: 10,087.63067

Timestep Collection Time: 4.18155
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.95914

Cumulative Model Updates: 54,204
Cumulative Timesteps: 904,144,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,664.71611
Policy Entropy: 1.06072
Value Function Loss: 3.05908

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07764

Collected Steps per Second: 11,731.90879
Overall Steps per Second: 9,906.99327

Timestep Collection Time: 4.26444
Timestep Consumption Time: 0.78553
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.04997

Cumulative Model Updates: 54,207
Cumulative Timesteps: 904,194,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 904194698...
Checkpoint 904194698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,873.16802
Policy Entropy: 1.06486
Value Function Loss: 3.05207

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 11,894.07227
Overall Steps per Second: 10,096.71741

Timestep Collection Time: 4.20512
Timestep Consumption Time: 0.74857
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.95369

Cumulative Model Updates: 54,210
Cumulative Timesteps: 904,244,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,542.84361
Policy Entropy: 1.06961
Value Function Loss: 3.06631

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 12,186.74472
Overall Steps per Second: 10,469.48159

Timestep Collection Time: 4.10462
Timestep Consumption Time: 0.67326
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.77789

Cumulative Model Updates: 54,213
Cumulative Timesteps: 904,294,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904294736...
Checkpoint 904294736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,074.51984
Policy Entropy: 1.06332
Value Function Loss: 2.98288

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.15522
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 12,365.65719
Overall Steps per Second: 10,390.85126

Timestep Collection Time: 4.04410
Timestep Consumption Time: 0.76859
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.81270

Cumulative Model Updates: 54,216
Cumulative Timesteps: 904,344,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,695.32611
Policy Entropy: 1.04456
Value Function Loss: 3.05851

Mean KL Divergence: 0.03314
SB3 Clip Fraction: 0.19592
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.11354

Collected Steps per Second: 12,516.10114
Overall Steps per Second: 10,532.71309

Timestep Collection Time: 3.99661
Timestep Consumption Time: 0.75259
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.74920

Cumulative Model Updates: 54,219
Cumulative Timesteps: 904,394,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904394766...
Checkpoint 904394766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,810.19118
Policy Entropy: 1.06170
Value Function Loss: 3.01569

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.10577

Collected Steps per Second: 12,558.11140
Overall Steps per Second: 10,447.86181

Timestep Collection Time: 3.98149
Timestep Consumption Time: 0.80418
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.78567

Cumulative Model Updates: 54,222
Cumulative Timesteps: 904,444,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,706.67877
Policy Entropy: 1.07307
Value Function Loss: 3.03775

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.15512
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.09110

Collected Steps per Second: 11,845.17564
Overall Steps per Second: 10,035.27717

Timestep Collection Time: 4.22231
Timestep Consumption Time: 0.76151
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.98382

Cumulative Model Updates: 54,225
Cumulative Timesteps: 904,494,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 904494780...
Checkpoint 904494780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,907.98943
Policy Entropy: 1.05200
Value Function Loss: 3.00917

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 12,449.28451
Overall Steps per Second: 10,550.55856

Timestep Collection Time: 4.01887
Timestep Consumption Time: 0.72325
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.74212

Cumulative Model Updates: 54,228
Cumulative Timesteps: 904,544,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,573.41039
Policy Entropy: 1.03483
Value Function Loss: 2.98313

Mean KL Divergence: 0.02883
SB3 Clip Fraction: 0.19164
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.08645

Collected Steps per Second: 12,463.79784
Overall Steps per Second: 10,365.71352

Timestep Collection Time: 4.01226
Timestep Consumption Time: 0.81211
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.82437

Cumulative Model Updates: 54,231
Cumulative Timesteps: 904,594,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 904594820...
Checkpoint 904594820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,426.26404
Policy Entropy: 1.04564
Value Function Loss: 3.03079

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.08929

Collected Steps per Second: 11,889.90954
Overall Steps per Second: 9,984.90444

Timestep Collection Time: 4.20592
Timestep Consumption Time: 0.80244
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.00836

Cumulative Model Updates: 54,234
Cumulative Timesteps: 904,644,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,394.99186
Policy Entropy: 1.05681
Value Function Loss: 2.98784

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 12,133.34950
Overall Steps per Second: 10,125.03130

Timestep Collection Time: 4.12120
Timestep Consumption Time: 0.81745
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.93865

Cumulative Model Updates: 54,237
Cumulative Timesteps: 904,694,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 904694832...
Checkpoint 904694832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,499.10121
Policy Entropy: 1.03445
Value Function Loss: 3.15925

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 11,949.39488
Overall Steps per Second: 10,019.26719

Timestep Collection Time: 4.18615
Timestep Consumption Time: 0.80643
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.99258

Cumulative Model Updates: 54,240
Cumulative Timesteps: 904,744,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,778.57988
Policy Entropy: 1.04696
Value Function Loss: 3.11949

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.17925
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 11,398.47529
Overall Steps per Second: 9,870.79251

Timestep Collection Time: 4.38655
Timestep Consumption Time: 0.67890
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 5.06545

Cumulative Model Updates: 54,243
Cumulative Timesteps: 904,794,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 904794854...
Checkpoint 904794854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,224.33110
Policy Entropy: 1.04848
Value Function Loss: 3.21700

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 11,884.61592
Overall Steps per Second: 9,993.42775

Timestep Collection Time: 4.20880
Timestep Consumption Time: 0.79649
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.00529

Cumulative Model Updates: 54,246
Cumulative Timesteps: 904,844,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,675.12220
Policy Entropy: 1.05367
Value Function Loss: 3.16078

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11185
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 12,056.61397
Overall Steps per Second: 10,215.21742

Timestep Collection Time: 4.14859
Timestep Consumption Time: 0.74783
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.89642

Cumulative Model Updates: 54,249
Cumulative Timesteps: 904,894,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 904894892...
Checkpoint 904894892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,633.53756
Policy Entropy: 1.04764
Value Function Loss: 3.15288

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 12,135.63506
Overall Steps per Second: 10,414.27364

Timestep Collection Time: 4.12323
Timestep Consumption Time: 0.68152
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.80475

Cumulative Model Updates: 54,252
Cumulative Timesteps: 904,944,930

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,035.20415
Policy Entropy: 1.04226
Value Function Loss: 3.08651

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.06172

Collected Steps per Second: 11,546.86420
Overall Steps per Second: 9,823.57828

Timestep Collection Time: 4.33105
Timestep Consumption Time: 0.75977
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.09081

Cumulative Model Updates: 54,255
Cumulative Timesteps: 904,994,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 904994940...
Checkpoint 904994940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,513.93740
Policy Entropy: 1.04991
Value Function Loss: 3.04736

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 11,579.82803
Overall Steps per Second: 9,859.47819

Timestep Collection Time: 4.31889
Timestep Consumption Time: 0.75359
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.07248

Cumulative Model Updates: 54,258
Cumulative Timesteps: 905,044,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,621.39747
Policy Entropy: 1.05215
Value Function Loss: 3.19846

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 11,862.27661
Overall Steps per Second: 10,073.07136

Timestep Collection Time: 4.21555
Timestep Consumption Time: 0.74878
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.96433

Cumulative Model Updates: 54,261
Cumulative Timesteps: 905,094,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905094958...
Checkpoint 905094958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,266.66872
Policy Entropy: 1.05427
Value Function Loss: 3.24597

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 11,929.70633
Overall Steps per Second: 10,077.07658

Timestep Collection Time: 4.19222
Timestep Consumption Time: 0.77072
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.96295

Cumulative Model Updates: 54,264
Cumulative Timesteps: 905,144,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,169.80139
Policy Entropy: 1.06005
Value Function Loss: 3.22397

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.06270

Collected Steps per Second: 11,671.60747
Overall Steps per Second: 10,055.71540

Timestep Collection Time: 4.28493
Timestep Consumption Time: 0.68856
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.97349

Cumulative Model Updates: 54,267
Cumulative Timesteps: 905,194,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 905194982...
Checkpoint 905194982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,908.21389
Policy Entropy: 1.05108
Value Function Loss: 3.19095

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.07235
Value Function Update Magnitude: 0.06726

Collected Steps per Second: 11,924.24287
Overall Steps per Second: 10,059.86209

Timestep Collection Time: 4.19549
Timestep Consumption Time: 0.77754
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.97303

Cumulative Model Updates: 54,270
Cumulative Timesteps: 905,245,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,697.13993
Policy Entropy: 1.07513
Value Function Loss: 3.20818

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.08491

Collected Steps per Second: 11,925.06501
Overall Steps per Second: 10,273.81908

Timestep Collection Time: 4.19335
Timestep Consumption Time: 0.67397
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.86732

Cumulative Model Updates: 54,273
Cumulative Timesteps: 905,295,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905295016...
Checkpoint 905295016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,459.28146
Policy Entropy: 1.06700
Value Function Loss: 3.26809

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 11,750.12510
Overall Steps per Second: 9,879.86667

Timestep Collection Time: 4.25612
Timestep Consumption Time: 0.80568
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.06181

Cumulative Model Updates: 54,276
Cumulative Timesteps: 905,345,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,600.36498
Policy Entropy: 1.06222
Value Function Loss: 3.16845

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 11,647.20828
Overall Steps per Second: 9,917.97301

Timestep Collection Time: 4.29511
Timestep Consumption Time: 0.74887
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 5.04397

Cumulative Model Updates: 54,279
Cumulative Timesteps: 905,395,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 905395052...
Checkpoint 905395052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,243.96038
Policy Entropy: 1.05229
Value Function Loss: 3.08300

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.17721
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 12,106.13925
Overall Steps per Second: 10,169.60009

Timestep Collection Time: 4.13096
Timestep Consumption Time: 0.78664
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.91760

Cumulative Model Updates: 54,282
Cumulative Timesteps: 905,445,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,828.24637
Policy Entropy: 1.06596
Value Function Loss: 3.07252

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.09379

Collected Steps per Second: 12,055.60241
Overall Steps per Second: 10,092.95536

Timestep Collection Time: 4.14894
Timestep Consumption Time: 0.80679
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.95573

Cumulative Model Updates: 54,285
Cumulative Timesteps: 905,495,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905495080...
Checkpoint 905495080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,964.11883
Policy Entropy: 1.07612
Value Function Loss: 3.13420

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.16561
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 12,260.40434
Overall Steps per Second: 10,497.53000

Timestep Collection Time: 4.08045
Timestep Consumption Time: 0.68524
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.76569

Cumulative Model Updates: 54,288
Cumulative Timesteps: 905,545,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,148.80255
Policy Entropy: 1.03663
Value Function Loss: 3.08994

Mean KL Divergence: 0.04878
SB3 Clip Fraction: 0.21990
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 12,331.48148
Overall Steps per Second: 10,349.87540

Timestep Collection Time: 4.05661
Timestep Consumption Time: 0.77669
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.83329

Cumulative Model Updates: 54,291
Cumulative Timesteps: 905,595,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 905595132...
Checkpoint 905595132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742,346.34758
Policy Entropy: 1.07360
Value Function Loss: 2.95641

Mean KL Divergence: 0.03664
SB3 Clip Fraction: 0.20964
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 12,020.68134
Overall Steps per Second: 10,196.39376

Timestep Collection Time: 4.15950
Timestep Consumption Time: 0.74420
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.90369

Cumulative Model Updates: 54,294
Cumulative Timesteps: 905,645,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,179.32828
Policy Entropy: 1.03843
Value Function Loss: 2.84483

Mean KL Divergence: 0.05704
SB3 Clip Fraction: 0.26567
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 11,899.54345
Overall Steps per Second: 10,189.25866

Timestep Collection Time: 4.20235
Timestep Consumption Time: 0.70537
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.90772

Cumulative Model Updates: 54,297
Cumulative Timesteps: 905,695,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905695138...
Checkpoint 905695138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,493.36195
Policy Entropy: 1.07647
Value Function Loss: 2.79214

Mean KL Divergence: 0.03659
SB3 Clip Fraction: 0.22872
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 11,919.21042
Overall Steps per Second: 10,096.27752

Timestep Collection Time: 4.19692
Timestep Consumption Time: 0.75778
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.95470

Cumulative Model Updates: 54,300
Cumulative Timesteps: 905,745,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,041.30365
Policy Entropy: 1.04000
Value Function Loss: 2.99439

Mean KL Divergence: 0.06678
SB3 Clip Fraction: 0.26767
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 12,183.60492
Overall Steps per Second: 10,300.11750

Timestep Collection Time: 4.10601
Timestep Consumption Time: 0.75083
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.85684

Cumulative Model Updates: 54,303
Cumulative Timesteps: 905,795,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 905795188...
Checkpoint 905795188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,332.07786
Policy Entropy: 1.06872
Value Function Loss: 3.17612

Mean KL Divergence: 0.04102
SB3 Clip Fraction: 0.23458
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 12,130.85338
Overall Steps per Second: 10,237.44551

Timestep Collection Time: 4.12419
Timestep Consumption Time: 0.76277
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 4.88696

Cumulative Model Updates: 54,306
Cumulative Timesteps: 905,845,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737,935.97783
Policy Entropy: 1.03520
Value Function Loss: 3.33963

Mean KL Divergence: 0.07032
SB3 Clip Fraction: 0.29358
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11,937.07217
Overall Steps per Second: 10,120.95900

Timestep Collection Time: 4.19014
Timestep Consumption Time: 0.75188
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 4.94202

Cumulative Model Updates: 54,309
Cumulative Timesteps: 905,895,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905895236...
Checkpoint 905895236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,568.20425
Policy Entropy: 1.07267
Value Function Loss: 3.19460

Mean KL Divergence: 0.04319
SB3 Clip Fraction: 0.23044
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 11,889.19934
Overall Steps per Second: 9,968.31366

Timestep Collection Time: 4.20583
Timestep Consumption Time: 0.81046
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 5.01629

Cumulative Model Updates: 54,312
Cumulative Timesteps: 905,945,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,896.54971
Policy Entropy: 1.04986
Value Function Loss: 3.04257

Mean KL Divergence: 0.04771
SB3 Clip Fraction: 0.25881
Policy Update Magnitude: 0.04365
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 11,775.98804
Overall Steps per Second: 9,851.82853

Timestep Collection Time: 4.24627
Timestep Consumption Time: 0.82934
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 5.07561

Cumulative Model Updates: 54,315
Cumulative Timesteps: 905,995,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 905995244...
Checkpoint 905995244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,830.53829
Policy Entropy: 1.07104
Value Function Loss: 3.07962

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.16976
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.08526

Collected Steps per Second: 11,921.22962
Overall Steps per Second: 10,072.54301

Timestep Collection Time: 4.19638
Timestep Consumption Time: 0.77019
PPO Batch Consumption Time: 0.03994
Total Iteration Time: 4.96657

Cumulative Model Updates: 54,318
Cumulative Timesteps: 906,045,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,494.47315
Policy Entropy: 1.05261
Value Function Loss: 3.13107

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.18233
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 12,026.31101
Overall Steps per Second: 10,161.51840

Timestep Collection Time: 4.15855
Timestep Consumption Time: 0.76316
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 4.92171

Cumulative Model Updates: 54,321
Cumulative Timesteps: 906,095,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 906095282...
Checkpoint 906095282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,930.68248
Policy Entropy: 1.04805
Value Function Loss: 3.21338

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.08790

Collected Steps per Second: 12,059.06294
Overall Steps per Second: 10,054.67872

Timestep Collection Time: 4.14875
Timestep Consumption Time: 0.82705
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.97579

Cumulative Model Updates: 54,324
Cumulative Timesteps: 906,145,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,629.09111
Policy Entropy: 1.05360
Value Function Loss: 3.20305

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.09261

Collected Steps per Second: 11,960.54164
Overall Steps per Second: 10,265.61694

Timestep Collection Time: 4.18259
Timestep Consumption Time: 0.69057
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.87316

Cumulative Model Updates: 54,327
Cumulative Timesteps: 906,195,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 906195338...
Checkpoint 906195338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,539.61585
Policy Entropy: 1.06854
Value Function Loss: 3.16096

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 11,897.42181
Overall Steps per Second: 9,949.27363

Timestep Collection Time: 4.20343
Timestep Consumption Time: 0.82307
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.02650

Cumulative Model Updates: 54,330
Cumulative Timesteps: 906,245,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,635.34989
Policy Entropy: 1.04975
Value Function Loss: 3.24557

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 11,842.68320
Overall Steps per Second: 10,065.13582

Timestep Collection Time: 4.22354
Timestep Consumption Time: 0.74590
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.96943

Cumulative Model Updates: 54,333
Cumulative Timesteps: 906,295,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 906295366...
Checkpoint 906295366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,422.22709
Policy Entropy: 1.05721
Value Function Loss: 3.12350

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 11,857.32212
Overall Steps per Second: 10,051.19742

Timestep Collection Time: 4.21933
Timestep Consumption Time: 0.75818
PPO Batch Consumption Time: 0.03878
Total Iteration Time: 4.97752

Cumulative Model Updates: 54,336
Cumulative Timesteps: 906,345,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,196.82564
Policy Entropy: 1.06245
Value Function Loss: 3.14478

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 12,072.10667
Overall Steps per Second: 10,122.70204

Timestep Collection Time: 4.14277
Timestep Consumption Time: 0.79780
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 4.94058

Cumulative Model Updates: 54,339
Cumulative Timesteps: 906,395,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 906395408...
Checkpoint 906395408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,495.11659
Policy Entropy: 1.06995
Value Function Loss: 2.92915

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 11,907.58713
Overall Steps per Second: 10,022.79500

Timestep Collection Time: 4.20152
Timestep Consumption Time: 0.79010
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.99162

Cumulative Model Updates: 54,342
Cumulative Timesteps: 906,445,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,094.46799
Policy Entropy: 1.04611
Value Function Loss: 2.92154

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.10327

Collected Steps per Second: 12,069.09321
Overall Steps per Second: 10,181.29399

Timestep Collection Time: 4.14530
Timestep Consumption Time: 0.76861
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 4.91391

Cumulative Model Updates: 54,345
Cumulative Timesteps: 906,495,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 906495468...
Checkpoint 906495468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,564.02271
Policy Entropy: 1.04744
Value Function Loss: 2.86576

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 11,788.90035
Overall Steps per Second: 10,156.42837

Timestep Collection Time: 4.24331
Timestep Consumption Time: 0.68204
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.92535

Cumulative Model Updates: 54,348
Cumulative Timesteps: 906,545,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,475.81166
Policy Entropy: 1.06069
Value Function Loss: 2.99922

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.10416

Collected Steps per Second: 12,001.57187
Overall Steps per Second: 9,766.78854

Timestep Collection Time: 4.16779
Timestep Consumption Time: 0.95365
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 5.12144

Cumulative Model Updates: 54,351
Cumulative Timesteps: 906,595,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 906595512...
Checkpoint 906595512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,124.07800
Policy Entropy: 1.06935
Value Function Loss: 3.08235

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.09707

Collected Steps per Second: 11,834.41112
Overall Steps per Second: 9,928.96974

Timestep Collection Time: 4.22497
Timestep Consumption Time: 0.81080
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.03577

Cumulative Model Updates: 54,354
Cumulative Timesteps: 906,645,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,990.75088
Policy Entropy: 1.04956
Value Function Loss: 3.29884

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11,941.07744
Overall Steps per Second: 10,206.63163

Timestep Collection Time: 4.18790
Timestep Consumption Time: 0.71166
PPO Batch Consumption Time: 0.04476
Total Iteration Time: 4.89956

Cumulative Model Updates: 54,357
Cumulative Timesteps: 906,695,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 906695520...
Checkpoint 906695520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,387.14185
Policy Entropy: 1.06638
Value Function Loss: 3.37135

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.08744

Collected Steps per Second: 12,345.28810
Overall Steps per Second: 10,311.16159

Timestep Collection Time: 4.05191
Timestep Consumption Time: 0.79934
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.85125

Cumulative Model Updates: 54,360
Cumulative Timesteps: 906,745,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,181.25720
Policy Entropy: 1.06177
Value Function Loss: 3.31095

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.09929

Collected Steps per Second: 12,471.67512
Overall Steps per Second: 10,529.04226

Timestep Collection Time: 4.00973
Timestep Consumption Time: 0.73980
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.74953

Cumulative Model Updates: 54,363
Cumulative Timesteps: 906,795,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 906795550...
Checkpoint 906795550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,386.13401
Policy Entropy: 1.05331
Value Function Loss: 3.10307

Mean KL Divergence: 0.02789
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 12,813.20287
Overall Steps per Second: 10,720.53071

Timestep Collection Time: 3.90301
Timestep Consumption Time: 0.76188
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.66488

Cumulative Model Updates: 54,366
Cumulative Timesteps: 906,845,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,919.40547
Policy Entropy: 1.04329
Value Function Loss: 2.97143

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.18521
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.08491

Collected Steps per Second: 12,642.46350
Overall Steps per Second: 10,663.62193

Timestep Collection Time: 3.95493
Timestep Consumption Time: 0.73391
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.68884

Cumulative Model Updates: 54,369
Cumulative Timesteps: 906,895,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 906895560...
Checkpoint 906895560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,287.62266
Policy Entropy: 1.05025
Value Function Loss: 2.98062

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08685

Collected Steps per Second: 11,675.45076
Overall Steps per Second: 10,069.64634

Timestep Collection Time: 4.28472
Timestep Consumption Time: 0.68328
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.96800

Cumulative Model Updates: 54,372
Cumulative Timesteps: 906,945,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,676.33248
Policy Entropy: 1.06332
Value Function Loss: 2.97892

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 12,667.53480
Overall Steps per Second: 10,598.29000

Timestep Collection Time: 3.94710
Timestep Consumption Time: 0.77064
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.71774

Cumulative Model Updates: 54,375
Cumulative Timesteps: 906,995,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 906995586...
Checkpoint 906995586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,704.53032
Policy Entropy: 1.03899
Value Function Loss: 2.94273

Mean KL Divergence: 0.03261
SB3 Clip Fraction: 0.18347
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.07264

Collected Steps per Second: 11,889.82959
Overall Steps per Second: 10,034.44726

Timestep Collection Time: 4.20780
Timestep Consumption Time: 0.77803
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 4.98583

Cumulative Model Updates: 54,378
Cumulative Timesteps: 907,045,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,876.30935
Policy Entropy: 1.06354
Value Function Loss: 2.89808

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06213

Collected Steps per Second: 12,133.91742
Overall Steps per Second: 10,265.73914

Timestep Collection Time: 4.12216
Timestep Consumption Time: 0.75016
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.87232

Cumulative Model Updates: 54,381
Cumulative Timesteps: 907,095,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907095634...
Checkpoint 907095634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,241.17531
Policy Entropy: 1.05658
Value Function Loss: 2.90753

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.05646

Collected Steps per Second: 11,695.99039
Overall Steps per Second: 9,789.46505

Timestep Collection Time: 4.27668
Timestep Consumption Time: 0.83290
PPO Batch Consumption Time: 0.03781
Total Iteration Time: 5.10957

Cumulative Model Updates: 54,384
Cumulative Timesteps: 907,145,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,822.44513
Policy Entropy: 1.04265
Value Function Loss: 3.14965

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.07142

Collected Steps per Second: 11,746.38866
Overall Steps per Second: 10,139.02904

Timestep Collection Time: 4.25816
Timestep Consumption Time: 0.67505
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.93321

Cumulative Model Updates: 54,387
Cumulative Timesteps: 907,195,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907195672...
Checkpoint 907195672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,972.71476
Policy Entropy: 1.02812
Value Function Loss: 3.16182

Mean KL Divergence: 0.03315
SB3 Clip Fraction: 0.20631
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 11,401.80962
Overall Steps per Second: 9,666.73449

Timestep Collection Time: 4.38527
Timestep Consumption Time: 0.78711
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.17238

Cumulative Model Updates: 54,390
Cumulative Timesteps: 907,245,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,854.67925
Policy Entropy: 1.04751
Value Function Loss: 3.09290

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.08232

Collected Steps per Second: 12,035.03432
Overall Steps per Second: 10,177.94412

Timestep Collection Time: 4.15620
Timestep Consumption Time: 0.75835
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.91455

Cumulative Model Updates: 54,393
Cumulative Timesteps: 907,295,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 907295692...
Checkpoint 907295692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753,466.77803
Policy Entropy: 1.05742
Value Function Loss: 2.96768

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 12,113.34380
Overall Steps per Second: 10,181.34353

Timestep Collection Time: 4.12933
Timestep Consumption Time: 0.78358
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 4.91291

Cumulative Model Updates: 54,396
Cumulative Timesteps: 907,345,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,173.94420
Policy Entropy: 1.03949
Value Function Loss: 2.91406

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 11,907.59682
Overall Steps per Second: 10,047.79976

Timestep Collection Time: 4.20102
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 4.97860

Cumulative Model Updates: 54,399
Cumulative Timesteps: 907,395,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 907395736...
Checkpoint 907395736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,503.36337
Policy Entropy: 1.05391
Value Function Loss: 3.07570

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.16783
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 11,895.23585
Overall Steps per Second: 10,230.39157

Timestep Collection Time: 4.20589
Timestep Consumption Time: 0.68445
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.89033

Cumulative Model Updates: 54,402
Cumulative Timesteps: 907,445,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,186.88223
Policy Entropy: 1.04839
Value Function Loss: 3.10909

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.17060
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.07107

Collected Steps per Second: 11,658.03369
Overall Steps per Second: 9,845.30181

Timestep Collection Time: 4.28940
Timestep Consumption Time: 0.78977
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.07917

Cumulative Model Updates: 54,405
Cumulative Timesteps: 907,495,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 907495772...
Checkpoint 907495772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,890.14137
Policy Entropy: 1.03307
Value Function Loss: 3.15774

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.17610
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 11,230.59339
Overall Steps per Second: 9,601.06776

Timestep Collection Time: 4.45212
Timestep Consumption Time: 0.75563
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.20775

Cumulative Model Updates: 54,408
Cumulative Timesteps: 907,545,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,261.33124
Policy Entropy: 1.02736
Value Function Loss: 3.07821

Mean KL Divergence: 0.02731
SB3 Clip Fraction: 0.19541
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 12,269.00229
Overall Steps per Second: 10,247.38257

Timestep Collection Time: 4.07792
Timestep Consumption Time: 0.80450
PPO Batch Consumption Time: 0.03880
Total Iteration Time: 4.88242

Cumulative Model Updates: 54,411
Cumulative Timesteps: 907,595,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 907595804...
Checkpoint 907595804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,562.09641
Policy Entropy: 1.03719
Value Function Loss: 3.04437

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 11,667.55808
Overall Steps per Second: 9,776.91197

Timestep Collection Time: 4.28590
Timestep Consumption Time: 0.82880
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.11470

Cumulative Model Updates: 54,414
Cumulative Timesteps: 907,645,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,796.36490
Policy Entropy: 1.05110
Value Function Loss: 2.98118

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.17867
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 12,080.00807
Overall Steps per Second: 10,349.29566

Timestep Collection Time: 4.14122
Timestep Consumption Time: 0.69254
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.83376

Cumulative Model Updates: 54,417
Cumulative Timesteps: 907,695,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 907695836...
Checkpoint 907695836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,056.44240
Policy Entropy: 1.01609
Value Function Loss: 2.91267

Mean KL Divergence: 0.07192
SB3 Clip Fraction: 0.24842
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.07389

Collected Steps per Second: 11,590.48669
Overall Steps per Second: 9,749.42838

Timestep Collection Time: 4.31388
Timestep Consumption Time: 0.81462
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.12851

Cumulative Model Updates: 54,420
Cumulative Timesteps: 907,745,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,837.88860
Policy Entropy: 1.05120
Value Function Loss: 2.78913

Mean KL Divergence: 0.04428
SB3 Clip Fraction: 0.23013
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 11,717.45770
Overall Steps per Second: 9,948.92293

Timestep Collection Time: 4.26748
Timestep Consumption Time: 0.75859
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.02607

Cumulative Model Updates: 54,423
Cumulative Timesteps: 907,795,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 907795840...
Checkpoint 907795840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,515.45051
Policy Entropy: 1.02504
Value Function Loss: 2.86647

Mean KL Divergence: 0.05120
SB3 Clip Fraction: 0.23041
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 11,627.06898
Overall Steps per Second: 9,827.34245

Timestep Collection Time: 4.30289
Timestep Consumption Time: 0.78801
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.09090

Cumulative Model Updates: 54,426
Cumulative Timesteps: 907,845,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,684.72172
Policy Entropy: 1.05032
Value Function Loss: 2.92402

Mean KL Divergence: 0.03528
SB3 Clip Fraction: 0.19569
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 11,725.10309
Overall Steps per Second: 9,959.04840

Timestep Collection Time: 4.26589
Timestep Consumption Time: 0.75648
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.02237

Cumulative Model Updates: 54,429
Cumulative Timesteps: 907,895,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907895888...
Checkpoint 907895888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,023.17610
Policy Entropy: 1.03521
Value Function Loss: 2.97767

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 12,026.76612
Overall Steps per Second: 10,354.45719

Timestep Collection Time: 4.15972
Timestep Consumption Time: 0.67182
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 4.83154

Cumulative Model Updates: 54,432
Cumulative Timesteps: 907,945,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,938.23214
Policy Entropy: 1.02453
Value Function Loss: 3.14354

Mean KL Divergence: 0.03182
SB3 Clip Fraction: 0.20501
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.08688

Collected Steps per Second: 12,230.79866
Overall Steps per Second: 10,247.14259

Timestep Collection Time: 4.08820
Timestep Consumption Time: 0.79140
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.87960

Cumulative Model Updates: 54,435
Cumulative Timesteps: 907,995,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 907995918...
Checkpoint 907995918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759,243.37624
Policy Entropy: 1.03966
Value Function Loss: 3.07171

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 12,039.17055
Overall Steps per Second: 10,173.09122

Timestep Collection Time: 4.15494
Timestep Consumption Time: 0.76215
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.91709

Cumulative Model Updates: 54,438
Cumulative Timesteps: 908,045,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,610.77655
Policy Entropy: 1.03464
Value Function Loss: 3.24202

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 11,935.56968
Overall Steps per Second: 10,174.14793

Timestep Collection Time: 4.19100
Timestep Consumption Time: 0.72558
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.91658

Cumulative Model Updates: 54,441
Cumulative Timesteps: 908,095,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 908095962...
Checkpoint 908095962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,898.43902
Policy Entropy: 1.03344
Value Function Loss: 3.01053

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.10623

Collected Steps per Second: 11,531.87762
Overall Steps per Second: 9,815.35347

Timestep Collection Time: 4.33650
Timestep Consumption Time: 0.75837
PPO Batch Consumption Time: 0.03345
Total Iteration Time: 5.09488

Cumulative Model Updates: 54,444
Cumulative Timesteps: 908,145,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,421.46728
Policy Entropy: 1.02154
Value Function Loss: 3.08522

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.06513
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 12,255.02570
Overall Steps per Second: 10,363.75783

Timestep Collection Time: 4.08045
Timestep Consumption Time: 0.74464
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.82508

Cumulative Model Updates: 54,447
Cumulative Timesteps: 908,195,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 908195976...
Checkpoint 908195976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,706.34660
Policy Entropy: 1.04494
Value Function Loss: 2.99998

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.10757

Collected Steps per Second: 11,327.98944
Overall Steps per Second: 9,589.66147

Timestep Collection Time: 4.41508
Timestep Consumption Time: 0.80033
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.21541

Cumulative Model Updates: 54,450
Cumulative Timesteps: 908,245,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,119.41905
Policy Entropy: 1.03954
Value Function Loss: 3.02730

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11,255.60020
Overall Steps per Second: 9,599.70088

Timestep Collection Time: 4.44259
Timestep Consumption Time: 0.76632
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 5.20891

Cumulative Model Updates: 54,453
Cumulative Timesteps: 908,295,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 908295994...
Checkpoint 908295994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,465.36042
Policy Entropy: 1.02620
Value Function Loss: 3.07767

Mean KL Divergence: 0.02589
SB3 Clip Fraction: 0.17097
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 11,697.06774
Overall Steps per Second: 10,082.22862

Timestep Collection Time: 4.27629
Timestep Consumption Time: 0.68492
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.96120

Cumulative Model Updates: 54,456
Cumulative Timesteps: 908,346,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,100.83848
Policy Entropy: 1.01482
Value Function Loss: 3.18619

Mean KL Divergence: 0.03497
SB3 Clip Fraction: 0.20414
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 11,885.73052
Overall Steps per Second: 10,012.54652

Timestep Collection Time: 4.20740
Timestep Consumption Time: 0.78714
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 4.99453

Cumulative Model Updates: 54,459
Cumulative Timesteps: 908,396,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 908396022...
Checkpoint 908396022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,224.27320
Policy Entropy: 1.02420
Value Function Loss: 3.13810

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 11,431.18845
Overall Steps per Second: 9,692.32778

Timestep Collection Time: 4.37662
Timestep Consumption Time: 0.78519
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.16181

Cumulative Model Updates: 54,462
Cumulative Timesteps: 908,446,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795,020.17654
Policy Entropy: 1.03383
Value Function Loss: 3.10818

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.09262

Collected Steps per Second: 12,209.03842
Overall Steps per Second: 10,295.81006

Timestep Collection Time: 4.09762
Timestep Consumption Time: 0.76144
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.85906

Cumulative Model Updates: 54,465
Cumulative Timesteps: 908,496,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 908496080...
Checkpoint 908496080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,147.92354
Policy Entropy: 1.01487
Value Function Loss: 3.11202

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 12,097.01794
Overall Steps per Second: 10,145.57284

Timestep Collection Time: 4.13408
Timestep Consumption Time: 0.79517
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.92924

Cumulative Model Updates: 54,468
Cumulative Timesteps: 908,546,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,312.77909
Policy Entropy: 1.01456
Value Function Loss: 3.31555

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.16469
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.09169

Collected Steps per Second: 11,710.79427
Overall Steps per Second: 10,080.79589

Timestep Collection Time: 4.27179
Timestep Consumption Time: 0.69072
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.96250

Cumulative Model Updates: 54,471
Cumulative Timesteps: 908,596,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 908596116...
Checkpoint 908596116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,475.93958
Policy Entropy: 1.03486
Value Function Loss: 3.29026

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 11,563.58219
Overall Steps per Second: 9,827.88235

Timestep Collection Time: 4.32444
Timestep Consumption Time: 0.76374
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 5.08818

Cumulative Model Updates: 54,474
Cumulative Timesteps: 908,646,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766,434.36763
Policy Entropy: 1.03547
Value Function Loss: 3.15859

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 11,808.84710
Overall Steps per Second: 10,066.70910

Timestep Collection Time: 4.23598
Timestep Consumption Time: 0.73308
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.96905

Cumulative Model Updates: 54,477
Cumulative Timesteps: 908,696,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 908696144...
Checkpoint 908696144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,839.30676
Policy Entropy: 1.02407
Value Function Loss: 3.00519

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 11,323.23183
Overall Steps per Second: 9,814.65589

Timestep Collection Time: 4.41658
Timestep Consumption Time: 0.67886
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.09544

Cumulative Model Updates: 54,480
Cumulative Timesteps: 908,746,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,658.66706
Policy Entropy: 1.00290
Value Function Loss: 2.98407

Mean KL Divergence: 0.03307
SB3 Clip Fraction: 0.20300
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 12,069.10325
Overall Steps per Second: 10,189.49358

Timestep Collection Time: 4.14463
Timestep Consumption Time: 0.76454
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.90917

Cumulative Model Updates: 54,483
Cumulative Timesteps: 908,796,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 908796176...
Checkpoint 908796176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,133.86202
Policy Entropy: 1.04218
Value Function Loss: 2.87778

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.20927
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 11,796.28412
Overall Steps per Second: 10,062.67861

Timestep Collection Time: 4.23862
Timestep Consumption Time: 0.73023
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.96886

Cumulative Model Updates: 54,486
Cumulative Timesteps: 908,846,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,676.56948
Policy Entropy: 1.00062
Value Function Loss: 3.03214

Mean KL Divergence: 0.05484
SB3 Clip Fraction: 0.24821
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09034

Collected Steps per Second: 12,125.60334
Overall Steps per Second: 10,165.61736

Timestep Collection Time: 4.12615
Timestep Consumption Time: 0.79554
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.92169

Cumulative Model Updates: 54,489
Cumulative Timesteps: 908,896,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 908896208...
Checkpoint 908896208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,815.99414
Policy Entropy: 1.04814
Value Function Loss: 2.96879

Mean KL Divergence: 0.04457
SB3 Clip Fraction: 0.24209
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.08628

Collected Steps per Second: 11,775.93394
Overall Steps per Second: 9,918.90527

Timestep Collection Time: 4.24850
Timestep Consumption Time: 0.79541
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.04390

Cumulative Model Updates: 54,492
Cumulative Timesteps: 908,946,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,529.79847
Policy Entropy: 1.00665
Value Function Loss: 3.18361

Mean KL Divergence: 0.06051
SB3 Clip Fraction: 0.27319
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.09405

Collected Steps per Second: 11,670.36757
Overall Steps per Second: 10,046.45037

Timestep Collection Time: 4.28504
Timestep Consumption Time: 0.69264
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 4.97768

Cumulative Model Updates: 54,495
Cumulative Timesteps: 908,996,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 908996246...
Checkpoint 908996246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,210.23467
Policy Entropy: 1.03970
Value Function Loss: 3.11248

Mean KL Divergence: 0.04137
SB3 Clip Fraction: 0.24362
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.09353

Collected Steps per Second: 11,380.10699
Overall Steps per Second: 9,645.77640

Timestep Collection Time: 4.39556
Timestep Consumption Time: 0.79033
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.18590

Cumulative Model Updates: 54,498
Cumulative Timesteps: 909,046,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,059.60227
Policy Entropy: 1.00550
Value Function Loss: 3.15442

Mean KL Divergence: 0.04840
SB3 Clip Fraction: 0.23865
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 11,923.67324
Overall Steps per Second: 10,089.35674

Timestep Collection Time: 4.19552
Timestep Consumption Time: 0.76278
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.95829

Cumulative Model Updates: 54,501
Cumulative Timesteps: 909,096,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 909096294...
Checkpoint 909096294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,525.06762
Policy Entropy: 1.02923
Value Function Loss: 3.13471

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.18840
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 12,809.49164
Overall Steps per Second: 10,893.12638

Timestep Collection Time: 3.90460
Timestep Consumption Time: 0.68691
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.59152

Cumulative Model Updates: 54,504
Cumulative Timesteps: 909,146,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,022.86432
Policy Entropy: 1.02040
Value Function Loss: 3.07942

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 12,660.43067
Overall Steps per Second: 10,529.59524

Timestep Collection Time: 3.95121
Timestep Consumption Time: 0.79959
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.75080

Cumulative Model Updates: 54,507
Cumulative Timesteps: 909,196,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 909196334...
Checkpoint 909196334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,076.79261
Policy Entropy: 1.00636
Value Function Loss: 2.98608

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.18974
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.06799

Collected Steps per Second: 11,460.86749
Overall Steps per Second: 9,730.86442

Timestep Collection Time: 4.36511
Timestep Consumption Time: 0.77605
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.14117

Cumulative Model Updates: 54,510
Cumulative Timesteps: 909,246,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,141.32847
Policy Entropy: 1.02381
Value Function Loss: 3.02298

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.09206

Collected Steps per Second: 12,758.88378
Overall Steps per Second: 10,637.76622

Timestep Collection Time: 3.92056
Timestep Consumption Time: 0.78174
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.70230

Cumulative Model Updates: 54,513
Cumulative Timesteps: 909,296,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 909296384...
Checkpoint 909296384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,811.00597
Policy Entropy: 1.02940
Value Function Loss: 2.87992

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.18027
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 11,584.84326
Overall Steps per Second: 9,768.66251

Timestep Collection Time: 4.31616
Timestep Consumption Time: 0.80246
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 5.11861

Cumulative Model Updates: 54,516
Cumulative Timesteps: 909,346,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766,955.88590
Policy Entropy: 1.02362
Value Function Loss: 3.10950

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 12,619.38803
Overall Steps per Second: 10,694.44111

Timestep Collection Time: 3.96295
Timestep Consumption Time: 0.71331
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 4.67626

Cumulative Model Updates: 54,519
Cumulative Timesteps: 909,396,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 909396396...
Checkpoint 909396396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,280.88305
Policy Entropy: 0.99814
Value Function Loss: 3.11838

Mean KL Divergence: 0.03494
SB3 Clip Fraction: 0.23791
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.10047

Collected Steps per Second: 11,872.92326
Overall Steps per Second: 9,996.61051

Timestep Collection Time: 4.21295
Timestep Consumption Time: 0.79075
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.00370

Cumulative Model Updates: 54,522
Cumulative Timesteps: 909,446,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,244.17177
Policy Entropy: 1.03097
Value Function Loss: 3.14985

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.17933
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.08852

Collected Steps per Second: 11,859.96946
Overall Steps per Second: 10,067.36078

Timestep Collection Time: 4.21704
Timestep Consumption Time: 0.75089
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.96794

Cumulative Model Updates: 54,525
Cumulative Timesteps: 909,496,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 909496430...
Checkpoint 909496430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,492.68272
Policy Entropy: 1.00388
Value Function Loss: 2.94116

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.19076
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.08711

Collected Steps per Second: 12,068.10712
Overall Steps per Second: 10,185.22066

Timestep Collection Time: 4.14365
Timestep Consumption Time: 0.76601
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.90966

Cumulative Model Updates: 54,528
Cumulative Timesteps: 909,546,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,906.49594
Policy Entropy: 1.02157
Value Function Loss: 3.08675

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11,983.11642
Overall Steps per Second: 10,159.33858

Timestep Collection Time: 4.17454
Timestep Consumption Time: 0.74940
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.92394

Cumulative Model Updates: 54,531
Cumulative Timesteps: 909,596,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 909596460...
Checkpoint 909596460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,644.83983
Policy Entropy: 1.02531
Value Function Loss: 3.14598

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 11,355.87711
Overall Steps per Second: 9,618.35200

Timestep Collection Time: 4.40530
Timestep Consumption Time: 0.79580
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.20110

Cumulative Model Updates: 54,534
Cumulative Timesteps: 909,646,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,149.01977
Policy Entropy: 1.02367
Value Function Loss: 3.16697

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.07213
Value Function Update Magnitude: 0.09499

Collected Steps per Second: 11,858.57375
Overall Steps per Second: 9,973.80302

Timestep Collection Time: 4.21838
Timestep Consumption Time: 0.79716
PPO Batch Consumption Time: 0.03337
Total Iteration Time: 5.01554

Cumulative Model Updates: 54,537
Cumulative Timesteps: 909,696,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 909696510...
Checkpoint 909696510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,079.35257
Policy Entropy: 1.01969
Value Function Loss: 3.03933

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.07126
Value Function Update Magnitude: 0.09121

Collected Steps per Second: 12,098.86448
Overall Steps per Second: 10,285.54021

Timestep Collection Time: 4.13510
Timestep Consumption Time: 0.72901
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.86411

Cumulative Model Updates: 54,540
Cumulative Timesteps: 909,746,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,783.20325
Policy Entropy: 1.00896
Value Function Loss: 2.88060

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.18085
Policy Update Magnitude: 0.06637
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 11,446.48783
Overall Steps per Second: 9,686.14317

Timestep Collection Time: 4.37007
Timestep Consumption Time: 0.79421
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 5.16428

Cumulative Model Updates: 54,543
Cumulative Timesteps: 909,796,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 909796562...
Checkpoint 909796562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,529.17777
Policy Entropy: 1.02192
Value Function Loss: 2.96309

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.15967
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.10804

Collected Steps per Second: 11,728.27655
Overall Steps per Second: 9,976.05623

Timestep Collection Time: 4.26337
Timestep Consumption Time: 0.74883
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.01220

Cumulative Model Updates: 54,546
Cumulative Timesteps: 909,846,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,508.40218
Policy Entropy: 1.03485
Value Function Loss: 2.78940

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.18173
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 11,859.70276
Overall Steps per Second: 10,223.87461

Timestep Collection Time: 4.21832
Timestep Consumption Time: 0.67493
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.89325

Cumulative Model Updates: 54,549
Cumulative Timesteps: 909,896,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 909896592...
Checkpoint 909896592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,200.50131
Policy Entropy: 1.02307
Value Function Loss: 2.99747

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 11,441.67064
Overall Steps per Second: 9,694.64148

Timestep Collection Time: 4.37034
Timestep Consumption Time: 0.78756
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.15790

Cumulative Model Updates: 54,552
Cumulative Timesteps: 909,946,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,397.86369
Policy Entropy: 1.01841
Value Function Loss: 3.12052

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.19264
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 12,006.79641
Overall Steps per Second: 10,086.68091

Timestep Collection Time: 4.16514
Timestep Consumption Time: 0.79288
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.95802

Cumulative Model Updates: 54,555
Cumulative Timesteps: 909,996,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 909996606...
Checkpoint 909996606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,640.23507
Policy Entropy: 1.03232
Value Function Loss: 3.22050

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.08821

Collected Steps per Second: 11,995.11646
Overall Steps per Second: 10,117.52692

Timestep Collection Time: 4.16870
Timestep Consumption Time: 0.77362
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.94231

Cumulative Model Updates: 54,558
Cumulative Timesteps: 910,046,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,002.44163
Policy Entropy: 1.02712
Value Function Loss: 3.21151

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 12,032.33618
Overall Steps per Second: 10,120.19880

Timestep Collection Time: 4.15813
Timestep Consumption Time: 0.78565
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 4.94378

Cumulative Model Updates: 54,561
Cumulative Timesteps: 910,096,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 910096642...
Checkpoint 910096642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,851.18349
Policy Entropy: 1.02798
Value Function Loss: 3.14450

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.07800

Collected Steps per Second: 12,024.95610
Overall Steps per Second: 10,259.78095

Timestep Collection Time: 4.15852
Timestep Consumption Time: 0.71546
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.87398

Cumulative Model Updates: 54,564
Cumulative Timesteps: 910,146,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,714.63056
Policy Entropy: 1.02352
Value Function Loss: 3.27871

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 11,935.40355
Overall Steps per Second: 10,049.07165

Timestep Collection Time: 4.19073
Timestep Consumption Time: 0.78665
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 4.97738

Cumulative Model Updates: 54,567
Cumulative Timesteps: 910,196,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 910196666...
Checkpoint 910196666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,644.27084
Policy Entropy: 1.02723
Value Function Loss: 3.14350

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.07433

Collected Steps per Second: 11,472.29823
Overall Steps per Second: 9,798.52501

Timestep Collection Time: 4.35920
Timestep Consumption Time: 0.74463
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 5.10383

Cumulative Model Updates: 54,570
Cumulative Timesteps: 910,246,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,577.70543
Policy Entropy: 1.03455
Value Function Loss: 3.00111

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 12,267.47231
Overall Steps per Second: 10,276.26912

Timestep Collection Time: 4.07598
Timestep Consumption Time: 0.78979
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.86577

Cumulative Model Updates: 54,573
Cumulative Timesteps: 910,296,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 910296678...
Checkpoint 910296678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,589.91956
Policy Entropy: 1.03612
Value Function Loss: 2.84256

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.08468

Collected Steps per Second: 11,687.07554
Overall Steps per Second: 9,907.40625

Timestep Collection Time: 4.27857
Timestep Consumption Time: 0.76856
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 5.04713

Cumulative Model Updates: 54,576
Cumulative Timesteps: 910,346,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,980.98896
Policy Entropy: 1.03936
Value Function Loss: 2.87899

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 11,795.80212
Overall Steps per Second: 10,147.10955

Timestep Collection Time: 4.23914
Timestep Consumption Time: 0.68877
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.92791

Cumulative Model Updates: 54,579
Cumulative Timesteps: 910,396,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 910396686...
Checkpoint 910396686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,099.05374
Policy Entropy: 1.03678
Value Function Loss: 2.92735

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.09631

Collected Steps per Second: 12,078.06599
Overall Steps per Second: 10,130.90308

Timestep Collection Time: 4.14007
Timestep Consumption Time: 0.79572
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.93579

Cumulative Model Updates: 54,582
Cumulative Timesteps: 910,446,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,033.25584
Policy Entropy: 1.03750
Value Function Loss: 2.98825

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.07478
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 11,740.31551
Overall Steps per Second: 10,031.23313

Timestep Collection Time: 4.26002
Timestep Consumption Time: 0.72581
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 4.98583

Cumulative Model Updates: 54,585
Cumulative Timesteps: 910,496,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 910496704...
Checkpoint 910496704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768,629.50344
Policy Entropy: 1.02876
Value Function Loss: 2.92890

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.07947
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 11,675.72792
Overall Steps per Second: 9,922.02896

Timestep Collection Time: 4.28410
Timestep Consumption Time: 0.75721
PPO Batch Consumption Time: 0.03293
Total Iteration Time: 5.04131

Cumulative Model Updates: 54,588
Cumulative Timesteps: 910,546,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,938.28956
Policy Entropy: 1.02575
Value Function Loss: 3.01648

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.07818
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 12,054.16918
Overall Steps per Second: 10,095.95743

Timestep Collection Time: 4.14844
Timestep Consumption Time: 0.80463
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.95307

Cumulative Model Updates: 54,591
Cumulative Timesteps: 910,596,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910596730...
Checkpoint 910596730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,375.15411
Policy Entropy: 1.01477
Value Function Loss: 3.05003

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.07813
Value Function Update Magnitude: 0.06311

Collected Steps per Second: 11,624.15523
Overall Steps per Second: 10,027.30165

Timestep Collection Time: 4.30156
Timestep Consumption Time: 0.68503
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.98659

Cumulative Model Updates: 54,594
Cumulative Timesteps: 910,646,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,521.57288
Policy Entropy: 1.02922
Value Function Loss: 3.22470

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.06523

Collected Steps per Second: 11,857.10713
Overall Steps per Second: 10,077.15880

Timestep Collection Time: 4.21739
Timestep Consumption Time: 0.74493
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.96231

Cumulative Model Updates: 54,597
Cumulative Timesteps: 910,696,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910696738...
Checkpoint 910696738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566,795.86320
Policy Entropy: 1.03285
Value Function Loss: 3.12444

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.06972

Collected Steps per Second: 11,932.56478
Overall Steps per Second: 10,063.57077

Timestep Collection Time: 4.19021
Timestep Consumption Time: 0.77820
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 4.96842

Cumulative Model Updates: 54,600
Cumulative Timesteps: 910,746,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,439.73046
Policy Entropy: 1.03311
Value Function Loss: 3.06871

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.07126
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 11,563.26236
Overall Steps per Second: 9,960.24821

Timestep Collection Time: 4.32594
Timestep Consumption Time: 0.69622
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.02216

Cumulative Model Updates: 54,603
Cumulative Timesteps: 910,796,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 910796760...
Checkpoint 910796760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859,668.26110
Policy Entropy: 1.03304
Value Function Loss: 2.99707

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.06908
Value Function Update Magnitude: 0.09674

Collected Steps per Second: 11,413.00073
Overall Steps per Second: 9,613.24691

Timestep Collection Time: 4.38237
Timestep Consumption Time: 0.82045
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.20282

Cumulative Model Updates: 54,606
Cumulative Timesteps: 910,846,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760,349.70570
Policy Entropy: 1.03177
Value Function Loss: 3.02001

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.09619

Collected Steps per Second: 11,882.80373
Overall Steps per Second: 10,100.28912

Timestep Collection Time: 4.20843
Timestep Consumption Time: 0.74271
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.95115

Cumulative Model Updates: 54,609
Cumulative Timesteps: 910,896,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 910896784...
Checkpoint 910896784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,493.85886
Policy Entropy: 1.03444
Value Function Loss: 3.08706

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.07577
Value Function Update Magnitude: 0.08846

Collected Steps per Second: 12,019.30354
Overall Steps per Second: 10,092.07872

Timestep Collection Time: 4.16197
Timestep Consumption Time: 0.79479
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.95676

Cumulative Model Updates: 54,612
Cumulative Timesteps: 910,946,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,926.65438
Policy Entropy: 1.03391
Value Function Loss: 3.01248

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.07775
Value Function Update Magnitude: 0.09757

Collected Steps per Second: 11,575.47604
Overall Steps per Second: 9,793.55416

Timestep Collection Time: 4.32017
Timestep Consumption Time: 0.78605
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.10622

Cumulative Model Updates: 54,615
Cumulative Timesteps: 910,996,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 910996816...
Checkpoint 910996816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,665.40945
Policy Entropy: 1.05193
Value Function Loss: 2.95386

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.16520
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 11,881.35705
Overall Steps per Second: 10,094.34865

Timestep Collection Time: 4.20827
Timestep Consumption Time: 0.74499
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.95327

Cumulative Model Updates: 54,618
Cumulative Timesteps: 911,046,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,727.57203
Policy Entropy: 1.04817
Value Function Loss: 3.09486

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.06336
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 12,149.05746
Overall Steps per Second: 10,086.55180

Timestep Collection Time: 4.11703
Timestep Consumption Time: 0.84185
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.95888

Cumulative Model Updates: 54,621
Cumulative Timesteps: 911,096,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911096834...
Checkpoint 911096834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,493.76048
Policy Entropy: 1.03427
Value Function Loss: 3.03267

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.11854

Collected Steps per Second: 11,442.50440
Overall Steps per Second: 9,772.43678

Timestep Collection Time: 4.37072
Timestep Consumption Time: 0.74694
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.11766

Cumulative Model Updates: 54,624
Cumulative Timesteps: 911,146,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,444.86433
Policy Entropy: 1.01701
Value Function Loss: 3.19607

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.18367
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.11396

Collected Steps per Second: 12,009.43959
Overall Steps per Second: 10,320.45016

Timestep Collection Time: 4.16522
Timestep Consumption Time: 0.68166
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 4.84688

Cumulative Model Updates: 54,627
Cumulative Timesteps: 911,196,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 911196868...
Checkpoint 911196868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,674.57101
Policy Entropy: 1.04256
Value Function Loss: 3.05669

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 11,758.64420
Overall Steps per Second: 9,946.46888

Timestep Collection Time: 4.25372
Timestep Consumption Time: 0.77500
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.02872

Cumulative Model Updates: 54,630
Cumulative Timesteps: 911,246,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820,098.68400
Policy Entropy: 1.04218
Value Function Loss: 3.14200

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 11,916.84385
Overall Steps per Second: 10,077.52211

Timestep Collection Time: 4.19625
Timestep Consumption Time: 0.76589
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.96213

Cumulative Model Updates: 54,633
Cumulative Timesteps: 911,296,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 911296892...
Checkpoint 911296892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746,640.31601
Policy Entropy: 1.02324
Value Function Loss: 3.00756

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12114

Collected Steps per Second: 12,180.58975
Overall Steps per Second: 10,178.05306

Timestep Collection Time: 4.10703
Timestep Consumption Time: 0.80806
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.91509

Cumulative Model Updates: 54,636
Cumulative Timesteps: 911,346,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,513.47268
Policy Entropy: 1.01409
Value Function Loss: 2.91849

Mean KL Divergence: 0.03627
SB3 Clip Fraction: 0.20281
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.10893

Collected Steps per Second: 11,936.53886
Overall Steps per Second: 10,096.67368

Timestep Collection Time: 4.18966
Timestep Consumption Time: 0.76346
PPO Batch Consumption Time: 0.03403
Total Iteration Time: 4.95312

Cumulative Model Updates: 54,639
Cumulative Timesteps: 911,396,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 911396928...
Checkpoint 911396928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,853.42638
Policy Entropy: 1.03903
Value Function Loss: 2.96160

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 11,324.24847
Overall Steps per Second: 9,624.04008

Timestep Collection Time: 4.41619
Timestep Consumption Time: 0.78018
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 5.19636

Cumulative Model Updates: 54,642
Cumulative Timesteps: 911,446,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,451.23253
Policy Entropy: 1.03116
Value Function Loss: 2.98722

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11728

Collected Steps per Second: 11,774.03550
Overall Steps per Second: 9,941.22949

Timestep Collection Time: 4.24833
Timestep Consumption Time: 0.78324
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.03157

Cumulative Model Updates: 54,645
Cumulative Timesteps: 911,496,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 911496958...
Checkpoint 911496958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741,591.91520
Policy Entropy: 1.02143
Value Function Loss: 2.90766

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.20539
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 12,709.96370
Overall Steps per Second: 10,530.87426

Timestep Collection Time: 3.93408
Timestep Consumption Time: 0.81405
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.74813

Cumulative Model Updates: 54,648
Cumulative Timesteps: 911,546,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,819.51695
Policy Entropy: 1.03088
Value Function Loss: 2.94639

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.11766

Collected Steps per Second: 13,209.57278
Overall Steps per Second: 10,970.73668

Timestep Collection Time: 3.78604
Timestep Consumption Time: 0.77263
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.55867

Cumulative Model Updates: 54,651
Cumulative Timesteps: 911,596,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911596972...
Checkpoint 911596972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773,663.20057
Policy Entropy: 1.03927
Value Function Loss: 2.96875

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.17042
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 12,845.10068
Overall Steps per Second: 10,705.22339

Timestep Collection Time: 3.89347
Timestep Consumption Time: 0.77827
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 4.67174

Cumulative Model Updates: 54,654
Cumulative Timesteps: 911,646,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,619.23494
Policy Entropy: 1.00452
Value Function Loss: 3.03537

Mean KL Divergence: 0.04286
SB3 Clip Fraction: 0.19129
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 12,521.84185
Overall Steps per Second: 10,690.91606

Timestep Collection Time: 3.99302
Timestep Consumption Time: 0.68384
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.67687

Cumulative Model Updates: 54,657
Cumulative Timesteps: 911,696,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 911696984...
Checkpoint 911696984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,102.42320
Policy Entropy: 1.02931
Value Function Loss: 2.93873

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.10055

Collected Steps per Second: 11,894.51680
Overall Steps per Second: 9,938.92254

Timestep Collection Time: 4.20479
Timestep Consumption Time: 0.82734
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.03214

Cumulative Model Updates: 54,660
Cumulative Timesteps: 911,746,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,085.13176
Policy Entropy: 1.03448
Value Function Loss: 2.83832

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.17602
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.09281

Collected Steps per Second: 12,476.38354
Overall Steps per Second: 10,525.15073

Timestep Collection Time: 4.00917
Timestep Consumption Time: 0.74325
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 4.75243

Cumulative Model Updates: 54,663
Cumulative Timesteps: 911,797,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 911797018...
Checkpoint 911797018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,640.82871
Policy Entropy: 1.01994
Value Function Loss: 2.89530

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.08493

Collected Steps per Second: 11,898.34459
Overall Steps per Second: 10,259.95025

Timestep Collection Time: 4.20495
Timestep Consumption Time: 0.67148
PPO Batch Consumption Time: 0.03845
Total Iteration Time: 4.87644

Cumulative Model Updates: 54,666
Cumulative Timesteps: 911,847,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,998.03054
Policy Entropy: 1.01524
Value Function Loss: 2.95435

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 12,022.31042
Overall Steps per Second: 10,188.12158

Timestep Collection Time: 4.16076
Timestep Consumption Time: 0.74907
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.90984

Cumulative Model Updates: 54,669
Cumulative Timesteps: 911,897,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 911897072...
Checkpoint 911897072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,886.46926
Policy Entropy: 1.02616
Value Function Loss: 2.98880

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 11,623.52007
Overall Steps per Second: 9,918.67551

Timestep Collection Time: 4.30403
Timestep Consumption Time: 0.73979
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.04382

Cumulative Model Updates: 54,672
Cumulative Timesteps: 911,947,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,446.37415
Policy Entropy: 1.02951
Value Function Loss: 2.99700

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11355

Collected Steps per Second: 12,000.70365
Overall Steps per Second: 10,127.42099

Timestep Collection Time: 4.16742
Timestep Consumption Time: 0.77085
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.93828

Cumulative Model Updates: 54,675
Cumulative Timesteps: 911,997,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911997112...
Checkpoint 911997112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,749.27066
Policy Entropy: 1.01961
Value Function Loss: 2.96250

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.11397

Collected Steps per Second: 11,393.24949
Overall Steps per Second: 9,650.32175

Timestep Collection Time: 4.38856
Timestep Consumption Time: 0.79261
PPO Batch Consumption Time: 0.03857
Total Iteration Time: 5.18117

Cumulative Model Updates: 54,678
Cumulative Timesteps: 912,047,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,586.13690
Policy Entropy: 1.00383
Value Function Loss: 3.15106

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.18802
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 11,802.61225
Overall Steps per Second: 10,099.45200

Timestep Collection Time: 4.23821
Timestep Consumption Time: 0.71473
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.95294

Cumulative Model Updates: 54,681
Cumulative Timesteps: 912,097,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 912097134...
Checkpoint 912097134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793,141.82703
Policy Entropy: 1.02498
Value Function Loss: 3.12858

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 12,026.42640
Overall Steps per Second: 10,116.70067

Timestep Collection Time: 4.15901
Timestep Consumption Time: 0.78509
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.94410

Cumulative Model Updates: 54,684
Cumulative Timesteps: 912,147,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,524.93499
Policy Entropy: 1.02549
Value Function Loss: 3.09831

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.12085

Collected Steps per Second: 11,805.06849
Overall Steps per Second: 9,992.05695

Timestep Collection Time: 4.23581
Timestep Consumption Time: 0.76857
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.00438

Cumulative Model Updates: 54,687
Cumulative Timesteps: 912,197,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 912197156...
Checkpoint 912197156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,708.79186
Policy Entropy: 1.01485
Value Function Loss: 2.86728

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 11,893.54111
Overall Steps per Second: 9,919.51776

Timestep Collection Time: 4.20531
Timestep Consumption Time: 0.83687
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.04218

Cumulative Model Updates: 54,690
Cumulative Timesteps: 912,247,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,626.58340
Policy Entropy: 0.99637
Value Function Loss: 2.84439

Mean KL Divergence: 0.03688
SB3 Clip Fraction: 0.20105
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.09160

Collected Steps per Second: 11,797.83516
Overall Steps per Second: 9,999.25392

Timestep Collection Time: 4.23840
Timestep Consumption Time: 0.76237
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.00077

Cumulative Model Updates: 54,693
Cumulative Timesteps: 912,297,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 912297176...
Checkpoint 912297176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,678.91417
Policy Entropy: 1.02045
Value Function Loss: 2.91382

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.10382

Collected Steps per Second: 11,469.80049
Overall Steps per Second: 9,967.96126

Timestep Collection Time: 4.36067
Timestep Consumption Time: 0.65701
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 5.01768

Cumulative Model Updates: 54,696
Cumulative Timesteps: 912,347,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,325.61684
Policy Entropy: 1.01503
Value Function Loss: 3.12584

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.11495

Collected Steps per Second: 11,806.72695
Overall Steps per Second: 9,870.60440

Timestep Collection Time: 4.23538
Timestep Consumption Time: 0.83077
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.06615

Cumulative Model Updates: 54,699
Cumulative Timesteps: 912,397,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 912397198...
Checkpoint 912397198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,611.69793
Policy Entropy: 1.01108
Value Function Loss: 3.19550

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 11,847.08786
Overall Steps per Second: 10,071.82356

Timestep Collection Time: 4.22180
Timestep Consumption Time: 0.74414
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 4.96593

Cumulative Model Updates: 54,702
Cumulative Timesteps: 912,447,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,057.84778
Policy Entropy: 1.00472
Value Function Loss: 3.12168

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.09975

Collected Steps per Second: 12,073.76407
Overall Steps per Second: 10,367.86223

Timestep Collection Time: 4.14353
Timestep Consumption Time: 0.68177
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.82530

Cumulative Model Updates: 54,705
Cumulative Timesteps: 912,497,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 912497242...
Checkpoint 912497242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807,779.97471
Policy Entropy: 1.01912
Value Function Loss: 3.05869

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.09376

Collected Steps per Second: 11,882.78124
Overall Steps per Second: 9,919.36131

Timestep Collection Time: 4.20895
Timestep Consumption Time: 0.83311
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.04206

Cumulative Model Updates: 54,708
Cumulative Timesteps: 912,547,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,533.70453
Policy Entropy: 1.02043
Value Function Loss: 2.98074

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.08527

Collected Steps per Second: 11,927.20794
Overall Steps per Second: 10,117.37878

Timestep Collection Time: 4.19461
Timestep Consumption Time: 0.75035
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.94496

Cumulative Model Updates: 54,711
Cumulative Timesteps: 912,597,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 912597286...
Checkpoint 912597286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766,988.12643
Policy Entropy: 1.02526
Value Function Loss: 2.91100

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.09201

Collected Steps per Second: 11,478.04427
Overall Steps per Second: 9,759.24750

Timestep Collection Time: 4.35649
Timestep Consumption Time: 0.76726
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.12376

Cumulative Model Updates: 54,714
Cumulative Timesteps: 912,647,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,803.16593
Policy Entropy: 1.02023
Value Function Loss: 2.89624

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 11,813.38871
Overall Steps per Second: 9,903.93351

Timestep Collection Time: 4.23350
Timestep Consumption Time: 0.81621
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.04971

Cumulative Model Updates: 54,717
Cumulative Timesteps: 912,697,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 912697302...
Checkpoint 912697302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,812.86759
Policy Entropy: 1.01856
Value Function Loss: 2.91235

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.07266
Value Function Update Magnitude: 0.09500

Collected Steps per Second: 11,703.89821
Overall Steps per Second: 10,043.90514

Timestep Collection Time: 4.27413
Timestep Consumption Time: 0.70640
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.98053

Cumulative Model Updates: 54,720
Cumulative Timesteps: 912,747,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,810.52760
Policy Entropy: 1.00041
Value Function Loss: 2.98581

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.18178
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.09728

Collected Steps per Second: 11,932.67775
Overall Steps per Second: 10,072.46354

Timestep Collection Time: 4.19185
Timestep Consumption Time: 0.77416
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.96601

Cumulative Model Updates: 54,723
Cumulative Timesteps: 912,797,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 912797346...
Checkpoint 912797346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,309.96933
Policy Entropy: 1.02630
Value Function Loss: 2.95694

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.09795

Collected Steps per Second: 12,010.28567
Overall Steps per Second: 10,159.39573

Timestep Collection Time: 4.16510
Timestep Consumption Time: 0.75882
PPO Batch Consumption Time: 0.03298
Total Iteration Time: 4.92391

Cumulative Model Updates: 54,726
Cumulative Timesteps: 912,847,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,272.75760
Policy Entropy: 1.03460
Value Function Loss: 2.88549

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.09728

Collected Steps per Second: 12,036.29568
Overall Steps per Second: 10,173.11933

Timestep Collection Time: 4.15643
Timestep Consumption Time: 0.76124
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.91767

Cumulative Model Updates: 54,729
Cumulative Timesteps: 912,897,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 912897398...
Checkpoint 912897398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762,833.95291
Policy Entropy: 1.01951
Value Function Loss: 2.93166

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 11,531.46132
Overall Steps per Second: 9,783.54575

Timestep Collection Time: 4.33822
Timestep Consumption Time: 0.77506
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.11328

Cumulative Model Updates: 54,732
Cumulative Timesteps: 912,947,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,523.81779
Policy Entropy: 0.99949
Value Function Loss: 2.91269

Mean KL Divergence: 0.03064
SB3 Clip Fraction: 0.20793
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08659

Collected Steps per Second: 12,068.96069
Overall Steps per Second: 10,275.29974

Timestep Collection Time: 4.14286
Timestep Consumption Time: 0.72318
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.86604

Cumulative Model Updates: 54,735
Cumulative Timesteps: 912,997,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 912997424...
Checkpoint 912997424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,181.50341
Policy Entropy: 1.01699
Value Function Loss: 2.98515

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.08462

Collected Steps per Second: 11,714.94715
Overall Steps per Second: 9,941.46996

Timestep Collection Time: 4.27044
Timestep Consumption Time: 0.76181
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.03225

Cumulative Model Updates: 54,738
Cumulative Timesteps: 913,047,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,086.48769
Policy Entropy: 1.02761
Value Function Loss: 2.99977

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 12,028.61373
Overall Steps per Second: 10,170.70999

Timestep Collection Time: 4.15775
Timestep Consumption Time: 0.75950
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.91726

Cumulative Model Updates: 54,741
Cumulative Timesteps: 913,097,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 913097464...
Checkpoint 913097464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788,067.07998
Policy Entropy: 1.01600
Value Function Loss: 2.93237

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 11,722.24634
Overall Steps per Second: 10,108.29382

Timestep Collection Time: 4.26574
Timestep Consumption Time: 0.68109
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.94683

Cumulative Model Updates: 54,744
Cumulative Timesteps: 913,147,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,533.82143
Policy Entropy: 1.00267
Value Function Loss: 3.05576

Mean KL Divergence: 0.03163
SB3 Clip Fraction: 0.20789
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 11,814.81815
Overall Steps per Second: 9,901.00166

Timestep Collection Time: 4.23299
Timestep Consumption Time: 0.81822
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.05121

Cumulative Model Updates: 54,747
Cumulative Timesteps: 913,197,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 913197480...
Checkpoint 913197480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,451.42322
Policy Entropy: 1.01759
Value Function Loss: 3.01780

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.07687

Collected Steps per Second: 11,373.26179
Overall Steps per Second: 9,832.96076

Timestep Collection Time: 4.39803
Timestep Consumption Time: 0.68894
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.08697

Cumulative Model Updates: 54,750
Cumulative Timesteps: 913,247,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,165.46026
Policy Entropy: 1.03504
Value Function Loss: 3.02190

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.08908

Collected Steps per Second: 12,014.39738
Overall Steps per Second: 10,075.81708

Timestep Collection Time: 4.16201
Timestep Consumption Time: 0.80077
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.96277

Cumulative Model Updates: 54,753
Cumulative Timesteps: 913,297,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 913297504...
Checkpoint 913297504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,850.03253
Policy Entropy: 0.99210
Value Function Loss: 2.91602

Mean KL Divergence: 0.07764
SB3 Clip Fraction: 0.20962
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.09202

Collected Steps per Second: 11,902.82288
Overall Steps per Second: 10,027.12779

Timestep Collection Time: 4.20068
Timestep Consumption Time: 0.78579
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.98647

Cumulative Model Updates: 54,756
Cumulative Timesteps: 913,347,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,817.48636
Policy Entropy: 1.01117
Value Function Loss: 2.92673

Mean KL Divergence: 0.03088
SB3 Clip Fraction: 0.16651
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.08251

Collected Steps per Second: 11,562.90197
Overall Steps per Second: 10,005.81109

Timestep Collection Time: 4.32677
Timestep Consumption Time: 0.67333
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.00009

Cumulative Model Updates: 54,759
Cumulative Timesteps: 913,397,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 913397534...
Checkpoint 913397534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,137.90406
Policy Entropy: 1.00196
Value Function Loss: 2.98527

Mean KL Divergence: 0.03237
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.08232

Collected Steps per Second: 11,814.76796
Overall Steps per Second: 10,025.58880

Timestep Collection Time: 4.23453
Timestep Consumption Time: 0.75570
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.99023

Cumulative Model Updates: 54,762
Cumulative Timesteps: 913,447,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,475.01184
Policy Entropy: 1.00323
Value Function Loss: 3.05537

Mean KL Divergence: 0.03242
SB3 Clip Fraction: 0.17009
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 11,646.13833
Overall Steps per Second: 10,010.55854

Timestep Collection Time: 4.29327
Timestep Consumption Time: 0.70146
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.99473

Cumulative Model Updates: 54,765
Cumulative Timesteps: 913,497,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 913497564...
Checkpoint 913497564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,318.85223
Policy Entropy: 1.01597
Value Function Loss: 3.07134

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 11,490.00095
Overall Steps per Second: 9,793.23220

Timestep Collection Time: 4.35178
Timestep Consumption Time: 0.75399
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 5.10577

Cumulative Model Updates: 54,768
Cumulative Timesteps: 913,547,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,180.05201
Policy Entropy: 1.01607
Value Function Loss: 3.03928

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 11,959.77981
Overall Steps per Second: 10,053.65028

Timestep Collection Time: 4.18269
Timestep Consumption Time: 0.79302
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.97571

Cumulative Model Updates: 54,771
Cumulative Timesteps: 913,597,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 913597590...
Checkpoint 913597590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,696.74629
Policy Entropy: 1.02613
Value Function Loss: 3.03043

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.07112
Value Function Update Magnitude: 0.10621

Collected Steps per Second: 11,747.52546
Overall Steps per Second: 10,112.86927

Timestep Collection Time: 4.25690
Timestep Consumption Time: 0.68809
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.94499

Cumulative Model Updates: 54,774
Cumulative Timesteps: 913,647,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,438.52353
Policy Entropy: 1.02006
Value Function Loss: 2.87952

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.10312

Collected Steps per Second: 11,937.94084
Overall Steps per Second: 9,998.92576

Timestep Collection Time: 4.19084
Timestep Consumption Time: 0.81270
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 5.00354

Cumulative Model Updates: 54,777
Cumulative Timesteps: 913,697,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 913697628...
Checkpoint 913697628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,525.50577
Policy Entropy: 1.03250
Value Function Loss: 2.80828

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 11,832.33205
Overall Steps per Second: 10,095.98801

Timestep Collection Time: 4.22588
Timestep Consumption Time: 0.72678
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.95266

Cumulative Model Updates: 54,780
Cumulative Timesteps: 913,747,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,255.32579
Policy Entropy: 1.02874
Value Function Loss: 2.96669

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.08712

Collected Steps per Second: 12,346.89772
Overall Steps per Second: 10,327.89615

Timestep Collection Time: 4.05106
Timestep Consumption Time: 0.79194
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.84300

Cumulative Model Updates: 54,783
Cumulative Timesteps: 913,797,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913797648...
Checkpoint 913797648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,315.60485
Policy Entropy: 1.04493
Value Function Loss: 2.97931

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.16237
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.10580

Collected Steps per Second: 11,332.11345
Overall Steps per Second: 9,649.52681

Timestep Collection Time: 4.41436
Timestep Consumption Time: 0.76973
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.18409

Cumulative Model Updates: 54,786
Cumulative Timesteps: 913,847,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,908.13606
Policy Entropy: 1.03131
Value Function Loss: 3.08707

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 11,951.47596
Overall Steps per Second: 10,217.05270

Timestep Collection Time: 4.18358
Timestep Consumption Time: 0.71020
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.89378

Cumulative Model Updates: 54,789
Cumulative Timesteps: 913,897,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 913897672...
Checkpoint 913897672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,150.61982
Policy Entropy: 1.02253
Value Function Loss: 2.78278

Mean KL Divergence: 0.03070
SB3 Clip Fraction: 0.18365
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 12,282.70964
Overall Steps per Second: 10,267.65565

Timestep Collection Time: 4.07288
Timestep Consumption Time: 0.79931
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.87219

Cumulative Model Updates: 54,792
Cumulative Timesteps: 913,947,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768,651.62715
Policy Entropy: 1.03441
Value Function Loss: 2.87659

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.09920

Collected Steps per Second: 12,802.55586
Overall Steps per Second: 10,676.57540

Timestep Collection Time: 3.90656
Timestep Consumption Time: 0.77790
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.68446

Cumulative Model Updates: 54,795
Cumulative Timesteps: 913,997,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 913997712...
Checkpoint 913997712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,587.41510
Policy Entropy: 1.04487
Value Function Loss: 2.88953

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.17943
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.08424

Collected Steps per Second: 12,787.78199
Overall Steps per Second: 10,656.05933

Timestep Collection Time: 3.91076
Timestep Consumption Time: 0.78234
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.69310

Cumulative Model Updates: 54,798
Cumulative Timesteps: 914,047,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,112.88205
Policy Entropy: 1.02943
Value Function Loss: 2.98304

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.08132

Collected Steps per Second: 12,536.71308
Overall Steps per Second: 10,412.90289

Timestep Collection Time: 3.98972
Timestep Consumption Time: 0.81374
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 4.80346

Cumulative Model Updates: 54,801
Cumulative Timesteps: 914,097,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 914097740...
Checkpoint 914097740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,937.65758
Policy Entropy: 1.01374
Value Function Loss: 2.97196

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.16953
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 11,894.41836
Overall Steps per Second: 10,215.56864

Timestep Collection Time: 4.20483
Timestep Consumption Time: 0.69103
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.89586

Cumulative Model Updates: 54,804
Cumulative Timesteps: 914,147,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,863.19049
Policy Entropy: 1.02975
Value Function Loss: 2.97773

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 12,543.97741
Overall Steps per Second: 10,464.17045

Timestep Collection Time: 3.98693
Timestep Consumption Time: 0.79242
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.77936

Cumulative Model Updates: 54,807
Cumulative Timesteps: 914,197,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 914197766...
Checkpoint 914197766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,135.92868
Policy Entropy: 1.03936
Value Function Loss: 3.00350

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 12,191.54743
Overall Steps per Second: 10,279.53498

Timestep Collection Time: 4.10186
Timestep Consumption Time: 0.76295
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.86481

Cumulative Model Updates: 54,810
Cumulative Timesteps: 914,247,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,182.54256
Policy Entropy: 1.00032
Value Function Loss: 2.94242

Mean KL Divergence: 0.05886
SB3 Clip Fraction: 0.21845
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.07718

Collected Steps per Second: 12,103.84794
Overall Steps per Second: 10,133.19999

Timestep Collection Time: 4.13125
Timestep Consumption Time: 0.80342
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.93467

Cumulative Model Updates: 54,813
Cumulative Timesteps: 914,297,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 914297778...
Checkpoint 914297778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,073.33738
Policy Entropy: 1.03231
Value Function Loss: 2.87830

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.08251

Collected Steps per Second: 11,677.82540
Overall Steps per Second: 9,828.54582

Timestep Collection Time: 4.28248
Timestep Consumption Time: 0.80576
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.08824

Cumulative Model Updates: 54,816
Cumulative Timesteps: 914,347,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,173.96895
Policy Entropy: 1.01858
Value Function Loss: 2.81912

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 11,863.00573
Overall Steps per Second: 10,189.04497

Timestep Collection Time: 4.21731
Timestep Consumption Time: 0.69286
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.91018

Cumulative Model Updates: 54,819
Cumulative Timesteps: 914,397,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 914397818...
Checkpoint 914397818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,313.99144
Policy Entropy: 1.01747
Value Function Loss: 2.87425

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.08742

Collected Steps per Second: 11,656.21550
Overall Steps per Second: 9,817.84161

Timestep Collection Time: 4.29179
Timestep Consumption Time: 0.80363
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.09542

Cumulative Model Updates: 54,822
Cumulative Timesteps: 914,447,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,197.72646
Policy Entropy: 1.00874
Value Function Loss: 2.89050

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.09768

Collected Steps per Second: 11,935.13203
Overall Steps per Second: 10,071.51205

Timestep Collection Time: 4.18982
Timestep Consumption Time: 0.77528
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 4.96509

Cumulative Model Updates: 54,825
Cumulative Timesteps: 914,497,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 914497850...
Checkpoint 914497850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,328.65686
Policy Entropy: 1.02945
Value Function Loss: 3.04350

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.15471
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.09052

Collected Steps per Second: 11,883.38034
Overall Steps per Second: 10,245.13005

Timestep Collection Time: 4.20840
Timestep Consumption Time: 0.67295
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.88134

Cumulative Model Updates: 54,828
Cumulative Timesteps: 914,547,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,318.62449
Policy Entropy: 1.03209
Value Function Loss: 3.04770

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.17697
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.08787

Collected Steps per Second: 11,632.01219
Overall Steps per Second: 9,784.08819

Timestep Collection Time: 4.30055
Timestep Consumption Time: 0.81225
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.11279

Cumulative Model Updates: 54,831
Cumulative Timesteps: 914,597,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914597884...
Checkpoint 914597884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,202.14960
Policy Entropy: 1.01119
Value Function Loss: 3.00329

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 11,709.65341
Overall Steps per Second: 9,997.69585

Timestep Collection Time: 4.27169
Timestep Consumption Time: 0.73146
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.00315

Cumulative Model Updates: 54,834
Cumulative Timesteps: 914,647,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,032.55910
Policy Entropy: 0.99896
Value Function Loss: 2.84376

Mean KL Divergence: 0.03056
SB3 Clip Fraction: 0.19548
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 12,082.77286
Overall Steps per Second: 10,199.31049

Timestep Collection Time: 4.13961
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.90406

Cumulative Model Updates: 54,837
Cumulative Timesteps: 914,697,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 914697922...
Checkpoint 914697922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,923.59677
Policy Entropy: 1.00849
Value Function Loss: 2.82201

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 11,411.74566
Overall Steps per Second: 9,723.00234

Timestep Collection Time: 4.38233
Timestep Consumption Time: 0.76115
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 5.14347

Cumulative Model Updates: 54,840
Cumulative Timesteps: 914,747,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,148.99503
Policy Entropy: 1.02167
Value Function Loss: 2.97414

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.16055
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 12,011.35328
Overall Steps per Second: 10,298.35758

Timestep Collection Time: 4.16489
Timestep Consumption Time: 0.69277
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 4.85767

Cumulative Model Updates: 54,843
Cumulative Timesteps: 914,797,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 914797958...
Checkpoint 914797958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,841.96016
Policy Entropy: 0.99425
Value Function Loss: 2.88359

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 11,863.40346
Overall Steps per Second: 9,951.98641

Timestep Collection Time: 4.21616
Timestep Consumption Time: 0.80977
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.02593

Cumulative Model Updates: 54,846
Cumulative Timesteps: 914,847,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806,719.16685
Policy Entropy: 1.00337
Value Function Loss: 2.84142

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.07825

Collected Steps per Second: 11,768.14593
Overall Steps per Second: 9,936.08307

Timestep Collection Time: 4.25063
Timestep Consumption Time: 0.78375
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.03438

Cumulative Model Updates: 54,849
Cumulative Timesteps: 914,897,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914897998...
Checkpoint 914897998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,887.19269
Policy Entropy: 1.01483
Value Function Loss: 2.74945

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.09856

Collected Steps per Second: 12,064.83551
Overall Steps per Second: 10,137.99825

Timestep Collection Time: 4.14494
Timestep Consumption Time: 0.78779
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.93273

Cumulative Model Updates: 54,852
Cumulative Timesteps: 914,948,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,949.58503
Policy Entropy: 1.01097
Value Function Loss: 2.84162

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.10578

Collected Steps per Second: 11,883.33512
Overall Steps per Second: 10,103.56661

Timestep Collection Time: 4.20757
Timestep Consumption Time: 0.74117
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.94875

Cumulative Model Updates: 54,855
Cumulative Timesteps: 914,998,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 914998006...
Checkpoint 914998006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,171.52367
Policy Entropy: 1.01411
Value Function Loss: 2.86902

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.10317

Collected Steps per Second: 11,453.48179
Overall Steps per Second: 9,809.77827

Timestep Collection Time: 4.36601
Timestep Consumption Time: 0.73156
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.09757

Cumulative Model Updates: 54,858
Cumulative Timesteps: 915,048,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,673.96032
Policy Entropy: 0.99855
Value Function Loss: 2.90168

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.17828
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.09759

Collected Steps per Second: 11,785.93026
Overall Steps per Second: 9,933.03624

Timestep Collection Time: 4.24235
Timestep Consumption Time: 0.79136
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.03371

Cumulative Model Updates: 54,861
Cumulative Timesteps: 915,098,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 915098012...
Checkpoint 915098012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,831.04250
Policy Entropy: 1.02568
Value Function Loss: 2.88708

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16322
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 11,798.85567
Overall Steps per Second: 10,031.46076

Timestep Collection Time: 4.23990
Timestep Consumption Time: 0.74701
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.98691

Cumulative Model Updates: 54,864
Cumulative Timesteps: 915,148,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,439.93298
Policy Entropy: 1.02358
Value Function Loss: 3.00099

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.16515
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 12,461.81781
Overall Steps per Second: 10,350.83385

Timestep Collection Time: 4.01450
Timestep Consumption Time: 0.81873
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.83323

Cumulative Model Updates: 54,867
Cumulative Timesteps: 915,198,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 915198066...
Checkpoint 915198066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,051.63498
Policy Entropy: 1.00965
Value Function Loss: 2.95292

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 12,204.63321
Overall Steps per Second: 10,291.51325

Timestep Collection Time: 4.09861
Timestep Consumption Time: 0.76190
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.86051

Cumulative Model Updates: 54,870
Cumulative Timesteps: 915,248,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,013.34062
Policy Entropy: 1.00168
Value Function Loss: 3.06946

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.18349
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.10157

Collected Steps per Second: 12,071.83393
Overall Steps per Second: 10,385.04746

Timestep Collection Time: 4.14287
Timestep Consumption Time: 0.67290
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.81577

Cumulative Model Updates: 54,873
Cumulative Timesteps: 915,298,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 915298100...
Checkpoint 915298100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,523.16502
Policy Entropy: 1.02511
Value Function Loss: 2.95162

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.08736

Collected Steps per Second: 11,924.97565
Overall Steps per Second: 10,020.49116

Timestep Collection Time: 4.19422
Timestep Consumption Time: 0.79715
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.99137

Cumulative Model Updates: 54,876
Cumulative Timesteps: 915,348,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,229.28274
Policy Entropy: 1.03862
Value Function Loss: 2.97531

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.17696
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 12,138.16608
Overall Steps per Second: 10,221.84515

Timestep Collection Time: 4.12039
Timestep Consumption Time: 0.77246
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.89285

Cumulative Model Updates: 54,879
Cumulative Timesteps: 915,398,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 915398130...
Checkpoint 915398130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,813.34033
Policy Entropy: 1.00351
Value Function Loss: 2.89594

Mean KL Divergence: 0.05081
SB3 Clip Fraction: 0.20137
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 12,095.57726
Overall Steps per Second: 10,076.67644

Timestep Collection Time: 4.13457
Timestep Consumption Time: 0.82838
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.96295

Cumulative Model Updates: 54,882
Cumulative Timesteps: 915,448,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,426.23718
Policy Entropy: 1.02336
Value Function Loss: 2.98922

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.15990
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.10344

Collected Steps per Second: 11,979.85275
Overall Steps per Second: 10,043.16307

Timestep Collection Time: 4.17401
Timestep Consumption Time: 0.80490
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 4.97891

Cumulative Model Updates: 54,885
Cumulative Timesteps: 915,498,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 915498144...
Checkpoint 915498144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743,188.52393
Policy Entropy: 1.00752
Value Function Loss: 2.96323

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.09871

Collected Steps per Second: 11,933.85254
Overall Steps per Second: 10,244.15237

Timestep Collection Time: 4.19228
Timestep Consumption Time: 0.69149
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.88376

Cumulative Model Updates: 54,888
Cumulative Timesteps: 915,548,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737,146.63977
Policy Entropy: 1.01498
Value Function Loss: 2.85632

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.06573
Value Function Update Magnitude: 0.09067

Collected Steps per Second: 11,948.32721
Overall Steps per Second: 10,052.03638

Timestep Collection Time: 4.18469
Timestep Consumption Time: 0.78943
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.97412

Cumulative Model Updates: 54,891
Cumulative Timesteps: 915,598,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 915598174...
Checkpoint 915598174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,659.59537
Policy Entropy: 1.00245
Value Function Loss: 2.77308

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.07265
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 11,736.41838
Overall Steps per Second: 9,877.42800

Timestep Collection Time: 4.26041
Timestep Consumption Time: 0.80184
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.06225

Cumulative Model Updates: 54,894
Cumulative Timesteps: 915,648,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,188.94056
Policy Entropy: 0.99945
Value Function Loss: 2.77885

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 12,039.98121
Overall Steps per Second: 10,140.31663

Timestep Collection Time: 4.15283
Timestep Consumption Time: 0.77798
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.93081

Cumulative Model Updates: 54,897
Cumulative Timesteps: 915,698,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 915698176...
Checkpoint 915698176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,328.48653
Policy Entropy: 1.00544
Value Function Loss: 2.86143

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.08425

Collected Steps per Second: 11,851.94495
Overall Steps per Second: 9,855.41477

Timestep Collection Time: 4.22024
Timestep Consumption Time: 0.85494
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.07518

Cumulative Model Updates: 54,900
Cumulative Timesteps: 915,748,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,864.41228
Policy Entropy: 1.02378
Value Function Loss: 2.90155

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.09564

Collected Steps per Second: 11,783.57925
Overall Steps per Second: 10,137.97384

Timestep Collection Time: 4.24370
Timestep Consumption Time: 0.68884
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.93254

Cumulative Model Updates: 54,903
Cumulative Timesteps: 915,798,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 915798200...
Checkpoint 915798200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,863.35010
Policy Entropy: 1.03475
Value Function Loss: 2.93001

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 11,592.76774
Overall Steps per Second: 9,848.19768

Timestep Collection Time: 4.31321
Timestep Consumption Time: 0.76407
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.07727

Cumulative Model Updates: 54,906
Cumulative Timesteps: 915,848,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754,445.14298
Policy Entropy: 1.03262
Value Function Loss: 3.04106

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.06550
Value Function Update Magnitude: 0.09423

Collected Steps per Second: 12,031.51671
Overall Steps per Second: 10,149.02724

Timestep Collection Time: 4.15725
Timestep Consumption Time: 0.77111
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 4.92835

Cumulative Model Updates: 54,909
Cumulative Timesteps: 915,898,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915898220...
Checkpoint 915898220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,700.96324
Policy Entropy: 1.03191
Value Function Loss: 2.95642

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 12,016.69518
Overall Steps per Second: 10,015.82772

Timestep Collection Time: 4.16238
Timestep Consumption Time: 0.83152
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.99390

Cumulative Model Updates: 54,912
Cumulative Timesteps: 915,948,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,783.77177
Policy Entropy: 1.02588
Value Function Loss: 2.92599

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.11120

Collected Steps per Second: 11,924.54257
Overall Steps per Second: 10,028.22724

Timestep Collection Time: 4.19572
Timestep Consumption Time: 0.79340
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.98912

Cumulative Model Updates: 54,915
Cumulative Timesteps: 915,998,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 915998270...
Checkpoint 915998270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,520.16806
Policy Entropy: 1.03846
Value Function Loss: 2.97661

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 11,621.25475
Overall Steps per Second: 10,049.41606

Timestep Collection Time: 4.30281
Timestep Consumption Time: 0.67301
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 4.97581

Cumulative Model Updates: 54,918
Cumulative Timesteps: 916,048,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,485.87871
Policy Entropy: 1.03507
Value Function Loss: 3.04560

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.09391

Collected Steps per Second: 11,920.85515
Overall Steps per Second: 9,963.35509

Timestep Collection Time: 4.19601
Timestep Consumption Time: 0.82439
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.02040

Cumulative Model Updates: 54,921
Cumulative Timesteps: 916,098,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916098294...
Checkpoint 916098294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,576.49576
Policy Entropy: 1.03518
Value Function Loss: 2.93795

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.09866

Collected Steps per Second: 11,753.65622
Overall Steps per Second: 9,970.85267

Timestep Collection Time: 4.25587
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.01682

Cumulative Model Updates: 54,924
Cumulative Timesteps: 916,148,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,893.23291
Policy Entropy: 1.03636
Value Function Loss: 2.87071

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.09106

Collected Steps per Second: 12,218.14527
Overall Steps per Second: 10,096.96621

Timestep Collection Time: 4.09309
Timestep Consumption Time: 0.85988
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.95297

Cumulative Model Updates: 54,927
Cumulative Timesteps: 916,198,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 916198326...
Checkpoint 916198326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,954.67840
Policy Entropy: 1.04620
Value Function Loss: 2.81862

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.08508

Collected Steps per Second: 11,880.49826
Overall Steps per Second: 9,920.28909

Timestep Collection Time: 4.21093
Timestep Consumption Time: 0.83206
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.04300

Cumulative Model Updates: 54,930
Cumulative Timesteps: 916,248,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,461.32090
Policy Entropy: 1.04862
Value Function Loss: 2.97047

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.08471

Collected Steps per Second: 11,627.12421
Overall Steps per Second: 9,923.23080

Timestep Collection Time: 4.30046
Timestep Consumption Time: 0.73842
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.03888

Cumulative Model Updates: 54,933
Cumulative Timesteps: 916,298,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 916298356...
Checkpoint 916298356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,322.69375
Policy Entropy: 1.04590
Value Function Loss: 2.91175

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.07339
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 12,063.22923
Overall Steps per Second: 10,178.42216

Timestep Collection Time: 4.14599
Timestep Consumption Time: 0.76774
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.91373

Cumulative Model Updates: 54,936
Cumulative Timesteps: 916,348,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,153.20069
Policy Entropy: 1.04564
Value Function Loss: 2.94714

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 12,779.17027
Overall Steps per Second: 10,717.95326

Timestep Collection Time: 3.91293
Timestep Consumption Time: 0.75251
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.66544

Cumulative Model Updates: 54,939
Cumulative Timesteps: 916,398,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 916398374...
Checkpoint 916398374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,180.78751
Policy Entropy: 1.04763
Value Function Loss: 2.89444

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.10507

Collected Steps per Second: 13,084.02771
Overall Steps per Second: 10,886.70037

Timestep Collection Time: 3.82268
Timestep Consumption Time: 0.77155
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.59423

Cumulative Model Updates: 54,942
Cumulative Timesteps: 916,448,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,056.20186
Policy Entropy: 1.04418
Value Function Loss: 2.88815

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.10331

Collected Steps per Second: 12,418.25068
Overall Steps per Second: 10,265.49370

Timestep Collection Time: 4.02665
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.87108

Cumulative Model Updates: 54,945
Cumulative Timesteps: 916,498,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 916498394...
Checkpoint 916498394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,154.95695
Policy Entropy: 1.04965
Value Function Loss: 2.85144

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 12,314.93739
Overall Steps per Second: 10,418.96179

Timestep Collection Time: 4.06141
Timestep Consumption Time: 0.73907
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.80048

Cumulative Model Updates: 54,948
Cumulative Timesteps: 916,548,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,598.20247
Policy Entropy: 1.04639
Value Function Loss: 2.89701

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 12,274.96651
Overall Steps per Second: 10,177.60662

Timestep Collection Time: 4.07545
Timestep Consumption Time: 0.83985
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.91530

Cumulative Model Updates: 54,951
Cumulative Timesteps: 916,598,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 916598436...
Checkpoint 916598436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,892.39744
Policy Entropy: 1.04434
Value Function Loss: 3.07624

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 12,670.65996
Overall Steps per Second: 10,579.70639

Timestep Collection Time: 3.94660
Timestep Consumption Time: 0.78000
PPO Batch Consumption Time: 0.03323
Total Iteration Time: 4.72660

Cumulative Model Updates: 54,954
Cumulative Timesteps: 916,648,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,062.89000
Policy Entropy: 1.06177
Value Function Loss: 3.19429

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.09708

Collected Steps per Second: 11,619.95192
Overall Steps per Second: 10,050.09049

Timestep Collection Time: 4.30398
Timestep Consumption Time: 0.67230
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.97627

Cumulative Model Updates: 54,957
Cumulative Timesteps: 916,698,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 916698454...
Checkpoint 916698454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559,096.49370
Policy Entropy: 1.07021
Value Function Loss: 3.15857

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 11,888.10986
Overall Steps per Second: 10,003.14410

Timestep Collection Time: 4.20841
Timestep Consumption Time: 0.79302
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.00143

Cumulative Model Updates: 54,960
Cumulative Timesteps: 916,748,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,163.54530
Policy Entropy: 1.05199
Value Function Loss: 3.09517

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.08447

Collected Steps per Second: 12,470.10055
Overall Steps per Second: 10,477.06066

Timestep Collection Time: 4.01119
Timestep Consumption Time: 0.76305
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.77424

Cumulative Model Updates: 54,963
Cumulative Timesteps: 916,798,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916798504...
Checkpoint 916798504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,084.44180
Policy Entropy: 1.05186
Value Function Loss: 2.95084

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.08715

Collected Steps per Second: 11,870.31383
Overall Steps per Second: 10,004.14293

Timestep Collection Time: 4.21421
Timestep Consumption Time: 0.78612
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.00033

Cumulative Model Updates: 54,966
Cumulative Timesteps: 916,848,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,864.93530
Policy Entropy: 1.05704
Value Function Loss: 2.99675

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.09180

Collected Steps per Second: 11,137.02629
Overall Steps per Second: 9,595.57974

Timestep Collection Time: 4.49025
Timestep Consumption Time: 0.72132
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.21157

Cumulative Model Updates: 54,969
Cumulative Timesteps: 916,898,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 916898536...
Checkpoint 916898536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,320.99067
Policy Entropy: 1.06841
Value Function Loss: 2.96200

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.09406

Collected Steps per Second: 12,021.17691
Overall Steps per Second: 10,079.87823

Timestep Collection Time: 4.15949
Timestep Consumption Time: 0.80108
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.96058

Cumulative Model Updates: 54,972
Cumulative Timesteps: 916,948,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,550.41175
Policy Entropy: 1.04719
Value Function Loss: 3.01676

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.10698

Collected Steps per Second: 11,712.10328
Overall Steps per Second: 10,102.48950

Timestep Collection Time: 4.26926
Timestep Consumption Time: 0.68021
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.94947

Cumulative Model Updates: 54,975
Cumulative Timesteps: 916,998,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 916998540...
Checkpoint 916998540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,272.37669
Policy Entropy: 1.05363
Value Function Loss: 2.97757

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.09446

Collected Steps per Second: 11,777.21460
Overall Steps per Second: 9,913.90494

Timestep Collection Time: 4.24701
Timestep Consumption Time: 0.79822
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.04524

Cumulative Model Updates: 54,978
Cumulative Timesteps: 917,048,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,967.86221
Policy Entropy: 1.06336
Value Function Loss: 2.95770

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.07832

Collected Steps per Second: 11,864.91226
Overall Steps per Second: 10,035.66188

Timestep Collection Time: 4.21444
Timestep Consumption Time: 0.76819
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.98263

Cumulative Model Updates: 54,981
Cumulative Timesteps: 917,098,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 917098562...
Checkpoint 917098562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,734.83126
Policy Entropy: 1.06111
Value Function Loss: 2.93376

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 11,772.49554
Overall Steps per Second: 10,034.18551

Timestep Collection Time: 4.24923
Timestep Consumption Time: 0.73613
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.98536

Cumulative Model Updates: 54,984
Cumulative Timesteps: 917,148,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,513.67037
Policy Entropy: 1.06040
Value Function Loss: 2.93399

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.06732
Value Function Update Magnitude: 0.06847

Collected Steps per Second: 11,388.04055
Overall Steps per Second: 9,651.16523

Timestep Collection Time: 4.39250
Timestep Consumption Time: 0.79050
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 5.18300

Cumulative Model Updates: 54,987
Cumulative Timesteps: 917,198,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 917198608...
Checkpoint 917198608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,314.59054
Policy Entropy: 1.04661
Value Function Loss: 3.01114

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 11,788.60321
Overall Steps per Second: 9,958.65690

Timestep Collection Time: 4.24325
Timestep Consumption Time: 0.77972
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.02297

Cumulative Model Updates: 54,990
Cumulative Timesteps: 917,248,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,552.02961
Policy Entropy: 1.06654
Value Function Loss: 2.88984

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.06460

Collected Steps per Second: 11,986.23038
Overall Steps per Second: 10,083.25143

Timestep Collection Time: 4.17296
Timestep Consumption Time: 0.78755
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.96050

Cumulative Model Updates: 54,993
Cumulative Timesteps: 917,298,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 917298648...
Checkpoint 917298648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,241.32660
Policy Entropy: 1.06788
Value Function Loss: 2.86158

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.05803

Collected Steps per Second: 11,844.97910
Overall Steps per Second: 10,012.57436

Timestep Collection Time: 4.22322
Timestep Consumption Time: 0.77289
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.99612

Cumulative Model Updates: 54,996
Cumulative Timesteps: 917,348,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,462.23084
Policy Entropy: 1.05220
Value Function Loss: 2.86803

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 11,646.83693
Overall Steps per Second: 10,078.33577

Timestep Collection Time: 4.29318
Timestep Consumption Time: 0.66815
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.96133

Cumulative Model Updates: 54,999
Cumulative Timesteps: 917,398,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 917398674...
Checkpoint 917398674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,183.81191
Policy Entropy: 1.05131
Value Function Loss: 2.99251

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 11,519.72828
Overall Steps per Second: 9,657.16206

Timestep Collection Time: 4.34090
Timestep Consumption Time: 0.83722
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.17813

Cumulative Model Updates: 55,002
Cumulative Timesteps: 917,448,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,661.74271
Policy Entropy: 1.05775
Value Function Loss: 2.96177

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.08486

Collected Steps per Second: 11,330.58921
Overall Steps per Second: 9,705.58026

Timestep Collection Time: 4.41442
Timestep Consumption Time: 0.73911
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.15353

Cumulative Model Updates: 55,005
Cumulative Timesteps: 917,498,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 917498698...
Checkpoint 917498698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,548.42682
Policy Entropy: 1.06934
Value Function Loss: 2.94645

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.15725
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.08910

Collected Steps per Second: 12,284.17121
Overall Steps per Second: 10,319.02770

Timestep Collection Time: 4.07077
Timestep Consumption Time: 0.77523
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 4.84600

Cumulative Model Updates: 55,008
Cumulative Timesteps: 917,548,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,106.68572
Policy Entropy: 1.03673
Value Function Loss: 2.84194

Mean KL Divergence: 0.04666
SB3 Clip Fraction: 0.19965
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 12,296.53710
Overall Steps per Second: 10,356.79944

Timestep Collection Time: 4.06814
Timestep Consumption Time: 0.76193
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.83006

Cumulative Model Updates: 55,011
Cumulative Timesteps: 917,598,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 917598728...
Checkpoint 917598728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,065.89685
Policy Entropy: 1.05928
Value Function Loss: 2.88221

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.17261
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 12,277.52420
Overall Steps per Second: 10,520.63998

Timestep Collection Time: 4.07297
Timestep Consumption Time: 0.68016
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.75313

Cumulative Model Updates: 55,014
Cumulative Timesteps: 917,648,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,432.03013
Policy Entropy: 1.05411
Value Function Loss: 2.80919

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 12,154.37293
Overall Steps per Second: 10,245.97215

Timestep Collection Time: 4.11556
Timestep Consumption Time: 0.76656
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.88211

Cumulative Model Updates: 55,017
Cumulative Timesteps: 917,698,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 917698756...
Checkpoint 917698756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,115.51137
Policy Entropy: 1.05072
Value Function Loss: 2.78566

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 12,055.90857
Overall Steps per Second: 10,282.47287

Timestep Collection Time: 4.14983
Timestep Consumption Time: 0.71573
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.86556

Cumulative Model Updates: 55,020
Cumulative Timesteps: 917,748,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,849.63412
Policy Entropy: 1.03925
Value Function Loss: 2.75608

Mean KL Divergence: 0.03311
SB3 Clip Fraction: 0.19916
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 11,907.34956
Overall Steps per Second: 10,013.63889

Timestep Collection Time: 4.20127
Timestep Consumption Time: 0.79452
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.99579

Cumulative Model Updates: 55,023
Cumulative Timesteps: 917,798,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 917798812...
Checkpoint 917798812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,626.06102
Policy Entropy: 1.05601
Value Function Loss: 2.80878

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.09318

Collected Steps per Second: 12,388.23627
Overall Steps per Second: 10,367.70744

Timestep Collection Time: 4.03738
Timestep Consumption Time: 0.78683
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.82421

Cumulative Model Updates: 55,026
Cumulative Timesteps: 917,848,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,781.89274
Policy Entropy: 1.05166
Value Function Loss: 2.90750

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 12,102.28093
Overall Steps per Second: 10,330.28418

Timestep Collection Time: 4.13145
Timestep Consumption Time: 0.70869
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 4.84014

Cumulative Model Updates: 55,029
Cumulative Timesteps: 917,898,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 917898828...
Checkpoint 917898828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,153.00946
Policy Entropy: 1.03618
Value Function Loss: 2.87687

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.08678

Collected Steps per Second: 11,776.71336
Overall Steps per Second: 9,964.31946

Timestep Collection Time: 4.24618
Timestep Consumption Time: 0.77233
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.01851

Cumulative Model Updates: 55,032
Cumulative Timesteps: 917,948,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766,787.30631
Policy Entropy: 1.03015
Value Function Loss: 2.83394

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.17657
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 11,708.96697
Overall Steps per Second: 9,983.97980

Timestep Collection Time: 4.27143
Timestep Consumption Time: 0.73800
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.00943

Cumulative Model Updates: 55,035
Cumulative Timesteps: 917,998,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 917998848...
Checkpoint 917998848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,319.64930
Policy Entropy: 1.04735
Value Function Loss: 2.85422

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 11,935.46781
Overall Steps per Second: 10,084.37940

Timestep Collection Time: 4.19037
Timestep Consumption Time: 0.76918
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.95955

Cumulative Model Updates: 55,038
Cumulative Timesteps: 918,048,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599,017.20609
Policy Entropy: 1.05887
Value Function Loss: 3.04102

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.17597
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 11,637.35294
Overall Steps per Second: 9,779.88971

Timestep Collection Time: 4.29788
Timestep Consumption Time: 0.81628
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 5.11417

Cumulative Model Updates: 55,041
Cumulative Timesteps: 918,098,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 918098878...
Checkpoint 918098878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,119.85897
Policy Entropy: 1.01880
Value Function Loss: 3.06490

Mean KL Divergence: 0.07256
SB3 Clip Fraction: 0.24169
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 11,901.46363
Overall Steps per Second: 10,248.03138

Timestep Collection Time: 4.20133
Timestep Consumption Time: 0.67785
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 4.87918

Cumulative Model Updates: 55,044
Cumulative Timesteps: 918,148,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,091.48266
Policy Entropy: 1.06020
Value Function Loss: 3.03444

Mean KL Divergence: 0.03993
SB3 Clip Fraction: 0.23112
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 11,790.77932
Overall Steps per Second: 10,001.81593

Timestep Collection Time: 4.24060
Timestep Consumption Time: 0.75849
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.99909

Cumulative Model Updates: 55,047
Cumulative Timesteps: 918,198,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 918198880...
Checkpoint 918198880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,917.25634
Policy Entropy: 1.02044
Value Function Loss: 2.82338

Mean KL Divergence: 0.06378
SB3 Clip Fraction: 0.26235
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.08503

Collected Steps per Second: 11,764.17782
Overall Steps per Second: 10,165.77937

Timestep Collection Time: 4.25087
Timestep Consumption Time: 0.66838
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.91925

Cumulative Model Updates: 55,050
Cumulative Timesteps: 918,248,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734,985.53312
Policy Entropy: 1.05932
Value Function Loss: 2.85610

Mean KL Divergence: 0.04397
SB3 Clip Fraction: 0.23655
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 11,803.03212
Overall Steps per Second: 9,965.80508

Timestep Collection Time: 4.23654
Timestep Consumption Time: 0.78102
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.01756

Cumulative Model Updates: 55,053
Cumulative Timesteps: 918,298,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 918298892...
Checkpoint 918298892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,097.56696
Policy Entropy: 1.02424
Value Function Loss: 2.77629

Mean KL Divergence: 0.05634
SB3 Clip Fraction: 0.24245
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 11,833.58852
Overall Steps per Second: 10,070.95108

Timestep Collection Time: 4.22695
Timestep Consumption Time: 0.73981
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.96676

Cumulative Model Updates: 55,056
Cumulative Timesteps: 918,348,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,104.01287
Policy Entropy: 1.05023
Value Function Loss: 3.01129

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.18747
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.10210

Collected Steps per Second: 11,681.58177
Overall Steps per Second: 9,818.37305

Timestep Collection Time: 4.28264
Timestep Consumption Time: 0.81271
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.09535

Cumulative Model Updates: 55,059
Cumulative Timesteps: 918,398,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 918398940...
Checkpoint 918398940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,045.24457
Policy Entropy: 1.04136
Value Function Loss: 3.03880

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.18164
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.09348

Collected Steps per Second: 11,775.16580
Overall Steps per Second: 10,009.46377

Timestep Collection Time: 4.24792
Timestep Consumption Time: 0.74935
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 4.99727

Cumulative Model Updates: 55,062
Cumulative Timesteps: 918,448,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,231.57618
Policy Entropy: 1.04183
Value Function Loss: 3.05388

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.17001
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 11,870.82334
Overall Steps per Second: 10,231.01750

Timestep Collection Time: 4.21251
Timestep Consumption Time: 0.67517
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.88769

Cumulative Model Updates: 55,065
Cumulative Timesteps: 918,498,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 918498966...
Checkpoint 918498966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,900.99453
Policy Entropy: 1.04694
Value Function Loss: 2.83614

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.08170

Collected Steps per Second: 11,880.62250
Overall Steps per Second: 10,037.70340

Timestep Collection Time: 4.21022
Timestep Consumption Time: 0.77299
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.98321

Cumulative Model Updates: 55,068
Cumulative Timesteps: 918,548,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,986.44278
Policy Entropy: 1.04169
Value Function Loss: 2.83164

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 12,016.10792
Overall Steps per Second: 10,065.55650

Timestep Collection Time: 4.16324
Timestep Consumption Time: 0.80677
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.97002

Cumulative Model Updates: 55,071
Cumulative Timesteps: 918,599,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 918599012...
Checkpoint 918599012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,733.31017
Policy Entropy: 1.04042
Value Function Loss: 2.80016

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 11,646.96847
Overall Steps per Second: 10,019.26558

Timestep Collection Time: 4.29485
Timestep Consumption Time: 0.69773
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 4.99258

Cumulative Model Updates: 55,074
Cumulative Timesteps: 918,649,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,960.27700
Policy Entropy: 1.04655
Value Function Loss: 2.88590

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 11,434.66429
Overall Steps per Second: 9,696.85560

Timestep Collection Time: 4.37477
Timestep Consumption Time: 0.78402
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.15879

Cumulative Model Updates: 55,077
Cumulative Timesteps: 918,699,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918699058...
Checkpoint 918699058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,328.77631
Policy Entropy: 1.04941
Value Function Loss: 2.75942

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.08193

Collected Steps per Second: 11,991.37960
Overall Steps per Second: 10,190.81040

Timestep Collection Time: 4.16983
Timestep Consumption Time: 0.73675
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 4.90658

Cumulative Model Updates: 55,080
Cumulative Timesteps: 918,749,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,132.28051
Policy Entropy: 1.03699
Value Function Loss: 2.83332

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.08522

Collected Steps per Second: 12,421.82202
Overall Steps per Second: 10,414.73994

Timestep Collection Time: 4.02517
Timestep Consumption Time: 0.77571
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.80089

Cumulative Model Updates: 55,083
Cumulative Timesteps: 918,799,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 918799060...
Checkpoint 918799060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,838.73594
Policy Entropy: 1.05129
Value Function Loss: 2.77930

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.17055
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 12,359.68339
Overall Steps per Second: 10,391.88799

Timestep Collection Time: 4.04671
Timestep Consumption Time: 0.76628
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.81298

Cumulative Model Updates: 55,086
Cumulative Timesteps: 918,849,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,386.79755
Policy Entropy: 1.04595
Value Function Loss: 2.90418

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.16573
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 12,659.11580
Overall Steps per Second: 10,812.14153

Timestep Collection Time: 3.95162
Timestep Consumption Time: 0.67503
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.62665

Cumulative Model Updates: 55,089
Cumulative Timesteps: 918,899,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918899100...
Checkpoint 918899100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,177.44341
Policy Entropy: 1.03624
Value Function Loss: 2.89646

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 12,480.83204
Overall Steps per Second: 10,469.22102

Timestep Collection Time: 4.00871
Timestep Consumption Time: 0.77025
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.77896

Cumulative Model Updates: 55,092
Cumulative Timesteps: 918,949,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,772.65065
Policy Entropy: 1.03110
Value Function Loss: 3.03021

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.19525
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.07673

Collected Steps per Second: 11,804.14696
Overall Steps per Second: 9,978.69414

Timestep Collection Time: 4.23783
Timestep Consumption Time: 0.77525
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 5.01308

Cumulative Model Updates: 55,095
Cumulative Timesteps: 918,999,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918999156...
Checkpoint 918999156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807,490.69681
Policy Entropy: 1.05368
Value Function Loss: 3.01891

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 13,040.81154
Overall Steps per Second: 10,789.27476

Timestep Collection Time: 3.83504
Timestep Consumption Time: 0.80031
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.63534

Cumulative Model Updates: 55,098
Cumulative Timesteps: 919,049,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,143.87564
Policy Entropy: 1.05861
Value Function Loss: 2.90120

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 12,077.02529
Overall Steps per Second: 10,231.82085

Timestep Collection Time: 4.14241
Timestep Consumption Time: 0.74704
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.88945

Cumulative Model Updates: 55,101
Cumulative Timesteps: 919,099,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 919099196...
Checkpoint 919099196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,263.60670
Policy Entropy: 1.04266
Value Function Loss: 2.82205

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 11,759.05567
Overall Steps per Second: 10,102.09292

Timestep Collection Time: 4.25221
Timestep Consumption Time: 0.69746
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.94967

Cumulative Model Updates: 55,104
Cumulative Timesteps: 919,149,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,894.57450
Policy Entropy: 1.02796
Value Function Loss: 2.69954

Mean KL Divergence: 0.03389
SB3 Clip Fraction: 0.21106
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.07973

Collected Steps per Second: 11,906.28508
Overall Steps per Second: 10,020.18641

Timestep Collection Time: 4.20097
Timestep Consumption Time: 0.79075
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.99172

Cumulative Model Updates: 55,107
Cumulative Timesteps: 919,199,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 919199216...
Checkpoint 919199216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,027.81322
Policy Entropy: 1.04043
Value Function Loss: 2.80190

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 11,916.55685
Overall Steps per Second: 10,076.71925

Timestep Collection Time: 4.19752
Timestep Consumption Time: 0.76640
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.96392

Cumulative Model Updates: 55,110
Cumulative Timesteps: 919,249,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,609.31070
Policy Entropy: 1.04413
Value Function Loss: 2.82841

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.08496

Collected Steps per Second: 11,447.09981
Overall Steps per Second: 9,716.95328

Timestep Collection Time: 4.36914
Timestep Consumption Time: 0.77795
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.14709

Cumulative Model Updates: 55,113
Cumulative Timesteps: 919,299,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 919299250...
Checkpoint 919299250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834,967.20577
Policy Entropy: 1.03587
Value Function Loss: 2.95828

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.08889

Collected Steps per Second: 11,767.66758
Overall Steps per Second: 9,889.26948

Timestep Collection Time: 4.25114
Timestep Consumption Time: 0.80747
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.05861

Cumulative Model Updates: 55,116
Cumulative Timesteps: 919,349,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,019.84260
Policy Entropy: 1.02501
Value Function Loss: 2.99745

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.18081
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.09538

Collected Steps per Second: 11,963.94935
Overall Steps per Second: 10,325.79702

Timestep Collection Time: 4.18123
Timestep Consumption Time: 0.66334
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.84457

Cumulative Model Updates: 55,119
Cumulative Timesteps: 919,399,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919399300...
Checkpoint 919399300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,193.06045
Policy Entropy: 1.04581
Value Function Loss: 3.04189

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.15308
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.10564

Collected Steps per Second: 11,929.79231
Overall Steps per Second: 10,068.22491

Timestep Collection Time: 4.19119
Timestep Consumption Time: 0.77493
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.96612

Cumulative Model Updates: 55,122
Cumulative Timesteps: 919,449,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501,568.53850
Policy Entropy: 1.04448
Value Function Loss: 2.95636

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.11256

Collected Steps per Second: 11,762.35426
Overall Steps per Second: 10,015.97021

Timestep Collection Time: 4.25289
Timestep Consumption Time: 0.74153
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.99442

Cumulative Model Updates: 55,125
Cumulative Timesteps: 919,499,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919499324...
Checkpoint 919499324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,186.97666
Policy Entropy: 1.02471
Value Function Loss: 2.86025

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 11,505.53922
Overall Steps per Second: 9,951.00362

Timestep Collection Time: 4.34591
Timestep Consumption Time: 0.67891
PPO Batch Consumption Time: 0.03308
Total Iteration Time: 5.02482

Cumulative Model Updates: 55,128
Cumulative Timesteps: 919,549,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,592.61277
Policy Entropy: 1.02785
Value Function Loss: 2.86666

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 11,745.21018
Overall Steps per Second: 9,909.50485

Timestep Collection Time: 4.25910
Timestep Consumption Time: 0.78898
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.04808

Cumulative Model Updates: 55,131
Cumulative Timesteps: 919,599,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919599350...
Checkpoint 919599350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,874.46384
Policy Entropy: 1.04005
Value Function Loss: 2.81129

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 11,875.08059
Overall Steps per Second: 10,196.52988

Timestep Collection Time: 4.21185
Timestep Consumption Time: 0.69335
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.90520

Cumulative Model Updates: 55,134
Cumulative Timesteps: 919,649,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,985.02526
Policy Entropy: 1.04669
Value Function Loss: 2.87363

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.12271

Collected Steps per Second: 11,716.78586
Overall Steps per Second: 9,865.68238

Timestep Collection Time: 4.26772
Timestep Consumption Time: 0.80076
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.06848

Cumulative Model Updates: 55,137
Cumulative Timesteps: 919,699,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 919699370...
Checkpoint 919699370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,246.45078
Policy Entropy: 1.05302
Value Function Loss: 2.79839

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.12317

Collected Steps per Second: 11,519.04391
Overall Steps per Second: 9,744.63867

Timestep Collection Time: 4.34116
Timestep Consumption Time: 0.79048
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.13164

Cumulative Model Updates: 55,140
Cumulative Timesteps: 919,749,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,278.52653
Policy Entropy: 1.04936
Value Function Loss: 2.83432

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 12,149.51468
Overall Steps per Second: 10,242.51872

Timestep Collection Time: 4.11621
Timestep Consumption Time: 0.76637
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.88259

Cumulative Model Updates: 55,143
Cumulative Timesteps: 919,799,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 919799386...
Checkpoint 919799386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,151.56599
Policy Entropy: 1.04783
Value Function Loss: 2.79960

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 11,537.56582
Overall Steps per Second: 9,813.42732

Timestep Collection Time: 4.33384
Timestep Consumption Time: 0.76142
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.09526

Cumulative Model Updates: 55,146
Cumulative Timesteps: 919,849,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,961.39882
Policy Entropy: 1.03573
Value Function Loss: 2.88808

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 11,276.55279
Overall Steps per Second: 9,803.09691

Timestep Collection Time: 4.43682
Timestep Consumption Time: 0.66688
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.10369

Cumulative Model Updates: 55,149
Cumulative Timesteps: 919,899,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 919899420...
Checkpoint 919899420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,095.00436
Policy Entropy: 1.05187
Value Function Loss: 2.96905

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.09815

Collected Steps per Second: 11,868.35102
Overall Steps per Second: 9,965.47816

Timestep Collection Time: 4.21322
Timestep Consumption Time: 0.80450
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.01772

Cumulative Model Updates: 55,152
Cumulative Timesteps: 919,949,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,870.21037
Policy Entropy: 1.06347
Value Function Loss: 3.06237

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.15624
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.09503

Collected Steps per Second: 12,091.10440
Overall Steps per Second: 10,238.61700

Timestep Collection Time: 4.13759
Timestep Consumption Time: 0.74862
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.88621

Cumulative Model Updates: 55,155
Cumulative Timesteps: 919,999,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 919999452...
Checkpoint 919999452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,401.43792
Policy Entropy: 1.04435
Value Function Loss: 3.01479

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08493

Collected Steps per Second: 12,021.42680
Overall Steps per Second: 10,116.39190

Timestep Collection Time: 4.16124
Timestep Consumption Time: 0.78361
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.94485

Cumulative Model Updates: 55,158
Cumulative Timesteps: 920,049,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,756.37338
Policy Entropy: 1.02584
Value Function Loss: 2.99563

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 11,965.28031
Overall Steps per Second: 10,031.79979

Timestep Collection Time: 4.18076
Timestep Consumption Time: 0.80578
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.98654

Cumulative Model Updates: 55,161
Cumulative Timesteps: 920,099,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 920099500...
Checkpoint 920099500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,140.01802
Policy Entropy: 1.03431
Value Function Loss: 2.92549

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 11,871.97096
Overall Steps per Second: 10,199.44151

Timestep Collection Time: 4.21160
Timestep Consumption Time: 0.69063
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.90223

Cumulative Model Updates: 55,164
Cumulative Timesteps: 920,149,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694,778.14327
Policy Entropy: 1.04659
Value Function Loss: 2.89367

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 11,437.49472
Overall Steps per Second: 9,751.28282

Timestep Collection Time: 4.37264
Timestep Consumption Time: 0.75613
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.12876

Cumulative Model Updates: 55,167
Cumulative Timesteps: 920,199,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 920199512...
Checkpoint 920199512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,157.24329
Policy Entropy: 1.03121
Value Function Loss: 2.88545

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.08573

Collected Steps per Second: 12,060.96117
Overall Steps per Second: 10,216.91217

Timestep Collection Time: 4.14710
Timestep Consumption Time: 0.74851
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.89561

Cumulative Model Updates: 55,170
Cumulative Timesteps: 920,249,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,559.79101
Policy Entropy: 1.02704
Value Function Loss: 3.00910

Mean KL Divergence: 0.02821
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 11,901.56597
Overall Steps per Second: 10,309.38822

Timestep Collection Time: 4.20214
Timestep Consumption Time: 0.64898
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.85111

Cumulative Model Updates: 55,173
Cumulative Timesteps: 920,299,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 920299542...
Checkpoint 920299542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,546.64732
Policy Entropy: 1.03571
Value Function Loss: 3.09505

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 11,766.36322
Overall Steps per Second: 9,926.32356

Timestep Collection Time: 4.24991
Timestep Consumption Time: 0.78780
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.03772

Cumulative Model Updates: 55,176
Cumulative Timesteps: 920,349,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,413.90948
Policy Entropy: 1.04895
Value Function Loss: 3.10338

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.17012
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 11,870.29464
Overall Steps per Second: 10,201.18965

Timestep Collection Time: 4.21304
Timestep Consumption Time: 0.68933
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.90237

Cumulative Model Updates: 55,179
Cumulative Timesteps: 920,399,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 920399558...
Checkpoint 920399558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,514.75195
Policy Entropy: 1.00748
Value Function Loss: 3.02687

Mean KL Divergence: 0.06046
SB3 Clip Fraction: 0.24743
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 11,944.75843
Overall Steps per Second: 10,060.77017

Timestep Collection Time: 4.18694
Timestep Consumption Time: 0.78405
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.97099

Cumulative Model Updates: 55,182
Cumulative Timesteps: 920,449,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,243.41789
Policy Entropy: 1.03832
Value Function Loss: 2.97138

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.19138
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.09001

Collected Steps per Second: 11,548.34843
Overall Steps per Second: 9,860.54110

Timestep Collection Time: 4.33118
Timestep Consumption Time: 0.74136
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.07254

Cumulative Model Updates: 55,185
Cumulative Timesteps: 920,499,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 920499588...
Checkpoint 920499588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,176.54714
Policy Entropy: 1.01426
Value Function Loss: 2.99409

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.18805
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 11,793.81202
Overall Steps per Second: 10,186.54147

Timestep Collection Time: 4.24002
Timestep Consumption Time: 0.66901
PPO Batch Consumption Time: 0.03247
Total Iteration Time: 4.90903

Cumulative Model Updates: 55,188
Cumulative Timesteps: 920,549,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612,313.22549
Policy Entropy: 1.02720
Value Function Loss: 3.04723

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.17307
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 11,614.24736
Overall Steps per Second: 9,848.85987

Timestep Collection Time: 4.30764
Timestep Consumption Time: 0.77214
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.07978

Cumulative Model Updates: 55,191
Cumulative Timesteps: 920,599,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 920599624...
Checkpoint 920599624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,723.60657
Policy Entropy: 1.03010
Value Function Loss: 3.13969

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 11,647.25306
Overall Steps per Second: 9,936.39831

Timestep Collection Time: 4.29286
Timestep Consumption Time: 0.73915
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.03200

Cumulative Model Updates: 55,194
Cumulative Timesteps: 920,649,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,784.80792
Policy Entropy: 1.03531
Value Function Loss: 3.13251

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 11,898.29969
Overall Steps per Second: 10,108.20093

Timestep Collection Time: 4.20245
Timestep Consumption Time: 0.74423
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 4.94668

Cumulative Model Updates: 55,197
Cumulative Timesteps: 920,699,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 920699626...
Checkpoint 920699626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,231.28939
Policy Entropy: 1.03099
Value Function Loss: 3.02816

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.10215

Collected Steps per Second: 11,894.58985
Overall Steps per Second: 10,058.86526

Timestep Collection Time: 4.20410
Timestep Consumption Time: 0.76724
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.97134

Cumulative Model Updates: 55,200
Cumulative Timesteps: 920,749,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,388.53266
Policy Entropy: 1.03731
Value Function Loss: 2.87536

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.09115

Collected Steps per Second: 11,421.56337
Overall Steps per Second: 9,907.38334

Timestep Collection Time: 4.37961
Timestep Consumption Time: 0.66935
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.04896

Cumulative Model Updates: 55,203
Cumulative Timesteps: 920,799,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920799654...
Checkpoint 920799654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,798.33459
Policy Entropy: 1.03182
Value Function Loss: 2.86708

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.08402
Value Function Update Magnitude: 0.10281

Collected Steps per Second: 11,789.38480
Overall Steps per Second: 9,959.61932

Timestep Collection Time: 4.24263
Timestep Consumption Time: 0.77945
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 5.02208

Cumulative Model Updates: 55,206
Cumulative Timesteps: 920,849,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,102.88587
Policy Entropy: 1.03172
Value Function Loss: 2.95928

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.07700
Value Function Update Magnitude: 0.09839

Collected Steps per Second: 12,022.21774
Overall Steps per Second: 10,185.94585

Timestep Collection Time: 4.16030
Timestep Consumption Time: 0.75000
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.91030

Cumulative Model Updates: 55,209
Cumulative Timesteps: 920,899,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 920899688...
Checkpoint 920899688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,999.49572
Policy Entropy: 1.03643
Value Function Loss: 3.09210

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.07333
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 12,179.30684
Overall Steps per Second: 10,234.10097

Timestep Collection Time: 4.10729
Timestep Consumption Time: 0.78068
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.88797

Cumulative Model Updates: 55,212
Cumulative Timesteps: 920,949,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,921.32700
Policy Entropy: 1.03639
Value Function Loss: 2.97943

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.06957
Value Function Update Magnitude: 0.09799

Collected Steps per Second: 11,825.69553
Overall Steps per Second: 9,885.19175

Timestep Collection Time: 4.23011
Timestep Consumption Time: 0.83039
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.06050

Cumulative Model Updates: 55,215
Cumulative Timesteps: 920,999,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 920999736...
Checkpoint 920999736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,618.47581
Policy Entropy: 1.03842
Value Function Loss: 2.92112

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.09846

Collected Steps per Second: 11,995.88040
Overall Steps per Second: 10,274.72192

Timestep Collection Time: 4.16826
Timestep Consumption Time: 0.69824
PPO Batch Consumption Time: 0.03329
Total Iteration Time: 4.86651

Cumulative Model Updates: 55,218
Cumulative Timesteps: 921,049,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,343.53674
Policy Entropy: 1.03561
Value Function Loss: 2.83568

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.09064

Collected Steps per Second: 11,551.91573
Overall Steps per Second: 9,816.55904

Timestep Collection Time: 4.33036
Timestep Consumption Time: 0.76552
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.09588

Cumulative Model Updates: 55,221
Cumulative Timesteps: 921,099,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 921099762...
Checkpoint 921099762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,492.10862
Policy Entropy: 1.03502
Value Function Loss: 2.79543

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.06947
Value Function Update Magnitude: 0.08399

Collected Steps per Second: 11,913.65325
Overall Steps per Second: 9,937.07170

Timestep Collection Time: 4.19737
Timestep Consumption Time: 0.83490
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.03227

Cumulative Model Updates: 55,224
Cumulative Timesteps: 921,149,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,717.29994
Policy Entropy: 1.04226
Value Function Loss: 2.81615

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.09229

Collected Steps per Second: 12,832.29991
Overall Steps per Second: 10,749.78250

Timestep Collection Time: 3.89735
Timestep Consumption Time: 0.75502
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.65237

Cumulative Model Updates: 55,227
Cumulative Timesteps: 921,199,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 921199780...
Checkpoint 921199780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,176.92461
Policy Entropy: 1.05823
Value Function Loss: 2.74071

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 12,447.15626
Overall Steps per Second: 10,343.65832

Timestep Collection Time: 4.01843
Timestep Consumption Time: 0.81719
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.83562

Cumulative Model Updates: 55,230
Cumulative Timesteps: 921,249,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,872.42006
Policy Entropy: 1.06343
Value Function Loss: 2.88041

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.11440

Collected Steps per Second: 12,450.73162
Overall Steps per Second: 10,654.34392

Timestep Collection Time: 4.01743
Timestep Consumption Time: 0.67736
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.69480

Cumulative Model Updates: 55,233
Cumulative Timesteps: 921,299,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 921299818...
Checkpoint 921299818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751,308.92278
Policy Entropy: 1.06558
Value Function Loss: 2.92604

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 12,443.68212
Overall Steps per Second: 10,403.05961

Timestep Collection Time: 4.02019
Timestep Consumption Time: 0.78858
PPO Batch Consumption Time: 0.03355
Total Iteration Time: 4.80878

Cumulative Model Updates: 55,236
Cumulative Timesteps: 921,349,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,852.84522
Policy Entropy: 1.05597
Value Function Loss: 3.19544

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.11439

Collected Steps per Second: 12,055.22896
Overall Steps per Second: 10,098.05759

Timestep Collection Time: 4.14758
Timestep Consumption Time: 0.80387
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.95145

Cumulative Model Updates: 55,239
Cumulative Timesteps: 921,399,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 921399844...
Checkpoint 921399844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,812.42048
Policy Entropy: 1.06922
Value Function Loss: 3.24200

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 12,702.15456
Overall Steps per Second: 10,592.33239

Timestep Collection Time: 3.93760
Timestep Consumption Time: 0.78431
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.72191

Cumulative Model Updates: 55,242
Cumulative Timesteps: 921,449,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,271.87844
Policy Entropy: 1.06610
Value Function Loss: 3.17205

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.09590

Collected Steps per Second: 12,528.51207
Overall Steps per Second: 10,555.53083

Timestep Collection Time: 3.99090
Timestep Consumption Time: 0.74596
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.73685

Cumulative Model Updates: 55,245
Cumulative Timesteps: 921,499,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 921499860...
Checkpoint 921499860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,884.41743
Policy Entropy: 1.07374
Value Function Loss: 3.06898

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 11,678.89538
Overall Steps per Second: 9,934.28043

Timestep Collection Time: 4.28294
Timestep Consumption Time: 0.75215
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 5.03509

Cumulative Model Updates: 55,248
Cumulative Timesteps: 921,549,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,747.30502
Policy Entropy: 1.07590
Value Function Loss: 3.11758

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 11,858.76769
Overall Steps per Second: 9,891.14773

Timestep Collection Time: 4.21696
Timestep Consumption Time: 0.83887
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 5.05583

Cumulative Model Updates: 55,251
Cumulative Timesteps: 921,599,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 921599888...
Checkpoint 921599888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,487.80380
Policy Entropy: 1.07397
Value Function Loss: 3.10484

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.07084
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 12,079.02996
Overall Steps per Second: 10,210.51061

Timestep Collection Time: 4.13974
Timestep Consumption Time: 0.75757
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.89731

Cumulative Model Updates: 55,254
Cumulative Timesteps: 921,649,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,931.01482
Policy Entropy: 1.09002
Value Function Loss: 3.09641

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 11,799.06081
Overall Steps per Second: 9,942.55369

Timestep Collection Time: 4.24034
Timestep Consumption Time: 0.79177
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.03211

Cumulative Model Updates: 55,257
Cumulative Timesteps: 921,699,924

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 921699924...
Checkpoint 921699924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,101.13143
Policy Entropy: 1.08590
Value Function Loss: 2.89035

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.06542
Value Function Update Magnitude: 0.10569

Collected Steps per Second: 11,915.69752
Overall Steps per Second: 10,034.04475

Timestep Collection Time: 4.19631
Timestep Consumption Time: 0.78692
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 4.98323

Cumulative Model Updates: 55,260
Cumulative Timesteps: 921,749,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,787.90522
Policy Entropy: 1.08294
Value Function Loss: 2.92486

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.07701
Value Function Update Magnitude: 0.09522

Collected Steps per Second: 11,825.93288
Overall Steps per Second: 10,202.31040

Timestep Collection Time: 4.23003
Timestep Consumption Time: 0.67318
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.90320

Cumulative Model Updates: 55,263
Cumulative Timesteps: 921,799,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 921799950...
Checkpoint 921799950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,135.62215
Policy Entropy: 1.07089
Value Function Loss: 2.80387

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 11,897.79631
Overall Steps per Second: 10,007.57703

Timestep Collection Time: 4.20263
Timestep Consumption Time: 0.79379
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.99641

Cumulative Model Updates: 55,266
Cumulative Timesteps: 921,849,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,780.29440
Policy Entropy: 1.08109
Value Function Loss: 2.88710

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 11,723.51049
Overall Steps per Second: 9,909.61395

Timestep Collection Time: 4.26681
Timestep Consumption Time: 0.78101
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.04783

Cumulative Model Updates: 55,269
Cumulative Timesteps: 921,899,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 921899974...
Checkpoint 921899974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,660.60653
Policy Entropy: 1.08474
Value Function Loss: 2.75520

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.06659
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 12,151.21372
Overall Steps per Second: 10,284.17094

Timestep Collection Time: 4.11679
Timestep Consumption Time: 0.74738
PPO Batch Consumption Time: 0.03254
Total Iteration Time: 4.86417

Cumulative Model Updates: 55,272
Cumulative Timesteps: 921,949,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,645.11037
Policy Entropy: 1.09369
Value Function Loss: 2.89236

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.08324
Value Function Update Magnitude: 0.08741

Collected Steps per Second: 11,670.36367
Overall Steps per Second: 9,788.51210

Timestep Collection Time: 4.28658
Timestep Consumption Time: 0.82410
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.11068

Cumulative Model Updates: 55,275
Cumulative Timesteps: 922,000,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 922000024...
Checkpoint 922000024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,208.32042
Policy Entropy: 1.09195
Value Function Loss: 3.04415

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.07885
Value Function Update Magnitude: 0.10980

Collected Steps per Second: 11,777.60832
Overall Steps per Second: 10,155.07758

Timestep Collection Time: 4.24534
Timestep Consumption Time: 0.67830
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.92365

Cumulative Model Updates: 55,278
Cumulative Timesteps: 922,050,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,322.20742
Policy Entropy: 1.10351
Value Function Loss: 3.29956

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 12,152.64204
Overall Steps per Second: 10,202.01478

Timestep Collection Time: 4.11598
Timestep Consumption Time: 0.78698
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.90295

Cumulative Model Updates: 55,281
Cumulative Timesteps: 922,100,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 922100044...
Checkpoint 922100044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,328.55709
Policy Entropy: 1.10558
Value Function Loss: 3.33325

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.10715

Collected Steps per Second: 11,702.10431
Overall Steps per Second: 9,907.61466

Timestep Collection Time: 4.27274
Timestep Consumption Time: 0.77389
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.04662

Cumulative Model Updates: 55,284
Cumulative Timesteps: 922,150,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,052.18636
Policy Entropy: 1.10623
Value Function Loss: 3.34875

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.11294

Collected Steps per Second: 11,829.97731
Overall Steps per Second: 10,191.32104

Timestep Collection Time: 4.22875
Timestep Consumption Time: 0.67994
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.90869

Cumulative Model Updates: 55,287
Cumulative Timesteps: 922,200,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 922200070...
Checkpoint 922200070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,950.79579
Policy Entropy: 1.10459
Value Function Loss: 3.28293

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.07459
Value Function Update Magnitude: 0.11146

Collected Steps per Second: 12,054.97624
Overall Steps per Second: 10,123.16784

Timestep Collection Time: 4.14899
Timestep Consumption Time: 0.79175
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 4.94075

Cumulative Model Updates: 55,290
Cumulative Timesteps: 922,250,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,945.88021
Policy Entropy: 1.10131
Value Function Loss: 3.27044

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.07846
Value Function Update Magnitude: 0.10169

Collected Steps per Second: 11,511.76010
Overall Steps per Second: 9,758.48330

Timestep Collection Time: 4.34356
Timestep Consumption Time: 0.78039
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.12395

Cumulative Model Updates: 55,293
Cumulative Timesteps: 922,300,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 922300088...
Checkpoint 922300088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,835.16720
Policy Entropy: 1.08923
Value Function Loss: 3.11922

Mean KL Divergence: 0.03457
SB3 Clip Fraction: 0.20283
Policy Update Magnitude: 0.07221
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 12,202.76226
Overall Steps per Second: 10,237.66041

Timestep Collection Time: 4.09956
Timestep Consumption Time: 0.78690
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.88647

Cumulative Model Updates: 55,296
Cumulative Timesteps: 922,350,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794,777.24963
Policy Entropy: 1.10931
Value Function Loss: 3.02950

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 11,900.34634
Overall Steps per Second: 9,931.16949

Timestep Collection Time: 4.20374
Timestep Consumption Time: 0.83353
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.03727

Cumulative Model Updates: 55,299
Cumulative Timesteps: 922,400,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 922400140...
Checkpoint 922400140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,043.69260
Policy Entropy: 1.11152
Value Function Loss: 3.02057

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.11820

Collected Steps per Second: 12,147.75435
Overall Steps per Second: 10,440.66948

Timestep Collection Time: 4.11730
Timestep Consumption Time: 0.67319
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.79050

Cumulative Model Updates: 55,302
Cumulative Timesteps: 922,450,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,265.60626
Policy Entropy: 1.10150
Value Function Loss: 3.17594

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.11223

Collected Steps per Second: 11,989.56561
Overall Steps per Second: 10,092.17630

Timestep Collection Time: 4.17213
Timestep Consumption Time: 0.78438
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.95651

Cumulative Model Updates: 55,305
Cumulative Timesteps: 922,500,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 922500178...
Checkpoint 922500178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,915.88936
Policy Entropy: 1.08479
Value Function Loss: 3.19723

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.16217
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.10380

Collected Steps per Second: 11,821.67352
Overall Steps per Second: 10,045.89255

Timestep Collection Time: 4.23138
Timestep Consumption Time: 0.74797
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.97935

Cumulative Model Updates: 55,308
Cumulative Timesteps: 922,550,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,825.11719
Policy Entropy: 1.10384
Value Function Loss: 3.08179

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 12,152.79726
Overall Steps per Second: 10,163.66132

Timestep Collection Time: 4.11609
Timestep Consumption Time: 0.80556
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.92165

Cumulative Model Updates: 55,311
Cumulative Timesteps: 922,600,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 922600222...
Checkpoint 922600222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,704.69087
Policy Entropy: 1.09640
Value Function Loss: 2.87585

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 11,933.90659
Overall Steps per Second: 10,033.41437

Timestep Collection Time: 4.19242
Timestep Consumption Time: 0.79411
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.98654

Cumulative Model Updates: 55,314
Cumulative Timesteps: 922,650,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,295.55269
Policy Entropy: 1.09073
Value Function Loss: 2.85664

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 12,013.26099
Overall Steps per Second: 10,298.06321

Timestep Collection Time: 4.16340
Timestep Consumption Time: 0.69344
PPO Batch Consumption Time: 0.03367
Total Iteration Time: 4.85684

Cumulative Model Updates: 55,317
Cumulative Timesteps: 922,700,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 922700270...
Checkpoint 922700270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,908.21681
Policy Entropy: 1.07246
Value Function Loss: 2.85927

Mean KL Divergence: 0.03216
SB3 Clip Fraction: 0.20154
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.10958

Collected Steps per Second: 11,889.41946
Overall Steps per Second: 9,972.24910

Timestep Collection Time: 4.20643
Timestep Consumption Time: 0.80869
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.01512

Cumulative Model Updates: 55,320
Cumulative Timesteps: 922,750,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,569.08487
Policy Entropy: 1.08753
Value Function Loss: 2.86814

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11,691.63909
Overall Steps per Second: 9,942.38460

Timestep Collection Time: 4.27673
Timestep Consumption Time: 0.75244
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.02918

Cumulative Model Updates: 55,323
Cumulative Timesteps: 922,800,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 922800284...
Checkpoint 922800284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,298.08245
Policy Entropy: 1.08891
Value Function Loss: 2.78092

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.10251

Collected Steps per Second: 12,132.49470
Overall Steps per Second: 10,157.96808

Timestep Collection Time: 4.12199
Timestep Consumption Time: 0.80124
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.92323

Cumulative Model Updates: 55,326
Cumulative Timesteps: 922,850,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,555.90261
Policy Entropy: 1.09220
Value Function Loss: 2.68626

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.08866

Collected Steps per Second: 11,908.52595
Overall Steps per Second: 9,956.00366

Timestep Collection Time: 4.19951
Timestep Consumption Time: 0.82359
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.02310

Cumulative Model Updates: 55,329
Cumulative Timesteps: 922,900,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 922900304...
Checkpoint 922900304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,892.48303
Policy Entropy: 1.09371
Value Function Loss: 2.71453

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 11,930.46074
Overall Steps per Second: 10,089.42520

Timestep Collection Time: 4.19280
Timestep Consumption Time: 0.76507
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.95786

Cumulative Model Updates: 55,332
Cumulative Timesteps: 922,950,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575,760.14775
Policy Entropy: 1.09603
Value Function Loss: 2.84621

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.08970

Collected Steps per Second: 11,730.88316
Overall Steps per Second: 9,959.87198

Timestep Collection Time: 4.26379
Timestep Consumption Time: 0.75816
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.02195

Cumulative Model Updates: 55,335
Cumulative Timesteps: 923,000,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 923000344...
Checkpoint 923000344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,430.90558
Policy Entropy: 1.09809
Value Function Loss: 2.99674

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.08446

Collected Steps per Second: 11,928.49135
Overall Steps per Second: 10,147.50506

Timestep Collection Time: 4.19265
Timestep Consumption Time: 0.73585
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.92850

Cumulative Model Updates: 55,338
Cumulative Timesteps: 923,050,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784,455.99452
Policy Entropy: 1.09533
Value Function Loss: 3.09302

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.08539

Collected Steps per Second: 11,881.80991
Overall Steps per Second: 10,035.20909

Timestep Collection Time: 4.21013
Timestep Consumption Time: 0.77472
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.98485

Cumulative Model Updates: 55,341
Cumulative Timesteps: 923,100,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 923100380...
Checkpoint 923100380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,271.81409
Policy Entropy: 1.09018
Value Function Loss: 3.09855

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 11,922.01322
Overall Steps per Second: 10,059.38785

Timestep Collection Time: 4.19409
Timestep Consumption Time: 0.77659
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.97068

Cumulative Model Updates: 55,344
Cumulative Timesteps: 923,150,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,543.42842
Policy Entropy: 1.10409
Value Function Loss: 3.25003

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.08027

Collected Steps per Second: 11,931.14731
Overall Steps per Second: 10,013.50422

Timestep Collection Time: 4.19239
Timestep Consumption Time: 0.80287
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.99525

Cumulative Model Updates: 55,347
Cumulative Timesteps: 923,200,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 923200402...
Checkpoint 923200402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,606.51720
Policy Entropy: 1.10619
Value Function Loss: 3.14591

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 11,676.16358
Overall Steps per Second: 9,763.45012

Timestep Collection Time: 4.28480
Timestep Consumption Time: 0.83942
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.12421

Cumulative Model Updates: 55,350
Cumulative Timesteps: 923,250,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,934.50373
Policy Entropy: 1.10452
Value Function Loss: 3.08876

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 11,987.60916
Overall Steps per Second: 10,145.07214

Timestep Collection Time: 4.17231
Timestep Consumption Time: 0.75777
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.93008

Cumulative Model Updates: 55,353
Cumulative Timesteps: 923,300,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 923300448...
Checkpoint 923300448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,215.63754
Policy Entropy: 1.09767
Value Function Loss: 2.92406

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 11,642.69549
Overall Steps per Second: 10,081.10628

Timestep Collection Time: 4.29505
Timestep Consumption Time: 0.66531
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.96037

Cumulative Model Updates: 55,356
Cumulative Timesteps: 923,350,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,101.07327
Policy Entropy: 1.10034
Value Function Loss: 2.85101

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 11,687.35409
Overall Steps per Second: 9,951.35279

Timestep Collection Time: 4.27898
Timestep Consumption Time: 0.74646
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.02545

Cumulative Model Updates: 55,359
Cumulative Timesteps: 923,400,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923400464...
Checkpoint 923400464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,126.46134
Policy Entropy: 1.10057
Value Function Loss: 2.91031

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.08588

Collected Steps per Second: 11,887.72664
Overall Steps per Second: 10,250.45423

Timestep Collection Time: 4.20703
Timestep Consumption Time: 0.67198
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.87900

Cumulative Model Updates: 55,362
Cumulative Timesteps: 923,450,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,240.83187
Policy Entropy: 1.10089
Value Function Loss: 2.85305

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.08690

Collected Steps per Second: 11,751.50288
Overall Steps per Second: 9,839.70799

Timestep Collection Time: 4.25563
Timestep Consumption Time: 0.82684
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.08247

Cumulative Model Updates: 55,365
Cumulative Timesteps: 923,500,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923500486...
Checkpoint 923500486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,199.37041
Policy Entropy: 1.09836
Value Function Loss: 2.96981

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.09252

Collected Steps per Second: 12,027.90966
Overall Steps per Second: 10,182.95035

Timestep Collection Time: 4.15700
Timestep Consumption Time: 0.75317
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.91017

Cumulative Model Updates: 55,368
Cumulative Timesteps: 923,550,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,207.15535
Policy Entropy: 1.10133
Value Function Loss: 2.94838

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 12,306.08026
Overall Steps per Second: 10,394.14601

Timestep Collection Time: 4.06401
Timestep Consumption Time: 0.74755
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.81155

Cumulative Model Updates: 55,371
Cumulative Timesteps: 923,600,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 923600498...
Checkpoint 923600498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,233.96618
Policy Entropy: 1.08831
Value Function Loss: 2.98570

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.10375

Collected Steps per Second: 12,789.62474
Overall Steps per Second: 10,725.85032

Timestep Collection Time: 3.90973
Timestep Consumption Time: 0.75228
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.66201

Cumulative Model Updates: 55,374
Cumulative Timesteps: 923,650,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,960.56504
Policy Entropy: 1.10408
Value Function Loss: 2.84060

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.09095

Collected Steps per Second: 12,612.95767
Overall Steps per Second: 10,739.16832

Timestep Collection Time: 3.96640
Timestep Consumption Time: 0.69206
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.65846

Cumulative Model Updates: 55,377
Cumulative Timesteps: 923,700,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 923700530...
Checkpoint 923700530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,679.21822
Policy Entropy: 1.10633
Value Function Loss: 2.84724

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.08496

Collected Steps per Second: 12,632.87431
Overall Steps per Second: 10,547.55157

Timestep Collection Time: 3.95840
Timestep Consumption Time: 0.78260
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.74101

Cumulative Model Updates: 55,380
Cumulative Timesteps: 923,750,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,143.21412
Policy Entropy: 1.09721
Value Function Loss: 3.00585

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 12,625.49180
Overall Steps per Second: 10,598.53401

Timestep Collection Time: 3.96072
Timestep Consumption Time: 0.75748
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.71820

Cumulative Model Updates: 55,383
Cumulative Timesteps: 923,800,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 923800542...
Checkpoint 923800542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,617.42185
Policy Entropy: 1.09433
Value Function Loss: 3.21205

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 12,115.24523
Overall Steps per Second: 10,214.64789

Timestep Collection Time: 4.12885
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.89709

Cumulative Model Updates: 55,386
Cumulative Timesteps: 923,850,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,683.35035
Policy Entropy: 1.10065
Value Function Loss: 3.11389

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.08445

Collected Steps per Second: 12,905.54373
Overall Steps per Second: 10,740.65671

Timestep Collection Time: 3.87554
Timestep Consumption Time: 0.78115
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.65670

Cumulative Model Updates: 55,389
Cumulative Timesteps: 923,900,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 923900580...
Checkpoint 923900580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,174.09471
Policy Entropy: 1.10589
Value Function Loss: 2.86522

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 12,061.39991
Overall Steps per Second: 10,366.88030

Timestep Collection Time: 4.14745
Timestep Consumption Time: 0.67792
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.82537

Cumulative Model Updates: 55,392
Cumulative Timesteps: 923,950,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,509.48618
Policy Entropy: 1.09802
Value Function Loss: 2.73521

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.09690

Collected Steps per Second: 12,003.21190
Overall Steps per Second: 10,150.97093

Timestep Collection Time: 4.16688
Timestep Consumption Time: 0.76033
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.92721

Cumulative Model Updates: 55,395
Cumulative Timesteps: 924,000,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 924000620...
Checkpoint 924000620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,397.35634
Policy Entropy: 1.08588
Value Function Loss: 2.82327

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.09224

Collected Steps per Second: 11,717.19133
Overall Steps per Second: 9,938.94737

Timestep Collection Time: 4.26945
Timestep Consumption Time: 0.76388
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 5.03333

Cumulative Model Updates: 55,398
Cumulative Timesteps: 924,050,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,509.75249
Policy Entropy: 1.09747
Value Function Loss: 2.92859

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 12,320.82567
Overall Steps per Second: 10,329.22697

Timestep Collection Time: 4.05947
Timestep Consumption Time: 0.78271
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 4.84218

Cumulative Model Updates: 55,401
Cumulative Timesteps: 924,100,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 924100662...
Checkpoint 924100662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,442.90928
Policy Entropy: 1.09440
Value Function Loss: 3.08336

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.08294

Collected Steps per Second: 11,454.40475
Overall Steps per Second: 9,754.49345

Timestep Collection Time: 4.36566
Timestep Consumption Time: 0.76080
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.12646

Cumulative Model Updates: 55,404
Cumulative Timesteps: 924,150,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,758.34509
Policy Entropy: 1.10174
Value Function Loss: 3.04077

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.08506

Collected Steps per Second: 11,976.78239
Overall Steps per Second: 10,269.24587

Timestep Collection Time: 4.17742
Timestep Consumption Time: 0.69461
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.87202

Cumulative Model Updates: 55,407
Cumulative Timesteps: 924,200,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 924200700...
Checkpoint 924200700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,384.03392
Policy Entropy: 1.09673
Value Function Loss: 3.02608

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.07415
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 11,621.39625
Overall Steps per Second: 9,867.40429

Timestep Collection Time: 4.30310
Timestep Consumption Time: 0.76490
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.06800

Cumulative Model Updates: 55,410
Cumulative Timesteps: 924,250,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,200.84936
Policy Entropy: 1.09836
Value Function Loss: 2.88670

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 12,031.76494
Overall Steps per Second: 10,147.50962

Timestep Collection Time: 4.15633
Timestep Consumption Time: 0.77177
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.92811

Cumulative Model Updates: 55,413
Cumulative Timesteps: 924,300,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 924300716...
Checkpoint 924300716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,573.13136
Policy Entropy: 1.09050
Value Function Loss: 2.91244

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.07315
Value Function Update Magnitude: 0.10320

Collected Steps per Second: 11,867.82963
Overall Steps per Second: 10,166.89638

Timestep Collection Time: 4.21341
Timestep Consumption Time: 0.70491
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.91832

Cumulative Model Updates: 55,416
Cumulative Timesteps: 924,350,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,973.83799
Policy Entropy: 1.07732
Value Function Loss: 2.87056

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.06996
Value Function Update Magnitude: 0.09555

Collected Steps per Second: 12,018.48211
Overall Steps per Second: 10,164.81215

Timestep Collection Time: 4.16126
Timestep Consumption Time: 0.75885
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.92011

Cumulative Model Updates: 55,419
Cumulative Timesteps: 924,400,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 924400732...
Checkpoint 924400732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,421.19682
Policy Entropy: 1.09528
Value Function Loss: 2.92518

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 11,234.02070
Overall Steps per Second: 9,616.12452

Timestep Collection Time: 4.45290
Timestep Consumption Time: 0.74919
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.20210

Cumulative Model Updates: 55,422
Cumulative Timesteps: 924,450,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,718.58087
Policy Entropy: 1.09325
Value Function Loss: 2.97654

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 12,161.48850
Overall Steps per Second: 10,255.00796

Timestep Collection Time: 4.11183
Timestep Consumption Time: 0.76442
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.87625

Cumulative Model Updates: 55,425
Cumulative Timesteps: 924,500,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 924500762...
Checkpoint 924500762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,525.54662
Policy Entropy: 1.08482
Value Function Loss: 3.03478

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09175

Collected Steps per Second: 11,870.12818
Overall Steps per Second: 10,123.42992

Timestep Collection Time: 4.21444
Timestep Consumption Time: 0.72716
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.94161

Cumulative Model Updates: 55,428
Cumulative Timesteps: 924,550,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,722.65044
Policy Entropy: 1.07999
Value Function Loss: 2.97862

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.17513
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 11,977.14793
Overall Steps per Second: 10,296.99015

Timestep Collection Time: 4.17629
Timestep Consumption Time: 0.68144
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.85773

Cumulative Model Updates: 55,431
Cumulative Timesteps: 924,600,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 924600808...
Checkpoint 924600808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,927.83113
Policy Entropy: 1.09375
Value Function Loss: 2.93101

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.09475

Collected Steps per Second: 11,723.49868
Overall Steps per Second: 9,976.87268

Timestep Collection Time: 4.26664
Timestep Consumption Time: 0.74695
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 5.01360

Cumulative Model Updates: 55,434
Cumulative Timesteps: 924,650,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,834.19334
Policy Entropy: 1.09587
Value Function Loss: 2.80971

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 11,815.38481
Overall Steps per Second: 10,000.72079

Timestep Collection Time: 4.23329
Timestep Consumption Time: 0.76815
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.00144

Cumulative Model Updates: 55,437
Cumulative Timesteps: 924,700,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 924700846...
Checkpoint 924700846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,107.71099
Policy Entropy: 1.08723
Value Function Loss: 2.89256

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.08505

Collected Steps per Second: 11,666.32954
Overall Steps per Second: 9,901.45984

Timestep Collection Time: 4.28618
Timestep Consumption Time: 0.76398
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.05016

Cumulative Model Updates: 55,440
Cumulative Timesteps: 924,750,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,362.94050
Policy Entropy: 1.07136
Value Function Loss: 2.95348

Mean KL Divergence: 0.02662
SB3 Clip Fraction: 0.17466
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.08414

Collected Steps per Second: 12,039.51039
Overall Steps per Second: 10,123.63056

Timestep Collection Time: 4.15382
Timestep Consumption Time: 0.78610
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.93993

Cumulative Model Updates: 55,443
Cumulative Timesteps: 924,800,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 924800860...
Checkpoint 924800860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,108.97547
Policy Entropy: 1.08630
Value Function Loss: 3.14653

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08522

Collected Steps per Second: 11,745.36969
Overall Steps per Second: 10,177.07852

Timestep Collection Time: 4.25785
Timestep Consumption Time: 0.65614
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 4.91398

Cumulative Model Updates: 55,446
Cumulative Timesteps: 924,850,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,303.98203
Policy Entropy: 1.08548
Value Function Loss: 3.17221

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.08825

Collected Steps per Second: 12,057.88498
Overall Steps per Second: 10,131.50970

Timestep Collection Time: 4.14816
Timestep Consumption Time: 0.78872
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.93688

Cumulative Model Updates: 55,449
Cumulative Timesteps: 924,900,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 924900888...
Checkpoint 924900888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,127.29249
Policy Entropy: 1.07039
Value Function Loss: 3.10302

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 11,510.66885
Overall Steps per Second: 9,841.70552

Timestep Collection Time: 4.34536
Timestep Consumption Time: 0.73689
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.08225

Cumulative Model Updates: 55,452
Cumulative Timesteps: 924,950,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,884.77950
Policy Entropy: 1.05583
Value Function Loss: 2.87279

Mean KL Divergence: 0.02948
SB3 Clip Fraction: 0.18327
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 12,367.76502
Overall Steps per Second: 10,453.75623

Timestep Collection Time: 4.04390
Timestep Consumption Time: 0.74041
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.78431

Cumulative Model Updates: 55,455
Cumulative Timesteps: 925,000,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 925000920...
Checkpoint 925000920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,538.23894
Policy Entropy: 1.06433
Value Function Loss: 2.74398

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 11,501.98565
Overall Steps per Second: 9,780.05344

Timestep Collection Time: 4.34708
Timestep Consumption Time: 0.76537
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.11245

Cumulative Model Updates: 55,458
Cumulative Timesteps: 925,050,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,344.57371
Policy Entropy: 1.06957
Value Function Loss: 2.69857

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.10557

Collected Steps per Second: 12,382.35285
Overall Steps per Second: 10,411.03084

Timestep Collection Time: 4.03817
Timestep Consumption Time: 0.76462
PPO Batch Consumption Time: 0.03368
Total Iteration Time: 4.80279

Cumulative Model Updates: 55,461
Cumulative Timesteps: 925,100,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 925100922...
Checkpoint 925100922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,207.03817
Policy Entropy: 1.06449
Value Function Loss: 2.80406

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 11,890.24066
Overall Steps per Second: 10,067.58575

Timestep Collection Time: 4.20664
Timestep Consumption Time: 0.76158
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.96822

Cumulative Model Updates: 55,464
Cumulative Timesteps: 925,150,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,069.50370
Policy Entropy: 1.06222
Value Function Loss: 2.86947

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.07028
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 11,668.62314
Overall Steps per Second: 10,048.61553

Timestep Collection Time: 4.28585
Timestep Consumption Time: 0.69095
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 4.97681

Cumulative Model Updates: 55,467
Cumulative Timesteps: 925,200,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 925200950...
Checkpoint 925200950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,520.48492
Policy Entropy: 1.06148
Value Function Loss: 2.96942

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.09487

Collected Steps per Second: 11,771.79242
Overall Steps per Second: 9,955.47638

Timestep Collection Time: 4.24965
Timestep Consumption Time: 0.77532
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.02497

Cumulative Model Updates: 55,470
Cumulative Timesteps: 925,250,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,894.98694
Policy Entropy: 1.06137
Value Function Loss: 3.12698

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.06702
Value Function Update Magnitude: 0.09375

Collected Steps per Second: 11,805.06285
Overall Steps per Second: 10,004.40008

Timestep Collection Time: 4.23649
Timestep Consumption Time: 0.76251
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.99900

Cumulative Model Updates: 55,473
Cumulative Timesteps: 925,300,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 925300988...
Checkpoint 925300988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,790.18984
Policy Entropy: 1.07655
Value Function Loss: 3.09567

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.10159

Collected Steps per Second: 11,514.13631
Overall Steps per Second: 9,742.89781

Timestep Collection Time: 4.34475
Timestep Consumption Time: 0.78987
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.13461

Cumulative Model Updates: 55,476
Cumulative Timesteps: 925,351,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,249.21455
Policy Entropy: 1.08208
Value Function Loss: 3.04745

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16140
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 12,040.27926
Overall Steps per Second: 10,107.20633

Timestep Collection Time: 4.15273
Timestep Consumption Time: 0.79424
PPO Batch Consumption Time: 0.03735
Total Iteration Time: 4.94697

Cumulative Model Updates: 55,479
Cumulative Timesteps: 925,401,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 925401014...
Checkpoint 925401014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,435.95873
Policy Entropy: 1.06770
Value Function Loss: 2.93250

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.16732
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 11,337.03511
Overall Steps per Second: 9,871.11468

Timestep Collection Time: 4.41068
Timestep Consumption Time: 0.65501
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.06569

Cumulative Model Updates: 55,482
Cumulative Timesteps: 925,451,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,949.08124
Policy Entropy: 1.07423
Value Function Loss: 2.91075

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.11243

Collected Steps per Second: 11,780.83336
Overall Steps per Second: 9,921.19585

Timestep Collection Time: 4.24639
Timestep Consumption Time: 0.79595
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.04234

Cumulative Model Updates: 55,485
Cumulative Timesteps: 925,501,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 925501044...
Checkpoint 925501044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,051.99409
Policy Entropy: 1.08025
Value Function Loss: 2.91210

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 11,682.44877
Overall Steps per Second: 9,944.14092

Timestep Collection Time: 4.28044
Timestep Consumption Time: 0.74825
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.02869

Cumulative Model Updates: 55,488
Cumulative Timesteps: 925,551,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,344.21483
Policy Entropy: 1.08714
Value Function Loss: 2.87073

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.10216

Collected Steps per Second: 11,882.26102
Overall Steps per Second: 10,113.10024

Timestep Collection Time: 4.20846
Timestep Consumption Time: 0.73622
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.94468

Cumulative Model Updates: 55,491
Cumulative Timesteps: 925,601,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 925601056...
Checkpoint 925601056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,921.27991
Policy Entropy: 1.06997
Value Function Loss: 2.84398

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 11,441.09308
Overall Steps per Second: 9,806.51222

Timestep Collection Time: 4.37021
Timestep Consumption Time: 0.72844
PPO Batch Consumption Time: 0.03831
Total Iteration Time: 5.09865

Cumulative Model Updates: 55,494
Cumulative Timesteps: 925,651,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,685.42395
Policy Entropy: 1.07174
Value Function Loss: 2.81529

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.16506
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.09470

Collected Steps per Second: 11,843.08782
Overall Steps per Second: 10,158.12550

Timestep Collection Time: 4.22407
Timestep Consumption Time: 0.70066
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 4.92473

Cumulative Model Updates: 55,497
Cumulative Timesteps: 925,701,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 925701082...
Checkpoint 925701082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,061.75739
Policy Entropy: 1.07957
Value Function Loss: 2.77922

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.09476

Collected Steps per Second: 11,672.67495
Overall Steps per Second: 9,848.12816

Timestep Collection Time: 4.28522
Timestep Consumption Time: 0.79392
PPO Batch Consumption Time: 0.03364
Total Iteration Time: 5.07914

Cumulative Model Updates: 55,500
Cumulative Timesteps: 925,751,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,106.63868
Policy Entropy: 1.08770
Value Function Loss: 2.98214

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.10429

Collected Steps per Second: 11,585.77732
Overall Steps per Second: 9,870.47937

Timestep Collection Time: 4.31633
Timestep Consumption Time: 0.75009
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.06642

Cumulative Model Updates: 55,503
Cumulative Timesteps: 925,801,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 925801110...
Checkpoint 925801110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,640.28109
Policy Entropy: 1.06826
Value Function Loss: 2.99746

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.10688

Collected Steps per Second: 11,244.25584
Overall Steps per Second: 9,451.64290

Timestep Collection Time: 4.44671
Timestep Consumption Time: 0.84337
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.29009

Cumulative Model Updates: 55,506
Cumulative Timesteps: 925,851,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,505.86374
Policy Entropy: 1.06690
Value Function Loss: 3.04790

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.09750

Collected Steps per Second: 10,982.89462
Overall Steps per Second: 9,228.70807

Timestep Collection Time: 4.55326
Timestep Consumption Time: 0.86548
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.41874

Cumulative Model Updates: 55,509
Cumulative Timesteps: 925,901,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 925901118...
Checkpoint 925901118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,279.47937
Policy Entropy: 1.07770
Value Function Loss: 2.76890

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 10,632.14993
Overall Steps per Second: 9,220.60978

Timestep Collection Time: 4.70422
Timestep Consumption Time: 0.72015
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.42437

Cumulative Model Updates: 55,512
Cumulative Timesteps: 925,951,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,439.04160
Policy Entropy: 1.09468
Value Function Loss: 2.77248

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.15899
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 11,376.88086
Overall Steps per Second: 9,598.86110

Timestep Collection Time: 4.39488
Timestep Consumption Time: 0.81407
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.20895

Cumulative Model Updates: 55,515
Cumulative Timesteps: 926,001,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 926001134...
Checkpoint 926001134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,919.11379
Policy Entropy: 1.07756
Value Function Loss: 2.80930

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 12,051.11859
Overall Steps per Second: 10,001.72199

Timestep Collection Time: 4.15165
Timestep Consumption Time: 0.85069
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.00234

Cumulative Model Updates: 55,518
Cumulative Timesteps: 926,051,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,281.65574
Policy Entropy: 1.09352
Value Function Loss: 2.93508

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 10,985.34353
Overall Steps per Second: 9,304.55096

Timestep Collection Time: 4.55207
Timestep Consumption Time: 0.82229
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 5.37436

Cumulative Model Updates: 55,521
Cumulative Timesteps: 926,101,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 926101172...
Checkpoint 926101172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,546.40285
Policy Entropy: 1.08562
Value Function Loss: 2.82102

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 10,762.66713
Overall Steps per Second: 9,218.85660

Timestep Collection Time: 4.64569
Timestep Consumption Time: 0.77798
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.42367

Cumulative Model Updates: 55,524
Cumulative Timesteps: 926,151,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,795.59125
Policy Entropy: 1.07029
Value Function Loss: 2.70090

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 12,274.35177
Overall Steps per Second: 10,343.67622

Timestep Collection Time: 4.07402
Timestep Consumption Time: 0.76043
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.83445

Cumulative Model Updates: 55,527
Cumulative Timesteps: 926,201,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 926201178...
Checkpoint 926201178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,323.81779
Policy Entropy: 1.06293
Value Function Loss: 2.68038

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.17857
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.11130

Collected Steps per Second: 12,579.81771
Overall Steps per Second: 10,523.44280

Timestep Collection Time: 3.97557
Timestep Consumption Time: 0.77686
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.75244

Cumulative Model Updates: 55,530
Cumulative Timesteps: 926,251,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,872.94067
Policy Entropy: 1.06548
Value Function Loss: 2.85903

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.10201

Collected Steps per Second: 11,987.78283
Overall Steps per Second: 9,995.25604

Timestep Collection Time: 4.17108
Timestep Consumption Time: 0.83149
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 5.00257

Cumulative Model Updates: 55,533
Cumulative Timesteps: 926,301,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 926301192...
Checkpoint 926301192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,027.21056
Policy Entropy: 1.07899
Value Function Loss: 3.08393

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.16844
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.09949

Collected Steps per Second: 11,141.02882
Overall Steps per Second: 9,371.59680

Timestep Collection Time: 4.48827
Timestep Consumption Time: 0.84742
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.33570

Cumulative Model Updates: 55,536
Cumulative Timesteps: 926,351,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625,915.43641
Policy Entropy: 1.05743
Value Function Loss: 3.11112

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.10121

Collected Steps per Second: 11,394.03924
Overall Steps per Second: 9,753.97256

Timestep Collection Time: 4.38931
Timestep Consumption Time: 0.73803
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.12735

Cumulative Model Updates: 55,539
Cumulative Timesteps: 926,401,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 926401208...
Checkpoint 926401208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,177.69752
Policy Entropy: 1.07045
Value Function Loss: 3.13278

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 11,819.46634
Overall Steps per Second: 10,185.44579

Timestep Collection Time: 4.23116
Timestep Consumption Time: 0.67879
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 4.90995

Cumulative Model Updates: 55,542
Cumulative Timesteps: 926,451,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,305.88910
Policy Entropy: 1.06676
Value Function Loss: 2.88481

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 11,611.92862
Overall Steps per Second: 9,828.94039

Timestep Collection Time: 4.30626
Timestep Consumption Time: 0.78116
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.08743

Cumulative Model Updates: 55,545
Cumulative Timesteps: 926,501,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 926501222...
Checkpoint 926501222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,510.05893
Policy Entropy: 1.05792
Value Function Loss: 2.84973

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 11,859.22415
Overall Steps per Second: 10,084.95898

Timestep Collection Time: 4.21646
Timestep Consumption Time: 0.74181
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.95828

Cumulative Model Updates: 55,548
Cumulative Timesteps: 926,551,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,523.21614
Policy Entropy: 1.04858
Value Function Loss: 2.74706

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.19101
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.09241

Collected Steps per Second: 11,786.62360
Overall Steps per Second: 10,178.25813

Timestep Collection Time: 4.24261
Timestep Consumption Time: 0.67042
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.91302

Cumulative Model Updates: 55,551
Cumulative Timesteps: 926,601,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 926601232...
Checkpoint 926601232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,856.28558
Policy Entropy: 1.06240
Value Function Loss: 2.89104

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 11,770.77081
Overall Steps per Second: 9,991.74947

Timestep Collection Time: 4.24815
Timestep Consumption Time: 0.75638
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.00453

Cumulative Model Updates: 55,554
Cumulative Timesteps: 926,651,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,184.75796
Policy Entropy: 1.07627
Value Function Loss: 2.93072

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 11,735.26146
Overall Steps per Second: 9,937.08322

Timestep Collection Time: 4.26203
Timestep Consumption Time: 0.77124
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.03327

Cumulative Model Updates: 55,557
Cumulative Timesteps: 926,701,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 926701252...
Checkpoint 926701252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,153.08992
Policy Entropy: 1.04329
Value Function Loss: 2.83576

Mean KL Divergence: 0.03458
SB3 Clip Fraction: 0.19577
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 12,153.39362
Overall Steps per Second: 10,284.62935

Timestep Collection Time: 4.11556
Timestep Consumption Time: 0.74782
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.86337

Cumulative Model Updates: 55,560
Cumulative Timesteps: 926,751,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,319.34542
Policy Entropy: 1.06408
Value Function Loss: 2.85731

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.16215
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 11,530.67857
Overall Steps per Second: 9,778.70859

Timestep Collection Time: 4.33886
Timestep Consumption Time: 0.77736
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.11622

Cumulative Model Updates: 55,563
Cumulative Timesteps: 926,801,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 926801300...
Checkpoint 926801300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,160.84048
Policy Entropy: 1.05964
Value Function Loss: 2.74875

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11,790.63068
Overall Steps per Second: 10,169.96317

Timestep Collection Time: 4.24286
Timestep Consumption Time: 0.67613
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.91900

Cumulative Model Updates: 55,566
Cumulative Timesteps: 926,851,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,002.54014
Policy Entropy: 1.05650
Value Function Loss: 2.80092

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 11,953.50962
Overall Steps per Second: 10,028.70599

Timestep Collection Time: 4.18354
Timestep Consumption Time: 0.80294
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.98649

Cumulative Model Updates: 55,569
Cumulative Timesteps: 926,901,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 926901334...
Checkpoint 926901334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,064.23059
Policy Entropy: 1.04219
Value Function Loss: 2.77637

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 11,756.09088
Overall Steps per Second: 9,997.61556

Timestep Collection Time: 4.25345
Timestep Consumption Time: 0.74814
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.00159

Cumulative Model Updates: 55,572
Cumulative Timesteps: 926,951,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,439.86318
Policy Entropy: 1.05574
Value Function Loss: 3.02083

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 12,219.73636
Overall Steps per Second: 10,267.22137

Timestep Collection Time: 4.09338
Timestep Consumption Time: 0.77844
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.87181

Cumulative Model Updates: 55,575
Cumulative Timesteps: 927,001,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 927001358...
Checkpoint 927001358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,628.67665
Policy Entropy: 1.06730
Value Function Loss: 2.94374

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 11,798.28397
Overall Steps per Second: 9,969.56850

Timestep Collection Time: 4.23960
Timestep Consumption Time: 0.77767
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.01727

Cumulative Model Updates: 55,578
Cumulative Timesteps: 927,051,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,282.11059
Policy Entropy: 1.05133
Value Function Loss: 2.80060

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 11,555.80948
Overall Steps per Second: 9,940.31615

Timestep Collection Time: 4.32683
Timestep Consumption Time: 0.70319
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.03002

Cumulative Model Updates: 55,581
Cumulative Timesteps: 927,101,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 927101378...
Checkpoint 927101378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,822.60181
Policy Entropy: 1.04330
Value Function Loss: 2.59743

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.17523
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 11,806.78646
Overall Steps per Second: 10,022.36961

Timestep Collection Time: 4.23689
Timestep Consumption Time: 0.75435
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.99123

Cumulative Model Updates: 55,584
Cumulative Timesteps: 927,151,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,792.92625
Policy Entropy: 1.05225
Value Function Loss: 2.72387

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 11,923.91467
Overall Steps per Second: 10,084.94148

Timestep Collection Time: 4.19460
Timestep Consumption Time: 0.76488
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 4.95947

Cumulative Model Updates: 55,587
Cumulative Timesteps: 927,201,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927201418...
Checkpoint 927201418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732,877.37554
Policy Entropy: 1.06302
Value Function Loss: 2.93292

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.09511

Collected Steps per Second: 12,248.80188
Overall Steps per Second: 10,255.57572

Timestep Collection Time: 4.08203
Timestep Consumption Time: 0.79336
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.87540

Cumulative Model Updates: 55,590
Cumulative Timesteps: 927,251,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,322.20394
Policy Entropy: 1.04992
Value Function Loss: 3.02993

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.16094
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 11,722.63987
Overall Steps per Second: 9,959.68918

Timestep Collection Time: 4.26730
Timestep Consumption Time: 0.75535
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.02265

Cumulative Model Updates: 55,593
Cumulative Timesteps: 927,301,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 927301442...
Checkpoint 927301442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,663.17773
Policy Entropy: 1.06009
Value Function Loss: 3.08999

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 11,759.38455
Overall Steps per Second: 10,193.08600

Timestep Collection Time: 4.25192
Timestep Consumption Time: 0.65336
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.90529

Cumulative Model Updates: 55,596
Cumulative Timesteps: 927,351,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,428.14090
Policy Entropy: 1.06295
Value Function Loss: 3.13736

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 12,025.03493
Overall Steps per Second: 10,013.97916

Timestep Collection Time: 4.15816
Timestep Consumption Time: 0.83506
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.99322

Cumulative Model Updates: 55,599
Cumulative Timesteps: 927,401,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 927401444...
Checkpoint 927401444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,665.18953
Policy Entropy: 1.05956
Value Function Loss: 3.27816

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 12,069.43845
Overall Steps per Second: 10,202.56426

Timestep Collection Time: 4.14468
Timestep Consumption Time: 0.75840
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 4.90308

Cumulative Model Updates: 55,602
Cumulative Timesteps: 927,451,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,475.81723
Policy Entropy: 1.05763
Value Function Loss: 3.19616

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 12,348.94815
Overall Steps per Second: 10,343.68922

Timestep Collection Time: 4.05022
Timestep Consumption Time: 0.78519
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.83541

Cumulative Model Updates: 55,605
Cumulative Timesteps: 927,501,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927501484...
Checkpoint 927501484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,662.49948
Policy Entropy: 1.06352
Value Function Loss: 3.05085

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.10509

Collected Steps per Second: 11,700.24955
Overall Steps per Second: 9,913.58617

Timestep Collection Time: 4.27564
Timestep Consumption Time: 0.77057
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 5.04621

Cumulative Model Updates: 55,608
Cumulative Timesteps: 927,551,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,990.23464
Policy Entropy: 1.05972
Value Function Loss: 2.83504

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 11,972.69030
Overall Steps per Second: 10,279.22290

Timestep Collection Time: 4.17784
Timestep Consumption Time: 0.68829
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.86613

Cumulative Model Updates: 55,611
Cumulative Timesteps: 927,601,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 927601530...
Checkpoint 927601530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,814.23330
Policy Entropy: 1.05244
Value Function Loss: 2.64139

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.06561
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 11,845.53098
Overall Steps per Second: 9,952.18547

Timestep Collection Time: 4.22370
Timestep Consumption Time: 0.80353
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.02724

Cumulative Model Updates: 55,614
Cumulative Timesteps: 927,651,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,476.22465
Policy Entropy: 1.04943
Value Function Loss: 2.75047

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.11129

Collected Steps per Second: 11,820.82345
Overall Steps per Second: 9,906.55614

Timestep Collection Time: 4.23152
Timestep Consumption Time: 0.81767
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.04918

Cumulative Model Updates: 55,617
Cumulative Timesteps: 927,701,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 927701582...
Checkpoint 927701582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,128.37278
Policy Entropy: 1.06320
Value Function Loss: 2.62477

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 11,912.74723
Overall Steps per Second: 10,052.70769

Timestep Collection Time: 4.19937
Timestep Consumption Time: 0.77700
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.97637

Cumulative Model Updates: 55,620
Cumulative Timesteps: 927,751,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,868.00587
Policy Entropy: 1.06126
Value Function Loss: 2.68661

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.09850

Collected Steps per Second: 11,738.28661
Overall Steps per Second: 9,987.08714

Timestep Collection Time: 4.26195
Timestep Consumption Time: 0.74732
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.00927

Cumulative Model Updates: 55,623
Cumulative Timesteps: 927,801,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 927801636...
Checkpoint 927801636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,819.49668
Policy Entropy: 1.06137
Value Function Loss: 2.69649

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.11167

Collected Steps per Second: 11,732.65999
Overall Steps per Second: 10,142.65650

Timestep Collection Time: 4.26399
Timestep Consumption Time: 0.66844
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 4.93244

Cumulative Model Updates: 55,626
Cumulative Timesteps: 927,851,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699,130.31075
Policy Entropy: 1.05716
Value Function Loss: 2.99301

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.10595

Collected Steps per Second: 11,789.91406
Overall Steps per Second: 9,919.07121

Timestep Collection Time: 4.24176
Timestep Consumption Time: 0.80004
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.04180

Cumulative Model Updates: 55,629
Cumulative Timesteps: 927,901,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 927901674...
Checkpoint 927901674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,680.30080
Policy Entropy: 1.04521
Value Function Loss: 3.06968

Mean KL Divergence: 0.02577
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 11,704.23814
Overall Steps per Second: 10,006.74450

Timestep Collection Time: 4.27452
Timestep Consumption Time: 0.72511
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 4.99963

Cumulative Model Updates: 55,632
Cumulative Timesteps: 927,951,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709,980.61824
Policy Entropy: 1.06025
Value Function Loss: 3.10308

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.09714

Collected Steps per Second: 12,254.44949
Overall Steps per Second: 10,152.59667

Timestep Collection Time: 4.08162
Timestep Consumption Time: 0.84500
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 4.92662

Cumulative Model Updates: 55,635
Cumulative Timesteps: 928,001,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 928001722...
Checkpoint 928001722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735,555.27711
Policy Entropy: 1.06183
Value Function Loss: 2.87745

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.08823

Collected Steps per Second: 11,619.57770
Overall Steps per Second: 9,883.19856

Timestep Collection Time: 4.30549
Timestep Consumption Time: 0.75643
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 5.06192

Cumulative Model Updates: 55,638
Cumulative Timesteps: 928,051,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,766.92591
Policy Entropy: 1.05504
Value Function Loss: 2.75458

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 11,861.75524
Overall Steps per Second: 10,189.76093

Timestep Collection Time: 4.21776
Timestep Consumption Time: 0.69207
PPO Batch Consumption Time: 0.03391
Total Iteration Time: 4.90983

Cumulative Model Updates: 55,641
Cumulative Timesteps: 928,101,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 928101780...
Checkpoint 928101780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,502.99192
Policy Entropy: 1.03320
Value Function Loss: 2.58643

Mean KL Divergence: 0.03149
SB3 Clip Fraction: 0.18531
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11,901.07939
Overall Steps per Second: 10,034.45119

Timestep Collection Time: 4.20197
Timestep Consumption Time: 0.78166
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.98363

Cumulative Model Updates: 55,644
Cumulative Timesteps: 928,151,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777,383.12957
Policy Entropy: 1.05448
Value Function Loss: 2.56365

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.09635

Collected Steps per Second: 11,926.25948
Overall Steps per Second: 10,117.41341

Timestep Collection Time: 4.19394
Timestep Consumption Time: 0.74982
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.94375

Cumulative Model Updates: 55,647
Cumulative Timesteps: 928,201,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 928201806...
Checkpoint 928201806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,394.10638
Policy Entropy: 1.04834
Value Function Loss: 2.71036

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 11,998.81144
Overall Steps per Second: 10,056.86156

Timestep Collection Time: 4.16908
Timestep Consumption Time: 0.80504
PPO Batch Consumption Time: 0.03926
Total Iteration Time: 4.97412

Cumulative Model Updates: 55,650
Cumulative Timesteps: 928,251,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,386.19632
Policy Entropy: 1.05131
Value Function Loss: 2.82376

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 11,811.52100
Overall Steps per Second: 9,819.34024

Timestep Collection Time: 4.23400
Timestep Consumption Time: 0.85901
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.09301

Cumulative Model Updates: 55,653
Cumulative Timesteps: 928,301,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 928301840...
Checkpoint 928301840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,729.50310
Policy Entropy: 1.03954
Value Function Loss: 2.93997

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.12918

Collected Steps per Second: 11,742.00076
Overall Steps per Second: 10,087.48496

Timestep Collection Time: 4.26009
Timestep Consumption Time: 0.69873
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.95882

Cumulative Model Updates: 55,656
Cumulative Timesteps: 928,351,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,047.23799
Policy Entropy: 1.06415
Value Function Loss: 2.83456

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.11406

Collected Steps per Second: 11,856.85021
Overall Steps per Second: 10,005.91784

Timestep Collection Time: 4.21815
Timestep Consumption Time: 0.78029
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.99844

Cumulative Model Updates: 55,659
Cumulative Timesteps: 928,401,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928401876...
Checkpoint 928401876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,328.09936
Policy Entropy: 1.04908
Value Function Loss: 2.81730

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 12,529.27068
Overall Steps per Second: 10,524.36627

Timestep Collection Time: 3.99209
Timestep Consumption Time: 0.76050
PPO Batch Consumption Time: 0.03355
Total Iteration Time: 4.75259

Cumulative Model Updates: 55,662
Cumulative Timesteps: 928,451,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,673.75708
Policy Entropy: 1.04735
Value Function Loss: 2.85335

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.09085

Collected Steps per Second: 12,697.21203
Overall Steps per Second: 10,537.14609

Timestep Collection Time: 3.93960
Timestep Consumption Time: 0.80760
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.74721

Cumulative Model Updates: 55,665
Cumulative Timesteps: 928,501,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 928501916...
Checkpoint 928501916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,458.58041
Policy Entropy: 1.04059
Value Function Loss: 2.95871

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.08046

Collected Steps per Second: 12,229.00419
Overall Steps per Second: 10,198.65377

Timestep Collection Time: 4.09060
Timestep Consumption Time: 0.81436
PPO Batch Consumption Time: 0.03329
Total Iteration Time: 4.90496

Cumulative Model Updates: 55,668
Cumulative Timesteps: 928,551,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770,939.77043
Policy Entropy: 1.03363
Value Function Loss: 3.05944

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 12,483.97953
Overall Steps per Second: 10,621.62584

Timestep Collection Time: 4.00722
Timestep Consumption Time: 0.70261
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.70983

Cumulative Model Updates: 55,671
Cumulative Timesteps: 928,601,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 928601966...
Checkpoint 928601966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762,032.75984
Policy Entropy: 1.04868
Value Function Loss: 3.07852

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.10343

Collected Steps per Second: 11,636.51793
Overall Steps per Second: 9,783.79962

Timestep Collection Time: 4.29888
Timestep Consumption Time: 0.81406
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 5.11294

Cumulative Model Updates: 55,674
Cumulative Timesteps: 928,651,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,370.39852
Policy Entropy: 1.04610
Value Function Loss: 3.07096

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.06524
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 12,652.98968
Overall Steps per Second: 10,612.03771

Timestep Collection Time: 3.95322
Timestep Consumption Time: 0.76030
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.71352

Cumulative Model Updates: 55,677
Cumulative Timesteps: 928,702,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 928702010...
Checkpoint 928702010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,549.51423
Policy Entropy: 1.05050
Value Function Loss: 2.96513

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 11,644.63213
Overall Steps per Second: 9,867.11218

Timestep Collection Time: 4.29537
Timestep Consumption Time: 0.77379
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 5.06916

Cumulative Model Updates: 55,680
Cumulative Timesteps: 928,752,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,239.02919
Policy Entropy: 1.05503
Value Function Loss: 3.01719

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.07658
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 11,789.48242
Overall Steps per Second: 9,953.28241

Timestep Collection Time: 4.24310
Timestep Consumption Time: 0.78278
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.02588

Cumulative Model Updates: 55,683
Cumulative Timesteps: 928,802,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 928802052...
Checkpoint 928802052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,080.05109
Policy Entropy: 1.05239
Value Function Loss: 3.09024

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.07951
Value Function Update Magnitude: 0.10455

Collected Steps per Second: 11,819.87608
Overall Steps per Second: 10,190.28828

Timestep Collection Time: 4.23033
Timestep Consumption Time: 0.67650
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.90683

Cumulative Model Updates: 55,686
Cumulative Timesteps: 928,852,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,065.47083
Policy Entropy: 1.05764
Value Function Loss: 2.98920

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.07195
Value Function Update Magnitude: 0.11001

Collected Steps per Second: 11,763.74868
Overall Steps per Second: 9,941.68336

Timestep Collection Time: 4.25137
Timestep Consumption Time: 0.77917
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 5.03054

Cumulative Model Updates: 55,689
Cumulative Timesteps: 928,902,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 928902066...
Checkpoint 928902066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,273.28245
Policy Entropy: 1.05537
Value Function Loss: 2.79059

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 11,302.08919
Overall Steps per Second: 9,641.85750

Timestep Collection Time: 4.42414
Timestep Consumption Time: 0.76179
PPO Batch Consumption Time: 0.03920
Total Iteration Time: 5.18593

Cumulative Model Updates: 55,692
Cumulative Timesteps: 928,952,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,564.74134
Policy Entropy: 1.07157
Value Function Loss: 2.61180

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.10136

Collected Steps per Second: 11,759.48987
Overall Steps per Second: 10,130.59919

Timestep Collection Time: 4.25410
Timestep Consumption Time: 0.68401
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.93811

Cumulative Model Updates: 55,695
Cumulative Timesteps: 929,002,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 929002094...
Checkpoint 929002094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,374.41818
Policy Entropy: 1.07784
Value Function Loss: 2.80149

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.10144

Collected Steps per Second: 11,789.78487
Overall Steps per Second: 9,936.11490

Timestep Collection Time: 4.24367
Timestep Consumption Time: 0.79169
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 5.03537

Cumulative Model Updates: 55,698
Cumulative Timesteps: 929,052,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,192.21267
Policy Entropy: 1.06372
Value Function Loss: 3.05101

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.10697

Collected Steps per Second: 11,436.29355
Overall Steps per Second: 9,741.72013

Timestep Collection Time: 4.37275
Timestep Consumption Time: 0.76064
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 5.13339

Cumulative Model Updates: 55,701
Cumulative Timesteps: 929,102,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 929102134...
Checkpoint 929102134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,840.20772
Policy Entropy: 1.06425
Value Function Loss: 3.16675

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.16252
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.10778

Collected Steps per Second: 11,966.30380
Overall Steps per Second: 10,136.06859

Timestep Collection Time: 4.17940
Timestep Consumption Time: 0.75466
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.93406

Cumulative Model Updates: 55,704
Cumulative Timesteps: 929,152,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,815.29743
Policy Entropy: 1.07722
Value Function Loss: 3.07863

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.11535

Collected Steps per Second: 11,691.94158
Overall Steps per Second: 9,801.81611

Timestep Collection Time: 4.27765
Timestep Consumption Time: 0.82488
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 5.10252

Cumulative Model Updates: 55,707
Cumulative Timesteps: 929,202,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 929202160...
Checkpoint 929202160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,669.23882
Policy Entropy: 1.07911
Value Function Loss: 3.01140

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 11,341.25012
Overall Steps per Second: 9,826.49275

Timestep Collection Time: 4.40957
Timestep Consumption Time: 0.67974
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 5.08930

Cumulative Model Updates: 55,710
Cumulative Timesteps: 929,252,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,335.00508
Policy Entropy: 1.06111
Value Function Loss: 2.91991

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 11,718.38220
Overall Steps per Second: 9,926.25834

Timestep Collection Time: 4.26731
Timestep Consumption Time: 0.77044
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.03775

Cumulative Model Updates: 55,713
Cumulative Timesteps: 929,302,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 929302176...
Checkpoint 929302176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,178.01279
Policy Entropy: 1.04666
Value Function Loss: 2.90237

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.19274
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 11,746.24026
Overall Steps per Second: 10,037.08787

Timestep Collection Time: 4.25924
Timestep Consumption Time: 0.72528
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.98451

Cumulative Model Updates: 55,716
Cumulative Timesteps: 929,352,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,049.39421
Policy Entropy: 1.06646
Value Function Loss: 2.86393

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.11637

Collected Steps per Second: 11,920.91410
Overall Steps per Second: 10,209.12661

Timestep Collection Time: 4.19448
Timestep Consumption Time: 0.70330
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.89777

Cumulative Model Updates: 55,719
Cumulative Timesteps: 929,402,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 929402208...
Checkpoint 929402208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,005.93287
Policy Entropy: 1.06210
Value Function Loss: 2.96909

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 11,801.64915
Overall Steps per Second: 9,930.34504

Timestep Collection Time: 4.23839
Timestep Consumption Time: 0.79870
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.03709

Cumulative Model Updates: 55,722
Cumulative Timesteps: 929,452,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,315.19850
Policy Entropy: 1.05259
Value Function Loss: 2.91733

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.16486
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 11,776.42734
Overall Steps per Second: 10,079.13260

Timestep Collection Time: 4.24611
Timestep Consumption Time: 0.71503
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.96114

Cumulative Model Updates: 55,725
Cumulative Timesteps: 929,502,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 929502232...
Checkpoint 929502232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572,611.19040
Policy Entropy: 1.06931
Value Function Loss: 2.86637

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.09209

Collected Steps per Second: 11,533.21488
Overall Steps per Second: 9,803.61186

Timestep Collection Time: 4.33756
Timestep Consumption Time: 0.76525
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.10281

Cumulative Model Updates: 55,728
Cumulative Timesteps: 929,552,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,986.13244
Policy Entropy: 1.07433
Value Function Loss: 2.69323

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.16127
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 11,907.54051
Overall Steps per Second: 10,147.10049

Timestep Collection Time: 4.20003
Timestep Consumption Time: 0.72867
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.92870

Cumulative Model Updates: 55,731
Cumulative Timesteps: 929,602,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 929602270...
Checkpoint 929602270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,971.29213
Policy Entropy: 1.05573
Value Function Loss: 2.71147

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 12,237.73520
Overall Steps per Second: 10,481.44624

Timestep Collection Time: 4.08621
Timestep Consumption Time: 0.68469
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 4.77091

Cumulative Model Updates: 55,734
Cumulative Timesteps: 929,652,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,900.94853
Policy Entropy: 1.04918
Value Function Loss: 2.75442

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.17186
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.09866

Collected Steps per Second: 12,011.41743
Overall Steps per Second: 10,092.78065

Timestep Collection Time: 4.16371
Timestep Consumption Time: 0.79152
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 4.95523

Cumulative Model Updates: 55,737
Cumulative Timesteps: 929,702,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 929702288...
Checkpoint 929702288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,764.70706
Policy Entropy: 1.06037
Value Function Loss: 2.74223

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 12,246.45168
Overall Steps per Second: 10,337.75456

Timestep Collection Time: 4.08314
Timestep Consumption Time: 0.75389
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.83703

Cumulative Model Updates: 55,740
Cumulative Timesteps: 929,752,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,090.88740
Policy Entropy: 1.07833
Value Function Loss: 2.76414

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.17847
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.09729

Collected Steps per Second: 12,278.25130
Overall Steps per Second: 10,319.95917

Timestep Collection Time: 4.07436
Timestep Consumption Time: 0.77314
PPO Batch Consumption Time: 0.03381
Total Iteration Time: 4.84750

Cumulative Model Updates: 55,743
Cumulative Timesteps: 929,802,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 929802318...
Checkpoint 929802318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,347.81940
Policy Entropy: 1.04205
Value Function Loss: 2.87898

Mean KL Divergence: 0.04767
SB3 Clip Fraction: 0.22210
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 11,649.08437
Overall Steps per Second: 9,849.20646

Timestep Collection Time: 4.29270
Timestep Consumption Time: 0.78446
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.07716

Cumulative Model Updates: 55,746
Cumulative Timesteps: 929,852,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,445.71195
Policy Entropy: 1.07777
Value Function Loss: 3.08014

Mean KL Divergence: 0.03070
SB3 Clip Fraction: 0.20284
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 12,523.95770
Overall Steps per Second: 10,557.76415

Timestep Collection Time: 3.99235
Timestep Consumption Time: 0.74350
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.73585

Cumulative Model Updates: 55,749
Cumulative Timesteps: 929,902,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 929902324...
Checkpoint 929902324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,740.27953
Policy Entropy: 1.03772
Value Function Loss: 2.95873

Mean KL Divergence: 0.05193
SB3 Clip Fraction: 0.24252
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 11,729.20216
Overall Steps per Second: 9,952.15808

Timestep Collection Time: 4.26355
Timestep Consumption Time: 0.76129
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 5.02484

Cumulative Model Updates: 55,752
Cumulative Timesteps: 929,952,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,471.97010
Policy Entropy: 1.06013
Value Function Loss: 2.92931

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.16381
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.09741

Collected Steps per Second: 11,994.51371
Overall Steps per Second: 10,278.16814

Timestep Collection Time: 4.16857
Timestep Consumption Time: 0.69611
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.86468

Cumulative Model Updates: 55,755
Cumulative Timesteps: 930,002,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 930002332...
Checkpoint 930002332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,607.42108
Policy Entropy: 1.05291
Value Function Loss: 2.76195

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.08900

Collected Steps per Second: 11,818.40629
Overall Steps per Second: 9,951.47635

Timestep Collection Time: 4.23086
Timestep Consumption Time: 0.79372
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.02458

Cumulative Model Updates: 55,758
Cumulative Timesteps: 930,052,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784,055.13747
Policy Entropy: 1.04445
Value Function Loss: 2.93418

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.07002
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 11,859.84073
Overall Steps per Second: 10,091.43555

Timestep Collection Time: 4.21675
Timestep Consumption Time: 0.73894
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.95569

Cumulative Model Updates: 55,761
Cumulative Timesteps: 930,102,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 930102344...
Checkpoint 930102344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,879.87598
Policy Entropy: 1.05436
Value Function Loss: 2.83199

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.16016
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 11,277.14502
Overall Steps per Second: 9,764.20400

Timestep Collection Time: 4.43481
Timestep Consumption Time: 0.68716
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 5.12197

Cumulative Model Updates: 55,764
Cumulative Timesteps: 930,152,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,133.93077
Policy Entropy: 1.04690
Value Function Loss: 2.82715

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.10473

Collected Steps per Second: 11,634.38828
Overall Steps per Second: 9,856.20626

Timestep Collection Time: 4.29967
Timestep Consumption Time: 0.77571
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.07538

Cumulative Model Updates: 55,767
Cumulative Timesteps: 930,202,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 930202380...
Checkpoint 930202380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778,587.70681
Policy Entropy: 1.05363
Value Function Loss: 2.73712

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 11,656.89311
Overall Steps per Second: 9,968.33381

Timestep Collection Time: 4.28982
Timestep Consumption Time: 0.72666
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.01649

Cumulative Model Updates: 55,770
Cumulative Timesteps: 930,252,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,432.69329
Policy Entropy: 1.04225
Value Function Loss: 2.83075

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 11,881.53520
Overall Steps per Second: 10,000.78804

Timestep Collection Time: 4.20939
Timestep Consumption Time: 0.79162
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.00101

Cumulative Model Updates: 55,773
Cumulative Timesteps: 930,302,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 930302400...
Checkpoint 930302400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,536.46520
Policy Entropy: 1.05156
Value Function Loss: 2.88833

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 11,879.22149
Overall Steps per Second: 10,058.24741

Timestep Collection Time: 4.21004
Timestep Consumption Time: 0.76220
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.97224

Cumulative Model Updates: 55,776
Cumulative Timesteps: 930,352,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,648.44907
Policy Entropy: 1.05235
Value Function Loss: 2.92456

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 11,784.19594
Overall Steps per Second: 10,182.86411

Timestep Collection Time: 4.24331
Timestep Consumption Time: 0.66729
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 4.91060

Cumulative Model Updates: 55,779
Cumulative Timesteps: 930,402,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 930402416...
Checkpoint 930402416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,621.29178
Policy Entropy: 1.05833
Value Function Loss: 2.96128

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 11,327.14023
Overall Steps per Second: 9,698.53767

Timestep Collection Time: 4.41435
Timestep Consumption Time: 0.74127
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.15562

Cumulative Model Updates: 55,782
Cumulative Timesteps: 930,452,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,480.72671
Policy Entropy: 1.05613
Value Function Loss: 3.06309

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.07540
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 12,003.06389
Overall Steps per Second: 10,175.16307

Timestep Collection Time: 4.16777
Timestep Consumption Time: 0.74871
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 4.91648

Cumulative Model Updates: 55,785
Cumulative Timesteps: 930,502,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 930502444...
Checkpoint 930502444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,536.32500
Policy Entropy: 1.06930
Value Function Loss: 3.13583

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 11,986.52849
Overall Steps per Second: 10,087.59364

Timestep Collection Time: 4.17218
Timestep Consumption Time: 0.78539
PPO Batch Consumption Time: 0.03354
Total Iteration Time: 4.95757

Cumulative Model Updates: 55,788
Cumulative Timesteps: 930,552,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,139.51403
Policy Entropy: 1.06893
Value Function Loss: 3.05983

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.11440

Collected Steps per Second: 11,890.96419
Overall Steps per Second: 10,111.68979

Timestep Collection Time: 4.20756
Timestep Consumption Time: 0.74037
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 4.94794

Cumulative Model Updates: 55,791
Cumulative Timesteps: 930,602,486

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 930602486...
Checkpoint 930602486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753,942.51634
Policy Entropy: 1.07188
Value Function Loss: 2.96191

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.07488
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 11,864.36717
Overall Steps per Second: 10,107.75126

Timestep Collection Time: 4.21481
Timestep Consumption Time: 0.73249
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.94729

Cumulative Model Updates: 55,794
Cumulative Timesteps: 930,652,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,348.07440
Policy Entropy: 1.06780
Value Function Loss: 3.00271

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.07116
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 11,745.48056
Overall Steps per Second: 9,968.59573

Timestep Collection Time: 4.25866
Timestep Consumption Time: 0.75910
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 5.01776

Cumulative Model Updates: 55,797
Cumulative Timesteps: 930,702,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 930702512...
Checkpoint 930702512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,369.06264
Policy Entropy: 1.06417
Value Function Loss: 2.92481

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 11,327.19549
Overall Steps per Second: 9,690.66168

Timestep Collection Time: 4.41416
Timestep Consumption Time: 0.74545
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 5.15961

Cumulative Model Updates: 55,800
Cumulative Timesteps: 930,752,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,232.69171
Policy Entropy: 1.07516
Value Function Loss: 3.02209

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 12,078.83023
Overall Steps per Second: 10,179.45719

Timestep Collection Time: 4.14179
Timestep Consumption Time: 0.77281
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.91460

Cumulative Model Updates: 55,803
Cumulative Timesteps: 930,802,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 930802540...
Checkpoint 930802540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,306.90951
Policy Entropy: 1.08134
Value Function Loss: 3.09224

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09805

Collected Steps per Second: 12,605.04445
Overall Steps per Second: 10,630.87797

Timestep Collection Time: 3.96667
Timestep Consumption Time: 0.73661
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.70328

Cumulative Model Updates: 55,806
Cumulative Timesteps: 930,852,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763,813.26658
Policy Entropy: 1.07369
Value Function Loss: 3.10369

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.10736

Collected Steps per Second: 12,274.99192
Overall Steps per Second: 10,518.36771

Timestep Collection Time: 4.07414
Timestep Consumption Time: 0.68040
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.75454

Cumulative Model Updates: 55,809
Cumulative Timesteps: 930,902,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 930902550...
Checkpoint 930902550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,186.66764
Policy Entropy: 1.06083
Value Function Loss: 2.99770

Mean KL Divergence: 0.04325
SB3 Clip Fraction: 0.18898
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 12,429.81579
Overall Steps per Second: 10,367.42086

Timestep Collection Time: 4.02452
Timestep Consumption Time: 0.80060
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.82512

Cumulative Model Updates: 55,812
Cumulative Timesteps: 930,952,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,765.74875
Policy Entropy: 1.07707
Value Function Loss: 2.87871

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 12,639.70121
Overall Steps per Second: 10,590.09409

Timestep Collection Time: 3.95674
Timestep Consumption Time: 0.76579
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.72253

Cumulative Model Updates: 55,815
Cumulative Timesteps: 931,002,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 931002586...
Checkpoint 931002586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,396.49516
Policy Entropy: 1.07382
Value Function Loss: 2.96725

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.06603
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 11,853.78475
Overall Steps per Second: 10,214.88126

Timestep Collection Time: 4.22042
Timestep Consumption Time: 0.67714
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.89756

Cumulative Model Updates: 55,818
Cumulative Timesteps: 931,052,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,541.69945
Policy Entropy: 1.07416
Value Function Loss: 3.06283

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.06659
Value Function Update Magnitude: 0.10610

Collected Steps per Second: 12,848.16572
Overall Steps per Second: 10,677.72768

Timestep Collection Time: 3.89332
Timestep Consumption Time: 0.79139
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.68470

Cumulative Model Updates: 55,821
Cumulative Timesteps: 931,102,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 931102636...
Checkpoint 931102636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,335.52916
Policy Entropy: 1.07619
Value Function Loss: 2.98489

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.10924

Collected Steps per Second: 11,712.30077
Overall Steps per Second: 10,098.65038

Timestep Collection Time: 4.27141
Timestep Consumption Time: 0.68252
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 4.95393

Cumulative Model Updates: 55,824
Cumulative Timesteps: 931,152,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788,251.43659
Policy Entropy: 1.08526
Value Function Loss: 2.90402

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 11,856.95278
Overall Steps per Second: 10,011.79043

Timestep Collection Time: 4.21896
Timestep Consumption Time: 0.77755
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.99651

Cumulative Model Updates: 55,827
Cumulative Timesteps: 931,202,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 931202688...
Checkpoint 931202688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,308.53116
Policy Entropy: 1.06539
Value Function Loss: 2.71365

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.10511

Collected Steps per Second: 11,855.42105
Overall Steps per Second: 10,102.29595

Timestep Collection Time: 4.21782
Timestep Consumption Time: 0.73195
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.94977

Cumulative Model Updates: 55,830
Cumulative Timesteps: 931,252,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558,208.57068
Policy Entropy: 1.06410
Value Function Loss: 2.87085

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.16501
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 11,871.36769
Overall Steps per Second: 10,207.99025

Timestep Collection Time: 4.21316
Timestep Consumption Time: 0.68653
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.89969

Cumulative Model Updates: 55,833
Cumulative Timesteps: 931,302,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 931302708...
Checkpoint 931302708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,212.87826
Policy Entropy: 1.08417
Value Function Loss: 2.94879

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.09745

Collected Steps per Second: 11,425.63627
Overall Steps per Second: 9,682.93957

Timestep Collection Time: 4.37805
Timestep Consumption Time: 0.78794
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 5.16599

Cumulative Model Updates: 55,836
Cumulative Timesteps: 931,352,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,425.02735
Policy Entropy: 1.08751
Value Function Loss: 2.98697

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.11349

Collected Steps per Second: 11,926.92096
Overall Steps per Second: 10,040.93884

Timestep Collection Time: 4.19371
Timestep Consumption Time: 0.78770
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.98141

Cumulative Model Updates: 55,839
Cumulative Timesteps: 931,402,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931402748...
Checkpoint 931402748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564,031.81394
Policy Entropy: 1.05659
Value Function Loss: 2.92479

Mean KL Divergence: 0.03935
SB3 Clip Fraction: 0.20245
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 12,053.48413
Overall Steps per Second: 10,244.76050

Timestep Collection Time: 4.15067
Timestep Consumption Time: 0.73280
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.88347

Cumulative Model Updates: 55,842
Cumulative Timesteps: 931,452,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744,848.03559
Policy Entropy: 1.07286
Value Function Loss: 2.91494

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 11,790.58688
Overall Steps per Second: 10,064.02287

Timestep Collection Time: 4.24186
Timestep Consumption Time: 0.72772
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.96958

Cumulative Model Updates: 55,845
Cumulative Timesteps: 931,502,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 931502792...
Checkpoint 931502792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,288.20119
Policy Entropy: 1.07322
Value Function Loss: 2.94440

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.10621

Collected Steps per Second: 11,642.03413
Overall Steps per Second: 10,007.42451

Timestep Collection Time: 4.29513
Timestep Consumption Time: 0.70156
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.99669

Cumulative Model Updates: 55,848
Cumulative Timesteps: 931,552,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,302.63911
Policy Entropy: 1.07277
Value Function Loss: 2.84083

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.09874

Collected Steps per Second: 11,148.85085
Overall Steps per Second: 9,486.71287

Timestep Collection Time: 4.48566
Timestep Consumption Time: 0.78592
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.27158

Cumulative Model Updates: 55,851
Cumulative Timesteps: 931,602,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 931602806...
Checkpoint 931602806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,994.39868
Policy Entropy: 1.06817
Value Function Loss: 2.80561

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.07699
Value Function Update Magnitude: 0.09599

Collected Steps per Second: 11,282.69632
Overall Steps per Second: 9,647.34410

Timestep Collection Time: 4.43210
Timestep Consumption Time: 0.75130
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.18340

Cumulative Model Updates: 55,854
Cumulative Timesteps: 931,652,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,793.75591
Policy Entropy: 1.07285
Value Function Loss: 2.84546

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 12,120.86028
Overall Steps per Second: 10,188.18904

Timestep Collection Time: 4.12726
Timestep Consumption Time: 0.78293
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.91020

Cumulative Model Updates: 55,857
Cumulative Timesteps: 931,702,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 931702838...
Checkpoint 931702838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,773.56798
Policy Entropy: 1.08678
Value Function Loss: 2.99525

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 11,659.42403
Overall Steps per Second: 9,884.84218

Timestep Collection Time: 4.28838
Timestep Consumption Time: 0.76987
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 5.05825

Cumulative Model Updates: 55,860
Cumulative Timesteps: 931,752,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,685.28732
Policy Entropy: 1.08784
Value Function Loss: 3.00826

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.11747

Collected Steps per Second: 12,122.75053
Overall Steps per Second: 10,431.16294

Timestep Collection Time: 4.12547
Timestep Consumption Time: 0.66901
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.79448

Cumulative Model Updates: 55,863
Cumulative Timesteps: 931,802,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 931802850...
Checkpoint 931802850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,185.41870
Policy Entropy: 1.07984
Value Function Loss: 2.89732

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 11,864.94943
Overall Steps per Second: 10,021.59702

Timestep Collection Time: 4.21443
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.98962

Cumulative Model Updates: 55,866
Cumulative Timesteps: 931,852,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,200.37864
Policy Entropy: 1.06178
Value Function Loss: 2.77467

Mean KL Divergence: 0.03932
SB3 Clip Fraction: 0.19950
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 11,880.09101
Overall Steps per Second: 10,148.66465

Timestep Collection Time: 4.21125
Timestep Consumption Time: 0.71847
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.92971

Cumulative Model Updates: 55,869
Cumulative Timesteps: 931,902,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931902884...
Checkpoint 931902884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,761.60327
Policy Entropy: 1.08449
Value Function Loss: 2.72992

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.12667

Collected Steps per Second: 11,302.03960
Overall Steps per Second: 9,755.63758

Timestep Collection Time: 4.42681
Timestep Consumption Time: 0.70171
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.12852

Cumulative Model Updates: 55,872
Cumulative Timesteps: 931,952,916

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,300.62241
Policy Entropy: 1.07546
Value Function Loss: 2.73796

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.12150

Collected Steps per Second: 12,054.54987
Overall Steps per Second: 10,120.79811

Timestep Collection Time: 4.14980
Timestep Consumption Time: 0.79289
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 4.94269

Cumulative Model Updates: 55,875
Cumulative Timesteps: 932,002,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 932002940...
Checkpoint 932002940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,436.43261
Policy Entropy: 1.06334
Value Function Loss: 2.79720

Mean KL Divergence: 0.02950
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.12119

Collected Steps per Second: 12,040.66811
Overall Steps per Second: 10,374.27447

Timestep Collection Time: 4.15309
Timestep Consumption Time: 0.66710
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.82019

Cumulative Model Updates: 55,878
Cumulative Timesteps: 932,052,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,681.38664
Policy Entropy: 1.08562
Value Function Loss: 2.78158

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 11,780.22481
Overall Steps per Second: 10,005.70056

Timestep Collection Time: 4.24491
Timestep Consumption Time: 0.75284
PPO Batch Consumption Time: 0.03438
Total Iteration Time: 4.99775

Cumulative Model Updates: 55,881
Cumulative Timesteps: 932,102,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 932102952...
Checkpoint 932102952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,873.53856
Policy Entropy: 1.09205
Value Function Loss: 2.82375

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11374

Collected Steps per Second: 12,104.21546
Overall Steps per Second: 10,272.71089

Timestep Collection Time: 4.13079
Timestep Consumption Time: 0.73647
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.86726

Cumulative Model Updates: 55,884
Cumulative Timesteps: 932,152,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,935.16936
Policy Entropy: 1.06620
Value Function Loss: 2.74414

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.10168

Collected Steps per Second: 11,994.86639
Overall Steps per Second: 10,262.95082

Timestep Collection Time: 4.16962
Timestep Consumption Time: 0.70364
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.87326

Cumulative Model Updates: 55,887
Cumulative Timesteps: 932,202,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 932202966...
Checkpoint 932202966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,570.86081
Policy Entropy: 1.05277
Value Function Loss: 2.70983

Mean KL Divergence: 0.03227
SB3 Clip Fraction: 0.17041
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 11,572.23037
Overall Steps per Second: 9,877.64605

Timestep Collection Time: 4.32276
Timestep Consumption Time: 0.74160
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.06436

Cumulative Model Updates: 55,890
Cumulative Timesteps: 932,252,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,792.18349
Policy Entropy: 1.06276
Value Function Loss: 2.80835

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 12,343.18952
Overall Steps per Second: 10,413.46718

Timestep Collection Time: 4.05309
Timestep Consumption Time: 0.75108
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.80416

Cumulative Model Updates: 55,893
Cumulative Timesteps: 932,303,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 932303018...
Checkpoint 932303018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,173.97023
Policy Entropy: 1.06446
Value Function Loss: 2.85797

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 12,015.18800
Overall Steps per Second: 10,144.89017

Timestep Collection Time: 4.16223
Timestep Consumption Time: 0.76734
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.92958

Cumulative Model Updates: 55,896
Cumulative Timesteps: 932,353,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,918.77679
Policy Entropy: 1.06767
Value Function Loss: 2.96834

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.09512

Collected Steps per Second: 12,024.13904
Overall Steps per Second: 10,109.57816

Timestep Collection Time: 4.16046
Timestep Consumption Time: 0.78791
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 4.94838

Cumulative Model Updates: 55,899
Cumulative Timesteps: 932,403,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932403054...
Checkpoint 932403054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,350.30678
Policy Entropy: 1.06916
Value Function Loss: 2.86579

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.09137

Collected Steps per Second: 11,954.06461
Overall Steps per Second: 10,329.75026

Timestep Collection Time: 4.18402
Timestep Consumption Time: 0.65792
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.84194

Cumulative Model Updates: 55,902
Cumulative Timesteps: 932,453,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,722.86521
Policy Entropy: 1.07297
Value Function Loss: 2.80047

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.06880
Value Function Update Magnitude: 0.08059

Collected Steps per Second: 12,111.72557
Overall Steps per Second: 10,182.14470

Timestep Collection Time: 4.13038
Timestep Consumption Time: 0.78273
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.91311

Cumulative Model Updates: 55,905
Cumulative Timesteps: 932,503,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932503096...
Checkpoint 932503096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,286.66619
Policy Entropy: 1.06620
Value Function Loss: 2.79886

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.08886

Collected Steps per Second: 11,296.69177
Overall Steps per Second: 9,620.87144

Timestep Collection Time: 4.42625
Timestep Consumption Time: 0.77099
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.19724

Cumulative Model Updates: 55,908
Cumulative Timesteps: 932,553,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,561.36136
Policy Entropy: 1.07521
Value Function Loss: 2.98095

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 12,145.93489
Overall Steps per Second: 10,208.49515

Timestep Collection Time: 4.11825
Timestep Consumption Time: 0.78159
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 4.89984

Cumulative Model Updates: 55,911
Cumulative Timesteps: 932,603,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 932603118...
Checkpoint 932603118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,852.32299
Policy Entropy: 1.06769
Value Function Loss: 3.05534

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.09750

Collected Steps per Second: 12,005.23540
Overall Steps per Second: 10,143.57138

Timestep Collection Time: 4.16518
Timestep Consumption Time: 0.76444
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.92962

Cumulative Model Updates: 55,914
Cumulative Timesteps: 932,653,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,818.40695
Policy Entropy: 1.07307
Value Function Loss: 3.09391

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 11,789.55878
Overall Steps per Second: 10,194.05152

Timestep Collection Time: 4.24342
Timestep Consumption Time: 0.66415
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 4.90757

Cumulative Model Updates: 55,917
Cumulative Timesteps: 932,703,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 932703150...
Checkpoint 932703150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,772.05381
Policy Entropy: 1.06606
Value Function Loss: 3.00469

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.12217

Collected Steps per Second: 11,731.25516
Overall Steps per Second: 9,971.67513

Timestep Collection Time: 4.26246
Timestep Consumption Time: 0.75214
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.01460

Cumulative Model Updates: 55,920
Cumulative Timesteps: 932,753,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,032.69184
Policy Entropy: 1.07479
Value Function Loss: 3.01305

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 11,947.79696
Overall Steps per Second: 10,159.12433

Timestep Collection Time: 4.18554
Timestep Consumption Time: 0.73693
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.92247

Cumulative Model Updates: 55,923
Cumulative Timesteps: 932,803,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932803162...
Checkpoint 932803162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,655.31238
Policy Entropy: 1.08068
Value Function Loss: 3.12012

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.10456

Collected Steps per Second: 11,529.44800
Overall Steps per Second: 9,765.54738

Timestep Collection Time: 4.33707
Timestep Consumption Time: 0.78338
PPO Batch Consumption Time: 0.03909
Total Iteration Time: 5.12045

Cumulative Model Updates: 55,926
Cumulative Timesteps: 932,853,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,879.17234
Policy Entropy: 1.07899
Value Function Loss: 3.18287

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 12,109.99092
Overall Steps per Second: 10,208.32391

Timestep Collection Time: 4.13146
Timestep Consumption Time: 0.76963
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 4.90110

Cumulative Model Updates: 55,929
Cumulative Timesteps: 932,903,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 932903198...
Checkpoint 932903198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,323.24345
Policy Entropy: 1.07603
Value Function Loss: 3.15251

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 11,639.58089
Overall Steps per Second: 10,025.90061

Timestep Collection Time: 4.29620
Timestep Consumption Time: 0.69148
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.98768

Cumulative Model Updates: 55,932
Cumulative Timesteps: 932,953,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,794.06751
Policy Entropy: 1.07798
Value Function Loss: 2.99434

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 12,201.44886
Overall Steps per Second: 10,172.32485

Timestep Collection Time: 4.09902
Timestep Consumption Time: 0.81765
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.91667

Cumulative Model Updates: 55,935
Cumulative Timesteps: 933,003,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 933003218...
Checkpoint 933003218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,415.11206
Policy Entropy: 1.07293
Value Function Loss: 2.76570

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.07513
Value Function Update Magnitude: 0.07733

Collected Steps per Second: 11,734.60222
Overall Steps per Second: 9,942.95949

Timestep Collection Time: 4.26210
Timestep Consumption Time: 0.76800
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.03009

Cumulative Model Updates: 55,938
Cumulative Timesteps: 933,053,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,481.19253
Policy Entropy: 1.06903
Value Function Loss: 2.73351

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.06974
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 12,060.81602
Overall Steps per Second: 10,098.54024

Timestep Collection Time: 4.14582
Timestep Consumption Time: 0.80559
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.95141

Cumulative Model Updates: 55,941
Cumulative Timesteps: 933,103,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 933103234...
Checkpoint 933103234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,565.47270
Policy Entropy: 1.06727
Value Function Loss: 2.78936

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.08580

Collected Steps per Second: 11,380.99513
Overall Steps per Second: 9,694.28945

Timestep Collection Time: 4.39364
Timestep Consumption Time: 0.76445
PPO Batch Consumption Time: 0.03837
Total Iteration Time: 5.15809

Cumulative Model Updates: 55,944
Cumulative Timesteps: 933,153,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,251.95652
Policy Entropy: 1.07917
Value Function Loss: 2.98733

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.08134

Collected Steps per Second: 12,049.44483
Overall Steps per Second: 10,282.54214

Timestep Collection Time: 4.15123
Timestep Consumption Time: 0.71333
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 4.86456

Cumulative Model Updates: 55,947
Cumulative Timesteps: 933,203,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 933203258...
Checkpoint 933203258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,266.44914
Policy Entropy: 1.08936
Value Function Loss: 3.07271

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.08445

Collected Steps per Second: 12,489.35887
Overall Steps per Second: 10,518.83639

Timestep Collection Time: 4.00533
Timestep Consumption Time: 0.75033
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.75566

Cumulative Model Updates: 55,950
Cumulative Timesteps: 933,253,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747,407.85515
Policy Entropy: 1.06367
Value Function Loss: 3.14767

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.08262

Collected Steps per Second: 12,758.57973
Overall Steps per Second: 10,717.78999

Timestep Collection Time: 3.92003
Timestep Consumption Time: 0.74642
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 4.66645

Cumulative Model Updates: 55,953
Cumulative Timesteps: 933,303,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 933303296...
Checkpoint 933303296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,123.27813
Policy Entropy: 1.05682
Value Function Loss: 3.07342

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 12,448.68267
Overall Steps per Second: 10,677.78593

Timestep Collection Time: 4.01665
Timestep Consumption Time: 0.66616
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 4.68281

Cumulative Model Updates: 55,956
Cumulative Timesteps: 933,353,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,017.36665
Policy Entropy: 1.06354
Value Function Loss: 3.01654

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.07559

Collected Steps per Second: 12,731.38752
Overall Steps per Second: 10,570.95407

Timestep Collection Time: 3.92950
Timestep Consumption Time: 0.80309
PPO Batch Consumption Time: 0.03342
Total Iteration Time: 4.73259

Cumulative Model Updates: 55,959
Cumulative Timesteps: 933,403,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 933403326...
Checkpoint 933403326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,115.54818
Policy Entropy: 1.07308
Value Function Loss: 2.76510

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 11,860.87189
Overall Steps per Second: 10,029.67000

Timestep Collection Time: 4.21790
Timestep Consumption Time: 0.77010
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.98800

Cumulative Model Updates: 55,962
Cumulative Timesteps: 933,453,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,175.70011
Policy Entropy: 1.05027
Value Function Loss: 2.74017

Mean KL Divergence: 0.03222
SB3 Clip Fraction: 0.18611
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.08056

Collected Steps per Second: 12,966.81345
Overall Steps per Second: 10,785.53520

Timestep Collection Time: 3.85800
Timestep Consumption Time: 0.78025
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.63825

Cumulative Model Updates: 55,965
Cumulative Timesteps: 933,503,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 933503380...
Checkpoint 933503380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,539.09654
Policy Entropy: 1.07746
Value Function Loss: 2.72546

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 12,222.07968
Overall Steps per Second: 10,242.93714

Timestep Collection Time: 4.09308
Timestep Consumption Time: 0.79087
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.88395

Cumulative Model Updates: 55,968
Cumulative Timesteps: 933,553,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596,824.85760
Policy Entropy: 1.06997
Value Function Loss: 2.79335

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 11,729.03398
Overall Steps per Second: 10,097.50481

Timestep Collection Time: 4.26327
Timestep Consumption Time: 0.68885
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.95211

Cumulative Model Updates: 55,971
Cumulative Timesteps: 933,603,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 933603410...
Checkpoint 933603410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,898.09401
Policy Entropy: 1.06008
Value Function Loss: 2.66844

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 11,880.64175
Overall Steps per Second: 10,055.62433

Timestep Collection Time: 4.21072
Timestep Consumption Time: 0.76421
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 4.97493

Cumulative Model Updates: 55,974
Cumulative Timesteps: 933,653,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,160.11805
Policy Entropy: 1.04893
Value Function Loss: 2.58898

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 11,979.10817
Overall Steps per Second: 10,190.86666

Timestep Collection Time: 4.17560
Timestep Consumption Time: 0.73271
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.90832

Cumulative Model Updates: 55,977
Cumulative Timesteps: 933,703,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 933703456...
Checkpoint 933703456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,314.90135
Policy Entropy: 1.06325
Value Function Loss: 2.73855

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 11,973.56364
Overall Steps per Second: 10,032.95508

Timestep Collection Time: 4.17670
Timestep Consumption Time: 0.80787
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.98457

Cumulative Model Updates: 55,980
Cumulative Timesteps: 933,753,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,987.20698
Policy Entropy: 1.07365
Value Function Loss: 2.77449

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11,793.37841
Overall Steps per Second: 9,947.47961

Timestep Collection Time: 4.24136
Timestep Consumption Time: 0.78705
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.02841

Cumulative Model Updates: 55,983
Cumulative Timesteps: 933,803,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 933803486...
Checkpoint 933803486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,951.58595
Policy Entropy: 1.04270
Value Function Loss: 2.82319

Mean KL Divergence: 0.03374
SB3 Clip Fraction: 0.19086
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 11,730.33489
Overall Steps per Second: 10,132.15510

Timestep Collection Time: 4.26262
Timestep Consumption Time: 0.67236
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.93498

Cumulative Model Updates: 55,986
Cumulative Timesteps: 933,853,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,496.78048
Policy Entropy: 1.06735
Value Function Loss: 2.83424

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.07791

Collected Steps per Second: 11,966.35156
Overall Steps per Second: 10,110.32844

Timestep Collection Time: 4.18072
Timestep Consumption Time: 0.76748
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.94821

Cumulative Model Updates: 55,989
Cumulative Timesteps: 933,903,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 933903516...
Checkpoint 933903516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,368.71512
Policy Entropy: 1.06453
Value Function Loss: 2.88955

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.15752
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.10787

Collected Steps per Second: 11,659.23847
Overall Steps per Second: 10,076.59019

Timestep Collection Time: 4.28913
Timestep Consumption Time: 0.67366
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.96279

Cumulative Model Updates: 55,992
Cumulative Timesteps: 933,953,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,796.39761
Policy Entropy: 1.06225
Value Function Loss: 2.94464

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.06561
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 11,826.17640
Overall Steps per Second: 10,009.70040

Timestep Collection Time: 4.22791
Timestep Consumption Time: 0.76725
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.99515

Cumulative Model Updates: 55,995
Cumulative Timesteps: 934,003,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 934003524...
Checkpoint 934003524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,053.78167
Policy Entropy: 1.04694
Value Function Loss: 2.78118

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.17177
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.10241

Collected Steps per Second: 11,514.89286
Overall Steps per Second: 9,773.91737

Timestep Collection Time: 4.34220
Timestep Consumption Time: 0.77345
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.11566

Cumulative Model Updates: 55,998
Cumulative Timesteps: 934,053,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,045.29078
Policy Entropy: 1.06788
Value Function Loss: 2.75230

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.16458
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.09500

Collected Steps per Second: 11,738.40714
Overall Steps per Second: 10,141.97015

Timestep Collection Time: 4.26225
Timestep Consumption Time: 0.67092
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.93316

Cumulative Model Updates: 56,001
Cumulative Timesteps: 934,103,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 934103556...
Checkpoint 934103556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769,954.60979
Policy Entropy: 1.06871
Value Function Loss: 2.62761

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.16438
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11,767.93860
Overall Steps per Second: 9,952.49634

Timestep Collection Time: 4.24883
Timestep Consumption Time: 0.77503
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.02387

Cumulative Model Updates: 56,004
Cumulative Timesteps: 934,153,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,924.00852
Policy Entropy: 1.06019
Value Function Loss: 2.67506

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08796

Collected Steps per Second: 11,832.91868
Overall Steps per Second: 10,058.81830

Timestep Collection Time: 4.22651
Timestep Consumption Time: 0.74544
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.97196

Cumulative Model Updates: 56,007
Cumulative Timesteps: 934,203,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 934203568...
Checkpoint 934203568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,267.78638
Policy Entropy: 1.04398
Value Function Loss: 2.76010

Mean KL Divergence: 0.03590
SB3 Clip Fraction: 0.19729
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.09271

Collected Steps per Second: 12,221.68547
Overall Steps per Second: 10,242.89312

Timestep Collection Time: 4.09125
Timestep Consumption Time: 0.79038
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 4.88163

Cumulative Model Updates: 56,010
Cumulative Timesteps: 934,253,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,543.77344
Policy Entropy: 1.06650
Value Function Loss: 2.76207

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.09495

Collected Steps per Second: 11,900.13726
Overall Steps per Second: 10,060.56718

Timestep Collection Time: 4.20264
Timestep Consumption Time: 0.76845
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.97109

Cumulative Model Updates: 56,013
Cumulative Timesteps: 934,303,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 934303582...
Checkpoint 934303582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,320.11994
Policy Entropy: 1.04493
Value Function Loss: 2.92528

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.16321
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.09013

Collected Steps per Second: 11,791.21796
Overall Steps per Second: 10,038.50328

Timestep Collection Time: 4.24095
Timestep Consumption Time: 0.74047
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.98142

Cumulative Model Updates: 56,016
Cumulative Timesteps: 934,353,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722,959.24430
Policy Entropy: 1.04604
Value Function Loss: 2.92293

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 11,822.84275
Overall Steps per Second: 9,969.06608

Timestep Collection Time: 4.23113
Timestep Consumption Time: 0.78679
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.01792

Cumulative Model Updates: 56,019
Cumulative Timesteps: 934,403,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934403612...
Checkpoint 934403612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,705.95166
Policy Entropy: 1.05487
Value Function Loss: 3.15204

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 12,077.47845
Overall Steps per Second: 10,200.04727

Timestep Collection Time: 4.14043
Timestep Consumption Time: 0.76209
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.90253

Cumulative Model Updates: 56,022
Cumulative Timesteps: 934,453,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,731.88919
Policy Entropy: 1.05926
Value Function Loss: 3.06669

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 12,412.46063
Overall Steps per Second: 10,379.61151

Timestep Collection Time: 4.03014
Timestep Consumption Time: 0.78930
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.81945

Cumulative Model Updates: 56,025
Cumulative Timesteps: 934,503,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934503642...
Checkpoint 934503642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,258.03602
Policy Entropy: 1.03775
Value Function Loss: 2.84575

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.16433
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.08479

Collected Steps per Second: 11,830.36187
Overall Steps per Second: 10,026.67914

Timestep Collection Time: 4.22760
Timestep Consumption Time: 0.76050
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.98809

Cumulative Model Updates: 56,028
Cumulative Timesteps: 934,553,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,178.96983
Policy Entropy: 1.05891
Value Function Loss: 2.71941

Mean KL Divergence: 0.02785
SB3 Clip Fraction: 0.18409
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 11,706.62587
Overall Steps per Second: 10,086.11912

Timestep Collection Time: 4.27109
Timestep Consumption Time: 0.68622
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 4.95731

Cumulative Model Updates: 56,031
Cumulative Timesteps: 934,603,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 934603656...
Checkpoint 934603656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,095.22923
Policy Entropy: 1.05153
Value Function Loss: 2.60652

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.09041

Collected Steps per Second: 12,078.50930
Overall Steps per Second: 10,004.56357

Timestep Collection Time: 4.14041
Timestep Consumption Time: 0.85831
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.99872

Cumulative Model Updates: 56,034
Cumulative Timesteps: 934,653,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,949.57040
Policy Entropy: 1.04772
Value Function Loss: 2.76523

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.17529
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 12,075.42483
Overall Steps per Second: 10,224.93466

Timestep Collection Time: 4.14213
Timestep Consumption Time: 0.74964
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 4.89177

Cumulative Model Updates: 56,037
Cumulative Timesteps: 934,703,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 934703684...
Checkpoint 934703684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,159.06956
Policy Entropy: 1.04528
Value Function Loss: 2.61718

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.18769
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.11435

Collected Steps per Second: 11,881.50746
Overall Steps per Second: 10,184.74607

Timestep Collection Time: 4.21041
Timestep Consumption Time: 0.70145
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.91186

Cumulative Model Updates: 56,040
Cumulative Timesteps: 934,753,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,177.53618
Policy Entropy: 1.05210
Value Function Loss: 2.74489

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 11,889.26406
Overall Steps per Second: 10,030.27231

Timestep Collection Time: 4.20665
Timestep Consumption Time: 0.77965
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.98631

Cumulative Model Updates: 56,043
Cumulative Timesteps: 934,803,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 934803724...
Checkpoint 934803724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,228.01401
Policy Entropy: 1.06280
Value Function Loss: 2.75941

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.09875

Collected Steps per Second: 11,681.63645
Overall Steps per Second: 10,079.66616

Timestep Collection Time: 4.28159
Timestep Consumption Time: 0.68048
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.96207

Cumulative Model Updates: 56,046
Cumulative Timesteps: 934,853,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752,912.03577
Policy Entropy: 1.03713
Value Function Loss: 2.96289

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 11,974.05610
Overall Steps per Second: 10,120.21124

Timestep Collection Time: 4.17820
Timestep Consumption Time: 0.76537
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.94357

Cumulative Model Updates: 56,049
Cumulative Timesteps: 934,903,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 934903770...
Checkpoint 934903770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,989.77201
Policy Entropy: 1.05765
Value Function Loss: 2.95749

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.08997

Collected Steps per Second: 11,959.94580
Overall Steps per Second: 10,032.83735

Timestep Collection Time: 4.18296
Timestep Consumption Time: 0.80346
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 4.98643

Cumulative Model Updates: 56,052
Cumulative Timesteps: 934,953,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,833.40473
Policy Entropy: 1.04843
Value Function Loss: 3.05214

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 11,621.73955
Overall Steps per Second: 10,006.30141

Timestep Collection Time: 4.30280
Timestep Consumption Time: 0.69465
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 4.99745

Cumulative Model Updates: 56,055
Cumulative Timesteps: 935,003,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 935003804...
Checkpoint 935003804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,696.21685
Policy Entropy: 1.04850
Value Function Loss: 2.94858

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.07002
Value Function Update Magnitude: 0.10179

Collected Steps per Second: 11,919.27114
Overall Steps per Second: 10,108.20029

Timestep Collection Time: 4.19757
Timestep Consumption Time: 0.75207
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.94964

Cumulative Model Updates: 56,058
Cumulative Timesteps: 935,053,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,380.37165
Policy Entropy: 1.04178
Value Function Loss: 2.94443

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.12587

Collected Steps per Second: 11,853.88753
Overall Steps per Second: 10,069.22294

Timestep Collection Time: 4.21954
Timestep Consumption Time: 0.74787
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.96741

Cumulative Model Updates: 56,061
Cumulative Timesteps: 935,103,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935103854...
Checkpoint 935103854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,032.94437
Policy Entropy: 1.04676
Value Function Loss: 2.82124

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 12,015.75411
Overall Steps per Second: 10,121.36655

Timestep Collection Time: 4.16237
Timestep Consumption Time: 0.77906
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.94143

Cumulative Model Updates: 56,064
Cumulative Timesteps: 935,153,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,918.88867
Policy Entropy: 1.04384
Value Function Loss: 2.91683

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.06872
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 11,864.09035
Overall Steps per Second: 10,010.69547

Timestep Collection Time: 4.21659
Timestep Consumption Time: 0.78067
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 4.99726

Cumulative Model Updates: 56,067
Cumulative Timesteps: 935,203,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 935203894...
Checkpoint 935203894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,498.41566
Policy Entropy: 1.03319
Value Function Loss: 2.98900

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.09892

Collected Steps per Second: 11,773.47824
Overall Steps per Second: 10,079.29045

Timestep Collection Time: 4.24904
Timestep Consumption Time: 0.71420
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.96325

Cumulative Model Updates: 56,070
Cumulative Timesteps: 935,253,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,000.99637
Policy Entropy: 1.04577
Value Function Loss: 3.03380

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09215

Collected Steps per Second: 11,743.87337
Overall Steps per Second: 9,964.86592

Timestep Collection Time: 4.25822
Timestep Consumption Time: 0.76021
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.01843

Cumulative Model Updates: 56,073
Cumulative Timesteps: 935,303,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 935303928...
Checkpoint 935303928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,840.62885
Policy Entropy: 1.05984
Value Function Loss: 2.88901

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.15823
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 11,710.53271
Overall Steps per Second: 9,918.21772

Timestep Collection Time: 4.27205
Timestep Consumption Time: 0.77200
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.04405

Cumulative Model Updates: 56,076
Cumulative Timesteps: 935,353,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,880.14931
Policy Entropy: 1.04276
Value Function Loss: 2.69365

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 11,438.02247
Overall Steps per Second: 9,776.87977

Timestep Collection Time: 4.37261
Timestep Consumption Time: 0.74293
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.11554

Cumulative Model Updates: 56,079
Cumulative Timesteps: 935,403,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 935403970...
Checkpoint 935403970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,293.03186
Policy Entropy: 1.04183
Value Function Loss: 2.71668

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 11,646.88311
Overall Steps per Second: 9,808.51582

Timestep Collection Time: 4.29334
Timestep Consumption Time: 0.80468
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.09802

Cumulative Model Updates: 56,082
Cumulative Timesteps: 935,453,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,399.49279
Policy Entropy: 1.04801
Value Function Loss: 2.76133

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 11,787.95418
Overall Steps per Second: 10,007.53797

Timestep Collection Time: 4.24315
Timestep Consumption Time: 0.75489
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.99803

Cumulative Model Updates: 56,085
Cumulative Timesteps: 935,503,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935503992...
Checkpoint 935503992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,845.01881
Policy Entropy: 1.05914
Value Function Loss: 2.77451

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16728
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.09495

Collected Steps per Second: 12,074.57907
Overall Steps per Second: 9,985.13433

Timestep Collection Time: 4.14093
Timestep Consumption Time: 0.86651
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.00744

Cumulative Model Updates: 56,088
Cumulative Timesteps: 935,553,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,463.28024
Policy Entropy: 1.03096
Value Function Loss: 2.77319

Mean KL Divergence: 0.03584
SB3 Clip Fraction: 0.20444
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.09076

Collected Steps per Second: 11,639.14274
Overall Steps per Second: 9,836.62843

Timestep Collection Time: 4.29774
Timestep Consumption Time: 0.78754
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 5.08528

Cumulative Model Updates: 56,091
Cumulative Timesteps: 935,604,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 935604014...
Checkpoint 935604014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,718.55867
Policy Entropy: 1.05647
Value Function Loss: 2.88916

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 12,040.34218
Overall Steps per Second: 10,381.22193

Timestep Collection Time: 4.15271
Timestep Consumption Time: 0.66368
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.81639

Cumulative Model Updates: 56,094
Cumulative Timesteps: 935,654,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,973.86861
Policy Entropy: 1.05093
Value Function Loss: 2.98488

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 12,467.06445
Overall Steps per Second: 10,449.14462

Timestep Collection Time: 4.01185
Timestep Consumption Time: 0.77476
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.78661

Cumulative Model Updates: 56,097
Cumulative Timesteps: 935,704,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 935704030...
Checkpoint 935704030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,003.85326
Policy Entropy: 1.03781
Value Function Loss: 3.07785

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09186

Collected Steps per Second: 12,533.87199
Overall Steps per Second: 10,594.31193

Timestep Collection Time: 3.99142
Timestep Consumption Time: 0.73073
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.72216

Cumulative Model Updates: 56,100
Cumulative Timesteps: 935,754,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,622.04073
Policy Entropy: 1.03259
Value Function Loss: 3.00123

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 12,587.14994
Overall Steps per Second: 10,488.70964

Timestep Collection Time: 3.97246
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.76722

Cumulative Model Updates: 56,103
Cumulative Timesteps: 935,804,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 935804060...
Checkpoint 935804060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,315.87912
Policy Entropy: 1.02766
Value Function Loss: 2.95002

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.17414
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 12,434.91186
Overall Steps per Second: 10,406.89494

Timestep Collection Time: 4.02126
Timestep Consumption Time: 0.78363
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.80489

Cumulative Model Updates: 56,106
Cumulative Timesteps: 935,854,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,286.24619
Policy Entropy: 1.04615
Value Function Loss: 2.83397

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.16868
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 11,911.23617
Overall Steps per Second: 10,190.08321

Timestep Collection Time: 4.19923
Timestep Consumption Time: 0.70927
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.90850

Cumulative Model Updates: 56,109
Cumulative Timesteps: 935,904,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935904082...
Checkpoint 935904082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,357.40966
Policy Entropy: 1.04714
Value Function Loss: 2.75677

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.17150
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 12,754.80609
Overall Steps per Second: 10,624.38390

Timestep Collection Time: 3.92197
Timestep Consumption Time: 0.78644
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.70841

Cumulative Model Updates: 56,112
Cumulative Timesteps: 935,954,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,805.04703
Policy Entropy: 1.03439
Value Function Loss: 2.70512

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 11,747.71161
Overall Steps per Second: 9,979.93894

Timestep Collection Time: 4.25666
Timestep Consumption Time: 0.75399
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.01065

Cumulative Model Updates: 56,115
Cumulative Timesteps: 936,004,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 936004112...
Checkpoint 936004112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,861.85199
Policy Entropy: 1.03024
Value Function Loss: 2.75605

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.16633
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 12,080.88819
Overall Steps per Second: 10,205.65186

Timestep Collection Time: 4.14092
Timestep Consumption Time: 0.76087
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 4.90179

Cumulative Model Updates: 56,118
Cumulative Timesteps: 936,054,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,671.56650
Policy Entropy: 1.03888
Value Function Loss: 2.84400

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 11,928.86948
Overall Steps per Second: 10,003.04419

Timestep Collection Time: 4.19336
Timestep Consumption Time: 0.80732
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 5.00068

Cumulative Model Updates: 56,121
Cumulative Timesteps: 936,104,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 936104160...
Checkpoint 936104160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,842.28862
Policy Entropy: 1.05272
Value Function Loss: 2.94634

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 11,905.37365
Overall Steps per Second: 10,255.05398

Timestep Collection Time: 4.20146
Timestep Consumption Time: 0.67613
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.87759

Cumulative Model Updates: 56,124
Cumulative Timesteps: 936,154,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,512.07863
Policy Entropy: 1.02824
Value Function Loss: 3.00450

Mean KL Divergence: 0.02814
SB3 Clip Fraction: 0.17677
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.09955

Collected Steps per Second: 11,373.85521
Overall Steps per Second: 9,621.37751

Timestep Collection Time: 4.39640
Timestep Consumption Time: 0.80078
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.19718

Cumulative Model Updates: 56,127
Cumulative Timesteps: 936,204,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 936204184...
Checkpoint 936204184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,516.68802
Policy Entropy: 1.04842
Value Function Loss: 2.99439

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.09774

Collected Steps per Second: 11,681.62196
Overall Steps per Second: 9,945.32201

Timestep Collection Time: 4.28143
Timestep Consumption Time: 0.74747
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.02890

Cumulative Model Updates: 56,130
Cumulative Timesteps: 936,254,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761,751.47513
Policy Entropy: 1.04653
Value Function Loss: 3.03401

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.16455
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 12,167.41994
Overall Steps per Second: 10,258.37598

Timestep Collection Time: 4.11131
Timestep Consumption Time: 0.76510
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 4.87641

Cumulative Model Updates: 56,133
Cumulative Timesteps: 936,304,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 936304222...
Checkpoint 936304222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,650.94598
Policy Entropy: 1.02373
Value Function Loss: 2.84195

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.17214
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.09107

Collected Steps per Second: 11,817.58670
Overall Steps per Second: 9,989.06607

Timestep Collection Time: 4.23234
Timestep Consumption Time: 0.77474
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.00707

Cumulative Model Updates: 56,136
Cumulative Timesteps: 936,354,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799,457.28469
Policy Entropy: 1.02286
Value Function Loss: 2.89084

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.19276
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.08933

Collected Steps per Second: 11,845.94119
Overall Steps per Second: 10,228.69282

Timestep Collection Time: 4.22237
Timestep Consumption Time: 0.66760
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 4.88997

Cumulative Model Updates: 56,139
Cumulative Timesteps: 936,404,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936404256...
Checkpoint 936404256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,233.20863
Policy Entropy: 1.03248
Value Function Loss: 2.74666

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.10686

Collected Steps per Second: 11,780.77880
Overall Steps per Second: 9,952.35502

Timestep Collection Time: 4.24675
Timestep Consumption Time: 0.78020
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.02695

Cumulative Model Updates: 56,142
Cumulative Timesteps: 936,454,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,063.44218
Policy Entropy: 1.03678
Value Function Loss: 2.93386

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.17547
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 11,190.64728
Overall Steps per Second: 9,574.49919

Timestep Collection Time: 4.46891
Timestep Consumption Time: 0.75434
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.22325

Cumulative Model Updates: 56,145
Cumulative Timesteps: 936,504,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 936504296...
Checkpoint 936504296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,395.02337
Policy Entropy: 1.01607
Value Function Loss: 2.80877

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 12,160.46631
Overall Steps per Second: 10,227.58922

Timestep Collection Time: 4.11234
Timestep Consumption Time: 0.77718
PPO Batch Consumption Time: 0.03742
Total Iteration Time: 4.88952

Cumulative Model Updates: 56,148
Cumulative Timesteps: 936,554,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,473.18183
Policy Entropy: 1.01037
Value Function Loss: 2.83844

Mean KL Divergence: 0.03461
SB3 Clip Fraction: 0.17637
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 12,072.31930
Overall Steps per Second: 10,165.04374

Timestep Collection Time: 4.14237
Timestep Consumption Time: 0.77724
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.91960

Cumulative Model Updates: 56,151
Cumulative Timesteps: 936,604,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 936604312...
Checkpoint 936604312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774,496.63671
Policy Entropy: 1.03071
Value Function Loss: 2.80361

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11,930.40859
Overall Steps per Second: 10,268.73695

Timestep Collection Time: 4.19097
Timestep Consumption Time: 0.67818
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 4.86915

Cumulative Model Updates: 56,154
Cumulative Timesteps: 936,654,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,747.59063
Policy Entropy: 1.03484
Value Function Loss: 2.94442

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 11,703.86635
Overall Steps per Second: 9,970.32067

Timestep Collection Time: 4.27346
Timestep Consumption Time: 0.74303
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.01649

Cumulative Model Updates: 56,157
Cumulative Timesteps: 936,704,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 936704328...
Checkpoint 936704328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,948.69043
Policy Entropy: 1.03195
Value Function Loss: 2.90171

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.06884
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 11,902.63238
Overall Steps per Second: 10,071.60712

Timestep Collection Time: 4.20226
Timestep Consumption Time: 0.76397
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.96624

Cumulative Model Updates: 56,160
Cumulative Timesteps: 936,754,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,632.61738
Policy Entropy: 1.02888
Value Function Loss: 2.80321

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 11,648.55160
Overall Steps per Second: 9,816.54868

Timestep Collection Time: 4.29410
Timestep Consumption Time: 0.80138
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.09548

Cumulative Model Updates: 56,163
Cumulative Timesteps: 936,804,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 936804366...
Checkpoint 936804366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,108.23930
Policy Entropy: 1.03961
Value Function Loss: 2.69786

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.09568

Collected Steps per Second: 11,985.95505
Overall Steps per Second: 10,066.40343

Timestep Collection Time: 4.17155
Timestep Consumption Time: 0.79547
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.96702

Cumulative Model Updates: 56,166
Cumulative Timesteps: 936,854,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,543.34289
Policy Entropy: 1.04935
Value Function Loss: 2.77115

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 12,086.07547
Overall Steps per Second: 10,398.16814

Timestep Collection Time: 4.13865
Timestep Consumption Time: 0.67182
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.81046

Cumulative Model Updates: 56,169
Cumulative Timesteps: 936,904,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 936904386...
Checkpoint 936904386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,787.57620
Policy Entropy: 1.03311
Value Function Loss: 2.82158

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 11,932.52621
Overall Steps per Second: 10,112.98693

Timestep Collection Time: 4.19123
Timestep Consumption Time: 0.75409
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.94532

Cumulative Model Updates: 56,172
Cumulative Timesteps: 936,954,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,147.77929
Policy Entropy: 1.02047
Value Function Loss: 2.84184

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.18145
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.07403

Collected Steps per Second: 12,122.60704
Overall Steps per Second: 10,332.19475

Timestep Collection Time: 4.12667
Timestep Consumption Time: 0.71509
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.84176

Cumulative Model Updates: 56,175
Cumulative Timesteps: 937,004,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 937004424...
Checkpoint 937004424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,637.24033
Policy Entropy: 1.03439
Value Function Loss: 2.88446

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 11,835.70603
Overall Steps per Second: 10,231.01340

Timestep Collection Time: 4.22670
Timestep Consumption Time: 0.66294
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.88964

Cumulative Model Updates: 56,178
Cumulative Timesteps: 937,054,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,093.69089
Policy Entropy: 1.03588
Value Function Loss: 2.91542

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.17509
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 11,633.47467
Overall Steps per Second: 9,879.65671

Timestep Collection Time: 4.30035
Timestep Consumption Time: 0.76339
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.06374

Cumulative Model Updates: 56,181
Cumulative Timesteps: 937,104,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937104478...
Checkpoint 937104478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,553.33258
Policy Entropy: 1.01658
Value Function Loss: 2.99008

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.17961
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.08978

Collected Steps per Second: 11,930.55577
Overall Steps per Second: 10,181.59568

Timestep Collection Time: 4.19092
Timestep Consumption Time: 0.71990
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.91082

Cumulative Model Updates: 56,184
Cumulative Timesteps: 937,154,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,355.64271
Policy Entropy: 1.03402
Value Function Loss: 2.92103

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.18556
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 12,130.78185
Overall Steps per Second: 10,144.39096

Timestep Collection Time: 4.12323
Timestep Consumption Time: 0.80738
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.93061

Cumulative Model Updates: 56,187
Cumulative Timesteps: 937,204,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 937204496...
Checkpoint 937204496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,899.13730
Policy Entropy: 1.03174
Value Function Loss: 2.80186

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.18456
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.10371

Collected Steps per Second: 11,921.39139
Overall Steps per Second: 10,080.97255

Timestep Collection Time: 4.19464
Timestep Consumption Time: 0.76579
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 4.96043

Cumulative Model Updates: 56,190
Cumulative Timesteps: 937,254,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799,159.81052
Policy Entropy: 1.01989
Value Function Loss: 2.72259

Mean KL Divergence: 0.02865
SB3 Clip Fraction: 0.16946
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.09478

Collected Steps per Second: 11,967.26761
Overall Steps per Second: 10,297.44677

Timestep Collection Time: 4.17907
Timestep Consumption Time: 0.67767
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.85674

Cumulative Model Updates: 56,193
Cumulative Timesteps: 937,304,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 937304514...
Checkpoint 937304514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,047.96216
Policy Entropy: 1.02100
Value Function Loss: 2.78258

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.15910
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 11,816.27013
Overall Steps per Second: 10,016.25399

Timestep Collection Time: 4.23348
Timestep Consumption Time: 0.76080
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.99428

Cumulative Model Updates: 56,196
Cumulative Timesteps: 937,354,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,613.79079
Policy Entropy: 1.02806
Value Function Loss: 2.80943

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.09995

Collected Steps per Second: 11,286.83451
Overall Steps per Second: 9,630.53427

Timestep Collection Time: 4.43224
Timestep Consumption Time: 0.76228
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.19452

Cumulative Model Updates: 56,199
Cumulative Timesteps: 937,404,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 937404564...
Checkpoint 937404564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,978.74586
Policy Entropy: 1.03900
Value Function Loss: 2.87279

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.16990
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.09827

Collected Steps per Second: 11,806.27704
Overall Steps per Second: 9,850.69776

Timestep Collection Time: 4.23520
Timestep Consumption Time: 0.84078
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.07599

Cumulative Model Updates: 56,202
Cumulative Timesteps: 937,454,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634,635.79068
Policy Entropy: 1.01604
Value Function Loss: 2.91241

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.09695

Collected Steps per Second: 11,641.60607
Overall Steps per Second: 9,870.91615

Timestep Collection Time: 4.29769
Timestep Consumption Time: 0.77094
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.06863

Cumulative Model Updates: 56,205
Cumulative Timesteps: 937,504,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 937504598...
Checkpoint 937504598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,053.51964
Policy Entropy: 1.03427
Value Function Loss: 2.87156

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.16987
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.09487

Collected Steps per Second: 11,744.20957
Overall Steps per Second: 10,161.72546

Timestep Collection Time: 4.25827
Timestep Consumption Time: 0.66314
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.92141

Cumulative Model Updates: 56,208
Cumulative Timesteps: 937,554,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,690.09257
Policy Entropy: 1.03564
Value Function Loss: 2.93326

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 11,716.25244
Overall Steps per Second: 9,943.94707

Timestep Collection Time: 4.26792
Timestep Consumption Time: 0.76067
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.02859

Cumulative Model Updates: 56,211
Cumulative Timesteps: 937,604,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 937604612...
Checkpoint 937604612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,007.65473
Policy Entropy: 1.02440
Value Function Loss: 2.79636

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.15738
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 11,493.63374
Overall Steps per Second: 9,850.58023

Timestep Collection Time: 4.35163
Timestep Consumption Time: 0.72584
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.07747

Cumulative Model Updates: 56,214
Cumulative Timesteps: 937,654,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,389.41856
Policy Entropy: 1.01750
Value Function Loss: 2.83643

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.18239
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 11,497.82181
Overall Steps per Second: 9,910.56835

Timestep Collection Time: 4.35108
Timestep Consumption Time: 0.69686
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.04794

Cumulative Model Updates: 56,217
Cumulative Timesteps: 937,704,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937704656...
Checkpoint 937704656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,959.11850
Policy Entropy: 1.03004
Value Function Loss: 2.72921

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.06228
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 11,824.00993
Overall Steps per Second: 10,035.90289

Timestep Collection Time: 4.22953
Timestep Consumption Time: 0.75358
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.98311

Cumulative Model Updates: 56,220
Cumulative Timesteps: 937,754,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,104.88859
Policy Entropy: 1.03905
Value Function Loss: 2.74699

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.12268

Collected Steps per Second: 11,620.49806
Overall Steps per Second: 9,870.88123

Timestep Collection Time: 4.30515
Timestep Consumption Time: 0.76309
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.06824

Cumulative Model Updates: 56,223
Cumulative Timesteps: 937,804,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937804694...
Checkpoint 937804694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,897.18630
Policy Entropy: 1.03990
Value Function Loss: 2.85642

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.07616
Value Function Update Magnitude: 0.10551

Collected Steps per Second: 12,120.73314
Overall Steps per Second: 10,188.68642

Timestep Collection Time: 4.12747
Timestep Consumption Time: 0.78268
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.91015

Cumulative Model Updates: 56,226
Cumulative Timesteps: 937,854,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,886.87844
Policy Entropy: 1.03541
Value Function Loss: 2.90096

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.08416
Value Function Update Magnitude: 0.09648

Collected Steps per Second: 11,906.54888
Overall Steps per Second: 10,024.68702

Timestep Collection Time: 4.19971
Timestep Consumption Time: 0.78838
PPO Batch Consumption Time: 0.03374
Total Iteration Time: 4.98809

Cumulative Model Updates: 56,229
Cumulative Timesteps: 937,904,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 937904726...
Checkpoint 937904726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,749.81894
Policy Entropy: 1.01904
Value Function Loss: 2.87057

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.18583
Policy Update Magnitude: 0.07210
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 11,822.32511
Overall Steps per Second: 10,188.07554

Timestep Collection Time: 4.22929
Timestep Consumption Time: 0.67841
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.90770

Cumulative Model Updates: 56,232
Cumulative Timesteps: 937,954,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572,012.91322
Policy Entropy: 1.03481
Value Function Loss: 2.85273

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.08496

Collected Steps per Second: 11,399.55275
Overall Steps per Second: 9,633.46271

Timestep Collection Time: 4.38772
Timestep Consumption Time: 0.80439
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.19211

Cumulative Model Updates: 56,235
Cumulative Timesteps: 938,004,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 938004744...
Checkpoint 938004744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,061.12759
Policy Entropy: 1.04025
Value Function Loss: 2.95914

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.09190

Collected Steps per Second: 11,877.28528
Overall Steps per Second: 10,121.92289

Timestep Collection Time: 4.21089
Timestep Consumption Time: 0.73026
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.94116

Cumulative Model Updates: 56,238
Cumulative Timesteps: 938,054,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764,836.27222
Policy Entropy: 1.02899
Value Function Loss: 3.05495

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.10047

Collected Steps per Second: 12,696.80124
Overall Steps per Second: 10,569.37605

Timestep Collection Time: 3.93847
Timestep Consumption Time: 0.79274
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.73122

Cumulative Model Updates: 56,241
Cumulative Timesteps: 938,104,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 938104764...
Checkpoint 938104764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,805.17488
Policy Entropy: 1.02341
Value Function Loss: 2.93131

Mean KL Divergence: 0.03353
SB3 Clip Fraction: 0.18591
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.09025

Collected Steps per Second: 12,466.29018
Overall Steps per Second: 10,329.16998

Timestep Collection Time: 4.01322
Timestep Consumption Time: 0.83034
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 4.84356

Cumulative Model Updates: 56,244
Cumulative Timesteps: 938,154,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,606.23651
Policy Entropy: 1.03723
Value Function Loss: 2.98934

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.08761

Collected Steps per Second: 12,722.90885
Overall Steps per Second: 10,764.92613

Timestep Collection Time: 3.93008
Timestep Consumption Time: 0.71482
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.64490

Cumulative Model Updates: 56,247
Cumulative Timesteps: 938,204,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938204796...
Checkpoint 938204796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,839.44268
Policy Entropy: 1.05197
Value Function Loss: 3.03285

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.09567

Collected Steps per Second: 12,335.94070
Overall Steps per Second: 10,357.40481

Timestep Collection Time: 4.05449
Timestep Consumption Time: 0.77451
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 4.82901

Cumulative Model Updates: 56,250
Cumulative Timesteps: 938,254,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,075.57049
Policy Entropy: 1.01947
Value Function Loss: 3.13572

Mean KL Divergence: 0.03763
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.11028

Collected Steps per Second: 11,925.56107
Overall Steps per Second: 10,158.45042

Timestep Collection Time: 4.19385
Timestep Consumption Time: 0.72954
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.92339

Cumulative Model Updates: 56,253
Cumulative Timesteps: 938,304,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 938304826...
Checkpoint 938304826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,262.98691
Policy Entropy: 1.04352
Value Function Loss: 2.97957

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.11661

Collected Steps per Second: 12,400.05622
Overall Steps per Second: 10,607.23313

Timestep Collection Time: 4.03353
Timestep Consumption Time: 0.68174
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 4.71527

Cumulative Model Updates: 56,256
Cumulative Timesteps: 938,354,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801,470.09235
Policy Entropy: 1.04308
Value Function Loss: 2.81881

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 12,067.05461
Overall Steps per Second: 10,158.55902

Timestep Collection Time: 4.14517
Timestep Consumption Time: 0.77876
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.92393

Cumulative Model Updates: 56,259
Cumulative Timesteps: 938,404,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938404862...
Checkpoint 938404862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,002.87532
Policy Entropy: 1.03124
Value Function Loss: 2.76205

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 11,895.09367
Overall Steps per Second: 10,084.92822

Timestep Collection Time: 4.20560
Timestep Consumption Time: 0.75487
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.96047

Cumulative Model Updates: 56,262
Cumulative Timesteps: 938,454,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,957.15935
Policy Entropy: 1.01221
Value Function Loss: 2.79366

Mean KL Divergence: 0.03206
SB3 Clip Fraction: 0.17871
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.09969

Collected Steps per Second: 11,940.13060
Overall Steps per Second: 10,090.39226

Timestep Collection Time: 4.18856
Timestep Consumption Time: 0.76783
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.95640

Cumulative Model Updates: 56,265
Cumulative Timesteps: 938,504,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 938504900...
Checkpoint 938504900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,151.92531
Policy Entropy: 1.03832
Value Function Loss: 2.82092

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.09387

Collected Steps per Second: 12,016.10664
Overall Steps per Second: 10,211.31632

Timestep Collection Time: 4.16308
Timestep Consumption Time: 0.73580
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.89888

Cumulative Model Updates: 56,268
Cumulative Timesteps: 938,554,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,867.85866
Policy Entropy: 1.03953
Value Function Loss: 2.88686

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.09993

Collected Steps per Second: 11,155.59682
Overall Steps per Second: 9,681.77262

Timestep Collection Time: 4.48241
Timestep Consumption Time: 0.68234
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.16476

Cumulative Model Updates: 56,271
Cumulative Timesteps: 938,604,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 938604928...
Checkpoint 938604928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,615.46902
Policy Entropy: 1.03715
Value Function Loss: 2.80070

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 11,694.87920
Overall Steps per Second: 9,947.32790

Timestep Collection Time: 4.27538
Timestep Consumption Time: 0.75110
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.02648

Cumulative Model Updates: 56,274
Cumulative Timesteps: 938,654,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755,777.20219
Policy Entropy: 1.02474
Value Function Loss: 2.79846

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 11,914.48754
Overall Steps per Second: 10,121.39850

Timestep Collection Time: 4.19791
Timestep Consumption Time: 0.74370
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.94161

Cumulative Model Updates: 56,277
Cumulative Timesteps: 938,704,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 938704944...
Checkpoint 938704944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,214.89940
Policy Entropy: 1.03188
Value Function Loss: 2.65262

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.10639

Collected Steps per Second: 11,709.12622
Overall Steps per Second: 10,147.78550

Timestep Collection Time: 4.27120
Timestep Consumption Time: 0.65717
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.92837

Cumulative Model Updates: 56,280
Cumulative Timesteps: 938,754,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730,064.69394
Policy Entropy: 1.03626
Value Function Loss: 2.65289

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.17561
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 11,913.19237
Overall Steps per Second: 10,043.75009

Timestep Collection Time: 4.19736
Timestep Consumption Time: 0.78125
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.97862

Cumulative Model Updates: 56,283
Cumulative Timesteps: 938,804,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 938804960...
Checkpoint 938804960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,825.96065
Policy Entropy: 1.01445
Value Function Loss: 2.48659

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 11,288.74762
Overall Steps per Second: 9,661.69338

Timestep Collection Time: 4.43185
Timestep Consumption Time: 0.74633
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.17818

Cumulative Model Updates: 56,286
Cumulative Timesteps: 938,854,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,485.67302
Policy Entropy: 1.01140
Value Function Loss: 2.60177

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.18247
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.10784

Collected Steps per Second: 11,456.77576
Overall Steps per Second: 9,735.70026

Timestep Collection Time: 4.36598
Timestep Consumption Time: 0.77182
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.13779

Cumulative Model Updates: 56,289
Cumulative Timesteps: 938,905,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938905010...
Checkpoint 938905010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,270.77127
Policy Entropy: 1.02825
Value Function Loss: 2.69731

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.10284

Collected Steps per Second: 11,831.53552
Overall Steps per Second: 10,030.05969

Timestep Collection Time: 4.22616
Timestep Consumption Time: 0.75905
PPO Batch Consumption Time: 0.03529
Total Iteration Time: 4.98521

Cumulative Model Updates: 56,292
Cumulative Timesteps: 938,955,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,562.68499
Policy Entropy: 1.05027
Value Function Loss: 2.78980

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.17112
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 11,845.58923
Overall Steps per Second: 10,219.30306

Timestep Collection Time: 4.22182
Timestep Consumption Time: 0.67186
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.89368

Cumulative Model Updates: 56,295
Cumulative Timesteps: 939,005,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 939005022...
Checkpoint 939005022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,081.92360
Policy Entropy: 1.01960
Value Function Loss: 2.70705

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 11,846.06922
Overall Steps per Second: 10,012.56566

Timestep Collection Time: 4.22199
Timestep Consumption Time: 0.77313
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.99512

Cumulative Model Updates: 56,298
Cumulative Timesteps: 939,055,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,993.74939
Policy Entropy: 1.03951
Value Function Loss: 2.67321

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.18927
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.09092

Collected Steps per Second: 11,784.31624
Overall Steps per Second: 10,038.10861

Timestep Collection Time: 4.24446
Timestep Consumption Time: 0.73836
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.98281

Cumulative Model Updates: 56,301
Cumulative Timesteps: 939,105,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939105054...
Checkpoint 939105054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,931.28002
Policy Entropy: 1.02651
Value Function Loss: 2.69147

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.16341
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.08401

Collected Steps per Second: 11,832.06910
Overall Steps per Second: 10,161.32799

Timestep Collection Time: 4.22800
Timestep Consumption Time: 0.69517
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.92318

Cumulative Model Updates: 56,304
Cumulative Timesteps: 939,155,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,967.36135
Policy Entropy: 1.01941
Value Function Loss: 2.94002

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 11,318.74874
Overall Steps per Second: 9,599.85621

Timestep Collection Time: 4.41869
Timestep Consumption Time: 0.79118
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.20987

Cumulative Model Updates: 56,307
Cumulative Timesteps: 939,205,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 939205094...
Checkpoint 939205094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,170.18085
Policy Entropy: 1.00914
Value Function Loss: 2.95318

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.19865
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 11,656.27321
Overall Steps per Second: 9,897.09005

Timestep Collection Time: 4.29039
Timestep Consumption Time: 0.76261
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.05300

Cumulative Model Updates: 56,310
Cumulative Timesteps: 939,255,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,420.94304
Policy Entropy: 1.02286
Value Function Loss: 3.00798

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 12,121.99787
Overall Steps per Second: 10,256.07253

Timestep Collection Time: 4.12655
Timestep Consumption Time: 0.75076
PPO Batch Consumption Time: 0.03408
Total Iteration Time: 4.87731

Cumulative Model Updates: 56,313
Cumulative Timesteps: 939,305,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 939305126...
Checkpoint 939305126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,455.01315
Policy Entropy: 1.03456
Value Function Loss: 2.88749

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.15256
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 12,001.76636
Overall Steps per Second: 10,128.40326

Timestep Collection Time: 4.16789
Timestep Consumption Time: 0.77090
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.93878

Cumulative Model Updates: 56,316
Cumulative Timesteps: 939,355,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,989.44732
Policy Entropy: 1.01189
Value Function Loss: 2.86501

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 11,832.73428
Overall Steps per Second: 10,162.56612

Timestep Collection Time: 4.22759
Timestep Consumption Time: 0.69478
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.92238

Cumulative Model Updates: 56,319
Cumulative Timesteps: 939,405,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 939405172...
Checkpoint 939405172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,623.32199
Policy Entropy: 1.00071
Value Function Loss: 2.89233

Mean KL Divergence: 0.03238
SB3 Clip Fraction: 0.21115
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 11,747.15126
Overall Steps per Second: 9,975.84456

Timestep Collection Time: 4.25703
Timestep Consumption Time: 0.75588
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.01291

Cumulative Model Updates: 56,322
Cumulative Timesteps: 939,455,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,694.30113
Policy Entropy: 1.02552
Value Function Loss: 2.70587

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.12929

Collected Steps per Second: 11,522.18897
Overall Steps per Second: 9,839.57983

Timestep Collection Time: 4.34119
Timestep Consumption Time: 0.74236
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.08355

Cumulative Model Updates: 56,325
Cumulative Timesteps: 939,505,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 939505200...
Checkpoint 939505200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753,895.23081
Policy Entropy: 1.03650
Value Function Loss: 2.63133

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 11,977.08098
Overall Steps per Second: 10,123.09150

Timestep Collection Time: 4.17681
Timestep Consumption Time: 0.76496
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.94177

Cumulative Model Updates: 56,328
Cumulative Timesteps: 939,555,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,228.21553
Policy Entropy: 1.02151
Value Function Loss: 2.68807

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.10698

Collected Steps per Second: 11,760.73056
Overall Steps per Second: 9,978.00382

Timestep Collection Time: 4.25212
Timestep Consumption Time: 0.75971
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.01182

Cumulative Model Updates: 56,331
Cumulative Timesteps: 939,605,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 939605234...
Checkpoint 939605234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,948.72879
Policy Entropy: 1.01138
Value Function Loss: 2.84274

Mean KL Divergence: 0.02696
SB3 Clip Fraction: 0.18546
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 11,762.93232
Overall Steps per Second: 10,070.56503

Timestep Collection Time: 4.25200
Timestep Consumption Time: 0.71455
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.96655

Cumulative Model Updates: 56,334
Cumulative Timesteps: 939,655,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,918.51069
Policy Entropy: 1.02212
Value Function Loss: 3.01756

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 12,076.31087
Overall Steps per Second: 10,211.74066

Timestep Collection Time: 4.14067
Timestep Consumption Time: 0.75605
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.89672

Cumulative Model Updates: 56,337
Cumulative Timesteps: 939,705,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 939705254...
Checkpoint 939705254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763,192.22898
Policy Entropy: 1.02522
Value Function Loss: 2.99762

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 11,987.36769
Overall Steps per Second: 10,151.27321

Timestep Collection Time: 4.17339
Timestep Consumption Time: 0.75486
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 4.92825

Cumulative Model Updates: 56,340
Cumulative Timesteps: 939,755,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861,967.02846
Policy Entropy: 1.01042
Value Function Loss: 3.06163

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 11,517.83012
Overall Steps per Second: 9,801.79505

Timestep Collection Time: 4.34127
Timestep Consumption Time: 0.76004
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.10131

Cumulative Model Updates: 56,343
Cumulative Timesteps: 939,805,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 939805284...
Checkpoint 939805284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,801.18526
Policy Entropy: 0.99371
Value Function Loss: 3.02045

Mean KL Divergence: 0.03000
SB3 Clip Fraction: 0.19352
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 11,965.50477
Overall Steps per Second: 10,083.38880

Timestep Collection Time: 4.17901
Timestep Consumption Time: 0.78003
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.95905

Cumulative Model Updates: 56,346
Cumulative Timesteps: 939,855,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,194.14874
Policy Entropy: 1.01001
Value Function Loss: 2.90635

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 11,854.02176
Overall Steps per Second: 10,205.61927

Timestep Collection Time: 4.21933
Timestep Consumption Time: 0.68150
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 4.90083

Cumulative Model Updates: 56,349
Cumulative Timesteps: 939,905,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 939905304...
Checkpoint 939905304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765,992.94013
Policy Entropy: 1.01846
Value Function Loss: 2.81412

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.17116
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.10217

Collected Steps per Second: 11,785.18780
Overall Steps per Second: 9,986.85519

Timestep Collection Time: 4.24380
Timestep Consumption Time: 0.76418
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.00798

Cumulative Model Updates: 56,352
Cumulative Timesteps: 939,955,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790,913.76106
Policy Entropy: 0.99642
Value Function Loss: 2.79068

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 11,871.77674
Overall Steps per Second: 10,062.05916

Timestep Collection Time: 4.21217
Timestep Consumption Time: 0.75758
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 4.96976

Cumulative Model Updates: 56,355
Cumulative Timesteps: 940,005,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940005324...
Checkpoint 940005324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732,917.64003
Policy Entropy: 1.02433
Value Function Loss: 2.80766

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.17389
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11,741.05147
Overall Steps per Second: 9,989.09482

Timestep Collection Time: 4.25907
Timestep Consumption Time: 0.74699
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.00606

Cumulative Model Updates: 56,358
Cumulative Timesteps: 940,055,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,615.89668
Policy Entropy: 1.02634
Value Function Loss: 2.77150

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11,398.00490
Overall Steps per Second: 9,713.30067

Timestep Collection Time: 4.38691
Timestep Consumption Time: 0.76088
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.14779

Cumulative Model Updates: 56,361
Cumulative Timesteps: 940,105,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940105332...
Checkpoint 940105332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,123.02230
Policy Entropy: 1.01582
Value Function Loss: 2.71038

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.15537
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.09749

Collected Steps per Second: 11,746.96535
Overall Steps per Second: 10,146.75281

Timestep Collection Time: 4.25778
Timestep Consumption Time: 0.67148
PPO Batch Consumption Time: 0.03701
Total Iteration Time: 4.92926

Cumulative Model Updates: 56,364
Cumulative Timesteps: 940,155,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,328.39790
Policy Entropy: 0.99396
Value Function Loss: 2.75644

Mean KL Divergence: 0.03483
SB3 Clip Fraction: 0.20319
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 11,837.16912
Overall Steps per Second: 9,950.12779

Timestep Collection Time: 4.22483
Timestep Consumption Time: 0.80124
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.02607

Cumulative Model Updates: 56,367
Cumulative Timesteps: 940,205,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 940205358...
Checkpoint 940205358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,594.63828
Policy Entropy: 1.01213
Value Function Loss: 2.75677

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.11120

Collected Steps per Second: 11,728.91924
Overall Steps per Second: 9,983.64677

Timestep Collection Time: 4.26416
Timestep Consumption Time: 0.74543
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.00959

Cumulative Model Updates: 56,370
Cumulative Timesteps: 940,255,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,729.89337
Policy Entropy: 1.00398
Value Function Loss: 2.81095

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.10568

Collected Steps per Second: 11,728.57706
Overall Steps per Second: 10,130.09688

Timestep Collection Time: 4.26497
Timestep Consumption Time: 0.67299
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 4.93796

Cumulative Model Updates: 56,373
Cumulative Timesteps: 940,305,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940305394...
Checkpoint 940305394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,631.06703
Policy Entropy: 1.01004
Value Function Loss: 2.82420

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 11,966.88170
Overall Steps per Second: 10,071.59494

Timestep Collection Time: 4.17820
Timestep Consumption Time: 0.78626
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.96446

Cumulative Model Updates: 56,376
Cumulative Timesteps: 940,355,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,877.06285
Policy Entropy: 1.01422
Value Function Loss: 2.96948

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 11,437.13730
Overall Steps per Second: 9,910.39598

Timestep Collection Time: 4.37417
Timestep Consumption Time: 0.67386
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 5.04803

Cumulative Model Updates: 56,379
Cumulative Timesteps: 940,405,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 940405422...
Checkpoint 940405422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,193.03997
Policy Entropy: 1.01308
Value Function Loss: 2.97802

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.06814
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 11,814.94284
Overall Steps per Second: 9,992.45712

Timestep Collection Time: 4.23464
Timestep Consumption Time: 0.77234
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 5.00698

Cumulative Model Updates: 56,382
Cumulative Timesteps: 940,455,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,198.03943
Policy Entropy: 1.00672
Value Function Loss: 2.92193

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.12896

Collected Steps per Second: 12,405.01127
Overall Steps per Second: 10,392.70930

Timestep Collection Time: 4.03289
Timestep Consumption Time: 0.78087
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 4.81376

Cumulative Model Updates: 56,385
Cumulative Timesteps: 940,505,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 940505482...
Checkpoint 940505482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,083.35403
Policy Entropy: 1.00544
Value Function Loss: 2.83784

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 12,870.70980
Overall Steps per Second: 10,670.42456

Timestep Collection Time: 3.88541
Timestep Consumption Time: 0.80119
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 4.68660

Cumulative Model Updates: 56,388
Cumulative Timesteps: 940,555,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,274.23036
Policy Entropy: 1.01549
Value Function Loss: 2.73706

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 12,504.43739
Overall Steps per Second: 10,467.46354

Timestep Collection Time: 3.99954
Timestep Consumption Time: 0.77831
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.77785

Cumulative Model Updates: 56,391
Cumulative Timesteps: 940,605,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 940605502...
Checkpoint 940605502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,427.93374
Policy Entropy: 1.02568
Value Function Loss: 2.72985

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11,782.70271
Overall Steps per Second: 10,152.89757

Timestep Collection Time: 4.24487
Timestep Consumption Time: 0.68141
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.92628

Cumulative Model Updates: 56,394
Cumulative Timesteps: 940,655,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,415.02057
Policy Entropy: 1.02050
Value Function Loss: 2.71962

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 11,927.05516
Overall Steps per Second: 10,019.76201

Timestep Collection Time: 4.19265
Timestep Consumption Time: 0.79808
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.99074

Cumulative Model Updates: 56,397
Cumulative Timesteps: 940,705,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940705524...
Checkpoint 940705524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745,593.81405
Policy Entropy: 1.00760
Value Function Loss: 2.72450

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 12,221.51980
Overall Steps per Second: 10,319.86039

Timestep Collection Time: 4.09360
Timestep Consumption Time: 0.75433
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.84793

Cumulative Model Updates: 56,400
Cumulative Timesteps: 940,755,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,465.44653
Policy Entropy: 1.00764
Value Function Loss: 2.80275

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.15138
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.08796

Collected Steps per Second: 12,276.02807
Overall Steps per Second: 10,294.00529

Timestep Collection Time: 4.07526
Timestep Consumption Time: 0.78466
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.85992

Cumulative Model Updates: 56,403
Cumulative Timesteps: 940,805,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 940805582...
Checkpoint 940805582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,882.92133
Policy Entropy: 1.01836
Value Function Loss: 2.90196

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.09661

Collected Steps per Second: 11,917.47047
Overall Steps per Second: 9,904.71721

Timestep Collection Time: 4.19552
Timestep Consumption Time: 0.85258
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.04810

Cumulative Model Updates: 56,406
Cumulative Timesteps: 940,855,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,698.75132
Policy Entropy: 1.02554
Value Function Loss: 2.81938

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.09563

Collected Steps per Second: 11,690.24398
Overall Steps per Second: 10,042.56420

Timestep Collection Time: 4.27707
Timestep Consumption Time: 0.70174
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 4.97881

Cumulative Model Updates: 56,409
Cumulative Timesteps: 940,905,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 940905582...
Checkpoint 940905582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,627.54134
Policy Entropy: 1.01725
Value Function Loss: 2.72751

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.09400

Collected Steps per Second: 11,926.35298
Overall Steps per Second: 10,081.60035

Timestep Collection Time: 4.19474
Timestep Consumption Time: 0.76756
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.96231

Cumulative Model Updates: 56,412
Cumulative Timesteps: 940,955,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746,767.01685
Policy Entropy: 1.01176
Value Function Loss: 2.59188

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.08354

Collected Steps per Second: 11,228.86970
Overall Steps per Second: 9,567.05682

Timestep Collection Time: 4.45388
Timestep Consumption Time: 0.77365
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 5.22752

Cumulative Model Updates: 56,415
Cumulative Timesteps: 941,005,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 941005622...
Checkpoint 941005622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,740.82234
Policy Entropy: 1.00814
Value Function Loss: 2.75873

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 11,908.70183
Overall Steps per Second: 10,263.76817

Timestep Collection Time: 4.20029
Timestep Consumption Time: 0.67316
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 4.87345

Cumulative Model Updates: 56,418
Cumulative Timesteps: 941,055,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,510.28025
Policy Entropy: 1.01356
Value Function Loss: 2.71122

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.09453

Collected Steps per Second: 11,842.69823
Overall Steps per Second: 10,009.45678

Timestep Collection Time: 4.22387
Timestep Consumption Time: 0.77361
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 4.99747

Cumulative Model Updates: 56,421
Cumulative Timesteps: 941,105,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 941105664...
Checkpoint 941105664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,076.33234
Policy Entropy: 1.02199
Value Function Loss: 2.72375

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.10773

Collected Steps per Second: 11,860.14065
Overall Steps per Second: 10,108.45508

Timestep Collection Time: 4.21681
Timestep Consumption Time: 0.73073
PPO Batch Consumption Time: 0.03373
Total Iteration Time: 4.94754

Cumulative Model Updates: 56,424
Cumulative Timesteps: 941,155,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,424.48825
Policy Entropy: 1.02773
Value Function Loss: 2.72511

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 11,958.67915
Overall Steps per Second: 10,027.20272

Timestep Collection Time: 4.18240
Timestep Consumption Time: 0.80563
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.98803

Cumulative Model Updates: 56,427
Cumulative Timesteps: 941,205,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941205692...
Checkpoint 941205692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774,810.19069
Policy Entropy: 1.02384
Value Function Loss: 2.77894

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 11,570.98510
Overall Steps per Second: 9,811.36498

Timestep Collection Time: 4.32392
Timestep Consumption Time: 0.77547
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.09939

Cumulative Model Updates: 56,430
Cumulative Timesteps: 941,255,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,753.15764
Policy Entropy: 1.02614
Value Function Loss: 2.82343

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.07368
Value Function Update Magnitude: 0.10445

Collected Steps per Second: 11,456.02793
Overall Steps per Second: 9,931.32627

Timestep Collection Time: 4.36451
Timestep Consumption Time: 0.67006
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.03457

Cumulative Model Updates: 56,433
Cumulative Timesteps: 941,305,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 941305724...
Checkpoint 941305724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,499.12027
Policy Entropy: 1.02769
Value Function Loss: 2.74155

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.15910
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 11,731.11691
Overall Steps per Second: 9,898.50373

Timestep Collection Time: 4.26421
Timestep Consumption Time: 0.78948
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.05369

Cumulative Model Updates: 56,436
Cumulative Timesteps: 941,355,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,074.02226
Policy Entropy: 1.03223
Value Function Loss: 2.75616

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.08612

Collected Steps per Second: 11,771.70963
Overall Steps per Second: 10,008.51530

Timestep Collection Time: 4.24764
Timestep Consumption Time: 0.74830
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 4.99595

Cumulative Model Updates: 56,439
Cumulative Timesteps: 941,405,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 941405750...
Checkpoint 941405750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 777,359.43209
Policy Entropy: 1.03757
Value Function Loss: 2.82359

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.07245

Collected Steps per Second: 11,796.49422
Overall Steps per Second: 10,143.92986

Timestep Collection Time: 4.23973
Timestep Consumption Time: 0.69070
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.93044

Cumulative Model Updates: 56,442
Cumulative Timesteps: 941,455,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,724.86164
Policy Entropy: 1.03996
Value Function Loss: 2.87789

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 11,921.35652
Overall Steps per Second: 10,065.03004

Timestep Collection Time: 4.19499
Timestep Consumption Time: 0.77370
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.96869

Cumulative Model Updates: 56,445
Cumulative Timesteps: 941,505,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 941505774...
Checkpoint 941505774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,833.64060
Policy Entropy: 1.04131
Value Function Loss: 3.04757

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.07659
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 11,849.29778
Overall Steps per Second: 10,060.81038

Timestep Collection Time: 4.22135
Timestep Consumption Time: 0.75042
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.97177

Cumulative Model Updates: 56,448
Cumulative Timesteps: 941,555,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,853.22267
Policy Entropy: 1.03870
Value Function Loss: 3.04354

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.07631
Value Function Update Magnitude: 0.08661

Collected Steps per Second: 11,701.56891
Overall Steps per Second: 9,895.97610

Timestep Collection Time: 4.27396
Timestep Consumption Time: 0.77981
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.05377

Cumulative Model Updates: 56,451
Cumulative Timesteps: 941,605,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 941605806...
Checkpoint 941605806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,498.64785
Policy Entropy: 1.03097
Value Function Loss: 3.00701

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.07205
Value Function Update Magnitude: 0.08417

Collected Steps per Second: 12,071.98450
Overall Steps per Second: 10,192.73053

Timestep Collection Time: 4.14298
Timestep Consumption Time: 0.76385
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.90683

Cumulative Model Updates: 56,454
Cumulative Timesteps: 941,655,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,571.43995
Policy Entropy: 1.03873
Value Function Loss: 2.91081

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.07862

Collected Steps per Second: 11,834.67735
Overall Steps per Second: 10,217.66557

Timestep Collection Time: 4.22673
Timestep Consumption Time: 0.66891
PPO Batch Consumption Time: 0.03348
Total Iteration Time: 4.89564

Cumulative Model Updates: 56,457
Cumulative Timesteps: 941,705,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 941705842...
Checkpoint 941705842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732,120.14179
Policy Entropy: 1.04585
Value Function Loss: 2.79390

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.07727

Collected Steps per Second: 11,941.30351
Overall Steps per Second: 10,131.43763

Timestep Collection Time: 4.18798
Timestep Consumption Time: 0.74814
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.93612

Cumulative Model Updates: 56,460
Cumulative Timesteps: 941,755,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,200.54585
Policy Entropy: 1.04604
Value Function Loss: 2.90279

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.07599
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 12,116.85985
Overall Steps per Second: 10,282.99202

Timestep Collection Time: 4.12714
Timestep Consumption Time: 0.73603
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 4.86318

Cumulative Model Updates: 56,463
Cumulative Timesteps: 941,805,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 941805860...
Checkpoint 941805860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,734.67519
Policy Entropy: 1.04837
Value Function Loss: 2.86651

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.09789

Collected Steps per Second: 12,176.06035
Overall Steps per Second: 10,381.37594

Timestep Collection Time: 4.10658
Timestep Consumption Time: 0.70993
PPO Batch Consumption Time: 0.03379
Total Iteration Time: 4.81651

Cumulative Model Updates: 56,466
Cumulative Timesteps: 941,855,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,961.77312
Policy Entropy: 1.02794
Value Function Loss: 2.89833

Mean KL Divergence: 0.03116
SB3 Clip Fraction: 0.18892
Policy Update Magnitude: 0.06875
Value Function Update Magnitude: 0.09480

Collected Steps per Second: 11,677.55890
Overall Steps per Second: 9,842.91544

Timestep Collection Time: 4.28274
Timestep Consumption Time: 0.79827
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 5.08101

Cumulative Model Updates: 56,469
Cumulative Timesteps: 941,905,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 941905874...
Checkpoint 941905874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,771.79279
Policy Entropy: 1.05004
Value Function Loss: 2.77262

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.08605

Collected Steps per Second: 12,052.66765
Overall Steps per Second: 10,248.39317

Timestep Collection Time: 4.14846
Timestep Consumption Time: 0.73035
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.87881

Cumulative Model Updates: 56,472
Cumulative Timesteps: 941,955,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,936.27846
Policy Entropy: 1.05245
Value Function Loss: 2.78566

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.16248
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.07814

Collected Steps per Second: 12,144.45837
Overall Steps per Second: 10,289.83008

Timestep Collection Time: 4.11974
Timestep Consumption Time: 0.74254
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.86228

Cumulative Model Updates: 56,475
Cumulative Timesteps: 942,005,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 942005906...
Checkpoint 942005906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,853.86401
Policy Entropy: 1.03985
Value Function Loss: 2.85658

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08051

Collected Steps per Second: 11,949.37944
Overall Steps per Second: 10,138.30755

Timestep Collection Time: 4.18683
Timestep Consumption Time: 0.74792
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.93475

Cumulative Model Updates: 56,478
Cumulative Timesteps: 942,055,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,944.03725
Policy Entropy: 1.03241
Value Function Loss: 2.94584

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.18697
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.09133

Collected Steps per Second: 11,871.25838
Overall Steps per Second: 10,199.79715

Timestep Collection Time: 4.21253
Timestep Consumption Time: 0.69032
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.90284

Cumulative Model Updates: 56,481
Cumulative Timesteps: 942,105,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 942105944...
Checkpoint 942105944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,425.47339
Policy Entropy: 1.04462
Value Function Loss: 2.94483

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.09245

Collected Steps per Second: 12,006.88301
Overall Steps per Second: 10,151.88480

Timestep Collection Time: 4.16661
Timestep Consumption Time: 0.76134
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.92795

Cumulative Model Updates: 56,484
Cumulative Timesteps: 942,155,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,903.90837
Policy Entropy: 1.04210
Value Function Loss: 2.93536

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 11,438.76321
Overall Steps per Second: 9,716.65910

Timestep Collection Time: 4.37215
Timestep Consumption Time: 0.77489
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.14704

Cumulative Model Updates: 56,487
Cumulative Timesteps: 942,205,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 942205984...
Checkpoint 942205984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,693.18271
Policy Entropy: 1.03945
Value Function Loss: 2.93723

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 11,882.63203
Overall Steps per Second: 10,176.84088

Timestep Collection Time: 4.20833
Timestep Consumption Time: 0.70538
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.91371

Cumulative Model Updates: 56,490
Cumulative Timesteps: 942,255,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,185.49432
Policy Entropy: 1.04297
Value Function Loss: 2.91110

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 11,633.71362
Overall Steps per Second: 9,860.61689

Timestep Collection Time: 4.30060
Timestep Consumption Time: 0.77332
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.07392

Cumulative Model Updates: 56,493
Cumulative Timesteps: 942,306,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 942306022...
Checkpoint 942306022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804,200.53127
Policy Entropy: 1.04532
Value Function Loss: 2.93354

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.07895
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 11,997.10227
Overall Steps per Second: 10,221.48179

Timestep Collection Time: 4.16851
Timestep Consumption Time: 0.72413
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.89264

Cumulative Model Updates: 56,496
Cumulative Timesteps: 942,356,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,196.64966
Policy Entropy: 1.05812
Value Function Loss: 2.97289

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.16633
Policy Update Magnitude: 0.06855
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 12,173.34259
Overall Steps per Second: 10,268.94508

Timestep Collection Time: 4.10783
Timestep Consumption Time: 0.76181
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 4.86963

Cumulative Model Updates: 56,499
Cumulative Timesteps: 942,406,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 942406038...
Checkpoint 942406038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,033.81722
Policy Entropy: 1.06708
Value Function Loss: 2.99120

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.07143
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 11,771.33288
Overall Steps per Second: 10,047.49473

Timestep Collection Time: 4.24982
Timestep Consumption Time: 0.72914
PPO Batch Consumption Time: 0.03708
Total Iteration Time: 4.97895

Cumulative Model Updates: 56,502
Cumulative Timesteps: 942,456,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762,151.76829
Policy Entropy: 1.06469
Value Function Loss: 2.94635

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.07645
Value Function Update Magnitude: 0.09245

Collected Steps per Second: 11,486.14825
Overall Steps per Second: 9,967.05036

Timestep Collection Time: 4.35568
Timestep Consumption Time: 0.66386
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.01954

Cumulative Model Updates: 56,505
Cumulative Timesteps: 942,506,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 942506094...
Checkpoint 942506094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,126.34945
Policy Entropy: 1.06204
Value Function Loss: 2.78697

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.07380
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 11,594.47617
Overall Steps per Second: 9,887.02393

Timestep Collection Time: 4.31481
Timestep Consumption Time: 0.74515
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.05997

Cumulative Model Updates: 56,508
Cumulative Timesteps: 942,556,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,091.55046
Policy Entropy: 1.06048
Value Function Loss: 2.76124

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.07380
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 11,815.76888
Overall Steps per Second: 9,878.38905

Timestep Collection Time: 4.23316
Timestep Consumption Time: 0.83022
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 5.06338

Cumulative Model Updates: 56,511
Cumulative Timesteps: 942,606,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 942606140...
Checkpoint 942606140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,938.62670
Policy Entropy: 1.06235
Value Function Loss: 2.79622

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.09258

Collected Steps per Second: 12,146.17010
Overall Steps per Second: 10,241.72620

Timestep Collection Time: 4.11669
Timestep Consumption Time: 0.76550
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.88218

Cumulative Model Updates: 56,514
Cumulative Timesteps: 942,656,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,859.69869
Policy Entropy: 1.07117
Value Function Loss: 2.89583

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.11065

Collected Steps per Second: 11,878.57841
Overall Steps per Second: 10,057.31058

Timestep Collection Time: 4.20926
Timestep Consumption Time: 0.76225
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.97151

Cumulative Model Updates: 56,517
Cumulative Timesteps: 942,706,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 942706142...
Checkpoint 942706142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,035.02136
Policy Entropy: 1.08242
Value Function Loss: 2.82225

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 11,810.64170
Overall Steps per Second: 10,132.96380

Timestep Collection Time: 4.23466
Timestep Consumption Time: 0.70112
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.93577

Cumulative Model Updates: 56,520
Cumulative Timesteps: 942,756,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,271.49923
Policy Entropy: 1.09077
Value Function Loss: 2.75357

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 11,465.89451
Overall Steps per Second: 9,685.90591

Timestep Collection Time: 4.36268
Timestep Consumption Time: 0.80173
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.16441

Cumulative Model Updates: 56,523
Cumulative Timesteps: 942,806,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 942806178...
Checkpoint 942806178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,785.96063
Policy Entropy: 1.08862
Value Function Loss: 2.76139

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 11,831.48329
Overall Steps per Second: 10,096.87563

Timestep Collection Time: 4.22804
Timestep Consumption Time: 0.72636
PPO Batch Consumption Time: 0.03401
Total Iteration Time: 4.95440

Cumulative Model Updates: 56,526
Cumulative Timesteps: 942,856,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,785.06072
Policy Entropy: 1.07720
Value Function Loss: 2.73031

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.09724

Collected Steps per Second: 12,136.75946
Overall Steps per Second: 10,244.87005

Timestep Collection Time: 4.12153
Timestep Consumption Time: 0.76111
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.88264

Cumulative Model Updates: 56,529
Cumulative Timesteps: 942,906,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 942906224...
Checkpoint 942906224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,472.40343
Policy Entropy: 1.07160
Value Function Loss: 2.75325

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.15855
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 12,631.71339
Overall Steps per Second: 10,554.52298

Timestep Collection Time: 3.95877
Timestep Consumption Time: 0.77911
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 4.73787

Cumulative Model Updates: 56,532
Cumulative Timesteps: 942,956,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,892.07926
Policy Entropy: 1.08072
Value Function Loss: 2.67915

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.10469

Collected Steps per Second: 12,530.12273
Overall Steps per Second: 10,647.84809

Timestep Collection Time: 3.99038
Timestep Consumption Time: 0.70540
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.69578

Cumulative Model Updates: 56,535
Cumulative Timesteps: 943,006,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 943006230...
Checkpoint 943006230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,714.97635
Policy Entropy: 1.08630
Value Function Loss: 2.65011

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.10398

Collected Steps per Second: 12,648.70640
Overall Steps per Second: 10,618.75288

Timestep Collection Time: 3.95376
Timestep Consumption Time: 0.75583
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.70959

Cumulative Model Updates: 56,538
Cumulative Timesteps: 943,056,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,179.83360
Policy Entropy: 1.06727
Value Function Loss: 2.74050

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.09488

Collected Steps per Second: 12,585.02163
Overall Steps per Second: 10,435.09344

Timestep Collection Time: 3.97314
Timestep Consumption Time: 0.81858
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.79172

Cumulative Model Updates: 56,541
Cumulative Timesteps: 943,106,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 943106242...
Checkpoint 943106242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,806.97099
Policy Entropy: 1.06337
Value Function Loss: 2.84143

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 12,921.48288
Overall Steps per Second: 10,675.00616

Timestep Collection Time: 3.86968
Timestep Consumption Time: 0.81435
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.68403

Cumulative Model Updates: 56,544
Cumulative Timesteps: 943,156,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,946.67894
Policy Entropy: 1.07029
Value Function Loss: 2.83868

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 12,523.24388
Overall Steps per Second: 10,471.78967

Timestep Collection Time: 3.99449
Timestep Consumption Time: 0.78253
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.77702

Cumulative Model Updates: 56,547
Cumulative Timesteps: 943,206,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 943206268...
Checkpoint 943206268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,581.23291
Policy Entropy: 1.08117
Value Function Loss: 2.76274

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.16513
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.09533

Collected Steps per Second: 11,710.76417
Overall Steps per Second: 10,141.49783

Timestep Collection Time: 4.26958
Timestep Consumption Time: 0.66066
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.93024

Cumulative Model Updates: 56,550
Cumulative Timesteps: 943,256,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,504.24281
Policy Entropy: 1.05463
Value Function Loss: 2.60377

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.18405
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 11,828.06111
Overall Steps per Second: 9,971.82862

Timestep Collection Time: 4.22910
Timestep Consumption Time: 0.78724
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 5.01633

Cumulative Model Updates: 56,553
Cumulative Timesteps: 943,306,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 943306290...
Checkpoint 943306290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,064.69133
Policy Entropy: 1.07874
Value Function Loss: 2.65692

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.17077
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.10241

Collected Steps per Second: 12,022.57845
Overall Steps per Second: 10,162.78990

Timestep Collection Time: 4.16117
Timestep Consumption Time: 0.76149
PPO Batch Consumption Time: 0.03346
Total Iteration Time: 4.92266

Cumulative Model Updates: 56,556
Cumulative Timesteps: 943,356,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762,372.95692
Policy Entropy: 1.07272
Value Function Loss: 2.74267

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.16647
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 11,724.43215
Overall Steps per Second: 10,105.66807

Timestep Collection Time: 4.26630
Timestep Consumption Time: 0.68339
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 4.94970

Cumulative Model Updates: 56,559
Cumulative Timesteps: 943,406,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 943406338...
Checkpoint 943406338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,987.59139
Policy Entropy: 1.05369
Value Function Loss: 2.85845

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.10244

Collected Steps per Second: 11,320.36069
Overall Steps per Second: 9,604.62017

Timestep Collection Time: 4.41876
Timestep Consumption Time: 0.78935
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 5.20812

Cumulative Model Updates: 56,562
Cumulative Timesteps: 943,456,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,153.36047
Policy Entropy: 1.03971
Value Function Loss: 2.79526

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.18711
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.09144

Collected Steps per Second: 11,856.41201
Overall Steps per Second: 9,998.06232

Timestep Collection Time: 4.21831
Timestep Consumption Time: 0.78406
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 5.00237

Cumulative Model Updates: 56,565
Cumulative Timesteps: 943,506,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 943506374...
Checkpoint 943506374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,250.44492
Policy Entropy: 1.05164
Value Function Loss: 2.77802

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 12,034.30747
Overall Steps per Second: 10,161.92410

Timestep Collection Time: 4.15695
Timestep Consumption Time: 0.76594
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 4.92289

Cumulative Model Updates: 56,568
Cumulative Timesteps: 943,556,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,872.40005
Policy Entropy: 1.06711
Value Function Loss: 2.75377

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.08176

Collected Steps per Second: 11,961.72249
Overall Steps per Second: 10,092.10662

Timestep Collection Time: 4.18134
Timestep Consumption Time: 0.77461
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 4.95595

Cumulative Model Updates: 56,571
Cumulative Timesteps: 943,606,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 943606416...
Checkpoint 943606416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,274.60832
Policy Entropy: 1.04819
Value Function Loss: 2.79013

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 11,631.24706
Overall Steps per Second: 9,994.93999

Timestep Collection Time: 4.30083
Timestep Consumption Time: 0.70410
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.00493

Cumulative Model Updates: 56,574
Cumulative Timesteps: 943,656,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,675.48799
Policy Entropy: 1.06188
Value Function Loss: 2.87198

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.09241

Collected Steps per Second: 11,539.09002
Overall Steps per Second: 9,773.09282

Timestep Collection Time: 4.33587
Timestep Consumption Time: 0.78349
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.11936

Cumulative Model Updates: 56,577
Cumulative Timesteps: 943,706,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 943706472...
Checkpoint 943706472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756,244.02713
Policy Entropy: 1.06432
Value Function Loss: 2.91656

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.09706

Collected Steps per Second: 11,709.40153
Overall Steps per Second: 10,147.23861

Timestep Collection Time: 4.27246
Timestep Consumption Time: 0.65774
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 4.93021

Cumulative Model Updates: 56,580
Cumulative Timesteps: 943,756,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,053.51511
Policy Entropy: 1.04398
Value Function Loss: 2.86385

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 11,925.75641
Overall Steps per Second: 10,027.27837

Timestep Collection Time: 4.19344
Timestep Consumption Time: 0.79395
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.98740

Cumulative Model Updates: 56,583
Cumulative Timesteps: 943,806,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 943806510...
Checkpoint 943806510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,688.96077
Policy Entropy: 1.03587
Value Function Loss: 2.66929

Mean KL Divergence: 0.03208
SB3 Clip Fraction: 0.19009
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10,289.69563
Overall Steps per Second: 8,869.04952

Timestep Collection Time: 4.86001
Timestep Consumption Time: 0.77848
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.63848

Cumulative Model Updates: 56,586
Cumulative Timesteps: 943,856,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754,350.07241
Policy Entropy: 1.05317
Value Function Loss: 2.60023

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 11,743.00114
Overall Steps per Second: 9,944.78126

Timestep Collection Time: 4.25990
Timestep Consumption Time: 0.77028
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 5.03018

Cumulative Model Updates: 56,589
Cumulative Timesteps: 943,906,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 943906542...
Checkpoint 943906542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,114.14235
Policy Entropy: 1.04928
Value Function Loss: 2.60534

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 11,944.61709
Overall Steps per Second: 10,059.01942

Timestep Collection Time: 4.18766
Timestep Consumption Time: 0.78499
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 4.97265

Cumulative Model Updates: 56,592
Cumulative Timesteps: 943,956,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765,591.73856
Policy Entropy: 1.04144
Value Function Loss: 2.71900

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 11,843.34333
Overall Steps per Second: 10,063.58219

Timestep Collection Time: 4.22381
Timestep Consumption Time: 0.74699
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.97079

Cumulative Model Updates: 56,595
Cumulative Timesteps: 944,006,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 944006586...
Checkpoint 944006586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,863.49044
Policy Entropy: 1.04578
Value Function Loss: 2.71120

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.10390

Collected Steps per Second: 11,822.82143
Overall Steps per Second: 9,946.25859

Timestep Collection Time: 4.23080
Timestep Consumption Time: 0.79823
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.02903

Cumulative Model Updates: 56,598
Cumulative Timesteps: 944,056,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,646.03878
Policy Entropy: 1.05043
Value Function Loss: 2.70958

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 11,939.55777
Overall Steps per Second: 10,159.78816

Timestep Collection Time: 4.18943
Timestep Consumption Time: 0.73390
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.92333

Cumulative Model Updates: 56,601
Cumulative Timesteps: 944,106,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 944106626...
Checkpoint 944106626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821,542.01065
Policy Entropy: 1.05998
Value Function Loss: 2.68848

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 12,003.63695
Overall Steps per Second: 10,126.21832

Timestep Collection Time: 4.16624
Timestep Consumption Time: 0.77243
PPO Batch Consumption Time: 0.03364
Total Iteration Time: 4.93867

Cumulative Model Updates: 56,604
Cumulative Timesteps: 944,156,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,185.37506
Policy Entropy: 1.06026
Value Function Loss: 2.64548

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.10131

Collected Steps per Second: 11,928.93520
Overall Steps per Second: 10,178.46519

Timestep Collection Time: 4.19333
Timestep Consumption Time: 0.72116
PPO Batch Consumption Time: 0.03298
Total Iteration Time: 4.91449

Cumulative Model Updates: 56,607
Cumulative Timesteps: 944,206,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 944206658...
Checkpoint 944206658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,697.25352
Policy Entropy: 1.06093
Value Function Loss: 2.75322

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.09822

Collected Steps per Second: 12,122.06794
Overall Steps per Second: 10,438.99860

Timestep Collection Time: 4.12718
Timestep Consumption Time: 0.66542
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 4.79261

Cumulative Model Updates: 56,610
Cumulative Timesteps: 944,256,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,518.39251
Policy Entropy: 1.05309
Value Function Loss: 2.66365

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 12,196.24832
Overall Steps per Second: 10,205.19647

Timestep Collection Time: 4.10126
Timestep Consumption Time: 0.80016
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 4.90142

Cumulative Model Updates: 56,613
Cumulative Timesteps: 944,306,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 944306708...
Checkpoint 944306708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,938.27834
Policy Entropy: 1.04190
Value Function Loss: 2.75190

Mean KL Divergence: 0.02900
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.07721
Value Function Update Magnitude: 0.11142

Collected Steps per Second: 11,780.57139
Overall Steps per Second: 9,973.71165

Timestep Collection Time: 4.24665
Timestep Consumption Time: 0.76933
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 5.01599

Cumulative Model Updates: 56,616
Cumulative Timesteps: 944,356,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,452.90069
Policy Entropy: 1.06199
Value Function Loss: 2.65518

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.15896
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 12,244.42163
Overall Steps per Second: 10,297.82705

Timestep Collection Time: 4.08398
Timestep Consumption Time: 0.77199
PPO Batch Consumption Time: 0.03679
Total Iteration Time: 4.85598

Cumulative Model Updates: 56,619
Cumulative Timesteps: 944,406,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 944406742...
Checkpoint 944406742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,072.60001
Policy Entropy: 1.06630
Value Function Loss: 2.75241

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 11,750.52274
Overall Steps per Second: 10,002.67854

Timestep Collection Time: 4.25700
Timestep Consumption Time: 0.74386
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 5.00086

Cumulative Model Updates: 56,622
Cumulative Timesteps: 944,456,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,938.00683
Policy Entropy: 1.04735
Value Function Loss: 2.69633

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.15627
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 12,011.07450
Overall Steps per Second: 10,312.47820

Timestep Collection Time: 4.16282
Timestep Consumption Time: 0.68567
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.84850

Cumulative Model Updates: 56,625
Cumulative Timesteps: 944,506,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 944506764...
Checkpoint 944506764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742,874.36281
Policy Entropy: 1.04256
Value Function Loss: 2.64933

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.11748

Collected Steps per Second: 12,117.96326
Overall Steps per Second: 10,246.22796

Timestep Collection Time: 4.12825
Timestep Consumption Time: 0.75413
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.88238

Cumulative Model Updates: 56,628
Cumulative Timesteps: 944,556,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,736.97153
Policy Entropy: 1.04961
Value Function Loss: 2.53568

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 11,908.29073
Overall Steps per Second: 10,087.22049

Timestep Collection Time: 4.20010
Timestep Consumption Time: 0.75825
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 4.95835

Cumulative Model Updates: 56,631
Cumulative Timesteps: 944,606,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 944606806...
Checkpoint 944606806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,325.93690
Policy Entropy: 1.05065
Value Function Loss: 2.55659

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.11000

Collected Steps per Second: 11,472.28262
Overall Steps per Second: 9,923.83267

Timestep Collection Time: 4.35850
Timestep Consumption Time: 0.68007
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.03858

Cumulative Model Updates: 56,634
Cumulative Timesteps: 944,656,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,140.94779
Policy Entropy: 1.04161
Value Function Loss: 2.54875

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.10446

Collected Steps per Second: 12,006.71310
Overall Steps per Second: 10,084.85637

Timestep Collection Time: 4.16517
Timestep Consumption Time: 0.79375
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 4.95892

Cumulative Model Updates: 56,637
Cumulative Timesteps: 944,706,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 944706818...
Checkpoint 944706818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,044.31075
Policy Entropy: 1.05713
Value Function Loss: 2.69327

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.09603

Collected Steps per Second: 11,865.47660
Overall Steps per Second: 10,111.26599

Timestep Collection Time: 4.21407
Timestep Consumption Time: 0.73110
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.94518

Cumulative Model Updates: 56,640
Cumulative Timesteps: 944,756,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,401.94761
Policy Entropy: 1.05696
Value Function Loss: 2.89046

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.09025

Collected Steps per Second: 12,194.56370
Overall Steps per Second: 10,238.32579

Timestep Collection Time: 4.10035
Timestep Consumption Time: 0.78345
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.88381

Cumulative Model Updates: 56,643
Cumulative Timesteps: 944,806,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 944806822...
Checkpoint 944806822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,832.44910
Policy Entropy: 1.06044
Value Function Loss: 2.98052

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.08439

Collected Steps per Second: 11,852.73271
Overall Steps per Second: 10,102.24493

Timestep Collection Time: 4.21945
Timestep Consumption Time: 0.73113
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.95058

Cumulative Model Updates: 56,646
Cumulative Timesteps: 944,856,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,297.42352
Policy Entropy: 1.05455
Value Function Loss: 2.98818

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 12,050.76104
Overall Steps per Second: 10,357.65191

Timestep Collection Time: 4.15028
Timestep Consumption Time: 0.67842
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 4.82870

Cumulative Model Updates: 56,649
Cumulative Timesteps: 944,906,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 944906848...
Checkpoint 944906848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743,791.48496
Policy Entropy: 1.06160
Value Function Loss: 2.88200

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.08155

Collected Steps per Second: 11,248.13869
Overall Steps per Second: 9,557.81284

Timestep Collection Time: 4.44767
Timestep Consumption Time: 0.78658
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.23425

Cumulative Model Updates: 56,652
Cumulative Timesteps: 944,956,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,016.72608
Policy Entropy: 1.06561
Value Function Loss: 2.80893

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 11,813.10156
Overall Steps per Second: 9,977.32855

Timestep Collection Time: 4.23327
Timestep Consumption Time: 0.77890
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.01216

Cumulative Model Updates: 56,655
Cumulative Timesteps: 945,006,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 945006884...
Checkpoint 945006884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,279.01846
Policy Entropy: 1.06166
Value Function Loss: 2.65769

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 11,971.89834
Overall Steps per Second: 10,064.77524

Timestep Collection Time: 4.17879
Timestep Consumption Time: 0.79182
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.97060

Cumulative Model Updates: 56,658
Cumulative Timesteps: 945,056,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,897.74489
Policy Entropy: 1.05501
Value Function Loss: 2.58038

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 11,980.60328
Overall Steps per Second: 10,061.68784

Timestep Collection Time: 4.17458
Timestep Consumption Time: 0.79616
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.97074

Cumulative Model Updates: 56,661
Cumulative Timesteps: 945,106,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 945106926...
Checkpoint 945106926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,069.70093
Policy Entropy: 1.06398
Value Function Loss: 2.69460

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.09640

Collected Steps per Second: 11,732.13576
Overall Steps per Second: 10,114.36756

Timestep Collection Time: 4.26436
Timestep Consumption Time: 0.68207
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.94643

Cumulative Model Updates: 56,664
Cumulative Timesteps: 945,156,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,227.97215
Policy Entropy: 1.07057
Value Function Loss: 2.83439

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.17511
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.09372

Collected Steps per Second: 11,993.02925
Overall Steps per Second: 10,130.73314

Timestep Collection Time: 4.16942
Timestep Consumption Time: 0.76645
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.93587

Cumulative Model Updates: 56,667
Cumulative Timesteps: 945,206,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 945206960...
Checkpoint 945206960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,533.75232
Policy Entropy: 1.04816
Value Function Loss: 3.00133

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.17455
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.08940

Collected Steps per Second: 11,374.99601
Overall Steps per Second: 9,695.16938

Timestep Collection Time: 4.39824
Timestep Consumption Time: 0.76206
PPO Batch Consumption Time: 0.03804
Total Iteration Time: 5.16030

Cumulative Model Updates: 56,670
Cumulative Timesteps: 945,256,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,245.00528
Policy Entropy: 1.06592
Value Function Loss: 3.00254

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.16763
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.08441

Collected Steps per Second: 11,985.54123
Overall Steps per Second: 10,167.54863

Timestep Collection Time: 4.17236
Timestep Consumption Time: 0.74603
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.91839

Cumulative Model Updates: 56,673
Cumulative Timesteps: 945,306,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 945306998...
Checkpoint 945306998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,513.77049
Policy Entropy: 1.06659
Value Function Loss: 3.00928

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.17109
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 12,603.55290
Overall Steps per Second: 10,505.69004

Timestep Collection Time: 3.96856
Timestep Consumption Time: 0.79248
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.76104

Cumulative Model Updates: 56,676
Cumulative Timesteps: 945,357,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,606.31816
Policy Entropy: 1.05607
Value Function Loss: 2.81824

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.08194

Collected Steps per Second: 12,720.36806
Overall Steps per Second: 10,739.00353

Timestep Collection Time: 3.93086
Timestep Consumption Time: 0.72525
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.65611

Cumulative Model Updates: 56,679
Cumulative Timesteps: 945,407,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 945407018...
Checkpoint 945407018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,132.25943
Policy Entropy: 1.03900
Value Function Loss: 2.75405

Mean KL Divergence: 0.02907
SB3 Clip Fraction: 0.19946
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 12,640.08622
Overall Steps per Second: 10,593.77869

Timestep Collection Time: 3.95614
Timestep Consumption Time: 0.76417
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.72032

Cumulative Model Updates: 56,682
Cumulative Timesteps: 945,457,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,818.70504
Policy Entropy: 1.05590
Value Function Loss: 2.66507

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 12,805.27454
Overall Steps per Second: 10,778.09627

Timestep Collection Time: 3.90573
Timestep Consumption Time: 0.73460
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.64034

Cumulative Model Updates: 56,685
Cumulative Timesteps: 945,507,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 945507038...
Checkpoint 945507038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,447.06966
Policy Entropy: 1.05595
Value Function Loss: 2.75270

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 12,262.47012
Overall Steps per Second: 10,309.12002

Timestep Collection Time: 4.07813
Timestep Consumption Time: 0.77272
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.85085

Cumulative Model Updates: 56,688
Cumulative Timesteps: 945,557,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,704.59900
Policy Entropy: 1.05395
Value Function Loss: 2.74350

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 12,392.75073
Overall Steps per Second: 10,464.68758

Timestep Collection Time: 4.03542
Timestep Consumption Time: 0.74351
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.77893

Cumulative Model Updates: 56,691
Cumulative Timesteps: 945,607,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 945607056...
Checkpoint 945607056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,395.98693
Policy Entropy: 1.03983
Value Function Loss: 2.82780

Mean KL Divergence: 0.02806
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 11,753.75555
Overall Steps per Second: 9,976.62751

Timestep Collection Time: 4.25515
Timestep Consumption Time: 0.75797
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 5.01312

Cumulative Model Updates: 56,694
Cumulative Timesteps: 945,657,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,713.48356
Policy Entropy: 1.06041
Value Function Loss: 2.64990

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 11,605.42942
Overall Steps per Second: 9,860.90372

Timestep Collection Time: 4.30936
Timestep Consumption Time: 0.76238
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.07175

Cumulative Model Updates: 56,697
Cumulative Timesteps: 945,707,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 945707082...
Checkpoint 945707082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,603.98403
Policy Entropy: 1.06889
Value Function Loss: 2.70472

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.10543

Collected Steps per Second: 11,983.44221
Overall Steps per Second: 10,123.63347

Timestep Collection Time: 4.17476
Timestep Consumption Time: 0.76694
PPO Batch Consumption Time: 0.03829
Total Iteration Time: 4.94170

Cumulative Model Updates: 56,700
Cumulative Timesteps: 945,757,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603,996.47946
Policy Entropy: 1.04973
Value Function Loss: 2.79335

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 11,781.86256
Overall Steps per Second: 10,120.06275

Timestep Collection Time: 4.24551
Timestep Consumption Time: 0.69715
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.94266

Cumulative Model Updates: 56,703
Cumulative Timesteps: 945,807,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 945807130...
Checkpoint 945807130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,261.59181
Policy Entropy: 1.03983
Value Function Loss: 2.91948

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.16927
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.11704

Collected Steps per Second: 11,205.71318
Overall Steps per Second: 9,520.11641

Timestep Collection Time: 4.46219
Timestep Consumption Time: 0.79006
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 5.25225

Cumulative Model Updates: 56,706
Cumulative Timesteps: 945,857,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,003.34012
Policy Entropy: 1.05124
Value Function Loss: 2.92286

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 11,838.73434
Overall Steps per Second: 10,035.74192

Timestep Collection Time: 4.22596
Timestep Consumption Time: 0.75922
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 4.98518

Cumulative Model Updates: 56,709
Cumulative Timesteps: 945,907,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 945907162...
Checkpoint 945907162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,484.23692
Policy Entropy: 1.06025
Value Function Loss: 2.83490

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.10097

Collected Steps per Second: 12,040.74152
Overall Steps per Second: 10,174.27607

Timestep Collection Time: 4.15423
Timestep Consumption Time: 0.76209
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.91632

Cumulative Model Updates: 56,712
Cumulative Timesteps: 945,957,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,079.03468
Policy Entropy: 1.04336
Value Function Loss: 2.82070

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.09435

Collected Steps per Second: 12,064.06567
Overall Steps per Second: 10,209.51910

Timestep Collection Time: 4.14520
Timestep Consumption Time: 0.75297
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.89817

Cumulative Model Updates: 56,715
Cumulative Timesteps: 946,007,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 946007190...
Checkpoint 946007190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,108.07450
Policy Entropy: 1.06168
Value Function Loss: 2.80504

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.17199
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 11,866.38116
Overall Steps per Second: 10,242.96731

Timestep Collection Time: 4.21544
Timestep Consumption Time: 0.66811
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.88355

Cumulative Model Updates: 56,718
Cumulative Timesteps: 946,057,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,326.25879
Policy Entropy: 1.06267
Value Function Loss: 2.80556

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.08700

Collected Steps per Second: 11,785.50744
Overall Steps per Second: 9,921.67113

Timestep Collection Time: 4.24352
Timestep Consumption Time: 0.79717
PPO Batch Consumption Time: 0.03322
Total Iteration Time: 5.04068

Cumulative Model Updates: 56,721
Cumulative Timesteps: 946,107,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946107224...
Checkpoint 946107224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596,075.85055
Policy Entropy: 1.03912
Value Function Loss: 2.93705

Mean KL Divergence: 0.03245
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.08412

Collected Steps per Second: 11,241.42979
Overall Steps per Second: 9,623.86994

Timestep Collection Time: 4.44801
Timestep Consumption Time: 0.74761
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.19562

Cumulative Model Updates: 56,724
Cumulative Timesteps: 946,157,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,760.92234
Policy Entropy: 1.04625
Value Function Loss: 2.89819

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.09280

Collected Steps per Second: 12,144.89267
Overall Steps per Second: 10,238.14356

Timestep Collection Time: 4.11943
Timestep Consumption Time: 0.76720
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.88663

Cumulative Model Updates: 56,727
Cumulative Timesteps: 946,207,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 946207256...
Checkpoint 946207256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,999.36826
Policy Entropy: 1.05356
Value Function Loss: 2.94113

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 11,783.56449
Overall Steps per Second: 9,981.10452

Timestep Collection Time: 4.24422
Timestep Consumption Time: 0.76645
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.01067

Cumulative Model Updates: 56,730
Cumulative Timesteps: 946,257,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,013.80356
Policy Entropy: 1.06615
Value Function Loss: 2.81520

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.08611

Collected Steps per Second: 11,747.50529
Overall Steps per Second: 9,970.90987

Timestep Collection Time: 4.25827
Timestep Consumption Time: 0.75873
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.01699

Cumulative Model Updates: 56,733
Cumulative Timesteps: 946,307,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 946307292...
Checkpoint 946307292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,691.19162
Policy Entropy: 1.04158
Value Function Loss: 2.82259

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 12,322.63123
Overall Steps per Second: 10,310.44175

Timestep Collection Time: 4.05936
Timestep Consumption Time: 0.79223
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 4.85159

Cumulative Model Updates: 56,736
Cumulative Timesteps: 946,357,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,890.24355
Policy Entropy: 1.06290
Value Function Loss: 2.78341

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.17597
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 11,793.93254
Overall Steps per Second: 9,937.37617

Timestep Collection Time: 4.24133
Timestep Consumption Time: 0.79239
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.03372

Cumulative Model Updates: 56,739
Cumulative Timesteps: 946,407,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 946407336...
Checkpoint 946407336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,498.61940
Policy Entropy: 1.05196
Value Function Loss: 2.68276

Mean KL Divergence: 0.02873
SB3 Clip Fraction: 0.18671
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 11,301.97561
Overall Steps per Second: 9,792.32958

Timestep Collection Time: 4.42489
Timestep Consumption Time: 0.68217
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.10706

Cumulative Model Updates: 56,742
Cumulative Timesteps: 946,457,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,327.50738
Policy Entropy: 1.04476
Value Function Loss: 2.70956

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 11,717.47236
Overall Steps per Second: 9,954.32860

Timestep Collection Time: 4.26935
Timestep Consumption Time: 0.75620
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.02555

Cumulative Model Updates: 56,745
Cumulative Timesteps: 946,507,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 946507372...
Checkpoint 946507372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,288.58661
Policy Entropy: 1.04957
Value Function Loss: 2.68206

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.17251
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.08550

Collected Steps per Second: 11,881.38069
Overall Steps per Second: 10,129.04026

Timestep Collection Time: 4.20978
Timestep Consumption Time: 0.72830
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.93808

Cumulative Model Updates: 56,748
Cumulative Timesteps: 946,557,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,673.34744
Policy Entropy: 1.05757
Value Function Loss: 2.83221

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 12,428.03241
Overall Steps per Second: 10,434.83878

Timestep Collection Time: 4.02445
Timestep Consumption Time: 0.76872
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.79317

Cumulative Model Updates: 56,751
Cumulative Timesteps: 946,607,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 946607406...
Checkpoint 946607406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,317.82361
Policy Entropy: 1.06114
Value Function Loss: 2.75021

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.07629
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 11,939.53108
Overall Steps per Second: 10,081.37920

Timestep Collection Time: 4.18844
Timestep Consumption Time: 0.77199
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.96043

Cumulative Model Updates: 56,754
Cumulative Timesteps: 946,657,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,433.27334
Policy Entropy: 1.06029
Value Function Loss: 2.82894

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11,732.40345
Overall Steps per Second: 10,085.29376

Timestep Collection Time: 4.26375
Timestep Consumption Time: 0.69635
PPO Batch Consumption Time: 0.03774
Total Iteration Time: 4.96009

Cumulative Model Updates: 56,757
Cumulative Timesteps: 946,707,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 946707438...
Checkpoint 946707438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609,193.81107
Policy Entropy: 1.06636
Value Function Loss: 2.83758

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.08607

Collected Steps per Second: 11,204.73474
Overall Steps per Second: 9,566.78141

Timestep Collection Time: 4.46508
Timestep Consumption Time: 0.76448
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.22955

Cumulative Model Updates: 56,760
Cumulative Timesteps: 946,757,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,458.50166
Policy Entropy: 1.06404
Value Function Loss: 2.90462

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.06725
Value Function Update Magnitude: 0.09854

Collected Steps per Second: 11,905.45968
Overall Steps per Second: 10,151.02933

Timestep Collection Time: 4.20211
Timestep Consumption Time: 0.72626
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.92837

Cumulative Model Updates: 56,763
Cumulative Timesteps: 946,807,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 946807496...
Checkpoint 946807496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,913.58965
Policy Entropy: 1.07401
Value Function Loss: 2.81454

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 11,774.71343
Overall Steps per Second: 9,899.35550

Timestep Collection Time: 4.24656
Timestep Consumption Time: 0.80448
PPO Batch Consumption Time: 0.03805
Total Iteration Time: 5.05104

Cumulative Model Updates: 56,766
Cumulative Timesteps: 946,857,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,767.79525
Policy Entropy: 1.07597
Value Function Loss: 2.75954

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 12,083.01743
Overall Steps per Second: 10,136.16883

Timestep Collection Time: 4.14019
Timestep Consumption Time: 0.79520
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.93540

Cumulative Model Updates: 56,769
Cumulative Timesteps: 946,907,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 946907524...
Checkpoint 946907524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,502.77750
Policy Entropy: 1.07407
Value Function Loss: 2.66938

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.09379

Collected Steps per Second: 11,916.70306
Overall Steps per Second: 10,254.30134

Timestep Collection Time: 4.19747
Timestep Consumption Time: 0.68048
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.87795

Cumulative Model Updates: 56,772
Cumulative Timesteps: 946,957,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769,964.80914
Policy Entropy: 1.07099
Value Function Loss: 2.67475

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.07103
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 11,860.98510
Overall Steps per Second: 10,023.39628

Timestep Collection Time: 4.21668
Timestep Consumption Time: 0.77304
PPO Batch Consumption Time: 0.03772
Total Iteration Time: 4.98973

Cumulative Model Updates: 56,775
Cumulative Timesteps: 947,007,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 947007558...
Checkpoint 947007558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,429.43801
Policy Entropy: 1.07822
Value Function Loss: 2.65281

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.08368

Collected Steps per Second: 11,306.15483
Overall Steps per Second: 9,597.93184

Timestep Collection Time: 4.42255
Timestep Consumption Time: 0.78712
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.20966

Cumulative Model Updates: 56,778
Cumulative Timesteps: 947,057,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,358.31012
Policy Entropy: 1.09281
Value Function Loss: 2.81209

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 12,120.55861
Overall Steps per Second: 10,173.85267

Timestep Collection Time: 4.12687
Timestep Consumption Time: 0.78965
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.91652

Cumulative Model Updates: 56,781
Cumulative Timesteps: 947,107,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 947107580...
Checkpoint 947107580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,494.63787
Policy Entropy: 1.09400
Value Function Loss: 2.90249

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.07960

Collected Steps per Second: 11,533.68594
Overall Steps per Second: 9,852.95284

Timestep Collection Time: 4.33582
Timestep Consumption Time: 0.73961
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.07543

Cumulative Model Updates: 56,784
Cumulative Timesteps: 947,157,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,093.87654
Policy Entropy: 1.08828
Value Function Loss: 2.88966

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.07416
Value Function Update Magnitude: 0.09028

Collected Steps per Second: 11,839.21334
Overall Steps per Second: 10,214.46768

Timestep Collection Time: 4.22511
Timestep Consumption Time: 0.67206
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.89717

Cumulative Model Updates: 56,787
Cumulative Timesteps: 947,207,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 947207610...
Checkpoint 947207610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,150.10148
Policy Entropy: 1.09977
Value Function Loss: 2.83347

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 11,537.78778
Overall Steps per Second: 9,780.71580

Timestep Collection Time: 4.33445
Timestep Consumption Time: 0.77867
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.11312

Cumulative Model Updates: 56,790
Cumulative Timesteps: 947,257,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,076.24411
Policy Entropy: 1.10341
Value Function Loss: 2.68283

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 11,947.88427
Overall Steps per Second: 10,151.11320

Timestep Collection Time: 4.18585
Timestep Consumption Time: 0.74090
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.92675

Cumulative Model Updates: 56,793
Cumulative Timesteps: 947,307,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 947307632...
Checkpoint 947307632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,929.53803
Policy Entropy: 1.08650
Value Function Loss: 2.71719

Mean KL Divergence: 0.02622
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.09815

Collected Steps per Second: 11,543.60104
Overall Steps per Second: 9,797.85404

Timestep Collection Time: 4.33348
Timestep Consumption Time: 0.77212
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.10561

Cumulative Model Updates: 56,796
Cumulative Timesteps: 947,357,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,029.12901
Policy Entropy: 1.09336
Value Function Loss: 2.75625

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 12,093.16812
Overall Steps per Second: 10,164.86972

Timestep Collection Time: 4.13605
Timestep Consumption Time: 0.78462
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.92067

Cumulative Model Updates: 56,799
Cumulative Timesteps: 947,407,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 947407674...
Checkpoint 947407674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537,755.63993
Policy Entropy: 1.09517
Value Function Loss: 2.89287

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.09409

Collected Steps per Second: 11,867.72264
Overall Steps per Second: 10,132.19835

Timestep Collection Time: 4.21564
Timestep Consumption Time: 0.72209
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.93772

Cumulative Model Updates: 56,802
Cumulative Timesteps: 947,457,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,837.45770
Policy Entropy: 1.10076
Value Function Loss: 2.83958

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 11,934.94894
Overall Steps per Second: 10,052.64733

Timestep Collection Time: 4.18971
Timestep Consumption Time: 0.78450
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.97421

Cumulative Model Updates: 56,805
Cumulative Timesteps: 947,507,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947507708...
Checkpoint 947507708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,861.01349
Policy Entropy: 1.09276
Value Function Loss: 2.76229

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11,845.20800
Overall Steps per Second: 10,041.59573

Timestep Collection Time: 4.22280
Timestep Consumption Time: 0.75848
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.98128

Cumulative Model Updates: 56,808
Cumulative Timesteps: 947,557,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,716.62878
Policy Entropy: 1.08253
Value Function Loss: 2.68025

Mean KL Divergence: 0.04044
SB3 Clip Fraction: 0.18343
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 11,932.21373
Overall Steps per Second: 10,229.40972

Timestep Collection Time: 4.19185
Timestep Consumption Time: 0.69778
PPO Batch Consumption Time: 0.03353
Total Iteration Time: 4.88963

Cumulative Model Updates: 56,811
Cumulative Timesteps: 947,607,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 947607746...
Checkpoint 947607746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,776.31228
Policy Entropy: 1.09611
Value Function Loss: 2.66405

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 11,249.09191
Overall Steps per Second: 9,567.10303

Timestep Collection Time: 4.44534
Timestep Consumption Time: 0.78153
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.22687

Cumulative Model Updates: 56,814
Cumulative Timesteps: 947,657,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,475.37893
Policy Entropy: 1.09591
Value Function Loss: 2.63368

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 11,771.19408
Overall Steps per Second: 10,098.61605

Timestep Collection Time: 4.24953
Timestep Consumption Time: 0.70383
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.95335

Cumulative Model Updates: 56,817
Cumulative Timesteps: 947,707,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 947707774...
Checkpoint 947707774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,415.82469
Policy Entropy: 1.08478
Value Function Loss: 2.58239

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07257

Collected Steps per Second: 12,600.63501
Overall Steps per Second: 10,566.92247

Timestep Collection Time: 3.96885
Timestep Consumption Time: 0.76385
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 4.73269

Cumulative Model Updates: 56,820
Cumulative Timesteps: 947,757,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753,977.79768
Policy Entropy: 1.08201
Value Function Loss: 2.56176

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 12,424.50196
Overall Steps per Second: 10,460.87451

Timestep Collection Time: 4.02592
Timestep Consumption Time: 0.75571
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.78163

Cumulative Model Updates: 56,823
Cumulative Timesteps: 947,807,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 947807804...
Checkpoint 947807804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,304.06586
Policy Entropy: 1.09646
Value Function Loss: 2.73615

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.07406

Collected Steps per Second: 12,718.77104
Overall Steps per Second: 10,581.31160

Timestep Collection Time: 3.93340
Timestep Consumption Time: 0.79456
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.72796

Cumulative Model Updates: 56,826
Cumulative Timesteps: 947,857,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,214.49049
Policy Entropy: 1.09636
Value Function Loss: 2.84490

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 12,681.85148
Overall Steps per Second: 10,572.40343

Timestep Collection Time: 3.94327
Timestep Consumption Time: 0.78678
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.73005

Cumulative Model Updates: 56,829
Cumulative Timesteps: 947,907,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 947907840...
Checkpoint 947907840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,570.09052
Policy Entropy: 1.09652
Value Function Loss: 2.93014

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.08343

Collected Steps per Second: 11,815.12694
Overall Steps per Second: 10,111.95141

Timestep Collection Time: 4.23203
Timestep Consumption Time: 0.71281
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.94484

Cumulative Model Updates: 56,832
Cumulative Timesteps: 947,957,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,318.13509
Policy Entropy: 1.08525
Value Function Loss: 2.82113

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.06918
Value Function Update Magnitude: 0.09429

Collected Steps per Second: 12,439.90561
Overall Steps per Second: 10,406.53547

Timestep Collection Time: 4.01932
Timestep Consumption Time: 0.78535
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.80467

Cumulative Model Updates: 56,835
Cumulative Timesteps: 948,007,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 948007842...
Checkpoint 948007842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,360.60602
Policy Entropy: 1.10175
Value Function Loss: 2.79509

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.08476

Collected Steps per Second: 12,032.83691
Overall Steps per Second: 10,179.63253

Timestep Collection Time: 4.15563
Timestep Consumption Time: 0.75653
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.91216

Cumulative Model Updates: 56,838
Cumulative Timesteps: 948,057,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,997.33865
Policy Entropy: 1.10321
Value Function Loss: 2.66417

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.09704

Collected Steps per Second: 12,124.64756
Overall Steps per Second: 10,139.93705

Timestep Collection Time: 4.12598
Timestep Consumption Time: 0.80759
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.93356

Cumulative Model Updates: 56,841
Cumulative Timesteps: 948,107,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 948107872...
Checkpoint 948107872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,600.72664
Policy Entropy: 1.09735
Value Function Loss: 2.59631

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.10668

Collected Steps per Second: 12,026.92628
Overall Steps per Second: 10,098.77461

Timestep Collection Time: 4.15983
Timestep Consumption Time: 0.79423
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 4.95407

Cumulative Model Updates: 56,844
Cumulative Timesteps: 948,157,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,204.37662
Policy Entropy: 1.08816
Value Function Loss: 2.57770

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.16776
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 11,798.55958
Overall Steps per Second: 10,172.87999

Timestep Collection Time: 4.24001
Timestep Consumption Time: 0.67758
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.91758

Cumulative Model Updates: 56,847
Cumulative Timesteps: 948,207,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 948207928...
Checkpoint 948207928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,568.50679
Policy Entropy: 1.09641
Value Function Loss: 2.67076

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 11,411.42997
Overall Steps per Second: 9,669.60956

Timestep Collection Time: 4.38262
Timestep Consumption Time: 0.78946
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.17208

Cumulative Model Updates: 56,850
Cumulative Timesteps: 948,257,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,822.08663
Policy Entropy: 1.10134
Value Function Loss: 2.61412

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.11574

Collected Steps per Second: 11,785.34580
Overall Steps per Second: 9,909.97325

Timestep Collection Time: 4.24358
Timestep Consumption Time: 0.80306
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.04663

Cumulative Model Updates: 56,853
Cumulative Timesteps: 948,307,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 948307952...
Checkpoint 948307952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,479.96882
Policy Entropy: 1.06945
Value Function Loss: 2.58648

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.19474
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 12,035.06831
Overall Steps per Second: 10,142.29426

Timestep Collection Time: 4.15586
Timestep Consumption Time: 0.77557
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.93143

Cumulative Model Updates: 56,856
Cumulative Timesteps: 948,357,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,118.30692
Policy Entropy: 1.09553
Value Function Loss: 2.58237

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.08610

Collected Steps per Second: 11,808.48423
Overall Steps per Second: 9,986.47693

Timestep Collection Time: 4.23594
Timestep Consumption Time: 0.77284
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.00877

Cumulative Model Updates: 56,859
Cumulative Timesteps: 948,407,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 948407988...
Checkpoint 948407988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838,972.09381
Policy Entropy: 1.09312
Value Function Loss: 2.65132

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.15839
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.08598

Collected Steps per Second: 11,707.35599
Overall Steps per Second: 10,115.42630

Timestep Collection Time: 4.27167
Timestep Consumption Time: 0.67226
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 4.94393

Cumulative Model Updates: 56,862
Cumulative Timesteps: 948,457,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,890.00513
Policy Entropy: 1.08754
Value Function Loss: 2.62506

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.08810

Collected Steps per Second: 12,005.48626
Overall Steps per Second: 10,116.12019

Timestep Collection Time: 4.16626
Timestep Consumption Time: 0.77812
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.94439

Cumulative Model Updates: 56,865
Cumulative Timesteps: 948,508,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948508016...
Checkpoint 948508016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,123.71722
Policy Entropy: 1.08054
Value Function Loss: 2.59198

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.17797
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 11,206.62074
Overall Steps per Second: 9,507.25537

Timestep Collection Time: 4.46201
Timestep Consumption Time: 0.79756
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.25956

Cumulative Model Updates: 56,868
Cumulative Timesteps: 948,558,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,045.40565
Policy Entropy: 1.08215
Value Function Loss: 2.59146

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.07921

Collected Steps per Second: 11,913.55591
Overall Steps per Second: 10,291.48403

Timestep Collection Time: 4.19875
Timestep Consumption Time: 0.66178
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.86052

Cumulative Model Updates: 56,871
Cumulative Timesteps: 948,608,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 948608042...
Checkpoint 948608042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,222.53978
Policy Entropy: 1.09310
Value Function Loss: 2.58282

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.16066
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.08592

Collected Steps per Second: 11,859.59311
Overall Steps per Second: 9,987.97901

Timestep Collection Time: 4.21836
Timestep Consumption Time: 0.79046
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.00882

Cumulative Model Updates: 56,874
Cumulative Timesteps: 948,658,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,028.52716
Policy Entropy: 1.07186
Value Function Loss: 2.65768

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 11,756.49180
Overall Steps per Second: 9,961.29216

Timestep Collection Time: 4.25467
Timestep Consumption Time: 0.76677
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.02144

Cumulative Model Updates: 56,877
Cumulative Timesteps: 948,708,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 948708090...
Checkpoint 948708090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,080.65751
Policy Entropy: 1.08897
Value Function Loss: 2.83888

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.17019
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 12,113.54385
Overall Steps per Second: 10,117.01170

Timestep Collection Time: 4.12910
Timestep Consumption Time: 0.81485
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.94395

Cumulative Model Updates: 56,880
Cumulative Timesteps: 948,758,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,316.80203
Policy Entropy: 1.08589
Value Function Loss: 3.03829

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.08800

Collected Steps per Second: 11,926.70844
Overall Steps per Second: 10,015.33086

Timestep Collection Time: 4.19244
Timestep Consumption Time: 0.80011
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 4.99255

Cumulative Model Updates: 56,883
Cumulative Timesteps: 948,808,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 948808110...
Checkpoint 948808110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,027.40565
Policy Entropy: 1.07148
Value Function Loss: 3.05577

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.08764

Collected Steps per Second: 11,482.62863
Overall Steps per Second: 9,951.68208

Timestep Collection Time: 4.35475
Timestep Consumption Time: 0.66993
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.02468

Cumulative Model Updates: 56,886
Cumulative Timesteps: 948,858,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,665.80441
Policy Entropy: 1.06291
Value Function Loss: 2.77848

Mean KL Divergence: 0.02903
SB3 Clip Fraction: 0.19937
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 12,078.10394
Overall Steps per Second: 10,123.82051

Timestep Collection Time: 4.13989
Timestep Consumption Time: 0.79916
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 4.93904

Cumulative Model Updates: 56,889
Cumulative Timesteps: 948,908,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 948908116...
Checkpoint 948908116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,837.33558
Policy Entropy: 1.07419
Value Function Loss: 2.68008

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11,717.41377
Overall Steps per Second: 9,974.89938

Timestep Collection Time: 4.26749
Timestep Consumption Time: 0.74549
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.01298

Cumulative Model Updates: 56,892
Cumulative Timesteps: 948,958,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,725.09853
Policy Entropy: 1.08363
Value Function Loss: 2.66862

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.08469

Collected Steps per Second: 12,076.81908
Overall Steps per Second: 10,389.33092

Timestep Collection Time: 4.14165
Timestep Consumption Time: 0.67271
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.81436

Cumulative Model Updates: 56,895
Cumulative Timesteps: 949,008,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949008138...
Checkpoint 949008138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,053.53009
Policy Entropy: 1.06742
Value Function Loss: 2.84259

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 12,269.61017
Overall Steps per Second: 10,352.54792

Timestep Collection Time: 4.07527
Timestep Consumption Time: 0.75465
PPO Batch Consumption Time: 0.03653
Total Iteration Time: 4.82992

Cumulative Model Updates: 56,898
Cumulative Timesteps: 949,058,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,270.54474
Policy Entropy: 1.05537
Value Function Loss: 2.80698

Mean KL Divergence: 0.03268
SB3 Clip Fraction: 0.18820
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.07861

Collected Steps per Second: 11,978.74276
Overall Steps per Second: 10,168.32143

Timestep Collection Time: 4.17473
Timestep Consumption Time: 0.74329
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.91802

Cumulative Model Updates: 56,901
Cumulative Timesteps: 949,108,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 949108148...
Checkpoint 949108148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,389.48636
Policy Entropy: 1.06776
Value Function Loss: 2.67561

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11,575.14900
Overall Steps per Second: 9,840.34789

Timestep Collection Time: 4.32202
Timestep Consumption Time: 0.76195
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.08397

Cumulative Model Updates: 56,904
Cumulative Timesteps: 949,158,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,827.70452
Policy Entropy: 1.07642
Value Function Loss: 2.57943

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.09285

Collected Steps per Second: 11,903.90269
Overall Steps per Second: 10,178.21314

Timestep Collection Time: 4.20232
Timestep Consumption Time: 0.71249
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.91481

Cumulative Model Updates: 56,907
Cumulative Timesteps: 949,208,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 949208200...
Checkpoint 949208200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,404.60254
Policy Entropy: 1.04956
Value Function Loss: 2.55641

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.10298

Collected Steps per Second: 12,082.56648
Overall Steps per Second: 10,313.96357

Timestep Collection Time: 4.13902
Timestep Consumption Time: 0.70975
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 4.84877

Cumulative Model Updates: 56,910
Cumulative Timesteps: 949,258,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,137.42839
Policy Entropy: 1.06837
Value Function Loss: 2.79441

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.10287

Collected Steps per Second: 11,798.18958
Overall Steps per Second: 9,965.31724

Timestep Collection Time: 4.23946
Timestep Consumption Time: 0.77974
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.01921

Cumulative Model Updates: 56,913
Cumulative Timesteps: 949,308,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949308228...
Checkpoint 949308228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765,826.36092
Policy Entropy: 1.07061
Value Function Loss: 2.87344

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.17017
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 11,893.92631
Overall Steps per Second: 10,107.72676

Timestep Collection Time: 4.20484
Timestep Consumption Time: 0.74306
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.94790

Cumulative Model Updates: 56,916
Cumulative Timesteps: 949,358,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,847.32812
Policy Entropy: 1.06621
Value Function Loss: 2.94915

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 12,103.19976
Overall Steps per Second: 10,219.04890

Timestep Collection Time: 4.13312
Timestep Consumption Time: 0.76205
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.89517

Cumulative Model Updates: 56,919
Cumulative Timesteps: 949,408,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 949408264...
Checkpoint 949408264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,448.24009
Policy Entropy: 1.05824
Value Function Loss: 2.67544

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.18850
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.10557

Collected Steps per Second: 11,324.23776
Overall Steps per Second: 9,582.75728

Timestep Collection Time: 4.41654
Timestep Consumption Time: 0.80262
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.21917

Cumulative Model Updates: 56,922
Cumulative Timesteps: 949,458,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,379.20264
Policy Entropy: 1.06601
Value Function Loss: 2.62551

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.10106

Collected Steps per Second: 11,964.51006
Overall Steps per Second: 10,117.07798

Timestep Collection Time: 4.17953
Timestep Consumption Time: 0.76320
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.94273

Cumulative Model Updates: 56,925
Cumulative Timesteps: 949,508,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 949508284...
Checkpoint 949508284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753,401.11153
Policy Entropy: 1.07924
Value Function Loss: 2.53860

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 12,212.70158
Overall Steps per Second: 10,111.29400

Timestep Collection Time: 4.09426
Timestep Consumption Time: 0.85090
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 4.94516

Cumulative Model Updates: 56,928
Cumulative Timesteps: 949,558,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564,890.55094
Policy Entropy: 1.05004
Value Function Loss: 2.65202

Mean KL Divergence: 0.03259
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.09599

Collected Steps per Second: 11,896.43611
Overall Steps per Second: 10,133.24861

Timestep Collection Time: 4.20395
Timestep Consumption Time: 0.73149
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.93544

Cumulative Model Updates: 56,931
Cumulative Timesteps: 949,608,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 949608298...
Checkpoint 949608298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,695.24312
Policy Entropy: 1.06936
Value Function Loss: 2.65707

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 11,556.92162
Overall Steps per Second: 9,989.05904

Timestep Collection Time: 4.32849
Timestep Consumption Time: 0.67939
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.00788

Cumulative Model Updates: 56,934
Cumulative Timesteps: 949,658,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,572.04566
Policy Entropy: 1.06328
Value Function Loss: 2.66601

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.10929

Collected Steps per Second: 11,621.10323
Overall Steps per Second: 9,885.03737

Timestep Collection Time: 4.30303
Timestep Consumption Time: 0.75572
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.05876

Cumulative Model Updates: 56,937
Cumulative Timesteps: 949,708,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 949708328...
Checkpoint 949708328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,596.08924
Policy Entropy: 1.05697
Value Function Loss: 2.72201

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.09924

Collected Steps per Second: 11,462.08642
Overall Steps per Second: 9,757.83801

Timestep Collection Time: 4.36308
Timestep Consumption Time: 0.76203
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.12511

Cumulative Model Updates: 56,940
Cumulative Timesteps: 949,758,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,033.89300
Policy Entropy: 1.05533
Value Function Loss: 2.78859

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.08760

Collected Steps per Second: 11,849.71968
Overall Steps per Second: 10,035.94498

Timestep Collection Time: 4.22035
Timestep Consumption Time: 0.76274
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.98309

Cumulative Model Updates: 56,943
Cumulative Timesteps: 949,808,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 949808348...
Checkpoint 949808348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,489.69655
Policy Entropy: 1.05765
Value Function Loss: 2.81731

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 11,896.38808
Overall Steps per Second: 9,960.55934

Timestep Collection Time: 4.20329
Timestep Consumption Time: 0.81691
PPO Batch Consumption Time: 0.03659
Total Iteration Time: 5.02020

Cumulative Model Updates: 56,946
Cumulative Timesteps: 949,858,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,044.25668
Policy Entropy: 1.06570
Value Function Loss: 2.73208

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 11,727.26853
Overall Steps per Second: 10,112.91945

Timestep Collection Time: 4.26510
Timestep Consumption Time: 0.68085
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 4.94595

Cumulative Model Updates: 56,949
Cumulative Timesteps: 949,908,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949908370...
Checkpoint 949908370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,795.45655
Policy Entropy: 1.05954
Value Function Loss: 2.68953

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 11,885.07790
Overall Steps per Second: 10,062.56797

Timestep Collection Time: 4.20864
Timestep Consumption Time: 0.76226
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 4.97090

Cumulative Model Updates: 56,952
Cumulative Timesteps: 949,958,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,170.32428
Policy Entropy: 1.05606
Value Function Loss: 2.71364

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 11,533.50500
Overall Steps per Second: 9,948.88756

Timestep Collection Time: 4.33762
Timestep Consumption Time: 0.69088
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.02850

Cumulative Model Updates: 56,955
Cumulative Timesteps: 950,008,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 950008418...
Checkpoint 950008418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,806.63657
Policy Entropy: 1.05502
Value Function Loss: 2.69592

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.07365
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 11,407.37776
Overall Steps per Second: 9,683.22858

Timestep Collection Time: 4.38541
Timestep Consumption Time: 0.78084
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.16625

Cumulative Model Updates: 56,958
Cumulative Timesteps: 950,058,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,610.45920
Policy Entropy: 1.04664
Value Function Loss: 2.68990

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.06232

Collected Steps per Second: 11,916.48786
Overall Steps per Second: 10,002.56783

Timestep Collection Time: 4.19755
Timestep Consumption Time: 0.80317
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 5.00072

Cumulative Model Updates: 56,961
Cumulative Timesteps: 950,108,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950108464...
Checkpoint 950108464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,310.00681
Policy Entropy: 1.06109
Value Function Loss: 2.79072

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 12,407.45195
Overall Steps per Second: 10,672.98819

Timestep Collection Time: 4.03177
Timestep Consumption Time: 0.65520
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.68697

Cumulative Model Updates: 56,964
Cumulative Timesteps: 950,158,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,649.00612
Policy Entropy: 1.06272
Value Function Loss: 2.81597

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 12,685.32917
Overall Steps per Second: 10,508.92326

Timestep Collection Time: 3.94408
Timestep Consumption Time: 0.81682
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.76091

Cumulative Model Updates: 56,967
Cumulative Timesteps: 950,208,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 950208520...
Checkpoint 950208520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,089.62867
Policy Entropy: 1.05052
Value Function Loss: 2.77632

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.08077

Collected Steps per Second: 12,653.70417
Overall Steps per Second: 10,556.05748

Timestep Collection Time: 3.95220
Timestep Consumption Time: 0.78536
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.73756

Cumulative Model Updates: 56,970
Cumulative Timesteps: 950,258,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,914.05923
Policy Entropy: 1.03884
Value Function Loss: 2.68569

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.19916
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 12,669.56342
Overall Steps per Second: 10,449.67610

Timestep Collection Time: 3.94647
Timestep Consumption Time: 0.83837
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.78484

Cumulative Model Updates: 56,973
Cumulative Timesteps: 950,308,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 950308530...
Checkpoint 950308530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,811.87188
Policy Entropy: 1.05496
Value Function Loss: 2.73467

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.08289

Collected Steps per Second: 12,045.70655
Overall Steps per Second: 10,038.14398

Timestep Collection Time: 4.15302
Timestep Consumption Time: 0.83058
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.98359

Cumulative Model Updates: 56,976
Cumulative Timesteps: 950,358,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806,549.33980
Policy Entropy: 1.04514
Value Function Loss: 2.92953

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 12,198.24838
Overall Steps per Second: 10,494.17225

Timestep Collection Time: 4.10075
Timestep Consumption Time: 0.66589
PPO Batch Consumption Time: 0.03331
Total Iteration Time: 4.76665

Cumulative Model Updates: 56,979
Cumulative Timesteps: 950,408,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 950408578...
Checkpoint 950408578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,398.72834
Policy Entropy: 1.04392
Value Function Loss: 2.92133

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 12,234.94578
Overall Steps per Second: 10,172.76767

Timestep Collection Time: 4.08911
Timestep Consumption Time: 0.82893
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.91803

Cumulative Model Updates: 56,982
Cumulative Timesteps: 950,458,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781,030.52056
Policy Entropy: 1.03401
Value Function Loss: 2.86227

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.07164
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 11,940.56648
Overall Steps per Second: 10,162.01869

Timestep Collection Time: 4.18841
Timestep Consumption Time: 0.73305
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.92146

Cumulative Model Updates: 56,985
Cumulative Timesteps: 950,508,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 950508620...
Checkpoint 950508620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,955.93244
Policy Entropy: 1.05033
Value Function Loss: 2.67437

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.09131

Collected Steps per Second: 11,850.85003
Overall Steps per Second: 10,133.20908

Timestep Collection Time: 4.21928
Timestep Consumption Time: 0.71519
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 4.93447

Cumulative Model Updates: 56,988
Cumulative Timesteps: 950,558,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,577.07734
Policy Entropy: 1.04744
Value Function Loss: 2.55796

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 11,982.02352
Overall Steps per Second: 10,063.69935

Timestep Collection Time: 4.17525
Timestep Consumption Time: 0.79588
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.97113

Cumulative Model Updates: 56,991
Cumulative Timesteps: 950,608,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 950608650...
Checkpoint 950608650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,664.17284
Policy Entropy: 1.03737
Value Function Loss: 2.54255

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.10087

Collected Steps per Second: 11,628.93952
Overall Steps per Second: 9,838.69228

Timestep Collection Time: 4.29962
Timestep Consumption Time: 0.78236
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.08198

Cumulative Model Updates: 56,994
Cumulative Timesteps: 950,658,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579,794.64793
Policy Entropy: 1.03326
Value Function Loss: 2.58971

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 12,132.47779
Overall Steps per Second: 10,125.35205

Timestep Collection Time: 4.12183
Timestep Consumption Time: 0.81706
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.93889

Cumulative Model Updates: 56,997
Cumulative Timesteps: 950,708,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 950708658...
Checkpoint 950708658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,131.06590
Policy Entropy: 1.03951
Value Function Loss: 2.66265

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.09221

Collected Steps per Second: 11,955.11732
Overall Steps per Second: 10,049.47452

Timestep Collection Time: 4.18315
Timestep Consumption Time: 0.79323
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.97638

Cumulative Model Updates: 57,000
Cumulative Timesteps: 950,758,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,965.93655
Policy Entropy: 1.05554
Value Function Loss: 2.70439

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16007
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 11,951.13526
Overall Steps per Second: 10,305.43178

Timestep Collection Time: 4.18487
Timestep Consumption Time: 0.66829
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 4.85317

Cumulative Model Updates: 57,003
Cumulative Timesteps: 950,808,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 950808682...
Checkpoint 950808682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,617.74714
Policy Entropy: 1.03661
Value Function Loss: 2.69018

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.09400

Collected Steps per Second: 11,590.79825
Overall Steps per Second: 9,769.58637

Timestep Collection Time: 4.31635
Timestep Consumption Time: 0.80464
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 5.12099

Cumulative Model Updates: 57,006
Cumulative Timesteps: 950,858,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,133.00036
Policy Entropy: 1.06627
Value Function Loss: 2.74787

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.16611
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.09216

Collected Steps per Second: 11,660.49801
Overall Steps per Second: 9,901.84093

Timestep Collection Time: 4.28867
Timestep Consumption Time: 0.76171
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 5.05037

Cumulative Model Updates: 57,009
Cumulative Timesteps: 950,908,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 950908720...
Checkpoint 950908720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784,716.32964
Policy Entropy: 1.06011
Value Function Loss: 2.82803

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.17065
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 11,549.16969
Overall Steps per Second: 9,906.60306

Timestep Collection Time: 4.32966
Timestep Consumption Time: 0.71788
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.04754

Cumulative Model Updates: 57,012
Cumulative Timesteps: 950,958,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,408.21535
Policy Entropy: 1.05429
Value Function Loss: 2.86923

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.10784

Collected Steps per Second: 11,739.20826
Overall Steps per Second: 9,846.39793

Timestep Collection Time: 4.25991
Timestep Consumption Time: 0.81890
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 5.07881

Cumulative Model Updates: 57,015
Cumulative Timesteps: 951,008,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 951008732...
Checkpoint 951008732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,026.49465
Policy Entropy: 1.04104
Value Function Loss: 2.86148

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.17738
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 11,861.74452
Overall Steps per Second: 10,020.31917

Timestep Collection Time: 4.21574
Timestep Consumption Time: 0.77472
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 4.99046

Cumulative Model Updates: 57,018
Cumulative Timesteps: 951,058,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,120.60170
Policy Entropy: 1.06207
Value Function Loss: 2.73505

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 12,113.51253
Overall Steps per Second: 10,089.63048

Timestep Collection Time: 4.12993
Timestep Consumption Time: 0.82842
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.95836

Cumulative Model Updates: 57,021
Cumulative Timesteps: 951,108,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 951108766...
Checkpoint 951108766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,127.97558
Policy Entropy: 1.05042
Value Function Loss: 2.69201

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.09779

Collected Steps per Second: 11,770.59344
Overall Steps per Second: 9,877.43268

Timestep Collection Time: 4.24804
Timestep Consumption Time: 0.81420
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.06225

Cumulative Model Updates: 57,024
Cumulative Timesteps: 951,158,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,450.02765
Policy Entropy: 1.05026
Value Function Loss: 2.65799

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 11,869.71248
Overall Steps per Second: 10,200.85776

Timestep Collection Time: 4.21459
Timestep Consumption Time: 0.68950
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 4.90410

Cumulative Model Updates: 57,027
Cumulative Timesteps: 951,208,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 951208794...
Checkpoint 951208794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,074.09514
Policy Entropy: 1.05393
Value Function Loss: 2.89094

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.10008

Collected Steps per Second: 11,561.06259
Overall Steps per Second: 9,686.71546

Timestep Collection Time: 4.32728
Timestep Consumption Time: 0.83731
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.16460

Cumulative Model Updates: 57,030
Cumulative Timesteps: 951,258,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600,355.91041
Policy Entropy: 1.06790
Value Function Loss: 2.91769

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.10051

Collected Steps per Second: 11,777.32714
Overall Steps per Second: 9,950.73158

Timestep Collection Time: 4.24680
Timestep Consumption Time: 0.77956
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.02636

Cumulative Model Updates: 57,033
Cumulative Timesteps: 951,308,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 951308838...
Checkpoint 951308838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,547.03870
Policy Entropy: 1.06481
Value Function Loss: 3.05748

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 11,935.76627
Overall Steps per Second: 10,120.02155

Timestep Collection Time: 4.18943
Timestep Consumption Time: 0.75167
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 4.94110

Cumulative Model Updates: 57,036
Cumulative Timesteps: 951,358,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792,175.95246
Policy Entropy: 1.06014
Value Function Loss: 2.92042

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.10639

Collected Steps per Second: 12,148.79218
Overall Steps per Second: 10,087.29057

Timestep Collection Time: 4.11778
Timestep Consumption Time: 0.84153
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 4.95931

Cumulative Model Updates: 57,039
Cumulative Timesteps: 951,408,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 951408868...
Checkpoint 951408868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,491.01815
Policy Entropy: 1.05368
Value Function Loss: 2.82169

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.08282
Value Function Update Magnitude: 0.10165

Collected Steps per Second: 11,677.61908
Overall Steps per Second: 9,960.86011

Timestep Collection Time: 4.28341
Timestep Consumption Time: 0.73825
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.02165

Cumulative Model Updates: 57,042
Cumulative Timesteps: 951,458,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,485.60238
Policy Entropy: 1.05876
Value Function Loss: 2.72818

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.08449
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 12,557.33038
Overall Steps per Second: 10,494.49480

Timestep Collection Time: 3.98349
Timestep Consumption Time: 0.78301
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.76650

Cumulative Model Updates: 57,045
Cumulative Timesteps: 951,508,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 951508910...
Checkpoint 951508910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,654.45381
Policy Entropy: 1.04794
Value Function Loss: 2.67595

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.08377
Value Function Update Magnitude: 0.09235

Collected Steps per Second: 11,682.21680
Overall Steps per Second: 9,761.65094

Timestep Collection Time: 4.28206
Timestep Consumption Time: 0.84248
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.12454

Cumulative Model Updates: 57,048
Cumulative Timesteps: 951,558,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,949.63931
Policy Entropy: 1.05285
Value Function Loss: 2.73191

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 12,074.10331
Overall Steps per Second: 10,384.10084

Timestep Collection Time: 4.14159
Timestep Consumption Time: 0.67404
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.81563

Cumulative Model Updates: 57,051
Cumulative Timesteps: 951,608,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 951608940...
Checkpoint 951608940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,784.81323
Policy Entropy: 1.05941
Value Function Loss: 2.72385

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.07150
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 11,881.85423
Overall Steps per Second: 10,047.36056

Timestep Collection Time: 4.20944
Timestep Consumption Time: 0.76858
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.97802

Cumulative Model Updates: 57,054
Cumulative Timesteps: 951,658,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,338.33934
Policy Entropy: 1.05639
Value Function Loss: 2.83070

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 11,949.46134
Overall Steps per Second: 10,096.61305

Timestep Collection Time: 4.18446
Timestep Consumption Time: 0.76790
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.95235

Cumulative Model Updates: 57,057
Cumulative Timesteps: 951,708,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 951708958...
Checkpoint 951708958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,616.80528
Policy Entropy: 1.04332
Value Function Loss: 2.93700

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 11,869.24103
Overall Steps per Second: 10,230.11794

Timestep Collection Time: 4.21442
Timestep Consumption Time: 0.67526
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.88968

Cumulative Model Updates: 57,060
Cumulative Timesteps: 951,758,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,187.96831
Policy Entropy: 1.02879
Value Function Loss: 2.91889

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.17121
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 11,665.05793
Overall Steps per Second: 9,848.56100

Timestep Collection Time: 4.28785
Timestep Consumption Time: 0.79086
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.07871

Cumulative Model Updates: 57,063
Cumulative Timesteps: 951,808,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 951808998...
Checkpoint 951808998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,759.68468
Policy Entropy: 1.04025
Value Function Loss: 2.78205

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.08442

Collected Steps per Second: 11,675.60889
Overall Steps per Second: 10,014.81212

Timestep Collection Time: 4.28260
Timestep Consumption Time: 0.71020
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.99280

Cumulative Model Updates: 57,066
Cumulative Timesteps: 951,859,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777,174.89622
Policy Entropy: 1.05332
Value Function Loss: 2.68013

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.08268

Collected Steps per Second: 11,981.44027
Overall Steps per Second: 10,074.54275

Timestep Collection Time: 4.17312
Timestep Consumption Time: 0.78988
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.96300

Cumulative Model Updates: 57,069
Cumulative Timesteps: 951,909,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 951909000...
Checkpoint 951909000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,537.25692
Policy Entropy: 1.03626
Value Function Loss: 2.64493

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.08390

Collected Steps per Second: 11,954.63946
Overall Steps per Second: 10,036.84315

Timestep Collection Time: 4.18515
Timestep Consumption Time: 0.79968
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 4.98483

Cumulative Model Updates: 57,072
Cumulative Timesteps: 951,959,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,653.31773
Policy Entropy: 1.04891
Value Function Loss: 2.75024

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16943
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 12,011.26884
Overall Steps per Second: 10,327.35827

Timestep Collection Time: 4.16526
Timestep Consumption Time: 0.67916
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 4.84441

Cumulative Model Updates: 57,075
Cumulative Timesteps: 952,009,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952009062...
Checkpoint 952009062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,907.97194
Policy Entropy: 1.04768
Value Function Loss: 2.79977

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.16945
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.09142

Collected Steps per Second: 11,773.34364
Overall Steps per Second: 10,011.56997

Timestep Collection Time: 4.24688
Timestep Consumption Time: 0.74734
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.99422

Cumulative Model Updates: 57,078
Cumulative Timesteps: 952,059,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,754.44669
Policy Entropy: 1.03298
Value Function Loss: 2.82211

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 11,922.23260
Overall Steps per Second: 10,162.63632

Timestep Collection Time: 4.19519
Timestep Consumption Time: 0.72637
PPO Batch Consumption Time: 0.03359
Total Iteration Time: 4.92156

Cumulative Model Updates: 57,081
Cumulative Timesteps: 952,109,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 952109078...
Checkpoint 952109078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,137.15508
Policy Entropy: 1.03170
Value Function Loss: 2.83886

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.08664

Collected Steps per Second: 11,857.29162
Overall Steps per Second: 9,876.31267

Timestep Collection Time: 4.21783
Timestep Consumption Time: 0.84601
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.06383

Cumulative Model Updates: 57,084
Cumulative Timesteps: 952,159,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,855.78733
Policy Entropy: 1.04459
Value Function Loss: 2.80075

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 11,904.19735
Overall Steps per Second: 10,044.68119

Timestep Collection Time: 4.20054
Timestep Consumption Time: 0.77762
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.97816

Cumulative Model Updates: 57,087
Cumulative Timesteps: 952,209,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 952209094...
Checkpoint 952209094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,438.69416
Policy Entropy: 1.04877
Value Function Loss: 2.82125

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.08708

Collected Steps per Second: 11,832.10386
Overall Steps per Second: 10,158.49379

Timestep Collection Time: 4.22596
Timestep Consumption Time: 0.69623
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.92219

Cumulative Model Updates: 57,090
Cumulative Timesteps: 952,259,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,749.58150
Policy Entropy: 1.03489
Value Function Loss: 2.74572

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.09952

Collected Steps per Second: 11,893.60357
Overall Steps per Second: 9,940.61174

Timestep Collection Time: 4.20495
Timestep Consumption Time: 0.82613
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.03108

Cumulative Model Updates: 57,093
Cumulative Timesteps: 952,309,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 952309108...
Checkpoint 952309108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,692.06406
Policy Entropy: 1.03279
Value Function Loss: 2.75385

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.15854
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 11,697.63870
Overall Steps per Second: 9,962.37117

Timestep Collection Time: 4.27659
Timestep Consumption Time: 0.74491
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.02150

Cumulative Model Updates: 57,096
Cumulative Timesteps: 952,359,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,622.94060
Policy Entropy: 1.03868
Value Function Loss: 2.78161

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.11414

Collected Steps per Second: 12,206.63602
Overall Steps per Second: 10,286.24145

Timestep Collection Time: 4.09859
Timestep Consumption Time: 0.76519
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.86378

Cumulative Model Updates: 57,099
Cumulative Timesteps: 952,409,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952409164...
Checkpoint 952409164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,238.12526
Policy Entropy: 1.04421
Value Function Loss: 2.74383

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.11928

Collected Steps per Second: 11,962.57906
Overall Steps per Second: 9,997.96666

Timestep Collection Time: 4.18104
Timestep Consumption Time: 0.82158
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.00262

Cumulative Model Updates: 57,102
Cumulative Timesteps: 952,459,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,436.28854
Policy Entropy: 1.05651
Value Function Loss: 2.73266

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.10982

Collected Steps per Second: 11,706.85150
Overall Steps per Second: 10,106.38646

Timestep Collection Time: 4.27152
Timestep Consumption Time: 0.67644
PPO Batch Consumption Time: 0.03282
Total Iteration Time: 4.94796

Cumulative Model Updates: 57,105
Cumulative Timesteps: 952,509,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 952509186...
Checkpoint 952509186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,321.93335
Policy Entropy: 1.04976
Value Function Loss: 2.75022

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14203
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 11,960.50518
Overall Steps per Second: 10,038.74625

Timestep Collection Time: 4.18310
Timestep Consumption Time: 0.80079
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.98389

Cumulative Model Updates: 57,108
Cumulative Timesteps: 952,559,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,069.98811
Policy Entropy: 1.04702
Value Function Loss: 2.78579

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.08960

Collected Steps per Second: 12,722.94818
Overall Steps per Second: 10,567.83984

Timestep Collection Time: 3.93226
Timestep Consumption Time: 0.80191
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.73417

Cumulative Model Updates: 57,111
Cumulative Timesteps: 952,609,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952609248...
Checkpoint 952609248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,291.99665
Policy Entropy: 1.05863
Value Function Loss: 2.86312

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.08833

Collected Steps per Second: 12,694.25840
Overall Steps per Second: 10,810.64798

Timestep Collection Time: 3.94099
Timestep Consumption Time: 0.68667
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.62766

Cumulative Model Updates: 57,114
Cumulative Timesteps: 952,659,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,111.41051
Policy Entropy: 1.05872
Value Function Loss: 2.89139

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 12,727.80138
Overall Steps per Second: 10,568.36377

Timestep Collection Time: 3.93077
Timestep Consumption Time: 0.80317
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.73394

Cumulative Model Updates: 57,117
Cumulative Timesteps: 952,709,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952709306...
Checkpoint 952709306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,415.12042
Policy Entropy: 1.05317
Value Function Loss: 2.98869

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 12,482.48938
Overall Steps per Second: 10,619.87593

Timestep Collection Time: 4.00785
Timestep Consumption Time: 0.70294
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.71079

Cumulative Model Updates: 57,120
Cumulative Timesteps: 952,759,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,102.53906
Policy Entropy: 1.05355
Value Function Loss: 2.97727

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.07894
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 11,929.73480
Overall Steps per Second: 10,111.81453

Timestep Collection Time: 4.19188
Timestep Consumption Time: 0.75362
PPO Batch Consumption Time: 0.03335
Total Iteration Time: 4.94550

Cumulative Model Updates: 57,123
Cumulative Timesteps: 952,809,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 952809342...
Checkpoint 952809342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,615.38405
Policy Entropy: 1.05219
Value Function Loss: 2.98139

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.07949
Value Function Update Magnitude: 0.10904

Collected Steps per Second: 12,560.32416
Overall Steps per Second: 10,485.83876

Timestep Collection Time: 3.98190
Timestep Consumption Time: 0.78777
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.76967

Cumulative Model Updates: 57,126
Cumulative Timesteps: 952,859,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,617.44013
Policy Entropy: 1.06527
Value Function Loss: 2.80594

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.12039

Collected Steps per Second: 11,404.28028
Overall Steps per Second: 9,866.54498

Timestep Collection Time: 4.38537
Timestep Consumption Time: 0.68348
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.06885

Cumulative Model Updates: 57,129
Cumulative Timesteps: 952,909,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 952909368...
Checkpoint 952909368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,816.54123
Policy Entropy: 1.06254
Value Function Loss: 2.72897

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.07635
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 11,852.07490
Overall Steps per Second: 9,943.05353

Timestep Collection Time: 4.21901
Timestep Consumption Time: 0.81003
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 5.02904

Cumulative Model Updates: 57,132
Cumulative Timesteps: 952,959,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,671.16624
Policy Entropy: 1.06522
Value Function Loss: 2.77306

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.07677
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 11,898.90754
Overall Steps per Second: 10,098.28134

Timestep Collection Time: 4.20240
Timestep Consumption Time: 0.74933
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.95173

Cumulative Model Updates: 57,135
Cumulative Timesteps: 953,009,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 953009376...
Checkpoint 953009376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,911.96203
Policy Entropy: 1.05096
Value Function Loss: 2.80528

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.18242
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.08191

Collected Steps per Second: 11,675.19218
Overall Steps per Second: 10,027.55835

Timestep Collection Time: 4.28498
Timestep Consumption Time: 0.70407
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.98905

Cumulative Model Updates: 57,138
Cumulative Timesteps: 953,059,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,953.19697
Policy Entropy: 1.06474
Value Function Loss: 2.92828

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 11,420.55420
Overall Steps per Second: 9,696.69648

Timestep Collection Time: 4.38000
Timestep Consumption Time: 0.77867
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.15866

Cumulative Model Updates: 57,141
Cumulative Timesteps: 953,109,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 953109426...
Checkpoint 953109426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768,051.99182
Policy Entropy: 1.06046
Value Function Loss: 2.83464

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.11069

Collected Steps per Second: 11,964.99526
Overall Steps per Second: 10,175.95819

Timestep Collection Time: 4.18086
Timestep Consumption Time: 0.73504
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 4.91590

Cumulative Model Updates: 57,144
Cumulative Timesteps: 953,159,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,297.32568
Policy Entropy: 1.04170
Value Function Loss: 2.80036

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.16402
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 12,233.24638
Overall Steps per Second: 10,294.14395

Timestep Collection Time: 4.08886
Timestep Consumption Time: 0.77022
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 4.85907

Cumulative Model Updates: 57,147
Cumulative Timesteps: 953,209,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 953209470...
Checkpoint 953209470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,218.46742
Policy Entropy: 1.03201
Value Function Loss: 2.64996

Mean KL Divergence: 0.03131
SB3 Clip Fraction: 0.20874
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.10189

Collected Steps per Second: 11,830.55940
Overall Steps per Second: 9,949.29512

Timestep Collection Time: 4.22685
Timestep Consumption Time: 0.79923
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.02608

Cumulative Model Updates: 57,150
Cumulative Timesteps: 953,259,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,756.90709
Policy Entropy: 1.04887
Value Function Loss: 2.73929

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.09847

Collected Steps per Second: 11,921.58584
Overall Steps per Second: 10,249.69412

Timestep Collection Time: 4.19676
Timestep Consumption Time: 0.68456
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.88132

Cumulative Model Updates: 57,153
Cumulative Timesteps: 953,309,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 953309508...
Checkpoint 953309508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,134.86431
Policy Entropy: 1.05804
Value Function Loss: 2.90368

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.17617
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.08634

Collected Steps per Second: 11,875.25301
Overall Steps per Second: 9,926.21123

Timestep Collection Time: 4.21229
Timestep Consumption Time: 0.82710
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.03939

Cumulative Model Updates: 57,156
Cumulative Timesteps: 953,359,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,771.35617
Policy Entropy: 1.03390
Value Function Loss: 3.05161

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.09045

Collected Steps per Second: 11,338.11985
Overall Steps per Second: 9,737.00489

Timestep Collection Time: 4.41114
Timestep Consumption Time: 0.72535
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.13649

Cumulative Model Updates: 57,159
Cumulative Timesteps: 953,409,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 953409544...
Checkpoint 953409544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,261.03937
Policy Entropy: 1.04383
Value Function Loss: 2.97090

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.17199
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.08672

Collected Steps per Second: 11,887.66967
Overall Steps per Second: 10,160.13477

Timestep Collection Time: 4.20722
Timestep Consumption Time: 0.71536
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.92257

Cumulative Model Updates: 57,162
Cumulative Timesteps: 953,459,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629,856.74870
Policy Entropy: 1.04866
Value Function Loss: 2.85606

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.18313
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 11,800.86382
Overall Steps per Second: 9,916.98491

Timestep Collection Time: 4.23833
Timestep Consumption Time: 0.80513
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.04347

Cumulative Model Updates: 57,165
Cumulative Timesteps: 953,509,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 953509574...
Checkpoint 953509574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,293.57331
Policy Entropy: 1.03705
Value Function Loss: 2.92047

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 11,701.36960
Overall Steps per Second: 9,938.54738

Timestep Collection Time: 4.27488
Timestep Consumption Time: 0.75825
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.03313

Cumulative Model Updates: 57,168
Cumulative Timesteps: 953,559,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783,040.86932
Policy Entropy: 1.02268
Value Function Loss: 2.85341

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 11,791.84826
Overall Steps per Second: 9,959.29026

Timestep Collection Time: 4.24242
Timestep Consumption Time: 0.78063
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.02305

Cumulative Model Updates: 57,171
Cumulative Timesteps: 953,609,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 953609622...
Checkpoint 953609622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,046.14634
Policy Entropy: 1.03845
Value Function Loss: 2.84754

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.12082
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 11,739.37342
Overall Steps per Second: 9,924.44895

Timestep Collection Time: 4.26070
Timestep Consumption Time: 0.77917
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.03988

Cumulative Model Updates: 57,174
Cumulative Timesteps: 953,659,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,308.15078
Policy Entropy: 1.05399
Value Function Loss: 2.70220

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.10302

Collected Steps per Second: 11,409.91640
Overall Steps per Second: 9,858.50421

Timestep Collection Time: 4.38285
Timestep Consumption Time: 0.68972
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.07257

Cumulative Model Updates: 57,177
Cumulative Timesteps: 953,709,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 953709648...
Checkpoint 953709648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,846.04546
Policy Entropy: 1.03624
Value Function Loss: 2.75519

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 11,788.82883
Overall Steps per Second: 9,995.94188

Timestep Collection Time: 4.24385
Timestep Consumption Time: 0.76118
PPO Batch Consumption Time: 0.03317
Total Iteration Time: 5.00503

Cumulative Model Updates: 57,180
Cumulative Timesteps: 953,759,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,743.53722
Policy Entropy: 1.04847
Value Function Loss: 2.78734

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 12,086.28754
Overall Steps per Second: 10,249.28218

Timestep Collection Time: 4.13775
Timestep Consumption Time: 0.74162
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.87937

Cumulative Model Updates: 57,183
Cumulative Timesteps: 953,809,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 953809688...
Checkpoint 953809688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,085.42250
Policy Entropy: 1.05531
Value Function Loss: 2.62864

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 12,344.22035
Overall Steps per Second: 10,343.97822

Timestep Collection Time: 4.05242
Timestep Consumption Time: 0.78363
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.83605

Cumulative Model Updates: 57,186
Cumulative Timesteps: 953,859,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,410.02205
Policy Entropy: 1.06419
Value Function Loss: 2.55812

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.10293

Collected Steps per Second: 12,199.78085
Overall Steps per Second: 10,135.37593

Timestep Collection Time: 4.09942
Timestep Consumption Time: 0.83498
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.93440

Cumulative Model Updates: 57,189
Cumulative Timesteps: 953,909,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 953909724...
Checkpoint 953909724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756,262.87696
Policy Entropy: 1.04305
Value Function Loss: 2.57819

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.09078

Collected Steps per Second: 12,064.70615
Overall Steps per Second: 10,200.84091

Timestep Collection Time: 4.14647
Timestep Consumption Time: 0.75763
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.90411

Cumulative Model Updates: 57,192
Cumulative Timesteps: 953,959,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,958.76357
Policy Entropy: 1.02967
Value Function Loss: 2.75477

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.17415
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 11,474.78018
Overall Steps per Second: 9,773.70989

Timestep Collection Time: 4.35912
Timestep Consumption Time: 0.75869
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.11781

Cumulative Model Updates: 57,195
Cumulative Timesteps: 954,009,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 954009770...
Checkpoint 954009770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,071.49860
Policy Entropy: 1.03966
Value Function Loss: 2.84912

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 11,943.22505
Overall Steps per Second: 10,051.89560

Timestep Collection Time: 4.18731
Timestep Consumption Time: 0.78787
PPO Batch Consumption Time: 0.03643
Total Iteration Time: 4.97518

Cumulative Model Updates: 57,198
Cumulative Timesteps: 954,059,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,496.25520
Policy Entropy: 1.05009
Value Function Loss: 3.04748

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 12,132.33446
Overall Steps per Second: 10,164.53247

Timestep Collection Time: 4.12122
Timestep Consumption Time: 0.79785
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.91907

Cumulative Model Updates: 57,201
Cumulative Timesteps: 954,109,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 954109780...
Checkpoint 954109780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,644.05414
Policy Entropy: 1.03518
Value Function Loss: 3.02967

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.07447

Collected Steps per Second: 11,778.50004
Overall Steps per Second: 9,965.72203

Timestep Collection Time: 4.24553
Timestep Consumption Time: 0.77227
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 5.01780

Cumulative Model Updates: 57,204
Cumulative Timesteps: 954,159,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796,454.67753
Policy Entropy: 1.03989
Value Function Loss: 2.97976

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.15354
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.08645

Collected Steps per Second: 11,754.92304
Overall Steps per Second: 10,088.09361

Timestep Collection Time: 4.25439
Timestep Consumption Time: 0.70294
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.95733

Cumulative Model Updates: 57,207
Cumulative Timesteps: 954,209,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 954209796...
Checkpoint 954209796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,959.19891
Policy Entropy: 1.05178
Value Function Loss: 2.78191

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.09507

Collected Steps per Second: 11,831.90854
Overall Steps per Second: 9,948.61177

Timestep Collection Time: 4.22671
Timestep Consumption Time: 0.80013
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 5.02683

Cumulative Model Updates: 57,210
Cumulative Timesteps: 954,259,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,693.75637
Policy Entropy: 1.05135
Value Function Loss: 2.73942

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.10588

Collected Steps per Second: 11,435.36951
Overall Steps per Second: 9,721.40975

Timestep Collection Time: 4.37485
Timestep Consumption Time: 0.77132
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.14617

Cumulative Model Updates: 57,213
Cumulative Timesteps: 954,309,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 954309834...
Checkpoint 954309834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,849.92334
Policy Entropy: 1.04995
Value Function Loss: 2.62843

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 11,999.79658
Overall Steps per Second: 10,165.85677

Timestep Collection Time: 4.16674
Timestep Consumption Time: 0.75169
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.91842

Cumulative Model Updates: 57,216
Cumulative Timesteps: 954,359,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,081.37861
Policy Entropy: 1.04037
Value Function Loss: 2.67124

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.11559

Collected Steps per Second: 12,012.11616
Overall Steps per Second: 10,033.41442

Timestep Collection Time: 4.16380
Timestep Consumption Time: 0.82115
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.98494

Cumulative Model Updates: 57,219
Cumulative Timesteps: 954,409,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 954409850...
Checkpoint 954409850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,038.80503
Policy Entropy: 1.03219
Value Function Loss: 2.75080

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.10448

Collected Steps per Second: 11,705.13826
Overall Steps per Second: 10,081.65642

Timestep Collection Time: 4.27317
Timestep Consumption Time: 0.68812
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.96129

Cumulative Model Updates: 57,222
Cumulative Timesteps: 954,459,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,213.52396
Policy Entropy: 1.03973
Value Function Loss: 2.81610

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.09108

Collected Steps per Second: 11,851.01890
Overall Steps per Second: 10,004.86919

Timestep Collection Time: 4.21955
Timestep Consumption Time: 0.77861
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 4.99817

Cumulative Model Updates: 57,225
Cumulative Timesteps: 954,509,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 954509874...
Checkpoint 954509874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,531.81090
Policy Entropy: 1.04231
Value Function Loss: 2.74814

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 11,825.64755
Overall Steps per Second: 10,042.12261

Timestep Collection Time: 4.22827
Timestep Consumption Time: 0.75096
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.97923

Cumulative Model Updates: 57,228
Cumulative Timesteps: 954,559,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774,523.43824
Policy Entropy: 1.04972
Value Function Loss: 2.61248

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 11,634.89565
Overall Steps per Second: 9,879.97150

Timestep Collection Time: 4.29948
Timestep Consumption Time: 0.76369
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.06317

Cumulative Model Updates: 57,231
Cumulative Timesteps: 954,609,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 954609900...
Checkpoint 954609900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,111.36884
Policy Entropy: 1.05403
Value Function Loss: 2.59155

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.07060
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 12,058.31858
Overall Steps per Second: 10,048.99881

Timestep Collection Time: 4.14817
Timestep Consumption Time: 0.82944
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.97761

Cumulative Model Updates: 57,234
Cumulative Timesteps: 954,659,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,023.95530
Policy Entropy: 1.04907
Value Function Loss: 2.57060

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 11,647.39434
Overall Steps per Second: 9,950.59510

Timestep Collection Time: 4.29521
Timestep Consumption Time: 0.73243
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.02764

Cumulative Model Updates: 57,237
Cumulative Timesteps: 954,709,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 954709948...
Checkpoint 954709948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,305.21701
Policy Entropy: 1.04895
Value Function Loss: 2.68494

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 12,004.71780
Overall Steps per Second: 10,159.20199

Timestep Collection Time: 4.16703
Timestep Consumption Time: 0.75698
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.92401

Cumulative Model Updates: 57,240
Cumulative Timesteps: 954,759,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,795.23349
Policy Entropy: 1.04259
Value Function Loss: 2.74296

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.08115
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 11,825.73835
Overall Steps per Second: 10,151.11290

Timestep Collection Time: 4.22874
Timestep Consumption Time: 0.69761
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.92636

Cumulative Model Updates: 57,243
Cumulative Timesteps: 954,809,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 954809980...
Checkpoint 954809980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,480.42976
Policy Entropy: 1.06710
Value Function Loss: 2.82733

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.10285

Collected Steps per Second: 12,012.15367
Overall Steps per Second: 10,128.19933

Timestep Collection Time: 4.16345
Timestep Consumption Time: 0.77445
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 4.93790

Cumulative Model Updates: 57,246
Cumulative Timesteps: 954,859,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,582.21792
Policy Entropy: 1.06826
Value Function Loss: 2.89826

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.09746

Collected Steps per Second: 11,308.48277
Overall Steps per Second: 9,649.82684

Timestep Collection Time: 4.42199
Timestep Consumption Time: 0.76007
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.18206

Cumulative Model Updates: 57,249
Cumulative Timesteps: 954,909,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 954909998...
Checkpoint 954909998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,774.58705
Policy Entropy: 1.07032
Value Function Loss: 2.91435

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.09228

Collected Steps per Second: 12,183.95432
Overall Steps per Second: 10,079.57162

Timestep Collection Time: 4.10474
Timestep Consumption Time: 0.85698
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 4.96172

Cumulative Model Updates: 57,252
Cumulative Timesteps: 954,960,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,801.55026
Policy Entropy: 1.06077
Value Function Loss: 2.84819

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.09240

Collected Steps per Second: 12,984.01859
Overall Steps per Second: 10,797.08300

Timestep Collection Time: 3.85135
Timestep Consumption Time: 0.78009
PPO Batch Consumption Time: 0.03353
Total Iteration Time: 4.63144

Cumulative Model Updates: 57,255
Cumulative Timesteps: 955,010,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 955010016...
Checkpoint 955010016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,734.68553
Policy Entropy: 1.07653
Value Function Loss: 2.76017

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 12,397.19348
Overall Steps per Second: 10,534.06664

Timestep Collection Time: 4.03317
Timestep Consumption Time: 0.71333
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 4.74651

Cumulative Model Updates: 57,258
Cumulative Timesteps: 955,060,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692,568.44157
Policy Entropy: 1.07332
Value Function Loss: 2.66700

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 12,554.96877
Overall Steps per Second: 10,451.53711

Timestep Collection Time: 3.98488
Timestep Consumption Time: 0.80198
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.78686

Cumulative Model Updates: 57,261
Cumulative Timesteps: 955,110,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 955110046...
Checkpoint 955110046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,730.02593
Policy Entropy: 1.07156
Value Function Loss: 2.70745

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.10129

Collected Steps per Second: 12,636.28357
Overall Steps per Second: 10,571.29558

Timestep Collection Time: 3.95749
Timestep Consumption Time: 0.77305
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 4.73055

Cumulative Model Updates: 57,264
Cumulative Timesteps: 955,160,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,216.39462
Policy Entropy: 1.07178
Value Function Loss: 2.76752

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.07394
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 11,785.14449
Overall Steps per Second: 9,964.88641

Timestep Collection Time: 4.24399
Timestep Consumption Time: 0.77524
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.01922

Cumulative Model Updates: 57,267
Cumulative Timesteps: 955,210,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 955210070...
Checkpoint 955210070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,906.84861
Policy Entropy: 1.08064
Value Function Loss: 2.89158

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.06847
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 12,578.95452
Overall Steps per Second: 10,558.72809

Timestep Collection Time: 3.97632
Timestep Consumption Time: 0.76080
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.73712

Cumulative Model Updates: 57,270
Cumulative Timesteps: 955,260,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,608.88581
Policy Entropy: 1.08890
Value Function Loss: 2.93556

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.08990

Collected Steps per Second: 11,789.51930
Overall Steps per Second: 10,149.31699

Timestep Collection Time: 4.24258
Timestep Consumption Time: 0.68563
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.92821

Cumulative Model Updates: 57,273
Cumulative Timesteps: 955,310,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 955310106...
Checkpoint 955310106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,276.28148
Policy Entropy: 1.09383
Value Function Loss: 3.00057

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.09064

Collected Steps per Second: 12,212.40670
Overall Steps per Second: 10,256.13325

Timestep Collection Time: 4.09518
Timestep Consumption Time: 0.78112
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.87630

Cumulative Model Updates: 57,276
Cumulative Timesteps: 955,360,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588,761.59157
Policy Entropy: 1.09099
Value Function Loss: 2.89392

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.07577
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 11,944.76613
Overall Steps per Second: 10,067.77206

Timestep Collection Time: 4.18694
Timestep Consumption Time: 0.78060
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.96753

Cumulative Model Updates: 57,279
Cumulative Timesteps: 955,410,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 955410130...
Checkpoint 955410130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,281.14789
Policy Entropy: 1.08729
Value Function Loss: 2.87804

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.08418

Collected Steps per Second: 11,747.01744
Overall Steps per Second: 10,069.41954

Timestep Collection Time: 4.25861
Timestep Consumption Time: 0.70950
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.96811

Cumulative Model Updates: 57,282
Cumulative Timesteps: 955,460,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680,063.40083
Policy Entropy: 1.07243
Value Function Loss: 2.76024

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.16591
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 11,371.71888
Overall Steps per Second: 9,622.24019

Timestep Collection Time: 4.39740
Timestep Consumption Time: 0.79952
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.19692

Cumulative Model Updates: 57,285
Cumulative Timesteps: 955,510,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 955510162...
Checkpoint 955510162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,481.08192
Policy Entropy: 1.09331
Value Function Loss: 2.67795

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 11,893.42724
Overall Steps per Second: 10,092.73818

Timestep Collection Time: 4.20434
Timestep Consumption Time: 0.75011
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.95445

Cumulative Model Updates: 57,288
Cumulative Timesteps: 955,560,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,420.42760
Policy Entropy: 1.09782
Value Function Loss: 2.68608

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.08878

Collected Steps per Second: 12,238.39177
Overall Steps per Second: 10,270.55831

Timestep Collection Time: 4.08697
Timestep Consumption Time: 0.78306
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.87004

Cumulative Model Updates: 57,291
Cumulative Timesteps: 955,610,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 955610184...
Checkpoint 955610184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,503.66956
Policy Entropy: 1.09731
Value Function Loss: 2.73741

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.09291

Collected Steps per Second: 11,823.53567
Overall Steps per Second: 9,957.87814

Timestep Collection Time: 4.22953
Timestep Consumption Time: 0.79242
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.02195

Cumulative Model Updates: 57,294
Cumulative Timesteps: 955,660,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,476.40645
Policy Entropy: 1.07730
Value Function Loss: 2.77272

Mean KL Divergence: 0.04153
SB3 Clip Fraction: 0.20077
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.09732

Collected Steps per Second: 11,786.56253
Overall Steps per Second: 10,129.37354

Timestep Collection Time: 4.24466
Timestep Consumption Time: 0.69444
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.93910

Cumulative Model Updates: 57,297
Cumulative Timesteps: 955,710,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 955710222...
Checkpoint 955710222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,015.79659
Policy Entropy: 1.09065
Value Function Loss: 2.87719

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 11,525.81486
Overall Steps per Second: 9,748.48644

Timestep Collection Time: 4.33826
Timestep Consumption Time: 0.79094
PPO Batch Consumption Time: 0.03258
Total Iteration Time: 5.12921

Cumulative Model Updates: 57,300
Cumulative Timesteps: 955,760,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,001.71210
Policy Entropy: 1.08250
Value Function Loss: 2.85035

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.11025

Collected Steps per Second: 11,345.03051
Overall Steps per Second: 9,684.79836

Timestep Collection Time: 4.40722
Timestep Consumption Time: 0.75551
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 5.16273

Cumulative Model Updates: 57,303
Cumulative Timesteps: 955,810,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 955810224...
Checkpoint 955810224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,769.97730
Policy Entropy: 1.07535
Value Function Loss: 2.93776

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 12,274.97526
Overall Steps per Second: 10,275.12182

Timestep Collection Time: 4.07349
Timestep Consumption Time: 0.79283
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.86632

Cumulative Model Updates: 57,306
Cumulative Timesteps: 955,860,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,802.75529
Policy Entropy: 1.07810
Value Function Loss: 2.88498

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 11,781.98534
Overall Steps per Second: 9,936.48930

Timestep Collection Time: 4.24394
Timestep Consumption Time: 0.78822
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.03216

Cumulative Model Updates: 57,309
Cumulative Timesteps: 955,910,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 955910228...
Checkpoint 955910228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,303.92549
Policy Entropy: 1.08719
Value Function Loss: 2.84668

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 11,697.77629
Overall Steps per Second: 10,036.16544

Timestep Collection Time: 4.27466
Timestep Consumption Time: 0.70772
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.98238

Cumulative Model Updates: 57,312
Cumulative Timesteps: 955,960,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,828.45476
Policy Entropy: 1.08893
Value Function Loss: 2.78869

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.08820

Collected Steps per Second: 11,818.51840
Overall Steps per Second: 9,934.29858

Timestep Collection Time: 4.23234
Timestep Consumption Time: 0.80274
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.03508

Cumulative Model Updates: 57,315
Cumulative Timesteps: 956,010,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956010252...
Checkpoint 956010252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,719.22929
Policy Entropy: 1.07428
Value Function Loss: 2.67962

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.08630

Collected Steps per Second: 11,884.40611
Overall Steps per Second: 10,032.75513

Timestep Collection Time: 4.20753
Timestep Consumption Time: 0.77654
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.98407

Cumulative Model Updates: 57,318
Cumulative Timesteps: 956,060,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,028.33474
Policy Entropy: 1.06093
Value Function Loss: 2.82735

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.18490
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 11,492.87307
Overall Steps per Second: 9,729.50331

Timestep Collection Time: 4.35261
Timestep Consumption Time: 0.78886
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.14148

Cumulative Model Updates: 57,321
Cumulative Timesteps: 956,110,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 956110280...
Checkpoint 956110280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,012.32528
Policy Entropy: 1.06996
Value Function Loss: 2.88936

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.08489

Collected Steps per Second: 11,656.33016
Overall Steps per Second: 9,827.34436

Timestep Collection Time: 4.29072
Timestep Consumption Time: 0.79855
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 5.08927

Cumulative Model Updates: 57,324
Cumulative Timesteps: 956,160,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,332.88609
Policy Entropy: 1.07952
Value Function Loss: 2.91343

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.09903

Collected Steps per Second: 12,123.57984
Overall Steps per Second: 10,278.74403

Timestep Collection Time: 4.12518
Timestep Consumption Time: 0.74039
PPO Batch Consumption Time: 0.03331
Total Iteration Time: 4.86558

Cumulative Model Updates: 57,327
Cumulative Timesteps: 956,210,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 956210306...
Checkpoint 956210306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,676.06701
Policy Entropy: 1.05901
Value Function Loss: 2.69945

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.10955

Collected Steps per Second: 12,220.80149
Overall Steps per Second: 10,082.65658

Timestep Collection Time: 4.09351
Timestep Consumption Time: 0.86808
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.96159

Cumulative Model Updates: 57,330
Cumulative Timesteps: 956,260,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,504.97929
Policy Entropy: 1.06414
Value Function Loss: 2.69920

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.10158

Collected Steps per Second: 12,295.16521
Overall Steps per Second: 10,361.39902

Timestep Collection Time: 4.06680
Timestep Consumption Time: 0.75899
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 4.82580

Cumulative Model Updates: 57,333
Cumulative Timesteps: 956,310,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 956310334...
Checkpoint 956310334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,148.09299
Policy Entropy: 1.06883
Value Function Loss: 2.71378

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.09711

Collected Steps per Second: 12,100.59456
Overall Steps per Second: 10,262.65086

Timestep Collection Time: 4.13352
Timestep Consumption Time: 0.74027
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.87379

Cumulative Model Updates: 57,336
Cumulative Timesteps: 956,360,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,037.67316
Policy Entropy: 1.07254
Value Function Loss: 2.88113

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.09493

Collected Steps per Second: 11,422.72771
Overall Steps per Second: 9,695.12366

Timestep Collection Time: 4.37881
Timestep Consumption Time: 0.78027
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.15909

Cumulative Model Updates: 57,339
Cumulative Timesteps: 956,410,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 956410370...
Checkpoint 956410370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,722.12482
Policy Entropy: 1.07904
Value Function Loss: 2.72643

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.09375

Collected Steps per Second: 12,187.23734
Overall Steps per Second: 10,156.47728

Timestep Collection Time: 4.10479
Timestep Consumption Time: 0.82074
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 4.92553

Cumulative Model Updates: 57,342
Cumulative Timesteps: 956,460,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,394.60352
Policy Entropy: 1.07705
Value Function Loss: 2.86982

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 12,032.40466
Overall Steps per Second: 10,013.36156

Timestep Collection Time: 4.15777
Timestep Consumption Time: 0.83835
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 4.99612

Cumulative Model Updates: 57,345
Cumulative Timesteps: 956,510,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 956510424...
Checkpoint 956510424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,957.34193
Policy Entropy: 1.07457
Value Function Loss: 2.79403

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.08536

Collected Steps per Second: 12,044.21787
Overall Steps per Second: 10,106.85139

Timestep Collection Time: 4.15286
Timestep Consumption Time: 0.79606
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 4.94892

Cumulative Model Updates: 57,348
Cumulative Timesteps: 956,560,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,062.33328
Policy Entropy: 1.07365
Value Function Loss: 2.82266

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.06564
Value Function Update Magnitude: 0.09612

Collected Steps per Second: 11,953.29596
Overall Steps per Second: 10,237.54000

Timestep Collection Time: 4.18378
Timestep Consumption Time: 0.70118
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.88496

Cumulative Model Updates: 57,351
Cumulative Timesteps: 956,610,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 956610452...
Checkpoint 956610452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,382.34604
Policy Entropy: 1.08938
Value Function Loss: 2.67681

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.09971

Collected Steps per Second: 11,762.34329
Overall Steps per Second: 9,939.49190

Timestep Collection Time: 4.25255
Timestep Consumption Time: 0.77990
PPO Batch Consumption Time: 0.03526
Total Iteration Time: 5.03245

Cumulative Model Updates: 57,354
Cumulative Timesteps: 956,660,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,720.85555
Policy Entropy: 1.09633
Value Function Loss: 2.62138

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.09144

Collected Steps per Second: 11,397.07941
Overall Steps per Second: 9,732.85267

Timestep Collection Time: 4.38867
Timestep Consumption Time: 0.75042
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.13909

Cumulative Model Updates: 57,357
Cumulative Timesteps: 956,710,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 956710490...
Checkpoint 956710490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,990.40136
Policy Entropy: 1.10382
Value Function Loss: 2.75449

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.06801
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 12,127.65642
Overall Steps per Second: 10,188.34609

Timestep Collection Time: 4.12429
Timestep Consumption Time: 0.78504
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 4.90933

Cumulative Model Updates: 57,360
Cumulative Timesteps: 956,760,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,573.57596
Policy Entropy: 1.09747
Value Function Loss: 2.83753

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 12,054.41903
Overall Steps per Second: 10,197.72325

Timestep Collection Time: 4.14935
Timestep Consumption Time: 0.75547
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 4.90482

Cumulative Model Updates: 57,363
Cumulative Timesteps: 956,810,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 956810526...
Checkpoint 956810526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,547.09609
Policy Entropy: 1.07952
Value Function Loss: 2.90889

Mean KL Divergence: 0.03871
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 11,858.44174
Overall Steps per Second: 10,126.29107

Timestep Collection Time: 4.21674
Timestep Consumption Time: 0.72129
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 4.93804

Cumulative Model Updates: 57,366
Cumulative Timesteps: 956,860,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,956.53489
Policy Entropy: 1.09111
Value Function Loss: 2.85385

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 11,912.84729
Overall Steps per Second: 10,131.10089

Timestep Collection Time: 4.19849
Timestep Consumption Time: 0.73838
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.93688

Cumulative Model Updates: 57,369
Cumulative Timesteps: 956,910,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 956910546...
Checkpoint 956910546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,627.19949
Policy Entropy: 1.09455
Value Function Loss: 2.83766

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 11,880.76314
Overall Steps per Second: 10,078.81370

Timestep Collection Time: 4.21034
Timestep Consumption Time: 0.75275
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.96308

Cumulative Model Updates: 57,372
Cumulative Timesteps: 956,960,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624,160.09184
Policy Entropy: 1.07822
Value Function Loss: 2.80833

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 11,557.47225
Overall Steps per Second: 9,963.26246

Timestep Collection Time: 4.32621
Timestep Consumption Time: 0.69223
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 5.01844

Cumulative Model Updates: 57,375
Cumulative Timesteps: 957,010,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 957010568...
Checkpoint 957010568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,564.61575
Policy Entropy: 1.06897
Value Function Loss: 2.72871

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.18563
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.09402

Collected Steps per Second: 11,872.09061
Overall Steps per Second: 10,059.79792

Timestep Collection Time: 4.21358
Timestep Consumption Time: 0.75908
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.97266

Cumulative Model Updates: 57,378
Cumulative Timesteps: 957,060,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,111.56348
Policy Entropy: 1.07579
Value Function Loss: 2.72350

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 11,784.71522
Overall Steps per Second: 9,996.74186

Timestep Collection Time: 4.24278
Timestep Consumption Time: 0.75885
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.00163

Cumulative Model Updates: 57,381
Cumulative Timesteps: 957,110,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 957110592...
Checkpoint 957110592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,757.32465
Policy Entropy: 1.08697
Value Function Loss: 2.64128

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.16634
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.08226

Collected Steps per Second: 12,286.89200
Overall Steps per Second: 10,320.32327

Timestep Collection Time: 4.07101
Timestep Consumption Time: 0.77574
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.84675

Cumulative Model Updates: 57,384
Cumulative Timesteps: 957,160,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,831.81803
Policy Entropy: 1.05139
Value Function Loss: 2.58935

Mean KL Divergence: 0.05744
SB3 Clip Fraction: 0.22753
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.07978

Collected Steps per Second: 11,792.81139
Overall Steps per Second: 9,917.02460

Timestep Collection Time: 4.24258
Timestep Consumption Time: 0.80248
PPO Batch Consumption Time: 0.03344
Total Iteration Time: 5.04506

Cumulative Model Updates: 57,387
Cumulative Timesteps: 957,210,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 957210644...
Checkpoint 957210644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,325.16069
Policy Entropy: 1.08623
Value Function Loss: 2.55064

Mean KL Divergence: 0.03332
SB3 Clip Fraction: 0.20768
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 11,894.44315
Overall Steps per Second: 10,186.99727

Timestep Collection Time: 4.20617
Timestep Consumption Time: 0.70500
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.91116

Cumulative Model Updates: 57,390
Cumulative Timesteps: 957,260,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591,219.69561
Policy Entropy: 1.04820
Value Function Loss: 2.64516

Mean KL Divergence: 0.05826
SB3 Clip Fraction: 0.24242
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.08703

Collected Steps per Second: 11,393.00547
Overall Steps per Second: 9,673.56429

Timestep Collection Time: 4.39094
Timestep Consumption Time: 0.78047
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.17141

Cumulative Model Updates: 57,393
Cumulative Timesteps: 957,310,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 957310700...
Checkpoint 957310700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,929.29294
Policy Entropy: 1.08541
Value Function Loss: 2.81878

Mean KL Divergence: 0.04049
SB3 Clip Fraction: 0.22657
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.09368

Collected Steps per Second: 11,996.13936
Overall Steps per Second: 10,132.61388

Timestep Collection Time: 4.16967
Timestep Consumption Time: 0.76686
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.93653

Cumulative Model Updates: 57,396
Cumulative Timesteps: 957,360,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,859.65282
Policy Entropy: 1.05532
Value Function Loss: 3.01582

Mean KL Divergence: 0.05049
SB3 Clip Fraction: 0.22868
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.09410

Collected Steps per Second: 12,988.39123
Overall Steps per Second: 10,776.63587

Timestep Collection Time: 3.85113
Timestep Consumption Time: 0.79039
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.64152

Cumulative Model Updates: 57,399
Cumulative Timesteps: 957,410,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 957410740...
Checkpoint 957410740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,735.27051
Policy Entropy: 1.06981
Value Function Loss: 3.04545

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.08648

Collected Steps per Second: 12,731.69281
Overall Steps per Second: 10,658.61546

Timestep Collection Time: 3.92909
Timestep Consumption Time: 0.76420
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.69329

Cumulative Model Updates: 57,402
Cumulative Timesteps: 957,460,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,826.77775
Policy Entropy: 1.06733
Value Function Loss: 3.07762

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 12,863.88688
Overall Steps per Second: 10,925.64131

Timestep Collection Time: 3.88685
Timestep Consumption Time: 0.68954
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.57639

Cumulative Model Updates: 57,405
Cumulative Timesteps: 957,510,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 957510764...
Checkpoint 957510764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,210.32135
Policy Entropy: 1.06042
Value Function Loss: 2.83926

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.07008
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 12,533.34580
Overall Steps per Second: 10,340.05439

Timestep Collection Time: 3.99143
Timestep Consumption Time: 0.84665
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.83808

Cumulative Model Updates: 57,408
Cumulative Timesteps: 957,560,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,975.07870
Policy Entropy: 1.05384
Value Function Loss: 2.78014

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.17527
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.10525

Collected Steps per Second: 12,088.02687
Overall Steps per Second: 10,216.17811

Timestep Collection Time: 4.13864
Timestep Consumption Time: 0.75830
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 4.89694

Cumulative Model Updates: 57,411
Cumulative Timesteps: 957,610,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 957610818...
Checkpoint 957610818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,742.65610
Policy Entropy: 1.06685
Value Function Loss: 2.67045

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 12,843.13717
Overall Steps per Second: 10,683.63566

Timestep Collection Time: 3.89562
Timestep Consumption Time: 0.78743
PPO Batch Consumption Time: 0.03269
Total Iteration Time: 4.68305

Cumulative Model Updates: 57,414
Cumulative Timesteps: 957,660,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,464.18354
Policy Entropy: 1.07114
Value Function Loss: 2.72055

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.16381
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 12,243.56363
Overall Steps per Second: 10,214.98009

Timestep Collection Time: 4.08460
Timestep Consumption Time: 0.81116
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 4.89575

Cumulative Model Updates: 57,417
Cumulative Timesteps: 957,710,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 957710860...
Checkpoint 957710860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,569.35712
Policy Entropy: 1.05733
Value Function Loss: 2.64164

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.11301

Collected Steps per Second: 11,597.80342
Overall Steps per Second: 9,943.04465

Timestep Collection Time: 4.31306
Timestep Consumption Time: 0.71780
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.03085

Cumulative Model Updates: 57,420
Cumulative Timesteps: 957,760,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,976.45542
Policy Entropy: 1.04586
Value Function Loss: 2.66404

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 11,895.66293
Overall Steps per Second: 9,958.80780

Timestep Collection Time: 4.20573
Timestep Consumption Time: 0.81796
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 5.02369

Cumulative Model Updates: 57,423
Cumulative Timesteps: 957,810,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 957810912...
Checkpoint 957810912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,327.88632
Policy Entropy: 1.06888
Value Function Loss: 2.70952

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 11,847.45983
Overall Steps per Second: 10,075.15704

Timestep Collection Time: 4.22234
Timestep Consumption Time: 0.74274
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.96508

Cumulative Model Updates: 57,426
Cumulative Timesteps: 957,860,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,343.17931
Policy Entropy: 1.07481
Value Function Loss: 2.83793

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 11,989.94828
Overall Steps per Second: 10,087.54182

Timestep Collection Time: 4.17083
Timestep Consumption Time: 0.78658
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.95740

Cumulative Model Updates: 57,429
Cumulative Timesteps: 957,910,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 957910944...
Checkpoint 957910944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796,211.01270
Policy Entropy: 1.05338
Value Function Loss: 2.75130

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.09846

Collected Steps per Second: 11,866.12050
Overall Steps per Second: 10,009.11590

Timestep Collection Time: 4.21553
Timestep Consumption Time: 0.78211
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 4.99764

Cumulative Model Updates: 57,432
Cumulative Timesteps: 957,960,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,822.84705
Policy Entropy: 1.04317
Value Function Loss: 2.71013

Mean KL Divergence: 0.03158
SB3 Clip Fraction: 0.20243
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.10982

Collected Steps per Second: 11,857.28464
Overall Steps per Second: 10,218.81248

Timestep Collection Time: 4.21834
Timestep Consumption Time: 0.67636
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.89470

Cumulative Model Updates: 57,435
Cumulative Timesteps: 958,010,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 958010984...
Checkpoint 958010984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,626.23324
Policy Entropy: 1.04910
Value Function Loss: 2.73526

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 11,955.48479
Overall Steps per Second: 10,083.67511

Timestep Collection Time: 4.18335
Timestep Consumption Time: 0.77655
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.95990

Cumulative Model Updates: 57,438
Cumulative Timesteps: 958,060,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,718.99106
Policy Entropy: 1.05826
Value Function Loss: 2.91047

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11002

Collected Steps per Second: 11,992.66623
Overall Steps per Second: 10,174.56259

Timestep Collection Time: 4.17172
Timestep Consumption Time: 0.74545
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.91716

Cumulative Model Updates: 57,441
Cumulative Timesteps: 958,111,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 958111028...
Checkpoint 958111028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,601.86637
Policy Entropy: 1.03857
Value Function Loss: 2.85468

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 11,894.79362
Overall Steps per Second: 10,175.14116

Timestep Collection Time: 4.20369
Timestep Consumption Time: 0.71045
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.91413

Cumulative Model Updates: 57,444
Cumulative Timesteps: 958,161,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760,340.01906
Policy Entropy: 1.04417
Value Function Loss: 2.76584

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.12753

Collected Steps per Second: 11,691.42677
Overall Steps per Second: 9,891.93359

Timestep Collection Time: 4.27664
Timestep Consumption Time: 0.77799
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 5.05462

Cumulative Model Updates: 57,447
Cumulative Timesteps: 958,211,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 958211030...
Checkpoint 958211030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,608.22448
Policy Entropy: 1.05405
Value Function Loss: 2.73259

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14742
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12267

Collected Steps per Second: 11,693.95072
Overall Steps per Second: 10,103.11480

Timestep Collection Time: 4.27657
Timestep Consumption Time: 0.67339
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.94996

Cumulative Model Updates: 57,450
Cumulative Timesteps: 958,261,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,351.82132
Policy Entropy: 1.05704
Value Function Loss: 2.71802

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 11,758.48437
Overall Steps per Second: 9,920.72661

Timestep Collection Time: 4.25412
Timestep Consumption Time: 0.78805
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.04217

Cumulative Model Updates: 57,453
Cumulative Timesteps: 958,311,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 958311062...
Checkpoint 958311062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,081.02044
Policy Entropy: 1.04097
Value Function Loss: 2.61792

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12065

Collected Steps per Second: 11,789.64041
Overall Steps per Second: 9,939.21587

Timestep Collection Time: 4.24373
Timestep Consumption Time: 0.79007
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.03380

Cumulative Model Updates: 57,456
Cumulative Timesteps: 958,361,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,714.26680
Policy Entropy: 1.03150
Value Function Loss: 2.58031

Mean KL Divergence: 0.02960
SB3 Clip Fraction: 0.19069
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 12,237.46246
Overall Steps per Second: 10,234.29986

Timestep Collection Time: 4.08696
Timestep Consumption Time: 0.79994
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.88690

Cumulative Model Updates: 57,459
Cumulative Timesteps: 958,411,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 958411108...
Checkpoint 958411108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,609.76760
Policy Entropy: 1.05102
Value Function Loss: 2.70790

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.11729

Collected Steps per Second: 11,953.15636
Overall Steps per Second: 10,029.09126

Timestep Collection Time: 4.18333
Timestep Consumption Time: 0.80257
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.98590

Cumulative Model Updates: 57,462
Cumulative Timesteps: 958,461,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,445.98645
Policy Entropy: 1.05098
Value Function Loss: 2.78503

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.11792

Collected Steps per Second: 11,884.02298
Overall Steps per Second: 9,949.51959

Timestep Collection Time: 4.20884
Timestep Consumption Time: 0.81833
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.02718

Cumulative Model Updates: 57,465
Cumulative Timesteps: 958,511,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 958511130...
Checkpoint 958511130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,969.59940
Policy Entropy: 1.04014
Value Function Loss: 2.80761

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.10921

Collected Steps per Second: 11,797.63489
Overall Steps per Second: 9,948.99707

Timestep Collection Time: 4.23882
Timestep Consumption Time: 0.78762
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 5.02644

Cumulative Model Updates: 57,468
Cumulative Timesteps: 958,561,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750,501.21150
Policy Entropy: 1.02699
Value Function Loss: 2.77159

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.10044

Collected Steps per Second: 12,076.94424
Overall Steps per Second: 10,248.17408

Timestep Collection Time: 4.14244
Timestep Consumption Time: 0.73921
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.88165

Cumulative Model Updates: 57,471
Cumulative Timesteps: 958,611,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 958611166...
Checkpoint 958611166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,357.24707
Policy Entropy: 1.04505
Value Function Loss: 2.64461

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.10120

Collected Steps per Second: 12,257.13424
Overall Steps per Second: 10,298.61369

Timestep Collection Time: 4.08170
Timestep Consumption Time: 0.77623
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.85794

Cumulative Model Updates: 57,474
Cumulative Timesteps: 958,661,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,846.23030
Policy Entropy: 1.05517
Value Function Loss: 2.54472

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.09973

Collected Steps per Second: 12,233.30576
Overall Steps per Second: 10,346.29234

Timestep Collection Time: 4.08818
Timestep Consumption Time: 0.74563
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.83381

Cumulative Model Updates: 57,477
Cumulative Timesteps: 958,711,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 958711208...
Checkpoint 958711208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,924.23365
Policy Entropy: 1.04120
Value Function Loss: 2.50561

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 11,821.15781
Overall Steps per Second: 10,097.85504

Timestep Collection Time: 4.23157
Timestep Consumption Time: 0.72216
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.95373

Cumulative Model Updates: 57,480
Cumulative Timesteps: 958,761,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,375.63292
Policy Entropy: 1.03280
Value Function Loss: 2.52843

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.16472
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 11,766.56204
Overall Steps per Second: 9,823.47016

Timestep Collection Time: 4.25103
Timestep Consumption Time: 0.84086
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.09189

Cumulative Model Updates: 57,483
Cumulative Timesteps: 958,811,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 958811250...
Checkpoint 958811250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,194.33395
Policy Entropy: 1.04627
Value Function Loss: 2.57230

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 11,847.10277
Overall Steps per Second: 10,098.61385

Timestep Collection Time: 4.22095
Timestep Consumption Time: 0.73082
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.95177

Cumulative Model Updates: 57,486
Cumulative Timesteps: 958,861,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,059.21013
Policy Entropy: 1.05364
Value Function Loss: 2.54051

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 12,062.87219
Overall Steps per Second: 10,121.41469

Timestep Collection Time: 4.14711
Timestep Consumption Time: 0.79548
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.94259

Cumulative Model Updates: 57,489
Cumulative Timesteps: 958,911,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 958911282...
Checkpoint 958911282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815,721.78343
Policy Entropy: 1.02486
Value Function Loss: 2.72104

Mean KL Divergence: 0.02835
SB3 Clip Fraction: 0.17315
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 11,840.18245
Overall Steps per Second: 10,064.74712

Timestep Collection Time: 4.22291
Timestep Consumption Time: 0.74493
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 4.96783

Cumulative Model Updates: 57,492
Cumulative Timesteps: 958,961,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,339.10028
Policy Entropy: 1.04088
Value Function Loss: 2.81469

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 11,823.88174
Overall Steps per Second: 10,143.51550

Timestep Collection Time: 4.23110
Timestep Consumption Time: 0.70092
PPO Batch Consumption Time: 0.03849
Total Iteration Time: 4.93202

Cumulative Model Updates: 57,495
Cumulative Timesteps: 959,011,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 959011310...
Checkpoint 959011310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,669.71278
Policy Entropy: 1.03837
Value Function Loss: 2.78506

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.17843
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12427

Collected Steps per Second: 12,168.99440
Overall Steps per Second: 10,238.96977

Timestep Collection Time: 4.10930
Timestep Consumption Time: 0.77459
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 4.88389

Cumulative Model Updates: 57,498
Cumulative Timesteps: 959,061,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,327.26606
Policy Entropy: 1.02975
Value Function Loss: 2.67767

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11438

Collected Steps per Second: 12,022.08058
Overall Steps per Second: 10,014.02953

Timestep Collection Time: 4.15935
Timestep Consumption Time: 0.83405
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.99339

Cumulative Model Updates: 57,501
Cumulative Timesteps: 959,111,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 959111320...
Checkpoint 959111320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,811.08922
Policy Entropy: 1.02549
Value Function Loss: 2.55760

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.19811
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 12,304.98705
Overall Steps per Second: 10,265.11370

Timestep Collection Time: 4.06502
Timestep Consumption Time: 0.80780
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.87282

Cumulative Model Updates: 57,504
Cumulative Timesteps: 959,161,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,515.65514
Policy Entropy: 1.04281
Value Function Loss: 2.65104

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.09066

Collected Steps per Second: 11,916.96223
Overall Steps per Second: 10,094.29075

Timestep Collection Time: 4.19671
Timestep Consumption Time: 0.75778
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.95448

Cumulative Model Updates: 57,507
Cumulative Timesteps: 959,211,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 959211352...
Checkpoint 959211352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,852.69749
Policy Entropy: 1.04862
Value Function Loss: 2.61380

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.08359

Collected Steps per Second: 11,872.89213
Overall Steps per Second: 10,106.09542

Timestep Collection Time: 4.21346
Timestep Consumption Time: 0.73662
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.95008

Cumulative Model Updates: 57,510
Cumulative Timesteps: 959,261,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750,052.73860
Policy Entropy: 1.03550
Value Function Loss: 2.54049

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11,883.12777
Overall Steps per Second: 10,064.23727

Timestep Collection Time: 4.21000
Timestep Consumption Time: 0.76087
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.97087

Cumulative Model Updates: 57,513
Cumulative Timesteps: 959,311,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 959311406...
Checkpoint 959311406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781,014.01499
Policy Entropy: 1.01556
Value Function Loss: 2.56507

Mean KL Divergence: 0.03426
SB3 Clip Fraction: 0.18707
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.08588

Collected Steps per Second: 12,060.35464
Overall Steps per Second: 10,233.63687

Timestep Collection Time: 4.14648
Timestep Consumption Time: 0.74015
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.88663

Cumulative Model Updates: 57,516
Cumulative Timesteps: 959,361,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,746.52284
Policy Entropy: 1.03748
Value Function Loss: 2.68379

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.08933

Collected Steps per Second: 11,972.38007
Overall Steps per Second: 10,091.84996

Timestep Collection Time: 4.17711
Timestep Consumption Time: 0.77837
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.95548

Cumulative Model Updates: 57,519
Cumulative Timesteps: 959,411,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 959411424...
Checkpoint 959411424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,389.15379
Policy Entropy: 1.04662
Value Function Loss: 2.92891

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 11,691.85893
Overall Steps per Second: 9,929.40112

Timestep Collection Time: 4.27785
Timestep Consumption Time: 0.75931
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.03716

Cumulative Model Updates: 57,522
Cumulative Timesteps: 959,461,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,919.64722
Policy Entropy: 1.02618
Value Function Loss: 2.89369

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.16364
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 11,964.61179
Overall Steps per Second: 10,086.62530

Timestep Collection Time: 4.18016
Timestep Consumption Time: 0.77829
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.95845

Cumulative Model Updates: 57,525
Cumulative Timesteps: 959,511,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 959511454...
Checkpoint 959511454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,378.40832
Policy Entropy: 1.03820
Value Function Loss: 2.90490

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 12,064.48297
Overall Steps per Second: 10,178.03048

Timestep Collection Time: 4.14589
Timestep Consumption Time: 0.76842
PPO Batch Consumption Time: 0.03317
Total Iteration Time: 4.91431

Cumulative Model Updates: 57,528
Cumulative Timesteps: 959,561,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752,066.05528
Policy Entropy: 1.03865
Value Function Loss: 2.85298

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 12,058.44269
Overall Steps per Second: 10,110.85053

Timestep Collection Time: 4.14896
Timestep Consumption Time: 0.79919
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.94815

Cumulative Model Updates: 57,531
Cumulative Timesteps: 959,611,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 959611502...
Checkpoint 959611502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,571.59114
Policy Entropy: 1.04205
Value Function Loss: 2.78101

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.08738

Collected Steps per Second: 12,052.86073
Overall Steps per Second: 10,316.08467

Timestep Collection Time: 4.15005
Timestep Consumption Time: 0.69869
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 4.84874

Cumulative Model Updates: 57,534
Cumulative Timesteps: 959,661,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,955.75434
Policy Entropy: 1.03478
Value Function Loss: 2.66065

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.16345
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 11,777.50868
Overall Steps per Second: 9,870.67159

Timestep Collection Time: 4.24742
Timestep Consumption Time: 0.82053
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.06794

Cumulative Model Updates: 57,537
Cumulative Timesteps: 959,711,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 959711546...
Checkpoint 959711546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665,564.43005
Policy Entropy: 1.04842
Value Function Loss: 2.63787

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.08721

Collected Steps per Second: 11,255.39349
Overall Steps per Second: 9,538.81576

Timestep Collection Time: 4.44480
Timestep Consumption Time: 0.79987
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.24468

Cumulative Model Updates: 57,540
Cumulative Timesteps: 959,761,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739,147.10855
Policy Entropy: 1.04993
Value Function Loss: 2.81054

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.09541

Collected Steps per Second: 12,092.08372
Overall Steps per Second: 10,193.75282

Timestep Collection Time: 4.13742
Timestep Consumption Time: 0.77049
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.90791

Cumulative Model Updates: 57,543
Cumulative Timesteps: 959,811,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 959811604...
Checkpoint 959811604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,888.28160
Policy Entropy: 1.03290
Value Function Loss: 2.82480

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.16236
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.08861

Collected Steps per Second: 12,556.21040
Overall Steps per Second: 10,520.42364

Timestep Collection Time: 3.98400
Timestep Consumption Time: 0.77094
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.75494

Cumulative Model Updates: 57,546
Cumulative Timesteps: 959,861,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,927.96522
Policy Entropy: 1.03176
Value Function Loss: 2.77081

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.18573
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.08270

Collected Steps per Second: 12,656.52553
Overall Steps per Second: 10,773.10900

Timestep Collection Time: 3.95069
Timestep Consumption Time: 0.69068
PPO Batch Consumption Time: 0.03326
Total Iteration Time: 4.64137

Cumulative Model Updates: 57,549
Cumulative Timesteps: 959,911,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 959911630...
Checkpoint 959911630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746,744.43454
Policy Entropy: 1.03929
Value Function Loss: 2.77011

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 12,643.97414
Overall Steps per Second: 10,514.30629

Timestep Collection Time: 3.95651
Timestep Consumption Time: 0.80139
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.75790

Cumulative Model Updates: 57,552
Cumulative Timesteps: 959,961,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803,782.28054
Policy Entropy: 1.05479
Value Function Loss: 2.73026

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16028
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.08926

Collected Steps per Second: 12,357.38056
Overall Steps per Second: 10,455.41129

Timestep Collection Time: 4.04811
Timestep Consumption Time: 0.73640
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.78451

Cumulative Model Updates: 57,555
Cumulative Timesteps: 960,011,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 960011680...
Checkpoint 960011680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735,436.98038
Policy Entropy: 1.03238
Value Function Loss: 2.71601

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 11,791.51422
Overall Steps per Second: 10,168.66062

Timestep Collection Time: 4.24152
Timestep Consumption Time: 0.67692
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.91845

Cumulative Model Updates: 57,558
Cumulative Timesteps: 960,061,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,045.10914
Policy Entropy: 1.03717
Value Function Loss: 2.65909

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.08069

Collected Steps per Second: 12,848.48801
Overall Steps per Second: 10,708.72608

Timestep Collection Time: 3.89260
Timestep Consumption Time: 0.77780
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.67040

Cumulative Model Updates: 57,561
Cumulative Timesteps: 960,111,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 960111708...
Checkpoint 960111708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,896.32539
Policy Entropy: 1.03807
Value Function Loss: 2.78634

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 11,927.19749
Overall Steps per Second: 10,236.55424

Timestep Collection Time: 4.19227
Timestep Consumption Time: 0.69238
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.88465

Cumulative Model Updates: 57,564
Cumulative Timesteps: 960,161,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,990.69685
Policy Entropy: 1.04258
Value Function Loss: 2.78232

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.08122

Collected Steps per Second: 12,007.35998
Overall Steps per Second: 10,118.72692

Timestep Collection Time: 4.16545
Timestep Consumption Time: 0.77747
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.94291

Cumulative Model Updates: 57,567
Cumulative Timesteps: 960,211,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 960211726...
Checkpoint 960211726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,743.91838
Policy Entropy: 1.04200
Value Function Loss: 2.75342

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.09748

Collected Steps per Second: 11,852.33608
Overall Steps per Second: 9,913.23599

Timestep Collection Time: 4.21959
Timestep Consumption Time: 0.82538
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.04497

Cumulative Model Updates: 57,570
Cumulative Timesteps: 960,261,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,171.45067
Policy Entropy: 1.05253
Value Function Loss: 2.66409

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.09960

Collected Steps per Second: 12,163.65235
Overall Steps per Second: 10,219.75582

Timestep Collection Time: 4.11094
Timestep Consumption Time: 0.78194
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.89288

Cumulative Model Updates: 57,573
Cumulative Timesteps: 960,311,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 960311742...
Checkpoint 960311742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,380.42304
Policy Entropy: 1.05505
Value Function Loss: 2.56496

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.09390

Collected Steps per Second: 11,604.78531
Overall Steps per Second: 9,793.38174

Timestep Collection Time: 4.30926
Timestep Consumption Time: 0.79705
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.10631

Cumulative Model Updates: 57,576
Cumulative Timesteps: 960,361,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,706.05332
Policy Entropy: 1.05692
Value Function Loss: 2.68080

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.08941

Collected Steps per Second: 12,095.59760
Overall Steps per Second: 10,398.38106

Timestep Collection Time: 4.13407
Timestep Consumption Time: 0.67476
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.80883

Cumulative Model Updates: 57,579
Cumulative Timesteps: 960,411,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 960411754...
Checkpoint 960411754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617,614.67110
Policy Entropy: 1.06118
Value Function Loss: 2.84493

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 11,903.15838
Overall Steps per Second: 10,037.99804

Timestep Collection Time: 4.20057
Timestep Consumption Time: 0.78051
PPO Batch Consumption Time: 0.03646
Total Iteration Time: 4.98107

Cumulative Model Updates: 57,582
Cumulative Timesteps: 960,461,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,282.60540
Policy Entropy: 1.06202
Value Function Loss: 2.91651

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.10452

Collected Steps per Second: 11,863.72709
Overall Steps per Second: 9,996.93791

Timestep Collection Time: 4.21503
Timestep Consumption Time: 0.78710
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 5.00213

Cumulative Model Updates: 57,585
Cumulative Timesteps: 960,511,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 960511760...
Checkpoint 960511760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,928.07113
Policy Entropy: 1.06212
Value Function Loss: 2.91776

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.10928

Collected Steps per Second: 12,271.12429
Overall Steps per Second: 10,257.38275

Timestep Collection Time: 4.07640
Timestep Consumption Time: 0.80028
PPO Batch Consumption Time: 0.03376
Total Iteration Time: 4.87668

Cumulative Model Updates: 57,588
Cumulative Timesteps: 960,561,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,987.56688
Policy Entropy: 1.06298
Value Function Loss: 2.89301

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.10415

Collected Steps per Second: 11,984.46648
Overall Steps per Second: 10,134.38103

Timestep Collection Time: 4.17440
Timestep Consumption Time: 0.76206
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.93646

Cumulative Model Updates: 57,591
Cumulative Timesteps: 960,611,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 960611810...
Checkpoint 960611810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,034.04401
Policy Entropy: 1.07086
Value Function Loss: 2.92154

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.09512

Collected Steps per Second: 11,279.02060
Overall Steps per Second: 9,799.47056

Timestep Collection Time: 4.43460
Timestep Consumption Time: 0.66955
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 5.10415

Cumulative Model Updates: 57,594
Cumulative Timesteps: 960,661,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,099.31575
Policy Entropy: 1.06360
Value Function Loss: 2.83574

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 11,971.97083
Overall Steps per Second: 9,946.80288

Timestep Collection Time: 4.17759
Timestep Consumption Time: 0.85056
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 5.02815

Cumulative Model Updates: 57,597
Cumulative Timesteps: 960,711,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 960711842...
Checkpoint 960711842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,750.91203
Policy Entropy: 1.04423
Value Function Loss: 2.72083

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.16632
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 12,143.27108
Overall Steps per Second: 10,252.81839

Timestep Collection Time: 4.11833
Timestep Consumption Time: 0.75935
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 4.87768

Cumulative Model Updates: 57,600
Cumulative Timesteps: 960,761,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,175.37139
Policy Entropy: 1.05926
Value Function Loss: 2.67732

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.15567
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 12,167.00845
Overall Steps per Second: 10,155.29456

Timestep Collection Time: 4.10947
Timestep Consumption Time: 0.81407
PPO Batch Consumption Time: 0.03723
Total Iteration Time: 4.92354

Cumulative Model Updates: 57,603
Cumulative Timesteps: 960,811,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 960811852...
Checkpoint 960811852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691,702.79955
Policy Entropy: 1.05833
Value Function Loss: 2.66606

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 11,965.43070
Overall Steps per Second: 10,043.25127

Timestep Collection Time: 4.18088
Timestep Consumption Time: 0.80018
PPO Batch Consumption Time: 0.03712
Total Iteration Time: 4.98106

Cumulative Model Updates: 57,606
Cumulative Timesteps: 960,861,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655,520.99976
Policy Entropy: 1.05521
Value Function Loss: 2.85338

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 12,033.56552
Overall Steps per Second: 10,321.94067

Timestep Collection Time: 4.15687
Timestep Consumption Time: 0.68931
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.84618

Cumulative Model Updates: 57,609
Cumulative Timesteps: 960,911,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 960911900...
Checkpoint 960911900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,610.32709
Policy Entropy: 1.04659
Value Function Loss: 2.95754

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.16369
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 11,547.22975
Overall Steps per Second: 9,763.79018

Timestep Collection Time: 4.33160
Timestep Consumption Time: 0.79120
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.12281

Cumulative Model Updates: 57,612
Cumulative Timesteps: 960,961,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,947.96332
Policy Entropy: 1.06978
Value Function Loss: 2.89478

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 12,078.82490
Overall Steps per Second: 10,206.02862

Timestep Collection Time: 4.13964
Timestep Consumption Time: 0.75962
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.89926

Cumulative Model Updates: 57,615
Cumulative Timesteps: 961,011,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 961011920...
Checkpoint 961011920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,744.42310
Policy Entropy: 1.06978
Value Function Loss: 2.71785

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.09051

Collected Steps per Second: 12,306.67990
Overall Steps per Second: 10,340.33047

Timestep Collection Time: 4.06283
Timestep Consumption Time: 0.77260
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.83544

Cumulative Model Updates: 57,618
Cumulative Timesteps: 961,061,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,320.67919
Policy Entropy: 1.05286
Value Function Loss: 2.61314

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.09313

Collected Steps per Second: 12,192.82028
Overall Steps per Second: 10,321.38718

Timestep Collection Time: 4.10307
Timestep Consumption Time: 0.74395
PPO Batch Consumption Time: 0.03354
Total Iteration Time: 4.84702

Cumulative Model Updates: 57,621
Cumulative Timesteps: 961,111,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 961111948...
Checkpoint 961111948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,716.24575
Policy Entropy: 1.04277
Value Function Loss: 2.70113

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.18425
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 12,218.40587
Overall Steps per Second: 10,469.33844

Timestep Collection Time: 4.09431
Timestep Consumption Time: 0.68402
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.77833

Cumulative Model Updates: 57,624
Cumulative Timesteps: 961,161,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,855.19237
Policy Entropy: 1.05585
Value Function Loss: 2.72372

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.08577

Collected Steps per Second: 11,914.89313
Overall Steps per Second: 10,026.29115

Timestep Collection Time: 4.19777
Timestep Consumption Time: 0.79071
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.98848

Cumulative Model Updates: 57,627
Cumulative Timesteps: 961,211,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 961211990...
Checkpoint 961211990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,668.76959
Policy Entropy: 1.06364
Value Function Loss: 2.69709

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11,449.14448
Overall Steps per Second: 9,730.64310

Timestep Collection Time: 4.36749
Timestep Consumption Time: 0.77133
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.13882

Cumulative Model Updates: 57,630
Cumulative Timesteps: 961,261,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763,902.68676
Policy Entropy: 1.02130
Value Function Loss: 2.72507

Mean KL Divergence: 0.06333
SB3 Clip Fraction: 0.26331
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 12,074.61314
Overall Steps per Second: 10,159.57171

Timestep Collection Time: 4.14175
Timestep Consumption Time: 0.78070
PPO Batch Consumption Time: 0.03264
Total Iteration Time: 4.92245

Cumulative Model Updates: 57,633
Cumulative Timesteps: 961,312,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961312004...
Checkpoint 961312004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,944.11083
Policy Entropy: 1.04978
Value Function Loss: 2.80487

Mean KL Divergence: 0.03087
SB3 Clip Fraction: 0.20697
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.08848

Collected Steps per Second: 11,940.56383
Overall Steps per Second: 10,106.16054

Timestep Collection Time: 4.18975
Timestep Consumption Time: 0.76050
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.95025

Cumulative Model Updates: 57,636
Cumulative Timesteps: 961,362,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756,303.52135
Policy Entropy: 1.00692
Value Function Loss: 2.91169

Mean KL Divergence: 0.06161
SB3 Clip Fraction: 0.27320
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.08881

Collected Steps per Second: 11,733.06939
Overall Steps per Second: 10,058.57212

Timestep Collection Time: 4.26351
Timestep Consumption Time: 0.70977
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.97327

Cumulative Model Updates: 57,639
Cumulative Timesteps: 961,412,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 961412056...
Checkpoint 961412056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,012.40637
Policy Entropy: 1.04198
Value Function Loss: 2.88160

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.20915
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.08908

Collected Steps per Second: 11,657.33124
Overall Steps per Second: 9,876.22080

Timestep Collection Time: 4.29000
Timestep Consumption Time: 0.77367
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.06368

Cumulative Model Updates: 57,642
Cumulative Timesteps: 961,462,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,475.53318
Policy Entropy: 1.01834
Value Function Loss: 2.82043

Mean KL Divergence: 0.03404
SB3 Clip Fraction: 0.19802
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.09005

Collected Steps per Second: 12,086.04744
Overall Steps per Second: 10,265.94357

Timestep Collection Time: 4.13783
Timestep Consumption Time: 0.73362
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.87145

Cumulative Model Updates: 57,645
Cumulative Timesteps: 961,512,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961512076...
Checkpoint 961512076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,823.88263
Policy Entropy: 1.04460
Value Function Loss: 2.78116

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.17590
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.10051

Collected Steps per Second: 11,574.00149
Overall Steps per Second: 9,817.20939

Timestep Collection Time: 4.32124
Timestep Consumption Time: 0.77329
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.09452

Cumulative Model Updates: 57,648
Cumulative Timesteps: 961,562,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592,832.55914
Policy Entropy: 1.03919
Value Function Loss: 2.76693

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 12,224.10743
Overall Steps per Second: 10,236.15916

Timestep Collection Time: 4.09191
Timestep Consumption Time: 0.79468
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.88660

Cumulative Model Updates: 57,651
Cumulative Timesteps: 961,612,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 961612110...
Checkpoint 961612110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,508.71754
Policy Entropy: 1.03091
Value Function Loss: 2.66352

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.10072

Collected Steps per Second: 11,368.85459
Overall Steps per Second: 9,879.33401

Timestep Collection Time: 4.40044
Timestep Consumption Time: 0.66346
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.06390

Cumulative Model Updates: 57,654
Cumulative Timesteps: 961,662,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,004.18862
Policy Entropy: 1.03331
Value Function Loss: 2.50611

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.07075
Value Function Update Magnitude: 0.10123

Collected Steps per Second: 11,921.30925
Overall Steps per Second: 9,911.29235

Timestep Collection Time: 4.19417
Timestep Consumption Time: 0.85058
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 5.04475

Cumulative Model Updates: 57,657
Cumulative Timesteps: 961,712,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 961712138...
Checkpoint 961712138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,535.09244
Policy Entropy: 1.02226
Value Function Loss: 2.42317

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.07482
Value Function Update Magnitude: 0.09193

Collected Steps per Second: 12,044.09198
Overall Steps per Second: 10,210.95903

Timestep Collection Time: 4.15141
Timestep Consumption Time: 0.74529
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.89670

Cumulative Model Updates: 57,660
Cumulative Timesteps: 961,762,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,031.25598
Policy Entropy: 1.02654
Value Function Loss: 2.50340

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 11,753.08330
Overall Steps per Second: 10,124.80330

Timestep Collection Time: 4.25693
Timestep Consumption Time: 0.68460
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.94153

Cumulative Model Updates: 57,663
Cumulative Timesteps: 961,812,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 961812170...
Checkpoint 961812170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,144.26622
Policy Entropy: 1.03626
Value Function Loss: 2.68583

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.16903
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.08946

Collected Steps per Second: 11,637.12858
Overall Steps per Second: 9,916.33236

Timestep Collection Time: 4.29780
Timestep Consumption Time: 0.74580
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.04360

Cumulative Model Updates: 57,666
Cumulative Timesteps: 961,862,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,670.34520
Policy Entropy: 1.04191
Value Function Loss: 2.63270

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11,921.70494
Overall Steps per Second: 10,232.59124

Timestep Collection Time: 4.19487
Timestep Consumption Time: 0.69246
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.88733

Cumulative Model Updates: 57,669
Cumulative Timesteps: 961,912,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961912194...
Checkpoint 961912194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,705.42931
Policy Entropy: 1.02156
Value Function Loss: 2.73119

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11,893.17710
Overall Steps per Second: 10,061.19480

Timestep Collection Time: 4.20409
Timestep Consumption Time: 0.76550
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.96959

Cumulative Model Updates: 57,672
Cumulative Timesteps: 961,962,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638,738.58455
Policy Entropy: 1.00928
Value Function Loss: 2.70563

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.19869
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 11,838.79702
Overall Steps per Second: 9,994.24290

Timestep Collection Time: 4.22442
Timestep Consumption Time: 0.77967
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.00408

Cumulative Model Updates: 57,675
Cumulative Timesteps: 962,012,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 962012206...
Checkpoint 962012206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,059.41435
Policy Entropy: 1.03292
Value Function Loss: 2.77540

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 12,018.06680
Overall Steps per Second: 10,368.58224

Timestep Collection Time: 4.16140
Timestep Consumption Time: 0.66202
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.82342

Cumulative Model Updates: 57,678
Cumulative Timesteps: 962,062,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709,378.03309
Policy Entropy: 1.03828
Value Function Loss: 2.72377

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.09049

Collected Steps per Second: 12,109.10114
Overall Steps per Second: 10,218.57238

Timestep Collection Time: 4.12979
Timestep Consumption Time: 0.76405
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.89383

Cumulative Model Updates: 57,681
Cumulative Timesteps: 962,112,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 962112226...
Checkpoint 962112226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,299.04245
Policy Entropy: 1.02369
Value Function Loss: 2.62037

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.17355
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 11,425.63432
Overall Steps per Second: 9,771.33208

Timestep Collection Time: 4.37788
Timestep Consumption Time: 0.74118
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.11906

Cumulative Model Updates: 57,684
Cumulative Timesteps: 962,162,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,408.92943
Policy Entropy: 1.03529
Value Function Loss: 2.68433

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.17435
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.09160

Collected Steps per Second: 12,367.17003
Overall Steps per Second: 10,347.74290

Timestep Collection Time: 4.04539
Timestep Consumption Time: 0.78948
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.83487

Cumulative Model Updates: 57,687
Cumulative Timesteps: 962,212,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 962212276...
Checkpoint 962212276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,769.09870
Policy Entropy: 1.03789
Value Function Loss: 2.79730

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.08278

Collected Steps per Second: 12,493.04846
Overall Steps per Second: 10,513.41947

Timestep Collection Time: 4.00415
Timestep Consumption Time: 0.75396
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.75811

Cumulative Model Updates: 57,690
Cumulative Timesteps: 962,262,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,816.90570
Policy Entropy: 1.03378
Value Function Loss: 2.83303

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 13,048.56912
Overall Steps per Second: 10,907.53062

Timestep Collection Time: 3.83398
Timestep Consumption Time: 0.75257
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 4.58656

Cumulative Model Updates: 57,693
Cumulative Timesteps: 962,312,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 962312328...
Checkpoint 962312328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,094.78597
Policy Entropy: 1.02690
Value Function Loss: 2.85286

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 12,632.17209
Overall Steps per Second: 10,510.65406

Timestep Collection Time: 3.95894
Timestep Consumption Time: 0.79909
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.75803

Cumulative Model Updates: 57,696
Cumulative Timesteps: 962,362,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,057.75114
Policy Entropy: 1.03329
Value Function Loss: 2.69031

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.07890

Collected Steps per Second: 12,481.57781
Overall Steps per Second: 10,642.95495

Timestep Collection Time: 4.00767
Timestep Consumption Time: 0.69234
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.70001

Cumulative Model Updates: 57,699
Cumulative Timesteps: 962,412,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 962412360...
Checkpoint 962412360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,645.61609
Policy Entropy: 1.03721
Value Function Loss: 2.62720

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.08505

Collected Steps per Second: 12,107.80948
Overall Steps per Second: 10,090.22767

Timestep Collection Time: 4.12990
Timestep Consumption Time: 0.82579
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.95569

Cumulative Model Updates: 57,702
Cumulative Timesteps: 962,462,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,570.72218
Policy Entropy: 1.04368
Value Function Loss: 2.58192

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.08744

Collected Steps per Second: 12,698.47750
Overall Steps per Second: 10,613.61069

Timestep Collection Time: 3.93890
Timestep Consumption Time: 0.77373
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 4.71263

Cumulative Model Updates: 57,705
Cumulative Timesteps: 962,512,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 962512382...
Checkpoint 962512382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,577.41210
Policy Entropy: 1.04211
Value Function Loss: 2.69613

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 12,627.91194
Overall Steps per Second: 10,572.64991

Timestep Collection Time: 3.96170
Timestep Consumption Time: 0.77013
PPO Batch Consumption Time: 0.03448
Total Iteration Time: 4.73183

Cumulative Model Updates: 57,708
Cumulative Timesteps: 962,562,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,692.32394
Policy Entropy: 1.03902
Value Function Loss: 2.77336

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 12,146.79582
Overall Steps per Second: 10,169.08389

Timestep Collection Time: 4.11730
Timestep Consumption Time: 0.80074
PPO Batch Consumption Time: 0.03779
Total Iteration Time: 4.91804

Cumulative Model Updates: 57,711
Cumulative Timesteps: 962,612,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 962612422...
Checkpoint 962612422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716,463.49672
Policy Entropy: 1.02146
Value Function Loss: 2.78154

Mean KL Divergence: 0.02876
SB3 Clip Fraction: 0.18740
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.09135

Collected Steps per Second: 11,603.96119
Overall Steps per Second: 10,004.55897

Timestep Collection Time: 4.30974
Timestep Consumption Time: 0.68899
PPO Batch Consumption Time: 0.03389
Total Iteration Time: 4.99872

Cumulative Model Updates: 57,714
Cumulative Timesteps: 962,662,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,170.31836
Policy Entropy: 1.04299
Value Function Loss: 2.69994

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 11,938.77525
Overall Steps per Second: 10,071.75537

Timestep Collection Time: 4.18820
Timestep Consumption Time: 0.77637
PPO Batch Consumption Time: 0.03675
Total Iteration Time: 4.96458

Cumulative Model Updates: 57,717
Cumulative Timesteps: 962,712,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 962712434...
Checkpoint 962712434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,895.72320
Policy Entropy: 1.04433
Value Function Loss: 2.72489

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11,906.43516
Overall Steps per Second: 10,014.34906

Timestep Collection Time: 4.20126
Timestep Consumption Time: 0.79378
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.99503

Cumulative Model Updates: 57,720
Cumulative Timesteps: 962,762,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,865.18902
Policy Entropy: 1.04320
Value Function Loss: 2.57837

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.08523

Collected Steps per Second: 12,078.61978
Overall Steps per Second: 10,227.15659

Timestep Collection Time: 4.14153
Timestep Consumption Time: 0.74976
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 4.89129

Cumulative Model Updates: 57,723
Cumulative Timesteps: 962,812,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 962812480...
Checkpoint 962812480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,813.20187
Policy Entropy: 1.03306
Value Function Loss: 2.48682

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.07730

Collected Steps per Second: 11,657.94842
Overall Steps per Second: 9,891.84163

Timestep Collection Time: 4.29012
Timestep Consumption Time: 0.76597
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 5.05609

Cumulative Model Updates: 57,726
Cumulative Timesteps: 962,862,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,002.29161
Policy Entropy: 1.03082
Value Function Loss: 2.47659

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.06125
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 11,805.58247
Overall Steps per Second: 10,202.40300

Timestep Collection Time: 4.23732
Timestep Consumption Time: 0.66584
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.90316

Cumulative Model Updates: 57,729
Cumulative Timesteps: 962,912,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 962912518...
Checkpoint 962912518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,228.79031
Policy Entropy: 1.03104
Value Function Loss: 2.60425

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.07046

Collected Steps per Second: 12,111.23599
Overall Steps per Second: 10,200.43317

Timestep Collection Time: 4.13071
Timestep Consumption Time: 0.77379
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 4.90450

Cumulative Model Updates: 57,732
Cumulative Timesteps: 962,962,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,280.19657
Policy Entropy: 1.03992
Value Function Loss: 2.65088

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.06430
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 11,668.29285
Overall Steps per Second: 10,083.43751

Timestep Collection Time: 4.28529
Timestep Consumption Time: 0.67354
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.95882

Cumulative Model Updates: 57,735
Cumulative Timesteps: 963,012,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963012548...
Checkpoint 963012548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,069.69454
Policy Entropy: 1.03726
Value Function Loss: 2.76402

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 12,093.36840
Overall Steps per Second: 10,009.83096

Timestep Collection Time: 4.13681
Timestep Consumption Time: 0.86107
PPO Batch Consumption Time: 0.03761
Total Iteration Time: 4.99789

Cumulative Model Updates: 57,738
Cumulative Timesteps: 963,062,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750,745.26833
Policy Entropy: 1.02744
Value Function Loss: 2.72185

Mean KL Divergence: 0.02479
SB3 Clip Fraction: 0.17824
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.10649

Collected Steps per Second: 11,825.29545
Overall Steps per Second: 10,011.63174

Timestep Collection Time: 4.23076
Timestep Consumption Time: 0.76643
PPO Batch Consumption Time: 0.03498
Total Iteration Time: 4.99719

Cumulative Model Updates: 57,741
Cumulative Timesteps: 963,112,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 963112606...
Checkpoint 963112606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,263.21813
Policy Entropy: 1.04085
Value Function Loss: 2.84505

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.15472
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.10595

Collected Steps per Second: 12,323.17041
Overall Steps per Second: 10,379.74971

Timestep Collection Time: 4.05870
Timestep Consumption Time: 0.75992
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.81861

Cumulative Model Updates: 57,744
Cumulative Timesteps: 963,162,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798,475.29851
Policy Entropy: 1.05016
Value Function Loss: 2.67909

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 12,050.23658
Overall Steps per Second: 10,158.73155

Timestep Collection Time: 4.14946
Timestep Consumption Time: 0.77261
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.92207

Cumulative Model Updates: 57,747
Cumulative Timesteps: 963,212,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963212624...
Checkpoint 963212624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,366.39423
Policy Entropy: 1.02915
Value Function Loss: 2.64114

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.09750

Collected Steps per Second: 11,921.17885
Overall Steps per Second: 10,247.13784

Timestep Collection Time: 4.19623
Timestep Consumption Time: 0.68552
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.88175

Cumulative Model Updates: 57,750
Cumulative Timesteps: 963,262,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,812.07623
Policy Entropy: 1.01793
Value Function Loss: 2.56029

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.19011
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.10340

Collected Steps per Second: 12,182.52512
Overall Steps per Second: 10,132.29469

Timestep Collection Time: 4.10605
Timestep Consumption Time: 0.83084
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.93689

Cumulative Model Updates: 57,753
Cumulative Timesteps: 963,312,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 963312670...
Checkpoint 963312670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,078.23629
Policy Entropy: 1.04128
Value Function Loss: 2.69679

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.10849

Collected Steps per Second: 11,895.99865
Overall Steps per Second: 10,057.02258

Timestep Collection Time: 4.20343
Timestep Consumption Time: 0.76862
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.97205

Cumulative Model Updates: 57,756
Cumulative Timesteps: 963,362,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,311.50317
Policy Entropy: 1.04979
Value Function Loss: 2.78603

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11163

Collected Steps per Second: 11,518.03539
Overall Steps per Second: 9,969.37457

Timestep Collection Time: 4.34275
Timestep Consumption Time: 0.67461
PPO Batch Consumption Time: 0.03788
Total Iteration Time: 5.01737

Cumulative Model Updates: 57,759
Cumulative Timesteps: 963,412,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963412694...
Checkpoint 963412694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,910.37593
Policy Entropy: 1.03304
Value Function Loss: 2.76525

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 12,186.77887
Overall Steps per Second: 10,218.20901

Timestep Collection Time: 4.10330
Timestep Consumption Time: 0.79051
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.89381

Cumulative Model Updates: 57,762
Cumulative Timesteps: 963,462,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621,036.39611
Policy Entropy: 1.02490
Value Function Loss: 2.66273

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.18860
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.11818

Collected Steps per Second: 12,111.39920
Overall Steps per Second: 10,225.09043

Timestep Collection Time: 4.12851
Timestep Consumption Time: 0.76162
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.89013

Cumulative Model Updates: 57,765
Cumulative Timesteps: 963,512,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963512702...
Checkpoint 963512702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698,902.47081
Policy Entropy: 1.03800
Value Function Loss: 2.64806

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 12,411.21630
Overall Steps per Second: 10,427.29820

Timestep Collection Time: 4.02926
Timestep Consumption Time: 0.76661
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.79587

Cumulative Model Updates: 57,768
Cumulative Timesteps: 963,562,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,775.86042
Policy Entropy: 1.05075
Value Function Loss: 2.63279

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.10677

Collected Steps per Second: 12,111.89420
Overall Steps per Second: 10,251.92311

Timestep Collection Time: 4.12850
Timestep Consumption Time: 0.74902
PPO Batch Consumption Time: 0.03289
Total Iteration Time: 4.87752

Cumulative Model Updates: 57,771
Cumulative Timesteps: 963,612,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 963612714...
Checkpoint 963612714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,890.93773
Policy Entropy: 1.02297
Value Function Loss: 2.70935

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.10013

Collected Steps per Second: 12,011.35978
Overall Steps per Second: 10,352.31163

Timestep Collection Time: 4.16406
Timestep Consumption Time: 0.66733
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 4.83138

Cumulative Model Updates: 57,774
Cumulative Timesteps: 963,662,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,942.94963
Policy Entropy: 1.03680
Value Function Loss: 2.65449

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.17081
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 11,605.43139
Overall Steps per Second: 9,865.29961

Timestep Collection Time: 4.31005
Timestep Consumption Time: 0.76025
PPO Batch Consumption Time: 0.03468
Total Iteration Time: 5.07030

Cumulative Model Updates: 57,777
Cumulative Timesteps: 963,712,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963712750...
Checkpoint 963712750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,590.05016
Policy Entropy: 1.03786
Value Function Loss: 2.62067

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.17814
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.09975

Collected Steps per Second: 11,819.20781
Overall Steps per Second: 10,050.09232

Timestep Collection Time: 4.23176
Timestep Consumption Time: 0.74492
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 4.97667

Cumulative Model Updates: 57,780
Cumulative Timesteps: 963,762,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,985.55198
Policy Entropy: 1.02752
Value Function Loss: 2.62802

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.15522
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 12,595.72552
Overall Steps per Second: 10,533.66570

Timestep Collection Time: 3.96992
Timestep Consumption Time: 0.77715
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 4.74707

Cumulative Model Updates: 57,783
Cumulative Timesteps: 963,812,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 963812770...
Checkpoint 963812770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,287.62055
Policy Entropy: 1.01906
Value Function Loss: 2.57301

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.18599
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 11,919.70452
Overall Steps per Second: 10,132.44797

Timestep Collection Time: 4.19557
Timestep Consumption Time: 0.74005
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.93563

Cumulative Model Updates: 57,786
Cumulative Timesteps: 963,862,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,512.46441
Policy Entropy: 1.02766
Value Function Loss: 2.58545

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09143

Collected Steps per Second: 12,083.73340
Overall Steps per Second: 10,367.25291

Timestep Collection Time: 4.14011
Timestep Consumption Time: 0.68547
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 4.82558

Cumulative Model Updates: 57,789
Cumulative Timesteps: 963,912,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 963912808...
Checkpoint 963912808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,248.39769
Policy Entropy: 1.04378
Value Function Loss: 2.52252

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 11,954.93627
Overall Steps per Second: 10,096.94908

Timestep Collection Time: 4.18488
Timestep Consumption Time: 0.77008
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.95496

Cumulative Model Updates: 57,792
Cumulative Timesteps: 963,962,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,437.51270
Policy Entropy: 1.02004
Value Function Loss: 2.63670

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.16133
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 11,419.20010
Overall Steps per Second: 9,783.13892

Timestep Collection Time: 4.38017
Timestep Consumption Time: 0.73251
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 5.11267

Cumulative Model Updates: 57,795
Cumulative Timesteps: 964,012,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 964012856...
Checkpoint 964012856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,373.85476
Policy Entropy: 1.04307
Value Function Loss: 2.66922

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.16135
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 12,113.89942
Overall Steps per Second: 10,321.44525

Timestep Collection Time: 4.12997
Timestep Consumption Time: 0.71722
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.84719

Cumulative Model Updates: 57,798
Cumulative Timesteps: 964,062,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,353.46561
Policy Entropy: 1.04488
Value Function Loss: 2.68997

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.17559
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 11,927.51659
Overall Steps per Second: 10,086.65088

Timestep Collection Time: 4.19249
Timestep Consumption Time: 0.76515
PPO Batch Consumption Time: 0.03504
Total Iteration Time: 4.95764

Cumulative Model Updates: 57,801
Cumulative Timesteps: 964,112,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 964112892...
Checkpoint 964112892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,560.73233
Policy Entropy: 1.02973
Value Function Loss: 2.76184

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.08555

Collected Steps per Second: 11,935.66925
Overall Steps per Second: 10,171.01619

Timestep Collection Time: 4.19164
Timestep Consumption Time: 0.72724
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.91888

Cumulative Model Updates: 57,804
Cumulative Timesteps: 964,162,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,284.20127
Policy Entropy: 1.01918
Value Function Loss: 2.78838

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.19018
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.09396

Collected Steps per Second: 12,229.69794
Overall Steps per Second: 10,296.22895

Timestep Collection Time: 4.08923
Timestep Consumption Time: 0.76789
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.85712

Cumulative Model Updates: 57,807
Cumulative Timesteps: 964,212,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 964212932...
Checkpoint 964212932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,205.60615
Policy Entropy: 1.02746
Value Function Loss: 2.71988

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.10944

Collected Steps per Second: 11,939.34579
Overall Steps per Second: 10,117.18029

Timestep Collection Time: 4.18850
Timestep Consumption Time: 0.75437
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.94288

Cumulative Model Updates: 57,810
Cumulative Timesteps: 964,262,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,363.47780
Policy Entropy: 1.04061
Value Function Loss: 2.67782

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 11,493.23877
Overall Steps per Second: 9,966.93393

Timestep Collection Time: 4.35125
Timestep Consumption Time: 0.66634
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.01759

Cumulative Model Updates: 57,813
Cumulative Timesteps: 964,312,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 964312950...
Checkpoint 964312950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,051.77138
Policy Entropy: 1.01375
Value Function Loss: 2.66663

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 11,878.63696
Overall Steps per Second: 10,025.82236

Timestep Collection Time: 4.21008
Timestep Consumption Time: 0.77804
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.98812

Cumulative Model Updates: 57,816
Cumulative Timesteps: 964,362,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,486.56544
Policy Entropy: 1.03676
Value Function Loss: 2.76583

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.17301
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.10015

Collected Steps per Second: 11,957.81116
Overall Steps per Second: 10,105.89042

Timestep Collection Time: 4.18304
Timestep Consumption Time: 0.76655
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.94959

Cumulative Model Updates: 57,819
Cumulative Timesteps: 964,412,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 964412980...
Checkpoint 964412980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624,170.89516
Policy Entropy: 1.03815
Value Function Loss: 2.74830

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.08855

Collected Steps per Second: 11,974.61261
Overall Steps per Second: 10,058.78086

Timestep Collection Time: 4.17700
Timestep Consumption Time: 0.79557
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 4.97257

Cumulative Model Updates: 57,822
Cumulative Timesteps: 964,462,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,921.13035
Policy Entropy: 1.02934
Value Function Loss: 2.80676

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08572

Collected Steps per Second: 12,008.26389
Overall Steps per Second: 10,136.79710

Timestep Collection Time: 4.16497
Timestep Consumption Time: 0.76894
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 4.93391

Cumulative Model Updates: 57,825
Cumulative Timesteps: 964,513,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 964513012...
Checkpoint 964513012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,047.15910
Policy Entropy: 1.01435
Value Function Loss: 2.69253

Mean KL Divergence: 0.03754
SB3 Clip Fraction: 0.21517
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 11,847.45878
Overall Steps per Second: 10,160.76380

Timestep Collection Time: 4.22268
Timestep Consumption Time: 0.70097
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 4.92365

Cumulative Model Updates: 57,828
Cumulative Timesteps: 964,563,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,997.80270
Policy Entropy: 1.04098
Value Function Loss: 2.70026

Mean KL Divergence: 0.03179
SB3 Clip Fraction: 0.19441
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11,564.20326
Overall Steps per Second: 9,788.60248

Timestep Collection Time: 4.32403
Timestep Consumption Time: 0.78436
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 5.10839

Cumulative Model Updates: 57,831
Cumulative Timesteps: 964,613,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 964613044...
Checkpoint 964613044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,739.10740
Policy Entropy: 1.01013
Value Function Loss: 2.64232

Mean KL Divergence: 0.04305
SB3 Clip Fraction: 0.23135
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 12,043.63988
Overall Steps per Second: 10,141.93704

Timestep Collection Time: 4.15306
Timestep Consumption Time: 0.77874
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.93180

Cumulative Model Updates: 57,834
Cumulative Timesteps: 964,663,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758,880.99134
Policy Entropy: 1.04034
Value Function Loss: 2.67684

Mean KL Divergence: 0.03045
SB3 Clip Fraction: 0.20039
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.10085

Collected Steps per Second: 12,556.24318
Overall Steps per Second: 10,703.71422

Timestep Collection Time: 3.98399
Timestep Consumption Time: 0.68952
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 4.67352

Cumulative Model Updates: 57,837
Cumulative Timesteps: 964,713,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 964713086...
Checkpoint 964713086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,663.40406
Policy Entropy: 1.02993
Value Function Loss: 2.69734

Mean KL Divergence: 0.02814
SB3 Clip Fraction: 0.17647
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.09021

Collected Steps per Second: 12,738.43651
Overall Steps per Second: 10,639.78862

Timestep Collection Time: 3.92560
Timestep Consumption Time: 0.77431
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.69991

Cumulative Model Updates: 57,840
Cumulative Timesteps: 964,763,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609,537.95742
Policy Entropy: 1.02667
Value Function Loss: 2.80054

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.19791
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 12,348.71930
Overall Steps per Second: 10,398.01520

Timestep Collection Time: 4.04933
Timestep Consumption Time: 0.75967
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 4.80899

Cumulative Model Updates: 57,843
Cumulative Timesteps: 964,813,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 964813096...
Checkpoint 964813096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,521.71372
Policy Entropy: 1.03771
Value Function Loss: 2.79281

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 12,112.59857
Overall Steps per Second: 10,209.95191

Timestep Collection Time: 4.12810
Timestep Consumption Time: 0.76928
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.89738

Cumulative Model Updates: 57,846
Cumulative Timesteps: 964,863,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,567.21571
Policy Entropy: 1.04718
Value Function Loss: 2.72002

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.09485

Collected Steps per Second: 11,884.58627
Overall Steps per Second: 10,027.72037

Timestep Collection Time: 4.20881
Timestep Consumption Time: 0.77936
PPO Batch Consumption Time: 0.03211
Total Iteration Time: 4.98817

Cumulative Model Updates: 57,849
Cumulative Timesteps: 964,913,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 964913118...
Checkpoint 964913118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759,667.66941
Policy Entropy: 1.01341
Value Function Loss: 2.63621

Mean KL Divergence: 0.03299
SB3 Clip Fraction: 0.20325
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.09171

Collected Steps per Second: 12,603.29552
Overall Steps per Second: 10,775.74067

Timestep Collection Time: 3.96928
Timestep Consumption Time: 0.67319
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 4.64247

Cumulative Model Updates: 57,852
Cumulative Timesteps: 964,963,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,106.77944
Policy Entropy: 1.03210
Value Function Loss: 2.63100

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 12,040.19618
Overall Steps per Second: 10,128.57775

Timestep Collection Time: 4.15508
Timestep Consumption Time: 0.78421
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.93929

Cumulative Model Updates: 57,855
Cumulative Timesteps: 965,013,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 965013172...
Checkpoint 965013172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,644.58700
Policy Entropy: 1.04016
Value Function Loss: 2.55148

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.17544
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.09393

Collected Steps per Second: 12,029.95657
Overall Steps per Second: 10,120.42689

Timestep Collection Time: 4.15829
Timestep Consumption Time: 0.78459
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 4.94287

Cumulative Model Updates: 57,858
Cumulative Timesteps: 965,063,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,455.63465
Policy Entropy: 1.01892
Value Function Loss: 2.58760

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.08980

Collected Steps per Second: 12,087.10021
Overall Steps per Second: 10,159.75808

Timestep Collection Time: 4.13747
Timestep Consumption Time: 0.78489
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.92236

Cumulative Model Updates: 57,861
Cumulative Timesteps: 965,113,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 965113206...
Checkpoint 965113206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,921.44011
Policy Entropy: 1.02021
Value Function Loss: 2.56902

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.08250

Collected Steps per Second: 11,706.89458
Overall Steps per Second: 9,852.22587

Timestep Collection Time: 4.27201
Timestep Consumption Time: 0.80420
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.07621

Cumulative Model Updates: 57,864
Cumulative Timesteps: 965,163,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742,163.56930
Policy Entropy: 1.03723
Value Function Loss: 2.78276

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 11,376.33143
Overall Steps per Second: 9,857.41955

Timestep Collection Time: 4.39720
Timestep Consumption Time: 0.67756
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.07476

Cumulative Model Updates: 57,867
Cumulative Timesteps: 965,213,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 965213242...
Checkpoint 965213242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,911.40121
Policy Entropy: 1.04930
Value Function Loss: 2.68225

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 12,023.85882
Overall Steps per Second: 10,106.64934

Timestep Collection Time: 4.15890
Timestep Consumption Time: 0.78893
PPO Batch Consumption Time: 0.03784
Total Iteration Time: 4.94783

Cumulative Model Updates: 57,870
Cumulative Timesteps: 965,263,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,515.79330
Policy Entropy: 1.04224
Value Function Loss: 2.79263

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 11,838.40042
Overall Steps per Second: 10,005.17837

Timestep Collection Time: 4.22608
Timestep Consumption Time: 0.77433
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.00041

Cumulative Model Updates: 57,873
Cumulative Timesteps: 965,313,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 965313278...
Checkpoint 965313278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,090.86620
Policy Entropy: 1.02642
Value Function Loss: 2.66828

Mean KL Divergence: 0.03037
SB3 Clip Fraction: 0.21127
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.08099

Collected Steps per Second: 11,957.25436
Overall Steps per Second: 10,089.89842

Timestep Collection Time: 4.18273
Timestep Consumption Time: 0.77411
PPO Batch Consumption Time: 0.03676
Total Iteration Time: 4.95684

Cumulative Model Updates: 57,876
Cumulative Timesteps: 965,363,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,845.88608
Policy Entropy: 1.03908
Value Function Loss: 2.82978

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 11,839.59354
Overall Steps per Second: 9,981.01169

Timestep Collection Time: 4.22413
Timestep Consumption Time: 0.78658
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 5.01071

Cumulative Model Updates: 57,879
Cumulative Timesteps: 965,413,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 965413304...
Checkpoint 965413304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,160.44940
Policy Entropy: 1.03164
Value Function Loss: 2.78604

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.09582

Collected Steps per Second: 11,568.11263
Overall Steps per Second: 9,991.11393

Timestep Collection Time: 4.32447
Timestep Consumption Time: 0.68258
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.00705

Cumulative Model Updates: 57,882
Cumulative Timesteps: 965,463,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,740.85109
Policy Entropy: 1.02735
Value Function Loss: 2.84167

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 11,509.32157
Overall Steps per Second: 9,765.41132

Timestep Collection Time: 4.34691
Timestep Consumption Time: 0.77627
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 5.12318

Cumulative Model Updates: 57,885
Cumulative Timesteps: 965,513,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 965513360...
Checkpoint 965513360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,347.68470
Policy Entropy: 1.03500
Value Function Loss: 2.85739

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 11,639.70700
Overall Steps per Second: 9,932.71056

Timestep Collection Time: 4.29581
Timestep Consumption Time: 0.73826
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.03407

Cumulative Model Updates: 57,888
Cumulative Timesteps: 965,563,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,182.52729
Policy Entropy: 1.03494
Value Function Loss: 2.89785

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.07567
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 11,671.54879
Overall Steps per Second: 10,106.12645

Timestep Collection Time: 4.28512
Timestep Consumption Time: 0.66376
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 4.94888

Cumulative Model Updates: 57,891
Cumulative Timesteps: 965,613,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 965613376...
Checkpoint 965613376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,565.22240
Policy Entropy: 1.02981
Value Function Loss: 2.87991

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 12,012.65783
Overall Steps per Second: 10,071.96001

Timestep Collection Time: 4.16261
Timestep Consumption Time: 0.80207
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 4.96467

Cumulative Model Updates: 57,894
Cumulative Timesteps: 965,663,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,807.87646
Policy Entropy: 1.02253
Value Function Loss: 2.76404

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 11,823.70302
Overall Steps per Second: 10,041.37264

Timestep Collection Time: 4.23099
Timestep Consumption Time: 0.75100
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.98199

Cumulative Model Updates: 57,897
Cumulative Timesteps: 965,713,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 965713406...
Checkpoint 965713406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,905.19796
Policy Entropy: 1.03470
Value Function Loss: 2.73824

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 12,095.04213
Overall Steps per Second: 10,164.74752

Timestep Collection Time: 4.13525
Timestep Consumption Time: 0.78529
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 4.92054

Cumulative Model Updates: 57,900
Cumulative Timesteps: 965,763,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,879.79058
Policy Entropy: 1.03967
Value Function Loss: 2.62306

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.08836

Collected Steps per Second: 11,214.81324
Overall Steps per Second: 9,588.50869

Timestep Collection Time: 4.46089
Timestep Consumption Time: 0.75661
PPO Batch Consumption Time: 0.03436
Total Iteration Time: 5.21750

Cumulative Model Updates: 57,903
Cumulative Timesteps: 965,813,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 965813450...
Checkpoint 965813450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,674.58776
Policy Entropy: 1.03799
Value Function Loss: 2.60875

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16358
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 11,997.69145
Overall Steps per Second: 10,296.58319

Timestep Collection Time: 4.16747
Timestep Consumption Time: 0.68851
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.85598

Cumulative Model Updates: 57,906
Cumulative Timesteps: 965,863,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730,720.06915
Policy Entropy: 1.02181
Value Function Loss: 2.44309

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 12,081.64392
Overall Steps per Second: 10,174.14461

Timestep Collection Time: 4.14033
Timestep Consumption Time: 0.77625
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.91658

Cumulative Model Updates: 57,909
Cumulative Timesteps: 965,913,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 965913472...
Checkpoint 965913472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646,868.11181
Policy Entropy: 1.01439
Value Function Loss: 2.52683

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.17378
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.09569

Collected Steps per Second: 12,151.09182
Overall Steps per Second: 10,299.87070

Timestep Collection Time: 4.11683
Timestep Consumption Time: 0.73993
PPO Batch Consumption Time: 0.03584
Total Iteration Time: 4.85676

Cumulative Model Updates: 57,912
Cumulative Timesteps: 965,963,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,648.68159
Policy Entropy: 1.04384
Value Function Loss: 2.46204

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.10506

Collected Steps per Second: 12,181.26707
Overall Steps per Second: 10,253.51622

Timestep Collection Time: 4.10598
Timestep Consumption Time: 0.77196
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 4.87794

Cumulative Model Updates: 57,915
Cumulative Timesteps: 966,013,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 966013512...
Checkpoint 966013512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,366.80295
Policy Entropy: 1.05091
Value Function Loss: 2.56948

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.10013

Collected Steps per Second: 12,155.89467
Overall Steps per Second: 10,298.93651

Timestep Collection Time: 4.11340
Timestep Consumption Time: 0.74167
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.85506

Cumulative Model Updates: 57,918
Cumulative Timesteps: 966,063,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,666.62152
Policy Entropy: 1.04318
Value Function Loss: 2.73701

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.09903

Collected Steps per Second: 11,691.31014
Overall Steps per Second: 10,107.18895

Timestep Collection Time: 4.27754
Timestep Consumption Time: 0.67043
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.94796

Cumulative Model Updates: 57,921
Cumulative Timesteps: 966,113,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 966113524...
Checkpoint 966113524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,189.02707
Policy Entropy: 1.03699
Value Function Loss: 2.93303

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 11,937.31827
Overall Steps per Second: 10,018.39409

Timestep Collection Time: 4.19039
Timestep Consumption Time: 0.80263
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 4.99302

Cumulative Model Updates: 57,924
Cumulative Timesteps: 966,163,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,174.33113
Policy Entropy: 1.04710
Value Function Loss: 2.97036

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 11,917.75017
Overall Steps per Second: 10,085.59526

Timestep Collection Time: 4.19609
Timestep Consumption Time: 0.76226
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.95836

Cumulative Model Updates: 57,927
Cumulative Timesteps: 966,213,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 966213554...
Checkpoint 966213554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,628.31119
Policy Entropy: 1.05162
Value Function Loss: 2.85279

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.08219

Collected Steps per Second: 11,935.05214
Overall Steps per Second: 10,084.33169

Timestep Collection Time: 4.18951
Timestep Consumption Time: 0.76888
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.95839

Cumulative Model Updates: 57,930
Cumulative Timesteps: 966,263,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,576.60989
Policy Entropy: 1.03492
Value Function Loss: 2.68179

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 11,756.64262
Overall Steps per Second: 9,939.46538

Timestep Collection Time: 4.25343
Timestep Consumption Time: 0.77763
PPO Batch Consumption Time: 0.03749
Total Iteration Time: 5.03106

Cumulative Model Updates: 57,933
Cumulative Timesteps: 966,313,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 966313562...
Checkpoint 966313562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773,683.09159
Policy Entropy: 1.03250
Value Function Loss: 2.70698

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.15955
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07866

Collected Steps per Second: 12,154.29436
Overall Steps per Second: 10,408.18464

Timestep Collection Time: 4.11492
Timestep Consumption Time: 0.69033
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.80526

Cumulative Model Updates: 57,936
Cumulative Timesteps: 966,363,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,459.13318
Policy Entropy: 1.04891
Value Function Loss: 2.70860

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 11,518.92914
Overall Steps per Second: 9,741.49806

Timestep Collection Time: 4.34085
Timestep Consumption Time: 0.79203
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 5.13289

Cumulative Model Updates: 57,939
Cumulative Timesteps: 966,413,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 966413578...
Checkpoint 966413578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776,750.31297
Policy Entropy: 1.05410
Value Function Loss: 2.71347

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.08176

Collected Steps per Second: 11,747.24869
Overall Steps per Second: 9,982.41780

Timestep Collection Time: 4.25734
Timestep Consumption Time: 0.75267
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.01001

Cumulative Model Updates: 57,942
Cumulative Timesteps: 966,463,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,310.46962
Policy Entropy: 1.03586
Value Function Loss: 2.69917

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 12,386.75602
Overall Steps per Second: 10,410.51563

Timestep Collection Time: 4.03689
Timestep Consumption Time: 0.76633
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.80322

Cumulative Model Updates: 57,945
Cumulative Timesteps: 966,513,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 966513594...
Checkpoint 966513594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,791.35901
Policy Entropy: 1.02159
Value Function Loss: 2.79101

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.09171

Collected Steps per Second: 12,004.30955
Overall Steps per Second: 10,119.07145

Timestep Collection Time: 4.16684
Timestep Consumption Time: 0.77630
PPO Batch Consumption Time: 0.03428
Total Iteration Time: 4.94314

Cumulative Model Updates: 57,948
Cumulative Timesteps: 966,563,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770,333.19268
Policy Entropy: 1.03848
Value Function Loss: 2.77629

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.09892

Collected Steps per Second: 11,809.76352
Overall Steps per Second: 10,161.81243

Timestep Collection Time: 4.23599
Timestep Consumption Time: 0.68695
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.92294

Cumulative Model Updates: 57,951
Cumulative Timesteps: 966,613,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 966613640...
Checkpoint 966613640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,362.97979
Policy Entropy: 1.05273
Value Function Loss: 2.71152

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 11,620.14276
Overall Steps per Second: 9,865.17340

Timestep Collection Time: 4.30373
Timestep Consumption Time: 0.76561
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.06935

Cumulative Model Updates: 57,954
Cumulative Timesteps: 966,663,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,420.70989
Policy Entropy: 1.03201
Value Function Loss: 2.64354

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 11,692.58488
Overall Steps per Second: 9,961.30287

Timestep Collection Time: 4.27792
Timestep Consumption Time: 0.74351
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 5.02143

Cumulative Model Updates: 57,957
Cumulative Timesteps: 966,713,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 966713670...
Checkpoint 966713670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743,823.84473
Policy Entropy: 1.01668
Value Function Loss: 2.69201

Mean KL Divergence: 0.02809
SB3 Clip Fraction: 0.17550
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.09099

Collected Steps per Second: 11,757.13305
Overall Steps per Second: 10,124.31650

Timestep Collection Time: 4.25546
Timestep Consumption Time: 0.68631
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.94177

Cumulative Model Updates: 57,960
Cumulative Timesteps: 966,763,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,503.75749
Policy Entropy: 1.02882
Value Function Loss: 2.73814

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.10725

Collected Steps per Second: 12,039.23664
Overall Steps per Second: 10,097.70693

Timestep Collection Time: 4.15425
Timestep Consumption Time: 0.79876
PPO Batch Consumption Time: 0.03371
Total Iteration Time: 4.95301

Cumulative Model Updates: 57,963
Cumulative Timesteps: 966,813,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 966813716...
Checkpoint 966813716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,248.07183
Policy Entropy: 1.03543
Value Function Loss: 2.65964

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.11427

Collected Steps per Second: 12,073.31730
Overall Steps per Second: 10,235.77880

Timestep Collection Time: 4.14269
Timestep Consumption Time: 0.74370
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.88639

Cumulative Model Updates: 57,966
Cumulative Timesteps: 966,863,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,254.52893
Policy Entropy: 1.00951
Value Function Loss: 2.67257

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 11,998.34467
Overall Steps per Second: 10,124.07589

Timestep Collection Time: 4.16908
Timestep Consumption Time: 0.77182
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 4.94090

Cumulative Model Updates: 57,969
Cumulative Timesteps: 966,913,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 966913754...
Checkpoint 966913754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,656.18659
Policy Entropy: 0.99918
Value Function Loss: 2.48592

Mean KL Divergence: 0.02809
SB3 Clip Fraction: 0.18183
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 11,835.04218
Overall Steps per Second: 9,972.72180

Timestep Collection Time: 4.22508
Timestep Consumption Time: 0.78900
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.01408

Cumulative Model Updates: 57,972
Cumulative Timesteps: 966,963,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,152.35182
Policy Entropy: 1.01825
Value Function Loss: 2.47581

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 11,572.46663
Overall Steps per Second: 9,943.97815

Timestep Collection Time: 4.32233
Timestep Consumption Time: 0.70785
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.03018

Cumulative Model Updates: 57,975
Cumulative Timesteps: 967,013,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 967013778...
Checkpoint 967013778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,801.00731
Policy Entropy: 1.03828
Value Function Loss: 2.41969

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.17201
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 11,845.81390
Overall Steps per Second: 9,992.48436

Timestep Collection Time: 4.22208
Timestep Consumption Time: 0.78308
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.00516

Cumulative Model Updates: 57,978
Cumulative Timesteps: 967,063,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,828.41262
Policy Entropy: 1.00293
Value Function Loss: 2.78817

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.18622
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 12,396.38385
Overall Steps per Second: 10,401.44578

Timestep Collection Time: 4.03553
Timestep Consumption Time: 0.77399
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 4.80952

Cumulative Model Updates: 57,981
Cumulative Timesteps: 967,113,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 967113818...
Checkpoint 967113818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,302.44867
Policy Entropy: 1.02415
Value Function Loss: 2.81884

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16657
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 12,466.65121
Overall Steps per Second: 10,536.57925

Timestep Collection Time: 4.01150
Timestep Consumption Time: 0.73482
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 4.74632

Cumulative Model Updates: 57,984
Cumulative Timesteps: 967,163,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,520.15391
Policy Entropy: 1.02085
Value Function Loss: 2.78756

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.16515
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.09877

Collected Steps per Second: 12,687.44775
Overall Steps per Second: 10,592.54811

Timestep Collection Time: 3.94295
Timestep Consumption Time: 0.77980
PPO Batch Consumption Time: 0.03378
Total Iteration Time: 4.72275

Cumulative Model Updates: 57,987
Cumulative Timesteps: 967,213,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 967213854...
Checkpoint 967213854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765,109.09000
Policy Entropy: 1.01682
Value Function Loss: 2.63993

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.16559
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 12,556.13750
Overall Steps per Second: 10,593.95246

Timestep Collection Time: 3.98228
Timestep Consumption Time: 0.73759
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.71986

Cumulative Model Updates: 57,990
Cumulative Timesteps: 967,263,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,109.89439
Policy Entropy: 1.01608
Value Function Loss: 2.70238

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.18924
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.11744

Collected Steps per Second: 12,772.15650
Overall Steps per Second: 10,526.01917

Timestep Collection Time: 3.91617
Timestep Consumption Time: 0.83567
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.75184

Cumulative Model Updates: 57,993
Cumulative Timesteps: 967,313,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 967313874...
Checkpoint 967313874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,633.76331
Policy Entropy: 1.03059
Value Function Loss: 2.77964

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 12,207.62256
Overall Steps per Second: 10,134.87718

Timestep Collection Time: 4.09580
Timestep Consumption Time: 0.83766
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 4.93346

Cumulative Model Updates: 57,996
Cumulative Timesteps: 967,363,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,981.39150
Policy Entropy: 1.04007
Value Function Loss: 2.84320

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.16357
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 12,150.96964
Overall Steps per Second: 10,445.26933

Timestep Collection Time: 4.11671
Timestep Consumption Time: 0.67225
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.78896

Cumulative Model Updates: 57,999
Cumulative Timesteps: 967,413,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 967413896...
Checkpoint 967413896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747,199.70009
Policy Entropy: 1.00352
Value Function Loss: 2.79546

Mean KL Divergence: 0.06137
SB3 Clip Fraction: 0.23958
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.10923

Collected Steps per Second: 11,935.37439
Overall Steps per Second: 10,020.04911

Timestep Collection Time: 4.19040
Timestep Consumption Time: 0.80099
PPO Batch Consumption Time: 0.03967
Total Iteration Time: 4.99139

Cumulative Model Updates: 58,002
Cumulative Timesteps: 967,463,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756,580.62904
Policy Entropy: 1.03724
Value Function Loss: 2.64376

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.19412
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.09538

Collected Steps per Second: 11,960.62327
Overall Steps per Second: 10,134.46127

Timestep Collection Time: 4.18089
Timestep Consumption Time: 0.75337
PPO Batch Consumption Time: 0.03789
Total Iteration Time: 4.93425

Cumulative Model Updates: 58,005
Cumulative Timesteps: 967,513,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 967513916...
Checkpoint 967513916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755,674.45658
Policy Entropy: 1.00466
Value Function Loss: 2.48836

Mean KL Divergence: 0.03225
SB3 Clip Fraction: 0.19815
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 11,553.90242
Overall Steps per Second: 9,975.98267

Timestep Collection Time: 4.33014
Timestep Consumption Time: 0.68491
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.01504

Cumulative Model Updates: 58,008
Cumulative Timesteps: 967,563,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,666.39845
Policy Entropy: 1.02639
Value Function Loss: 2.43809

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.18887
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.08334

Collected Steps per Second: 12,086.47935
Overall Steps per Second: 10,068.64664

Timestep Collection Time: 4.13917
Timestep Consumption Time: 0.82952
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.96869

Cumulative Model Updates: 58,011
Cumulative Timesteps: 967,613,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 967613974...
Checkpoint 967613974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,294.18040
Policy Entropy: 1.02195
Value Function Loss: 2.62718

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.17379
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 11,804.22457
Overall Steps per Second: 10,025.80881

Timestep Collection Time: 4.23594
Timestep Consumption Time: 0.75139
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.98733

Cumulative Model Updates: 58,014
Cumulative Timesteps: 967,663,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,644.79044
Policy Entropy: 1.02267
Value Function Loss: 2.79221

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.16881
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 12,073.32104
Overall Steps per Second: 10,138.14093

Timestep Collection Time: 4.14385
Timestep Consumption Time: 0.79098
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 4.93483

Cumulative Model Updates: 58,017
Cumulative Timesteps: 967,714,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 967714006...
Checkpoint 967714006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,950.70864
Policy Entropy: 1.02501
Value Function Loss: 2.87876

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.18240
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.08840

Collected Steps per Second: 11,839.85174
Overall Steps per Second: 10,041.62111

Timestep Collection Time: 4.22421
Timestep Consumption Time: 0.75646
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.98067

Cumulative Model Updates: 58,020
Cumulative Timesteps: 967,764,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,748.70601
Policy Entropy: 1.03107
Value Function Loss: 2.78814

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 11,862.14695
Overall Steps per Second: 10,220.37351

Timestep Collection Time: 4.21661
Timestep Consumption Time: 0.67734
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.89395

Cumulative Model Updates: 58,023
Cumulative Timesteps: 967,814,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 967814038...
Checkpoint 967814038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526,753.96833
Policy Entropy: 1.03180
Value Function Loss: 2.71779

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.16652
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 11,690.16265
Overall Steps per Second: 9,892.97487

Timestep Collection Time: 4.27984
Timestep Consumption Time: 0.77749
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 5.05733

Cumulative Model Updates: 58,026
Cumulative Timesteps: 967,864,070

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785,140.56977
Policy Entropy: 1.01062
Value Function Loss: 2.60429

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.07805

Collected Steps per Second: 11,992.04610
Overall Steps per Second: 10,114.67349

Timestep Collection Time: 4.16993
Timestep Consumption Time: 0.77398
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 4.94391

Cumulative Model Updates: 58,029
Cumulative Timesteps: 967,914,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 967914076...
Checkpoint 967914076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,248.00545
Policy Entropy: 1.02899
Value Function Loss: 2.68904

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.07991

Collected Steps per Second: 11,558.24806
Overall Steps per Second: 10,034.34954

Timestep Collection Time: 4.32678
Timestep Consumption Time: 0.65710
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 4.98388

Cumulative Model Updates: 58,032
Cumulative Timesteps: 967,964,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,080.21863
Policy Entropy: 1.04001
Value Function Loss: 2.70114

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 11,750.43215
Overall Steps per Second: 9,941.85853

Timestep Collection Time: 4.25652
Timestep Consumption Time: 0.77433
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.03085

Cumulative Model Updates: 58,035
Cumulative Timesteps: 968,014,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 968014102...
Checkpoint 968014102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,361.70801
Policy Entropy: 1.02546
Value Function Loss: 2.74240

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.09471

Collected Steps per Second: 11,017.25447
Overall Steps per Second: 9,573.49121

Timestep Collection Time: 4.54015
Timestep Consumption Time: 0.68469
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.22484

Cumulative Model Updates: 58,038
Cumulative Timesteps: 968,064,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,129.03462
Policy Entropy: 1.01037
Value Function Loss: 2.64764

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.18384
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.09345

Collected Steps per Second: 11,922.99363
Overall Steps per Second: 10,006.40463

Timestep Collection Time: 4.19559
Timestep Consumption Time: 0.80361
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.99920

Cumulative Model Updates: 58,041
Cumulative Timesteps: 968,114,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 968114146...
Checkpoint 968114146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672,395.97350
Policy Entropy: 1.02660
Value Function Loss: 2.54437

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09855

Collected Steps per Second: 11,846.20627
Overall Steps per Second: 10,043.27985

Timestep Collection Time: 4.22329
Timestep Consumption Time: 0.75815
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.98144

Cumulative Model Updates: 58,044
Cumulative Timesteps: 968,164,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,491.79895
Policy Entropy: 1.04364
Value Function Loss: 2.58199

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.08717

Collected Steps per Second: 11,966.65503
Overall Steps per Second: 10,197.44422

Timestep Collection Time: 4.17911
Timestep Consumption Time: 0.72506
PPO Batch Consumption Time: 0.03439
Total Iteration Time: 4.90417

Cumulative Model Updates: 58,047
Cumulative Timesteps: 968,214,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 968214186...
Checkpoint 968214186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,522.01143
Policy Entropy: 1.02380
Value Function Loss: 2.55719

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 11,752.36136
Overall Steps per Second: 9,864.43290

Timestep Collection Time: 4.25480
Timestep Consumption Time: 0.81432
PPO Batch Consumption Time: 0.03657
Total Iteration Time: 5.06912

Cumulative Model Updates: 58,050
Cumulative Timesteps: 968,264,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,304.51850
Policy Entropy: 1.02850
Value Function Loss: 2.57371

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.07164

Collected Steps per Second: 12,026.33412
Overall Steps per Second: 10,195.12900

Timestep Collection Time: 4.15771
Timestep Consumption Time: 0.74679
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.90450

Cumulative Model Updates: 58,053
Cumulative Timesteps: 968,314,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 968314192...
Checkpoint 968314192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,982.14648
Policy Entropy: 1.04411
Value Function Loss: 2.49959

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.07873

Collected Steps per Second: 12,132.88026
Overall Steps per Second: 10,247.76046

Timestep Collection Time: 4.12301
Timestep Consumption Time: 0.75845
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.88146

Cumulative Model Updates: 58,056
Cumulative Timesteps: 968,364,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,707.91100
Policy Entropy: 1.04667
Value Function Loss: 2.48767

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.07744

Collected Steps per Second: 12,115.03683
Overall Steps per Second: 10,195.98103

Timestep Collection Time: 4.12710
Timestep Consumption Time: 0.77679
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.90389

Cumulative Model Updates: 58,059
Cumulative Timesteps: 968,414,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968414216...
Checkpoint 968414216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,595.28833
Policy Entropy: 1.04660
Value Function Loss: 2.48126

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.07530

Collected Steps per Second: 11,895.64552
Overall Steps per Second: 10,261.92146

Timestep Collection Time: 4.20540
Timestep Consumption Time: 0.66951
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.87492

Cumulative Model Updates: 58,062
Cumulative Timesteps: 968,464,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,127.47228
Policy Entropy: 1.03547
Value Function Loss: 2.55755

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 12,173.14612
Overall Steps per Second: 10,243.60592

Timestep Collection Time: 4.10789
Timestep Consumption Time: 0.77378
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 4.88168

Cumulative Model Updates: 58,065
Cumulative Timesteps: 968,514,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 968514248...
Checkpoint 968514248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,780.25205
Policy Entropy: 1.04106
Value Function Loss: 2.73253

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 11,490.43659
Overall Steps per Second: 9,829.63377

Timestep Collection Time: 4.35249
Timestep Consumption Time: 0.73539
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.08788

Cumulative Model Updates: 58,068
Cumulative Timesteps: 968,564,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730,934.43142
Policy Entropy: 1.04243
Value Function Loss: 2.85178

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.06263
Value Function Update Magnitude: 0.09335

Collected Steps per Second: 12,231.01854
Overall Steps per Second: 10,308.18679

Timestep Collection Time: 4.08895
Timestep Consumption Time: 0.76273
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 4.85168

Cumulative Model Updates: 58,071
Cumulative Timesteps: 968,614,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 968614272...
Checkpoint 968614272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776,696.89748
Policy Entropy: 1.04700
Value Function Loss: 2.80483

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.07020
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 11,853.24340
Overall Steps per Second: 10,089.36546

Timestep Collection Time: 4.21977
Timestep Consumption Time: 0.73772
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.95750

Cumulative Model Updates: 58,074
Cumulative Timesteps: 968,664,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744,495.40143
Policy Entropy: 1.04536
Value Function Loss: 2.77312

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 12,187.86894
Overall Steps per Second: 10,481.03600

Timestep Collection Time: 4.10342
Timestep Consumption Time: 0.66824
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 4.77167

Cumulative Model Updates: 58,077
Cumulative Timesteps: 968,714,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 968714302...
Checkpoint 968714302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,441.87247
Policy Entropy: 1.04395
Value Function Loss: 2.69946

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.07580
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 11,764.49802
Overall Steps per Second: 9,909.42937

Timestep Collection Time: 4.25059
Timestep Consumption Time: 0.79572
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.04630

Cumulative Model Updates: 58,080
Cumulative Timesteps: 968,764,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,573.25584
Policy Entropy: 1.04586
Value Function Loss: 2.73293

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.07690
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 12,049.26541
Overall Steps per Second: 10,247.05665

Timestep Collection Time: 4.15146
Timestep Consumption Time: 0.73014
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.88160

Cumulative Model Updates: 58,083
Cumulative Timesteps: 968,814,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 968814330...
Checkpoint 968814330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,336.10579
Policy Entropy: 1.04602
Value Function Loss: 2.79169

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.07774
Value Function Update Magnitude: 0.10164

Collected Steps per Second: 11,765.95652
Overall Steps per Second: 9,973.85727

Timestep Collection Time: 4.25006
Timestep Consumption Time: 0.76365
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.01371

Cumulative Model Updates: 58,086
Cumulative Timesteps: 968,864,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,024.10687
Policy Entropy: 1.03236
Value Function Loss: 2.81769

Mean KL Divergence: 0.03358
SB3 Clip Fraction: 0.19417
Policy Update Magnitude: 0.06802
Value Function Update Magnitude: 0.10484

Collected Steps per Second: 11,903.50162
Overall Steps per Second: 9,937.36642

Timestep Collection Time: 4.20162
Timestep Consumption Time: 0.83130
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.03292

Cumulative Model Updates: 58,089
Cumulative Timesteps: 968,914,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 968914350...
Checkpoint 968914350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,914.77016
Policy Entropy: 1.05277
Value Function Loss: 2.90476

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.09838

Collected Steps per Second: 11,921.67315
Overall Steps per Second: 10,234.32938

Timestep Collection Time: 4.19438
Timestep Consumption Time: 0.69153
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.88591

Cumulative Model Updates: 58,092
Cumulative Timesteps: 968,964,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,845.48157
Policy Entropy: 1.05181
Value Function Loss: 2.75809

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 12,042.93397
Overall Steps per Second: 10,146.07752

Timestep Collection Time: 4.15414
Timestep Consumption Time: 0.77664
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.93077

Cumulative Model Updates: 58,095
Cumulative Timesteps: 969,014,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 969014382...
Checkpoint 969014382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,740.89428
Policy Entropy: 1.04454
Value Function Loss: 2.71717

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.06946
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11,746.94135
Overall Steps per Second: 10,035.74029

Timestep Collection Time: 4.25779
Timestep Consumption Time: 0.72600
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 4.98379

Cumulative Model Updates: 58,098
Cumulative Timesteps: 969,064,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,715.26399
Policy Entropy: 1.03399
Value Function Loss: 2.60558

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.08826

Collected Steps per Second: 11,952.56890
Overall Steps per Second: 10,322.74379

Timestep Collection Time: 4.18588
Timestep Consumption Time: 0.66090
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.84677

Cumulative Model Updates: 58,101
Cumulative Timesteps: 969,114,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 969114430...
Checkpoint 969114430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,993.06492
Policy Entropy: 1.04488
Value Function Loss: 2.65311

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.16763
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 11,471.42391
Overall Steps per Second: 9,749.78128

Timestep Collection Time: 4.35935
Timestep Consumption Time: 0.76979
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.12914

Cumulative Model Updates: 58,104
Cumulative Timesteps: 969,164,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,622.24993
Policy Entropy: 1.05062
Value Function Loss: 2.65365

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.16769
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.08159

Collected Steps per Second: 11,904.00466
Overall Steps per Second: 10,054.12493

Timestep Collection Time: 4.20228
Timestep Consumption Time: 0.77319
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.97547

Cumulative Model Updates: 58,107
Cumulative Timesteps: 969,214,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 969214462...
Checkpoint 969214462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,267.96305
Policy Entropy: 1.04204
Value Function Loss: 2.69234

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 11,781.10588
Overall Steps per Second: 10,129.55628

Timestep Collection Time: 4.24663
Timestep Consumption Time: 0.69238
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.93901

Cumulative Model Updates: 58,110
Cumulative Timesteps: 969,264,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,196.39663
Policy Entropy: 1.03856
Value Function Loss: 2.79711

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.17954
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.10035

Collected Steps per Second: 11,978.58465
Overall Steps per Second: 9,931.41143

Timestep Collection Time: 4.17528
Timestep Consumption Time: 0.86066
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.03594

Cumulative Model Updates: 58,113
Cumulative Timesteps: 969,314,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 969314506...
Checkpoint 969314506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745,566.46914
Policy Entropy: 1.04797
Value Function Loss: 2.78805

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 11,768.99309
Overall Steps per Second: 10,096.59235

Timestep Collection Time: 4.24930
Timestep Consumption Time: 0.70385
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 4.95316

Cumulative Model Updates: 58,116
Cumulative Timesteps: 969,364,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,171.00683
Policy Entropy: 1.05001
Value Function Loss: 2.65568

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 11,855.36568
Overall Steps per Second: 9,899.94878

Timestep Collection Time: 4.22003
Timestep Consumption Time: 0.83353
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.05356

Cumulative Model Updates: 58,119
Cumulative Timesteps: 969,414,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 969414546...
Checkpoint 969414546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634,003.63416
Policy Entropy: 1.02877
Value Function Loss: 2.55760

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.08932

Collected Steps per Second: 11,429.54822
Overall Steps per Second: 9,615.92444

Timestep Collection Time: 4.37585
Timestep Consumption Time: 0.82531
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 5.20116

Cumulative Model Updates: 58,122
Cumulative Timesteps: 969,464,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,015.08977
Policy Entropy: 1.03710
Value Function Loss: 2.67442

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.15911
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.08630

Collected Steps per Second: 11,886.41894
Overall Steps per Second: 10,198.39564

Timestep Collection Time: 4.20766
Timestep Consumption Time: 0.69645
PPO Batch Consumption Time: 0.03388
Total Iteration Time: 4.90410

Cumulative Model Updates: 58,125
Cumulative Timesteps: 969,514,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 969514574...
Checkpoint 969514574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,649.24326
Policy Entropy: 1.03696
Value Function Loss: 2.76305

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.09546

Collected Steps per Second: 12,888.29786
Overall Steps per Second: 10,572.04748

Timestep Collection Time: 3.87980
Timestep Consumption Time: 0.85003
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 4.72983

Cumulative Model Updates: 58,128
Cumulative Timesteps: 969,564,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,097.89481
Policy Entropy: 1.02983
Value Function Loss: 2.75188

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.10774

Collected Steps per Second: 12,795.13245
Overall Steps per Second: 10,631.40685

Timestep Collection Time: 3.90899
Timestep Consumption Time: 0.79556
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.70455

Cumulative Model Updates: 58,131
Cumulative Timesteps: 969,614,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 969614594...
Checkpoint 969614594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,205.34243
Policy Entropy: 1.02417
Value Function Loss: 2.73866

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.06967
Value Function Update Magnitude: 0.09847

Collected Steps per Second: 12,978.49675
Overall Steps per Second: 10,810.18593

Timestep Collection Time: 3.85330
Timestep Consumption Time: 0.77290
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.62619

Cumulative Model Updates: 58,134
Cumulative Timesteps: 969,664,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,741.25060
Policy Entropy: 1.04042
Value Function Loss: 2.72446

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 13,002.89285
Overall Steps per Second: 10,709.29838

Timestep Collection Time: 3.84576
Timestep Consumption Time: 0.82364
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.66940

Cumulative Model Updates: 58,137
Cumulative Timesteps: 969,714,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 969714610...
Checkpoint 969714610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,157.06262
Policy Entropy: 1.04115
Value Function Loss: 2.83741

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.09296

Collected Steps per Second: 11,998.08144
Overall Steps per Second: 10,317.18367

Timestep Collection Time: 4.16833
Timestep Consumption Time: 0.67911
PPO Batch Consumption Time: 0.03331
Total Iteration Time: 4.84745

Cumulative Model Updates: 58,140
Cumulative Timesteps: 969,764,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799,228.04271
Policy Entropy: 1.04305
Value Function Loss: 2.72766

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 12,509.02945
Overall Steps per Second: 10,451.75871

Timestep Collection Time: 3.99775
Timestep Consumption Time: 0.78690
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 4.78465

Cumulative Model Updates: 58,143
Cumulative Timesteps: 969,814,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 969814630...
Checkpoint 969814630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,938.51279
Policy Entropy: 1.04283
Value Function Loss: 2.73930

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.07216
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 11,906.26512
Overall Steps per Second: 10,103.82120

Timestep Collection Time: 4.20132
Timestep Consumption Time: 0.74948
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.95080

Cumulative Model Updates: 58,146
Cumulative Timesteps: 969,864,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,227.41659
Policy Entropy: 1.04578
Value Function Loss: 2.54957

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.08530
Value Function Update Magnitude: 0.09941

Collected Steps per Second: 11,822.50842
Overall Steps per Second: 10,148.02442

Timestep Collection Time: 4.22990
Timestep Consumption Time: 0.69796
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 4.92786

Cumulative Model Updates: 58,149
Cumulative Timesteps: 969,914,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 969914660...
Checkpoint 969914660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,828.22683
Policy Entropy: 1.04086
Value Function Loss: 2.64580

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.08168
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 12,027.56280
Overall Steps per Second: 10,151.18434

Timestep Collection Time: 4.15911
Timestep Consumption Time: 0.76878
PPO Batch Consumption Time: 0.03666
Total Iteration Time: 4.92790

Cumulative Model Updates: 58,152
Cumulative Timesteps: 969,964,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,145.67324
Policy Entropy: 1.04430
Value Function Loss: 2.70532

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.10147

Collected Steps per Second: 12,052.22299
Overall Steps per Second: 10,112.36205

Timestep Collection Time: 4.14878
Timestep Consumption Time: 0.79586
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 4.94464

Cumulative Model Updates: 58,155
Cumulative Timesteps: 970,014,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 970014686...
Checkpoint 970014686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,838.33676
Policy Entropy: 1.04051
Value Function Loss: 2.77078

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.07265
Value Function Update Magnitude: 0.10370

Collected Steps per Second: 11,558.11184
Overall Steps per Second: 9,824.50950

Timestep Collection Time: 4.32597
Timestep Consumption Time: 0.76335
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 5.08931

Cumulative Model Updates: 58,158
Cumulative Timesteps: 970,064,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,332.95603
Policy Entropy: 1.05214
Value Function Loss: 2.77963

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 12,083.66211
Overall Steps per Second: 10,182.78262

Timestep Collection Time: 4.13980
Timestep Consumption Time: 0.77280
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.91261

Cumulative Model Updates: 58,161
Cumulative Timesteps: 970,114,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 970114710...
Checkpoint 970114710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,461.65574
Policy Entropy: 1.05461
Value Function Loss: 2.75841

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.09825

Collected Steps per Second: 11,927.01117
Overall Steps per Second: 10,301.17247

Timestep Collection Time: 4.19468
Timestep Consumption Time: 0.66205
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.85673

Cumulative Model Updates: 58,164
Cumulative Timesteps: 970,164,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,727.78419
Policy Entropy: 1.05604
Value Function Loss: 2.83357

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.07249
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 12,064.19076
Overall Steps per Second: 10,177.52952

Timestep Collection Time: 4.14615
Timestep Consumption Time: 0.76859
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.91475

Cumulative Model Updates: 58,167
Cumulative Timesteps: 970,214,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 970214760...
Checkpoint 970214760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,925.81130
Policy Entropy: 1.05210
Value Function Loss: 2.77120

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.08351
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 11,761.98208
Overall Steps per Second: 9,889.46251

Timestep Collection Time: 4.25098
Timestep Consumption Time: 0.80490
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.05589

Cumulative Model Updates: 58,170
Cumulative Timesteps: 970,264,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,974.68670
Policy Entropy: 1.06080
Value Function Loss: 2.81659

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.07161
Value Function Update Magnitude: 0.11316

Collected Steps per Second: 11,870.44590
Overall Steps per Second: 10,224.03123

Timestep Collection Time: 4.21315
Timestep Consumption Time: 0.67846
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.89161

Cumulative Model Updates: 58,173
Cumulative Timesteps: 970,314,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 970314772...
Checkpoint 970314772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770,334.08907
Policy Entropy: 1.06527
Value Function Loss: 2.71649

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.10948

Collected Steps per Second: 11,436.27855
Overall Steps per Second: 9,644.27415

Timestep Collection Time: 4.37310
Timestep Consumption Time: 0.81257
PPO Batch Consumption Time: 0.03338
Total Iteration Time: 5.18567

Cumulative Model Updates: 58,176
Cumulative Timesteps: 970,364,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,663.33199
Policy Entropy: 1.06636
Value Function Loss: 2.73256

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.10086

Collected Steps per Second: 11,979.35816
Overall Steps per Second: 10,198.67785

Timestep Collection Time: 4.17502
Timestep Consumption Time: 0.72895
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.90397

Cumulative Model Updates: 58,179
Cumulative Timesteps: 970,414,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 970414798...
Checkpoint 970414798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,355.08048
Policy Entropy: 1.07008
Value Function Loss: 2.70152

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.09770

Collected Steps per Second: 11,942.50709
Overall Steps per Second: 10,064.45441

Timestep Collection Time: 4.18773
Timestep Consumption Time: 0.78144
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.96917

Cumulative Model Updates: 58,182
Cumulative Timesteps: 970,464,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720,526.32995
Policy Entropy: 1.06195
Value Function Loss: 2.68103

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.07699
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 12,160.85370
Overall Steps per Second: 10,271.93515

Timestep Collection Time: 4.11221
Timestep Consumption Time: 0.75620
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.86841

Cumulative Model Updates: 58,185
Cumulative Timesteps: 970,514,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 970514818...
Checkpoint 970514818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760,941.40259
Policy Entropy: 1.07769
Value Function Loss: 2.77014

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.06863
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 11,820.99325
Overall Steps per Second: 10,151.28484

Timestep Collection Time: 4.22993
Timestep Consumption Time: 0.69575
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.92568

Cumulative Model Updates: 58,188
Cumulative Timesteps: 970,564,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,693.16503
Policy Entropy: 1.07920
Value Function Loss: 2.68166

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.08803

Collected Steps per Second: 11,500.42078
Overall Steps per Second: 9,737.87864

Timestep Collection Time: 4.35010
Timestep Consumption Time: 0.78736
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.13746

Cumulative Model Updates: 58,191
Cumulative Timesteps: 970,614,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 970614848...
Checkpoint 970614848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,131.68941
Policy Entropy: 1.07986
Value Function Loss: 2.67194

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.08519

Collected Steps per Second: 11,375.41332
Overall Steps per Second: 9,705.14918

Timestep Collection Time: 4.39562
Timestep Consumption Time: 0.75649
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.15211

Cumulative Model Updates: 58,194
Cumulative Timesteps: 970,664,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,170.12107
Policy Entropy: 1.07633
Value Function Loss: 2.68525

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.08530

Collected Steps per Second: 12,182.43039
Overall Steps per Second: 10,221.39922

Timestep Collection Time: 4.10624
Timestep Consumption Time: 0.78780
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.89405

Cumulative Model Updates: 58,197
Cumulative Timesteps: 970,714,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 970714874...
Checkpoint 970714874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,774.30900
Policy Entropy: 1.07623
Value Function Loss: 2.77431

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 12,164.65571
Overall Steps per Second: 10,218.63586

Timestep Collection Time: 4.11175
Timestep Consumption Time: 0.78303
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.89478

Cumulative Model Updates: 58,200
Cumulative Timesteps: 970,764,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849,376.54758
Policy Entropy: 1.08363
Value Function Loss: 2.82490

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 12,018.62635
Overall Steps per Second: 10,348.73234

Timestep Collection Time: 4.16204
Timestep Consumption Time: 0.67160
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.83364

Cumulative Model Updates: 58,203
Cumulative Timesteps: 970,814,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 970814914...
Checkpoint 970814914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,201.50843
Policy Entropy: 1.08269
Value Function Loss: 2.71020

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.07769

Collected Steps per Second: 11,859.03648
Overall Steps per Second: 9,985.00254

Timestep Collection Time: 4.21856
Timestep Consumption Time: 0.79176
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.01031

Cumulative Model Updates: 58,206
Cumulative Timesteps: 970,864,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,035.23715
Policy Entropy: 1.08872
Value Function Loss: 2.74843

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 11,885.11829
Overall Steps per Second: 10,161.11531

Timestep Collection Time: 4.20711
Timestep Consumption Time: 0.71381
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.92092

Cumulative Model Updates: 58,209
Cumulative Timesteps: 970,914,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 970914944...
Checkpoint 970914944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,664.17228
Policy Entropy: 1.08470
Value Function Loss: 2.74819

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.08047

Collected Steps per Second: 11,566.21893
Overall Steps per Second: 9,976.55683

Timestep Collection Time: 4.32484
Timestep Consumption Time: 0.68912
PPO Batch Consumption Time: 0.03736
Total Iteration Time: 5.01395

Cumulative Model Updates: 58,212
Cumulative Timesteps: 970,964,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,472.72503
Policy Entropy: 1.09044
Value Function Loss: 2.85349

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 12,149.16729
Overall Steps per Second: 10,187.68415

Timestep Collection Time: 4.11715
Timestep Consumption Time: 0.79270
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 4.90985

Cumulative Model Updates: 58,215
Cumulative Timesteps: 971,014,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 971014986...
Checkpoint 971014986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,679.94335
Policy Entropy: 1.08826
Value Function Loss: 2.82860

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 11,870.05630
Overall Steps per Second: 10,013.36911

Timestep Collection Time: 4.21295
Timestep Consumption Time: 0.78117
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.99412

Cumulative Model Updates: 58,218
Cumulative Timesteps: 971,064,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,292.26727
Policy Entropy: 1.09956
Value Function Loss: 2.94336

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.07955

Collected Steps per Second: 11,922.88647
Overall Steps per Second: 10,078.17028

Timestep Collection Time: 4.19596
Timestep Consumption Time: 0.76803
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.96400

Cumulative Model Updates: 58,221
Cumulative Timesteps: 971,115,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 971115022...
Checkpoint 971115022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,572.09000
Policy Entropy: 1.10619
Value Function Loss: 2.89804

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 11,787.59934
Overall Steps per Second: 9,962.43822

Timestep Collection Time: 4.24175
Timestep Consumption Time: 0.77711
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.01885

Cumulative Model Updates: 58,224
Cumulative Timesteps: 971,165,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602,333.03756
Policy Entropy: 1.10451
Value Function Loss: 2.94963

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.07217
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 11,715.10331
Overall Steps per Second: 10,110.13845

Timestep Collection Time: 4.26885
Timestep Consumption Time: 0.67767
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.94652

Cumulative Model Updates: 58,227
Cumulative Timesteps: 971,215,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 971215032...
Checkpoint 971215032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,707.92023
Policy Entropy: 1.09019
Value Function Loss: 3.00731

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.17310
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 11,469.62021
Overall Steps per Second: 9,732.60692

Timestep Collection Time: 4.35969
Timestep Consumption Time: 0.77809
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.13778

Cumulative Model Updates: 58,230
Cumulative Timesteps: 971,265,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,733.80869
Policy Entropy: 1.11096
Value Function Loss: 3.04711

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.10111

Collected Steps per Second: 11,902.82734
Overall Steps per Second: 10,223.03632

Timestep Collection Time: 4.20236
Timestep Consumption Time: 0.69051
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 4.89287

Cumulative Model Updates: 58,233
Cumulative Timesteps: 971,315,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 971315056...
Checkpoint 971315056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727,574.26991
Policy Entropy: 1.10727
Value Function Loss: 2.99583

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 11,745.18959
Overall Steps per Second: 9,972.65455

Timestep Collection Time: 4.25876
Timestep Consumption Time: 0.75695
PPO Batch Consumption Time: 0.03324
Total Iteration Time: 5.01572

Cumulative Model Updates: 58,236
Cumulative Timesteps: 971,365,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,274.64374
Policy Entropy: 1.10225
Value Function Loss: 2.77651

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.12580

Collected Steps per Second: 11,570.68859
Overall Steps per Second: 9,836.36783

Timestep Collection Time: 4.32299
Timestep Consumption Time: 0.76222
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 5.08521

Cumulative Model Updates: 58,239
Cumulative Timesteps: 971,415,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 971415096...
Checkpoint 971415096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,460.31962
Policy Entropy: 1.09483
Value Function Loss: 2.68276

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 11,891.04763
Overall Steps per Second: 10,083.43201

Timestep Collection Time: 4.20686
Timestep Consumption Time: 0.75415
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.96101

Cumulative Model Updates: 58,242
Cumulative Timesteps: 971,465,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,092.86553
Policy Entropy: 1.08199
Value Function Loss: 2.58132

Mean KL Divergence: 0.03466
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.13704

Collected Steps per Second: 12,231.03496
Overall Steps per Second: 10,312.25314

Timestep Collection Time: 4.08976
Timestep Consumption Time: 0.76097
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 4.85073

Cumulative Model Updates: 58,245
Cumulative Timesteps: 971,515,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 971515142...
Checkpoint 971515142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,731.49144
Policy Entropy: 1.09565
Value Function Loss: 2.49445

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 11,475.93011
Overall Steps per Second: 9,939.69668

Timestep Collection Time: 4.35712
Timestep Consumption Time: 0.67342
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.03054

Cumulative Model Updates: 58,248
Cumulative Timesteps: 971,565,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,271.48522
Policy Entropy: 1.09519
Value Function Loss: 2.52176

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.06449
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 11,829.24998
Overall Steps per Second: 10,029.94403

Timestep Collection Time: 4.22783
Timestep Consumption Time: 0.75844
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.98627

Cumulative Model Updates: 58,251
Cumulative Timesteps: 971,615,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 971615156...
Checkpoint 971615156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,286.85719
Policy Entropy: 1.08973
Value Function Loss: 2.61887

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 11,938.30813
Overall Steps per Second: 10,019.53226

Timestep Collection Time: 4.18971
Timestep Consumption Time: 0.80234
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.99205

Cumulative Model Updates: 58,254
Cumulative Timesteps: 971,665,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,015.34097
Policy Entropy: 1.07298
Value Function Loss: 2.64152

Mean KL Divergence: 0.03807
SB3 Clip Fraction: 0.19685
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 11,119.26511
Overall Steps per Second: 9,665.67362

Timestep Collection Time: 4.49868
Timestep Consumption Time: 0.67654
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.17522

Cumulative Model Updates: 58,257
Cumulative Timesteps: 971,715,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 971715196...
Checkpoint 971715196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,842.25488
Policy Entropy: 1.09083
Value Function Loss: 2.78104

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 11,898.54361
Overall Steps per Second: 9,970.50119

Timestep Collection Time: 4.20304
Timestep Consumption Time: 0.81276
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.01580

Cumulative Model Updates: 58,260
Cumulative Timesteps: 971,765,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819,969.97316
Policy Entropy: 1.08496
Value Function Loss: 2.71035

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 11,579.69156
Overall Steps per Second: 9,962.43033

Timestep Collection Time: 4.31894
Timestep Consumption Time: 0.70112
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 5.02006

Cumulative Model Updates: 58,263
Cumulative Timesteps: 971,815,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 971815218...
Checkpoint 971815218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,163.21003
Policy Entropy: 1.08066
Value Function Loss: 2.93325

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 11,248.50235
Overall Steps per Second: 9,564.55938

Timestep Collection Time: 4.44681
Timestep Consumption Time: 0.78291
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.22972

Cumulative Model Updates: 58,266
Cumulative Timesteps: 971,865,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,669.04890
Policy Entropy: 1.09605
Value Function Loss: 3.00145

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 12,124.96598
Overall Steps per Second: 10,225.94410

Timestep Collection Time: 4.12537
Timestep Consumption Time: 0.76611
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 4.89148

Cumulative Model Updates: 58,269
Cumulative Timesteps: 971,915,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 971915258...
Checkpoint 971915258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,282.60176
Policy Entropy: 1.09870
Value Function Loss: 2.96084

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 12,625.56954
Overall Steps per Second: 10,774.64173

Timestep Collection Time: 3.96228
Timestep Consumption Time: 0.68066
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.64294

Cumulative Model Updates: 58,272
Cumulative Timesteps: 971,965,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,025.72388
Policy Entropy: 1.08299
Value Function Loss: 2.93625

Mean KL Divergence: 0.02829
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.09436

Collected Steps per Second: 12,726.93600
Overall Steps per Second: 10,665.36739

Timestep Collection Time: 3.92978
Timestep Consumption Time: 0.75961
PPO Batch Consumption Time: 0.03290
Total Iteration Time: 4.68938

Cumulative Model Updates: 58,275
Cumulative Timesteps: 972,015,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 972015298...
Checkpoint 972015298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,683.94355
Policy Entropy: 1.08722
Value Function Loss: 2.67086

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.09420

Collected Steps per Second: 12,563.74228
Overall Steps per Second: 10,484.29190

Timestep Collection Time: 3.98050
Timestep Consumption Time: 0.78949
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.76999

Cumulative Model Updates: 58,278
Cumulative Timesteps: 972,065,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,288.34322
Policy Entropy: 1.08832
Value Function Loss: 2.66587

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.11081

Collected Steps per Second: 12,886.82674
Overall Steps per Second: 10,654.48352

Timestep Collection Time: 3.88055
Timestep Consumption Time: 0.81306
PPO Batch Consumption Time: 0.03625
Total Iteration Time: 4.69361

Cumulative Model Updates: 58,281
Cumulative Timesteps: 972,115,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 972115316...
Checkpoint 972115316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,855.21913
Policy Entropy: 1.08822
Value Function Loss: 2.60293

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 11,972.52939
Overall Steps per Second: 10,029.04236

Timestep Collection Time: 4.17806
Timestep Consumption Time: 0.80965
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.98771

Cumulative Model Updates: 58,284
Cumulative Timesteps: 972,165,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,755.37720
Policy Entropy: 1.08596
Value Function Loss: 2.81296

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.08520
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 12,561.44958
Overall Steps per Second: 10,754.95644

Timestep Collection Time: 3.98202
Timestep Consumption Time: 0.66885
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.65088

Cumulative Model Updates: 58,287
Cumulative Timesteps: 972,215,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 972215358...
Checkpoint 972215358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,148.95031
Policy Entropy: 1.08531
Value Function Loss: 2.91236

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.09106
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 12,201.08429
Overall Steps per Second: 10,194.00964

Timestep Collection Time: 4.09931
Timestep Consumption Time: 0.80710
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.90641

Cumulative Model Updates: 58,290
Cumulative Timesteps: 972,265,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,329.60950
Policy Entropy: 1.09246
Value Function Loss: 2.95106

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.08089
Value Function Update Magnitude: 0.12196

Collected Steps per Second: 11,741.93715
Overall Steps per Second: 10,020.76138

Timestep Collection Time: 4.26080
Timestep Consumption Time: 0.73184
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 4.99263

Cumulative Model Updates: 58,293
Cumulative Timesteps: 972,315,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 972315404...
Checkpoint 972315404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,738.94888
Policy Entropy: 1.08985
Value Function Loss: 2.79101

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.07935
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 12,291.03454
Overall Steps per Second: 10,293.47028

Timestep Collection Time: 4.07028
Timestep Consumption Time: 0.78988
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.86017

Cumulative Model Updates: 58,296
Cumulative Timesteps: 972,365,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753,446.32451
Policy Entropy: 1.07955
Value Function Loss: 2.69817

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.07795
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 11,846.29822
Overall Steps per Second: 10,024.30004

Timestep Collection Time: 4.22258
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.03605
Total Iteration Time: 4.99007

Cumulative Model Updates: 58,299
Cumulative Timesteps: 972,415,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 972415454...
Checkpoint 972415454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,594.95127
Policy Entropy: 1.08840
Value Function Loss: 2.54096

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.12262

Collected Steps per Second: 11,748.58921
Overall Steps per Second: 10,048.26402

Timestep Collection Time: 4.25668
Timestep Consumption Time: 0.72030
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.97698

Cumulative Model Updates: 58,302
Cumulative Timesteps: 972,465,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,557.92093
Policy Entropy: 1.08606
Value Function Loss: 2.59862

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 12,274.56209
Overall Steps per Second: 10,336.88807

Timestep Collection Time: 4.07526
Timestep Consumption Time: 0.76392
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.83917

Cumulative Model Updates: 58,305
Cumulative Timesteps: 972,515,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 972515486...
Checkpoint 972515486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653,698.52891
Policy Entropy: 1.08437
Value Function Loss: 2.65435

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.10439

Collected Steps per Second: 11,838.03489
Overall Steps per Second: 10,075.87503

Timestep Collection Time: 4.22553
Timestep Consumption Time: 0.73900
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.96453

Cumulative Model Updates: 58,308
Cumulative Timesteps: 972,565,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,467.97836
Policy Entropy: 1.08046
Value Function Loss: 2.76800

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 11,902.51265
Overall Steps per Second: 10,120.36612

Timestep Collection Time: 4.20298
Timestep Consumption Time: 0.74012
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 4.94310

Cumulative Model Updates: 58,311
Cumulative Timesteps: 972,615,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 972615534...
Checkpoint 972615534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,545.74231
Policy Entropy: 1.08579
Value Function Loss: 2.68410

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.09743

Collected Steps per Second: 11,931.99317
Overall Steps per Second: 10,074.71300

Timestep Collection Time: 4.19109
Timestep Consumption Time: 0.77263
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.96371

Cumulative Model Updates: 58,314
Cumulative Timesteps: 972,665,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,083.99538
Policy Entropy: 1.09510
Value Function Loss: 2.74211

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.09446

Collected Steps per Second: 12,027.75424
Overall Steps per Second: 10,225.47014

Timestep Collection Time: 4.15905
Timestep Consumption Time: 0.73305
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.89210

Cumulative Model Updates: 58,317
Cumulative Timesteps: 972,715,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 972715566...
Checkpoint 972715566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,243.16214
Policy Entropy: 1.09721
Value Function Loss: 2.85105

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 12,360.45651
Overall Steps per Second: 10,227.50933

Timestep Collection Time: 4.04678
Timestep Consumption Time: 0.84396
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.89073

Cumulative Model Updates: 58,320
Cumulative Timesteps: 972,765,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,482.15376
Policy Entropy: 1.09785
Value Function Loss: 3.00225

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.08025
Value Function Update Magnitude: 0.07377

Collected Steps per Second: 11,776.72281
Overall Steps per Second: 9,977.15611

Timestep Collection Time: 4.24685
Timestep Consumption Time: 0.76600
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.01285

Cumulative Model Updates: 58,323
Cumulative Timesteps: 972,815,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 972815600...
Checkpoint 972815600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,347.09481
Policy Entropy: 1.08804
Value Function Loss: 2.91211

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.08242
Value Function Update Magnitude: 0.07287

Collected Steps per Second: 11,923.07123
Overall Steps per Second: 10,260.69805

Timestep Collection Time: 4.19439
Timestep Consumption Time: 0.67955
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.87394

Cumulative Model Updates: 58,326
Cumulative Timesteps: 972,865,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,500.44826
Policy Entropy: 1.09405
Value Function Loss: 2.79273

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.07480
Value Function Update Magnitude: 0.08288

Collected Steps per Second: 12,071.17096
Overall Steps per Second: 10,034.93065

Timestep Collection Time: 4.14343
Timestep Consumption Time: 0.84076
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 4.98419

Cumulative Model Updates: 58,329
Cumulative Timesteps: 972,915,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 972915626...
Checkpoint 972915626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574,568.66167
Policy Entropy: 1.08871
Value Function Loss: 2.56763

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 11,770.76502
Overall Steps per Second: 9,981.56765

Timestep Collection Time: 4.24832
Timestep Consumption Time: 0.76151
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.00983

Cumulative Model Updates: 58,332
Cumulative Timesteps: 972,965,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,101.59240
Policy Entropy: 1.10231
Value Function Loss: 2.63616

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.10750

Collected Steps per Second: 12,047.21868
Overall Steps per Second: 10,141.89180

Timestep Collection Time: 4.15216
Timestep Consumption Time: 0.78005
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 4.93222

Cumulative Model Updates: 58,335
Cumulative Timesteps: 973,015,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 973015654...
Checkpoint 973015654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,016.25026
Policy Entropy: 1.10402
Value Function Loss: 2.64894

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 11,922.46464
Overall Steps per Second: 9,939.59920

Timestep Collection Time: 4.19460
Timestep Consumption Time: 0.83679
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.03139

Cumulative Model Updates: 58,338
Cumulative Timesteps: 973,065,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,245.37231
Policy Entropy: 1.10916
Value Function Loss: 2.93856

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.07166
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 11,900.02683
Overall Steps per Second: 10,150.43925

Timestep Collection Time: 4.20167
Timestep Consumption Time: 0.72422
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 4.92590

Cumulative Model Updates: 58,341
Cumulative Timesteps: 973,115,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 973115664...
Checkpoint 973115664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,528.28740
Policy Entropy: 1.11215
Value Function Loss: 2.89406

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.11801

Collected Steps per Second: 11,977.26211
Overall Steps per Second: 10,107.34003

Timestep Collection Time: 4.17708
Timestep Consumption Time: 0.77279
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.94987

Cumulative Model Updates: 58,344
Cumulative Timesteps: 973,165,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,535.78946
Policy Entropy: 1.10020
Value Function Loss: 2.85115

Mean KL Divergence: 0.02664
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.12802

Collected Steps per Second: 12,357.92164
Overall Steps per Second: 10,416.39029

Timestep Collection Time: 4.04728
Timestep Consumption Time: 0.75438
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.80166

Cumulative Model Updates: 58,347
Cumulative Timesteps: 973,215,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 973215710...
Checkpoint 973215710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,323.80214
Policy Entropy: 1.11000
Value Function Loss: 2.77471

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 12,290.04355
Overall Steps per Second: 10,314.78211

Timestep Collection Time: 4.07012
Timestep Consumption Time: 0.77942
PPO Batch Consumption Time: 0.03387
Total Iteration Time: 4.84954

Cumulative Model Updates: 58,350
Cumulative Timesteps: 973,265,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662,102.89560
Policy Entropy: 1.10875
Value Function Loss: 2.87813

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.10032

Collected Steps per Second: 12,140.98745
Overall Steps per Second: 10,263.48220

Timestep Collection Time: 4.11845
Timestep Consumption Time: 0.75339
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 4.87184

Cumulative Model Updates: 58,353
Cumulative Timesteps: 973,315,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 973315734...
Checkpoint 973315734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,753.33194
Policy Entropy: 1.10678
Value Function Loss: 2.79806

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 12,172.07225
Overall Steps per Second: 10,442.43901

Timestep Collection Time: 4.10957
Timestep Consumption Time: 0.68069
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 4.79026

Cumulative Model Updates: 58,356
Cumulative Timesteps: 973,365,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,121.55974
Policy Entropy: 1.10416
Value Function Loss: 2.75523

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.09666

Collected Steps per Second: 11,706.90510
Overall Steps per Second: 9,925.92700

Timestep Collection Time: 4.27303
Timestep Consumption Time: 0.76670
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 5.03973

Cumulative Model Updates: 58,359
Cumulative Timesteps: 973,415,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 973415780...
Checkpoint 973415780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616,928.08603
Policy Entropy: 1.11976
Value Function Loss: 2.63237

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.09120

Collected Steps per Second: 12,070.55700
Overall Steps per Second: 10,382.17507

Timestep Collection Time: 4.14480
Timestep Consumption Time: 0.67404
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.81884

Cumulative Model Updates: 58,362
Cumulative Timesteps: 973,465,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,865.07473
Policy Entropy: 1.11636
Value Function Loss: 2.70410

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 11,958.88428
Overall Steps per Second: 10,036.21430

Timestep Collection Time: 4.18166
Timestep Consumption Time: 0.80109
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 4.98276

Cumulative Model Updates: 58,365
Cumulative Timesteps: 973,515,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 973515818...
Checkpoint 973515818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,022.39110
Policy Entropy: 1.09781
Value Function Loss: 2.71158

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 11,933.83971
Overall Steps per Second: 10,238.40749

Timestep Collection Time: 4.19060
Timestep Consumption Time: 0.69394
PPO Batch Consumption Time: 0.03576
Total Iteration Time: 4.88455

Cumulative Model Updates: 58,368
Cumulative Timesteps: 973,565,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,263.86311
Policy Entropy: 1.09978
Value Function Loss: 2.79517

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.10611

Collected Steps per Second: 12,061.16361
Overall Steps per Second: 10,094.49742

Timestep Collection Time: 4.14554
Timestep Consumption Time: 0.80766
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.95319

Cumulative Model Updates: 58,371
Cumulative Timesteps: 973,615,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 973615828...
Checkpoint 973615828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662,636.39991
Policy Entropy: 1.10339
Value Function Loss: 2.71697

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.10832

Collected Steps per Second: 11,952.50493
Overall Steps per Second: 10,096.61119

Timestep Collection Time: 4.18356
Timestep Consumption Time: 0.76899
PPO Batch Consumption Time: 0.03508
Total Iteration Time: 4.95255

Cumulative Model Updates: 58,374
Cumulative Timesteps: 973,665,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,543.68256
Policy Entropy: 1.11211
Value Function Loss: 2.70412

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 11,304.50323
Overall Steps per Second: 9,770.45278

Timestep Collection Time: 4.42372
Timestep Consumption Time: 0.69457
PPO Batch Consumption Time: 0.03860
Total Iteration Time: 5.11829

Cumulative Model Updates: 58,377
Cumulative Timesteps: 973,715,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 973715840...
Checkpoint 973715840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,112.93595
Policy Entropy: 1.07233
Value Function Loss: 2.57038

Mean KL Divergence: 0.06747
SB3 Clip Fraction: 0.25443
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 11,900.26810
Overall Steps per Second: 10,021.67798

Timestep Collection Time: 4.20394
Timestep Consumption Time: 0.78804
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.99198

Cumulative Model Updates: 58,380
Cumulative Timesteps: 973,765,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,306.03907
Policy Entropy: 1.09966
Value Function Loss: 2.57156

Mean KL Divergence: 0.02510
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 11,814.52592
Overall Steps per Second: 10,040.99296

Timestep Collection Time: 4.23411
Timestep Consumption Time: 0.74787
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.98198

Cumulative Model Updates: 58,383
Cumulative Timesteps: 973,815,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 973815892...
Checkpoint 973815892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707,005.98847
Policy Entropy: 1.07985
Value Function Loss: 2.47026

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.10501

Collected Steps per Second: 12,172.44327
Overall Steps per Second: 10,219.55574

Timestep Collection Time: 4.10830
Timestep Consumption Time: 0.78507
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.89336

Cumulative Model Updates: 58,386
Cumulative Timesteps: 973,865,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560,820.12072
Policy Entropy: 1.09450
Value Function Loss: 2.55517

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.10670

Collected Steps per Second: 11,942.24714
Overall Steps per Second: 10,053.99459

Timestep Collection Time: 4.18816
Timestep Consumption Time: 0.78658
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 4.97474

Cumulative Model Updates: 58,389
Cumulative Timesteps: 973,915,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 973915916...
Checkpoint 973915916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,480.47297
Policy Entropy: 1.09767
Value Function Loss: 2.45114

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.10600

Collected Steps per Second: 11,643.67432
Overall Steps per Second: 10,002.75725

Timestep Collection Time: 4.29435
Timestep Consumption Time: 0.70447
PPO Batch Consumption Time: 0.03407
Total Iteration Time: 4.99882

Cumulative Model Updates: 58,392
Cumulative Timesteps: 973,965,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,983.54873
Policy Entropy: 1.08391
Value Function Loss: 2.52379

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 11,470.89247
Overall Steps per Second: 9,737.77634

Timestep Collection Time: 4.36095
Timestep Consumption Time: 0.77616
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.13711

Cumulative Model Updates: 58,395
Cumulative Timesteps: 974,015,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 974015942...
Checkpoint 974015942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,059.82852
Policy Entropy: 1.07854
Value Function Loss: 2.50961

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.10946

Collected Steps per Second: 12,007.54702
Overall Steps per Second: 10,138.68383

Timestep Collection Time: 4.16588
Timestep Consumption Time: 0.76790
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 4.93378

Cumulative Model Updates: 58,398
Cumulative Timesteps: 974,065,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,983.44731
Policy Entropy: 1.08567
Value Function Loss: 2.65329

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 11,954.98381
Overall Steps per Second: 10,297.75810

Timestep Collection Time: 4.18369
Timestep Consumption Time: 0.67328
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.85698

Cumulative Model Updates: 58,401
Cumulative Timesteps: 974,115,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 974115980...
Checkpoint 974115980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,552.21766
Policy Entropy: 1.08987
Value Function Loss: 2.63213

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.11409

Collected Steps per Second: 12,104.87589
Overall Steps per Second: 10,136.65086

Timestep Collection Time: 4.13255
Timestep Consumption Time: 0.80241
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.93496

Cumulative Model Updates: 58,404
Cumulative Timesteps: 974,166,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,333.47104
Policy Entropy: 1.07103
Value Function Loss: 2.61484

Mean KL Divergence: 0.02890
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.11008

Collected Steps per Second: 11,961.07995
Overall Steps per Second: 10,287.00776

Timestep Collection Time: 4.18123
Timestep Consumption Time: 0.68044
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.86167

Cumulative Model Updates: 58,407
Cumulative Timesteps: 974,216,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 974216016...
Checkpoint 974216016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,881.70274
Policy Entropy: 1.09126
Value Function Loss: 2.68486

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 11,766.58522
Overall Steps per Second: 9,972.18824

Timestep Collection Time: 4.25119
Timestep Consumption Time: 0.76496
PPO Batch Consumption Time: 0.03710
Total Iteration Time: 5.01615

Cumulative Model Updates: 58,410
Cumulative Timesteps: 974,266,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,898.87055
Policy Entropy: 1.08812
Value Function Loss: 2.73427

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.10251

Collected Steps per Second: 11,538.18484
Overall Steps per Second: 9,949.42389

Timestep Collection Time: 4.33552
Timestep Consumption Time: 0.69231
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.02783

Cumulative Model Updates: 58,413
Cumulative Timesteps: 974,316,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 974316062...
Checkpoint 974316062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648,021.58308
Policy Entropy: 1.07948
Value Function Loss: 2.76736

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 11,925.44807
Overall Steps per Second: 10,076.91128

Timestep Collection Time: 4.19506
Timestep Consumption Time: 0.76955
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.96462

Cumulative Model Updates: 58,416
Cumulative Timesteps: 974,366,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,100.93277
Policy Entropy: 1.06290
Value Function Loss: 2.67912

Mean KL Divergence: 0.03869
SB3 Clip Fraction: 0.20730
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 12,763.34676
Overall Steps per Second: 10,619.04843

Timestep Collection Time: 3.91778
Timestep Consumption Time: 0.79112
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.70890

Cumulative Model Updates: 58,419
Cumulative Timesteps: 974,416,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 974416094...
Checkpoint 974416094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,029.31085
Policy Entropy: 1.07791
Value Function Loss: 2.67036

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 12,272.10675
Overall Steps per Second: 10,449.05496

Timestep Collection Time: 4.07640
Timestep Consumption Time: 0.71121
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.78761

Cumulative Model Updates: 58,422
Cumulative Timesteps: 974,466,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751,839.26544
Policy Entropy: 1.06111
Value Function Loss: 2.66096

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.09610

Collected Steps per Second: 12,899.08079
Overall Steps per Second: 10,708.73631

Timestep Collection Time: 3.87749
Timestep Consumption Time: 0.79309
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.67058

Cumulative Model Updates: 58,425
Cumulative Timesteps: 974,516,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 974516136...
Checkpoint 974516136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,380.93513
Policy Entropy: 1.05330
Value Function Loss: 2.64331

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.15088
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 12,359.66939
Overall Steps per Second: 10,372.82879

Timestep Collection Time: 4.04590
Timestep Consumption Time: 0.77496
PPO Batch Consumption Time: 0.03506
Total Iteration Time: 4.82086

Cumulative Model Updates: 58,428
Cumulative Timesteps: 974,566,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,140.88716
Policy Entropy: 1.06316
Value Function Loss: 2.67818

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 12,118.45202
Overall Steps per Second: 10,165.76395

Timestep Collection Time: 4.12676
Timestep Consumption Time: 0.79269
PPO Batch Consumption Time: 0.03431
Total Iteration Time: 4.91945

Cumulative Model Updates: 58,431
Cumulative Timesteps: 974,616,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 974616152...
Checkpoint 974616152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,067.62579
Policy Entropy: 1.06760
Value Function Loss: 2.60186

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 12,468.15973
Overall Steps per Second: 10,320.88094

Timestep Collection Time: 4.01198
Timestep Consumption Time: 0.83470
PPO Batch Consumption Time: 0.03611
Total Iteration Time: 4.84668

Cumulative Model Updates: 58,434
Cumulative Timesteps: 974,666,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851,165.30555
Policy Entropy: 1.06147
Value Function Loss: 2.54768

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 11,838.64146
Overall Steps per Second: 10,137.46682

Timestep Collection Time: 4.22532
Timestep Consumption Time: 0.70905
PPO Batch Consumption Time: 0.03677
Total Iteration Time: 4.93437

Cumulative Model Updates: 58,437
Cumulative Timesteps: 974,716,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 974716196...
Checkpoint 974716196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,570.13967
Policy Entropy: 1.04941
Value Function Loss: 2.44158

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 11,912.66394
Overall Steps per Second: 10,066.52843

Timestep Collection Time: 4.19738
Timestep Consumption Time: 0.76977
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.96715

Cumulative Model Updates: 58,440
Cumulative Timesteps: 974,766,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774,465.99144
Policy Entropy: 1.05835
Value Function Loss: 2.67421

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.08060

Collected Steps per Second: 11,763.86639
Overall Steps per Second: 9,987.99571

Timestep Collection Time: 4.25047
Timestep Consumption Time: 0.75574
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.00621

Cumulative Model Updates: 58,443
Cumulative Timesteps: 974,816,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974816200...
Checkpoint 974816200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,182.48013
Policy Entropy: 1.05779
Value Function Loss: 2.90538

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 11,900.04089
Overall Steps per Second: 10,208.04077

Timestep Collection Time: 4.20335
Timestep Consumption Time: 0.69671
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 4.90006

Cumulative Model Updates: 58,446
Cumulative Timesteps: 974,866,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,454.22688
Policy Entropy: 1.06219
Value Function Loss: 2.96369

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.10881

Collected Steps per Second: 11,613.23869
Overall Steps per Second: 9,824.00932

Timestep Collection Time: 4.30560
Timestep Consumption Time: 0.78417
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.08978

Cumulative Model Updates: 58,449
Cumulative Timesteps: 974,916,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974916222...
Checkpoint 974916222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,572.71955
Policy Entropy: 1.05571
Value Function Loss: 2.86346

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.09797

Collected Steps per Second: 12,006.63441
Overall Steps per Second: 10,148.87747

Timestep Collection Time: 4.16453
Timestep Consumption Time: 0.76232
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.92685

Cumulative Model Updates: 58,452
Cumulative Timesteps: 974,966,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,984.26606
Policy Entropy: 1.07216
Value Function Loss: 2.76256

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.09180

Collected Steps per Second: 12,080.69131
Overall Steps per Second: 10,174.43239

Timestep Collection Time: 4.13917
Timestep Consumption Time: 0.77551
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.91467

Cumulative Model Updates: 58,455
Cumulative Timesteps: 975,016,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 975016228...
Checkpoint 975016228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744,388.57012
Policy Entropy: 1.07209
Value Function Loss: 2.85097

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 11,815.00261
Overall Steps per Second: 10,008.35457

Timestep Collection Time: 4.23445
Timestep Consumption Time: 0.76438
PPO Batch Consumption Time: 0.03416
Total Iteration Time: 4.99882

Cumulative Model Updates: 58,458
Cumulative Timesteps: 975,066,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,611.16347
Policy Entropy: 1.07420
Value Function Loss: 2.77134

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.06356
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 11,882.29423
Overall Steps per Second: 10,234.91569

Timestep Collection Time: 4.20811
Timestep Consumption Time: 0.67732
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.88543

Cumulative Model Updates: 58,461
Cumulative Timesteps: 975,116,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 975116260...
Checkpoint 975116260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,544.94778
Policy Entropy: 1.05683
Value Function Loss: 2.84327

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.16032
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 11,771.88063
Overall Steps per Second: 9,975.74694

Timestep Collection Time: 4.24758
Timestep Consumption Time: 0.76478
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.01236

Cumulative Model Updates: 58,464
Cumulative Timesteps: 975,166,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,530.01197
Policy Entropy: 1.06751
Value Function Loss: 2.74936

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.10787

Collected Steps per Second: 11,276.27267
Overall Steps per Second: 9,641.81715

Timestep Collection Time: 4.43604
Timestep Consumption Time: 0.75199
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 5.18803

Cumulative Model Updates: 58,467
Cumulative Timesteps: 975,216,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 975216284...
Checkpoint 975216284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,910.64378
Policy Entropy: 1.06373
Value Function Loss: 2.77082

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 12,198.92517
Overall Steps per Second: 10,445.30108

Timestep Collection Time: 4.09954
Timestep Consumption Time: 0.68826
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.78780

Cumulative Model Updates: 58,470
Cumulative Timesteps: 975,266,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,930.57261
Policy Entropy: 1.05869
Value Function Loss: 2.58456

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 11,955.72947
Overall Steps per Second: 10,052.72313

Timestep Collection Time: 4.18310
Timestep Consumption Time: 0.79187
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.97497

Cumulative Model Updates: 58,473
Cumulative Timesteps: 975,316,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 975316306...
Checkpoint 975316306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,593.41932
Policy Entropy: 1.04134
Value Function Loss: 2.53272

Mean KL Divergence: 0.03412
SB3 Clip Fraction: 0.18573
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 11,787.09958
Overall Steps per Second: 10,113.59654

Timestep Collection Time: 4.24227
Timestep Consumption Time: 0.70197
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 4.94424

Cumulative Model Updates: 58,476
Cumulative Timesteps: 975,366,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744,915.03200
Policy Entropy: 1.06041
Value Function Loss: 2.48046

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.10413

Collected Steps per Second: 11,862.05642
Overall Steps per Second: 9,983.30083

Timestep Collection Time: 4.21731
Timestep Consumption Time: 0.79366
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.01097

Cumulative Model Updates: 58,479
Cumulative Timesteps: 975,416,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 975416336...
Checkpoint 975416336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,918.56735
Policy Entropy: 1.06132
Value Function Loss: 2.45608

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.09479

Collected Steps per Second: 11,827.18523
Overall Steps per Second: 10,063.41460

Timestep Collection Time: 4.23009
Timestep Consumption Time: 0.74139
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 4.97147

Cumulative Model Updates: 58,482
Cumulative Timesteps: 975,466,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,108.36541
Policy Entropy: 1.06042
Value Function Loss: 2.47526

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 11,268.82713
Overall Steps per Second: 9,754.24832

Timestep Collection Time: 4.43879
Timestep Consumption Time: 0.68923
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.12802

Cumulative Model Updates: 58,485
Cumulative Timesteps: 975,516,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 975516386...
Checkpoint 975516386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,183.39532
Policy Entropy: 1.07359
Value Function Loss: 2.60339

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.16161
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.10520

Collected Steps per Second: 11,777.66452
Overall Steps per Second: 9,931.97518

Timestep Collection Time: 4.24736
Timestep Consumption Time: 0.78930
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.03666

Cumulative Model Updates: 58,488
Cumulative Timesteps: 975,566,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633,054.11878
Policy Entropy: 1.07487
Value Function Loss: 2.67468

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.10196

Collected Steps per Second: 12,269.55646
Overall Steps per Second: 10,345.61245

Timestep Collection Time: 4.07725
Timestep Consumption Time: 0.75823
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.83548

Cumulative Model Updates: 58,491
Cumulative Timesteps: 975,616,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 975616436...
Checkpoint 975616436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741,966.52992
Policy Entropy: 1.05645
Value Function Loss: 2.68952

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 10,277.96698
Overall Steps per Second: 8,496.70042

Timestep Collection Time: 4.86711
Timestep Consumption Time: 1.02035
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 5.88746

Cumulative Model Updates: 58,494
Cumulative Timesteps: 975,666,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,775.77742
Policy Entropy: 1.04798
Value Function Loss: 2.60415

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.08704

Collected Steps per Second: 9,477.80583
Overall Steps per Second: 7,936.58035

Timestep Collection Time: 5.27738
Timestep Consumption Time: 1.02483
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 6.30221

Cumulative Model Updates: 58,497
Cumulative Timesteps: 975,716,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 975716478...
Checkpoint 975716478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,050.04690
Policy Entropy: 1.05773
Value Function Loss: 2.51520

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 9,539.62554
Overall Steps per Second: 8,293.60117

Timestep Collection Time: 5.24423
Timestep Consumption Time: 0.78789
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 6.03212

Cumulative Model Updates: 58,500
Cumulative Timesteps: 975,766,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,620.90295
Policy Entropy: 1.06872
Value Function Loss: 2.51261

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 12,031.82521
Overall Steps per Second: 10,153.07854

Timestep Collection Time: 4.15581
Timestep Consumption Time: 0.76900
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.92481

Cumulative Model Updates: 58,503
Cumulative Timesteps: 975,816,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 975816508...
Checkpoint 975816508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,205.85085
Policy Entropy: 1.05558
Value Function Loss: 2.50022

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.10075

Collected Steps per Second: 11,835.29316
Overall Steps per Second: 9,944.30244

Timestep Collection Time: 4.22499
Timestep Consumption Time: 0.80342
PPO Batch Consumption Time: 0.03814
Total Iteration Time: 5.02841

Cumulative Model Updates: 58,506
Cumulative Timesteps: 975,866,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,854.85070
Policy Entropy: 1.05287
Value Function Loss: 2.75090

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.15294
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 12,006.41533
Overall Steps per Second: 10,160.34366

Timestep Collection Time: 4.16677
Timestep Consumption Time: 0.75708
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.92385

Cumulative Model Updates: 58,509
Cumulative Timesteps: 975,916,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 975916540...
Checkpoint 975916540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,622.58988
Policy Entropy: 1.05986
Value Function Loss: 2.77620

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 12,005.34744
Overall Steps per Second: 10,115.03087

Timestep Collection Time: 4.16581
Timestep Consumption Time: 0.77851
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.94433

Cumulative Model Updates: 58,512
Cumulative Timesteps: 975,966,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755,172.59186
Policy Entropy: 1.06478
Value Function Loss: 2.83980

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 12,007.47572
Overall Steps per Second: 10,312.68649

Timestep Collection Time: 4.16607
Timestep Consumption Time: 0.68465
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.85072

Cumulative Model Updates: 58,515
Cumulative Timesteps: 976,016,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 976016576...
Checkpoint 976016576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,802.24619
Policy Entropy: 1.04306
Value Function Loss: 2.71233

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 11,728.40071
Overall Steps per Second: 9,886.94168

Timestep Collection Time: 4.26418
Timestep Consumption Time: 0.79421
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.05839

Cumulative Model Updates: 58,518
Cumulative Timesteps: 976,066,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,147.86952
Policy Entropy: 1.06213
Value Function Loss: 2.68861

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.13161

Collected Steps per Second: 11,887.20826
Overall Steps per Second: 10,235.71131

Timestep Collection Time: 4.20805
Timestep Consumption Time: 0.67895
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.88701

Cumulative Model Updates: 58,521
Cumulative Timesteps: 976,116,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 976116610...
Checkpoint 976116610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751,697.79715
Policy Entropy: 1.05394
Value Function Loss: 2.56375

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.12490

Collected Steps per Second: 11,873.84274
Overall Steps per Second: 9,944.75929

Timestep Collection Time: 4.21279
Timestep Consumption Time: 0.81720
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 5.02999

Cumulative Model Updates: 58,524
Cumulative Timesteps: 976,166,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,840.45774
Policy Entropy: 1.04669
Value Function Loss: 2.66369

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 11,859.10923
Overall Steps per Second: 10,089.92767

Timestep Collection Time: 4.21701
Timestep Consumption Time: 0.73942
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 4.95643

Cumulative Model Updates: 58,527
Cumulative Timesteps: 976,216,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 976216642...
Checkpoint 976216642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,130.74523
Policy Entropy: 1.03929
Value Function Loss: 2.66837

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.10155

Collected Steps per Second: 11,760.54000
Overall Steps per Second: 10,155.35636

Timestep Collection Time: 4.25219
Timestep Consumption Time: 0.67211
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.92430

Cumulative Model Updates: 58,530
Cumulative Timesteps: 976,266,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,356.56188
Policy Entropy: 1.05567
Value Function Loss: 2.79450

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09990

Collected Steps per Second: 12,274.79224
Overall Steps per Second: 10,319.55535

Timestep Collection Time: 4.07339
Timestep Consumption Time: 0.77178
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.84517

Cumulative Model Updates: 58,533
Cumulative Timesteps: 976,316,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 976316650...
Checkpoint 976316650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,278.77031
Policy Entropy: 1.05908
Value Function Loss: 2.70435

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10259

Collected Steps per Second: 11,717.59330
Overall Steps per Second: 9,802.22253

Timestep Collection Time: 4.26760
Timestep Consumption Time: 0.83390
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 5.10150

Cumulative Model Updates: 58,536
Cumulative Timesteps: 976,366,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780,564.61482
Policy Entropy: 1.03909
Value Function Loss: 2.61956

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.10363

Collected Steps per Second: 12,081.33341
Overall Steps per Second: 10,223.50882

Timestep Collection Time: 4.13928
Timestep Consumption Time: 0.75219
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.89147

Cumulative Model Updates: 58,539
Cumulative Timesteps: 976,416,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 976416664...
Checkpoint 976416664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,473.78121
Policy Entropy: 1.03311
Value Function Loss: 2.49875

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.10142

Collected Steps per Second: 11,914.63265
Overall Steps per Second: 10,051.14552

Timestep Collection Time: 4.19904
Timestep Consumption Time: 0.77850
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.97754

Cumulative Model Updates: 58,542
Cumulative Timesteps: 976,466,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,711.43793
Policy Entropy: 1.05141
Value Function Loss: 2.46278

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.09329

Collected Steps per Second: 11,916.98182
Overall Steps per Second: 10,209.95616

Timestep Collection Time: 4.19670
Timestep Consumption Time: 0.70166
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.89836

Cumulative Model Updates: 58,545
Cumulative Timesteps: 976,516,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 976516706...
Checkpoint 976516706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,098.60849
Policy Entropy: 1.06526
Value Function Loss: 2.40582

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.16897
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 11,870.78209
Overall Steps per Second: 9,918.59001

Timestep Collection Time: 4.21286
Timestep Consumption Time: 0.82918
PPO Batch Consumption Time: 0.03662
Total Iteration Time: 5.04205

Cumulative Model Updates: 58,548
Cumulative Timesteps: 976,566,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,958.31299
Policy Entropy: 1.04605
Value Function Loss: 2.53703

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 11,821.65474
Overall Steps per Second: 10,041.45276

Timestep Collection Time: 4.23071
Timestep Consumption Time: 0.75004
PPO Batch Consumption Time: 0.03307
Total Iteration Time: 4.98075

Cumulative Model Updates: 58,551
Cumulative Timesteps: 976,616,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 976616730...
Checkpoint 976616730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735,566.59328
Policy Entropy: 1.03559
Value Function Loss: 2.57887

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.16047
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11,923.51839
Overall Steps per Second: 10,131.12791

Timestep Collection Time: 4.19423
Timestep Consumption Time: 0.74204
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.93627

Cumulative Model Updates: 58,554
Cumulative Timesteps: 976,666,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,103.11308
Policy Entropy: 1.04646
Value Function Loss: 2.77360

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.12488

Collected Steps per Second: 11,964.89116
Overall Steps per Second: 10,080.99655

Timestep Collection Time: 4.18157
Timestep Consumption Time: 0.78143
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.96300

Cumulative Model Updates: 58,557
Cumulative Timesteps: 976,716,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 976716772...
Checkpoint 976716772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,659.06557
Policy Entropy: 1.05185
Value Function Loss: 2.71011

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12718

Collected Steps per Second: 12,042.79397
Overall Steps per Second: 10,134.28495

Timestep Collection Time: 4.15219
Timestep Consumption Time: 0.78195
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.93414

Cumulative Model Updates: 58,560
Cumulative Timesteps: 976,766,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,251.93026
Policy Entropy: 1.03982
Value Function Loss: 2.78950

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.13558

Collected Steps per Second: 13,122.80703
Overall Steps per Second: 10,840.50070

Timestep Collection Time: 3.81199
Timestep Consumption Time: 0.80256
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.61455

Cumulative Model Updates: 58,563
Cumulative Timesteps: 976,816,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 976816800...
Checkpoint 976816800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,541.34199
Policy Entropy: 1.03842
Value Function Loss: 2.67078

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.13919

Collected Steps per Second: 12,664.91230
Overall Steps per Second: 10,567.13503

Timestep Collection Time: 3.94870
Timestep Consumption Time: 0.78389
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.73260

Cumulative Model Updates: 58,566
Cumulative Timesteps: 976,866,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,199.22530
Policy Entropy: 1.04621
Value Function Loss: 2.68442

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.13860

Collected Steps per Second: 12,360.34968
Overall Steps per Second: 10,580.75185

Timestep Collection Time: 4.04730
Timestep Consumption Time: 0.68072
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.72802

Cumulative Model Updates: 58,569
Cumulative Timesteps: 976,916,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976916836...
Checkpoint 976916836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,903.40243
Policy Entropy: 1.05694
Value Function Loss: 2.58941

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 12,751.55752
Overall Steps per Second: 10,621.46573

Timestep Collection Time: 3.92313
Timestep Consumption Time: 0.78677
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 4.70990

Cumulative Model Updates: 58,572
Cumulative Timesteps: 976,966,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,568.00798
Policy Entropy: 1.03178
Value Function Loss: 2.63969

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14859
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.10918

Collected Steps per Second: 12,015.73863
Overall Steps per Second: 10,170.91790

Timestep Collection Time: 4.16354
Timestep Consumption Time: 0.75519
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.91873

Cumulative Model Updates: 58,575
Cumulative Timesteps: 977,016,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 977016890...
Checkpoint 977016890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,759.74129
Policy Entropy: 1.03594
Value Function Loss: 2.74222

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15256
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.09969

Collected Steps per Second: 12,692.49050
Overall Steps per Second: 10,650.68507

Timestep Collection Time: 3.93934
Timestep Consumption Time: 0.75520
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 4.69453

Cumulative Model Updates: 58,578
Cumulative Timesteps: 977,066,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,844.38302
Policy Entropy: 1.04998
Value Function Loss: 2.75320

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.09355

Collected Steps per Second: 11,802.00752
Overall Steps per Second: 10,019.12960

Timestep Collection Time: 4.23691
Timestep Consumption Time: 0.75395
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 4.99085

Cumulative Model Updates: 58,581
Cumulative Timesteps: 977,116,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 977116894...
Checkpoint 977116894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,830.19895
Policy Entropy: 1.05763
Value Function Loss: 2.68124

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.10168

Collected Steps per Second: 11,688.74900
Overall Steps per Second: 9,950.41896

Timestep Collection Time: 4.28001
Timestep Consumption Time: 0.74771
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.02773

Cumulative Model Updates: 58,584
Cumulative Timesteps: 977,166,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,956.84362
Policy Entropy: 1.04678
Value Function Loss: 2.56517

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.09547

Collected Steps per Second: 12,157.28609
Overall Steps per Second: 10,238.80543

Timestep Collection Time: 4.11424
Timestep Consumption Time: 0.77090
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 4.88514

Cumulative Model Updates: 58,587
Cumulative Timesteps: 977,216,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 977216940...
Checkpoint 977216940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,555.18455
Policy Entropy: 1.03180
Value Function Loss: 2.53733

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.17692
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 11,740.23250
Overall Steps per Second: 9,877.01704

Timestep Collection Time: 4.26124
Timestep Consumption Time: 0.80385
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.06509

Cumulative Model Updates: 58,590
Cumulative Timesteps: 977,266,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626,088.72610
Policy Entropy: 1.05246
Value Function Loss: 2.59235

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.09618

Collected Steps per Second: 11,329.87397
Overall Steps per Second: 9,810.81658

Timestep Collection Time: 4.41488
Timestep Consumption Time: 0.68358
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.09845

Cumulative Model Updates: 58,593
Cumulative Timesteps: 977,316,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 977316988...
Checkpoint 977316988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,213.71273
Policy Entropy: 1.05996
Value Function Loss: 2.65161

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.09294

Collected Steps per Second: 11,880.62834
Overall Steps per Second: 10,047.37057

Timestep Collection Time: 4.20887
Timestep Consumption Time: 0.76796
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.97682

Cumulative Model Updates: 58,596
Cumulative Timesteps: 977,366,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,578.18354
Policy Entropy: 1.04273
Value Function Loss: 2.73290

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.08880

Collected Steps per Second: 11,901.14809
Overall Steps per Second: 10,066.93410

Timestep Collection Time: 4.20279
Timestep Consumption Time: 0.76576
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.96854

Cumulative Model Updates: 58,599
Cumulative Timesteps: 977,417,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 977417010...
Checkpoint 977417010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,081.45211
Policy Entropy: 1.04707
Value Function Loss: 2.75941

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.09561

Collected Steps per Second: 11,568.64362
Overall Steps per Second: 10,017.87174

Timestep Collection Time: 4.32255
Timestep Consumption Time: 0.66913
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 4.99168

Cumulative Model Updates: 58,602
Cumulative Timesteps: 977,467,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745,345.29150
Policy Entropy: 1.04688
Value Function Loss: 2.64642

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.10145

Collected Steps per Second: 12,126.04619
Overall Steps per Second: 10,214.00347

Timestep Collection Time: 4.12402
Timestep Consumption Time: 0.77201
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.89602

Cumulative Model Updates: 58,605
Cumulative Timesteps: 977,517,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 977517024...
Checkpoint 977517024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778,370.09402
Policy Entropy: 1.04642
Value Function Loss: 2.61043

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 12,026.37896
Overall Steps per Second: 10,204.04603

Timestep Collection Time: 4.15836
Timestep Consumption Time: 0.74264
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.90100

Cumulative Model Updates: 58,608
Cumulative Timesteps: 977,567,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,572.89459
Policy Entropy: 1.05237
Value Function Loss: 2.64678

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 11,487.35242
Overall Steps per Second: 9,957.11359

Timestep Collection Time: 4.35470
Timestep Consumption Time: 0.66924
PPO Batch Consumption Time: 0.03623
Total Iteration Time: 5.02395

Cumulative Model Updates: 58,611
Cumulative Timesteps: 977,617,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 977617058...
Checkpoint 977617058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,990.45513
Policy Entropy: 1.04767
Value Function Loss: 2.76234

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.07013
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 12,163.07793
Overall Steps per Second: 10,222.25486

Timestep Collection Time: 4.11294
Timestep Consumption Time: 0.78089
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 4.89383

Cumulative Model Updates: 58,614
Cumulative Timesteps: 977,667,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623,080.01281
Policy Entropy: 1.06009
Value Function Loss: 2.83348

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.10061

Collected Steps per Second: 12,141.93929
Overall Steps per Second: 10,297.51482

Timestep Collection Time: 4.12043
Timestep Consumption Time: 0.73802
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.85845

Cumulative Model Updates: 58,617
Cumulative Timesteps: 977,717,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 977717114...
Checkpoint 977717114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,893.55731
Policy Entropy: 1.05712
Value Function Loss: 2.72655

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.10098

Collected Steps per Second: 12,283.63916
Overall Steps per Second: 10,325.71729

Timestep Collection Time: 4.07257
Timestep Consumption Time: 0.77223
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.84480

Cumulative Model Updates: 58,620
Cumulative Timesteps: 977,767,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,787.34403
Policy Entropy: 1.06272
Value Function Loss: 2.71209

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.09345

Collected Steps per Second: 11,757.58163
Overall Steps per Second: 10,020.36377

Timestep Collection Time: 4.25275
Timestep Consumption Time: 0.73729
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 4.99004

Cumulative Model Updates: 58,623
Cumulative Timesteps: 977,817,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 977817142...
Checkpoint 977817142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649,351.57585
Policy Entropy: 1.06043
Value Function Loss: 2.66308

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.08525

Collected Steps per Second: 11,877.95345
Overall Steps per Second: 10,173.66470

Timestep Collection Time: 4.21167
Timestep Consumption Time: 0.70554
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 4.91721

Cumulative Model Updates: 58,626
Cumulative Timesteps: 977,867,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,561.10098
Policy Entropy: 1.05997
Value Function Loss: 2.77273

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.07335
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 11,390.13850
Overall Steps per Second: 9,660.72429

Timestep Collection Time: 4.39064
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.17663

Cumulative Model Updates: 58,629
Cumulative Timesteps: 977,917,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 977917178...
Checkpoint 977917178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,485.26167
Policy Entropy: 1.07441
Value Function Loss: 2.78456

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.09087

Collected Steps per Second: 11,989.61016
Overall Steps per Second: 10,207.05454

Timestep Collection Time: 4.17211
Timestep Consumption Time: 0.72862
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 4.90073

Cumulative Model Updates: 58,632
Cumulative Timesteps: 977,967,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,603.27732
Policy Entropy: 1.08026
Value Function Loss: 2.67649

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.09521

Collected Steps per Second: 12,395.57803
Overall Steps per Second: 10,682.15489

Timestep Collection Time: 4.03531
Timestep Consumption Time: 0.64727
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.68258

Cumulative Model Updates: 58,635
Cumulative Timesteps: 978,017,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978017220...
Checkpoint 978017220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,650.58265
Policy Entropy: 1.09084
Value Function Loss: 2.61604

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 12,032.49283
Overall Steps per Second: 10,144.47214

Timestep Collection Time: 4.15741
Timestep Consumption Time: 0.77375
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 4.93116

Cumulative Model Updates: 58,638
Cumulative Timesteps: 978,067,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648,155.24582
Policy Entropy: 1.07632
Value Function Loss: 2.51003

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 12,252.40713
Overall Steps per Second: 10,380.93371

Timestep Collection Time: 4.08344
Timestep Consumption Time: 0.73616
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 4.81961

Cumulative Model Updates: 58,641
Cumulative Timesteps: 978,117,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 978117276...
Checkpoint 978117276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,008.65524
Policy Entropy: 1.07194
Value Function Loss: 2.57895

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 12,398.07053
Overall Steps per Second: 10,423.56644

Timestep Collection Time: 4.03401
Timestep Consumption Time: 0.76415
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.79817

Cumulative Model Updates: 58,644
Cumulative Timesteps: 978,167,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,824.71578
Policy Entropy: 1.06159
Value Function Loss: 2.63260

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.17547
Policy Update Magnitude: 0.06556
Value Function Update Magnitude: 0.09428

Collected Steps per Second: 11,660.02694
Overall Steps per Second: 9,929.81089

Timestep Collection Time: 4.29038
Timestep Consumption Time: 0.74758
PPO Batch Consumption Time: 0.03351
Total Iteration Time: 5.03796

Cumulative Model Updates: 58,647
Cumulative Timesteps: 978,217,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 978217316...
Checkpoint 978217316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,465.90476
Policy Entropy: 1.07710
Value Function Loss: 2.66403

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.10562

Collected Steps per Second: 12,388.26586
Overall Steps per Second: 10,670.86836

Timestep Collection Time: 4.03866
Timestep Consumption Time: 0.64999
PPO Batch Consumption Time: 0.03322
Total Iteration Time: 4.68865

Cumulative Model Updates: 58,650
Cumulative Timesteps: 978,267,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,328.69794
Policy Entropy: 1.07876
Value Function Loss: 2.65762

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 12,035.82358
Overall Steps per Second: 10,120.17081

Timestep Collection Time: 4.15510
Timestep Consumption Time: 0.78652
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.94162

Cumulative Model Updates: 58,653
Cumulative Timesteps: 978,317,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 978317358...
Checkpoint 978317358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675,433.61932
Policy Entropy: 1.05971
Value Function Loss: 2.50110

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 11,885.20384
Overall Steps per Second: 10,094.54604

Timestep Collection Time: 4.20792
Timestep Consumption Time: 0.74644
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.95436

Cumulative Model Updates: 58,656
Cumulative Timesteps: 978,367,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,252.62466
Policy Entropy: 1.05679
Value Function Loss: 2.47624

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 12,002.53855
Overall Steps per Second: 10,345.52977

Timestep Collection Time: 4.16679
Timestep Consumption Time: 0.66738
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 4.83417

Cumulative Model Updates: 58,659
Cumulative Timesteps: 978,417,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 978417382...
Checkpoint 978417382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,373.80905
Policy Entropy: 1.06506
Value Function Loss: 2.38859

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 11,911.00333
Overall Steps per Second: 10,080.33048

Timestep Collection Time: 4.19948
Timestep Consumption Time: 0.76266
PPO Batch Consumption Time: 0.03554
Total Iteration Time: 4.96214

Cumulative Model Updates: 58,662
Cumulative Timesteps: 978,467,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715,639.42922
Policy Entropy: 1.07816
Value Function Loss: 2.50729

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.16057
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.10770

Collected Steps per Second: 11,532.10598
Overall Steps per Second: 9,789.09211

Timestep Collection Time: 4.33624
Timestep Consumption Time: 0.77210
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 5.10834

Cumulative Model Updates: 58,665
Cumulative Timesteps: 978,517,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 978517408...
Checkpoint 978517408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,643.47355
Policy Entropy: 1.04698
Value Function Loss: 2.58838

Mean KL Divergence: 0.02867
SB3 Clip Fraction: 0.19735
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.08983

Collected Steps per Second: 11,874.71302
Overall Steps per Second: 10,017.08500

Timestep Collection Time: 4.21214
Timestep Consumption Time: 0.78113
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.99327

Cumulative Model Updates: 58,668
Cumulative Timesteps: 978,567,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676,706.15081
Policy Entropy: 1.07056
Value Function Loss: 2.61576

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.08771

Collected Steps per Second: 12,001.85250
Overall Steps per Second: 10,154.82514

Timestep Collection Time: 4.16669
Timestep Consumption Time: 0.75787
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.92456

Cumulative Model Updates: 58,671
Cumulative Timesteps: 978,617,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 978617434...
Checkpoint 978617434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,826.78982
Policy Entropy: 1.06845
Value Function Loss: 2.69692

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 12,080.22702
Overall Steps per Second: 10,300.78591

Timestep Collection Time: 4.14131
Timestep Consumption Time: 0.71540
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 4.85672

Cumulative Model Updates: 58,674
Cumulative Timesteps: 978,667,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,763.94088
Policy Entropy: 1.05639
Value Function Loss: 2.68654

Mean KL Divergence: 0.02573
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.08910

Collected Steps per Second: 12,080.35212
Overall Steps per Second: 10,174.26419

Timestep Collection Time: 4.13895
Timestep Consumption Time: 0.77541
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 4.91436

Cumulative Model Updates: 58,677
Cumulative Timesteps: 978,717,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 978717462...
Checkpoint 978717462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,572.25228
Policy Entropy: 1.05035
Value Function Loss: 2.70416

Mean KL Divergence: 0.02974
SB3 Clip Fraction: 0.19078
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 11,866.44519
Overall Steps per Second: 10,096.98150

Timestep Collection Time: 4.21440
Timestep Consumption Time: 0.73856
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.95297

Cumulative Model Updates: 58,680
Cumulative Timesteps: 978,767,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,188.16336
Policy Entropy: 1.05719
Value Function Loss: 2.64827

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.08583

Collected Steps per Second: 11,780.51609
Overall Steps per Second: 9,997.05738

Timestep Collection Time: 4.24447
Timestep Consumption Time: 0.75721
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.00167

Cumulative Model Updates: 58,683
Cumulative Timesteps: 978,817,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 978817474...
Checkpoint 978817474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,501.90930
Policy Entropy: 1.06709
Value Function Loss: 2.62884

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.07022
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 11,453.90823
Overall Steps per Second: 9,734.65731

Timestep Collection Time: 4.36654
Timestep Consumption Time: 0.77118
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.13773

Cumulative Model Updates: 58,686
Cumulative Timesteps: 978,867,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843,094.87405
Policy Entropy: 1.05659
Value Function Loss: 2.65593

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 11,273.26757
Overall Steps per Second: 9,716.25681

Timestep Collection Time: 4.43545
Timestep Consumption Time: 0.71077
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.14622

Cumulative Model Updates: 58,689
Cumulative Timesteps: 978,917,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 978917490...
Checkpoint 978917490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,606.44563
Policy Entropy: 1.06565
Value Function Loss: 2.69541

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.11696

Collected Steps per Second: 11,274.85334
Overall Steps per Second: 9,529.76589

Timestep Collection Time: 4.43695
Timestep Consumption Time: 0.81249
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.24945

Cumulative Model Updates: 58,692
Cumulative Timesteps: 978,967,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,267.05393
Policy Entropy: 1.06331
Value Function Loss: 2.87077

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.11587

Collected Steps per Second: 11,375.81982
Overall Steps per Second: 9,651.04843

Timestep Collection Time: 4.39652
Timestep Consumption Time: 0.78572
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.18223

Cumulative Model Updates: 58,695
Cumulative Timesteps: 979,017,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 979017530...
Checkpoint 979017530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,371.05805
Policy Entropy: 1.06730
Value Function Loss: 2.92896

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 11,526.86225
Overall Steps per Second: 9,766.88949

Timestep Collection Time: 4.33787
Timestep Consumption Time: 0.78167
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.11954

Cumulative Model Updates: 58,698
Cumulative Timesteps: 979,067,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,197.80315
Policy Entropy: 1.05940
Value Function Loss: 2.92061

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.09488

Collected Steps per Second: 11,053.21699
Overall Steps per Second: 9,365.89915

Timestep Collection Time: 4.52429
Timestep Consumption Time: 0.81508
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.33937

Cumulative Model Updates: 58,701
Cumulative Timesteps: 979,117,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 979117540...
Checkpoint 979117540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,602.06150
Policy Entropy: 1.07329
Value Function Loss: 2.78974

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.08773

Collected Steps per Second: 11,988.53373
Overall Steps per Second: 10,317.91852

Timestep Collection Time: 4.17182
Timestep Consumption Time: 0.67548
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.84730

Cumulative Model Updates: 58,704
Cumulative Timesteps: 979,167,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,939.41837
Policy Entropy: 1.07430
Value Function Loss: 2.72842

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 12,503.00421
Overall Steps per Second: 10,435.01909

Timestep Collection Time: 4.00064
Timestep Consumption Time: 0.79284
PPO Batch Consumption Time: 0.03380
Total Iteration Time: 4.79347

Cumulative Model Updates: 58,707
Cumulative Timesteps: 979,217,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979217574...
Checkpoint 979217574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,242.23573
Policy Entropy: 1.08171
Value Function Loss: 2.67497

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.09374

Collected Steps per Second: 11,985.52394
Overall Steps per Second: 10,128.32676

Timestep Collection Time: 4.17404
Timestep Consumption Time: 0.76538
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 4.93941

Cumulative Model Updates: 58,710
Cumulative Timesteps: 979,267,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785,689.29273
Policy Entropy: 1.07800
Value Function Loss: 2.62704

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.07195
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 12,778.58705
Overall Steps per Second: 10,650.41682

Timestep Collection Time: 3.91327
Timestep Consumption Time: 0.78195
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.69522

Cumulative Model Updates: 58,713
Cumulative Timesteps: 979,317,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 979317608...
Checkpoint 979317608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786,681.24928
Policy Entropy: 1.07484
Value Function Loss: 2.58307

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.11073

Collected Steps per Second: 12,414.13799
Overall Steps per Second: 10,363.38905

Timestep Collection Time: 4.02815
Timestep Consumption Time: 0.79711
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.82526

Cumulative Model Updates: 58,716
Cumulative Timesteps: 979,367,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,084.40975
Policy Entropy: 1.07533
Value Function Loss: 2.72332

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 11,952.19390
Overall Steps per Second: 10,272.67948

Timestep Collection Time: 4.18484
Timestep Consumption Time: 0.68419
PPO Batch Consumption Time: 0.03361
Total Iteration Time: 4.86903

Cumulative Model Updates: 58,719
Cumulative Timesteps: 979,417,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 979417632...
Checkpoint 979417632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847,335.01474
Policy Entropy: 1.07495
Value Function Loss: 2.90425

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.09729

Collected Steps per Second: 12,650.52764
Overall Steps per Second: 10,592.86803

Timestep Collection Time: 3.95288
Timestep Consumption Time: 0.76784
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.72072

Cumulative Model Updates: 58,722
Cumulative Timesteps: 979,467,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,276.59350
Policy Entropy: 1.09234
Value Function Loss: 3.02721

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 11,920.25212
Overall Steps per Second: 10,075.36984

Timestep Collection Time: 4.19505
Timestep Consumption Time: 0.76815
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.96319

Cumulative Model Updates: 58,725
Cumulative Timesteps: 979,517,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 979517644...
Checkpoint 979517644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705,302.10278
Policy Entropy: 1.10177
Value Function Loss: 2.91939

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 11,922.18765
Overall Steps per Second: 10,239.10589

Timestep Collection Time: 4.19453
Timestep Consumption Time: 0.68949
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 4.88402

Cumulative Model Updates: 58,728
Cumulative Timesteps: 979,567,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,671.54669
Policy Entropy: 1.08547
Value Function Loss: 2.70609

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08787

Collected Steps per Second: 11,953.01905
Overall Steps per Second: 10,048.24395

Timestep Collection Time: 4.18371
Timestep Consumption Time: 0.79308
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.97679

Cumulative Model Updates: 58,731
Cumulative Timesteps: 979,617,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 979617660...
Checkpoint 979617660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,666.39523
Policy Entropy: 1.07378
Value Function Loss: 2.55731

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.17710
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.08589

Collected Steps per Second: 11,954.66919
Overall Steps per Second: 10,070.46223

Timestep Collection Time: 4.18431
Timestep Consumption Time: 0.78289
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.96720

Cumulative Model Updates: 58,734
Cumulative Timesteps: 979,667,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,820.04494
Policy Entropy: 1.07762
Value Function Loss: 2.54855

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.08081

Collected Steps per Second: 11,540.20508
Overall Steps per Second: 9,698.59020

Timestep Collection Time: 4.33424
Timestep Consumption Time: 0.82301
PPO Batch Consumption Time: 0.03798
Total Iteration Time: 5.15724

Cumulative Model Updates: 58,737
Cumulative Timesteps: 979,717,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 979717700...
Checkpoint 979717700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,054.17203
Policy Entropy: 1.08968
Value Function Loss: 2.56234

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 11,687.03331
Overall Steps per Second: 9,933.81378

Timestep Collection Time: 4.27825
Timestep Consumption Time: 0.75507
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.03331

Cumulative Model Updates: 58,740
Cumulative Timesteps: 979,767,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,611.06237
Policy Entropy: 1.05970
Value Function Loss: 2.64893

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.16907
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 11,934.17299
Overall Steps per Second: 10,258.88424

Timestep Collection Time: 4.19133
Timestep Consumption Time: 0.68445
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.87577

Cumulative Model Updates: 58,743
Cumulative Timesteps: 979,817,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979817720...
Checkpoint 979817720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,054.26465
Policy Entropy: 1.08537
Value Function Loss: 2.56603

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.08571

Collected Steps per Second: 11,968.64172
Overall Steps per Second: 10,121.99547

Timestep Collection Time: 4.17825
Timestep Consumption Time: 0.76228
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 4.94053

Cumulative Model Updates: 58,746
Cumulative Timesteps: 979,867,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,570.83006
Policy Entropy: 1.08393
Value Function Loss: 2.52830

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 11,842.13819
Overall Steps per Second: 9,996.66964

Timestep Collection Time: 4.22339
Timestep Consumption Time: 0.77967
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 5.00307

Cumulative Model Updates: 58,749
Cumulative Timesteps: 979,917,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 979917742...
Checkpoint 979917742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,503.58035
Policy Entropy: 1.07534
Value Function Loss: 2.50904

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 11,426.75560
Overall Steps per Second: 9,934.57388

Timestep Collection Time: 4.37675
Timestep Consumption Time: 0.65739
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.03414

Cumulative Model Updates: 58,752
Cumulative Timesteps: 979,967,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,943.49170
Policy Entropy: 1.06454
Value Function Loss: 2.61242

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.17509
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.09913

Collected Steps per Second: 11,383.83909
Overall Steps per Second: 9,653.14681

Timestep Collection Time: 4.39342
Timestep Consumption Time: 0.78769
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.18111

Cumulative Model Updates: 58,755
Cumulative Timesteps: 980,017,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 980017768...
Checkpoint 980017768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,959.18045
Policy Entropy: 1.07000
Value Function Loss: 2.65395

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 11,915.58578
Overall Steps per Second: 10,255.98575

Timestep Collection Time: 4.19652
Timestep Consumption Time: 0.67907
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 4.87559

Cumulative Model Updates: 58,758
Cumulative Timesteps: 980,067,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,144.23931
Policy Entropy: 1.07552
Value Function Loss: 2.61078

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 12,005.27451
Overall Steps per Second: 10,048.46707

Timestep Collection Time: 4.16600
Timestep Consumption Time: 0.81127
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.97728

Cumulative Model Updates: 58,761
Cumulative Timesteps: 980,117,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 980117786...
Checkpoint 980117786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,428.19168
Policy Entropy: 1.06015
Value Function Loss: 2.56294

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11090

Collected Steps per Second: 11,860.48532
Overall Steps per Second: 9,992.76718

Timestep Collection Time: 4.21821
Timestep Consumption Time: 0.78841
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 5.00662

Cumulative Model Updates: 58,764
Cumulative Timesteps: 980,167,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658,118.58139
Policy Entropy: 1.04670
Value Function Loss: 2.65016

Mean KL Divergence: 0.02908
SB3 Clip Fraction: 0.18720
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 11,769.84710
Overall Steps per Second: 9,908.32383

Timestep Collection Time: 4.24916
Timestep Consumption Time: 0.79831
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.04747

Cumulative Model Updates: 58,767
Cumulative Timesteps: 980,217,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 980217828...
Checkpoint 980217828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783,082.94437
Policy Entropy: 1.06427
Value Function Loss: 2.63959

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 11,945.24756
Overall Steps per Second: 10,105.37542

Timestep Collection Time: 4.18811
Timestep Consumption Time: 0.76252
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.95063

Cumulative Model Updates: 58,770
Cumulative Timesteps: 980,267,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734,654.41602
Policy Entropy: 1.07846
Value Function Loss: 2.67283

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.10521

Collected Steps per Second: 11,691.95380
Overall Steps per Second: 9,917.22845

Timestep Collection Time: 4.27696
Timestep Consumption Time: 0.76538
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.04234

Cumulative Model Updates: 58,773
Cumulative Timesteps: 980,317,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 980317862...
Checkpoint 980317862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,422.45004
Policy Entropy: 1.06038
Value Function Loss: 2.57951

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.10670

Collected Steps per Second: 12,045.57630
Overall Steps per Second: 10,177.50074

Timestep Collection Time: 4.15256
Timestep Consumption Time: 0.76220
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 4.91476

Cumulative Model Updates: 58,776
Cumulative Timesteps: 980,367,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721,086.67057
Policy Entropy: 1.07336
Value Function Loss: 2.54316

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 12,338.34389
Overall Steps per Second: 10,395.14328

Timestep Collection Time: 4.05322
Timestep Consumption Time: 0.75768
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.81090

Cumulative Model Updates: 58,779
Cumulative Timesteps: 980,417,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980417892...
Checkpoint 980417892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,028.75604
Policy Entropy: 1.07152
Value Function Loss: 2.49181

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 11,967.28174
Overall Steps per Second: 10,324.83477

Timestep Collection Time: 4.18006
Timestep Consumption Time: 0.66495
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.84502

Cumulative Model Updates: 58,782
Cumulative Timesteps: 980,467,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,039.32504
Policy Entropy: 1.05560
Value Function Loss: 2.54025

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.11055

Collected Steps per Second: 12,139.25921
Overall Steps per Second: 10,254.71457

Timestep Collection Time: 4.12134
Timestep Consumption Time: 0.75739
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.87873

Cumulative Model Updates: 58,785
Cumulative Timesteps: 980,517,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 980517946...
Checkpoint 980517946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,590.02186
Policy Entropy: 1.04954
Value Function Loss: 2.52117

Mean KL Divergence: 0.02475
SB3 Clip Fraction: 0.17715
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 12,111.27159
Overall Steps per Second: 10,283.26316

Timestep Collection Time: 4.12855
Timestep Consumption Time: 0.73391
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 4.86246

Cumulative Model Updates: 58,788
Cumulative Timesteps: 980,567,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,833.67012
Policy Entropy: 1.05957
Value Function Loss: 2.51355

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.11227

Collected Steps per Second: 11,784.73361
Overall Steps per Second: 10,133.38748

Timestep Collection Time: 4.24464
Timestep Consumption Time: 0.69171
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.93636

Cumulative Model Updates: 58,791
Cumulative Timesteps: 980,617,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 980617970...
Checkpoint 980617970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,578.44805
Policy Entropy: 1.07747
Value Function Loss: 2.51160

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.11408

Collected Steps per Second: 12,053.12010
Overall Steps per Second: 10,139.36775

Timestep Collection Time: 4.14947
Timestep Consumption Time: 0.78319
PPO Batch Consumption Time: 0.03375
Total Iteration Time: 4.93265

Cumulative Model Updates: 58,794
Cumulative Timesteps: 980,667,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,968.20156
Policy Entropy: 1.04498
Value Function Loss: 2.51764

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.18843
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 11,995.49360
Overall Steps per Second: 10,194.36153

Timestep Collection Time: 4.17007
Timestep Consumption Time: 0.73676
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.90683

Cumulative Model Updates: 58,797
Cumulative Timesteps: 980,718,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 980718006...
Checkpoint 980718006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,087.93230
Policy Entropy: 1.06683
Value Function Loss: 2.51495

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.10113

Collected Steps per Second: 12,251.31763
Overall Steps per Second: 10,313.27814

Timestep Collection Time: 4.08299
Timestep Consumption Time: 0.76726
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.85025

Cumulative Model Updates: 58,800
Cumulative Timesteps: 980,768,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,331.61613
Policy Entropy: 1.07420
Value Function Loss: 2.43785

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.09264

Collected Steps per Second: 11,932.90714
Overall Steps per Second: 9,985.37874

Timestep Collection Time: 4.19093
Timestep Consumption Time: 0.81739
PPO Batch Consumption Time: 0.03487
Total Iteration Time: 5.00832

Cumulative Model Updates: 58,803
Cumulative Timesteps: 980,818,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980818038...
Checkpoint 980818038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827,173.72121
Policy Entropy: 1.06302
Value Function Loss: 2.43544

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.09967

Collected Steps per Second: 12,095.17528
Overall Steps per Second: 10,378.24409

Timestep Collection Time: 4.13586
Timestep Consumption Time: 0.68422
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 4.82008

Cumulative Model Updates: 58,806
Cumulative Timesteps: 980,868,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,110.04232
Policy Entropy: 1.05263
Value Function Loss: 2.53627

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.18165
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 11,855.90604
Overall Steps per Second: 9,959.63917

Timestep Collection Time: 4.21899
Timestep Consumption Time: 0.80328
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.02227

Cumulative Model Updates: 58,809
Cumulative Timesteps: 980,918,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980918082...
Checkpoint 980918082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,805.33392
Policy Entropy: 1.06119
Value Function Loss: 2.60497

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.09723

Collected Steps per Second: 11,721.27975
Overall Steps per Second: 9,944.75459

Timestep Collection Time: 4.26796
Timestep Consumption Time: 0.76243
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.03039

Cumulative Model Updates: 58,812
Cumulative Timesteps: 980,968,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,314.46618
Policy Entropy: 1.06967
Value Function Loss: 2.71832

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.09223

Collected Steps per Second: 11,996.79200
Overall Steps per Second: 10,127.56714

Timestep Collection Time: 4.16995
Timestep Consumption Time: 0.76964
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.93959

Cumulative Model Updates: 58,815
Cumulative Timesteps: 981,018,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 981018134...
Checkpoint 981018134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618,063.48499
Policy Entropy: 1.05694
Value Function Loss: 2.67589

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 11,873.22642
Overall Steps per Second: 10,055.09735

Timestep Collection Time: 4.21200
Timestep Consumption Time: 0.76160
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.97360

Cumulative Model Updates: 58,818
Cumulative Timesteps: 981,068,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,620.36756
Policy Entropy: 1.04525
Value Function Loss: 2.68811

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.17870
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.08102

Collected Steps per Second: 11,854.95099
Overall Steps per Second: 10,212.21874

Timestep Collection Time: 4.21967
Timestep Consumption Time: 0.67877
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.89845

Cumulative Model Updates: 58,821
Cumulative Timesteps: 981,118,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 981118168...
Checkpoint 981118168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605,111.15522
Policy Entropy: 1.05377
Value Function Loss: 2.54531

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.08534

Collected Steps per Second: 11,962.88912
Overall Steps per Second: 10,074.34918

Timestep Collection Time: 4.18126
Timestep Consumption Time: 0.78382
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.96508

Cumulative Model Updates: 58,824
Cumulative Timesteps: 981,168,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,962.88496
Policy Entropy: 1.05759
Value Function Loss: 2.48135

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 11,631.29669
Overall Steps per Second: 9,864.38862

Timestep Collection Time: 4.29995
Timestep Consumption Time: 0.77021
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 5.07016

Cumulative Model Updates: 58,827
Cumulative Timesteps: 981,218,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 981218202...
Checkpoint 981218202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,431.70449
Policy Entropy: 1.04385
Value Function Loss: 2.43526

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 12,030.47223
Overall Steps per Second: 10,180.57549

Timestep Collection Time: 4.15861
Timestep Consumption Time: 0.75565
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.91426

Cumulative Model Updates: 58,830
Cumulative Timesteps: 981,268,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,775.11467
Policy Entropy: 1.04572
Value Function Loss: 2.54718

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.09777

Collected Steps per Second: 12,022.83589
Overall Steps per Second: 10,103.36476

Timestep Collection Time: 4.16008
Timestep Consumption Time: 0.79035
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 4.95043

Cumulative Model Updates: 58,833
Cumulative Timesteps: 981,318,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 981318248...
Checkpoint 981318248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639,182.23658
Policy Entropy: 1.05633
Value Function Loss: 2.61371

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 11,927.28334
Overall Steps per Second: 10,181.35814

Timestep Collection Time: 4.19442
Timestep Consumption Time: 0.71927
PPO Batch Consumption Time: 0.03317
Total Iteration Time: 4.91369

Cumulative Model Updates: 58,836
Cumulative Timesteps: 981,368,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690,880.73575
Policy Entropy: 1.05736
Value Function Loss: 2.61494

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 11,810.53917
Overall Steps per Second: 9,957.90289

Timestep Collection Time: 4.23486
Timestep Consumption Time: 0.78788
PPO Batch Consumption Time: 0.03271
Total Iteration Time: 5.02274

Cumulative Model Updates: 58,839
Cumulative Timesteps: 981,418,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 981418292...
Checkpoint 981418292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,570.99016
Policy Entropy: 1.05588
Value Function Loss: 2.41947

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.08953

Collected Steps per Second: 11,495.47972
Overall Steps per Second: 9,765.92494

Timestep Collection Time: 4.35093
Timestep Consumption Time: 0.77055
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.12148

Cumulative Model Updates: 58,842
Cumulative Timesteps: 981,468,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,567.44169
Policy Entropy: 1.05310
Value Function Loss: 2.42965

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.09281

Collected Steps per Second: 11,844.36373
Overall Steps per Second: 9,988.91155

Timestep Collection Time: 4.22311
Timestep Consumption Time: 0.78445
PPO Batch Consumption Time: 0.03459
Total Iteration Time: 5.00755

Cumulative Model Updates: 58,845
Cumulative Timesteps: 981,518,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 981518328...
Checkpoint 981518328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,472.41724
Policy Entropy: 1.03590
Value Function Loss: 2.50925

Mean KL Divergence: 0.03553
SB3 Clip Fraction: 0.17909
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 11,799.83329
Overall Steps per Second: 9,960.04667

Timestep Collection Time: 4.23735
Timestep Consumption Time: 0.78271
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.02006

Cumulative Model Updates: 58,848
Cumulative Timesteps: 981,568,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,036.78194
Policy Entropy: 1.04867
Value Function Loss: 2.70747

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.09297

Collected Steps per Second: 12,500.22905
Overall Steps per Second: 10,447.36488

Timestep Collection Time: 4.00025
Timestep Consumption Time: 0.78603
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.78628

Cumulative Model Updates: 58,851
Cumulative Timesteps: 981,618,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 981618332...
Checkpoint 981618332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584,238.19946
Policy Entropy: 1.05581
Value Function Loss: 2.70079

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.15853
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 12,933.02966
Overall Steps per Second: 10,829.38645

Timestep Collection Time: 3.86731
Timestep Consumption Time: 0.75124
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.61854

Cumulative Model Updates: 58,854
Cumulative Timesteps: 981,668,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842,124.64492
Policy Entropy: 1.04062
Value Function Loss: 2.70721

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.08903

Collected Steps per Second: 12,732.48594
Overall Steps per Second: 10,604.35178

Timestep Collection Time: 3.92775
Timestep Consumption Time: 0.78824
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.71599

Cumulative Model Updates: 58,857
Cumulative Timesteps: 981,718,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 981718358...
Checkpoint 981718358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766,222.76226
Policy Entropy: 1.03299
Value Function Loss: 2.62000

Mean KL Divergence: 0.02978
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.09184

Collected Steps per Second: 12,787.96678
Overall Steps per Second: 10,778.21692

Timestep Collection Time: 3.91008
Timestep Consumption Time: 0.72909
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 4.63917

Cumulative Model Updates: 58,860
Cumulative Timesteps: 981,768,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,476.56858
Policy Entropy: 1.04710
Value Function Loss: 2.73401

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.10051

Collected Steps per Second: 12,986.27419
Overall Steps per Second: 10,713.39595

Timestep Collection Time: 3.85145
Timestep Consumption Time: 0.81710
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 4.66855

Cumulative Model Updates: 58,863
Cumulative Timesteps: 981,818,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 981818376...
Checkpoint 981818376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,132.12574
Policy Entropy: 1.06072
Value Function Loss: 2.68424

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15448
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 12,143.18384
Overall Steps per Second: 10,255.09014

Timestep Collection Time: 4.11984
Timestep Consumption Time: 0.75852
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 4.87836

Cumulative Model Updates: 58,866
Cumulative Timesteps: 981,868,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,118.01082
Policy Entropy: 1.03341
Value Function Loss: 2.76599

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.18708
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.08880

Collected Steps per Second: 12,583.08849
Overall Steps per Second: 10,398.55731

Timestep Collection Time: 3.97486
Timestep Consumption Time: 0.83504
PPO Batch Consumption Time: 0.03718
Total Iteration Time: 4.80990

Cumulative Model Updates: 58,869
Cumulative Timesteps: 981,918,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 981918420...
Checkpoint 981918420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,509.06721
Policy Entropy: 1.05380
Value Function Loss: 2.49231

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.08556

Collected Steps per Second: 11,798.74850
Overall Steps per Second: 9,983.35436

Timestep Collection Time: 4.23977
Timestep Consumption Time: 0.77097
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.01074

Cumulative Model Updates: 58,872
Cumulative Timesteps: 981,968,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,212.97927
Policy Entropy: 1.05055
Value Function Loss: 2.41321

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.09048

Collected Steps per Second: 11,773.41280
Overall Steps per Second: 10,084.79220

Timestep Collection Time: 4.24720
Timestep Consumption Time: 0.71116
PPO Batch Consumption Time: 0.03681
Total Iteration Time: 4.95836

Cumulative Model Updates: 58,875
Cumulative Timesteps: 982,018,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982018448...
Checkpoint 982018448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,265.82425
Policy Entropy: 1.03952
Value Function Loss: 2.30710

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.09314

Collected Steps per Second: 11,865.39998
Overall Steps per Second: 9,973.54894

Timestep Collection Time: 4.21612
Timestep Consumption Time: 0.79974
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.01587

Cumulative Model Updates: 58,878
Cumulative Timesteps: 982,068,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,145.62690
Policy Entropy: 1.02418
Value Function Loss: 2.36201

Mean KL Divergence: 0.03007
SB3 Clip Fraction: 0.19352
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 12,078.09442
Overall Steps per Second: 10,171.93300

Timestep Collection Time: 4.14088
Timestep Consumption Time: 0.77598
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.91686

Cumulative Model Updates: 58,881
Cumulative Timesteps: 982,118,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 982118488...
Checkpoint 982118488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,945.53032
Policy Entropy: 1.04209
Value Function Loss: 2.38313

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 11,411.98261
Overall Steps per Second: 9,635.05314

Timestep Collection Time: 4.38189
Timestep Consumption Time: 0.80812
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.19001

Cumulative Model Updates: 58,884
Cumulative Timesteps: 982,168,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,249.62368
Policy Entropy: 1.05176
Value Function Loss: 2.42116

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.08366

Collected Steps per Second: 11,766.03011
Overall Steps per Second: 9,919.01330

Timestep Collection Time: 4.25020
Timestep Consumption Time: 0.79143
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 5.04163

Cumulative Model Updates: 58,887
Cumulative Timesteps: 982,218,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982218502...
Checkpoint 982218502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695,377.22141
Policy Entropy: 1.02963
Value Function Loss: 2.50456

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 11,771.16571
Overall Steps per Second: 10,160.17874

Timestep Collection Time: 4.24852
Timestep Consumption Time: 0.67364
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.92216

Cumulative Model Updates: 58,890
Cumulative Timesteps: 982,268,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,183.70220
Policy Entropy: 1.04211
Value Function Loss: 2.55915

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.08041

Collected Steps per Second: 12,042.82645
Overall Steps per Second: 10,150.96217

Timestep Collection Time: 4.15218
Timestep Consumption Time: 0.77385
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.92604

Cumulative Model Updates: 58,893
Cumulative Timesteps: 982,318,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982318516...
Checkpoint 982318516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,936.08463
Policy Entropy: 1.04522
Value Function Loss: 2.59732

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.10789

Collected Steps per Second: 12,024.99577
Overall Steps per Second: 10,171.97116

Timestep Collection Time: 4.15867
Timestep Consumption Time: 0.75758
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 4.91625

Cumulative Model Updates: 58,896
Cumulative Timesteps: 982,368,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739,504.66029
Policy Entropy: 1.03508
Value Function Loss: 2.50605

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 12,066.07253
Overall Steps per Second: 10,118.35817

Timestep Collection Time: 4.14617
Timestep Consumption Time: 0.79811
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 4.94428

Cumulative Model Updates: 58,899
Cumulative Timesteps: 982,418,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 982418552...
Checkpoint 982418552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742,811.95108
Policy Entropy: 1.02481
Value Function Loss: 2.44849

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 11,437.39052
Overall Steps per Second: 9,798.61701

Timestep Collection Time: 4.37285
Timestep Consumption Time: 0.73134
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 5.10419

Cumulative Model Updates: 58,902
Cumulative Timesteps: 982,468,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687,207.64617
Policy Entropy: 1.03460
Value Function Loss: 2.42008

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.12641

Collected Steps per Second: 11,714.26074
Overall Steps per Second: 10,112.26073

Timestep Collection Time: 4.27052
Timestep Consumption Time: 0.67654
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 4.94706

Cumulative Model Updates: 58,905
Cumulative Timesteps: 982,518,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 982518592...
Checkpoint 982518592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,877.36224
Policy Entropy: 1.03625
Value Function Loss: 2.57917

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 12,060.32865
Overall Steps per Second: 10,120.84247

Timestep Collection Time: 4.14732
Timestep Consumption Time: 0.79476
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.94208

Cumulative Model Updates: 58,908
Cumulative Timesteps: 982,568,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754,792.65500
Policy Entropy: 1.02642
Value Function Loss: 2.67983

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.09787

Collected Steps per Second: 11,823.44746
Overall Steps per Second: 10,056.25073

Timestep Collection Time: 4.22939
Timestep Consumption Time: 0.74324
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 4.97263

Cumulative Model Updates: 58,911
Cumulative Timesteps: 982,618,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 982618616...
Checkpoint 982618616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,834.34561
Policy Entropy: 1.01236
Value Function Loss: 2.79000

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.18437
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 11,770.46543
Overall Steps per Second: 9,984.63026

Timestep Collection Time: 4.25013
Timestep Consumption Time: 0.76017
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.01030

Cumulative Model Updates: 58,914
Cumulative Timesteps: 982,668,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,369.64820
Policy Entropy: 1.03305
Value Function Loss: 2.75520

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 12,022.77259
Overall Steps per Second: 10,139.91633

Timestep Collection Time: 4.15977
Timestep Consumption Time: 0.77242
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 4.93219

Cumulative Model Updates: 58,917
Cumulative Timesteps: 982,718,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 982718654...
Checkpoint 982718654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760,362.57189
Policy Entropy: 1.04138
Value Function Loss: 2.76036

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.12478

Collected Steps per Second: 11,555.76677
Overall Steps per Second: 9,936.71941

Timestep Collection Time: 4.32875
Timestep Consumption Time: 0.70531
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.03406

Cumulative Model Updates: 58,920
Cumulative Timesteps: 982,768,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755,331.99972
Policy Entropy: 1.02123
Value Function Loss: 2.65816

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.11613

Collected Steps per Second: 11,719.75389
Overall Steps per Second: 9,946.00501

Timestep Collection Time: 4.26698
Timestep Consumption Time: 0.76096
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 5.02795

Cumulative Model Updates: 58,923
Cumulative Timesteps: 982,818,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982818684...
Checkpoint 982818684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716,668.28881
Policy Entropy: 1.01960
Value Function Loss: 2.67620

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.10543

Collected Steps per Second: 12,138.30267
Overall Steps per Second: 10,281.90851

Timestep Collection Time: 4.12002
Timestep Consumption Time: 0.74387
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.86388

Cumulative Model Updates: 58,926
Cumulative Timesteps: 982,868,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767,212.72444
Policy Entropy: 1.02425
Value Function Loss: 2.56012

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 12,109.26033
Overall Steps per Second: 10,438.61314

Timestep Collection Time: 4.13023
Timestep Consumption Time: 0.66102
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 4.79125

Cumulative Model Updates: 58,929
Cumulative Timesteps: 982,918,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 982918708...
Checkpoint 982918708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829,341.99111
Policy Entropy: 1.03460
Value Function Loss: 2.48112

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 11,860.55115
Overall Steps per Second: 10,028.00876

Timestep Collection Time: 4.21633
Timestep Consumption Time: 0.77050
PPO Batch Consumption Time: 0.03617
Total Iteration Time: 4.98683

Cumulative Model Updates: 58,932
Cumulative Timesteps: 982,968,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773,116.74615
Policy Entropy: 1.01890
Value Function Loss: 2.44081

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 11,992.79425
Overall Steps per Second: 10,194.42205

Timestep Collection Time: 4.16950
Timestep Consumption Time: 0.73553
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.90504

Cumulative Model Updates: 58,935
Cumulative Timesteps: 983,018,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983018720...
Checkpoint 983018720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,133.75290
Policy Entropy: 1.00775
Value Function Loss: 2.55595

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.19096
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.11145

Collected Steps per Second: 11,095.22027
Overall Steps per Second: 9,382.42403

Timestep Collection Time: 4.50861
Timestep Consumption Time: 0.82306
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.33167

Cumulative Model Updates: 58,938
Cumulative Timesteps: 983,068,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,222.95308
Policy Entropy: 1.01903
Value Function Loss: 2.62366

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.11771

Collected Steps per Second: 12,108.95787
Overall Steps per Second: 10,125.16554

Timestep Collection Time: 4.13116
Timestep Consumption Time: 0.80940
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 4.94056

Cumulative Model Updates: 58,941
Cumulative Timesteps: 983,118,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 983118768...
Checkpoint 983118768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,852.06038
Policy Entropy: 1.02370
Value Function Loss: 2.65400

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 11,858.03225
Overall Steps per Second: 10,274.17755

Timestep Collection Time: 4.21739
Timestep Consumption Time: 0.65015
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.86754

Cumulative Model Updates: 58,944
Cumulative Timesteps: 983,168,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661,295.84639
Policy Entropy: 1.01043
Value Function Loss: 2.67968

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 12,011.17928
Overall Steps per Second: 10,126.89534

Timestep Collection Time: 4.16445
Timestep Consumption Time: 0.77487
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.93932

Cumulative Model Updates: 58,947
Cumulative Timesteps: 983,218,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 983218798...
Checkpoint 983218798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825,618.06437
Policy Entropy: 0.99950
Value Function Loss: 2.61368

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.20068
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.10801

Collected Steps per Second: 11,874.54415
Overall Steps per Second: 10,119.79631

Timestep Collection Time: 4.21220
Timestep Consumption Time: 0.73039
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 4.94259

Cumulative Model Updates: 58,950
Cumulative Timesteps: 983,268,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,991.75946
Policy Entropy: 1.02265
Value Function Loss: 2.54272

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.11031

Collected Steps per Second: 12,201.20142
Overall Steps per Second: 10,290.40659

Timestep Collection Time: 4.09796
Timestep Consumption Time: 0.76094
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 4.85889

Cumulative Model Updates: 58,953
Cumulative Timesteps: 983,318,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 983318816...
Checkpoint 983318816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,250.87847
Policy Entropy: 1.02346
Value Function Loss: 2.38088

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.12632

Collected Steps per Second: 11,256.39279
Overall Steps per Second: 9,645.21554

Timestep Collection Time: 4.44370
Timestep Consumption Time: 0.74229
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.18599

Cumulative Model Updates: 58,956
Cumulative Timesteps: 983,368,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,365.95302
Policy Entropy: 1.00545
Value Function Loss: 2.62355

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 11,950.22276
Overall Steps per Second: 10,293.17104

Timestep Collection Time: 4.18670
Timestep Consumption Time: 0.67400
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.86070

Cumulative Model Updates: 58,959
Cumulative Timesteps: 983,418,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 983418868...
Checkpoint 983418868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667,046.28023
Policy Entropy: 1.00400
Value Function Loss: 2.71847

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 11,871.95877
Overall Steps per Second: 10,010.14483

Timestep Collection Time: 4.21312
Timestep Consumption Time: 0.78361
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.99673

Cumulative Model Updates: 58,962
Cumulative Timesteps: 983,468,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,320.12215
Policy Entropy: 1.01335
Value Function Loss: 2.81517

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 11,739.66635
Overall Steps per Second: 10,160.16460

Timestep Collection Time: 4.26009
Timestep Consumption Time: 0.66227
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 4.92236

Cumulative Model Updates: 58,965
Cumulative Timesteps: 983,518,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 983518898...
Checkpoint 983518898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762,969.07010
Policy Entropy: 1.02396
Value Function Loss: 2.70584

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 11,925.42973
Overall Steps per Second: 10,039.64532

Timestep Collection Time: 4.19406
Timestep Consumption Time: 0.78779
PPO Batch Consumption Time: 0.03591
Total Iteration Time: 4.98185

Cumulative Model Updates: 58,968
Cumulative Timesteps: 983,568,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753,755.48295
Policy Entropy: 1.00610
Value Function Loss: 2.62048

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16984
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 11,848.65477
Overall Steps per Second: 10,040.98627

Timestep Collection Time: 4.22107
Timestep Consumption Time: 0.75991
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.98098

Cumulative Model Updates: 58,971
Cumulative Timesteps: 983,618,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 983618928...
Checkpoint 983618928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,927.81857
Policy Entropy: 0.99634
Value Function Loss: 2.51413

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.19707
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 11,352.13807
Overall Steps per Second: 9,858.60045

Timestep Collection Time: 4.40728
Timestep Consumption Time: 0.66768
PPO Batch Consumption Time: 0.03578
Total Iteration Time: 5.07496

Cumulative Model Updates: 58,974
Cumulative Timesteps: 983,668,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,466.24758
Policy Entropy: 1.01146
Value Function Loss: 2.38738

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 11,970.52704
Overall Steps per Second: 10,117.84355

Timestep Collection Time: 4.17860
Timestep Consumption Time: 0.76514
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.94374

Cumulative Model Updates: 58,977
Cumulative Timesteps: 983,718,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 983718980...
Checkpoint 983718980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719,751.17365
Policy Entropy: 1.01791
Value Function Loss: 2.50032

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.18137
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 12,004.70971
Overall Steps per Second: 10,145.38246

Timestep Collection Time: 4.16587
Timestep Consumption Time: 0.76347
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 4.92934

Cumulative Model Updates: 58,980
Cumulative Timesteps: 983,768,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,976.53315
Policy Entropy: 1.00261
Value Function Loss: 2.70423

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16826
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.08938

Collected Steps per Second: 12,066.46765
Overall Steps per Second: 10,142.65788

Timestep Collection Time: 4.14388
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.92987

Cumulative Model Updates: 58,983
Cumulative Timesteps: 983,818,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 983818992...
Checkpoint 983818992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,344.72476
Policy Entropy: 1.01599
Value Function Loss: 2.82346

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.18679
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.08665

Collected Steps per Second: 11,753.37652
Overall Steps per Second: 9,965.15800

Timestep Collection Time: 4.25682
Timestep Consumption Time: 0.76387
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.02069

Cumulative Model Updates: 58,986
Cumulative Timesteps: 983,869,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,251.50639
Policy Entropy: 1.03354
Value Function Loss: 2.67220

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.16037
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.08858

Collected Steps per Second: 12,067.61599
Overall Steps per Second: 10,345.83747

Timestep Collection Time: 4.14514
Timestep Consumption Time: 0.68984
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.83499

Cumulative Model Updates: 58,989
Cumulative Timesteps: 983,919,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 983919046...
Checkpoint 983919046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590,869.17798
Policy Entropy: 1.00141
Value Function Loss: 2.48345

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.18202
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.09676

Collected Steps per Second: 11,306.72416
Overall Steps per Second: 9,585.30105

Timestep Collection Time: 4.42498
Timestep Consumption Time: 0.79468
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 5.21966

Cumulative Model Updates: 58,992
Cumulative Timesteps: 983,969,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771,556.03563
Policy Entropy: 1.01243
Value Function Loss: 2.47558

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.16488
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 12,056.44664
Overall Steps per Second: 10,215.48232

Timestep Collection Time: 4.14716
Timestep Consumption Time: 0.74737
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 4.89453

Cumulative Model Updates: 58,995
Cumulative Timesteps: 984,019,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 984019078...
Checkpoint 984019078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,968.20700
Policy Entropy: 1.01863
Value Function Loss: 2.64123

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.17334
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 13,018.20547
Overall Steps per Second: 10,815.78905

Timestep Collection Time: 3.84154
Timestep Consumption Time: 0.78225
PPO Batch Consumption Time: 0.03412
Total Iteration Time: 4.62380

Cumulative Model Updates: 58,998
Cumulative Timesteps: 984,069,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,454.48437
Policy Entropy: 1.03890
Value Function Loss: 2.74997

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.19700
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.09585

Collected Steps per Second: 12,829.66855
Overall Steps per Second: 10,703.63061

Timestep Collection Time: 3.89878
Timestep Consumption Time: 0.77440
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 4.67318

Cumulative Model Updates: 59,001
Cumulative Timesteps: 984,119,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 984119108...
Checkpoint 984119108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,494.76591
Policy Entropy: 1.01269
Value Function Loss: 2.74437

Mean KL Divergence: 0.03167
SB3 Clip Fraction: 0.21744
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.08938

Collected Steps per Second: 12,703.26752
Overall Steps per Second: 10,743.65925

Timestep Collection Time: 3.93757
Timestep Consumption Time: 0.71820
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 4.65577

Cumulative Model Updates: 59,004
Cumulative Timesteps: 984,169,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,235.83238
Policy Entropy: 1.02974
Value Function Loss: 2.68836

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 12,840.78497
Overall Steps per Second: 10,618.43400

Timestep Collection Time: 3.89602
Timestep Consumption Time: 0.81541
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.71143

Cumulative Model Updates: 59,007
Cumulative Timesteps: 984,219,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 984219156...
Checkpoint 984219156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,490.98391
Policy Entropy: 1.02703
Value Function Loss: 2.69964

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14834
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.08357

Collected Steps per Second: 12,183.21616
Overall Steps per Second: 10,284.04059

Timestep Collection Time: 4.10499
Timestep Consumption Time: 0.75808
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.86307

Cumulative Model Updates: 59,010
Cumulative Timesteps: 984,269,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757,200.89126
Policy Entropy: 1.01559
Value Function Loss: 2.69224

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 13,086.25893
Overall Steps per Second: 10,839.31799

Timestep Collection Time: 3.82141
Timestep Consumption Time: 0.79216
PPO Batch Consumption Time: 0.03445
Total Iteration Time: 4.61357

Cumulative Model Updates: 59,013
Cumulative Timesteps: 984,319,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 984319176...
Checkpoint 984319176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699,287.87870
Policy Entropy: 0.99800
Value Function Loss: 2.69078

Mean KL Divergence: 0.03318
SB3 Clip Fraction: 0.20671
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 11,849.52847
Overall Steps per Second: 10,049.67883

Timestep Collection Time: 4.22143
Timestep Consumption Time: 0.75604
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.97747

Cumulative Model Updates: 59,016
Cumulative Timesteps: 984,369,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672,953.68446
Policy Entropy: 1.02357
Value Function Loss: 2.58230

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.08039

Collected Steps per Second: 11,950.23986
Overall Steps per Second: 10,280.55840

Timestep Collection Time: 4.18502
Timestep Consumption Time: 0.67970
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.86472

Cumulative Model Updates: 59,019
Cumulative Timesteps: 984,419,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984419210...
Checkpoint 984419210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,071.86629
Policy Entropy: 1.02802
Value Function Loss: 2.47781

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08359

Collected Steps per Second: 11,790.17877
Overall Steps per Second: 9,945.55920

Timestep Collection Time: 4.24082
Timestep Consumption Time: 0.78655
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.02737

Cumulative Model Updates: 59,022
Cumulative Timesteps: 984,469,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,626.57238
Policy Entropy: 1.01681
Value Function Loss: 2.47285

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 11,922.51253
Overall Steps per Second: 10,182.66862

Timestep Collection Time: 4.19576
Timestep Consumption Time: 0.71690
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.91266

Cumulative Model Updates: 59,025
Cumulative Timesteps: 984,519,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 984519234...
Checkpoint 984519234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,951.82962
Policy Entropy: 1.00420
Value Function Loss: 2.50215

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.18977
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 11,555.71932
Overall Steps per Second: 9,759.22524

Timestep Collection Time: 4.32928
Timestep Consumption Time: 0.79694
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 5.12623

Cumulative Model Updates: 59,028
Cumulative Timesteps: 984,569,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715,973.87599
Policy Entropy: 1.02112
Value Function Loss: 2.46058

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 11,923.83509
Overall Steps per Second: 10,071.99939

Timestep Collection Time: 4.19412
Timestep Consumption Time: 0.77113
PPO Batch Consumption Time: 0.03538
Total Iteration Time: 4.96525

Cumulative Model Updates: 59,031
Cumulative Timesteps: 984,619,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 984619272...
Checkpoint 984619272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,559.95006
Policy Entropy: 1.02785
Value Function Loss: 2.43433

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.17099
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 11,930.96927
Overall Steps per Second: 10,301.85680

Timestep Collection Time: 4.19212
Timestep Consumption Time: 0.66293
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.85505

Cumulative Model Updates: 59,034
Cumulative Timesteps: 984,669,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831,048.18304
Policy Entropy: 1.00312
Value Function Loss: 2.50746

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.09445

Collected Steps per Second: 11,864.62419
Overall Steps per Second: 10,010.96779

Timestep Collection Time: 4.21522
Timestep Consumption Time: 0.78050
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.99572

Cumulative Model Updates: 59,037
Cumulative Timesteps: 984,719,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984719300...
Checkpoint 984719300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,879.01229
Policy Entropy: 1.00338
Value Function Loss: 2.63387

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11,914.25708
Overall Steps per Second: 10,133.78328

Timestep Collection Time: 4.19850
Timestep Consumption Time: 0.73766
PPO Batch Consumption Time: 0.03470
Total Iteration Time: 4.93616

Cumulative Model Updates: 59,040
Cumulative Timesteps: 984,769,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,036.62408
Policy Entropy: 1.01331
Value Function Loss: 2.66744

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.15283
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.08463

Collected Steps per Second: 11,882.87395
Overall Steps per Second: 10,276.30613

Timestep Collection Time: 4.20959
Timestep Consumption Time: 0.65811
PPO Batch Consumption Time: 0.03475
Total Iteration Time: 4.86770

Cumulative Model Updates: 59,043
Cumulative Timesteps: 984,819,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 984819344...
Checkpoint 984819344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,344.10997
Policy Entropy: 1.01644
Value Function Loss: 2.72592

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 11,497.97921
Overall Steps per Second: 9,789.86097

Timestep Collection Time: 4.34929
Timestep Consumption Time: 0.75886
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.10814

Cumulative Model Updates: 59,046
Cumulative Timesteps: 984,869,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813,594.42394
Policy Entropy: 1.00361
Value Function Loss: 2.67374

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.09353

Collected Steps per Second: 11,873.94472
Overall Steps per Second: 10,023.56610

Timestep Collection Time: 4.21174
Timestep Consumption Time: 0.77750
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.98924

Cumulative Model Updates: 59,049
Cumulative Timesteps: 984,919,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 984919362...
Checkpoint 984919362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,781.88813
Policy Entropy: 0.99193
Value Function Loss: 2.57926

Mean KL Divergence: 0.03126
SB3 Clip Fraction: 0.20243
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 12,206.66467
Overall Steps per Second: 10,255.77794

Timestep Collection Time: 4.09793
Timestep Consumption Time: 0.77952
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.87745

Cumulative Model Updates: 59,052
Cumulative Timesteps: 984,969,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767,322.12011
Policy Entropy: 1.02023
Value Function Loss: 2.49140

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 12,234.90379
Overall Steps per Second: 10,299.74096

Timestep Collection Time: 4.08683
Timestep Consumption Time: 0.76785
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 4.85469

Cumulative Model Updates: 59,055
Cumulative Timesteps: 985,019,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 985019386...
Checkpoint 985019386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,534.25767
Policy Entropy: 1.00498
Value Function Loss: 2.41694

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.12778

Collected Steps per Second: 11,694.08529
Overall Steps per Second: 10,143.47504

Timestep Collection Time: 4.27789
Timestep Consumption Time: 0.65395
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 4.93184

Cumulative Model Updates: 59,058
Cumulative Timesteps: 985,069,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681,228.01108
Policy Entropy: 1.00260
Value Function Loss: 2.48628

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 11,951.37686
Overall Steps per Second: 10,090.47961

Timestep Collection Time: 4.18479
Timestep Consumption Time: 0.77176
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.95655

Cumulative Model Updates: 59,061
Cumulative Timesteps: 985,119,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 985119426...
Checkpoint 985119426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,245.84578
Policy Entropy: 0.99513
Value Function Loss: 2.53555

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.07174
Value Function Update Magnitude: 0.13445

Collected Steps per Second: 11,481.07022
Overall Steps per Second: 9,727.84871

Timestep Collection Time: 4.35743
Timestep Consumption Time: 0.78533
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.14276

Cumulative Model Updates: 59,064
Cumulative Timesteps: 985,169,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737,858.15269
Policy Entropy: 1.00836
Value Function Loss: 2.56607

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.16020
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.13118

Collected Steps per Second: 11,933.91534
Overall Steps per Second: 10,302.73900

Timestep Collection Time: 4.19125
Timestep Consumption Time: 0.66358
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 4.85483

Cumulative Model Updates: 59,067
Cumulative Timesteps: 985,219,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 985219472...
Checkpoint 985219472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,112.03020
Policy Entropy: 1.01459
Value Function Loss: 2.58334

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 11,768.78980
Overall Steps per Second: 9,947.76063

Timestep Collection Time: 4.24937
Timestep Consumption Time: 0.77789
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.02726

Cumulative Model Updates: 59,070
Cumulative Timesteps: 985,269,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722,212.67032
Policy Entropy: 1.01916
Value Function Loss: 2.58868

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 11,949.54157
Overall Steps per Second: 10,194.51413

Timestep Collection Time: 4.18560
Timestep Consumption Time: 0.72057
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.90617

Cumulative Model Updates: 59,073
Cumulative Timesteps: 985,319,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 985319498...
Checkpoint 985319498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,151.55013
Policy Entropy: 1.02354
Value Function Loss: 2.56602

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 12,491.23650
Overall Steps per Second: 10,497.54637

Timestep Collection Time: 4.00297
Timestep Consumption Time: 0.76024
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.76321

Cumulative Model Updates: 59,076
Cumulative Timesteps: 985,369,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770,337.61656
Policy Entropy: 1.01181
Value Function Loss: 2.52223

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 11,993.08181
Overall Steps per Second: 10,149.31428

Timestep Collection Time: 4.16907
Timestep Consumption Time: 0.75737
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 4.92644

Cumulative Model Updates: 59,079
Cumulative Timesteps: 985,419,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985419500...
Checkpoint 985419500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792,979.83323
Policy Entropy: 0.99351
Value Function Loss: 2.44887

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.20767
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.11369

Collected Steps per Second: 11,807.87854
Overall Steps per Second: 10,121.63749

Timestep Collection Time: 4.23683
Timestep Consumption Time: 0.70585
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.94268

Cumulative Model Updates: 59,082
Cumulative Timesteps: 985,469,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,726.28997
Policy Entropy: 1.01161
Value Function Loss: 2.53881

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.16130
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 11,976.73581
Overall Steps per Second: 10,128.15930

Timestep Collection Time: 4.17476
Timestep Consumption Time: 0.76197
PPO Batch Consumption Time: 0.03363
Total Iteration Time: 4.93673

Cumulative Model Updates: 59,085
Cumulative Timesteps: 985,519,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985519528...
Checkpoint 985519528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806,461.03067
Policy Entropy: 1.01824
Value Function Loss: 2.57784

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.10880

Collected Steps per Second: 11,932.68483
Overall Steps per Second: 10,154.87319

Timestep Collection Time: 4.19151
Timestep Consumption Time: 0.73381
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.92532

Cumulative Model Updates: 59,088
Cumulative Timesteps: 985,569,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,029.06536
Policy Entropy: 1.00448
Value Function Loss: 2.63763

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.10773

Collected Steps per Second: 11,684.03912
Overall Steps per Second: 10,085.37541

Timestep Collection Time: 4.28037
Timestep Consumption Time: 0.67849
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.95886

Cumulative Model Updates: 59,091
Cumulative Timesteps: 985,619,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985619556...
Checkpoint 985619556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,164.56832
Policy Entropy: 0.99846
Value Function Loss: 2.59930

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.20151
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.09218

Collected Steps per Second: 11,842.26688
Overall Steps per Second: 10,029.07851

Timestep Collection Time: 4.22470
Timestep Consumption Time: 0.76380
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.98849

Cumulative Model Updates: 59,094
Cumulative Timesteps: 985,669,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,684.30868
Policy Entropy: 1.00995
Value Function Loss: 2.58306

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.10152

Collected Steps per Second: 12,063.20347
Overall Steps per Second: 10,353.59108

Timestep Collection Time: 4.14484
Timestep Consumption Time: 0.68441
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.82924

Cumulative Model Updates: 59,097
Cumulative Timesteps: 985,719,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985719586...
Checkpoint 985719586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747,045.26713
Policy Entropy: 1.01848
Value Function Loss: 2.53840

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 11,711.47860
Overall Steps per Second: 9,821.91770

Timestep Collection Time: 4.27085
Timestep Consumption Time: 0.82164
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 5.09249

Cumulative Model Updates: 59,100
Cumulative Timesteps: 985,769,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801,527.65522
Policy Entropy: 0.99917
Value Function Loss: 2.62449

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.11609

Collected Steps per Second: 12,054.07247
Overall Steps per Second: 10,239.87178

Timestep Collection Time: 4.14864
Timestep Consumption Time: 0.73502
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 4.88365

Cumulative Model Updates: 59,103
Cumulative Timesteps: 985,819,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 985819612...
Checkpoint 985819612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,340.94500
Policy Entropy: 0.98748
Value Function Loss: 2.76628

Mean KL Divergence: 0.03789
SB3 Clip Fraction: 0.20873
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 12,210.08820
Overall Steps per Second: 10,294.46330

Timestep Collection Time: 4.09710
Timestep Consumption Time: 0.76240
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.85951

Cumulative Model Updates: 59,106
Cumulative Timesteps: 985,869,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,135.88183
Policy Entropy: 1.00280
Value Function Loss: 2.79562

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16411
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.11080

Collected Steps per Second: 12,054.50782
Overall Steps per Second: 10,196.19978

Timestep Collection Time: 4.14882
Timestep Consumption Time: 0.75614
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 4.90496

Cumulative Model Updates: 59,109
Cumulative Timesteps: 985,919,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985919650...
Checkpoint 985919650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,136.05649
Policy Entropy: 1.00274
Value Function Loss: 2.82037

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 12,004.05664
Overall Steps per Second: 10,283.63800

Timestep Collection Time: 4.16709
Timestep Consumption Time: 0.69714
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 4.86423

Cumulative Model Updates: 59,112
Cumulative Timesteps: 985,969,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764,368.77341
Policy Entropy: 0.99471
Value Function Loss: 2.70948

Mean KL Divergence: 0.02942
SB3 Clip Fraction: 0.18759
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 11,677.84394
Overall Steps per Second: 9,927.77519

Timestep Collection Time: 4.28247
Timestep Consumption Time: 0.75491
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.03738

Cumulative Model Updates: 59,115
Cumulative Timesteps: 986,019,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 986019682...
Checkpoint 986019682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830,067.96816
Policy Entropy: 1.01600
Value Function Loss: 2.67807

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.17305
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11,895.21175
Overall Steps per Second: 9,933.55288

Timestep Collection Time: 4.20337
Timestep Consumption Time: 0.83007
PPO Batch Consumption Time: 0.03658
Total Iteration Time: 5.03345

Cumulative Model Updates: 59,118
Cumulative Timesteps: 986,069,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882,715.90410
Policy Entropy: 1.01300
Value Function Loss: 2.66778

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.06898
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 12,038.22284
Overall Steps per Second: 10,387.69238

Timestep Collection Time: 4.15394
Timestep Consumption Time: 0.66003
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.81397

Cumulative Model Updates: 59,121
Cumulative Timesteps: 986,119,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986119688...
Checkpoint 986119688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,331.55814
Policy Entropy: 1.00922
Value Function Loss: 2.77356

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.07094
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 11,756.16012
Overall Steps per Second: 9,941.11579

Timestep Collection Time: 4.25309
Timestep Consumption Time: 0.77653
PPO Batch Consumption Time: 0.03476
Total Iteration Time: 5.02962

Cumulative Model Updates: 59,124
Cumulative Timesteps: 986,169,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772,662.25970
Policy Entropy: 1.00333
Value Function Loss: 2.79820

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.06843
Value Function Update Magnitude: 0.08508

Collected Steps per Second: 11,928.50736
Overall Steps per Second: 10,082.33077

Timestep Collection Time: 4.19348
Timestep Consumption Time: 0.76787
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 4.96135

Cumulative Model Updates: 59,127
Cumulative Timesteps: 986,219,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986219710...
Checkpoint 986219710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788,293.30114
Policy Entropy: 1.00387
Value Function Loss: 2.62566

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.09413

Collected Steps per Second: 12,153.61800
Overall Steps per Second: 10,254.02069

Timestep Collection Time: 4.11598
Timestep Consumption Time: 0.76250
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 4.87848

Cumulative Model Updates: 59,130
Cumulative Timesteps: 986,269,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877,966.25567
Policy Entropy: 1.00804
Value Function Loss: 2.47428

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.09359

Collected Steps per Second: 11,346.45705
Overall Steps per Second: 9,628.07104

Timestep Collection Time: 4.40719
Timestep Consumption Time: 0.78658
PPO Batch Consumption Time: 0.03603
Total Iteration Time: 5.19377

Cumulative Model Updates: 59,133
Cumulative Timesteps: 986,319,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986319740...
Checkpoint 986319740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,753.23778
Policy Entropy: 1.01634
Value Function Loss: 2.47964

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.08387

Collected Steps per Second: 11,955.52417
Overall Steps per Second: 10,184.62043

Timestep Collection Time: 4.18233
Timestep Consumption Time: 0.72723
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 4.90956

Cumulative Model Updates: 59,136
Cumulative Timesteps: 986,369,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,404.92077
Policy Entropy: 1.03272
Value Function Loss: 2.62532

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 11,947.50237
Overall Steps per Second: 10,084.92762

Timestep Collection Time: 4.18615
Timestep Consumption Time: 0.77314
PPO Batch Consumption Time: 0.03491
Total Iteration Time: 4.95928

Cumulative Model Updates: 59,139
Cumulative Timesteps: 986,419,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 986419756...
Checkpoint 986419756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,229.09534
Policy Entropy: 1.02259
Value Function Loss: 2.64928

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.16563
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 12,264.51476
Overall Steps per Second: 10,315.92856

Timestep Collection Time: 4.07762
Timestep Consumption Time: 0.77023
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 4.84784

Cumulative Model Updates: 59,142
Cumulative Timesteps: 986,469,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,007.88980
Policy Entropy: 1.01411
Value Function Loss: 2.69106

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.18382
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 12,859.92401
Overall Steps per Second: 10,634.75534

Timestep Collection Time: 3.88976
Timestep Consumption Time: 0.81388
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.70363

Cumulative Model Updates: 59,145
Cumulative Timesteps: 986,519,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986519788...
Checkpoint 986519788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592,217.69828
Policy Entropy: 1.02499
Value Function Loss: 2.66505

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.08080

Collected Steps per Second: 12,463.34983
Overall Steps per Second: 10,420.90261

Timestep Collection Time: 4.01417
Timestep Consumption Time: 0.78676
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.80093

Cumulative Model Updates: 59,148
Cumulative Timesteps: 986,569,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725,950.46824
Policy Entropy: 1.03026
Value Function Loss: 2.63896

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 12,594.48095
Overall Steps per Second: 10,751.74775

Timestep Collection Time: 3.97174
Timestep Consumption Time: 0.68071
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.65245

Cumulative Model Updates: 59,151
Cumulative Timesteps: 986,619,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986619840...
Checkpoint 986619840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,598.57185
Policy Entropy: 1.01342
Value Function Loss: 2.51892

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.08308

Collected Steps per Second: 12,600.20084
Overall Steps per Second: 10,544.42961

Timestep Collection Time: 3.96867
Timestep Consumption Time: 0.77374
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.74241

Cumulative Model Updates: 59,154
Cumulative Timesteps: 986,669,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733,822.66133
Policy Entropy: 1.01423
Value Function Loss: 2.49549

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.15487
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 11,931.98525
Overall Steps per Second: 10,131.69296

Timestep Collection Time: 4.19126
Timestep Consumption Time: 0.74474
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.93600

Cumulative Model Updates: 59,157
Cumulative Timesteps: 986,719,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 986719856...
Checkpoint 986719856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,019.92283
Policy Entropy: 1.03439
Value Function Loss: 2.61834

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.08881

Collected Steps per Second: 12,550.57308
Overall Steps per Second: 10,718.26563

Timestep Collection Time: 3.98611
Timestep Consumption Time: 0.68143
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.66755

Cumulative Model Updates: 59,160
Cumulative Timesteps: 986,769,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,599.07759
Policy Entropy: 1.03605
Value Function Loss: 2.67592

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 11,915.59841
Overall Steps per Second: 10,084.16891

Timestep Collection Time: 4.19668
Timestep Consumption Time: 0.76218
PPO Batch Consumption Time: 0.03726
Total Iteration Time: 4.95886

Cumulative Model Updates: 59,163
Cumulative Timesteps: 986,819,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986819890...
Checkpoint 986819890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,424.92746
Policy Entropy: 1.02027
Value Function Loss: 2.57689

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.08832

Collected Steps per Second: 11,993.81016
Overall Steps per Second: 10,205.30854

Timestep Collection Time: 4.17032
Timestep Consumption Time: 0.73086
PPO Batch Consumption Time: 0.03527
Total Iteration Time: 4.90117

Cumulative Model Updates: 59,166
Cumulative Timesteps: 986,869,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726,948.84779
Policy Entropy: 0.99497
Value Function Loss: 2.48313

Mean KL Divergence: 0.03774
SB3 Clip Fraction: 0.22209
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 12,130.56045
Overall Steps per Second: 10,272.33116

Timestep Collection Time: 4.12363
Timestep Consumption Time: 0.74595
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 4.86959

Cumulative Model Updates: 59,169
Cumulative Timesteps: 986,919,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986919930...
Checkpoint 986919930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623,549.10664
Policy Entropy: 1.02245
Value Function Loss: 2.62365

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.08621

Collected Steps per Second: 11,935.91863
Overall Steps per Second: 9,991.77517

Timestep Collection Time: 4.18904
Timestep Consumption Time: 0.81508
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.00412

Cumulative Model Updates: 59,172
Cumulative Timesteps: 986,969,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845,356.24158
Policy Entropy: 1.00914
Value Function Loss: 2.67939

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.16813
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.08316

Collected Steps per Second: 11,200.34516
Overall Steps per Second: 9,695.65935

Timestep Collection Time: 4.46540
Timestep Consumption Time: 0.69299
PPO Batch Consumption Time: 0.03500
Total Iteration Time: 5.15839

Cumulative Model Updates: 59,175
Cumulative Timesteps: 987,019,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 987019944...
Checkpoint 987019944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,917.54671
Policy Entropy: 1.01288
Value Function Loss: 2.81137

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.17213
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.07916

Collected Steps per Second: 12,037.16029
Overall Steps per Second: 10,145.95812

Timestep Collection Time: 4.15596
Timestep Consumption Time: 0.77467
PPO Batch Consumption Time: 0.03629
Total Iteration Time: 4.93063

Cumulative Model Updates: 59,178
Cumulative Timesteps: 987,069,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,424.05482
Policy Entropy: 1.02813
Value Function Loss: 2.84340

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.17700
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.07711

Collected Steps per Second: 11,596.22665
Overall Steps per Second: 9,918.58690

Timestep Collection Time: 4.31226
Timestep Consumption Time: 0.72938
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.04165

Cumulative Model Updates: 59,181
Cumulative Timesteps: 987,119,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987119976...
Checkpoint 987119976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,780.58307
Policy Entropy: 1.02921
Value Function Loss: 2.93472

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.18148
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 12,216.38324
Overall Steps per Second: 10,300.21160

Timestep Collection Time: 4.09516
Timestep Consumption Time: 0.76183
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 4.85699

Cumulative Model Updates: 59,184
Cumulative Timesteps: 987,170,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,955.39761
Policy Entropy: 1.02256
Value Function Loss: 2.87654

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 11,763.22097
Overall Steps per Second: 9,954.47832

Timestep Collection Time: 4.25139
Timestep Consumption Time: 0.77248
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.02387

Cumulative Model Updates: 59,187
Cumulative Timesteps: 987,220,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 987220014...
Checkpoint 987220014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,267.19571
Policy Entropy: 0.99834
Value Function Loss: 2.87542

Mean KL Divergence: 0.04184
SB3 Clip Fraction: 0.22163
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.07858

Collected Steps per Second: 11,878.92476
Overall Steps per Second: 10,182.74488

Timestep Collection Time: 4.20947
Timestep Consumption Time: 0.70119
PPO Batch Consumption Time: 0.03369
Total Iteration Time: 4.91066

Cumulative Model Updates: 59,190
Cumulative Timesteps: 987,270,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678,430.13104
Policy Entropy: 1.03777
Value Function Loss: 2.90998

Mean KL Divergence: 0.04302
SB3 Clip Fraction: 0.23247
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 11,440.75215
Overall Steps per Second: 9,721.71782

Timestep Collection Time: 4.37122
Timestep Consumption Time: 0.77294
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.14415

Cumulative Model Updates: 59,193
Cumulative Timesteps: 987,320,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 987320028...
Checkpoint 987320028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,321.12275
Policy Entropy: 1.00340
Value Function Loss: 2.94562

Mean KL Divergence: 0.05131
SB3 Clip Fraction: 0.25787
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.08917

Collected Steps per Second: 12,059.95683
Overall Steps per Second: 10,249.89479

Timestep Collection Time: 4.14628
Timestep Consumption Time: 0.73221
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 4.87849

Cumulative Model Updates: 59,196
Cumulative Timesteps: 987,370,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,309.87595
Policy Entropy: 1.03254
Value Function Loss: 2.80470

Mean KL Divergence: 0.03714
SB3 Clip Fraction: 0.21795
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.08704

Collected Steps per Second: 12,130.31435
Overall Steps per Second: 10,379.68296

Timestep Collection Time: 4.12207
Timestep Consumption Time: 0.69523
PPO Batch Consumption Time: 0.03820
Total Iteration Time: 4.81730

Cumulative Model Updates: 59,199
Cumulative Timesteps: 987,420,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 987420034...
Checkpoint 987420034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696,547.48103
Policy Entropy: 1.00714
Value Function Loss: 2.70743

Mean KL Divergence: 0.03336
SB3 Clip Fraction: 0.19566
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 12,163.39834
Overall Steps per Second: 10,235.71194

Timestep Collection Time: 4.11250
Timestep Consumption Time: 0.77451
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 4.88701

Cumulative Model Updates: 59,202
Cumulative Timesteps: 987,470,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664,894.47791
Policy Entropy: 1.02132
Value Function Loss: 2.50606

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.18885
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 12,135.94471
Overall Steps per Second: 10,260.70981

Timestep Collection Time: 4.12065
Timestep Consumption Time: 0.75309
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 4.87374

Cumulative Model Updates: 59,205
Cumulative Timesteps: 987,520,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 987520064...
Checkpoint 987520064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,673.20522
Policy Entropy: 1.02613
Value Function Loss: 2.61917

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.19312
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 12,169.91757
Overall Steps per Second: 10,188.92531

Timestep Collection Time: 4.11030
Timestep Consumption Time: 0.79915
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 4.90945

Cumulative Model Updates: 59,208
Cumulative Timesteps: 987,570,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707,027.46239
Policy Entropy: 1.01954
Value Function Loss: 2.79979

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 11,583.21982
Overall Steps per Second: 9,818.93835

Timestep Collection Time: 4.31832
Timestep Consumption Time: 0.77592
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.09424

Cumulative Model Updates: 59,211
Cumulative Timesteps: 987,620,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 987620106...
Checkpoint 987620106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806,014.91258
Policy Entropy: 1.01841
Value Function Loss: 2.95408

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 12,049.42684
Overall Steps per Second: 10,398.88958

Timestep Collection Time: 4.15024
Timestep Consumption Time: 0.65874
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.80897

Cumulative Model Updates: 59,214
Cumulative Timesteps: 987,670,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795,206.57057
Policy Entropy: 1.02972
Value Function Loss: 2.75015

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 12,048.80994
Overall Steps per Second: 10,191.04033

Timestep Collection Time: 4.15029
Timestep Consumption Time: 0.75657
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.90686

Cumulative Model Updates: 59,217
Cumulative Timesteps: 987,720,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987720120...
Checkpoint 987720120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760,367.89313
Policy Entropy: 1.03884
Value Function Loss: 2.62998

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.16764
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 11,964.82945
Overall Steps per Second: 10,126.05431

Timestep Collection Time: 4.17992
Timestep Consumption Time: 0.75903
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 4.93894

Cumulative Model Updates: 59,220
Cumulative Timesteps: 987,770,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,782.68635
Policy Entropy: 1.01528
Value Function Loss: 2.61435

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.09210

Collected Steps per Second: 12,177.89127
Overall Steps per Second: 10,460.90285

Timestep Collection Time: 4.10810
Timestep Consumption Time: 0.67428
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.78238

Cumulative Model Updates: 59,223
Cumulative Timesteps: 987,820,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 987820160...
Checkpoint 987820160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,254.65596
Policy Entropy: 1.02676
Value Function Loss: 2.67255

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 11,926.85372
Overall Steps per Second: 10,151.72369

Timestep Collection Time: 4.19289
Timestep Consumption Time: 0.73317
PPO Batch Consumption Time: 0.03263
Total Iteration Time: 4.92606

Cumulative Model Updates: 59,226
Cumulative Timesteps: 987,870,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,187.16186
Policy Entropy: 1.02465
Value Function Loss: 2.67754

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.10011

Collected Steps per Second: 11,727.01496
Overall Steps per Second: 9,960.27205

Timestep Collection Time: 4.26400
Timestep Consumption Time: 0.75634
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.02034

Cumulative Model Updates: 59,229
Cumulative Timesteps: 987,920,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 987920172...
Checkpoint 987920172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,871.19395
Policy Entropy: 1.04054
Value Function Loss: 2.55025

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.16037
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 12,135.83102
Overall Steps per Second: 10,226.91123

Timestep Collection Time: 4.12003
Timestep Consumption Time: 0.76903
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.88906

Cumulative Model Updates: 59,232
Cumulative Timesteps: 987,970,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,937.18994
Policy Entropy: 1.01468
Value Function Loss: 2.49541

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.17032
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 12,041.19466
Overall Steps per Second: 10,203.95252

Timestep Collection Time: 4.15241
Timestep Consumption Time: 0.74765
PPO Batch Consumption Time: 0.03532
Total Iteration Time: 4.90006

Cumulative Model Updates: 59,235
Cumulative Timesteps: 988,020,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988020172...
Checkpoint 988020172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,380.37207
Policy Entropy: 1.03437
Value Function Loss: 2.54953

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 12,064.90979
Overall Steps per Second: 10,359.25331

Timestep Collection Time: 4.14425
Timestep Consumption Time: 0.68235
PPO Batch Consumption Time: 0.03524
Total Iteration Time: 4.82660

Cumulative Model Updates: 59,238
Cumulative Timesteps: 988,070,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753,685.53166
Policy Entropy: 1.03855
Value Function Loss: 2.58526

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.17899
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.11682

Collected Steps per Second: 12,065.32142
Overall Steps per Second: 10,219.07484

Timestep Collection Time: 4.14510
Timestep Consumption Time: 0.74888
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.89399

Cumulative Model Updates: 59,241
Cumulative Timesteps: 988,120,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 988120184...
Checkpoint 988120184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745,181.28192
Policy Entropy: 1.02649
Value Function Loss: 2.71953

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.11045

Collected Steps per Second: 11,945.46761
Overall Steps per Second: 10,118.14292

Timestep Collection Time: 4.18653
Timestep Consumption Time: 0.75608
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 4.94261

Cumulative Model Updates: 59,244
Cumulative Timesteps: 988,170,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760,378.01643
Policy Entropy: 1.01417
Value Function Loss: 2.67999

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.19709
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.09987

Collected Steps per Second: 11,465.82726
Overall Steps per Second: 9,948.26465

Timestep Collection Time: 4.36166
Timestep Consumption Time: 0.66535
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.02701

Cumulative Model Updates: 59,247
Cumulative Timesteps: 988,220,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 988220204...
Checkpoint 988220204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666,282.09120
Policy Entropy: 1.03423
Value Function Loss: 2.69021

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.18263
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.08711

Collected Steps per Second: 11,951.41945
Overall Steps per Second: 10,054.67281

Timestep Collection Time: 4.18444
Timestep Consumption Time: 0.78937
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 4.97381

Cumulative Model Updates: 59,250
Cumulative Timesteps: 988,270,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,194.80288
Policy Entropy: 1.01758
Value Function Loss: 2.55328

Mean KL Divergence: 0.03260
SB3 Clip Fraction: 0.20487
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 11,750.53315
Overall Steps per Second: 10,024.45377

Timestep Collection Time: 4.25598
Timestep Consumption Time: 0.73282
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 4.98880

Cumulative Model Updates: 59,253
Cumulative Timesteps: 988,320,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 988320224...
Checkpoint 988320224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678,633.09235
Policy Entropy: 1.03515
Value Function Loss: 2.54978

Mean KL Divergence: 0.03126
SB3 Clip Fraction: 0.17567
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.07368

Collected Steps per Second: 12,149.76974
Overall Steps per Second: 10,219.43013

Timestep Collection Time: 4.11761
Timestep Consumption Time: 0.77777
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 4.89538

Cumulative Model Updates: 59,256
Cumulative Timesteps: 988,370,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,911.51479
Policy Entropy: 1.04433
Value Function Loss: 2.47235

Mean KL Divergence: 0.03035
SB3 Clip Fraction: 0.17901
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 11,961.68960
Overall Steps per Second: 10,052.91363

Timestep Collection Time: 4.18269
Timestep Consumption Time: 0.79418
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 4.97687

Cumulative Model Updates: 59,259
Cumulative Timesteps: 988,420,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 988420284...
Checkpoint 988420284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,223.41099
Policy Entropy: 1.02883
Value Function Loss: 2.57918

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.15974
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.05727

Collected Steps per Second: 11,931.66887
Overall Steps per Second: 10,267.67013

Timestep Collection Time: 4.19187
Timestep Consumption Time: 0.67934
PPO Batch Consumption Time: 0.03606
Total Iteration Time: 4.87121

Cumulative Model Updates: 59,262
Cumulative Timesteps: 988,470,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,006.18296
Policy Entropy: 1.02364
Value Function Loss: 2.46464

Mean KL Divergence: 0.03294
SB3 Clip Fraction: 0.20550
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.06245

Collected Steps per Second: 11,554.01662
Overall Steps per Second: 9,853.63800

Timestep Collection Time: 4.32750
Timestep Consumption Time: 0.74677
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.07427

Cumulative Model Updates: 59,265
Cumulative Timesteps: 988,520,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988520300...
Checkpoint 988520300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,479.83261
Policy Entropy: 1.04082
Value Function Loss: 2.60036

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.07994

Collected Steps per Second: 11,964.36980
Overall Steps per Second: 10,179.10831

Timestep Collection Time: 4.18091
Timestep Consumption Time: 0.73327
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 4.91418

Cumulative Model Updates: 59,268
Cumulative Timesteps: 988,570,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,420.65918
Policy Entropy: 1.03530
Value Function Loss: 2.62886

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 12,383.38658
Overall Steps per Second: 10,356.30215

Timestep Collection Time: 4.03767
Timestep Consumption Time: 0.79031
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 4.82798

Cumulative Model Updates: 59,271
Cumulative Timesteps: 988,620,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988620322...
Checkpoint 988620322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,802.40361
Policy Entropy: 1.01706
Value Function Loss: 2.69521

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.09993

Collected Steps per Second: 11,514.85187
Overall Steps per Second: 9,770.46442

Timestep Collection Time: 4.34309
Timestep Consumption Time: 0.77540
PPO Batch Consumption Time: 0.03519
Total Iteration Time: 5.11849

Cumulative Model Updates: 59,274
Cumulative Timesteps: 988,670,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,558.35155
Policy Entropy: 1.03644
Value Function Loss: 2.70727

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.10600

Collected Steps per Second: 11,793.47864
Overall Steps per Second: 10,120.01959

Timestep Collection Time: 4.23963
Timestep Consumption Time: 0.70107
PPO Batch Consumption Time: 0.03418
Total Iteration Time: 4.94070

Cumulative Model Updates: 59,277
Cumulative Timesteps: 988,720,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988720332...
Checkpoint 988720332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,366.85675
Policy Entropy: 1.04419
Value Function Loss: 2.64659

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 11,969.08594
Overall Steps per Second: 10,040.04297

Timestep Collection Time: 4.17977
Timestep Consumption Time: 0.80308
PPO Batch Consumption Time: 0.03421
Total Iteration Time: 4.98285

Cumulative Model Updates: 59,280
Cumulative Timesteps: 988,770,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,002.84914
Policy Entropy: 1.02725
Value Function Loss: 2.60788

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.16559
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.09812

Collected Steps per Second: 11,645.43254
Overall Steps per Second: 9,884.99989

Timestep Collection Time: 4.29353
Timestep Consumption Time: 0.76464
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.05817

Cumulative Model Updates: 59,283
Cumulative Timesteps: 988,820,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988820360...
Checkpoint 988820360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,850.95035
Policy Entropy: 1.02349
Value Function Loss: 2.57041

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 11,880.34873
Overall Steps per Second: 10,040.99289

Timestep Collection Time: 4.21099
Timestep Consumption Time: 0.77139
PPO Batch Consumption Time: 0.03339
Total Iteration Time: 4.98238

Cumulative Model Updates: 59,286
Cumulative Timesteps: 988,870,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,051.99375
Policy Entropy: 1.02970
Value Function Loss: 2.53844

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 12,602.66785
Overall Steps per Second: 10,566.09650

Timestep Collection Time: 3.96884
Timestep Consumption Time: 0.76498
PPO Batch Consumption Time: 0.03309
Total Iteration Time: 4.73382

Cumulative Model Updates: 59,289
Cumulative Timesteps: 988,920,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 988920406...
Checkpoint 988920406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759,501.40189
Policy Entropy: 1.03034
Value Function Loss: 2.56906

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.09510

Collected Steps per Second: 12,796.06537
Overall Steps per Second: 10,918.65733

Timestep Collection Time: 3.90933
Timestep Consumption Time: 0.67219
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.58152

Cumulative Model Updates: 59,292
Cumulative Timesteps: 988,970,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,956.13721
Policy Entropy: 1.01625
Value Function Loss: 2.51560

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 12,835.89813
Overall Steps per Second: 10,636.47044

Timestep Collection Time: 3.89533
Timestep Consumption Time: 0.80548
PPO Batch Consumption Time: 0.03344
Total Iteration Time: 4.70081

Cumulative Model Updates: 59,295
Cumulative Timesteps: 989,020,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 989020430...
Checkpoint 989020430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781,997.21399
Policy Entropy: 1.02846
Value Function Loss: 2.46301

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.15968
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.07896

Collected Steps per Second: 12,293.15283
Overall Steps per Second: 10,325.83470

Timestep Collection Time: 4.06812
Timestep Consumption Time: 0.77507
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.84319

Cumulative Model Updates: 59,298
Cumulative Timesteps: 989,070,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,403.91061
Policy Entropy: 1.03181
Value Function Loss: 2.54773

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 12,878.96428
Overall Steps per Second: 10,550.50714

Timestep Collection Time: 3.88354
Timestep Consumption Time: 0.85708
PPO Batch Consumption Time: 0.03400
Total Iteration Time: 4.74063

Cumulative Model Updates: 59,301
Cumulative Timesteps: 989,120,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989120456...
Checkpoint 989120456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612,494.67845
Policy Entropy: 1.03263
Value Function Loss: 2.54586

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 12,514.87365
Overall Steps per Second: 10,417.87661

Timestep Collection Time: 3.99541
Timestep Consumption Time: 0.80423
PPO Batch Consumption Time: 0.03449
Total Iteration Time: 4.79963

Cumulative Model Updates: 59,304
Cumulative Timesteps: 989,170,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735,017.81086
Policy Entropy: 1.03589
Value Function Loss: 2.58079

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.09095

Collected Steps per Second: 12,354.14003
Overall Steps per Second: 10,555.68466

Timestep Collection Time: 4.04820
Timestep Consumption Time: 0.68972
PPO Batch Consumption Time: 0.03497
Total Iteration Time: 4.73792

Cumulative Model Updates: 59,307
Cumulative Timesteps: 989,220,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 989220470...
Checkpoint 989220470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,044.45782
Policy Entropy: 1.03284
Value Function Loss: 2.41666

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 11,811.43744
Overall Steps per Second: 9,952.53608

Timestep Collection Time: 4.23369
Timestep Consumption Time: 0.79075
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 5.02445

Cumulative Model Updates: 59,310
Cumulative Timesteps: 989,270,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,128.69873
Policy Entropy: 1.03579
Value Function Loss: 2.37544

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 11,934.25252
Overall Steps per Second: 9,999.06679

Timestep Collection Time: 4.19096
Timestep Consumption Time: 0.81110
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 5.00207

Cumulative Model Updates: 59,313
Cumulative Timesteps: 989,320,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989320492...
Checkpoint 989320492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,838.80881
Policy Entropy: 1.05035
Value Function Loss: 2.38748

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 11,918.45824
Overall Steps per Second: 10,217.55689

Timestep Collection Time: 4.19551
Timestep Consumption Time: 0.69842
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 4.89393

Cumulative Model Updates: 59,316
Cumulative Timesteps: 989,370,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654,638.36348
Policy Entropy: 1.05693
Value Function Loss: 2.54321

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 11,923.67295
Overall Steps per Second: 9,912.98119

Timestep Collection Time: 4.19502
Timestep Consumption Time: 0.85089
PPO Batch Consumption Time: 0.03649
Total Iteration Time: 5.04591

Cumulative Model Updates: 59,319
Cumulative Timesteps: 989,420,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 989420516...
Checkpoint 989420516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729,136.65077
Policy Entropy: 1.06375
Value Function Loss: 2.74442

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 11,804.80903
Overall Steps per Second: 9,882.21413

Timestep Collection Time: 4.23743
Timestep Consumption Time: 0.82440
PPO Batch Consumption Time: 0.03692
Total Iteration Time: 5.06182

Cumulative Model Updates: 59,322
Cumulative Timesteps: 989,470,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,856.80631
Policy Entropy: 1.05207
Value Function Loss: 2.82900

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.07908
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 12,255.42872
Overall Steps per Second: 10,344.92110

Timestep Collection Time: 4.08064
Timestep Consumption Time: 0.75362
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.83426

Cumulative Model Updates: 59,325
Cumulative Timesteps: 989,520,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 989520548...
Checkpoint 989520548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,698.30290
Policy Entropy: 1.04176
Value Function Loss: 2.80562

Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.09811

Collected Steps per Second: 11,901.18689
Overall Steps per Second: 10,035.56098

Timestep Collection Time: 4.20345
Timestep Consumption Time: 0.78143
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.98487

Cumulative Model Updates: 59,328
Cumulative Timesteps: 989,570,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763,229.21443
Policy Entropy: 1.05053
Value Function Loss: 2.66239

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.09707

Collected Steps per Second: 12,009.78286
Overall Steps per Second: 10,322.82387

Timestep Collection Time: 4.16594
Timestep Consumption Time: 0.68080
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 4.84674

Cumulative Model Updates: 59,331
Cumulative Timesteps: 989,620,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 989620606...
Checkpoint 989620606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,464.92889
Policy Entropy: 1.06738
Value Function Loss: 2.61692

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.06939
Value Function Update Magnitude: 0.09444

Collected Steps per Second: 11,826.09533
Overall Steps per Second: 9,988.58989

Timestep Collection Time: 4.22811
Timestep Consumption Time: 0.77780
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.00591

Cumulative Model Updates: 59,334
Cumulative Timesteps: 989,670,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,093.22370
Policy Entropy: 1.05466
Value Function Loss: 2.57192

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 11,876.27306
Overall Steps per Second: 9,929.55448

Timestep Collection Time: 4.21142
Timestep Consumption Time: 0.82566
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.03708

Cumulative Model Updates: 59,337
Cumulative Timesteps: 989,720,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 989720624...
Checkpoint 989720624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655,696.75225
Policy Entropy: 1.04827
Value Function Loss: 2.60901

Mean KL Divergence: 0.03134
SB3 Clip Fraction: 0.18997
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 11,690.86263
Overall Steps per Second: 9,978.92852

Timestep Collection Time: 4.27924
Timestep Consumption Time: 0.73412
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.01336

Cumulative Model Updates: 59,340
Cumulative Timesteps: 989,770,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,622.11952
Policy Entropy: 1.05178
Value Function Loss: 2.54898

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.13991

Collected Steps per Second: 12,067.46758
Overall Steps per Second: 10,117.83762

Timestep Collection Time: 4.14387
Timestep Consumption Time: 0.79849
PPO Batch Consumption Time: 0.03868
Total Iteration Time: 4.94236

Cumulative Model Updates: 59,343
Cumulative Timesteps: 989,820,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 989820658...
Checkpoint 989820658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,543.35702
Policy Entropy: 1.05677
Value Function Loss: 2.55064

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 11,853.61819
Overall Steps per Second: 10,030.45935

Timestep Collection Time: 4.21981
Timestep Consumption Time: 0.76700
PPO Batch Consumption Time: 0.03464
Total Iteration Time: 4.98681

Cumulative Model Updates: 59,346
Cumulative Timesteps: 989,870,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686,102.98638
Policy Entropy: 1.04072
Value Function Loss: 2.53023

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.06417
Value Function Update Magnitude: 0.10345

Collected Steps per Second: 12,214.59702
Overall Steps per Second: 10,221.66089

Timestep Collection Time: 4.09592
Timestep Consumption Time: 0.79859
PPO Batch Consumption Time: 0.03739
Total Iteration Time: 4.89451

Cumulative Model Updates: 59,349
Cumulative Timesteps: 989,920,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 989920708...
Checkpoint 989920708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,272.83646
Policy Entropy: 1.03452
Value Function Loss: 2.54450

Mean KL Divergence: 0.03367
SB3 Clip Fraction: 0.21063
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.09770

Collected Steps per Second: 11,782.26434
Overall Steps per Second: 9,981.42839

Timestep Collection Time: 4.24418
Timestep Consumption Time: 0.76573
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 5.00990

Cumulative Model Updates: 59,352
Cumulative Timesteps: 989,970,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,662.97337
Policy Entropy: 1.04156
Value Function Loss: 2.61090

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.10577

Collected Steps per Second: 12,037.80009
Overall Steps per Second: 10,309.40879

Timestep Collection Time: 4.15607
Timestep Consumption Time: 0.69677
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 4.85285

Cumulative Model Updates: 59,355
Cumulative Timesteps: 990,020,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 990020744...
Checkpoint 990020744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780,539.68981
Policy Entropy: 1.04467
Value Function Loss: 2.67058

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.09764

Collected Steps per Second: 11,854.39515
Overall Steps per Second: 9,990.71181

Timestep Collection Time: 4.21919
Timestep Consumption Time: 0.78706
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.00625

Cumulative Model Updates: 59,358
Cumulative Timesteps: 990,070,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,479.25303
Policy Entropy: 1.03052
Value Function Loss: 2.61090

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.09937

Collected Steps per Second: 12,072.12923
Overall Steps per Second: 10,217.79829

Timestep Collection Time: 4.14310
Timestep Consumption Time: 0.75189
PPO Batch Consumption Time: 0.03650
Total Iteration Time: 4.89499

Cumulative Model Updates: 59,361
Cumulative Timesteps: 990,120,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 990120776...
Checkpoint 990120776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,787.34169
Policy Entropy: 1.02789
Value Function Loss: 2.46590

Mean KL Divergence: 0.02731
SB3 Clip Fraction: 0.18354
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.09134

Collected Steps per Second: 12,104.45523
Overall Steps per Second: 10,251.42346

Timestep Collection Time: 4.13203
Timestep Consumption Time: 0.74690
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 4.87893

Cumulative Model Updates: 59,364
Cumulative Timesteps: 990,170,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797,663.16589
Policy Entropy: 1.04667
Value Function Loss: 2.33022

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.09247

Collected Steps per Second: 12,077.48722
Overall Steps per Second: 10,256.43298

Timestep Collection Time: 4.14010
Timestep Consumption Time: 0.73508
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 4.87518

Cumulative Model Updates: 59,367
Cumulative Timesteps: 990,220,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 990220794...
Checkpoint 990220794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,632.71757
Policy Entropy: 1.04896
Value Function Loss: 2.37666

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.09929

Collected Steps per Second: 12,103.75336
Overall Steps per Second: 10,413.18223

Timestep Collection Time: 4.13310
Timestep Consumption Time: 0.67100
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.80410

Cumulative Model Updates: 59,370
Cumulative Timesteps: 990,270,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711,987.79526
Policy Entropy: 1.03756
Value Function Loss: 2.63247

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 12,312.55945
Overall Steps per Second: 10,266.94972

Timestep Collection Time: 4.06317
Timestep Consumption Time: 0.80955
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 4.87272

Cumulative Model Updates: 59,373
Cumulative Timesteps: 990,320,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 990320848...
Checkpoint 990320848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792,728.23860
Policy Entropy: 1.02720
Value Function Loss: 2.71488

Mean KL Divergence: 0.03480
SB3 Clip Fraction: 0.20903
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.09438

Collected Steps per Second: 11,368.43423
Overall Steps per Second: 9,714.65220

Timestep Collection Time: 4.39849
Timestep Consumption Time: 0.74878
PPO Batch Consumption Time: 0.03351
Total Iteration Time: 5.14728

Cumulative Model Updates: 59,376
Cumulative Timesteps: 990,370,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802,469.26993
Policy Entropy: 1.04083
Value Function Loss: 2.74888

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 12,467.27409
Overall Steps per Second: 10,446.78426

Timestep Collection Time: 4.01146
Timestep Consumption Time: 0.77585
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 4.78731

Cumulative Model Updates: 59,379
Cumulative Timesteps: 990,420,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 990420864...
Checkpoint 990420864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,810.76042
Policy Entropy: 1.04983
Value Function Loss: 2.60207

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 12,008.39579
Overall Steps per Second: 10,082.29837

Timestep Collection Time: 4.16375
Timestep Consumption Time: 0.79543
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 4.95919

Cumulative Model Updates: 59,382
Cumulative Timesteps: 990,470,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,681.68120
Policy Entropy: 1.03530
Value Function Loss: 2.63406

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.06922
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 11,932.36387
Overall Steps per Second: 10,204.65134

Timestep Collection Time: 4.19246
Timestep Consumption Time: 0.70981
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.90227

Cumulative Model Updates: 59,385
Cumulative Timesteps: 990,520,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 990520890...
Checkpoint 990520890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,057.61722
Policy Entropy: 1.03025
Value Function Loss: 2.67139

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.08628

Collected Steps per Second: 12,074.43309
Overall Steps per Second: 10,076.14976

Timestep Collection Time: 4.14197
Timestep Consumption Time: 0.82143
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.96340

Cumulative Model Updates: 59,388
Cumulative Timesteps: 990,570,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719,979.22054
Policy Entropy: 1.04377
Value Function Loss: 2.61135

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.08776

Collected Steps per Second: 11,913.37031
Overall Steps per Second: 10,047.64808

Timestep Collection Time: 4.19814
Timestep Consumption Time: 0.77954
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.97768

Cumulative Model Updates: 59,391
Cumulative Timesteps: 990,620,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990620916...
Checkpoint 990620916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790,741.51290
Policy Entropy: 1.05114
Value Function Loss: 2.51115

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.08665

Collected Steps per Second: 11,357.30976
Overall Steps per Second: 9,796.37307

Timestep Collection Time: 4.40474
Timestep Consumption Time: 0.70184
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.10658

Cumulative Model Updates: 59,394
Cumulative Timesteps: 990,670,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,897.47985
Policy Entropy: 1.03463
Value Function Loss: 2.42640

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 12,062.45471
Overall Steps per Second: 10,149.91193

Timestep Collection Time: 4.14576
Timestep Consumption Time: 0.78118
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 4.92694

Cumulative Model Updates: 59,397
Cumulative Timesteps: 990,720,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 990720950...
Checkpoint 990720950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711,478.65746
Policy Entropy: 1.02375
Value Function Loss: 2.40081

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.18551
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 11,843.64718
Overall Steps per Second: 9,988.95558

Timestep Collection Time: 4.22235
Timestep Consumption Time: 0.78398
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.00633

Cumulative Model Updates: 59,400
Cumulative Timesteps: 990,770,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645,816.69671
Policy Entropy: 1.03506
Value Function Loss: 2.46389

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 12,229.87740
Overall Steps per Second: 10,305.43159

Timestep Collection Time: 4.09064
Timestep Consumption Time: 0.76389
PPO Batch Consumption Time: 0.03565
Total Iteration Time: 4.85453

Cumulative Model Updates: 59,403
Cumulative Timesteps: 990,820,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 990820986...
Checkpoint 990820986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715,505.91915
Policy Entropy: 1.04226
Value Function Loss: 2.40337

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.06383

Collected Steps per Second: 11,821.15755
Overall Steps per Second: 9,973.52600

Timestep Collection Time: 4.23004
Timestep Consumption Time: 0.78363
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 5.01367

Cumulative Model Updates: 59,406
Cumulative Timesteps: 990,870,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,274.80259
Policy Entropy: 1.02570
Value Function Loss: 2.55555

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.06550

Collected Steps per Second: 12,028.54446
Overall Steps per Second: 10,362.02437

Timestep Collection Time: 4.15744
Timestep Consumption Time: 0.66864
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.82608

Cumulative Model Updates: 59,409
Cumulative Timesteps: 990,920,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 990920998...
Checkpoint 990920998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,430.73693
Policy Entropy: 1.02629
Value Function Loss: 2.50862

Mean KL Divergence: 0.02834
SB3 Clip Fraction: 0.18795
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 11,414.06908
Overall Steps per Second: 9,632.20617

Timestep Collection Time: 4.38108
Timestep Consumption Time: 0.81046
PPO Batch Consumption Time: 0.03667
Total Iteration Time: 5.19154

Cumulative Model Updates: 59,412
Cumulative Timesteps: 990,971,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,514.04487
Policy Entropy: 1.03697
Value Function Loss: 2.65002

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05758

Collected Steps per Second: 12,044.87596
Overall Steps per Second: 10,185.06486

Timestep Collection Time: 4.15264
Timestep Consumption Time: 0.75828
PPO Batch Consumption Time: 0.03944
Total Iteration Time: 4.91092

Cumulative Model Updates: 59,415
Cumulative Timesteps: 991,021,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991021022...
Checkpoint 991021022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751,620.30497
Policy Entropy: 1.04023
Value Function Loss: 2.68859

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 12,335.23258
Overall Steps per Second: 10,290.46008

Timestep Collection Time: 4.05538
Timestep Consumption Time: 0.80583
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.86120

Cumulative Model Updates: 59,418
Cumulative Timesteps: 991,071,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618,420.06599
Policy Entropy: 1.01577
Value Function Loss: 2.82077

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 11,896.12842
Overall Steps per Second: 10,047.82894

Timestep Collection Time: 4.20456
Timestep Consumption Time: 0.77343
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.97799

Cumulative Model Updates: 59,421
Cumulative Timesteps: 991,121,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991121064...
Checkpoint 991121064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712,264.74515
Policy Entropy: 1.01620
Value Function Loss: 2.84447

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 12,074.63970
Overall Steps per Second: 10,370.10962

Timestep Collection Time: 4.14224
Timestep Consumption Time: 0.68086
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 4.82309

Cumulative Model Updates: 59,424
Cumulative Timesteps: 991,171,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,616.64900
Policy Entropy: 1.02710
Value Function Loss: 2.77193

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 12,007.06285
Overall Steps per Second: 10,086.29489

Timestep Collection Time: 4.16438
Timestep Consumption Time: 0.79304
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.95742

Cumulative Model Updates: 59,427
Cumulative Timesteps: 991,221,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 991221082...
Checkpoint 991221082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,988.68611
Policy Entropy: 1.03575
Value Function Loss: 2.52107

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16315
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 11,311.90971
Overall Steps per Second: 9,567.78119

Timestep Collection Time: 4.42206
Timestep Consumption Time: 0.80611
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.22817

Cumulative Model Updates: 59,430
Cumulative Timesteps: 991,271,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751,030.75026
Policy Entropy: 1.01650
Value Function Loss: 2.44441

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.09737

Collected Steps per Second: 12,452.10136
Overall Steps per Second: 10,195.73279

Timestep Collection Time: 4.01619
Timestep Consumption Time: 0.88880
PPO Batch Consumption Time: 0.03488
Total Iteration Time: 4.90499

Cumulative Model Updates: 59,433
Cumulative Timesteps: 991,321,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 991321114...
Checkpoint 991321114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836,920.74955
Policy Entropy: 1.04493
Value Function Loss: 2.48057

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.17994
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 12,628.15444
Overall Steps per Second: 10,537.64484

Timestep Collection Time: 3.96178
Timestep Consumption Time: 0.78596
PPO Batch Consumption Time: 0.03347
Total Iteration Time: 4.74774

Cumulative Model Updates: 59,436
Cumulative Timesteps: 991,371,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,326.89945
Policy Entropy: 1.03769
Value Function Loss: 2.62164

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.16189
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.08256

Collected Steps per Second: 12,699.36528
Overall Steps per Second: 10,787.34527

Timestep Collection Time: 3.93783
Timestep Consumption Time: 0.69797
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 4.63580

Cumulative Model Updates: 59,439
Cumulative Timesteps: 991,421,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 991421152...
Checkpoint 991421152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752,222.95023
Policy Entropy: 1.02353
Value Function Loss: 2.60594

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.07540

Collected Steps per Second: 12,660.09579
Overall Steps per Second: 10,574.59612

Timestep Collection Time: 3.95005
Timestep Consumption Time: 0.77902
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.72907

Cumulative Model Updates: 59,442
Cumulative Timesteps: 991,471,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802,968.16072
Policy Entropy: 1.00533
Value Function Loss: 2.53361

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 12,722.30000
Overall Steps per Second: 10,649.77513

Timestep Collection Time: 3.93089
Timestep Consumption Time: 0.76498
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 4.69587

Cumulative Model Updates: 59,445
Cumulative Timesteps: 991,521,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 991521170...
Checkpoint 991521170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,652.39556
Policy Entropy: 1.02643
Value Function Loss: 2.63657

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16100
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 11,825.89597
Overall Steps per Second: 10,119.51236

Timestep Collection Time: 4.23004
Timestep Consumption Time: 0.71328
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.94332

Cumulative Model Updates: 59,448
Cumulative Timesteps: 991,571,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,362.59225
Policy Entropy: 1.03254
Value Function Loss: 2.63310

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.06005

Collected Steps per Second: 12,612.28902
Overall Steps per Second: 10,524.55017

Timestep Collection Time: 3.96455
Timestep Consumption Time: 0.78644
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 4.75099

Cumulative Model Updates: 59,451
Cumulative Timesteps: 991,621,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 991621196...
Checkpoint 991621196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801,609.24442
Policy Entropy: 1.02297
Value Function Loss: 2.61542

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 11,924.83463
Overall Steps per Second: 10,051.24859

Timestep Collection Time: 4.19427
Timestep Consumption Time: 0.78183
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 4.97610

Cumulative Model Updates: 59,454
Cumulative Timesteps: 991,671,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,096.25005
Policy Entropy: 1.02437
Value Function Loss: 2.51470

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.18343
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 11,879.13998
Overall Steps per Second: 10,041.30195

Timestep Collection Time: 4.20956
Timestep Consumption Time: 0.77047
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.98003

Cumulative Model Updates: 59,457
Cumulative Timesteps: 991,721,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 991721218...
Checkpoint 991721218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,941.85372
Policy Entropy: 1.03199
Value Function Loss: 2.58423

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.08744

Collected Steps per Second: 12,012.79405
Overall Steps per Second: 10,092.75969

Timestep Collection Time: 4.16406
Timestep Consumption Time: 0.79217
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 4.95623

Cumulative Model Updates: 59,460
Cumulative Timesteps: 991,771,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775,710.34008
Policy Entropy: 1.04050
Value Function Loss: 2.66981

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.15813
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 11,643.39145
Overall Steps per Second: 10,015.91557

Timestep Collection Time: 4.29583
Timestep Consumption Time: 0.69802
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 4.99385

Cumulative Model Updates: 59,463
Cumulative Timesteps: 991,821,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991821258...
Checkpoint 991821258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808,079.63028
Policy Entropy: 1.01303
Value Function Loss: 2.55578

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 11,346.52344
Overall Steps per Second: 9,604.58188

Timestep Collection Time: 4.40928
Timestep Consumption Time: 0.79969
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.20897

Cumulative Model Updates: 59,466
Cumulative Timesteps: 991,871,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669,501.45821
Policy Entropy: 1.03308
Value Function Loss: 2.51388

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.11279

Collected Steps per Second: 11,941.37437
Overall Steps per Second: 10,083.32316

Timestep Collection Time: 4.18964
Timestep Consumption Time: 0.77202
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.96166

Cumulative Model Updates: 59,469
Cumulative Timesteps: 991,921,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 991921318...
Checkpoint 991921318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,146.14582
Policy Entropy: 1.02859
Value Function Loss: 2.49236

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.15454
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.10328

Collected Steps per Second: 12,053.69623
Overall Steps per Second: 10,114.28045

Timestep Collection Time: 4.14811
Timestep Consumption Time: 0.79540
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 4.94351

Cumulative Model Updates: 59,472
Cumulative Timesteps: 991,971,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778,435.97201
Policy Entropy: 1.01484
Value Function Loss: 2.49787

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.10883

Collected Steps per Second: 11,810.32520
Overall Steps per Second: 9,989.48971

Timestep Collection Time: 4.23562
Timestep Consumption Time: 0.77205
PPO Batch Consumption Time: 0.03433
Total Iteration Time: 5.00766

Cumulative Model Updates: 59,475
Cumulative Timesteps: 992,021,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 992021342...
Checkpoint 992021342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,365.42097
Policy Entropy: 1.00393
Value Function Loss: 2.43103

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.19885
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.10231

Collected Steps per Second: 11,691.43848
Overall Steps per Second: 10,034.69617

Timestep Collection Time: 4.27869
Timestep Consumption Time: 0.70642
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 4.98510

Cumulative Model Updates: 59,478
Cumulative Timesteps: 992,071,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,959.22038
Policy Entropy: 1.02053
Value Function Loss: 2.32357

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 11,821.02981
Overall Steps per Second: 10,045.97350

Timestep Collection Time: 4.23026
Timestep Consumption Time: 0.74746
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 4.97772

Cumulative Model Updates: 59,481
Cumulative Timesteps: 992,121,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 992121372...
Checkpoint 992121372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,491.11709
Policy Entropy: 1.03341
Value Function Loss: 2.37920

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.06931
Value Function Update Magnitude: 0.09478

Collected Steps per Second: 11,459.93216
Overall Steps per Second: 9,762.97190

Timestep Collection Time: 4.36407
Timestep Consumption Time: 0.75855
PPO Batch Consumption Time: 0.03595
Total Iteration Time: 5.12262

Cumulative Model Updates: 59,484
Cumulative Timesteps: 992,171,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808,896.01060
Policy Entropy: 1.01674
Value Function Loss: 2.45487

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.09283

Collected Steps per Second: 11,921.41805
Overall Steps per Second: 10,300.73938

Timestep Collection Time: 4.19665
Timestep Consumption Time: 0.66028
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 4.85693

Cumulative Model Updates: 59,487
Cumulative Timesteps: 992,221,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 992221414...
Checkpoint 992221414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621,683.33489
Policy Entropy: 1.01143
Value Function Loss: 2.62359

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.17712
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 11,877.08633
Overall Steps per Second: 10,002.32372

Timestep Collection Time: 4.21164
Timestep Consumption Time: 0.78940
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.00104

Cumulative Model Updates: 59,490
Cumulative Timesteps: 992,271,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803,134.88558
Policy Entropy: 1.02777
Value Function Loss: 2.59272

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.10649

Collected Steps per Second: 11,677.93178
Overall Steps per Second: 9,884.92222

Timestep Collection Time: 4.28192
Timestep Consumption Time: 0.77669
PPO Batch Consumption Time: 0.03541
Total Iteration Time: 5.05861

Cumulative Model Updates: 59,493
Cumulative Timesteps: 992,321,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992321440...
Checkpoint 992321440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685,304.31517
Policy Entropy: 1.03108
Value Function Loss: 2.59782

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 11,935.02023
Overall Steps per Second: 10,129.50828

Timestep Collection Time: 4.18952
Timestep Consumption Time: 0.74675
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.93627

Cumulative Model Updates: 59,496
Cumulative Timesteps: 992,371,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,284.15375
Policy Entropy: 1.01642
Value Function Loss: 2.48928

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.09774

Collected Steps per Second: 12,084.93148
Overall Steps per Second: 10,124.43520

Timestep Collection Time: 4.13821
Timestep Consumption Time: 0.80132
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 4.93953

Cumulative Model Updates: 59,499
Cumulative Timesteps: 992,421,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 992421452...
Checkpoint 992421452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,429.73582
Policy Entropy: 1.00460
Value Function Loss: 2.56715

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.09147

Collected Steps per Second: 11,582.59357
Overall Steps per Second: 9,954.13548

Timestep Collection Time: 4.31907
Timestep Consumption Time: 0.70658
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.02565

Cumulative Model Updates: 59,502
Cumulative Timesteps: 992,471,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675,111.28264
Policy Entropy: 1.01702
Value Function Loss: 2.67635

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.09263

Collected Steps per Second: 12,091.75689
Overall Steps per Second: 10,130.33507

Timestep Collection Time: 4.13505
Timestep Consumption Time: 0.80062
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.93567

Cumulative Model Updates: 59,505
Cumulative Timesteps: 992,521,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 992521478...
Checkpoint 992521478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724,654.09316
Policy Entropy: 1.02831
Value Function Loss: 2.59257

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 11,922.07169
Overall Steps per Second: 10,082.04098

Timestep Collection Time: 4.19457
Timestep Consumption Time: 0.76553
PPO Batch Consumption Time: 0.03523
Total Iteration Time: 4.96011

Cumulative Model Updates: 59,508
Cumulative Timesteps: 992,571,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671,619.43188
Policy Entropy: 1.00634
Value Function Loss: 2.58444

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.08175

Collected Steps per Second: 12,112.72475
Overall Steps per Second: 10,172.61542

Timestep Collection Time: 4.13020
Timestep Consumption Time: 0.78771
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.91791

Cumulative Model Updates: 59,511
Cumulative Timesteps: 992,621,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 992621514...
Checkpoint 992621514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755,006.59732
Policy Entropy: 1.02667
Value Function Loss: 2.51369

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.17662
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.07445

Collected Steps per Second: 11,768.30488
Overall Steps per Second: 9,947.95574

Timestep Collection Time: 4.24955
Timestep Consumption Time: 0.77761
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 5.02716

Cumulative Model Updates: 59,514
Cumulative Timesteps: 992,671,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,125.82675
Policy Entropy: 1.01596
Value Function Loss: 2.61670

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.07627

Collected Steps per Second: 12,194.94440
Overall Steps per Second: 10,412.68668

Timestep Collection Time: 4.10055
Timestep Consumption Time: 0.70186
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 4.80241

Cumulative Model Updates: 59,517
Cumulative Timesteps: 992,721,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 992721530...
Checkpoint 992721530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745,615.69159
Policy Entropy: 1.00331
Value Function Loss: 2.52567

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.09362

Collected Steps per Second: 11,336.79594
Overall Steps per Second: 9,668.97423

Timestep Collection Time: 4.41130
Timestep Consumption Time: 0.76091
PPO Batch Consumption Time: 0.03392
Total Iteration Time: 5.17221

Cumulative Model Updates: 59,520
Cumulative Timesteps: 992,771,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,572.40879
Policy Entropy: 0.99844
Value Function Loss: 2.54011

Mean KL Divergence: 0.02750
SB3 Clip Fraction: 0.20745
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.10437

Collected Steps per Second: 11,963.90014
Overall Steps per Second: 10,099.32457

Timestep Collection Time: 4.17957
Timestep Consumption Time: 0.77165
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 4.95122

Cumulative Model Updates: 59,523
Cumulative Timesteps: 992,821,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992821544...
Checkpoint 992821544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,408.49550
Policy Entropy: 1.01183
Value Function Loss: 2.53640

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.10049

Collected Steps per Second: 12,027.33954
Overall Steps per Second: 10,378.29323

Timestep Collection Time: 4.15786
Timestep Consumption Time: 0.66066
PPO Batch Consumption Time: 0.03281
Total Iteration Time: 4.81852

Cumulative Model Updates: 59,526
Cumulative Timesteps: 992,871,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,369.71577
Policy Entropy: 1.01760
Value Function Loss: 2.74493

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 12,193.21402
Overall Steps per Second: 10,281.45768

Timestep Collection Time: 4.10163
Timestep Consumption Time: 0.76267
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.86429

Cumulative Model Updates: 59,529
Cumulative Timesteps: 992,921,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 992921564...
Checkpoint 992921564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 791,237.39880
Policy Entropy: 1.02107
Value Function Loss: 2.60980

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.09955

Collected Steps per Second: 12,055.06482
Overall Steps per Second: 10,216.59154

Timestep Collection Time: 4.14846
Timestep Consumption Time: 0.74652
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 4.89498

Cumulative Model Updates: 59,532
Cumulative Timesteps: 992,971,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,345.82352
Policy Entropy: 1.02287
Value Function Loss: 2.58281

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.07922
Value Function Update Magnitude: 0.10310

Collected Steps per Second: 12,194.12457
Overall Steps per Second: 10,229.78874

Timestep Collection Time: 4.10099
Timestep Consumption Time: 0.78748
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.88847

Cumulative Model Updates: 59,535
Cumulative Timesteps: 993,021,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993021582...
Checkpoint 993021582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720,935.71946
Policy Entropy: 1.02079
Value Function Loss: 2.38229

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.07460
Value Function Update Magnitude: 0.09623

Collected Steps per Second: 11,417.95030
Overall Steps per Second: 9,634.94320

Timestep Collection Time: 4.38135
Timestep Consumption Time: 0.81080
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.19214

Cumulative Model Updates: 59,538
Cumulative Timesteps: 993,071,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756,329.85503
Policy Entropy: 1.01735
Value Function Loss: 2.43349

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.17626
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.09755

Collected Steps per Second: 12,175.38011
Overall Steps per Second: 10,290.53698

Timestep Collection Time: 4.10747
Timestep Consumption Time: 0.75234
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 4.85980

Cumulative Model Updates: 59,541
Cumulative Timesteps: 993,121,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 993121618...
Checkpoint 993121618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686,920.66961
Policy Entropy: 1.03033
Value Function Loss: 2.49227

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 12,239.10254
Overall Steps per Second: 10,321.52076

Timestep Collection Time: 4.08739
Timestep Consumption Time: 0.75938
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.84677

Cumulative Model Updates: 59,544
Cumulative Timesteps: 993,171,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760,938.26809
Policy Entropy: 1.03024
Value Function Loss: 2.50375

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.09198

Collected Steps per Second: 11,746.29128
Overall Steps per Second: 10,006.76512

Timestep Collection Time: 4.25922
Timestep Consumption Time: 0.74040
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 4.99962

Cumulative Model Updates: 59,547
Cumulative Timesteps: 993,221,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 993221674...
Checkpoint 993221674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,286.78120
Policy Entropy: 1.02257
Value Function Loss: 2.63441

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.06867
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 11,992.88203
Overall Steps per Second: 10,314.29469

Timestep Collection Time: 4.17181
Timestep Consumption Time: 0.67894
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 4.85074

Cumulative Model Updates: 59,550
Cumulative Timesteps: 993,271,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,302.92655
Policy Entropy: 1.02073
Value Function Loss: 2.74185

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.06726
Value Function Update Magnitude: 0.08703

Collected Steps per Second: 11,926.35907
Overall Steps per Second: 10,040.56442

Timestep Collection Time: 4.19307
Timestep Consumption Time: 0.78753
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.98060

Cumulative Model Updates: 59,553
Cumulative Timesteps: 993,321,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993321714...
Checkpoint 993321714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,199.82145
Policy Entropy: 1.02268
Value Function Loss: 2.83171

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.10528

Collected Steps per Second: 11,542.17438
Overall Steps per Second: 9,830.46101

Timestep Collection Time: 4.33350
Timestep Consumption Time: 0.75456
PPO Batch Consumption Time: 0.03641
Total Iteration Time: 5.08806

Cumulative Model Updates: 59,556
Cumulative Timesteps: 993,371,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617,136.31412
Policy Entropy: 1.03754
Value Function Loss: 2.73941

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 12,011.87150
Overall Steps per Second: 10,347.37385

Timestep Collection Time: 4.16321
Timestep Consumption Time: 0.66970
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 4.83292

Cumulative Model Updates: 59,559
Cumulative Timesteps: 993,421,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993421740...
Checkpoint 993421740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636,768.33748
Policy Entropy: 1.03776
Value Function Loss: 2.68140

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.09213

Collected Steps per Second: 12,194.27910
Overall Steps per Second: 10,233.08856

Timestep Collection Time: 4.10192
Timestep Consumption Time: 0.78614
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.88806

Cumulative Model Updates: 59,562
Cumulative Timesteps: 993,471,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696,491.16853
Policy Entropy: 1.02575
Value Function Loss: 2.72296

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 12,009.94266
Overall Steps per Second: 10,152.38709

Timestep Collection Time: 4.16488
Timestep Consumption Time: 0.76204
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 4.92692

Cumulative Model Updates: 59,565
Cumulative Timesteps: 993,521,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 993521780...
Checkpoint 993521780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812,975.34052
Policy Entropy: 1.01493
Value Function Loss: 2.73116

Mean KL Divergence: 0.03417
SB3 Clip Fraction: 0.20313
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.09281

Collected Steps per Second: 12,353.49221
Overall Steps per Second: 10,348.47710

Timestep Collection Time: 4.04744
Timestep Consumption Time: 0.78419
PPO Batch Consumption Time: 0.03381
Total Iteration Time: 4.83163

Cumulative Model Updates: 59,568
Cumulative Timesteps: 993,571,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,694.57425
Policy Entropy: 1.03253
Value Function Loss: 2.68506

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 12,005.94873
Overall Steps per Second: 10,039.14967

Timestep Collection Time: 4.16627
Timestep Consumption Time: 0.81623
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 4.98249

Cumulative Model Updates: 59,571
Cumulative Timesteps: 993,621,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 993621800...
Checkpoint 993621800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746,958.69685
Policy Entropy: 1.02379
Value Function Loss: 2.59399

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.16346
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.09625

Collected Steps per Second: 11,570.38541
Overall Steps per Second: 9,778.64805

Timestep Collection Time: 4.32224
Timestep Consumption Time: 0.79196
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.11420

Cumulative Model Updates: 59,574
Cumulative Timesteps: 993,671,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,776.09080
Policy Entropy: 1.01565
Value Function Loss: 2.58279

Mean KL Divergence: 0.03133
SB3 Clip Fraction: 0.18631
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.10409

Collected Steps per Second: 12,352.06126
Overall Steps per Second: 10,385.91436

Timestep Collection Time: 4.04904
Timestep Consumption Time: 0.76652
PPO Batch Consumption Time: 0.03478
Total Iteration Time: 4.81556

Cumulative Model Updates: 59,577
Cumulative Timesteps: 993,721,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 993721824...
Checkpoint 993721824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,926.08230
Policy Entropy: 1.03789
Value Function Loss: 2.58733

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.09313

Collected Steps per Second: 12,507.97975
Overall Steps per Second: 10,529.82385

Timestep Collection Time: 3.99825
Timestep Consumption Time: 0.75112
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.74937

Cumulative Model Updates: 59,580
Cumulative Timesteps: 993,771,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665,970.40406
Policy Entropy: 1.03751
Value Function Loss: 2.62299

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.08391

Collected Steps per Second: 12,296.67444
Overall Steps per Second: 10,533.11765

Timestep Collection Time: 4.06858
Timestep Consumption Time: 0.68120
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.74978

Cumulative Model Updates: 59,583
Cumulative Timesteps: 993,821,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 993821864...
Checkpoint 993821864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733,232.18505
Policy Entropy: 1.02293
Value Function Loss: 2.60927

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 12,498.42301
Overall Steps per Second: 10,473.24754

Timestep Collection Time: 4.00130
Timestep Consumption Time: 0.77372
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.77502

Cumulative Model Updates: 59,586
Cumulative Timesteps: 993,871,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666,010.99855
Policy Entropy: 1.00451
Value Function Loss: 2.64725

Mean KL Divergence: 0.03982
SB3 Clip Fraction: 0.21725
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.10024

Collected Steps per Second: 12,622.30077
Overall Steps per Second: 10,604.27831

Timestep Collection Time: 3.96330
Timestep Consumption Time: 0.75423
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 4.71753

Cumulative Model Updates: 59,589
Cumulative Timesteps: 993,921,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 993921900...
Checkpoint 993921900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,469.51948
Policy Entropy: 1.02860
Value Function Loss: 2.64675

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 12,763.72589
Overall Steps per Second: 10,551.80648

Timestep Collection Time: 3.91845
Timestep Consumption Time: 0.82140
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 4.73985

Cumulative Model Updates: 59,592
Cumulative Timesteps: 993,971,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,101.30618
Policy Entropy: 1.02906
Value Function Loss: 2.72451

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.10922

Collected Steps per Second: 12,182.27841
Overall Steps per Second: 10,298.38217

Timestep Collection Time: 4.10646
Timestep Consumption Time: 0.75120
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 4.85766

Cumulative Model Updates: 59,595
Cumulative Timesteps: 994,021,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 994021940...
Checkpoint 994021940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764,698.22479
Policy Entropy: 1.01218
Value Function Loss: 2.81331

Mean KL Divergence: 0.03689
SB3 Clip Fraction: 0.20325
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.09719

Collected Steps per Second: 12,446.61240
Overall Steps per Second: 10,564.37785

Timestep Collection Time: 4.01844
Timestep Consumption Time: 0.71596
PPO Batch Consumption Time: 0.03744
Total Iteration Time: 4.73440

Cumulative Model Updates: 59,598
Cumulative Timesteps: 994,071,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705,236.85704
Policy Entropy: 1.03215
Value Function Loss: 2.79900

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.09941

Collected Steps per Second: 11,667.66180
Overall Steps per Second: 9,908.17315

Timestep Collection Time: 4.28586
Timestep Consumption Time: 0.76108
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.04694

Cumulative Model Updates: 59,601
Cumulative Timesteps: 994,121,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 994121962...
Checkpoint 994121962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,084.68854
Policy Entropy: 1.01869
Value Function Loss: 2.67129

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.09409

Collected Steps per Second: 12,055.12361
Overall Steps per Second: 10,172.47742

Timestep Collection Time: 4.14960
Timestep Consumption Time: 0.76798
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 4.91758

Cumulative Model Updates: 59,604
Cumulative Timesteps: 994,171,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838,010.26933
Policy Entropy: 1.01572
Value Function Loss: 2.57430

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.09664

Collected Steps per Second: 12,138.97476
Overall Steps per Second: 10,400.82061

Timestep Collection Time: 4.12094
Timestep Consumption Time: 0.68868
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 4.80962

Cumulative Model Updates: 59,607
Cumulative Timesteps: 994,222,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 994222010...
Checkpoint 994222010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722,408.43567
Policy Entropy: 1.00596
Value Function Loss: 2.47273

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.07307
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 11,957.63193
Overall Steps per Second: 10,057.57691

Timestep Collection Time: 4.18310
Timestep Consumption Time: 0.79026
PPO Batch Consumption Time: 0.03555
Total Iteration Time: 4.97336

Cumulative Model Updates: 59,610
Cumulative Timesteps: 994,272,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708,364.24338
Policy Entropy: 1.01729
Value Function Loss: 2.44149

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.09665

Collected Steps per Second: 11,235.76578
Overall Steps per Second: 9,610.91713

Timestep Collection Time: 4.45221
Timestep Consumption Time: 0.75270
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.20491

Cumulative Model Updates: 59,613
Cumulative Timesteps: 994,322,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 994322054...
Checkpoint 994322054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771,050.99962
Policy Entropy: 1.02500
Value Function Loss: 2.40181

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 12,017.20686
Overall Steps per Second: 10,142.69732

Timestep Collection Time: 4.16120
Timestep Consumption Time: 0.76905
PPO Batch Consumption Time: 0.03385
Total Iteration Time: 4.93025

Cumulative Model Updates: 59,616
Cumulative Timesteps: 994,372,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777,830.78461
Policy Entropy: 1.03214
Value Function Loss: 2.50794

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 12,031.45115
Overall Steps per Second: 10,147.85453

Timestep Collection Time: 4.15644
Timestep Consumption Time: 0.77150
PPO Batch Consumption Time: 0.03505
Total Iteration Time: 4.92794

Cumulative Model Updates: 59,619
Cumulative Timesteps: 994,422,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 994422068...
Checkpoint 994422068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730,949.22955
Policy Entropy: 1.01791
Value Function Loss: 2.68112

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.07908

Collected Steps per Second: 11,838.72086
Overall Steps per Second: 10,202.75737

Timestep Collection Time: 4.22546
Timestep Consumption Time: 0.67753
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 4.90299

Cumulative Model Updates: 59,622
Cumulative Timesteps: 994,472,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776,545.03000
Policy Entropy: 1.01129
Value Function Loss: 2.70412

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.07002

Collected Steps per Second: 11,950.22912
Overall Steps per Second: 10,085.48340

Timestep Collection Time: 4.18486
Timestep Consumption Time: 0.77376
PPO Batch Consumption Time: 0.03394
Total Iteration Time: 4.95861

Cumulative Model Updates: 59,625
Cumulative Timesteps: 994,522,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 994522102...
Checkpoint 994522102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652,405.54963
Policy Entropy: 1.02413
Value Function Loss: 2.88691

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.17982
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 11,970.21959
Overall Steps per Second: 10,149.73353

Timestep Collection Time: 4.17804
Timestep Consumption Time: 0.74938
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 4.92742

Cumulative Model Updates: 59,628
Cumulative Timesteps: 994,572,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736,333.56418
Policy Entropy: 1.03848
Value Function Loss: 2.78117

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.18606
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 11,448.05358
Overall Steps per Second: 9,885.33990

Timestep Collection Time: 4.36913
Timestep Consumption Time: 0.69069
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.05982

Cumulative Model Updates: 59,631
Cumulative Timesteps: 994,622,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 994622132...
Checkpoint 994622132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803,222.91442
Policy Entropy: 1.01767
Value Function Loss: 2.74863

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 12,059.42235
Overall Steps per Second: 10,112.99293

Timestep Collection Time: 4.14696
Timestep Consumption Time: 0.79816
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 4.94512

Cumulative Model Updates: 59,634
Cumulative Timesteps: 994,672,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,611.25830
Policy Entropy: 1.02913
Value Function Loss: 2.57124

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.07396

Collected Steps per Second: 11,828.04735
Overall Steps per Second: 10,013.85230

Timestep Collection Time: 4.22775
Timestep Consumption Time: 0.76593
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 4.99368

Cumulative Model Updates: 59,637
Cumulative Timesteps: 994,722,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 994722148...
Checkpoint 994722148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,995.05946
Policy Entropy: 1.03413
Value Function Loss: 2.65858

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 11,975.40346
Overall Steps per Second: 10,065.79057

Timestep Collection Time: 4.17573
Timestep Consumption Time: 0.79219
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.96792

Cumulative Model Updates: 59,640
Cumulative Timesteps: 994,772,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754,489.80036
Policy Entropy: 1.02283
Value Function Loss: 2.67594

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.07212

Collected Steps per Second: 12,056.78864
Overall Steps per Second: 10,153.26110

Timestep Collection Time: 4.14853
Timestep Consumption Time: 0.77776
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 4.92630

Cumulative Model Updates: 59,643
Cumulative Timesteps: 994,822,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 994822172...
Checkpoint 994822172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688,281.45520
Policy Entropy: 1.01033
Value Function Loss: 2.62045

Mean KL Divergence: 0.03206
SB3 Clip Fraction: 0.19885
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.06722

Collected Steps per Second: 11,898.28604
Overall Steps per Second: 10,169.63926

Timestep Collection Time: 4.20481
Timestep Consumption Time: 0.71474
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 4.91955

Cumulative Model Updates: 59,646
Cumulative Timesteps: 994,872,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,348.51385
Policy Entropy: 1.02128
Value Function Loss: 2.58944

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 11,574.81846
Overall Steps per Second: 9,820.90563

Timestep Collection Time: 4.32093
Timestep Consumption Time: 0.77167
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.09261

Cumulative Model Updates: 59,649
Cumulative Timesteps: 994,922,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 994922216...
Checkpoint 994922216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629,086.80087
Policy Entropy: 1.03174
Value Function Loss: 2.55532

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.06732

Collected Steps per Second: 11,827.25568
Overall Steps per Second: 10,077.13496

Timestep Collection Time: 4.22989
Timestep Consumption Time: 0.73462
PPO Batch Consumption Time: 0.03544
Total Iteration Time: 4.96451

Cumulative Model Updates: 59,652
Cumulative Timesteps: 994,972,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741,112.52218
Policy Entropy: 1.01467
Value Function Loss: 2.41267

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.06688

Collected Steps per Second: 12,409.83464
Overall Steps per Second: 10,339.24222

Timestep Collection Time: 4.02971
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.03891
Total Iteration Time: 4.83672

Cumulative Model Updates: 59,655
Cumulative Timesteps: 995,022,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 995022252...
Checkpoint 995022252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,268.98376
Policy Entropy: 1.01723
Value Function Loss: 2.50769

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 12,046.28182
Overall Steps per Second: 10,185.02262

Timestep Collection Time: 4.15298
Timestep Consumption Time: 0.75894
PPO Batch Consumption Time: 0.03509
Total Iteration Time: 4.91192

Cumulative Model Updates: 59,658
Cumulative Timesteps: 995,072,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,568.74956
Policy Entropy: 1.03243
Value Function Loss: 2.72200

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.06011

Collected Steps per Second: 11,848.89353
Overall Steps per Second: 10,209.00446

Timestep Collection Time: 4.21980
Timestep Consumption Time: 0.67783
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 4.89764

Cumulative Model Updates: 59,661
Cumulative Timesteps: 995,122,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 995122280...
Checkpoint 995122280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,090.14147
Policy Entropy: 1.05120
Value Function Loss: 2.91235

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.19494
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 12,161.59830
Overall Steps per Second: 10,248.15551

Timestep Collection Time: 4.11377
Timestep Consumption Time: 0.76809
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 4.88185

Cumulative Model Updates: 59,664
Cumulative Timesteps: 995,172,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663,438.59821
Policy Entropy: 1.02389
Value Function Loss: 2.81368

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.16959
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 11,338.99027
Overall Steps per Second: 9,622.76432

Timestep Collection Time: 4.41168
Timestep Consumption Time: 0.78683
PPO Batch Consumption Time: 0.03414
Total Iteration Time: 5.19851

Cumulative Model Updates: 59,667
Cumulative Timesteps: 995,222,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 995222334...
Checkpoint 995222334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,136.69118
Policy Entropy: 1.04039
Value Function Loss: 2.65606

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.17432
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.06995

Collected Steps per Second: 11,889.67462
Overall Steps per Second: 10,206.58414

Timestep Collection Time: 4.20600
Timestep Consumption Time: 0.69358
PPO Batch Consumption Time: 0.03549
Total Iteration Time: 4.89958

Cumulative Model Updates: 59,670
Cumulative Timesteps: 995,272,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716,458.00229
Policy Entropy: 1.03132
Value Function Loss: 2.63930

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 11,777.39184
Overall Steps per Second: 9,919.98471

Timestep Collection Time: 4.24610
Timestep Consumption Time: 0.79504
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.04114

Cumulative Model Updates: 59,673
Cumulative Timesteps: 995,322,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 995322350...
Checkpoint 995322350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770,432.87695
Policy Entropy: 1.02659
Value Function Loss: 2.65841

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 12,009.99456
Overall Steps per Second: 10,174.86964

Timestep Collection Time: 4.16486
Timestep Consumption Time: 0.75117
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.91603

Cumulative Model Updates: 59,676
Cumulative Timesteps: 995,372,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,029.12454
Policy Entropy: 1.01458
Value Function Loss: 2.71681

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 12,214.52092
Overall Steps per Second: 10,253.53644

Timestep Collection Time: 4.09545
Timestep Consumption Time: 0.78325
PPO Batch Consumption Time: 0.03311
Total Iteration Time: 4.87871

Cumulative Model Updates: 59,679
Cumulative Timesteps: 995,422,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 995422394...
Checkpoint 995422394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,488.12517
Policy Entropy: 1.02836
Value Function Loss: 2.75489

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.09308

Collected Steps per Second: 11,838.96601
Overall Steps per Second: 9,944.27512

Timestep Collection Time: 4.22436
Timestep Consumption Time: 0.80487
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.02923

Cumulative Model Updates: 59,682
Cumulative Timesteps: 995,472,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697,975.88829
Policy Entropy: 1.03719
Value Function Loss: 2.79048

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.16229
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 11,551.21909
Overall Steps per Second: 9,821.26384

Timestep Collection Time: 4.33080
Timestep Consumption Time: 0.76284
PPO Batch Consumption Time: 0.03409
Total Iteration Time: 5.09364

Cumulative Model Updates: 59,685
Cumulative Timesteps: 995,522,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 995522432...
Checkpoint 995522432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,418.57044
Policy Entropy: 1.01296
Value Function Loss: 2.68232

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.11943

Collected Steps per Second: 11,729.39527
Overall Steps per Second: 9,933.21174

Timestep Collection Time: 4.26484
Timestep Consumption Time: 0.77119
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.03603

Cumulative Model Updates: 59,688
Cumulative Timesteps: 995,572,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,769.93749
Policy Entropy: 1.03210
Value Function Loss: 2.63780

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 11,817.20762
Overall Steps per Second: 10,048.09518

Timestep Collection Time: 4.23146
Timestep Consumption Time: 0.74501
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.97647

Cumulative Model Updates: 59,691
Cumulative Timesteps: 995,622,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 995622460...
Checkpoint 995622460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734,959.01845
Policy Entropy: 1.03322
Value Function Loss: 2.67071

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 11,874.47098
Overall Steps per Second: 10,043.63336

Timestep Collection Time: 4.21071
Timestep Consumption Time: 0.76756
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 4.97828

Cumulative Model Updates: 59,694
Cumulative Timesteps: 995,672,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764,235.77563
Policy Entropy: 1.01978
Value Function Loss: 2.71730

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.16167
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 11,910.27450
Overall Steps per Second: 10,084.17592

Timestep Collection Time: 4.19990
Timestep Consumption Time: 0.76054
PPO Batch Consumption Time: 0.03462
Total Iteration Time: 4.96044

Cumulative Model Updates: 59,697
Cumulative Timesteps: 995,722,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 995722482...
Checkpoint 995722482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637,849.21729
Policy Entropy: 1.01193
Value Function Loss: 2.73768

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.18142
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.09725

Collected Steps per Second: 11,854.43134
Overall Steps per Second: 10,053.75972

Timestep Collection Time: 4.22019
Timestep Consumption Time: 0.75585
PPO Batch Consumption Time: 0.03535
Total Iteration Time: 4.97605

Cumulative Model Updates: 59,700
Cumulative Timesteps: 995,772,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,948.97794
Policy Entropy: 1.01507
Value Function Loss: 2.61743

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.09750

Collected Steps per Second: 11,634.45106
Overall Steps per Second: 9,870.86133

Timestep Collection Time: 4.29982
Timestep Consumption Time: 0.76823
PPO Batch Consumption Time: 0.03520
Total Iteration Time: 5.06805

Cumulative Model Updates: 59,703
Cumulative Timesteps: 995,822,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 995822536...
Checkpoint 995822536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797,365.71385
Policy Entropy: 1.03060
Value Function Loss: 2.55923

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.09855

Collected Steps per Second: 11,983.19103
Overall Steps per Second: 10,159.32008

Timestep Collection Time: 4.17251
Timestep Consumption Time: 0.74908
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 4.92159

Cumulative Model Updates: 59,706
Cumulative Timesteps: 995,872,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,803.46919
Policy Entropy: 1.00618
Value Function Loss: 2.58259

Mean KL Divergence: 0.03331
SB3 Clip Fraction: 0.17130
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 11,901.50588
Overall Steps per Second: 10,214.57990

Timestep Collection Time: 4.20283
Timestep Consumption Time: 0.69409
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.89692

Cumulative Model Updates: 59,709
Cumulative Timesteps: 995,922,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 995922556...
Checkpoint 995922556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664,194.65748
Policy Entropy: 1.03002
Value Function Loss: 2.50859

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.15977
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.08848

Collected Steps per Second: 11,980.31102
Overall Steps per Second: 10,117.70781

Timestep Collection Time: 4.17535
Timestep Consumption Time: 0.76865
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.94401

Cumulative Model Updates: 59,712
Cumulative Timesteps: 995,972,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771,282.50420
Policy Entropy: 1.03090
Value Function Loss: 2.45737

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.17512
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09616

Collected Steps per Second: 12,106.79537
Overall Steps per Second: 10,172.11026

Timestep Collection Time: 4.13189
Timestep Consumption Time: 0.78587
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 4.91776

Cumulative Model Updates: 59,715
Cumulative Timesteps: 996,022,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 996022602...
Checkpoint 996022602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768,288.41433
Policy Entropy: 1.01469
Value Function Loss: 2.50300

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 12,036.04663
Overall Steps per Second: 10,302.54010

Timestep Collection Time: 4.15552
Timestep Consumption Time: 0.69921
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.85473

Cumulative Model Updates: 59,718
Cumulative Timesteps: 996,072,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,725.93097
Policy Entropy: 0.99920
Value Function Loss: 2.52554

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.17127
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.10809

Collected Steps per Second: 11,525.64439
Overall Steps per Second: 9,750.23740

Timestep Collection Time: 4.33989
Timestep Consumption Time: 0.79024
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.13013

Cumulative Model Updates: 59,721
Cumulative Timesteps: 996,122,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 996122638...
Checkpoint 996122638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,217.59143
Policy Entropy: 1.01546
Value Function Loss: 2.57721

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 11,895.59798
Overall Steps per Second: 10,064.84978

Timestep Collection Time: 4.20424
Timestep Consumption Time: 0.76473
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 4.96898

Cumulative Model Updates: 59,724
Cumulative Timesteps: 996,172,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693,119.73647
Policy Entropy: 1.02077
Value Function Loss: 2.54452

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 12,677.29835
Overall Steps per Second: 10,465.43897

Timestep Collection Time: 3.94532
Timestep Consumption Time: 0.83384
PPO Batch Consumption Time: 0.03481
Total Iteration Time: 4.77916

Cumulative Model Updates: 59,727
Cumulative Timesteps: 996,222,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 996222666...
Checkpoint 996222666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745,838.25466
Policy Entropy: 1.00816
Value Function Loss: 2.56386

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 12,552.93968
Overall Steps per Second: 10,433.65434

Timestep Collection Time: 3.98472
Timestep Consumption Time: 0.80938
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.79410

Cumulative Model Updates: 59,730
Cumulative Timesteps: 996,272,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691,329.07897
Policy Entropy: 1.00320
Value Function Loss: 2.53785

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 12,606.44121
Overall Steps per Second: 10,750.83531

Timestep Collection Time: 3.96718
Timestep Consumption Time: 0.68474
PPO Batch Consumption Time: 0.03580
Total Iteration Time: 4.65192

Cumulative Model Updates: 59,733
Cumulative Timesteps: 996,322,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 996322698...
Checkpoint 996322698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782,775.57229
Policy Entropy: 1.01594
Value Function Loss: 2.46678

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.10288

Collected Steps per Second: 12,481.10270
Overall Steps per Second: 10,425.14519

Timestep Collection Time: 4.00798
Timestep Consumption Time: 0.79042
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 4.79840

Cumulative Model Updates: 59,736
Cumulative Timesteps: 996,372,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796,840.76753
Policy Entropy: 1.02953
Value Function Loss: 2.52221

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.09661

Collected Steps per Second: 11,878.30599
Overall Steps per Second: 10,057.93213

Timestep Collection Time: 4.21154
Timestep Consumption Time: 0.76224
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.97379

Cumulative Model Updates: 59,739
Cumulative Timesteps: 996,422,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 996422748...
Checkpoint 996422748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742,613.68304
Policy Entropy: 1.01091
Value Function Loss: 2.61572

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.09187

Collected Steps per Second: 12,734.70767
Overall Steps per Second: 10,658.94009

Timestep Collection Time: 3.92659
Timestep Consumption Time: 0.76468
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 4.69127

Cumulative Model Updates: 59,742
Cumulative Timesteps: 996,472,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765,162.89207
Policy Entropy: 1.02004
Value Function Loss: 2.61970

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.16601
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.08720

Collected Steps per Second: 11,908.27585
Overall Steps per Second: 10,125.24972

Timestep Collection Time: 4.20061
Timestep Consumption Time: 0.73971
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 4.94032

Cumulative Model Updates: 59,745
Cumulative Timesteps: 996,522,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996522774...
Checkpoint 996522774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718,958.45925
Policy Entropy: 1.01746
Value Function Loss: 2.51852

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.19000
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 11,837.05178
Overall Steps per Second: 10,190.44520

Timestep Collection Time: 4.22436
Timestep Consumption Time: 0.68259
PPO Batch Consumption Time: 0.03542
Total Iteration Time: 4.90695

Cumulative Model Updates: 59,748
Cumulative Timesteps: 996,572,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718,364.61356
Policy Entropy: 1.00333
Value Function Loss: 2.47216

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 12,034.73301
Overall Steps per Second: 10,139.20808

Timestep Collection Time: 4.15464
Timestep Consumption Time: 0.77671
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.93135

Cumulative Model Updates: 59,751
Cumulative Timesteps: 996,622,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 996622778...
Checkpoint 996622778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809,053.07407
Policy Entropy: 0.99546
Value Function Loss: 2.37347

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.18368
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.09188

Collected Steps per Second: 11,803.43009
Overall Steps per Second: 9,990.74628

Timestep Collection Time: 4.23657
Timestep Consumption Time: 0.76867
PPO Batch Consumption Time: 0.03758
Total Iteration Time: 5.00523

Cumulative Model Updates: 59,754
Cumulative Timesteps: 996,672,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,115.84211
Policy Entropy: 1.02062
Value Function Loss: 2.39515

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 11,257.05541
Overall Steps per Second: 9,731.49340

Timestep Collection Time: 4.44308
Timestep Consumption Time: 0.69652
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.13960

Cumulative Model Updates: 59,757
Cumulative Timesteps: 996,722,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 996722800...
Checkpoint 996722800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775,911.34002
Policy Entropy: 1.02980
Value Function Loss: 2.36469

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.13276

Collected Steps per Second: 11,952.95299
Overall Steps per Second: 10,084.54351

Timestep Collection Time: 4.18357
Timestep Consumption Time: 0.77511
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.95868

Cumulative Model Updates: 59,760
Cumulative Timesteps: 996,772,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852,371.39923
Policy Entropy: 1.01400
Value Function Loss: 2.51704

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 12,034.89972
Overall Steps per Second: 10,211.80984

Timestep Collection Time: 4.15708
Timestep Consumption Time: 0.74215
PPO Batch Consumption Time: 0.03437
Total Iteration Time: 4.89923

Cumulative Model Updates: 59,763
Cumulative Timesteps: 996,822,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996822836...
Checkpoint 996822836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,110.29173
Policy Entropy: 1.00003
Value Function Loss: 2.54198

Mean KL Divergence: 0.02854
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.10569

Collected Steps per Second: 12,166.22668
Overall Steps per Second: 10,242.21659

Timestep Collection Time: 4.11072
Timestep Consumption Time: 0.77220
PPO Batch Consumption Time: 0.03583
Total Iteration Time: 4.88293

Cumulative Model Updates: 59,766
Cumulative Timesteps: 996,872,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,308.73823
Policy Entropy: 1.01206
Value Function Loss: 2.60589

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 11,859.28853
Overall Steps per Second: 10,021.94937

Timestep Collection Time: 4.21678
Timestep Consumption Time: 0.77307
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.98985

Cumulative Model Updates: 59,769
Cumulative Timesteps: 996,922,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 996922856...
Checkpoint 996922856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,488.76571
Policy Entropy: 1.02588
Value Function Loss: 2.55766

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.08596

Collected Steps per Second: 11,880.23309
Overall Steps per Second: 10,231.21294

Timestep Collection Time: 4.21036
Timestep Consumption Time: 0.67861
PPO Batch Consumption Time: 0.03455
Total Iteration Time: 4.88896

Cumulative Model Updates: 59,772
Cumulative Timesteps: 996,972,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789,082.84547
Policy Entropy: 1.00251
Value Function Loss: 2.55428

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 11,491.65643
Overall Steps per Second: 9,711.28357

Timestep Collection Time: 4.35255
Timestep Consumption Time: 0.79795
PPO Batch Consumption Time: 0.03522
Total Iteration Time: 5.15050

Cumulative Model Updates: 59,775
Cumulative Timesteps: 997,022,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 997022894...
Checkpoint 997022894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,008.54581
Policy Entropy: 1.02148
Value Function Loss: 2.48655

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 11,823.31323
Overall Steps per Second: 10,075.82074

Timestep Collection Time: 4.22910
Timestep Consumption Time: 0.73347
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 4.96257

Cumulative Model Updates: 59,778
Cumulative Timesteps: 997,072,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,202.25682
Policy Entropy: 1.01608
Value Function Loss: 2.59575

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.08818

Collected Steps per Second: 12,199.37817
Overall Steps per Second: 10,237.13401

Timestep Collection Time: 4.10103
Timestep Consumption Time: 0.78608
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 4.88711

Cumulative Model Updates: 59,781
Cumulative Timesteps: 997,122,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 997122926...
Checkpoint 997122926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732,599.42503
Policy Entropy: 1.01082
Value Function Loss: 2.60871

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.15752
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.09790

Collected Steps per Second: 11,986.61984
Overall Steps per Second: 10,054.47848

Timestep Collection Time: 4.17182
Timestep Consumption Time: 0.80169
PPO Batch Consumption Time: 0.03371
Total Iteration Time: 4.97351

Cumulative Model Updates: 59,784
Cumulative Timesteps: 997,172,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793,433.28496
Policy Entropy: 0.99871
Value Function Loss: 2.68612

Mean KL Divergence: 0.03084
SB3 Clip Fraction: 0.22113
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.10440

Collected Steps per Second: 12,010.61077
Overall Steps per Second: 10,340.20383

Timestep Collection Time: 4.16448
Timestep Consumption Time: 0.67275
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 4.83724

Cumulative Model Updates: 59,787
Cumulative Timesteps: 997,222,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 997222950...
Checkpoint 997222950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,411.81656
Policy Entropy: 1.01905
Value Function Loss: 2.58482

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.09811

Collected Steps per Second: 12,078.86873
Overall Steps per Second: 10,075.59151

Timestep Collection Time: 4.14178
Timestep Consumption Time: 0.82349
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 4.96527

Cumulative Model Updates: 59,790
Cumulative Timesteps: 997,272,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703,094.59249
Policy Entropy: 1.00802
Value Function Loss: 2.69684

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 11,439.28463
Overall Steps per Second: 9,768.42727

Timestep Collection Time: 4.37335
Timestep Consumption Time: 0.74805
PPO Batch Consumption Time: 0.03709
Total Iteration Time: 5.12140

Cumulative Model Updates: 59,793
Cumulative Timesteps: 997,323,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997323006...
Checkpoint 997323006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,481.91404
Policy Entropy: 1.00096
Value Function Loss: 2.61538

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.06597
Value Function Update Magnitude: 0.10028

Collected Steps per Second: 12,021.18211
Overall Steps per Second: 10,120.78717

Timestep Collection Time: 4.15949
Timestep Consumption Time: 0.78103
PPO Batch Consumption Time: 0.03516
Total Iteration Time: 4.94052

Cumulative Model Updates: 59,796
Cumulative Timesteps: 997,373,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,082.74133
Policy Entropy: 0.98834
Value Function Loss: 2.61631

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.19409
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.10943

Collected Steps per Second: 11,944.75483
Overall Steps per Second: 10,089.24790

Timestep Collection Time: 4.18711
Timestep Consumption Time: 0.77005
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.95716

Cumulative Model Updates: 59,799
Cumulative Timesteps: 997,423,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 997423022...
Checkpoint 997423022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,912.40683
Policy Entropy: 1.01116
Value Function Loss: 2.44862

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 12,008.95967
Overall Steps per Second: 10,338.52447

Timestep Collection Time: 4.16556
Timestep Consumption Time: 0.67305
PPO Batch Consumption Time: 0.03577
Total Iteration Time: 4.83860

Cumulative Model Updates: 59,802
Cumulative Timesteps: 997,473,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,685.54878
Policy Entropy: 1.01570
Value Function Loss: 2.42414

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.10302

Collected Steps per Second: 11,976.41163
Overall Steps per Second: 10,030.40777

Timestep Collection Time: 4.17504
Timestep Consumption Time: 0.81000
PPO Batch Consumption Time: 0.03426
Total Iteration Time: 4.98504

Cumulative Model Updates: 59,805
Cumulative Timesteps: 997,523,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 997523048...
Checkpoint 997523048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726,567.73659
Policy Entropy: 0.99860
Value Function Loss: 2.42132

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.16591
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.08906

Collected Steps per Second: 12,215.08704
Overall Steps per Second: 10,373.54791

Timestep Collection Time: 4.09428
Timestep Consumption Time: 0.72683
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 4.82111

Cumulative Model Updates: 59,808
Cumulative Timesteps: 997,573,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,227.46746
Policy Entropy: 1.00108
Value Function Loss: 2.68788

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.18981
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.09241

Collected Steps per Second: 11,603.43958
Overall Steps per Second: 10,060.09190

Timestep Collection Time: 4.31148
Timestep Consumption Time: 0.66144
PPO Batch Consumption Time: 0.03427
Total Iteration Time: 4.97292

Cumulative Model Updates: 59,811
Cumulative Timesteps: 997,623,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997623088...
Checkpoint 997623088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,802.81072
Policy Entropy: 1.01380
Value Function Loss: 2.79104

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.09664

Collected Steps per Second: 12,123.12027
Overall Steps per Second: 10,148.56515

Timestep Collection Time: 4.12584
Timestep Consumption Time: 0.80274
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.92858

Cumulative Model Updates: 59,814
Cumulative Timesteps: 997,673,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706,626.88201
Policy Entropy: 1.02366
Value Function Loss: 2.89094

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.18543
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 11,986.19591
Overall Steps per Second: 10,184.80458

Timestep Collection Time: 4.17297
Timestep Consumption Time: 0.73807
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.91104

Cumulative Model Updates: 59,817
Cumulative Timesteps: 997,723,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 997723124...
Checkpoint 997723124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,741.85759
Policy Entropy: 1.00972
Value Function Loss: 2.83566

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 12,196.31711
Overall Steps per Second: 10,276.06888

Timestep Collection Time: 4.10091
Timestep Consumption Time: 0.76632
PPO Batch Consumption Time: 0.03486
Total Iteration Time: 4.86723

Cumulative Model Updates: 59,820
Cumulative Timesteps: 997,773,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701,387.12483
Policy Entropy: 0.99720
Value Function Loss: 2.85590

Mean KL Divergence: 0.02870
SB3 Clip Fraction: 0.18679
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 11,811.11623
Overall Steps per Second: 9,961.99641

Timestep Collection Time: 4.23415
Timestep Consumption Time: 0.78593
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 5.02008

Cumulative Model Updates: 59,823
Cumulative Timesteps: 997,823,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 997823150...
Checkpoint 997823150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713,056.90642
Policy Entropy: 1.01788
Value Function Loss: 2.63093

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 11,629.85264
Overall Steps per Second: 9,908.90909

Timestep Collection Time: 4.29997
Timestep Consumption Time: 0.74680
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.04677

Cumulative Model Updates: 59,826
Cumulative Timesteps: 997,873,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898,199.94400
Policy Entropy: 1.01584
Value Function Loss: 2.43613

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.12377

Collected Steps per Second: 11,448.18407
Overall Steps per Second: 9,647.00023

Timestep Collection Time: 4.37030
Timestep Consumption Time: 0.81598
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 5.18628

Cumulative Model Updates: 59,829
Cumulative Timesteps: 997,923,190

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 997923190...
Checkpoint 997923190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,332.45781
Policy Entropy: 1.00998
Value Function Loss: 2.53029

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 11,886.81466
Overall Steps per Second: 10,085.20548

Timestep Collection Time: 4.20651
Timestep Consumption Time: 0.75145
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 4.95796

Cumulative Model Updates: 59,832
Cumulative Timesteps: 997,973,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,611.10015
Policy Entropy: 0.99533
Value Function Loss: 2.74437

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.20477
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.09138

Collected Steps per Second: 11,813.10861
Overall Steps per Second: 9,990.77395

Timestep Collection Time: 4.23462
Timestep Consumption Time: 0.77240
PPO Batch Consumption Time: 0.03618
Total Iteration Time: 5.00702

Cumulative Model Updates: 59,835
Cumulative Timesteps: 998,023,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 998023216...
Checkpoint 998023216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,985.95375
Policy Entropy: 1.00311
Value Function Loss: 2.86458

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.09423

Collected Steps per Second: 12,053.61058
Overall Steps per Second: 10,120.79762

Timestep Collection Time: 4.14830
Timestep Consumption Time: 0.79222
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 4.94052

Cumulative Model Updates: 59,838
Cumulative Timesteps: 998,073,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639,658.91778
Policy Entropy: 1.01328
Value Function Loss: 2.72861

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.16469
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 11,424.93756
Overall Steps per Second: 9,871.30663

Timestep Collection Time: 4.37692
Timestep Consumption Time: 0.68888
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.06579

Cumulative Model Updates: 59,841
Cumulative Timesteps: 998,123,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 998123224...
Checkpoint 998123224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661,048.56342
Policy Entropy: 0.99171
Value Function Loss: 2.66477

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.11274

Collected Steps per Second: 11,673.82367
Overall Steps per Second: 9,886.75314

Timestep Collection Time: 4.28531
Timestep Consumption Time: 0.77459
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.05990

Cumulative Model Updates: 59,844
Cumulative Timesteps: 998,173,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806,011.73371
Policy Entropy: 0.98815
Value Function Loss: 2.61104

Mean KL Divergence: 0.02467
SB3 Clip Fraction: 0.17671
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 11,464.00937
Overall Steps per Second: 9,813.94046

Timestep Collection Time: 4.36339
Timestep Consumption Time: 0.73364
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.09704

Cumulative Model Updates: 59,847
Cumulative Timesteps: 998,223,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998223272...
Checkpoint 998223272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802,866.14292
Policy Entropy: 1.00436
Value Function Loss: 2.52877

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.09649

Collected Steps per Second: 11,955.72444
Overall Steps per Second: 10,327.53725

Timestep Collection Time: 4.18477
Timestep Consumption Time: 0.65975
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 4.84452

Cumulative Model Updates: 59,850
Cumulative Timesteps: 998,273,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,213.62173
Policy Entropy: 1.01872
Value Function Loss: 2.49593

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.09503

Collected Steps per Second: 11,651.70230
Overall Steps per Second: 9,835.92082

Timestep Collection Time: 4.29242
Timestep Consumption Time: 0.79241
PPO Batch Consumption Time: 0.03638
Total Iteration Time: 5.08483

Cumulative Model Updates: 59,853
Cumulative Timesteps: 998,323,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 998323318...
Checkpoint 998323318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788,985.92000
Policy Entropy: 0.99428
Value Function Loss: 2.49944

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.09313

Collected Steps per Second: 11,793.70371
Overall Steps per Second: 9,996.99650

Timestep Collection Time: 4.24040
Timestep Consumption Time: 0.76210
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.00250

Cumulative Model Updates: 59,856
Cumulative Timesteps: 998,373,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,307.99999
Policy Entropy: 0.99233
Value Function Loss: 2.59650

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 11,995.71081
Overall Steps per Second: 10,104.95940

Timestep Collection Time: 4.16816
Timestep Consumption Time: 0.77991
PPO Batch Consumption Time: 0.03562
Total Iteration Time: 4.94807

Cumulative Model Updates: 59,859
Cumulative Timesteps: 998,423,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 998423328...
Checkpoint 998423328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,988.91216
Policy Entropy: 0.99239
Value Function Loss: 2.58175

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 11,742.11425
Overall Steps per Second: 9,932.79458

Timestep Collection Time: 4.25988
Timestep Consumption Time: 0.77596
PPO Batch Consumption Time: 0.03424
Total Iteration Time: 5.03584

Cumulative Model Updates: 59,862
Cumulative Timesteps: 998,473,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651,413.81498
Policy Entropy: 1.00424
Value Function Loss: 2.61682

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 11,641.07130
Overall Steps per Second: 10,028.43977

Timestep Collection Time: 4.29703
Timestep Consumption Time: 0.69099
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 4.98801

Cumulative Model Updates: 59,865
Cumulative Timesteps: 998,523,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998523370...
Checkpoint 998523370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760,049.71585
Policy Entropy: 1.00192
Value Function Loss: 2.58203

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.07541
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 11,896.35782
Overall Steps per Second: 9,981.86699

Timestep Collection Time: 4.20515
Timestep Consumption Time: 0.80654
PPO Batch Consumption Time: 0.03393
Total Iteration Time: 5.01169

Cumulative Model Updates: 59,868
Cumulative Timesteps: 998,573,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,054.62114
Policy Entropy: 1.00259
Value Function Loss: 2.63929

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.07727
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 12,562.56349
Overall Steps per Second: 10,539.99540

Timestep Collection Time: 3.98072
Timestep Consumption Time: 0.76388
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 4.74459

Cumulative Model Updates: 59,871
Cumulative Timesteps: 998,623,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 998623404...
Checkpoint 998623404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,466.68493
Policy Entropy: 0.99613
Value Function Loss: 2.63633

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 12,406.27740
Overall Steps per Second: 10,561.86525

Timestep Collection Time: 4.03022
Timestep Consumption Time: 0.70379
PPO Batch Consumption Time: 0.03528
Total Iteration Time: 4.73401

Cumulative Model Updates: 59,874
Cumulative Timesteps: 998,673,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,936.71440
Policy Entropy: 1.00208
Value Function Loss: 2.64811

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.06714
Value Function Update Magnitude: 0.07621

Collected Steps per Second: 12,575.32873
Overall Steps per Second: 10,470.55447

Timestep Collection Time: 3.97604
Timestep Consumption Time: 0.79926
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.77530

Cumulative Model Updates: 59,877
Cumulative Timesteps: 998,723,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 998723404...
Checkpoint 998723404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654,753.52048
Policy Entropy: 1.01623
Value Function Loss: 2.72117

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 12,639.96622
Overall Steps per Second: 10,595.22381

Timestep Collection Time: 3.95697
Timestep Consumption Time: 0.76364
PPO Batch Consumption Time: 0.03507
Total Iteration Time: 4.72062

Cumulative Model Updates: 59,880
Cumulative Timesteps: 998,773,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739,266.39717
Policy Entropy: 1.03646
Value Function Loss: 2.78860

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09237

Collected Steps per Second: 12,558.35898
Overall Steps per Second: 10,368.54039

Timestep Collection Time: 3.98364
Timestep Consumption Time: 0.84134
PPO Batch Consumption Time: 0.03422
Total Iteration Time: 4.82498

Cumulative Model Updates: 59,883
Cumulative Timesteps: 998,823,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 998823448...
Checkpoint 998823448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933,725.66102
Policy Entropy: 1.01743
Value Function Loss: 2.84994

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.09132

Collected Steps per Second: 12,502.68368
Overall Steps per Second: 10,453.71576

Timestep Collection Time: 4.00010
Timestep Consumption Time: 0.78403
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 4.78414

Cumulative Model Updates: 59,886
Cumulative Timesteps: 998,873,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783,723.36095
Policy Entropy: 1.01287
Value Function Loss: 2.77848

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.16876
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.08924

Collected Steps per Second: 12,221.44149
Overall Steps per Second: 10,260.54577

Timestep Collection Time: 4.09248
Timestep Consumption Time: 0.78211
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 4.87459

Cumulative Model Updates: 59,889
Cumulative Timesteps: 998,923,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 998923476...
Checkpoint 998923476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763,334.75485
Policy Entropy: 1.01170
Value Function Loss: 2.74577

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.09899

Collected Steps per Second: 12,223.57842
Overall Steps per Second: 10,209.99412

Timestep Collection Time: 4.09127
Timestep Consumption Time: 0.80687
PPO Batch Consumption Time: 0.03474
Total Iteration Time: 4.89814

Cumulative Model Updates: 59,892
Cumulative Timesteps: 998,973,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,860.43640
Policy Entropy: 1.02163
Value Function Loss: 2.67619

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.09802

Collected Steps per Second: 12,021.14189
Overall Steps per Second: 10,215.92052

Timestep Collection Time: 4.16150
Timestep Consumption Time: 0.73537
PPO Batch Consumption Time: 0.03545
Total Iteration Time: 4.89687

Cumulative Model Updates: 59,895
Cumulative Timesteps: 999,023,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 999023512...
Checkpoint 999023512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,837.42067
Policy Entropy: 0.99816
Value Function Loss: 2.70801

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.08878

Collected Steps per Second: 11,920.56465
Overall Steps per Second: 10,230.25540

Timestep Collection Time: 4.19577
Timestep Consumption Time: 0.69325
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 4.88903

Cumulative Model Updates: 59,898
Cumulative Timesteps: 999,073,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644,152.09453
Policy Entropy: 1.01299
Value Function Loss: 2.69425

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 11,980.79155
Overall Steps per Second: 10,003.09872

Timestep Collection Time: 4.17502
Timestep Consumption Time: 0.82543
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.00045

Cumulative Model Updates: 59,901
Cumulative Timesteps: 999,123,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999123548...
Checkpoint 999123548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,601.42548
Policy Entropy: 1.01316
Value Function Loss: 2.67531

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.06520
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 11,881.62922
Overall Steps per Second: 10,087.10681

Timestep Collection Time: 4.21003
Timestep Consumption Time: 0.74898
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 4.95900

Cumulative Model Updates: 59,904
Cumulative Timesteps: 999,173,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652,315.03759
Policy Entropy: 1.01395
Value Function Loss: 2.63135

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.09171

Collected Steps per Second: 11,763.11012
Overall Steps per Second: 10,109.12181

Timestep Collection Time: 4.25245
Timestep Consumption Time: 0.69576
PPO Batch Consumption Time: 0.03502
Total Iteration Time: 4.94820

Cumulative Model Updates: 59,907
Cumulative Timesteps: 999,223,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 999223592...
Checkpoint 999223592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,834.63637
Policy Entropy: 1.01070
Value Function Loss: 2.63293

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.07549
Value Function Update Magnitude: 0.09764

Collected Steps per Second: 11,953.06052
Overall Steps per Second: 10,097.66543

Timestep Collection Time: 4.18303
Timestep Consumption Time: 0.76861
PPO Batch Consumption Time: 0.03420
Total Iteration Time: 4.95164

Cumulative Model Updates: 59,910
Cumulative Timesteps: 999,273,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,121.14060
Policy Entropy: 1.00904
Value Function Loss: 2.76332

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.10461

Collected Steps per Second: 12,053.16346
Overall Steps per Second: 10,149.49598

Timestep Collection Time: 4.15011
Timestep Consumption Time: 0.77841
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 4.92852

Cumulative Model Updates: 59,913
Cumulative Timesteps: 999,323,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 999323614...
Checkpoint 999323614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600,501.23533
Policy Entropy: 1.02726
Value Function Loss: 2.75711

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.09672

Collected Steps per Second: 12,067.23936
Overall Steps per Second: 10,050.80077

Timestep Collection Time: 4.14494
Timestep Consumption Time: 0.83158
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 4.97652

Cumulative Model Updates: 59,916
Cumulative Timesteps: 999,373,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792,028.40445
Policy Entropy: 1.02055
Value Function Loss: 2.67578

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.09108

Collected Steps per Second: 12,006.48131
Overall Steps per Second: 10,030.73602

Timestep Collection Time: 4.16675
Timestep Consumption Time: 0.82072
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 4.98747

Cumulative Model Updates: 59,919
Cumulative Timesteps: 999,423,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 999423660...
Checkpoint 999423660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658,429.18692
Policy Entropy: 1.00941
Value Function Loss: 2.49909

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.16501
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.08682

Collected Steps per Second: 11,819.71797
Overall Steps per Second: 10,220.90270

Timestep Collection Time: 4.23259
Timestep Consumption Time: 0.66209
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 4.89468

Cumulative Model Updates: 59,922
Cumulative Timesteps: 999,473,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,427.56296
Policy Entropy: 0.99992
Value Function Loss: 2.49118

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.18727
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.09431

Collected Steps per Second: 11,998.02506
Overall Steps per Second: 10,059.43289

Timestep Collection Time: 4.16802
Timestep Consumption Time: 0.80324
PPO Batch Consumption Time: 0.03624
Total Iteration Time: 4.97125

Cumulative Model Updates: 59,925
Cumulative Timesteps: 999,523,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 999523696...
Checkpoint 999523696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838,416.46380
Policy Entropy: 1.01153
Value Function Loss: 2.49213

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.09391

Collected Steps per Second: 11,747.80413
Overall Steps per Second: 9,914.66344

Timestep Collection Time: 4.25748
Timestep Consumption Time: 0.78717
PPO Batch Consumption Time: 0.03686
Total Iteration Time: 5.04465

Cumulative Model Updates: 59,928
Cumulative Timesteps: 999,573,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,256.28947
Policy Entropy: 1.02545
Value Function Loss: 2.66807

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 12,004.27998
Overall Steps per Second: 10,187.69403

Timestep Collection Time: 4.16535
Timestep Consumption Time: 0.74273
PPO Batch Consumption Time: 0.03687
Total Iteration Time: 4.90808

Cumulative Model Updates: 59,931
Cumulative Timesteps: 999,623,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 999623714...
Checkpoint 999623714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,535.22051
Policy Entropy: 0.99770
Value Function Loss: 2.65706

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.16763
Policy Update Magnitude: 0.06573
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 12,113.18944
Overall Steps per Second: 10,169.05815

Timestep Collection Time: 4.12905
Timestep Consumption Time: 0.78940
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 4.91845

Cumulative Model Updates: 59,934
Cumulative Timesteps: 999,673,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646,897.34900
Policy Entropy: 1.02315
Value Function Loss: 2.76234

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.08697

Collected Steps per Second: 12,142.03000
Overall Steps per Second: 10,197.62590

Timestep Collection Time: 4.11925
Timestep Consumption Time: 0.78543
PPO Batch Consumption Time: 0.03811
Total Iteration Time: 4.90467

Cumulative Model Updates: 59,937
Cumulative Timesteps: 999,723,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 999723746...
Checkpoint 999723746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770,981.80614
Policy Entropy: 1.02346
Value Function Loss: 2.70026

Mean KL Divergence: 0.02340
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.08721

Collected Steps per Second: 11,951.72553
Overall Steps per Second: 10,083.96522

Timestep Collection Time: 4.18417
Timestep Consumption Time: 0.77499
PPO Batch Consumption Time: 0.03612
Total Iteration Time: 4.95916

Cumulative Model Updates: 59,940
Cumulative Timesteps: 999,773,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637,048.14560
Policy Entropy: 1.01635
Value Function Loss: 2.66821

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 11,999.86191
Overall Steps per Second: 10,157.74272

Timestep Collection Time: 4.16838
Timestep Consumption Time: 0.75594
PPO Batch Consumption Time: 0.03383
Total Iteration Time: 4.92432

Cumulative Model Updates: 59,943
Cumulative Timesteps: 999,823,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999823774...
Checkpoint 999823774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625,199.49605
Policy Entropy: 1.00425
Value Function Loss: 2.61810

Mean KL Divergence: 0.02988
SB3 Clip Fraction: 0.19427
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.10164

Collected Steps per Second: 12,191.58127
Overall Steps per Second: 10,453.81730

Timestep Collection Time: 4.10283
Timestep Consumption Time: 0.68202
PPO Batch Consumption Time: 0.03353
Total Iteration Time: 4.78485

Cumulative Model Updates: 59,946
Cumulative Timesteps: 999,873,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,511.42621
Policy Entropy: 1.02083
Value Function Loss: 2.53239

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.06926
Value Function Update Magnitude: 0.09588

Collected Steps per Second: 12,129.34636
Overall Steps per Second: 10,196.25206

Timestep Collection Time: 4.12339
Timestep Consumption Time: 0.78175
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 4.90514

Cumulative Model Updates: 59,949
Cumulative Timesteps: 999,923,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999923808...
Checkpoint 999923808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,465.51230
Policy Entropy: 1.02590
Value Function Loss: 2.50849

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 11,931.98696
Overall Steps per Second: 10,133.67536

Timestep Collection Time: 4.19125
Timestep Consumption Time: 0.74378
PPO Batch Consumption Time: 0.03493
Total Iteration Time: 4.93503

Cumulative Model Updates: 59,952
Cumulative Timesteps: 999,973,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839,991.38232
Policy Entropy: 1.01669
Value Function Loss: 2.48696

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.07515
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 12,415.11334
Overall Steps per Second: 10,390.82701

Timestep Collection Time: 4.02896
Timestep Consumption Time: 0.78490
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 4.81386

Cumulative Model Updates: 59,955
Cumulative Timesteps: 1,000,023,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1000023838...
Checkpoint 1000023838 saved!
