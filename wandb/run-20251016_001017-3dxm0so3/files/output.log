Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.78237
Policy Entropy: 1.27455
Value Function Loss: 8.35305

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.02178

Collected Steps per Second: 10,252.82248
Overall Steps per Second: 8,103.99513

Timestep Collection Time: 4.87924
Timestep Consumption Time: 1.29376
PPO Batch Consumption Time: 0.58205
Total Iteration Time: 6.17300

Cumulative Model Updates: 15,032
Cumulative Timesteps: 250,829,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.63508
Policy Entropy: 1.24248
Value Function Loss: 8.18957

Mean KL Divergence: 0.07752
SB3 Clip Fraction: 0.21617
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 11,407.70001
Overall Steps per Second: 9,769.89031

Timestep Collection Time: 4.38423
Timestep Consumption Time: 0.73497
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.11920

Cumulative Model Updates: 15,034
Cumulative Timesteps: 250,879,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 250879136...
Checkpoint 250879136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.83931
Policy Entropy: 1.18517
Value Function Loss: 6.73142

Mean KL Divergence: 0.64375
SB3 Clip Fraction: 0.32374
Policy Update Magnitude: 0.09852
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 11,134.29990
Overall Steps per Second: 9,439.75724

Timestep Collection Time: 4.49350
Timestep Consumption Time: 0.80663
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.30014

Cumulative Model Updates: 15,037
Cumulative Timesteps: 250,929,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.35170
Policy Entropy: 1.17889
Value Function Loss: 4.77904

Mean KL Divergence: 0.46381
SB3 Clip Fraction: 0.27739
Policy Update Magnitude: 0.11866
Value Function Update Magnitude: 0.17877

Collected Steps per Second: 12,591.08864
Overall Steps per Second: 10,564.00061

Timestep Collection Time: 3.97329
Timestep Consumption Time: 0.76242
PPO Batch Consumption Time: 0.03640
Total Iteration Time: 4.73571

Cumulative Model Updates: 15,040
Cumulative Timesteps: 250,979,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 250979196...
Checkpoint 250979196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.84468
Policy Entropy: 1.16246
Value Function Loss: 4.22115

Mean KL Divergence: 0.17379
SB3 Clip Fraction: 0.28677
Policy Update Magnitude: 0.14269
Value Function Update Magnitude: 0.20330

Collected Steps per Second: 12,364.87413
Overall Steps per Second: 10,572.43599

Timestep Collection Time: 4.04565
Timestep Consumption Time: 0.68590
PPO Batch Consumption Time: 0.03483
Total Iteration Time: 4.73155

Cumulative Model Updates: 15,043
Cumulative Timesteps: 251,029,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.58938
Policy Entropy: 1.15276
Value Function Loss: 5.10468

Mean KL Divergence: 0.08986
SB3 Clip Fraction: 0.26544
Policy Update Magnitude: 0.13716
Value Function Update Magnitude: 0.21395

Collected Steps per Second: 12,172.54766
Overall Steps per Second: 10,240.92375

Timestep Collection Time: 4.10958
Timestep Consumption Time: 0.77514
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.88472

Cumulative Model Updates: 15,046
Cumulative Timesteps: 251,079,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 251079244...
Checkpoint 251079244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.03302
Policy Entropy: 1.14508
Value Function Loss: 4.57624

Mean KL Divergence: 0.08510
SB3 Clip Fraction: 0.26736
Policy Update Magnitude: 0.12317
Value Function Update Magnitude: 0.20858

Collected Steps per Second: 12,028.14533
Overall Steps per Second: 10,151.24894

Timestep Collection Time: 4.15941
Timestep Consumption Time: 0.76905
PPO Batch Consumption Time: 0.03406
Total Iteration Time: 4.92846

Cumulative Model Updates: 15,049
Cumulative Timesteps: 251,129,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.85276
Policy Entropy: 1.12790
Value Function Loss: 4.63884

Mean KL Divergence: 0.06931
SB3 Clip Fraction: 0.25484
Policy Update Magnitude: 0.11888
Value Function Update Magnitude: 0.24757

Collected Steps per Second: 11,997.17744
Overall Steps per Second: 10,125.10034

Timestep Collection Time: 4.16898
Timestep Consumption Time: 0.77082
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 4.93980

Cumulative Model Updates: 15,052
Cumulative Timesteps: 251,179,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 251179290...
Checkpoint 251179290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.84896
Policy Entropy: 1.11561
Value Function Loss: 5.01968

Mean KL Divergence: 0.05287
SB3 Clip Fraction: 0.25478
Policy Update Magnitude: 0.11664
Value Function Update Magnitude: 0.26909

Collected Steps per Second: 11,080.53618
Overall Steps per Second: 9,435.79885

Timestep Collection Time: 4.51332
Timestep Consumption Time: 0.78671
PPO Batch Consumption Time: 0.03619
Total Iteration Time: 5.30003

Cumulative Model Updates: 15,055
Cumulative Timesteps: 251,229,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.12891
Policy Entropy: 1.12241
Value Function Loss: 5.26848

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.18933
Policy Update Magnitude: 0.10221
Value Function Update Magnitude: 0.25186

Collected Steps per Second: 11,606.46292
Overall Steps per Second: 10,008.26196

Timestep Collection Time: 4.30829
Timestep Consumption Time: 0.68798
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 4.99627

Cumulative Model Updates: 15,058
Cumulative Timesteps: 251,279,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 251279304...
Checkpoint 251279304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.12136
Policy Entropy: 1.11152
Value Function Loss: 5.49284

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.19940
Policy Update Magnitude: 0.10015
Value Function Update Magnitude: 0.27763

Collected Steps per Second: 11,699.97464
Overall Steps per Second: 9,851.22421

Timestep Collection Time: 4.27420
Timestep Consumption Time: 0.80213
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.07632

Cumulative Model Updates: 15,061
Cumulative Timesteps: 251,329,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.65463
Policy Entropy: 1.06783
Value Function Loss: 5.60669

Mean KL Divergence: 0.07152
SB3 Clip Fraction: 0.31070
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.28782

Collected Steps per Second: 11,736.31765
Overall Steps per Second: 9,904.84745

Timestep Collection Time: 4.26250
Timestep Consumption Time: 0.78816
PPO Batch Consumption Time: 0.03615
Total Iteration Time: 5.05066

Cumulative Model Updates: 15,064
Cumulative Timesteps: 251,379,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 251379338...
Checkpoint 251379338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.12981
Policy Entropy: 1.08279
Value Function Loss: 6.17258

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.18087
Policy Update Magnitude: 0.10389
Value Function Update Magnitude: 0.27822

Collected Steps per Second: 11,617.91555
Overall Steps per Second: 9,761.48485

Timestep Collection Time: 4.30439
Timestep Consumption Time: 0.81860
PPO Batch Consumption Time: 0.03647
Total Iteration Time: 5.12299

Cumulative Model Updates: 15,067
Cumulative Timesteps: 251,429,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.73640
Policy Entropy: 1.06481
Value Function Loss: 6.67362

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.19933
Policy Update Magnitude: 0.08943
Value Function Update Magnitude: 0.26671

Collected Steps per Second: 10,980.00121
Overall Steps per Second: 9,434.97964

Timestep Collection Time: 4.55610
Timestep Consumption Time: 0.74608
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 5.30218

Cumulative Model Updates: 15,070
Cumulative Timesteps: 251,479,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 251479372...
Checkpoint 251479372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.69740
Policy Entropy: 1.07076
Value Function Loss: 6.69884

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.08859
Value Function Update Magnitude: 0.28603

Collected Steps per Second: 10,636.14620
Overall Steps per Second: 9,191.30251

Timestep Collection Time: 4.70095
Timestep Consumption Time: 0.73897
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.43993

Cumulative Model Updates: 15,073
Cumulative Timesteps: 251,529,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.91285
Policy Entropy: 1.06368
Value Function Loss: 6.66015

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.08556
Value Function Update Magnitude: 0.25141

Collected Steps per Second: 11,026.84373
Overall Steps per Second: 9,366.55330

Timestep Collection Time: 4.53439
Timestep Consumption Time: 0.80375
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 5.33814

Cumulative Model Updates: 15,076
Cumulative Timesteps: 251,579,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 251579372...
Checkpoint 251579372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.76380
Policy Entropy: 1.05772
Value Function Loss: 6.84100

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.08191
Value Function Update Magnitude: 0.21464

Collected Steps per Second: 11,083.68218
Overall Steps per Second: 9,461.07682

Timestep Collection Time: 4.51348
Timestep Consumption Time: 0.77408
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.28756

Cumulative Model Updates: 15,079
Cumulative Timesteps: 251,629,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.19444
Policy Entropy: 1.05595
Value Function Loss: 6.98961

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.09204
Value Function Update Magnitude: 0.18720

Collected Steps per Second: 11,479.94232
Overall Steps per Second: 9,794.58930

Timestep Collection Time: 4.35769
Timestep Consumption Time: 0.74983
PPO Batch Consumption Time: 0.03572
Total Iteration Time: 5.10751

Cumulative Model Updates: 15,082
Cumulative Timesteps: 251,679,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 251679424...
Checkpoint 251679424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.48186
Policy Entropy: 1.05448
Value Function Loss: 7.23610

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.09407
Value Function Update Magnitude: 0.16403

Collected Steps per Second: 11,259.30005
Overall Steps per Second: 9,580.46384

Timestep Collection Time: 4.44202
Timestep Consumption Time: 0.77840
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.22042

Cumulative Model Updates: 15,085
Cumulative Timesteps: 251,729,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.92638
Policy Entropy: 1.05202
Value Function Loss: 7.07626

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.09653
Value Function Update Magnitude: 0.16584

Collected Steps per Second: 11,128.89152
Overall Steps per Second: 9,683.82270

Timestep Collection Time: 4.49371
Timestep Consumption Time: 0.67057
PPO Batch Consumption Time: 0.03419
Total Iteration Time: 5.16428

Cumulative Model Updates: 15,088
Cumulative Timesteps: 251,779,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 251779448...
Checkpoint 251779448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.64604
Policy Entropy: 1.05033
Value Function Loss: 7.30853

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.09546
Value Function Update Magnitude: 0.19470

Collected Steps per Second: 10,430.77591
Overall Steps per Second: 8,942.06146

Timestep Collection Time: 4.79562
Timestep Consumption Time: 0.79840
PPO Batch Consumption Time: 0.03680
Total Iteration Time: 5.59401

Cumulative Model Updates: 15,091
Cumulative Timesteps: 251,829,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.49044
Policy Entropy: 1.05566
Value Function Loss: 7.18184

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.08651
Value Function Update Magnitude: 0.18148

Collected Steps per Second: 11,514.46419
Overall Steps per Second: 9,765.18841

Timestep Collection Time: 4.34410
Timestep Consumption Time: 0.77818
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.12228

Cumulative Model Updates: 15,094
Cumulative Timesteps: 251,879,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 251879490...
Checkpoint 251879490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.18954
Policy Entropy: 1.06593
Value Function Loss: 7.11898

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.09293
Value Function Update Magnitude: 0.18989

Collected Steps per Second: 11,672.79219
Overall Steps per Second: 9,869.68745

Timestep Collection Time: 4.28535
Timestep Consumption Time: 0.78290
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.06825

Cumulative Model Updates: 15,097
Cumulative Timesteps: 251,929,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.08622
Policy Entropy: 1.06830
Value Function Loss: 6.99791

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.08175
Value Function Update Magnitude: 0.19747

Collected Steps per Second: 11,291.20309
Overall Steps per Second: 9,586.42423

Timestep Collection Time: 4.43017
Timestep Consumption Time: 0.78783
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.21800

Cumulative Model Updates: 15,100
Cumulative Timesteps: 251,979,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 251979534...
Checkpoint 251979534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.89966
Policy Entropy: 1.06179
Value Function Loss: 7.24045

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.07532
Value Function Update Magnitude: 0.16716

Collected Steps per Second: 11,476.75938
Overall Steps per Second: 9,921.76654

Timestep Collection Time: 4.35715
Timestep Consumption Time: 0.68288
PPO Batch Consumption Time: 0.03586
Total Iteration Time: 5.04003

Cumulative Model Updates: 15,103
Cumulative Timesteps: 252,029,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.63297
Policy Entropy: 1.04929
Value Function Loss: 7.34409

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.15483

Collected Steps per Second: 11,411.95399
Overall Steps per Second: 9,475.57873

Timestep Collection Time: 4.38225
Timestep Consumption Time: 0.89553
PPO Batch Consumption Time: 0.03413
Total Iteration Time: 5.27778

Cumulative Model Updates: 15,106
Cumulative Timesteps: 252,079,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 252079550...
Checkpoint 252079550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.17880
Policy Entropy: 1.04838
Value Function Loss: 7.41514

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.08436
Value Function Update Magnitude: 0.14517

Collected Steps per Second: 11,304.08941
Overall Steps per Second: 9,640.25979

Timestep Collection Time: 4.42424
Timestep Consumption Time: 0.76359
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.18783

Cumulative Model Updates: 15,109
Cumulative Timesteps: 252,129,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.50393
Policy Entropy: 1.05807
Value Function Loss: 6.97120

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.12674

Collected Steps per Second: 11,739.26997
Overall Steps per Second: 9,935.47327

Timestep Collection Time: 4.25938
Timestep Consumption Time: 0.77330
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.03267

Cumulative Model Updates: 15,112
Cumulative Timesteps: 252,179,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 252179564...
Checkpoint 252179564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.61117
Policy Entropy: 1.05003
Value Function Loss: 6.91633

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.07815
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 11,519.45914
Overall Steps per Second: 9,814.77488

Timestep Collection Time: 4.34083
Timestep Consumption Time: 0.75394
PPO Batch Consumption Time: 0.03539
Total Iteration Time: 5.09477

Cumulative Model Updates: 15,115
Cumulative Timesteps: 252,229,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.13408
Policy Entropy: 1.05145
Value Function Loss: 7.07270

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.07044
Value Function Update Magnitude: 0.14000

Collected Steps per Second: 11,316.56545
Overall Steps per Second: 9,788.45144

Timestep Collection Time: 4.41848
Timestep Consumption Time: 0.68979
PPO Batch Consumption Time: 0.03514
Total Iteration Time: 5.10826

Cumulative Model Updates: 15,118
Cumulative Timesteps: 252,279,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 252279570...
Checkpoint 252279570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.85205
Policy Entropy: 1.05458
Value Function Loss: 7.07139

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 11,031.24402
Overall Steps per Second: 9,242.76473

Timestep Collection Time: 4.53476
Timestep Consumption Time: 0.87748
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.41223

Cumulative Model Updates: 15,121
Cumulative Timesteps: 252,329,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.43004
Policy Entropy: 1.06594
Value Function Loss: 7.06407

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.06918
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10,469.23979
Overall Steps per Second: 9,001.41336

Timestep Collection Time: 4.77666
Timestep Consumption Time: 0.77891
PPO Batch Consumption Time: 0.03794
Total Iteration Time: 5.55557

Cumulative Model Updates: 15,124
Cumulative Timesteps: 252,379,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 252379602...
Checkpoint 252379602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.85549
Policy Entropy: 1.05352
Value Function Loss: 6.86399

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.07203
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 11,059.71007
Overall Steps per Second: 9,354.45630

Timestep Collection Time: 4.52254
Timestep Consumption Time: 0.82443
PPO Batch Consumption Time: 0.03671
Total Iteration Time: 5.34697

Cumulative Model Updates: 15,127
Cumulative Timesteps: 252,429,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.68200
Policy Entropy: 1.05082
Value Function Loss: 6.97771

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 10,354.93012
Overall Steps per Second: 8,846.17135

Timestep Collection Time: 4.82900
Timestep Consumption Time: 0.82361
PPO Batch Consumption Time: 0.03733
Total Iteration Time: 5.65261

Cumulative Model Updates: 15,130
Cumulative Timesteps: 252,479,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 252479624...
Checkpoint 252479624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.86454
Policy Entropy: 1.05423
Value Function Loss: 6.99118

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 10,495.00144
Overall Steps per Second: 9,099.46061

Timestep Collection Time: 4.76684
Timestep Consumption Time: 0.73107
PPO Batch Consumption Time: 0.03517
Total Iteration Time: 5.49791

Cumulative Model Updates: 15,133
Cumulative Timesteps: 252,529,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.62856
Policy Entropy: 1.06203
Value Function Loss: 7.04798

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.10206

Collected Steps per Second: 10,557.34791
Overall Steps per Second: 9,026.61177

Timestep Collection Time: 4.73642
Timestep Consumption Time: 0.80320
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.53962

Cumulative Model Updates: 15,136
Cumulative Timesteps: 252,579,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 252579656...
Checkpoint 252579656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.95981
Policy Entropy: 1.05643
Value Function Loss: 7.06006

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 9,123.72484
Overall Steps per Second: 7,825.06748

Timestep Collection Time: 5.48329
Timestep Consumption Time: 0.91001
PPO Batch Consumption Time: 0.03938
Total Iteration Time: 6.39330

Cumulative Model Updates: 15,139
Cumulative Timesteps: 252,629,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.00656
Policy Entropy: 1.05791
Value Function Loss: 6.93040

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 9,401.98234
Overall Steps per Second: 8,087.48206

Timestep Collection Time: 5.31973
Timestep Consumption Time: 0.86464
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 6.18437

Cumulative Model Updates: 15,142
Cumulative Timesteps: 252,679,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 252679700...
Checkpoint 252679700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.79037
Policy Entropy: 1.06493
Value Function Loss: 7.05396

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.07987
Value Function Update Magnitude: 0.08740

Collected Steps per Second: 9,463.35042
Overall Steps per Second: 7,973.62019

Timestep Collection Time: 5.28502
Timestep Consumption Time: 0.98741
PPO Batch Consumption Time: 0.04848
Total Iteration Time: 6.27243

Cumulative Model Updates: 15,145
Cumulative Timesteps: 252,729,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.46959
Policy Entropy: 1.06566
Value Function Loss: 7.03095

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.08379
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 9,846.36287
Overall Steps per Second: 8,695.98217

Timestep Collection Time: 5.07802
Timestep Consumption Time: 0.67176
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.74978

Cumulative Model Updates: 15,148
Cumulative Timesteps: 252,779,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 252779714...
Checkpoint 252779714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.05674
Policy Entropy: 1.06384
Value Function Loss: 7.10124

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.17410
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.08157

Collected Steps per Second: 10,236.34928
Overall Steps per Second: 8,852.70426

Timestep Collection Time: 4.88475
Timestep Consumption Time: 0.76347
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.64822

Cumulative Model Updates: 15,151
Cumulative Timesteps: 252,829,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.77449
Policy Entropy: 1.07194
Value Function Loss: 7.12361

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.08457
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 9,739.91862
Overall Steps per Second: 8,326.97134

Timestep Collection Time: 5.13392
Timestep Consumption Time: 0.87114
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.00506

Cumulative Model Updates: 15,154
Cumulative Timesteps: 252,879,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 252879720...
Checkpoint 252879720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.37655
Policy Entropy: 1.07602
Value Function Loss: 7.13102

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.07928
Value Function Update Magnitude: 0.13285

Collected Steps per Second: 9,881.97686
Overall Steps per Second: 8,466.05515

Timestep Collection Time: 5.06255
Timestep Consumption Time: 0.84670
PPO Batch Consumption Time: 0.04000
Total Iteration Time: 5.90925

Cumulative Model Updates: 15,157
Cumulative Timesteps: 252,929,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.11877
Policy Entropy: 1.06713
Value Function Loss: 6.97850

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.07853
Value Function Update Magnitude: 0.13403

Collected Steps per Second: 10,929.86735
Overall Steps per Second: 9,264.67817

Timestep Collection Time: 4.57627
Timestep Consumption Time: 0.82252
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 5.39878

Cumulative Model Updates: 15,160
Cumulative Timesteps: 252,979,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 252979766...
Checkpoint 252979766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.89880
Policy Entropy: 1.05769
Value Function Loss: 6.94931

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10,955.88282
Overall Steps per Second: 9,454.05854

Timestep Collection Time: 4.56631
Timestep Consumption Time: 0.72538
PPO Batch Consumption Time: 0.03531
Total Iteration Time: 5.29170

Cumulative Model Updates: 15,163
Cumulative Timesteps: 253,029,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.91849
Policy Entropy: 1.06191
Value Function Loss: 6.88568

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10,931.17681
Overall Steps per Second: 9,342.15889

Timestep Collection Time: 4.57572
Timestep Consumption Time: 0.77829
PPO Batch Consumption Time: 0.03425
Total Iteration Time: 5.35401

Cumulative Model Updates: 15,166
Cumulative Timesteps: 253,079,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 253079812...
Checkpoint 253079812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.34891
Policy Entropy: 1.07125
Value Function Loss: 7.04216

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.08216
Value Function Update Magnitude: 0.14803

Collected Steps per Second: 11,451.26893
Overall Steps per Second: 9,749.78515

Timestep Collection Time: 4.36720
Timestep Consumption Time: 0.76214
PPO Batch Consumption Time: 0.03395
Total Iteration Time: 5.12934

Cumulative Model Updates: 15,169
Cumulative Timesteps: 253,129,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.04166
Policy Entropy: 1.07401
Value Function Loss: 6.88908

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.08731
Value Function Update Magnitude: 0.14358

Collected Steps per Second: 11,204.32793
Overall Steps per Second: 9,541.42533

Timestep Collection Time: 4.46381
Timestep Consumption Time: 0.77796
PPO Batch Consumption Time: 0.03377
Total Iteration Time: 5.24177

Cumulative Model Updates: 15,172
Cumulative Timesteps: 253,179,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 253179836...
Checkpoint 253179836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.96288
Policy Entropy: 1.07745
Value Function Loss: 6.90323

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.07911
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 12,158.87339
Overall Steps per Second: 10,154.99493

Timestep Collection Time: 4.11370
Timestep Consumption Time: 0.81175
PPO Batch Consumption Time: 0.03378
Total Iteration Time: 4.92546

Cumulative Model Updates: 15,175
Cumulative Timesteps: 253,229,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.36722
Policy Entropy: 1.07650
Value Function Loss: 6.72684

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.08500
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 11,994.20046
Overall Steps per Second: 10,227.82295

Timestep Collection Time: 4.16985
Timestep Consumption Time: 0.72015
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 4.88999

Cumulative Model Updates: 15,178
Cumulative Timesteps: 253,279,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 253279868...
Checkpoint 253279868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.01222
Policy Entropy: 1.07349
Value Function Loss: 6.63281

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 11,952.29962
Overall Steps per Second: 10,004.73884

Timestep Collection Time: 4.18330
Timestep Consumption Time: 0.81434
PPO Batch Consumption Time: 0.03399
Total Iteration Time: 4.99763

Cumulative Model Updates: 15,181
Cumulative Timesteps: 253,329,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.67780
Policy Entropy: 1.06949
Value Function Loss: 6.49796

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.09759
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 11,747.46653
Overall Steps per Second: 10,066.61632

Timestep Collection Time: 4.25811
Timestep Consumption Time: 0.71099
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 4.96910

Cumulative Model Updates: 15,184
Cumulative Timesteps: 253,379,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 253379890...
Checkpoint 253379890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.66467
Policy Entropy: 1.07368
Value Function Loss: 6.56141

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.09441
Value Function Update Magnitude: 0.11607

Collected Steps per Second: 11,173.44717
Overall Steps per Second: 9,520.69505

Timestep Collection Time: 4.47668
Timestep Consumption Time: 0.77713
PPO Batch Consumption Time: 0.03706
Total Iteration Time: 5.25382

Cumulative Model Updates: 15,187
Cumulative Timesteps: 253,429,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.46355
Policy Entropy: 1.07700
Value Function Loss: 6.53907

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.08982
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 10,772.36078
Overall Steps per Second: 9,307.24545

Timestep Collection Time: 4.64207
Timestep Consumption Time: 0.73074
PPO Batch Consumption Time: 0.03450
Total Iteration Time: 5.37280

Cumulative Model Updates: 15,190
Cumulative Timesteps: 253,479,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 253479916...
Checkpoint 253479916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.18977
Policy Entropy: 1.07893
Value Function Loss: 6.82804

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.09301
Value Function Update Magnitude: 0.10621

Collected Steps per Second: 11,108.81815
Overall Steps per Second: 9,494.76753

Timestep Collection Time: 4.50363
Timestep Consumption Time: 0.76559
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.26922

Cumulative Model Updates: 15,193
Cumulative Timesteps: 253,529,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.19519
Policy Entropy: 1.08341
Value Function Loss: 6.91077

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.07957
Value Function Update Magnitude: 0.09364

Collected Steps per Second: 11,290.60910
Overall Steps per Second: 9,530.99656

Timestep Collection Time: 4.42917
Timestep Consumption Time: 0.81771
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.24688

Cumulative Model Updates: 15,196
Cumulative Timesteps: 253,579,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 253579954...
Checkpoint 253579954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.51447
Policy Entropy: 1.08576
Value Function Loss: 7.01659

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.07793
Value Function Update Magnitude: 0.08530

Collected Steps per Second: 11,236.44717
Overall Steps per Second: 9,742.36831

Timestep Collection Time: 4.44998
Timestep Consumption Time: 0.68244
PPO Batch Consumption Time: 0.03923
Total Iteration Time: 5.13243

Cumulative Model Updates: 15,199
Cumulative Timesteps: 253,629,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.50604
Policy Entropy: 1.08519
Value Function Loss: 6.86923

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.07320
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 11,215.04070
Overall Steps per Second: 9,517.27398

Timestep Collection Time: 4.45955
Timestep Consumption Time: 0.79553
PPO Batch Consumption Time: 0.03546
Total Iteration Time: 5.25508

Cumulative Model Updates: 15,202
Cumulative Timesteps: 253,679,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 253679970...
Checkpoint 253679970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.79605
Policy Entropy: 1.07858
Value Function Loss: 6.71362

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.06789
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 11,026.84113
Overall Steps per Second: 9,493.53503

Timestep Collection Time: 4.53639
Timestep Consumption Time: 0.73267
PPO Batch Consumption Time: 0.03847
Total Iteration Time: 5.26906

Cumulative Model Updates: 15,205
Cumulative Timesteps: 253,729,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.12560
Policy Entropy: 1.07153
Value Function Loss: 6.70936

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 10,916.82021
Overall Steps per Second: 9,385.33134

Timestep Collection Time: 4.58247
Timestep Consumption Time: 0.74776
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.33023

Cumulative Model Updates: 15,208
Cumulative Timesteps: 253,780,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 253780018...
Checkpoint 253780018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.79495
Policy Entropy: 1.09094
Value Function Loss: 6.69094

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 11,135.91721
Overall Steps per Second: 9,531.30218

Timestep Collection Time: 4.49141
Timestep Consumption Time: 0.75614
PPO Batch Consumption Time: 0.03446
Total Iteration Time: 5.24755

Cumulative Model Updates: 15,211
Cumulative Timesteps: 253,830,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.99693
Policy Entropy: 1.08181
Value Function Loss: 6.54698

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 11,567.24086
Overall Steps per Second: 9,859.86561

Timestep Collection Time: 4.32324
Timestep Consumption Time: 0.74863
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.07187

Cumulative Model Updates: 15,214
Cumulative Timesteps: 253,880,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 253880042...
Checkpoint 253880042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.42943
Policy Entropy: 1.08137
Value Function Loss: 6.52121

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 11,128.45259
Overall Steps per Second: 9,509.44451

Timestep Collection Time: 4.49532
Timestep Consumption Time: 0.76534
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.26066

Cumulative Model Updates: 15,217
Cumulative Timesteps: 253,930,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.42072
Policy Entropy: 1.07856
Value Function Loss: 6.61534

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.08007

Collected Steps per Second: 10,970.28824
Overall Steps per Second: 9,535.79229

Timestep Collection Time: 4.55977
Timestep Consumption Time: 0.68594
PPO Batch Consumption Time: 0.03499
Total Iteration Time: 5.24571

Cumulative Model Updates: 15,220
Cumulative Timesteps: 253,980,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 253980090...
Checkpoint 253980090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.04176
Policy Entropy: 1.09137
Value Function Loss: 6.63782

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.11202

Collected Steps per Second: 10,577.69675
Overall Steps per Second: 8,972.67370

Timestep Collection Time: 4.72995
Timestep Consumption Time: 0.84609
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.57604

Cumulative Model Updates: 15,223
Cumulative Timesteps: 254,030,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.31652
Policy Entropy: 1.09399
Value Function Loss: 6.73687

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14833
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.13169

Collected Steps per Second: 10,958.68874
Overall Steps per Second: 9,312.84255

Timestep Collection Time: 4.56441
Timestep Consumption Time: 0.80666
PPO Batch Consumption Time: 0.03669
Total Iteration Time: 5.37108

Cumulative Model Updates: 15,226
Cumulative Timesteps: 254,080,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 254080142...
Checkpoint 254080142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.42978
Policy Entropy: 1.08107
Value Function Loss: 6.64477

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.12275

Collected Steps per Second: 11,063.31532
Overall Steps per Second: 9,614.47715

Timestep Collection Time: 4.52125
Timestep Consumption Time: 0.68132
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.20257

Cumulative Model Updates: 15,229
Cumulative Timesteps: 254,130,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.37679
Policy Entropy: 1.08174
Value Function Loss: 6.50660

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.11277

Collected Steps per Second: 11,074.35211
Overall Steps per Second: 9,470.54771

Timestep Collection Time: 4.51584
Timestep Consumption Time: 0.76474
PPO Batch Consumption Time: 0.03598
Total Iteration Time: 5.28058

Cumulative Model Updates: 15,232
Cumulative Timesteps: 254,180,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 254180172...
Checkpoint 254180172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.59053
Policy Entropy: 1.09343
Value Function Loss: 6.49112

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.07304
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 10,902.37144
Overall Steps per Second: 9,318.03230

Timestep Collection Time: 4.58781
Timestep Consumption Time: 0.78006
PPO Batch Consumption Time: 0.03713
Total Iteration Time: 5.36787

Cumulative Model Updates: 15,235
Cumulative Timesteps: 254,230,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.18621
Policy Entropy: 1.10372
Value Function Loss: 6.71395

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 11,511.82188
Overall Steps per Second: 9,753.25665

Timestep Collection Time: 4.34510
Timestep Consumption Time: 0.78344
PPO Batch Consumption Time: 0.03402
Total Iteration Time: 5.12854

Cumulative Model Updates: 15,238
Cumulative Timesteps: 254,280,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 254280210...
Checkpoint 254280210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.38165
Policy Entropy: 1.09364
Value Function Loss: 6.89818

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10,672.49572
Overall Steps per Second: 9,166.88335

Timestep Collection Time: 4.68513
Timestep Consumption Time: 0.76951
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 5.45463

Cumulative Model Updates: 15,241
Cumulative Timesteps: 254,330,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.85344
Policy Entropy: 1.09119
Value Function Loss: 6.65821

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 11,363.22998
Overall Steps per Second: 9,853.68711

Timestep Collection Time: 4.40139
Timestep Consumption Time: 0.67427
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.07566

Cumulative Model Updates: 15,244
Cumulative Timesteps: 254,380,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 254380226...
Checkpoint 254380226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.31583
Policy Entropy: 1.09632
Value Function Loss: 6.53390

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.09314

Collected Steps per Second: 10,884.13585
Overall Steps per Second: 9,309.70648

Timestep Collection Time: 4.59568
Timestep Consumption Time: 0.77721
PPO Batch Consumption Time: 0.03548
Total Iteration Time: 5.37289

Cumulative Model Updates: 15,247
Cumulative Timesteps: 254,430,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.16521
Policy Entropy: 1.10094
Value Function Loss: 6.64559

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.09281

Collected Steps per Second: 11,297.82908
Overall Steps per Second: 9,675.48606

Timestep Collection Time: 4.42705
Timestep Consumption Time: 0.74231
PPO Batch Consumption Time: 0.03442
Total Iteration Time: 5.16935

Cumulative Model Updates: 15,250
Cumulative Timesteps: 254,480,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 254480262...
Checkpoint 254480262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.80069
Policy Entropy: 1.09302
Value Function Loss: 6.92685

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 11,306.33555
Overall Steps per Second: 9,718.64815

Timestep Collection Time: 4.42495
Timestep Consumption Time: 0.72288
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.14784

Cumulative Model Updates: 15,253
Cumulative Timesteps: 254,530,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.28501
Policy Entropy: 1.09326
Value Function Loss: 6.95480

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.08080

Collected Steps per Second: 11,302.82944
Overall Steps per Second: 9,610.18481

Timestep Collection Time: 4.42403
Timestep Consumption Time: 0.77920
PPO Batch Consumption Time: 0.03533
Total Iteration Time: 5.20323

Cumulative Model Updates: 15,256
Cumulative Timesteps: 254,580,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 254580296...
Checkpoint 254580296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.68150
Policy Entropy: 1.10255
Value Function Loss: 7.10952

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 10,657.65594
Overall Steps per Second: 9,275.42874

Timestep Collection Time: 4.69390
Timestep Consumption Time: 0.69949
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.39339

Cumulative Model Updates: 15,259
Cumulative Timesteps: 254,630,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.78855
Policy Entropy: 1.10107
Value Function Loss: 7.03150

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 11,168.31780
Overall Steps per Second: 9,542.97770

Timestep Collection Time: 4.47749
Timestep Consumption Time: 0.76260
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.24008

Cumulative Model Updates: 15,262
Cumulative Timesteps: 254,680,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 254680328...
Checkpoint 254680328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.70938
Policy Entropy: 1.10619
Value Function Loss: 7.06668

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 11,130.07485
Overall Steps per Second: 9,490.75953

Timestep Collection Time: 4.49431
Timestep Consumption Time: 0.77629
PPO Batch Consumption Time: 0.03415
Total Iteration Time: 5.27060

Cumulative Model Updates: 15,265
Cumulative Timesteps: 254,730,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.71593
Policy Entropy: 1.09661
Value Function Loss: 6.80328

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 11,210.54675
Overall Steps per Second: 9,554.74871

Timestep Collection Time: 4.46187
Timestep Consumption Time: 0.77322
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.23509

Cumulative Model Updates: 15,268
Cumulative Timesteps: 254,780,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 254780370...
Checkpoint 254780370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.49641
Policy Entropy: 1.09533
Value Function Loss: 6.74632

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.07433
Value Function Update Magnitude: 0.09840

Collected Steps per Second: 11,112.99658
Overall Steps per Second: 9,568.51185

Timestep Collection Time: 4.50050
Timestep Consumption Time: 0.72644
PPO Batch Consumption Time: 0.03700
Total Iteration Time: 5.22694

Cumulative Model Updates: 15,271
Cumulative Timesteps: 254,830,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.92265
Policy Entropy: 1.10883
Value Function Loss: 6.70471

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 10,737.64564
Overall Steps per Second: 9,311.62554

Timestep Collection Time: 4.65819
Timestep Consumption Time: 0.71337
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.37156

Cumulative Model Updates: 15,274
Cumulative Timesteps: 254,880,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 254880402...
Checkpoint 254880402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.65342
Policy Entropy: 1.11414
Value Function Loss: 6.58132

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.10217

Collected Steps per Second: 11,002.96565
Overall Steps per Second: 9,415.48040

Timestep Collection Time: 4.54659
Timestep Consumption Time: 0.76657
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.31316

Cumulative Model Updates: 15,277
Cumulative Timesteps: 254,930,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.92842
Policy Entropy: 1.09866
Value Function Loss: 6.46666

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.10630

Collected Steps per Second: 11,155.32515
Overall Steps per Second: 9,455.92893

Timestep Collection Time: 4.48467
Timestep Consumption Time: 0.80597
PPO Batch Consumption Time: 0.03714
Total Iteration Time: 5.29065

Cumulative Model Updates: 15,280
Cumulative Timesteps: 254,980,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 254980456...
Checkpoint 254980456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.86240
Policy Entropy: 1.08338
Value Function Loss: 6.50558

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 11,239.54475
Overall Steps per Second: 9,645.50800

Timestep Collection Time: 4.44876
Timestep Consumption Time: 0.73521
PPO Batch Consumption Time: 0.03557
Total Iteration Time: 5.18397

Cumulative Model Updates: 15,283
Cumulative Timesteps: 255,030,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.70488
Policy Entropy: 1.10360
Value Function Loss: 6.62748

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 11,030.85304
Overall Steps per Second: 9,436.08587

Timestep Collection Time: 4.53437
Timestep Consumption Time: 0.76634
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.30071

Cumulative Model Updates: 15,286
Cumulative Timesteps: 255,080,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 255080476...
Checkpoint 255080476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.78253
Policy Entropy: 1.11869
Value Function Loss: 6.66385

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.10897

Collected Steps per Second: 10,423.32437
Overall Steps per Second: 9,060.85066

Timestep Collection Time: 4.79770
Timestep Consumption Time: 0.72143
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.51913

Cumulative Model Updates: 15,289
Cumulative Timesteps: 255,130,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.48466
Policy Entropy: 1.09945
Value Function Loss: 6.64866

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 10,555.35295
Overall Steps per Second: 9,013.90119

Timestep Collection Time: 4.73883
Timestep Consumption Time: 0.81038
PPO Batch Consumption Time: 0.03592
Total Iteration Time: 5.54921

Cumulative Model Updates: 15,292
Cumulative Timesteps: 255,180,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 255180504...
Checkpoint 255180504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.74954
Policy Entropy: 1.08834
Value Function Loss: 6.77137

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.09014

Collected Steps per Second: 11,031.95015
Overall Steps per Second: 9,394.43043

Timestep Collection Time: 4.53320
Timestep Consumption Time: 0.79017
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 5.32337

Cumulative Model Updates: 15,295
Cumulative Timesteps: 255,230,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.98606
Policy Entropy: 1.10173
Value Function Loss: 6.91295

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 10,070.78668
Overall Steps per Second: 8,641.62358

Timestep Collection Time: 4.96605
Timestep Consumption Time: 0.82129
PPO Batch Consumption Time: 0.03651
Total Iteration Time: 5.78734

Cumulative Model Updates: 15,298
Cumulative Timesteps: 255,280,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 255280526...
Checkpoint 255280526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.48764
Policy Entropy: 1.10493
Value Function Loss: 6.68542

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 10,003.05748
Overall Steps per Second: 8,654.20128

Timestep Collection Time: 4.99987
Timestep Consumption Time: 0.77929
PPO Batch Consumption Time: 0.03848
Total Iteration Time: 5.77916

Cumulative Model Updates: 15,301
Cumulative Timesteps: 255,330,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.62190
Policy Entropy: 1.09776
Value Function Loss: 6.56848

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10,101.80578
Overall Steps per Second: 8,757.63307

Timestep Collection Time: 4.95100
Timestep Consumption Time: 0.75991
PPO Batch Consumption Time: 0.03480
Total Iteration Time: 5.71090

Cumulative Model Updates: 15,304
Cumulative Timesteps: 255,380,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 255380554...
Checkpoint 255380554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.86323
Policy Entropy: 1.08751
Value Function Loss: 6.65507

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.11039

Collected Steps per Second: 9,855.36056
Overall Steps per Second: 8,544.99149

Timestep Collection Time: 5.07338
Timestep Consumption Time: 0.77800
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.85138

Cumulative Model Updates: 15,307
Cumulative Timesteps: 255,430,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.00339
Policy Entropy: 1.10488
Value Function Loss: 6.82084

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.07401
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 11,310.31168
Overall Steps per Second: 9,649.52819

Timestep Collection Time: 4.42216
Timestep Consumption Time: 0.76110
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.18326

Cumulative Model Updates: 15,310
Cumulative Timesteps: 255,480,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 255480570...
Checkpoint 255480570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.68790
Policy Entropy: 1.11972
Value Function Loss: 6.52891

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 11,412.66838
Overall Steps per Second: 9,594.85667

Timestep Collection Time: 4.38162
Timestep Consumption Time: 0.83013
PPO Batch Consumption Time: 0.03728
Total Iteration Time: 5.21175

Cumulative Model Updates: 15,313
Cumulative Timesteps: 255,530,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.36539
Policy Entropy: 1.08726
Value Function Loss: 6.63498

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 11,339.68423
Overall Steps per Second: 9,651.91752

Timestep Collection Time: 4.41088
Timestep Consumption Time: 0.77130
PPO Batch Consumption Time: 0.03717
Total Iteration Time: 5.18218

Cumulative Model Updates: 15,316
Cumulative Timesteps: 255,580,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 255580594...
Checkpoint 255580594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.31839
Policy Entropy: 1.11604
Value Function Loss: 6.73426

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 10,919.00307
Overall Steps per Second: 9,392.80563

Timestep Collection Time: 4.58100
Timestep Consumption Time: 0.74435
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.32535

Cumulative Model Updates: 15,319
Cumulative Timesteps: 255,630,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.72856
Policy Entropy: 1.10199
Value Function Loss: 6.94105

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.09947

Collected Steps per Second: 10,724.09267
Overall Steps per Second: 9,208.71026

Timestep Collection Time: 4.66240
Timestep Consumption Time: 0.76724
PPO Batch Consumption Time: 0.03352
Total Iteration Time: 5.42964

Cumulative Model Updates: 15,322
Cumulative Timesteps: 255,680,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 255680614...
Checkpoint 255680614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.47099
Policy Entropy: 1.09985
Value Function Loss: 6.57009

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.08891

Collected Steps per Second: 9,936.13204
Overall Steps per Second: 8,529.60054

Timestep Collection Time: 5.03415
Timestep Consumption Time: 0.83013
PPO Batch Consumption Time: 0.03806
Total Iteration Time: 5.86428

Cumulative Model Updates: 15,325
Cumulative Timesteps: 255,730,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.92701
Policy Entropy: 1.11552
Value Function Loss: 6.36520

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.07784

Collected Steps per Second: 10,276.28331
Overall Steps per Second: 8,801.20291

Timestep Collection Time: 4.86596
Timestep Consumption Time: 0.81553
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.68150

Cumulative Model Updates: 15,328
Cumulative Timesteps: 255,780,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 255780638...
Checkpoint 255780638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.08809
Policy Entropy: 1.11444
Value Function Loss: 6.30088

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 10,310.03367
Overall Steps per Second: 8,836.61647

Timestep Collection Time: 4.85081
Timestep Consumption Time: 0.80882
PPO Batch Consumption Time: 0.03743
Total Iteration Time: 5.65963

Cumulative Model Updates: 15,331
Cumulative Timesteps: 255,830,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.07548
Policy Entropy: 1.10173
Value Function Loss: 6.52535

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.07251

Collected Steps per Second: 10,372.00078
Overall Steps per Second: 8,987.07042

Timestep Collection Time: 4.82086
Timestep Consumption Time: 0.74291
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 5.56377

Cumulative Model Updates: 15,334
Cumulative Timesteps: 255,880,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 255880652...
Checkpoint 255880652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.02410
Policy Entropy: 1.09050
Value Function Loss: 6.45974

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.06925

Collected Steps per Second: 10,334.11140
Overall Steps per Second: 8,906.58801

Timestep Collection Time: 4.83970
Timestep Consumption Time: 0.77569
PPO Batch Consumption Time: 0.03722
Total Iteration Time: 5.61539

Cumulative Model Updates: 15,337
Cumulative Timesteps: 255,930,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.03301
Policy Entropy: 1.09376
Value Function Loss: 6.51229

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 9,446.06787
Overall Steps per Second: 8,267.10466

Timestep Collection Time: 5.29554
Timestep Consumption Time: 0.75519
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 6.05073

Cumulative Model Updates: 15,340
Cumulative Timesteps: 255,980,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 255980688...
Checkpoint 255980688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.54119
Policy Entropy: 1.10294
Value Function Loss: 6.54288

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 10,316.22022
Overall Steps per Second: 8,812.89234

Timestep Collection Time: 4.84926
Timestep Consumption Time: 0.82720
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.67646

Cumulative Model Updates: 15,343
Cumulative Timesteps: 256,030,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.95757
Policy Entropy: 1.11500
Value Function Loss: 7.04211

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 10,197.16822
Overall Steps per Second: 8,835.77219

Timestep Collection Time: 4.90528
Timestep Consumption Time: 0.75580
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 5.66108

Cumulative Model Updates: 15,346
Cumulative Timesteps: 256,080,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 256080734...
Checkpoint 256080734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.90889
Policy Entropy: 1.12034
Value Function Loss: 7.10283

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.06697
Value Function Update Magnitude: 0.06686

Collected Steps per Second: 10,222.35931
Overall Steps per Second: 8,914.15181

Timestep Collection Time: 4.89339
Timestep Consumption Time: 0.71814
PPO Batch Consumption Time: 0.03560
Total Iteration Time: 5.61153

Cumulative Model Updates: 15,349
Cumulative Timesteps: 256,130,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.30430
Policy Entropy: 1.11578
Value Function Loss: 7.06180

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 9,898.88157
Overall Steps per Second: 8,471.35999

Timestep Collection Time: 5.05350
Timestep Consumption Time: 0.85157
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 5.90507

Cumulative Model Updates: 15,352
Cumulative Timesteps: 256,180,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 256180780...
Checkpoint 256180780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.05538
Policy Entropy: 1.10661
Value Function Loss: 6.94296

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.06813

Collected Steps per Second: 9,686.38714
Overall Steps per Second: 8,363.72811

Timestep Collection Time: 5.16271
Timestep Consumption Time: 0.81644
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.97915

Cumulative Model Updates: 15,355
Cumulative Timesteps: 256,230,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.86090
Policy Entropy: 1.11291
Value Function Loss: 6.87900

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.06256

Collected Steps per Second: 10,395.28606
Overall Steps per Second: 8,923.38769

Timestep Collection Time: 4.81160
Timestep Consumption Time: 0.79367
PPO Batch Consumption Time: 0.03757
Total Iteration Time: 5.60527

Cumulative Model Updates: 15,358
Cumulative Timesteps: 256,280,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 256280806...
Checkpoint 256280806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.60864
Policy Entropy: 1.11972
Value Function Loss: 6.82373

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 9,850.08985
Overall Steps per Second: 8,564.42744

Timestep Collection Time: 5.07874
Timestep Consumption Time: 0.76240
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.84114

Cumulative Model Updates: 15,361
Cumulative Timesteps: 256,330,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.17712
Policy Entropy: 1.10547
Value Function Loss: 6.62765

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 9,604.64692
Overall Steps per Second: 8,480.78322

Timestep Collection Time: 5.20748
Timestep Consumption Time: 0.69009
PPO Batch Consumption Time: 0.03886
Total Iteration Time: 5.89757

Cumulative Model Updates: 15,364
Cumulative Timesteps: 256,380,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 256380848...
Checkpoint 256380848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.55620
Policy Entropy: 1.11675
Value Function Loss: 6.39800

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 9,799.54117
Overall Steps per Second: 8,528.41456

Timestep Collection Time: 5.10228
Timestep Consumption Time: 0.76047
PPO Batch Consumption Time: 0.03336
Total Iteration Time: 5.86275

Cumulative Model Updates: 15,367
Cumulative Timesteps: 256,430,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.47182
Policy Entropy: 1.13149
Value Function Loss: 6.26610

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 10,219.85914
Overall Steps per Second: 8,706.86261

Timestep Collection Time: 4.89537
Timestep Consumption Time: 0.85067
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 5.74604

Cumulative Model Updates: 15,370
Cumulative Timesteps: 256,480,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 256480878...
Checkpoint 256480878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.88874
Policy Entropy: 1.13013
Value Function Loss: 6.47735

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 10,700.63691
Overall Steps per Second: 9,170.00744

Timestep Collection Time: 4.67411
Timestep Consumption Time: 0.78019
PPO Batch Consumption Time: 0.03579
Total Iteration Time: 5.45430

Cumulative Model Updates: 15,373
Cumulative Timesteps: 256,530,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.49175
Policy Entropy: 1.11985
Value Function Loss: 6.39850

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 10,651.99749
Overall Steps per Second: 9,167.27142

Timestep Collection Time: 4.69527
Timestep Consumption Time: 0.76044
PPO Batch Consumption Time: 0.03797
Total Iteration Time: 5.45571

Cumulative Model Updates: 15,376
Cumulative Timesteps: 256,580,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 256580908...
Checkpoint 256580908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.15705
Policy Entropy: 1.11166
Value Function Loss: 6.33652

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 10,693.32007
Overall Steps per Second: 9,322.66567

Timestep Collection Time: 4.67713
Timestep Consumption Time: 0.68765
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.36477

Cumulative Model Updates: 15,379
Cumulative Timesteps: 256,630,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.87498
Policy Entropy: 1.13167
Value Function Loss: 6.33290

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.06848

Collected Steps per Second: 10,393.82066
Overall Steps per Second: 8,894.61710

Timestep Collection Time: 4.81247
Timestep Consumption Time: 0.81115
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.62363

Cumulative Model Updates: 15,382
Cumulative Timesteps: 256,680,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 256680942...
Checkpoint 256680942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.00364
Policy Entropy: 1.13903
Value Function Loss: 6.59479

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.06618

Collected Steps per Second: 10,305.32402
Overall Steps per Second: 8,895.12830

Timestep Collection Time: 4.85283
Timestep Consumption Time: 0.76935
PPO Batch Consumption Time: 0.03751
Total Iteration Time: 5.62218

Cumulative Model Updates: 15,385
Cumulative Timesteps: 256,730,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.75218
Policy Entropy: 1.11845
Value Function Loss: 6.74313

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 9,797.88714
Overall Steps per Second: 8,503.76624

Timestep Collection Time: 5.10518
Timestep Consumption Time: 0.77692
PPO Batch Consumption Time: 0.03664
Total Iteration Time: 5.88210

Cumulative Model Updates: 15,388
Cumulative Timesteps: 256,780,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 256780972...
Checkpoint 256780972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.31846
Policy Entropy: 1.13610
Value Function Loss: 6.36675

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.08006

Collected Steps per Second: 10,134.32992
Overall Steps per Second: 8,771.23506

Timestep Collection Time: 4.93491
Timestep Consumption Time: 0.76691
PPO Batch Consumption Time: 0.03492
Total Iteration Time: 5.70182

Cumulative Model Updates: 15,391
Cumulative Timesteps: 256,830,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.54415
Policy Entropy: 1.13618
Value Function Loss: 6.32385

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 10,228.67100
Overall Steps per Second: 8,902.41037

Timestep Collection Time: 4.88978
Timestep Consumption Time: 0.72847
PPO Batch Consumption Time: 0.03503
Total Iteration Time: 5.61825

Cumulative Model Updates: 15,394
Cumulative Timesteps: 256,881,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 256881000...
Checkpoint 256881000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.21085
Policy Entropy: 1.13147
Value Function Loss: 6.35841

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 10,297.43862
Overall Steps per Second: 8,858.82943

Timestep Collection Time: 4.85635
Timestep Consumption Time: 0.78864
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.64499

Cumulative Model Updates: 15,397
Cumulative Timesteps: 256,931,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.97905
Policy Entropy: 1.11357
Value Function Loss: 6.47686

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 10,341.55215
Overall Steps per Second: 8,924.34382

Timestep Collection Time: 4.83757
Timestep Consumption Time: 0.76822
PPO Batch Consumption Time: 0.03802
Total Iteration Time: 5.60579

Cumulative Model Updates: 15,400
Cumulative Timesteps: 256,981,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 256981036...
Checkpoint 256981036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.59088
Policy Entropy: 1.13642
Value Function Loss: 6.61020

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.06265

Collected Steps per Second: 9,761.24277
Overall Steps per Second: 8,463.37983

Timestep Collection Time: 5.12435
Timestep Consumption Time: 0.78582
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.91017

Cumulative Model Updates: 15,403
Cumulative Timesteps: 257,031,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.45366
Policy Entropy: 1.12652
Value Function Loss: 6.34741

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 10,088.84558
Overall Steps per Second: 8,764.29257

Timestep Collection Time: 4.95795
Timestep Consumption Time: 0.74930
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.70725

Cumulative Model Updates: 15,406
Cumulative Timesteps: 257,081,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 257081076...
Checkpoint 257081076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.12025
Policy Entropy: 1.12695
Value Function Loss: 6.51768

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 9,844.75178
Overall Steps per Second: 8,561.65776

Timestep Collection Time: 5.08068
Timestep Consumption Time: 0.76142
PPO Batch Consumption Time: 0.03485
Total Iteration Time: 5.84209

Cumulative Model Updates: 15,409
Cumulative Timesteps: 257,131,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.25762
Policy Entropy: 1.10803
Value Function Loss: 6.34033

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 9,984.43094
Overall Steps per Second: 8,648.43430

Timestep Collection Time: 5.01000
Timestep Consumption Time: 0.77394
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.78394

Cumulative Model Updates: 15,412
Cumulative Timesteps: 257,181,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 257181116...
Checkpoint 257181116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.76746
Policy Entropy: 1.12088
Value Function Loss: 6.67293

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.07619

Collected Steps per Second: 9,991.90657
Overall Steps per Second: 8,611.59786

Timestep Collection Time: 5.00665
Timestep Consumption Time: 0.80249
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 5.80914

Cumulative Model Updates: 15,415
Cumulative Timesteps: 257,231,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.77993
Policy Entropy: 1.12511
Value Function Loss: 6.69144

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05980
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 9,975.28632
Overall Steps per Second: 8,542.65009

Timestep Collection Time: 5.01479
Timestep Consumption Time: 0.84100
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.85579

Cumulative Model Updates: 15,418
Cumulative Timesteps: 257,281,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 257281166...
Checkpoint 257281166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.79493
Policy Entropy: 1.12238
Value Function Loss: 6.89646

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.10067
Value Function Update Magnitude: 0.07357

Collected Steps per Second: 10,009.33197
Overall Steps per Second: 8,595.95830

Timestep Collection Time: 4.99734
Timestep Consumption Time: 0.82168
PPO Batch Consumption Time: 0.03691
Total Iteration Time: 5.81901

Cumulative Model Updates: 15,421
Cumulative Timesteps: 257,331,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.92182
Policy Entropy: 1.12541
Value Function Loss: 6.62421

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.09168
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 9,968.26491
Overall Steps per Second: 8,642.78270

Timestep Collection Time: 5.01612
Timestep Consumption Time: 0.76929
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.78541

Cumulative Model Updates: 15,424
Cumulative Timesteps: 257,381,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 257381188...
Checkpoint 257381188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.99735
Policy Entropy: 1.11873
Value Function Loss: 6.42729

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.08231
Value Function Update Magnitude: 0.06971

Collected Steps per Second: 9,783.93743
Overall Steps per Second: 8,446.77327

Timestep Collection Time: 5.11185
Timestep Consumption Time: 0.80923
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.92108

Cumulative Model Updates: 15,427
Cumulative Timesteps: 257,431,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.48105
Policy Entropy: 1.11559
Value Function Loss: 6.15114

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 10,082.04953
Overall Steps per Second: 8,683.46896

Timestep Collection Time: 4.96149
Timestep Consumption Time: 0.79911
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.76060

Cumulative Model Updates: 15,430
Cumulative Timesteps: 257,481,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 257481224...
Checkpoint 257481224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.91054
Policy Entropy: 1.13316
Value Function Loss: 6.08172

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.05591

Collected Steps per Second: 10,564.37320
Overall Steps per Second: 8,894.35541

Timestep Collection Time: 4.73459
Timestep Consumption Time: 0.88897
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.62357

Cumulative Model Updates: 15,433
Cumulative Timesteps: 257,531,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.85341
Policy Entropy: 1.13989
Value Function Loss: 6.14789

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.05499

Collected Steps per Second: 11,129.47556
Overall Steps per Second: 9,400.16198

Timestep Collection Time: 4.49437
Timestep Consumption Time: 0.82681
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 5.32118

Cumulative Model Updates: 15,436
Cumulative Timesteps: 257,581,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 257581262...
Checkpoint 257581262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.81410
Policy Entropy: 1.12627
Value Function Loss: 6.40450

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.05340

Collected Steps per Second: 10,939.36876
Overall Steps per Second: 9,457.04356

Timestep Collection Time: 4.57248
Timestep Consumption Time: 0.71670
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.28918

Cumulative Model Updates: 15,439
Cumulative Timesteps: 257,631,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.06837
Policy Entropy: 1.11301
Value Function Loss: 6.26127

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 11,200.36207
Overall Steps per Second: 9,490.73783

Timestep Collection Time: 4.46414
Timestep Consumption Time: 0.80415
PPO Batch Consumption Time: 0.03690
Total Iteration Time: 5.26829

Cumulative Model Updates: 15,442
Cumulative Timesteps: 257,681,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 257681282...
Checkpoint 257681282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.84199
Policy Entropy: 1.11984
Value Function Loss: 6.24926

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 11,087.68113
Overall Steps per Second: 9,373.15302

Timestep Collection Time: 4.51221
Timestep Consumption Time: 0.82537
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.33758

Cumulative Model Updates: 15,445
Cumulative Timesteps: 257,731,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.30854
Policy Entropy: 1.12728
Value Function Loss: 6.08653

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 11,007.93178
Overall Steps per Second: 9,365.43722

Timestep Collection Time: 4.54236
Timestep Consumption Time: 0.79663
PPO Batch Consumption Time: 0.03727
Total Iteration Time: 5.33899

Cumulative Model Updates: 15,448
Cumulative Timesteps: 257,781,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 257781314...
Checkpoint 257781314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.41753
Policy Entropy: 1.11780
Value Function Loss: 6.37536

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.07114

Collected Steps per Second: 9,751.15737
Overall Steps per Second: 8,421.71487

Timestep Collection Time: 5.12985
Timestep Consumption Time: 0.80979
PPO Batch Consumption Time: 0.03648
Total Iteration Time: 5.93965

Cumulative Model Updates: 15,451
Cumulative Timesteps: 257,831,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.15127
Policy Entropy: 1.10533
Value Function Loss: 6.48481

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 10,519.32469
Overall Steps per Second: 9,192.64191

Timestep Collection Time: 4.75582
Timestep Consumption Time: 0.68636
PPO Batch Consumption Time: 0.03626
Total Iteration Time: 5.44218

Cumulative Model Updates: 15,454
Cumulative Timesteps: 257,881,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 257881364...
Checkpoint 257881364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.14364
Policy Entropy: 1.14608
Value Function Loss: 6.47664

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.16403
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 10,402.28974
Overall Steps per Second: 8,929.04023

Timestep Collection Time: 4.80798
Timestep Consumption Time: 0.79329
PPO Batch Consumption Time: 0.03558
Total Iteration Time: 5.60127

Cumulative Model Updates: 15,457
Cumulative Timesteps: 257,931,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.76256
Policy Entropy: 1.12237
Value Function Loss: 6.49293

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 10,736.83903
Overall Steps per Second: 9,224.17979

Timestep Collection Time: 4.65817
Timestep Consumption Time: 0.76389
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.42205

Cumulative Model Updates: 15,460
Cumulative Timesteps: 257,981,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 257981392...
Checkpoint 257981392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.45899
Policy Entropy: 1.14355
Value Function Loss: 6.20152

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 10,677.56008
Overall Steps per Second: 9,258.48176

Timestep Collection Time: 4.68403
Timestep Consumption Time: 0.71794
PPO Batch Consumption Time: 0.03707
Total Iteration Time: 5.40197

Cumulative Model Updates: 15,463
Cumulative Timesteps: 258,031,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.18422
Policy Entropy: 1.12999
Value Function Loss: 6.16871

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 9,860.08503
Overall Steps per Second: 8,537.15794

Timestep Collection Time: 5.07318
Timestep Consumption Time: 0.78615
PPO Batch Consumption Time: 0.03745
Total Iteration Time: 5.85933

Cumulative Model Updates: 15,466
Cumulative Timesteps: 258,081,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 258081428...
Checkpoint 258081428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.79246
Policy Entropy: 1.13196
Value Function Loss: 6.25333

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.07835

Collected Steps per Second: 10,516.52848
Overall Steps per Second: 8,921.68616

Timestep Collection Time: 4.75632
Timestep Consumption Time: 0.85024
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 5.60656

Cumulative Model Updates: 15,469
Cumulative Timesteps: 258,131,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.50758
Policy Entropy: 1.12377
Value Function Loss: 6.51996

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.07025

Collected Steps per Second: 10,306.85484
Overall Steps per Second: 8,905.69505

Timestep Collection Time: 4.85366
Timestep Consumption Time: 0.76364
PPO Batch Consumption Time: 0.03734
Total Iteration Time: 5.61730

Cumulative Model Updates: 15,472
Cumulative Timesteps: 258,181,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 258181474...
Checkpoint 258181474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.64804
Policy Entropy: 1.14645
Value Function Loss: 6.48037

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 10,453.12189
Overall Steps per Second: 9,015.03123

Timestep Collection Time: 4.78441
Timestep Consumption Time: 0.76322
PPO Batch Consumption Time: 0.03762
Total Iteration Time: 5.54762

Cumulative Model Updates: 15,475
Cumulative Timesteps: 258,231,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.08624
Policy Entropy: 1.15221
Value Function Loss: 6.40598

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.07249

Collected Steps per Second: 10,388.62817
Overall Steps per Second: 9,063.22286

Timestep Collection Time: 4.81392
Timestep Consumption Time: 0.70399
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.51790

Cumulative Model Updates: 15,478
Cumulative Timesteps: 258,281,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 258281496...
Checkpoint 258281496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.96988
Policy Entropy: 1.13938
Value Function Loss: 6.30815

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 10,187.74263
Overall Steps per Second: 8,789.11854

Timestep Collection Time: 4.90963
Timestep Consumption Time: 0.78128
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 5.69090

Cumulative Model Updates: 15,481
Cumulative Timesteps: 258,331,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.01681
Policy Entropy: 1.12500
Value Function Loss: 6.68867

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 10,074.80789
Overall Steps per Second: 8,628.39154

Timestep Collection Time: 4.96565
Timestep Consumption Time: 0.83241
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 5.79807

Cumulative Model Updates: 15,484
Cumulative Timesteps: 258,381,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 258381542...
Checkpoint 258381542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.86345
Policy Entropy: 1.13838
Value Function Loss: 6.44929

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.06065

Collected Steps per Second: 10,319.28297
Overall Steps per Second: 9,001.58810

Timestep Collection Time: 4.84549
Timestep Consumption Time: 0.70931
PPO Batch Consumption Time: 0.03453
Total Iteration Time: 5.55480

Cumulative Model Updates: 15,487
Cumulative Timesteps: 258,431,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.19185
Policy Entropy: 1.14535
Value Function Loss: 6.49357

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 10,307.23789
Overall Steps per Second: 8,818.75677

Timestep Collection Time: 4.85135
Timestep Consumption Time: 0.81884
PPO Batch Consumption Time: 0.03397
Total Iteration Time: 5.67019

Cumulative Model Updates: 15,490
Cumulative Timesteps: 258,481,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 258481548...
Checkpoint 258481548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.57099
Policy Entropy: 1.11851
Value Function Loss: 5.85382

Mean KL Divergence: 0.04335
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.08160
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 10,398.41063
Overall Steps per Second: 9,074.06010

Timestep Collection Time: 4.80920
Timestep Consumption Time: 0.70190
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.51109

Cumulative Model Updates: 15,493
Cumulative Timesteps: 258,531,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.61852
Policy Entropy: 1.16171
Value Function Loss: 5.95031

Mean KL Divergence: 0.04714
SB3 Clip Fraction: 0.21177
Policy Update Magnitude: 0.07364
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 10,682.07350
Overall Steps per Second: 9,197.79670

Timestep Collection Time: 4.68336
Timestep Consumption Time: 0.75577
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.43913

Cumulative Model Updates: 15,496
Cumulative Timesteps: 258,581,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 258581584...
Checkpoint 258581584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.50921
Policy Entropy: 1.14727
Value Function Loss: 5.71118

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.18126
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.06142

Collected Steps per Second: 10,256.84029
Overall Steps per Second: 8,838.45640

Timestep Collection Time: 4.87499
Timestep Consumption Time: 0.78233
PPO Batch Consumption Time: 0.03844
Total Iteration Time: 5.65732

Cumulative Model Updates: 15,499
Cumulative Timesteps: 258,631,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.64447
Policy Entropy: 1.17091
Value Function Loss: 6.16947

Mean KL Divergence: 0.03922
SB3 Clip Fraction: 0.19913
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 10,831.28651
Overall Steps per Second: 9,416.78476

Timestep Collection Time: 4.61663
Timestep Consumption Time: 0.69347
PPO Batch Consumption Time: 0.03812
Total Iteration Time: 5.31009

Cumulative Model Updates: 15,502
Cumulative Timesteps: 258,681,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 258681590...
Checkpoint 258681590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.92437
Policy Entropy: 1.15365
Value Function Loss: 6.18777

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.15964
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 10,943.82794
Overall Steps per Second: 9,340.13395

Timestep Collection Time: 4.57134
Timestep Consumption Time: 0.78490
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.35624

Cumulative Model Updates: 15,505
Cumulative Timesteps: 258,731,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.34404
Policy Entropy: 1.17129
Value Function Loss: 6.12034

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.07838

Collected Steps per Second: 10,381.38819
Overall Steps per Second: 9,067.92932

Timestep Collection Time: 4.81901
Timestep Consumption Time: 0.69802
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.51703

Cumulative Model Updates: 15,508
Cumulative Timesteps: 258,781,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 258781646...
Checkpoint 258781646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.90248
Policy Entropy: 1.16070
Value Function Loss: 5.93463

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.06477

Collected Steps per Second: 10,774.57312
Overall Steps per Second: 9,162.67947

Timestep Collection Time: 4.64241
Timestep Consumption Time: 0.81669
PPO Batch Consumption Time: 0.03866
Total Iteration Time: 5.45910

Cumulative Model Updates: 15,511
Cumulative Timesteps: 258,831,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.47156
Policy Entropy: 1.16323
Value Function Loss: 5.89939

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 10,654.37676
Overall Steps per Second: 8,969.86766

Timestep Collection Time: 4.69441
Timestep Consumption Time: 0.88159
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 5.57600

Cumulative Model Updates: 15,514
Cumulative Timesteps: 258,881,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 258881682...
Checkpoint 258881682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.31734
Policy Entropy: 1.17243
Value Function Loss: 6.23356

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 10,870.70590
Overall Steps per Second: 9,457.17727

Timestep Collection Time: 4.60154
Timestep Consumption Time: 0.68777
PPO Batch Consumption Time: 0.03763
Total Iteration Time: 5.28932

Cumulative Model Updates: 15,517
Cumulative Timesteps: 258,931,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.46005
Policy Entropy: 1.17802
Value Function Loss: 6.20238

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.07386

Collected Steps per Second: 10,849.14794
Overall Steps per Second: 9,211.60747

Timestep Collection Time: 4.60884
Timestep Consumption Time: 0.81931
PPO Batch Consumption Time: 0.03864
Total Iteration Time: 5.42815

Cumulative Model Updates: 15,520
Cumulative Timesteps: 258,981,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 258981706...
Checkpoint 258981706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.27936
Policy Entropy: 1.16297
Value Function Loss: 6.22351

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.08372

Collected Steps per Second: 10,760.24148
Overall Steps per Second: 9,192.37243

Timestep Collection Time: 4.64897
Timestep Consumption Time: 0.79294
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.44190

Cumulative Model Updates: 15,523
Cumulative Timesteps: 259,031,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.41638
Policy Entropy: 1.17992
Value Function Loss: 6.08509

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.09397

Collected Steps per Second: 11,117.11098
Overall Steps per Second: 9,501.60687

Timestep Collection Time: 4.49973
Timestep Consumption Time: 0.76506
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.26479

Cumulative Model Updates: 15,526
Cumulative Timesteps: 259,081,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 259081754...
Checkpoint 259081754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.81149
Policy Entropy: 1.17312
Value Function Loss: 6.10996

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.08942

Collected Steps per Second: 10,723.14007
Overall Steps per Second: 9,190.02962

Timestep Collection Time: 4.66300
Timestep Consumption Time: 0.77790
PPO Batch Consumption Time: 0.03833
Total Iteration Time: 5.44090

Cumulative Model Updates: 15,529
Cumulative Timesteps: 259,131,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.53844
Policy Entropy: 1.18282
Value Function Loss: 6.26018

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 10,350.85341
Overall Steps per Second: 9,062.82127

Timestep Collection Time: 4.83265
Timestep Consumption Time: 0.68683
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.51947

Cumulative Model Updates: 15,532
Cumulative Timesteps: 259,181,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 259181778...
Checkpoint 259181778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.51479
Policy Entropy: 1.17260
Value Function Loss: 6.30356

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 10,801.73494
Overall Steps per Second: 9,193.62006

Timestep Collection Time: 4.63111
Timestep Consumption Time: 0.81006
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.44116

Cumulative Model Updates: 15,535
Cumulative Timesteps: 259,231,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.82030
Policy Entropy: 1.18905
Value Function Loss: 6.36357

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09819

Collected Steps per Second: 10,245.83383
Overall Steps per Second: 9,009.22391

Timestep Collection Time: 4.88042
Timestep Consumption Time: 0.66989
PPO Batch Consumption Time: 0.03634
Total Iteration Time: 5.55031

Cumulative Model Updates: 15,538
Cumulative Timesteps: 259,281,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 259281806...
Checkpoint 259281806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.52269
Policy Entropy: 1.16958
Value Function Loss: 6.25074

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.08006

Collected Steps per Second: 10,804.37111
Overall Steps per Second: 9,255.78606

Timestep Collection Time: 4.62905
Timestep Consumption Time: 0.77449
PPO Batch Consumption Time: 0.03755
Total Iteration Time: 5.40354

Cumulative Model Updates: 15,541
Cumulative Timesteps: 259,331,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.34962
Policy Entropy: 1.18761
Value Function Loss: 6.55114

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.07739

Collected Steps per Second: 10,401.18108
Overall Steps per Second: 8,921.19266

Timestep Collection Time: 4.80965
Timestep Consumption Time: 0.79790
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 5.60755

Cumulative Model Updates: 15,544
Cumulative Timesteps: 259,381,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 259381846...
Checkpoint 259381846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.17832
Policy Entropy: 1.19112
Value Function Loss: 6.29101

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 10,320.36267
Overall Steps per Second: 8,814.10624

Timestep Collection Time: 4.84673
Timestep Consumption Time: 0.82827
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 5.67499

Cumulative Model Updates: 15,547
Cumulative Timesteps: 259,431,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.04149
Policy Entropy: 1.19718
Value Function Loss: 6.47153

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.06564

Collected Steps per Second: 10,453.81336
Overall Steps per Second: 8,964.87946

Timestep Collection Time: 4.78371
Timestep Consumption Time: 0.79450
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.57821

Cumulative Model Updates: 15,550
Cumulative Timesteps: 259,481,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 259481874...
Checkpoint 259481874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.05981
Policy Entropy: 1.19319
Value Function Loss: 6.08830

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 10,447.73691
Overall Steps per Second: 8,938.86233

Timestep Collection Time: 4.78764
Timestep Consumption Time: 0.80815
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 5.59579

Cumulative Model Updates: 15,553
Cumulative Timesteps: 259,531,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.49043
Policy Entropy: 1.19441
Value Function Loss: 6.27469

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.05092

Collected Steps per Second: 10,449.83529
Overall Steps per Second: 8,942.32961

Timestep Collection Time: 4.78496
Timestep Consumption Time: 0.80665
PPO Batch Consumption Time: 0.03642
Total Iteration Time: 5.59161

Cumulative Model Updates: 15,556
Cumulative Timesteps: 259,581,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 259581896...
Checkpoint 259581896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.39514
Policy Entropy: 1.20700
Value Function Loss: 6.21004

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.05355

Collected Steps per Second: 10,355.83839
Overall Steps per Second: 8,965.22588

Timestep Collection Time: 4.83090
Timestep Consumption Time: 0.74933
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.58023

Cumulative Model Updates: 15,559
Cumulative Timesteps: 259,631,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.78242
Policy Entropy: 1.19415
Value Function Loss: 6.39727

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 10,344.55005
Overall Steps per Second: 8,741.50963

Timestep Collection Time: 4.83443
Timestep Consumption Time: 0.88655
PPO Batch Consumption Time: 0.03644
Total Iteration Time: 5.72098

Cumulative Model Updates: 15,562
Cumulative Timesteps: 259,681,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 259681934...
Checkpoint 259681934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.35362
Policy Entropy: 1.19073
Value Function Loss: 6.28965

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 10,458.81401
Overall Steps per Second: 9,005.55611

Timestep Collection Time: 4.78161
Timestep Consumption Time: 0.77163
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 5.55324

Cumulative Model Updates: 15,565
Cumulative Timesteps: 259,731,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.75402
Policy Entropy: 1.19859
Value Function Loss: 6.09550

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.04444

Collected Steps per Second: 10,146.30093
Overall Steps per Second: 8,800.36457

Timestep Collection Time: 4.92790
Timestep Consumption Time: 0.75368
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 5.68158

Cumulative Model Updates: 15,568
Cumulative Timesteps: 259,781,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 259781944...
Checkpoint 259781944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.58566
Policy Entropy: 1.19780
Value Function Loss: 5.82153

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 10,684.30475
Overall Steps per Second: 9,050.26057

Timestep Collection Time: 4.68145
Timestep Consumption Time: 0.84525
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 5.52669

Cumulative Model Updates: 15,571
Cumulative Timesteps: 259,831,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.49161
Policy Entropy: 1.19212
Value Function Loss: 6.16424

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 11,252.87144
Overall Steps per Second: 9,497.45673

Timestep Collection Time: 4.44420
Timestep Consumption Time: 0.82142
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 5.26562

Cumulative Model Updates: 15,574
Cumulative Timesteps: 259,881,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 259881972...
Checkpoint 259881972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.70223
Policy Entropy: 1.20073
Value Function Loss: 6.19182

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 11,515.97015
Overall Steps per Second: 9,787.31216

Timestep Collection Time: 4.34301
Timestep Consumption Time: 0.76707
PPO Batch Consumption Time: 0.03616
Total Iteration Time: 5.11009

Cumulative Model Updates: 15,577
Cumulative Timesteps: 259,931,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.13853
Policy Entropy: 1.20521
Value Function Loss: 6.68182

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 10,282.92049
Overall Steps per Second: 8,835.92686

Timestep Collection Time: 4.86515
Timestep Consumption Time: 0.79673
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 5.66188

Cumulative Model Updates: 15,580
Cumulative Timesteps: 259,982,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 259982014...
Checkpoint 259982014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.32559
Policy Entropy: 1.20857
Value Function Loss: 6.44365

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 10,728.50064
Overall Steps per Second: 9,338.06069

Timestep Collection Time: 4.66067
Timestep Consumption Time: 0.69398
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 5.35465

Cumulative Model Updates: 15,583
Cumulative Timesteps: 260,032,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.58378
Policy Entropy: 1.19862
Value Function Loss: 6.38143

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 10,688.04001
Overall Steps per Second: 9,051.65868

Timestep Collection Time: 4.67962
Timestep Consumption Time: 0.84599
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 5.52562

Cumulative Model Updates: 15,586
Cumulative Timesteps: 260,082,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 260082032...
Checkpoint 260082032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.20666
Policy Entropy: 1.20715
Value Function Loss: 6.04392

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 10,338.89874
Overall Steps per Second: 8,901.84989

Timestep Collection Time: 4.83649
Timestep Consumption Time: 0.78077
PPO Batch Consumption Time: 0.03553
Total Iteration Time: 5.61726

Cumulative Model Updates: 15,589
Cumulative Timesteps: 260,132,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.86973
Policy Entropy: 1.20808
Value Function Loss: 6.02873

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 10,986.09134
Overall Steps per Second: 9,389.32241

Timestep Collection Time: 4.55121
Timestep Consumption Time: 0.77399
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.32520

Cumulative Model Updates: 15,592
Cumulative Timesteps: 260,182,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 260182036...
Checkpoint 260182036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.23248
Policy Entropy: 1.21860
Value Function Loss: 6.21133

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 10,458.21503
Overall Steps per Second: 9,049.22798

Timestep Collection Time: 4.78208
Timestep Consumption Time: 0.74458
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.52666

Cumulative Model Updates: 15,595
Cumulative Timesteps: 260,232,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.61545
Policy Entropy: 1.21985
Value Function Loss: 6.17789

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.07571
Value Function Update Magnitude: 0.06873

Collected Steps per Second: 10,078.76497
Overall Steps per Second: 8,828.68885

Timestep Collection Time: 4.96152
Timestep Consumption Time: 0.70251
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 5.66403

Cumulative Model Updates: 15,598
Cumulative Timesteps: 260,282,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 260282054...
Checkpoint 260282054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.51711
Policy Entropy: 1.22555
Value Function Loss: 6.30277

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.07457
Value Function Update Magnitude: 0.05899

Collected Steps per Second: 10,295.74369
Overall Steps per Second: 8,871.78431

Timestep Collection Time: 4.85832
Timestep Consumption Time: 0.77978
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.63810

Cumulative Model Updates: 15,601
Cumulative Timesteps: 260,332,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.50266
Policy Entropy: 1.22571
Value Function Loss: 6.26831

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 10,488.14642
Overall Steps per Second: 9,062.68408

Timestep Collection Time: 4.76748
Timestep Consumption Time: 0.74987
PPO Batch Consumption Time: 0.03518
Total Iteration Time: 5.51735

Cumulative Model Updates: 15,604
Cumulative Timesteps: 260,382,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 260382076...
Checkpoint 260382076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.71121
Policy Entropy: 1.22343
Value Function Loss: 6.26415

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 10,545.35842
Overall Steps per Second: 9,090.81161

Timestep Collection Time: 4.74332
Timestep Consumption Time: 0.75894
PPO Batch Consumption Time: 0.03682
Total Iteration Time: 5.50226

Cumulative Model Updates: 15,607
Cumulative Timesteps: 260,432,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.47403
Policy Entropy: 1.22148
Value Function Loss: 6.22044

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 10,600.82293
Overall Steps per Second: 9,113.96521

Timestep Collection Time: 4.71907
Timestep Consumption Time: 0.76987
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.48894

Cumulative Model Updates: 15,610
Cumulative Timesteps: 260,482,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 260482122...
Checkpoint 260482122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.43391
Policy Entropy: 1.23112
Value Function Loss: 5.99495

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 10,141.33325
Overall Steps per Second: 8,919.35943

Timestep Collection Time: 4.93328
Timestep Consumption Time: 0.67587
PPO Batch Consumption Time: 0.03759
Total Iteration Time: 5.60915

Cumulative Model Updates: 15,613
Cumulative Timesteps: 260,532,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.70890
Policy Entropy: 1.22961
Value Function Loss: 6.06468

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07550
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.07816

Collected Steps per Second: 10,487.40223
Overall Steps per Second: 9,026.84149

Timestep Collection Time: 4.76762
Timestep Consumption Time: 0.77141
PPO Batch Consumption Time: 0.03573
Total Iteration Time: 5.53904

Cumulative Model Updates: 15,616
Cumulative Timesteps: 260,582,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 260582152...
Checkpoint 260582152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.59509
Policy Entropy: 1.22304
Value Function Loss: 5.93013

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.08060

Collected Steps per Second: 10,472.29620
Overall Steps per Second: 9,005.81497

Timestep Collection Time: 4.77527
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 5.55286

Cumulative Model Updates: 15,619
Cumulative Timesteps: 260,632,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.51410
Policy Entropy: 1.22370
Value Function Loss: 6.29110

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 10,515.28689
Overall Steps per Second: 9,032.93303

Timestep Collection Time: 4.75745
Timestep Consumption Time: 0.78072
PPO Batch Consumption Time: 0.03803
Total Iteration Time: 5.53818

Cumulative Model Updates: 15,622
Cumulative Timesteps: 260,682,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 260682186...
Checkpoint 260682186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.49732
Policy Entropy: 1.22594
Value Function Loss: 6.19308

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 10,041.42414
Overall Steps per Second: 8,701.60245

Timestep Collection Time: 4.97997
Timestep Consumption Time: 0.76679
PPO Batch Consumption Time: 0.03521
Total Iteration Time: 5.74676

Cumulative Model Updates: 15,625
Cumulative Timesteps: 260,732,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.15510
Policy Entropy: 1.23363
Value Function Loss: 6.40607

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 10,660.44226
Overall Steps per Second: 9,111.42559

Timestep Collection Time: 4.69155
Timestep Consumption Time: 0.79760
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.48915

Cumulative Model Updates: 15,628
Cumulative Timesteps: 260,782,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 260782206...
Checkpoint 260782206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.12897
Policy Entropy: 1.23929
Value Function Loss: 6.23461

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.09355

Collected Steps per Second: 10,521.48366
Overall Steps per Second: 8,989.57216

Timestep Collection Time: 4.75370
Timestep Consumption Time: 0.81008
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 5.56378

Cumulative Model Updates: 15,631
Cumulative Timesteps: 260,832,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.03338
Policy Entropy: 1.23440
Value Function Loss: 6.13819

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 10,169.08823
Overall Steps per Second: 8,820.34498

Timestep Collection Time: 4.91962
Timestep Consumption Time: 0.75227
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 5.67189

Cumulative Model Updates: 15,634
Cumulative Timesteps: 260,882,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 260882250...
Checkpoint 260882250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.81968
Policy Entropy: 1.23065
Value Function Loss: 5.98583

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.07279

Collected Steps per Second: 10,087.95767
Overall Steps per Second: 8,612.51801

Timestep Collection Time: 4.95740
Timestep Consumption Time: 0.84927
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.80666

Cumulative Model Updates: 15,637
Cumulative Timesteps: 260,932,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.58336
Policy Entropy: 1.22350
Value Function Loss: 6.10981

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.06826

Collected Steps per Second: 10,404.16053
Overall Steps per Second: 8,906.02461

Timestep Collection Time: 4.80731
Timestep Consumption Time: 0.80867
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 5.61597

Cumulative Model Updates: 15,640
Cumulative Timesteps: 260,982,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 260982276...
Checkpoint 260982276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.26070
Policy Entropy: 1.24362
Value Function Loss: 5.92722

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07554
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 10,570.49344
Overall Steps per Second: 9,221.63201

Timestep Collection Time: 4.73166
Timestep Consumption Time: 0.69211
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.42377

Cumulative Model Updates: 15,643
Cumulative Timesteps: 261,032,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.50782
Policy Entropy: 1.23197
Value Function Loss: 5.79058

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 10,165.04920
Overall Steps per Second: 8,767.14592

Timestep Collection Time: 4.91901
Timestep Consumption Time: 0.78433
PPO Batch Consumption Time: 0.03673
Total Iteration Time: 5.70334

Cumulative Model Updates: 15,646
Cumulative Timesteps: 261,082,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 261082294...
Checkpoint 261082294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.86099
Policy Entropy: 1.22629
Value Function Loss: 5.50753

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 10,797.48849
Overall Steps per Second: 9,274.39282

Timestep Collection Time: 4.63145
Timestep Consumption Time: 0.76060
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 5.39205

Cumulative Model Updates: 15,649
Cumulative Timesteps: 261,132,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.58646
Policy Entropy: 1.22634
Value Function Loss: 5.91540

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.08553

Collected Steps per Second: 10,860.47769
Overall Steps per Second: 9,318.97414

Timestep Collection Time: 4.60569
Timestep Consumption Time: 0.76185
PPO Batch Consumption Time: 0.03730
Total Iteration Time: 5.36754

Cumulative Model Updates: 15,652
Cumulative Timesteps: 261,182,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 261182322...
Checkpoint 261182322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.33626
Policy Entropy: 1.23120
Value Function Loss: 6.06227

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 10,666.76129
Overall Steps per Second: 9,200.66771

Timestep Collection Time: 4.68971
Timestep Consumption Time: 0.74729
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.43700

Cumulative Model Updates: 15,655
Cumulative Timesteps: 261,232,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.08040
Policy Entropy: 1.21927
Value Function Loss: 6.34005

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.08854

Collected Steps per Second: 10,874.52651
Overall Steps per Second: 9,472.33722

Timestep Collection Time: 4.59974
Timestep Consumption Time: 0.68090
PPO Batch Consumption Time: 0.03688
Total Iteration Time: 5.28064

Cumulative Model Updates: 15,658
Cumulative Timesteps: 261,282,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 261282366...
Checkpoint 261282366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.75264
Policy Entropy: 1.23230
Value Function Loss: 6.07776

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 10,200.55144
Overall Steps per Second: 8,732.01762

Timestep Collection Time: 4.90405
Timestep Consumption Time: 0.82475
PPO Batch Consumption Time: 0.03816
Total Iteration Time: 5.72880

Cumulative Model Updates: 15,661
Cumulative Timesteps: 261,332,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.71518
Policy Entropy: 1.22759
Value Function Loss: 6.01297

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 10,658.73992
Overall Steps per Second: 9,208.22113

Timestep Collection Time: 4.69230
Timestep Consumption Time: 0.73915
PPO Batch Consumption Time: 0.03614
Total Iteration Time: 5.43145

Cumulative Model Updates: 15,664
Cumulative Timesteps: 261,382,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 261382404...
Checkpoint 261382404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.23479
Policy Entropy: 1.20903
Value Function Loss: 5.83851

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.05030

Collected Steps per Second: 10,403.01893
Overall Steps per Second: 8,862.66913

Timestep Collection Time: 4.80841
Timestep Consumption Time: 0.83571
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 5.64412

Cumulative Model Updates: 15,667
Cumulative Timesteps: 261,432,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.40434
Policy Entropy: 1.23159
Value Function Loss: 5.93681

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 10,426.25926
Overall Steps per Second: 9,048.87296

Timestep Collection Time: 4.79558
Timestep Consumption Time: 0.72997
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.52555

Cumulative Model Updates: 15,670
Cumulative Timesteps: 261,482,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 261482426...
Checkpoint 261482426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.91201
Policy Entropy: 1.21228
Value Function Loss: 5.93828

Mean KL Divergence: 0.03105
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 10,412.83092
Overall Steps per Second: 9,087.01151

Timestep Collection Time: 4.80350
Timestep Consumption Time: 0.70084
PPO Batch Consumption Time: 0.03741
Total Iteration Time: 5.50434

Cumulative Model Updates: 15,673
Cumulative Timesteps: 261,532,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.18464
Policy Entropy: 1.23195
Value Function Loss: 5.89340

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 10,363.54503
Overall Steps per Second: 8,853.32254

Timestep Collection Time: 4.82731
Timestep Consumption Time: 0.82345
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 5.65076

Cumulative Model Updates: 15,676
Cumulative Timesteps: 261,582,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 261582472...
Checkpoint 261582472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.58222
Policy Entropy: 1.21497
Value Function Loss: 5.94170

Mean KL Divergence: 0.02577
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.05538

Collected Steps per Second: 10,198.64085
Overall Steps per Second: 8,776.44915

Timestep Collection Time: 4.90438
Timestep Consumption Time: 0.79474
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.69912

Cumulative Model Updates: 15,679
Cumulative Timesteps: 261,632,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.66648
Policy Entropy: 1.23466
Value Function Loss: 5.90912

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.05041

Collected Steps per Second: 10,728.71345
Overall Steps per Second: 9,060.39051

Timestep Collection Time: 4.66114
Timestep Consumption Time: 0.85827
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.51941

Cumulative Model Updates: 15,682
Cumulative Timesteps: 261,682,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 261682498...
Checkpoint 261682498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.19836
Policy Entropy: 1.21699
Value Function Loss: 6.07441

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.04550

Collected Steps per Second: 10,402.83724
Overall Steps per Second: 8,944.39895

Timestep Collection Time: 4.80926
Timestep Consumption Time: 0.78418
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.59344

Cumulative Model Updates: 15,685
Cumulative Timesteps: 261,732,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.02121
Policy Entropy: 1.22093
Value Function Loss: 6.14240

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.04700

Collected Steps per Second: 10,537.60474
Overall Steps per Second: 9,159.99025

Timestep Collection Time: 4.74586
Timestep Consumption Time: 0.71375
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.45961

Cumulative Model Updates: 15,688
Cumulative Timesteps: 261,782,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 261782538...
Checkpoint 261782538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.13974
Policy Entropy: 1.21241
Value Function Loss: 6.15214

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.08370
Value Function Update Magnitude: 0.04625

Collected Steps per Second: 10,936.20905
Overall Steps per Second: 9,281.58203

Timestep Collection Time: 4.57453
Timestep Consumption Time: 0.81550
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 5.39003

Cumulative Model Updates: 15,691
Cumulative Timesteps: 261,832,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.02393
Policy Entropy: 1.21857
Value Function Loss: 6.05550

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.04617

Collected Steps per Second: 10,964.24355
Overall Steps per Second: 9,349.69186

Timestep Collection Time: 4.56156
Timestep Consumption Time: 0.78771
PPO Batch Consumption Time: 0.03593
Total Iteration Time: 5.34927

Cumulative Model Updates: 15,694
Cumulative Timesteps: 261,882,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 261882580...
Checkpoint 261882580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.65612
Policy Entropy: 1.22463
Value Function Loss: 5.73718

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.04706

Collected Steps per Second: 11,876.20620
Overall Steps per Second: 10,022.16732

Timestep Collection Time: 4.21111
Timestep Consumption Time: 0.77903
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 4.99014

Cumulative Model Updates: 15,697
Cumulative Timesteps: 261,932,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.84762
Policy Entropy: 1.21641
Value Function Loss: 5.78963

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.04128

Collected Steps per Second: 11,765.42386
Overall Steps per Second: 9,992.25075

Timestep Collection Time: 4.25212
Timestep Consumption Time: 0.75456
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.00668

Cumulative Model Updates: 15,700
Cumulative Timesteps: 261,982,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 261982620...
Checkpoint 261982620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.43948
Policy Entropy: 1.21855
Value Function Loss: 5.85656

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 11,658.70467
Overall Steps per Second: 10,072.21942

Timestep Collection Time: 4.28864
Timestep Consumption Time: 0.67551
PPO Batch Consumption Time: 0.03530
Total Iteration Time: 4.96415

Cumulative Model Updates: 15,703
Cumulative Timesteps: 262,032,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.10089
Policy Entropy: 1.21823
Value Function Loss: 6.18112

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 11,724.14230
Overall Steps per Second: 9,829.92999

Timestep Collection Time: 4.26607
Timestep Consumption Time: 0.82206
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.08813

Cumulative Model Updates: 15,706
Cumulative Timesteps: 262,082,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 262082636...
Checkpoint 262082636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.46334
Policy Entropy: 1.21120
Value Function Loss: 6.12368

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 11,491.86556
Overall Steps per Second: 9,731.05624

Timestep Collection Time: 4.35299
Timestep Consumption Time: 0.78766
PPO Batch Consumption Time: 0.03764
Total Iteration Time: 5.14065

Cumulative Model Updates: 15,709
Cumulative Timesteps: 262,132,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.19601
Policy Entropy: 1.22062
Value Function Loss: 6.02134

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.07728

Collected Steps per Second: 10,296.37137
Overall Steps per Second: 8,883.66640

Timestep Collection Time: 4.85608
Timestep Consumption Time: 0.77223
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 5.62831

Cumulative Model Updates: 15,712
Cumulative Timesteps: 262,182,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 262182660...
Checkpoint 262182660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.79276
Policy Entropy: 1.21748
Value Function Loss: 5.96580

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.08407

Collected Steps per Second: 10,505.73650
Overall Steps per Second: 9,094.16455

Timestep Collection Time: 4.76064
Timestep Consumption Time: 0.73893
PPO Batch Consumption Time: 0.03656
Total Iteration Time: 5.49957

Cumulative Model Updates: 15,715
Cumulative Timesteps: 262,232,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.34205
Policy Entropy: 1.21309
Value Function Loss: 5.94343

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.07805

Collected Steps per Second: 11,034.97247
Overall Steps per Second: 9,495.41947

Timestep Collection Time: 4.53359
Timestep Consumption Time: 0.73506
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.26865

Cumulative Model Updates: 15,718
Cumulative Timesteps: 262,282,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 262282702...
Checkpoint 262282702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.30264
Policy Entropy: 1.21070
Value Function Loss: 5.82221

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.07578

Collected Steps per Second: 10,871.61797
Overall Steps per Second: 9,266.74611

Timestep Collection Time: 4.59987
Timestep Consumption Time: 0.79663
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.39650

Cumulative Model Updates: 15,721
Cumulative Timesteps: 262,332,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.38342
Policy Entropy: 1.21281
Value Function Loss: 5.67203

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.08319

Collected Steps per Second: 10,812.19983
Overall Steps per Second: 9,262.19111

Timestep Collection Time: 4.62626
Timestep Consumption Time: 0.77419
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.40045

Cumulative Model Updates: 15,724
Cumulative Timesteps: 262,382,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 262382730...
Checkpoint 262382730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.82867
Policy Entropy: 1.20684
Value Function Loss: 5.77753

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 10,334.02760
Overall Steps per Second: 8,808.35810

Timestep Collection Time: 4.83838
Timestep Consumption Time: 0.83804
PPO Batch Consumption Time: 0.03956
Total Iteration Time: 5.67643

Cumulative Model Updates: 15,727
Cumulative Timesteps: 262,432,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.77551
Policy Entropy: 1.21246
Value Function Loss: 5.90468

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.08987

Collected Steps per Second: 10,707.46795
Overall Steps per Second: 9,226.92297

Timestep Collection Time: 4.67057
Timestep Consumption Time: 0.74944
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.42001

Cumulative Model Updates: 15,730
Cumulative Timesteps: 262,482,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 262482740...
Checkpoint 262482740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.53179
Policy Entropy: 1.21358
Value Function Loss: 5.88052

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06218
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.09624

Collected Steps per Second: 10,546.76587
Overall Steps per Second: 9,227.00282

Timestep Collection Time: 4.74382
Timestep Consumption Time: 0.67852
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.42235

Cumulative Model Updates: 15,733
Cumulative Timesteps: 262,532,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.09314
Policy Entropy: 1.22385
Value Function Loss: 5.91785

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.06080
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 10,452.47212
Overall Steps per Second: 8,930.64847

Timestep Collection Time: 4.78643
Timestep Consumption Time: 0.81563
PPO Batch Consumption Time: 0.03636
Total Iteration Time: 5.60206

Cumulative Model Updates: 15,736
Cumulative Timesteps: 262,582,802

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 262582802...
Checkpoint 262582802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.52231
Policy Entropy: 1.22144
Value Function Loss: 5.85416

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.09118

Collected Steps per Second: 10,653.61804
Overall Steps per Second: 9,194.94699

Timestep Collection Time: 4.69587
Timestep Consumption Time: 0.74494
PPO Batch Consumption Time: 0.03776
Total Iteration Time: 5.44081

Cumulative Model Updates: 15,739
Cumulative Timesteps: 262,632,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.09266
Policy Entropy: 1.22428
Value Function Loss: 6.14743

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08688

Collected Steps per Second: 10,591.34868
Overall Steps per Second: 9,064.17183

Timestep Collection Time: 4.72253
Timestep Consumption Time: 0.79568
PPO Batch Consumption Time: 0.03852
Total Iteration Time: 5.51821

Cumulative Model Updates: 15,742
Cumulative Timesteps: 262,682,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 262682848...
Checkpoint 262682848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.47459
Policy Entropy: 1.22975
Value Function Loss: 6.29330

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.08790

Collected Steps per Second: 9,918.51237
Overall Steps per Second: 8,599.02763

Timestep Collection Time: 5.04269
Timestep Consumption Time: 0.77378
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.81647

Cumulative Model Updates: 15,745
Cumulative Timesteps: 262,732,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.21831
Policy Entropy: 1.22589
Value Function Loss: 6.29865

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.09004

Collected Steps per Second: 10,725.12256
Overall Steps per Second: 9,334.68458

Timestep Collection Time: 4.66270
Timestep Consumption Time: 0.69453
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.35722

Cumulative Model Updates: 15,748
Cumulative Timesteps: 262,782,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 262782872...
Checkpoint 262782872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.58443
Policy Entropy: 1.22155
Value Function Loss: 6.02198

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.09847

Collected Steps per Second: 10,462.76439
Overall Steps per Second: 8,918.32821

Timestep Collection Time: 4.78076
Timestep Consumption Time: 0.82791
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.60867

Cumulative Model Updates: 15,751
Cumulative Timesteps: 262,832,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.97220
Policy Entropy: 1.20334
Value Function Loss: 5.76975

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.07377
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 10,276.59669
Overall Steps per Second: 8,902.44586

Timestep Collection Time: 4.86562
Timestep Consumption Time: 0.75104
PPO Batch Consumption Time: 0.03775
Total Iteration Time: 5.61666

Cumulative Model Updates: 15,754
Cumulative Timesteps: 262,882,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 262882894...
Checkpoint 262882894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.55419
Policy Entropy: 1.22534
Value Function Loss: 5.76524

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.09693

Collected Steps per Second: 10,678.69441
Overall Steps per Second: 9,178.39797

Timestep Collection Time: 4.68428
Timestep Consumption Time: 0.76569
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.44997

Cumulative Model Updates: 15,757
Cumulative Timesteps: 262,932,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.59167
Policy Entropy: 1.21743
Value Function Loss: 5.94233

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 10,503.91431
Overall Steps per Second: 9,050.36133

Timestep Collection Time: 4.76280
Timestep Consumption Time: 0.76494
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.52774

Cumulative Model Updates: 15,760
Cumulative Timesteps: 262,982,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 262982944...
Checkpoint 262982944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.92851
Policy Entropy: 1.22641
Value Function Loss: 5.84754

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 10,956.23936
Overall Steps per Second: 9,482.64646

Timestep Collection Time: 4.56617
Timestep Consumption Time: 0.70958
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 5.27574

Cumulative Model Updates: 15,763
Cumulative Timesteps: 263,032,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.99803
Policy Entropy: 1.22347
Value Function Loss: 6.06834

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.08924

Collected Steps per Second: 11,091.27661
Overall Steps per Second: 9,516.36713

Timestep Collection Time: 4.51021
Timestep Consumption Time: 0.74642
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 5.25663

Cumulative Model Updates: 15,766
Cumulative Timesteps: 263,082,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 263082996...
Checkpoint 263082996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.64084
Policy Entropy: 1.22272
Value Function Loss: 6.38403

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.08634

Collected Steps per Second: 10,980.05754
Overall Steps per Second: 9,418.23257

Timestep Collection Time: 4.55371
Timestep Consumption Time: 0.75514
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.30885

Cumulative Model Updates: 15,769
Cumulative Timesteps: 263,132,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.43615
Policy Entropy: 1.22197
Value Function Loss: 6.69294

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.07440

Collected Steps per Second: 11,269.64907
Overall Steps per Second: 9,560.32846

Timestep Collection Time: 4.43936
Timestep Consumption Time: 0.79373
PPO Batch Consumption Time: 0.03716
Total Iteration Time: 5.23308

Cumulative Model Updates: 15,772
Cumulative Timesteps: 263,183,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 263183026...
Checkpoint 263183026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.01557
Policy Entropy: 1.22076
Value Function Loss: 6.91652

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.06781

Collected Steps per Second: 11,186.93846
Overall Steps per Second: 9,581.47431

Timestep Collection Time: 4.47200
Timestep Consumption Time: 0.74932
PPO Batch Consumption Time: 0.03858
Total Iteration Time: 5.22133

Cumulative Model Updates: 15,775
Cumulative Timesteps: 263,233,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.33842
Policy Entropy: 1.21852
Value Function Loss: 6.63129

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 10,253.52118
Overall Steps per Second: 8,983.92670

Timestep Collection Time: 4.87637
Timestep Consumption Time: 0.68912
PPO Batch Consumption Time: 0.03489
Total Iteration Time: 5.56550

Cumulative Model Updates: 15,778
Cumulative Timesteps: 263,283,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 263283054...
Checkpoint 263283054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.47131
Policy Entropy: 1.22167
Value Function Loss: 6.37895

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05607
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.09948

Collected Steps per Second: 10,958.40813
Overall Steps per Second: 9,401.10786

Timestep Collection Time: 4.56490
Timestep Consumption Time: 0.75618
PPO Batch Consumption Time: 0.03841
Total Iteration Time: 5.32107

Cumulative Model Updates: 15,781
Cumulative Timesteps: 263,333,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.82295
Policy Entropy: 1.22289
Value Function Loss: 5.92977

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.09344

Collected Steps per Second: 10,867.11025
Overall Steps per Second: 9,299.95823

Timestep Collection Time: 4.60159
Timestep Consumption Time: 0.77542
PPO Batch Consumption Time: 0.03697
Total Iteration Time: 5.37701

Cumulative Model Updates: 15,784
Cumulative Timesteps: 263,383,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 263383084...
Checkpoint 263383084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.79540
Policy Entropy: 1.22169
Value Function Loss: 5.75739

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04506
Policy Update Magnitude: 0.07389
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 11,009.27144
Overall Steps per Second: 9,395.79919

Timestep Collection Time: 4.54163
Timestep Consumption Time: 0.77990
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 5.32153

Cumulative Model Updates: 15,787
Cumulative Timesteps: 263,433,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.40529
Policy Entropy: 1.21679
Value Function Loss: 5.91176

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 11,218.98381
Overall Steps per Second: 9,570.70085

Timestep Collection Time: 4.45923
Timestep Consumption Time: 0.76798
PPO Batch Consumption Time: 0.03512
Total Iteration Time: 5.22720

Cumulative Model Updates: 15,790
Cumulative Timesteps: 263,483,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 263483112...
Checkpoint 263483112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.14556
Policy Entropy: 1.21350
Value Function Loss: 5.94556

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.08262
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 10,257.06037
Overall Steps per Second: 8,847.49015

Timestep Collection Time: 4.87645
Timestep Consumption Time: 0.77691
PPO Batch Consumption Time: 0.03737
Total Iteration Time: 5.65335

Cumulative Model Updates: 15,793
Cumulative Timesteps: 263,533,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.60484
Policy Entropy: 1.22476
Value Function Loss: 6.25076

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.07280

Collected Steps per Second: 10,787.70286
Overall Steps per Second: 9,248.98258

Timestep Collection Time: 4.63713
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.03515
Total Iteration Time: 5.40859

Cumulative Model Updates: 15,796
Cumulative Timesteps: 263,583,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 263583154...
Checkpoint 263583154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.50362
Policy Entropy: 1.21576
Value Function Loss: 6.12204

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 10,754.29648
Overall Steps per Second: 9,252.46747

Timestep Collection Time: 4.65191
Timestep Consumption Time: 0.75508
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 5.40699

Cumulative Model Updates: 15,799
Cumulative Timesteps: 263,633,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.23694
Policy Entropy: 1.22596
Value Function Loss: 6.10741

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 10,834.28242
Overall Steps per Second: 9,312.84948

Timestep Collection Time: 4.61683
Timestep Consumption Time: 0.75425
PPO Batch Consumption Time: 0.03444
Total Iteration Time: 5.37107

Cumulative Model Updates: 15,802
Cumulative Timesteps: 263,683,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 263683202...
Checkpoint 263683202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.67485
Policy Entropy: 1.22528
Value Function Loss: 6.09153

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.08411

Collected Steps per Second: 10,598.48671
Overall Steps per Second: 9,129.20523

Timestep Collection Time: 4.71954
Timestep Consumption Time: 0.75958
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 5.47912

Cumulative Model Updates: 15,805
Cumulative Timesteps: 263,733,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.46163
Policy Entropy: 1.23506
Value Function Loss: 6.13903

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 10,621.92600
Overall Steps per Second: 9,232.65948

Timestep Collection Time: 4.70988
Timestep Consumption Time: 0.70871
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 5.41859

Cumulative Model Updates: 15,808
Cumulative Timesteps: 263,783,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 263783250...
Checkpoint 263783250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.99104
Policy Entropy: 1.23108
Value Function Loss: 6.21309

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.07615

Collected Steps per Second: 10,203.78727
Overall Steps per Second: 8,729.31119

Timestep Collection Time: 4.90171
Timestep Consumption Time: 0.82795
PPO Batch Consumption Time: 0.03684
Total Iteration Time: 5.72966

Cumulative Model Updates: 15,811
Cumulative Timesteps: 263,833,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.19254
Policy Entropy: 1.24121
Value Function Loss: 6.01744

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.07928

Collected Steps per Second: 10,788.50155
Overall Steps per Second: 9,248.17713

Timestep Collection Time: 4.63475
Timestep Consumption Time: 0.77194
PPO Batch Consumption Time: 0.03645
Total Iteration Time: 5.40669

Cumulative Model Updates: 15,814
Cumulative Timesteps: 263,883,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 263883268...
Checkpoint 263883268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.26667
Policy Entropy: 1.23285
Value Function Loss: 5.85730

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 10,685.46575
Overall Steps per Second: 9,121.91120

Timestep Collection Time: 4.68187
Timestep Consumption Time: 0.80250
PPO Batch Consumption Time: 0.03596
Total Iteration Time: 5.48438

Cumulative Model Updates: 15,817
Cumulative Timesteps: 263,933,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.53133
Policy Entropy: 1.24390
Value Function Loss: 6.02058

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.06977

Collected Steps per Second: 10,453.30054
Overall Steps per Second: 9,040.69808

Timestep Collection Time: 4.78337
Timestep Consumption Time: 0.74740
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.53077

Cumulative Model Updates: 15,820
Cumulative Timesteps: 263,983,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 263983298...
Checkpoint 263983298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.56565
Policy Entropy: 1.23868
Value Function Loss: 6.10201

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 10,411.25477
Overall Steps per Second: 9,096.47513

Timestep Collection Time: 4.80307
Timestep Consumption Time: 0.69422
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 5.49729

Cumulative Model Updates: 15,823
Cumulative Timesteps: 264,033,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.03738
Policy Entropy: 1.23570
Value Function Loss: 6.27993

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 11,816.84053
Overall Steps per Second: 9,793.59496

Timestep Collection Time: 4.23277
Timestep Consumption Time: 0.87444
PPO Batch Consumption Time: 0.03602
Total Iteration Time: 5.10722

Cumulative Model Updates: 15,826
Cumulative Timesteps: 264,083,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 264083322...
Checkpoint 264083322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.61971
Policy Entropy: 1.23891
Value Function Loss: 6.30981

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 11,744.76112
Overall Steps per Second: 9,954.41596

Timestep Collection Time: 4.25841
Timestep Consumption Time: 0.76589
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.02430

Cumulative Model Updates: 15,829
Cumulative Timesteps: 264,133,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.33447
Policy Entropy: 1.23636
Value Function Loss: 6.40762

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05969
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.06086

Collected Steps per Second: 12,111.25956
Overall Steps per Second: 10,143.97622

Timestep Collection Time: 4.12855
Timestep Consumption Time: 0.80068
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 4.92923

Cumulative Model Updates: 15,832
Cumulative Timesteps: 264,183,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 264183338...
Checkpoint 264183338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.36424
Policy Entropy: 1.24116
Value Function Loss: 6.29293

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06613
Policy Update Magnitude: 0.07617
Value Function Update Magnitude: 0.06119

Collected Steps per Second: 11,517.94744
Overall Steps per Second: 9,747.27032

Timestep Collection Time: 4.34296
Timestep Consumption Time: 0.78894
PPO Batch Consumption Time: 0.03630
Total Iteration Time: 5.13190

Cumulative Model Updates: 15,835
Cumulative Timesteps: 264,233,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.75279
Policy Entropy: 1.23394
Value Function Loss: 6.31008

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06115
Policy Update Magnitude: 0.08147
Value Function Update Magnitude: 0.06112

Collected Steps per Second: 11,371.76650
Overall Steps per Second: 9,718.82375

Timestep Collection Time: 4.39932
Timestep Consumption Time: 0.74822
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 5.14754

Cumulative Model Updates: 15,838
Cumulative Timesteps: 264,283,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 264283388...
Checkpoint 264283388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.24647
Policy Entropy: 1.23613
Value Function Loss: 6.38782

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06795
Policy Update Magnitude: 0.07893
Value Function Update Magnitude: 0.05655

Collected Steps per Second: 11,471.51617
Overall Steps per Second: 9,719.11724

Timestep Collection Time: 4.36071
Timestep Consumption Time: 0.78626
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 5.14697

Cumulative Model Updates: 15,841
Cumulative Timesteps: 264,333,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.54751
Policy Entropy: 1.23749
Value Function Loss: 6.44767

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.05423

Collected Steps per Second: 10,563.85400
Overall Steps per Second: 9,034.57061

Timestep Collection Time: 4.73331
Timestep Consumption Time: 0.80121
PPO Batch Consumption Time: 0.03620
Total Iteration Time: 5.53452

Cumulative Model Updates: 15,844
Cumulative Timesteps: 264,383,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 264383414...
Checkpoint 264383414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.93747
Policy Entropy: 1.23927
Value Function Loss: 6.29140

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06171
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.06337

Collected Steps per Second: 11,019.45827
Overall Steps per Second: 9,383.69721

Timestep Collection Time: 4.53961
Timestep Consumption Time: 0.79134
PPO Batch Consumption Time: 0.03534
Total Iteration Time: 5.33095

Cumulative Model Updates: 15,847
Cumulative Timesteps: 264,433,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.43381
Policy Entropy: 1.24607
Value Function Loss: 6.25484

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.06499

Collected Steps per Second: 10,743.43570
Overall Steps per Second: 9,183.02651

Timestep Collection Time: 4.65438
Timestep Consumption Time: 0.79089
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.44526

Cumulative Model Updates: 15,850
Cumulative Timesteps: 264,483,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 264483442...
Checkpoint 264483442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.36303
Policy Entropy: 1.23855
Value Function Loss: 6.17427

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.07390
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 10,897.52179
Overall Steps per Second: 9,486.35464

Timestep Collection Time: 4.58930
Timestep Consumption Time: 0.68269
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.27199

Cumulative Model Updates: 15,853
Cumulative Timesteps: 264,533,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.29807
Policy Entropy: 1.23740
Value Function Loss: 6.01344

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.07109
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 11,119.45917
Overall Steps per Second: 9,522.18582

Timestep Collection Time: 4.49752
Timestep Consumption Time: 0.75442
PPO Batch Consumption Time: 0.03639
Total Iteration Time: 5.25195

Cumulative Model Updates: 15,856
Cumulative Timesteps: 264,583,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 264583464...
Checkpoint 264583464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.11788
Policy Entropy: 1.24160
Value Function Loss: 5.89526

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 10,843.64734
Overall Steps per Second: 9,340.38769

Timestep Collection Time: 4.61210
Timestep Consumption Time: 0.74228
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 5.35438

Cumulative Model Updates: 15,859
Cumulative Timesteps: 264,633,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.51794
Policy Entropy: 1.24258
Value Function Loss: 5.86637

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.05610

Collected Steps per Second: 10,511.50920
Overall Steps per Second: 8,954.82017

Timestep Collection Time: 4.75954
Timestep Consumption Time: 0.82739
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 5.58694

Cumulative Model Updates: 15,862
Cumulative Timesteps: 264,683,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 264683506...
Checkpoint 264683506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.99089
Policy Entropy: 1.23154
Value Function Loss: 5.95683

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 10,835.50644
Overall Steps per Second: 9,388.28949

Timestep Collection Time: 4.61686
Timestep Consumption Time: 0.71169
PPO Batch Consumption Time: 0.03604
Total Iteration Time: 5.32855

Cumulative Model Updates: 15,865
Cumulative Timesteps: 264,733,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.36164
Policy Entropy: 1.23481
Value Function Loss: 5.79149

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.05181

Collected Steps per Second: 10,552.69219
Overall Steps per Second: 9,162.44211

Timestep Collection Time: 4.73813
Timestep Consumption Time: 0.71893
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 5.45706

Cumulative Model Updates: 15,868
Cumulative Timesteps: 264,783,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 264783532...
Checkpoint 264783532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.87488
Policy Entropy: 1.23188
Value Function Loss: 5.62405

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.04233

Collected Steps per Second: 10,759.02441
Overall Steps per Second: 9,207.65887

Timestep Collection Time: 4.64745
Timestep Consumption Time: 0.78303
PPO Batch Consumption Time: 0.03632
Total Iteration Time: 5.43048

Cumulative Model Updates: 15,871
Cumulative Timesteps: 264,833,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.93508
Policy Entropy: 1.22606
Value Function Loss: 5.66426

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.04542

Collected Steps per Second: 10,864.98641
Overall Steps per Second: 9,239.74044

Timestep Collection Time: 4.60415
Timestep Consumption Time: 0.80986
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.41400

Cumulative Model Updates: 15,874
Cumulative Timesteps: 264,883,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 264883558...
Checkpoint 264883558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.48229
Policy Entropy: 1.22620
Value Function Loss: 5.97186

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 10,370.29338
Overall Steps per Second: 8,846.66426

Timestep Collection Time: 4.82224
Timestep Consumption Time: 0.83052
PPO Batch Consumption Time: 0.03957
Total Iteration Time: 5.65275

Cumulative Model Updates: 15,877
Cumulative Timesteps: 264,933,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.49526
Policy Entropy: 1.23591
Value Function Loss: 5.92200

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06479
Policy Update Magnitude: 0.06977
Value Function Update Magnitude: 0.04187

Collected Steps per Second: 10,629.77383
Overall Steps per Second: 9,182.83152

Timestep Collection Time: 4.70621
Timestep Consumption Time: 0.74156
PPO Batch Consumption Time: 0.03791
Total Iteration Time: 5.44777

Cumulative Model Updates: 15,880
Cumulative Timesteps: 264,983,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 264983592...
Checkpoint 264983592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.68723
Policy Entropy: 1.23979
Value Function Loss: 5.91764

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.06111

Collected Steps per Second: 10,361.12253
Overall Steps per Second: 9,058.36877

Timestep Collection Time: 4.82805
Timestep Consumption Time: 0.69436
PPO Batch Consumption Time: 0.03769
Total Iteration Time: 5.52241

Cumulative Model Updates: 15,883
Cumulative Timesteps: 265,033,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.04125
Policy Entropy: 1.21241
Value Function Loss: 5.61209

Mean KL Divergence: 0.03411
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.08274
Value Function Update Magnitude: 0.05134

Collected Steps per Second: 10,380.73937
Overall Steps per Second: 8,917.17736

Timestep Collection Time: 4.81931
Timestep Consumption Time: 0.79099
PPO Batch Consumption Time: 0.03566
Total Iteration Time: 5.61030

Cumulative Model Updates: 15,886
Cumulative Timesteps: 265,083,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 265083644...
Checkpoint 265083644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.42328
Policy Entropy: 1.23410
Value Function Loss: 5.87243

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.16067
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.04155

Collected Steps per Second: 10,516.06225
Overall Steps per Second: 9,097.12564

Timestep Collection Time: 4.75748
Timestep Consumption Time: 0.74206
PPO Batch Consumption Time: 0.03461
Total Iteration Time: 5.49954

Cumulative Model Updates: 15,889
Cumulative Timesteps: 265,133,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.93993
Policy Entropy: 1.22828
Value Function Loss: 5.92248

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 10,820.68831
Overall Steps per Second: 9,242.24582

Timestep Collection Time: 4.62115
Timestep Consumption Time: 0.78923
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.41037

Cumulative Model Updates: 15,892
Cumulative Timesteps: 265,183,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 265183678...
Checkpoint 265183678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.89913
Policy Entropy: 1.24351
Value Function Loss: 6.13514

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.04845

Collected Steps per Second: 10,363.90657
Overall Steps per Second: 8,853.64499

Timestep Collection Time: 4.82714
Timestep Consumption Time: 0.82342
PPO Batch Consumption Time: 0.03826
Total Iteration Time: 5.65055

Cumulative Model Updates: 15,895
Cumulative Timesteps: 265,233,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.41715
Policy Entropy: 1.22816
Value Function Loss: 5.99709

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 10,969.76941
Overall Steps per Second: 9,486.69789

Timestep Collection Time: 4.56035
Timestep Consumption Time: 0.71293
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 5.27328

Cumulative Model Updates: 15,898
Cumulative Timesteps: 265,283,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 265283732...
Checkpoint 265283732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.26053
Policy Entropy: 1.23719
Value Function Loss: 5.98988

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.05711

Collected Steps per Second: 10,885.40968
Overall Steps per Second: 9,330.02491

Timestep Collection Time: 4.59569
Timestep Consumption Time: 0.76614
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.36183

Cumulative Model Updates: 15,901
Cumulative Timesteps: 265,333,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.70622
Policy Entropy: 1.23468
Value Function Loss: 6.01945

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.06333

Collected Steps per Second: 10,941.65611
Overall Steps per Second: 9,411.27777

Timestep Collection Time: 4.57189
Timestep Consumption Time: 0.74344
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.31532

Cumulative Model Updates: 15,904
Cumulative Timesteps: 265,383,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 265383782...
Checkpoint 265383782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.08277
Policy Entropy: 1.23830
Value Function Loss: 5.98863

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.05830
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 11,289.43915
Overall Steps per Second: 9,610.96829

Timestep Collection Time: 4.43087
Timestep Consumption Time: 0.77381
PPO Batch Consumption Time: 0.03901
Total Iteration Time: 5.20468

Cumulative Model Updates: 15,907
Cumulative Timesteps: 265,433,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.31302
Policy Entropy: 1.24506
Value Function Loss: 6.08970

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.07539
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 10,589.55721
Overall Steps per Second: 8,994.48014

Timestep Collection Time: 4.72239
Timestep Consumption Time: 0.83747
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.55985

Cumulative Model Updates: 15,910
Cumulative Timesteps: 265,483,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 265483812...
Checkpoint 265483812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.98150
Policy Entropy: 1.24911
Value Function Loss: 5.84044

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.07649
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 10,798.83242
Overall Steps per Second: 9,395.97737

Timestep Collection Time: 4.63050
Timestep Consumption Time: 0.69135
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 5.32185

Cumulative Model Updates: 15,913
Cumulative Timesteps: 265,533,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.36264
Policy Entropy: 1.22848
Value Function Loss: 5.86536

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.07090
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 10,957.84796
Overall Steps per Second: 9,365.86154

Timestep Collection Time: 4.56349
Timestep Consumption Time: 0.77569
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 5.33918

Cumulative Model Updates: 15,916
Cumulative Timesteps: 265,583,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 265583822...
Checkpoint 265583822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.51110
Policy Entropy: 1.25023
Value Function Loss: 6.01556

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 10,897.39328
Overall Steps per Second: 9,310.80708

Timestep Collection Time: 4.59046
Timestep Consumption Time: 0.78223
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 5.37268

Cumulative Model Updates: 15,919
Cumulative Timesteps: 265,633,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.66859
Policy Entropy: 1.24111
Value Function Loss: 6.26661

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.06747

Collected Steps per Second: 11,075.02652
Overall Steps per Second: 9,380.26991

Timestep Collection Time: 4.51701
Timestep Consumption Time: 0.81610
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.33311

Cumulative Model Updates: 15,922
Cumulative Timesteps: 265,683,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 265683872...
Checkpoint 265683872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.11629
Policy Entropy: 1.25742
Value Function Loss: 6.24951

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 10,970.14680
Overall Steps per Second: 9,411.42090

Timestep Collection Time: 4.55855
Timestep Consumption Time: 0.75499
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.31354

Cumulative Model Updates: 15,925
Cumulative Timesteps: 265,733,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.27370
Policy Entropy: 1.24754
Value Function Loss: 6.07140

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 10,309.22310
Overall Steps per Second: 9,072.85821

Timestep Collection Time: 4.85100
Timestep Consumption Time: 0.66105
PPO Batch Consumption Time: 0.03652
Total Iteration Time: 5.51204

Cumulative Model Updates: 15,928
Cumulative Timesteps: 265,783,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 265783890...
Checkpoint 265783890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.74305
Policy Entropy: 1.24614
Value Function Loss: 6.02718

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.08522
Value Function Update Magnitude: 0.05683

Collected Steps per Second: 10,680.28857
Overall Steps per Second: 9,100.96284

Timestep Collection Time: 4.68414
Timestep Consumption Time: 0.81286
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 5.49700

Cumulative Model Updates: 15,931
Cumulative Timesteps: 265,833,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.66607
Policy Entropy: 1.23878
Value Function Loss: 5.97890

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.08310
Value Function Update Magnitude: 0.05245

Collected Steps per Second: 10,621.30381
Overall Steps per Second: 9,156.70758

Timestep Collection Time: 4.70978
Timestep Consumption Time: 0.75332
PPO Batch Consumption Time: 0.03621
Total Iteration Time: 5.46310

Cumulative Model Updates: 15,934
Cumulative Timesteps: 265,883,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 265883942...
Checkpoint 265883942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.22179
Policy Entropy: 1.25089
Value Function Loss: 5.90590

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.07007
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 10,939.50228
Overall Steps per Second: 9,347.26992

Timestep Collection Time: 4.57096
Timestep Consumption Time: 0.77863
PPO Batch Consumption Time: 0.03760
Total Iteration Time: 5.34958

Cumulative Model Updates: 15,937
Cumulative Timesteps: 265,933,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.20514
Policy Entropy: 1.24049
Value Function Loss: 6.05129

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 10,789.02859
Overall Steps per Second: 9,238.04145

Timestep Collection Time: 4.63656
Timestep Consumption Time: 0.77844
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 5.41500

Cumulative Model Updates: 15,940
Cumulative Timesteps: 265,983,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 265983970...
Checkpoint 265983970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.17194
Policy Entropy: 1.23752
Value Function Loss: 5.83696

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.05862

Collected Steps per Second: 10,275.35077
Overall Steps per Second: 8,844.61795

Timestep Collection Time: 4.86874
Timestep Consumption Time: 0.78758
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 5.65632

Cumulative Model Updates: 15,943
Cumulative Timesteps: 266,033,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.63965
Policy Entropy: 1.23806
Value Function Loss: 5.72142

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 10,549.55074
Overall Steps per Second: 8,968.62530

Timestep Collection Time: 4.74181
Timestep Consumption Time: 0.83585
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.57767

Cumulative Model Updates: 15,946
Cumulative Timesteps: 266,084,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 266084022...
Checkpoint 266084022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.59089
Policy Entropy: 1.24141
Value Function Loss: 5.51026

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05467
Policy Update Magnitude: 0.07112
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 10,644.82510
Overall Steps per Second: 9,176.53959

Timestep Collection Time: 4.69881
Timestep Consumption Time: 0.75183
PPO Batch Consumption Time: 0.03631
Total Iteration Time: 5.45064

Cumulative Model Updates: 15,949
Cumulative Timesteps: 266,134,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.75805
Policy Entropy: 1.23745
Value Function Loss: 5.72921

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05841
Policy Update Magnitude: 0.06975
Value Function Update Magnitude: 0.05794

Collected Steps per Second: 10,891.20882
Overall Steps per Second: 9,294.62460

Timestep Collection Time: 4.59178
Timestep Consumption Time: 0.78875
PPO Batch Consumption Time: 0.03494
Total Iteration Time: 5.38053

Cumulative Model Updates: 15,952
Cumulative Timesteps: 266,184,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 266184050...
Checkpoint 266184050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.20285
Policy Entropy: 1.23023
Value Function Loss: 5.88484

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.05673

Collected Steps per Second: 10,330.83443
Overall Steps per Second: 8,910.13773

Timestep Collection Time: 4.84007
Timestep Consumption Time: 0.77174
PPO Batch Consumption Time: 0.03570
Total Iteration Time: 5.61181

Cumulative Model Updates: 15,955
Cumulative Timesteps: 266,234,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.34798
Policy Entropy: 1.23759
Value Function Loss: 5.84921

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06640
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.05255

Collected Steps per Second: 11,335.48443
Overall Steps per Second: 9,763.40173

Timestep Collection Time: 4.41093
Timestep Consumption Time: 0.71024
PPO Batch Consumption Time: 0.03585
Total Iteration Time: 5.12117

Cumulative Model Updates: 15,958
Cumulative Timesteps: 266,284,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 266284052...
Checkpoint 266284052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.32239
Policy Entropy: 1.23936
Value Function Loss: 6.11943

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.06356

Collected Steps per Second: 11,275.65626
Overall Steps per Second: 9,612.84890

Timestep Collection Time: 4.43699
Timestep Consumption Time: 0.76750
PPO Batch Consumption Time: 0.03637
Total Iteration Time: 5.20449

Cumulative Model Updates: 15,961
Cumulative Timesteps: 266,334,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.71740
Policy Entropy: 1.24836
Value Function Loss: 6.22431

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.07396

Collected Steps per Second: 11,620.20625
Overall Steps per Second: 9,865.97176

Timestep Collection Time: 4.30388
Timestep Consumption Time: 0.76526
PPO Batch Consumption Time: 0.03563
Total Iteration Time: 5.06914

Cumulative Model Updates: 15,964
Cumulative Timesteps: 266,384,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 266384094...
Checkpoint 266384094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.05466
Policy Entropy: 1.24214
Value Function Loss: 6.25811

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.05943
Value Function Update Magnitude: 0.06272

Collected Steps per Second: 11,945.17100
Overall Steps per Second: 10,070.37541

Timestep Collection Time: 4.18579
Timestep Consumption Time: 0.77927
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 4.96506

Cumulative Model Updates: 15,967
Cumulative Timesteps: 266,434,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.87198
Policy Entropy: 1.25446
Value Function Loss: 6.23630

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 11,654.56380
Overall Steps per Second: 9,833.79096

Timestep Collection Time: 4.29137
Timestep Consumption Time: 0.79457
PPO Batch Consumption Time: 0.03550
Total Iteration Time: 5.08593

Cumulative Model Updates: 15,970
Cumulative Timesteps: 266,484,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 266484108...
Checkpoint 266484108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.29400
Policy Entropy: 1.25125
Value Function Loss: 6.00550

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.06653

Collected Steps per Second: 11,681.82773
Overall Steps per Second: 10,011.44116

Timestep Collection Time: 4.28169
Timestep Consumption Time: 0.71439
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 4.99608

Cumulative Model Updates: 15,973
Cumulative Timesteps: 266,534,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.22276
Policy Entropy: 1.25186
Value Function Loss: 6.01987

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 11,156.85034
Overall Steps per Second: 9,468.51451

Timestep Collection Time: 4.48370
Timestep Consumption Time: 0.79949
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 5.28319

Cumulative Model Updates: 15,976
Cumulative Timesteps: 266,584,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 266584150...
Checkpoint 266584150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.86909
Policy Entropy: 1.24899
Value Function Loss: 5.91912

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 10,499.62324
Overall Steps per Second: 9,039.28777

Timestep Collection Time: 4.76360
Timestep Consumption Time: 0.76958
PPO Batch Consumption Time: 0.03564
Total Iteration Time: 5.53318

Cumulative Model Updates: 15,979
Cumulative Timesteps: 266,634,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.46302
Policy Entropy: 1.24393
Value Function Loss: 6.05341

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 10,987.81715
Overall Steps per Second: 9,361.73971

Timestep Collection Time: 4.55177
Timestep Consumption Time: 0.79061
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 5.34238

Cumulative Model Updates: 15,982
Cumulative Timesteps: 266,684,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 266684180...
Checkpoint 266684180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.81056
Policy Entropy: 1.22944
Value Function Loss: 6.04138

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 11,075.63137
Overall Steps per Second: 9,447.86548

Timestep Collection Time: 4.51694
Timestep Consumption Time: 0.77822
PPO Batch Consumption Time: 0.03559
Total Iteration Time: 5.29516

Cumulative Model Updates: 15,985
Cumulative Timesteps: 266,734,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.41205
Policy Entropy: 1.23135
Value Function Loss: 5.91484

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 10,979.97194
Overall Steps per Second: 9,465.66055

Timestep Collection Time: 4.55447
Timestep Consumption Time: 0.72862
PPO Batch Consumption Time: 0.03670
Total Iteration Time: 5.28310

Cumulative Model Updates: 15,988
Cumulative Timesteps: 266,784,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 266784216...
Checkpoint 266784216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.83814
Policy Entropy: 1.23803
Value Function Loss: 5.71239

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.08543

Collected Steps per Second: 10,953.18677
Overall Steps per Second: 9,380.32730

Timestep Collection Time: 4.56616
Timestep Consumption Time: 0.76564
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 5.33180

Cumulative Model Updates: 15,991
Cumulative Timesteps: 266,834,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.75227
Policy Entropy: 1.23968
Value Function Loss: 5.85789

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.09076

Collected Steps per Second: 10,190.30933
Overall Steps per Second: 8,802.83844

Timestep Collection Time: 4.90662
Timestep Consumption Time: 0.77336
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 5.67999

Cumulative Model Updates: 15,994
Cumulative Timesteps: 266,884,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 266884230...
Checkpoint 266884230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.62772
Policy Entropy: 1.23424
Value Function Loss: 5.85606

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 10,659.11580
Overall Steps per Second: 9,151.19978

Timestep Collection Time: 4.69138
Timestep Consumption Time: 0.77304
PPO Batch Consumption Time: 0.03454
Total Iteration Time: 5.46442

Cumulative Model Updates: 15,997
Cumulative Timesteps: 266,934,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.58438
Policy Entropy: 1.24582
Value Function Loss: 6.01356

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.07610

Collected Steps per Second: 10,510.06493
Overall Steps per Second: 9,068.76025

Timestep Collection Time: 4.75849
Timestep Consumption Time: 0.75627
PPO Batch Consumption Time: 0.03748
Total Iteration Time: 5.51476

Cumulative Model Updates: 16,000
Cumulative Timesteps: 266,984,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 266984248...
Checkpoint 266984248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.24876
Policy Entropy: 1.24210
Value Function Loss: 5.78356

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.06886
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 10,783.46064
Overall Steps per Second: 9,420.86261

Timestep Collection Time: 4.63747
Timestep Consumption Time: 0.67075
PPO Batch Consumption Time: 0.03689
Total Iteration Time: 5.30822

Cumulative Model Updates: 16,003
Cumulative Timesteps: 267,034,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.41025
Policy Entropy: 1.23536
Value Function Loss: 5.97460

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 10,665.10064
Overall Steps per Second: 9,133.41124

Timestep Collection Time: 4.69025
Timestep Consumption Time: 0.78656
PPO Batch Consumption Time: 0.03896
Total Iteration Time: 5.47681

Cumulative Model Updates: 16,006
Cumulative Timesteps: 267,084,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 267084278...
Checkpoint 267084278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.08339
Policy Entropy: 1.24280
Value Function Loss: 5.91655

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.06674
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 10,554.07568
Overall Steps per Second: 9,104.14274

Timestep Collection Time: 4.73921
Timestep Consumption Time: 0.75477
PPO Batch Consumption Time: 0.03547
Total Iteration Time: 5.49398

Cumulative Model Updates: 16,009
Cumulative Timesteps: 267,134,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.15314
Policy Entropy: 1.24948
Value Function Loss: 5.86886

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07859

Collected Steps per Second: 10,466.74129
Overall Steps per Second: 8,950.38238

Timestep Collection Time: 4.77914
Timestep Consumption Time: 0.80967
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 5.58881

Cumulative Model Updates: 16,012
Cumulative Timesteps: 267,184,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 267184318...
Checkpoint 267184318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.05868
Policy Entropy: 1.24036
Value Function Loss: 5.52954

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 10,459.14973
Overall Steps per Second: 8,995.07244

Timestep Collection Time: 4.78127
Timestep Consumption Time: 0.77822
PPO Batch Consumption Time: 0.03792
Total Iteration Time: 5.55949

Cumulative Model Updates: 16,015
Cumulative Timesteps: 267,234,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.94478
Policy Entropy: 1.22651
Value Function Loss: 5.63370

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.06898
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 10,822.33401
Overall Steps per Second: 9,388.81594

Timestep Collection Time: 4.62137
Timestep Consumption Time: 0.70561
PPO Batch Consumption Time: 0.03787
Total Iteration Time: 5.32698

Cumulative Model Updates: 16,018
Cumulative Timesteps: 267,284,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 267284340...
Checkpoint 267284340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.19682
Policy Entropy: 1.23044
Value Function Loss: 5.70088

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.07237

Collected Steps per Second: 10,586.88070
Overall Steps per Second: 9,043.05347

Timestep Collection Time: 4.72528
Timestep Consumption Time: 0.80670
PPO Batch Consumption Time: 0.03613
Total Iteration Time: 5.53198

Cumulative Model Updates: 16,021
Cumulative Timesteps: 267,334,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.19971
Policy Entropy: 1.23520
Value Function Loss: 5.89236

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 10,629.33175
Overall Steps per Second: 9,132.34372

Timestep Collection Time: 4.70566
Timestep Consumption Time: 0.77136
PPO Batch Consumption Time: 0.03484
Total Iteration Time: 5.47702

Cumulative Model Updates: 16,024
Cumulative Timesteps: 267,384,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 267384384...
Checkpoint 267384384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.56684
Policy Entropy: 1.23943
Value Function Loss: 5.90706

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.06123

Collected Steps per Second: 10,845.11626
Overall Steps per Second: 9,241.92033

Timestep Collection Time: 4.61258
Timestep Consumption Time: 0.80014
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 5.41273

Cumulative Model Updates: 16,027
Cumulative Timesteps: 267,434,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.89425
Policy Entropy: 1.24127
Value Function Loss: 5.91197

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 11,298.78093
Overall Steps per Second: 9,669.04202

Timestep Collection Time: 4.42756
Timestep Consumption Time: 0.74627
PPO Batch Consumption Time: 0.03823
Total Iteration Time: 5.17383

Cumulative Model Updates: 16,030
Cumulative Timesteps: 267,484,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 267484434...
Checkpoint 267484434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.41043
Policy Entropy: 1.24817
Value Function Loss: 5.77958

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05318
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 11,116.08690
Overall Steps per Second: 9,688.01025

Timestep Collection Time: 4.50068
Timestep Consumption Time: 0.66343
PPO Batch Consumption Time: 0.03703
Total Iteration Time: 5.16412

Cumulative Model Updates: 16,033
Cumulative Timesteps: 267,534,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.93251
Policy Entropy: 1.24871
Value Function Loss: 5.61114

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05605
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11,266.89257
Overall Steps per Second: 9,511.97293

Timestep Collection Time: 4.44027
Timestep Consumption Time: 0.81921
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 5.25948

Cumulative Model Updates: 16,036
Cumulative Timesteps: 267,584,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 267584492...
Checkpoint 267584492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.13805
Policy Entropy: 1.24947
Value Function Loss: 5.61707

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05496
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.09135

Collected Steps per Second: 11,052.97689
Overall Steps per Second: 9,470.81118

Timestep Collection Time: 4.52602
Timestep Consumption Time: 0.75610
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 5.28212

Cumulative Model Updates: 16,039
Cumulative Timesteps: 267,634,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.68963
Policy Entropy: 1.24574
Value Function Loss: 5.64208

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05658
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 11,404.86186
Overall Steps per Second: 9,641.04160

Timestep Collection Time: 4.38550
Timestep Consumption Time: 0.80232
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.18782

Cumulative Model Updates: 16,042
Cumulative Timesteps: 267,684,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 267684534...
Checkpoint 267684534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.28381
Policy Entropy: 1.24669
Value Function Loss: 5.65009

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.07551
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 10,539.07586
Overall Steps per Second: 9,052.54592

Timestep Collection Time: 4.74672
Timestep Consumption Time: 0.77946
PPO Batch Consumption Time: 0.03756
Total Iteration Time: 5.52618

Cumulative Model Updates: 16,045
Cumulative Timesteps: 267,734,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.23964
Policy Entropy: 1.24822
Value Function Loss: 5.43839

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.06067

Collected Steps per Second: 10,772.17690
Overall Steps per Second: 9,378.92823

Timestep Collection Time: 4.64437
Timestep Consumption Time: 0.68993
PPO Batch Consumption Time: 0.03753
Total Iteration Time: 5.33430

Cumulative Model Updates: 16,048
Cumulative Timesteps: 267,784,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 267784590...
Checkpoint 267784590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.95104
Policy Entropy: 1.25043
Value Function Loss: 5.54025

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07150
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.05433

Collected Steps per Second: 10,982.31909
Overall Steps per Second: 9,373.15455

Timestep Collection Time: 4.55496
Timestep Consumption Time: 0.78199
PPO Batch Consumption Time: 0.03702
Total Iteration Time: 5.33694

Cumulative Model Updates: 16,051
Cumulative Timesteps: 267,834,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.06094
Policy Entropy: 1.23994
Value Function Loss: 5.41745

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 10,991.37708
Overall Steps per Second: 9,357.67691

Timestep Collection Time: 4.55102
Timestep Consumption Time: 0.79454
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 5.34556

Cumulative Model Updates: 16,054
Cumulative Timesteps: 267,884,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 267884636...
Checkpoint 267884636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.38954
Policy Entropy: 1.24022
Value Function Loss: 5.53603

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.04556

Collected Steps per Second: 11,184.55336
Overall Steps per Second: 9,551.67841

Timestep Collection Time: 4.47045
Timestep Consumption Time: 0.76423
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 5.23468

Cumulative Model Updates: 16,057
Cumulative Timesteps: 267,934,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.85749
Policy Entropy: 1.23717
Value Function Loss: 5.50189

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 10,856.51757
Overall Steps per Second: 9,243.57668

Timestep Collection Time: 4.60553
Timestep Consumption Time: 0.80363
PPO Batch Consumption Time: 0.03599
Total Iteration Time: 5.40916

Cumulative Model Updates: 16,060
Cumulative Timesteps: 267,984,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 267984636...
Checkpoint 267984636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.27374
Policy Entropy: 1.24455
Value Function Loss: 5.80406

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 10,458.17654
Overall Steps per Second: 9,127.59709

Timestep Collection Time: 4.78363
Timestep Consumption Time: 0.69734
PPO Batch Consumption Time: 0.03693
Total Iteration Time: 5.48096

Cumulative Model Updates: 16,063
Cumulative Timesteps: 268,034,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.39734
Policy Entropy: 1.24793
Value Function Loss: 5.73198

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 10,549.42845
Overall Steps per Second: 9,050.84869

Timestep Collection Time: 4.74263
Timestep Consumption Time: 0.78525
PPO Batch Consumption Time: 0.03900
Total Iteration Time: 5.52788

Cumulative Model Updates: 16,066
Cumulative Timesteps: 268,084,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 268084696...
Checkpoint 268084696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.57788
Policy Entropy: 1.25063
Value Function Loss: 5.47210

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 10,938.52802
Overall Steps per Second: 9,316.35084

Timestep Collection Time: 4.57356
Timestep Consumption Time: 0.79635
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 5.36991

Cumulative Model Updates: 16,069
Cumulative Timesteps: 268,134,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.09354
Policy Entropy: 1.23323
Value Function Loss: 5.39059

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 11,064.16457
Overall Steps per Second: 9,455.20010

Timestep Collection Time: 4.52072
Timestep Consumption Time: 0.76928
PPO Batch Consumption Time: 0.03747
Total Iteration Time: 5.29000

Cumulative Model Updates: 16,072
Cumulative Timesteps: 268,184,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 268184742...
Checkpoint 268184742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.37302
Policy Entropy: 1.22997
Value Function Loss: 5.53784

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 10,593.30266
Overall Steps per Second: 9,103.56522

Timestep Collection Time: 4.72280
Timestep Consumption Time: 0.77285
PPO Batch Consumption Time: 0.03443
Total Iteration Time: 5.49565

Cumulative Model Updates: 16,075
Cumulative Timesteps: 268,234,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.16144
Policy Entropy: 1.24336
Value Function Loss: 5.78797

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 10,172.04548
Overall Steps per Second: 8,901.09487

Timestep Collection Time: 4.91759
Timestep Consumption Time: 0.70216
PPO Batch Consumption Time: 0.03818
Total Iteration Time: 5.61976

Cumulative Model Updates: 16,078
Cumulative Timesteps: 268,284,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 268284794...
Checkpoint 268284794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.80585
Policy Entropy: 1.25251
Value Function Loss: 5.90173

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.04413

Collected Steps per Second: 10,601.74991
Overall Steps per Second: 9,103.92896

Timestep Collection Time: 4.71677
Timestep Consumption Time: 0.77602
PPO Batch Consumption Time: 0.03627
Total Iteration Time: 5.49279

Cumulative Model Updates: 16,081
Cumulative Timesteps: 268,334,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.20661
Policy Entropy: 1.23262
Value Function Loss: 5.70401

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.08059
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 10,706.37553
Overall Steps per Second: 9,209.37477

Timestep Collection Time: 4.67273
Timestep Consumption Time: 0.75956
PPO Batch Consumption Time: 0.03768
Total Iteration Time: 5.43229

Cumulative Model Updates: 16,084
Cumulative Timesteps: 268,384,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 268384828...
Checkpoint 268384828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.42288
Policy Entropy: 1.24792
Value Function Loss: 5.58693

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 10,686.81737
Overall Steps per Second: 9,127.11978

Timestep Collection Time: 4.67904
Timestep Consumption Time: 0.79958
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 5.47862

Cumulative Model Updates: 16,087
Cumulative Timesteps: 268,434,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.41619
Policy Entropy: 1.23248
Value Function Loss: 5.73073

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.07247
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 10,484.05224
Overall Steps per Second: 8,985.69286

Timestep Collection Time: 4.77144
Timestep Consumption Time: 0.79563
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 5.56707

Cumulative Model Updates: 16,090
Cumulative Timesteps: 268,484,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 268484856...
Checkpoint 268484856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.95417
Policy Entropy: 1.23376
Value Function Loss: 5.80803

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.07216
Value Function Update Magnitude: 0.05099

Collected Steps per Second: 11,848.66112
Overall Steps per Second: 10,080.18086

Timestep Collection Time: 4.22242
Timestep Consumption Time: 0.74079
PPO Batch Consumption Time: 0.03973
Total Iteration Time: 4.96320

Cumulative Model Updates: 16,093
Cumulative Timesteps: 268,534,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.97477
Policy Entropy: 1.23687
Value Function Loss: 5.82868

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 11,555.07112
Overall Steps per Second: 9,790.68318

Timestep Collection Time: 4.32797
Timestep Consumption Time: 0.77995
PPO Batch Consumption Time: 0.03540
Total Iteration Time: 5.10792

Cumulative Model Updates: 16,096
Cumulative Timesteps: 268,584,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 268584896...
Checkpoint 268584896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.08517
Policy Entropy: 1.23767
Value Function Loss: 5.62394

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.05128

Collected Steps per Second: 11,349.60452
Overall Steps per Second: 9,540.29226

Timestep Collection Time: 4.40597
Timestep Consumption Time: 0.83559
PPO Batch Consumption Time: 0.03479
Total Iteration Time: 5.24156

Cumulative Model Updates: 16,099
Cumulative Timesteps: 268,634,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.63739
Policy Entropy: 1.24054
Value Function Loss: 5.34841

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 12,115.22728
Overall Steps per Second: 10,167.17590

Timestep Collection Time: 4.12902
Timestep Consumption Time: 0.79113
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 4.92015

Cumulative Model Updates: 16,102
Cumulative Timesteps: 268,684,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 268684926...
Checkpoint 268684926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.95020
Policy Entropy: 1.22223
Value Function Loss: 5.46943

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 11,648.46534
Overall Steps per Second: 9,861.60902

Timestep Collection Time: 4.29413
Timestep Consumption Time: 0.77807
PPO Batch Consumption Time: 0.03537
Total Iteration Time: 5.07219

Cumulative Model Updates: 16,105
Cumulative Timesteps: 268,734,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.65369
Policy Entropy: 1.23870
Value Function Loss: 5.64211

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 11,838.73550
Overall Steps per Second: 10,180.71792

Timestep Collection Time: 4.22511
Timestep Consumption Time: 0.68810
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 4.91321

Cumulative Model Updates: 16,108
Cumulative Timesteps: 268,784,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 268784966...
Checkpoint 268784966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.16247
Policy Entropy: 1.22551
Value Function Loss: 5.76786

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.05173

Collected Steps per Second: 10,738.07218
Overall Steps per Second: 9,125.74362

Timestep Collection Time: 4.65707
Timestep Consumption Time: 0.82281
PPO Batch Consumption Time: 0.03862
Total Iteration Time: 5.47988

Cumulative Model Updates: 16,111
Cumulative Timesteps: 268,834,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.42419
Policy Entropy: 1.22071
Value Function Loss: 5.82687

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.05427

Collected Steps per Second: 10,891.73957
Overall Steps per Second: 9,322.99393

Timestep Collection Time: 4.59265
Timestep Consumption Time: 0.77279
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.36544

Cumulative Model Updates: 16,114
Cumulative Timesteps: 268,884,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 268884996...
Checkpoint 268884996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.47543
Policy Entropy: 1.22308
Value Function Loss: 5.85475

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.05442

Collected Steps per Second: 10,652.72017
Overall Steps per Second: 9,278.34029

Timestep Collection Time: 4.69589
Timestep Consumption Time: 0.69559
PPO Batch Consumption Time: 0.03633
Total Iteration Time: 5.39148

Cumulative Model Updates: 16,117
Cumulative Timesteps: 268,935,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.45832
Policy Entropy: 1.24362
Value Function Loss: 6.02234

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.04503

Collected Steps per Second: 10,925.92187
Overall Steps per Second: 9,304.80193

Timestep Collection Time: 4.57920
Timestep Consumption Time: 0.79781
PPO Batch Consumption Time: 0.03581
Total Iteration Time: 5.37701

Cumulative Model Updates: 16,120
Cumulative Timesteps: 268,985,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 268985052...
Checkpoint 268985052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.37111
Policy Entropy: 1.23492
Value Function Loss: 5.89686

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.03805

Collected Steps per Second: 10,741.71335
Overall Steps per Second: 9,356.09898

Timestep Collection Time: 4.65494
Timestep Consumption Time: 0.68938
PPO Batch Consumption Time: 0.03635
Total Iteration Time: 5.34432

Cumulative Model Updates: 16,123
Cumulative Timesteps: 269,035,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.49182
Policy Entropy: 1.23415
Value Function Loss: 5.69881

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.04993

Collected Steps per Second: 10,980.80007
Overall Steps per Second: 9,381.65835

Timestep Collection Time: 4.55504
Timestep Consumption Time: 0.77643
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.33147

Cumulative Model Updates: 16,126
Cumulative Timesteps: 269,085,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 269085072...
Checkpoint 269085072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.15232
Policy Entropy: 1.23027
Value Function Loss: 5.55409

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 10,022.36722
Overall Steps per Second: 8,691.72481

Timestep Collection Time: 4.99164
Timestep Consumption Time: 0.76418
PPO Batch Consumption Time: 0.03856
Total Iteration Time: 5.75582

Cumulative Model Updates: 16,129
Cumulative Timesteps: 269,135,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.57268
Policy Entropy: 1.23064
Value Function Loss: 5.41675

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.05517

Collected Steps per Second: 10,712.85599
Overall Steps per Second: 9,356.99969

Timestep Collection Time: 4.66897
Timestep Consumption Time: 0.67655
PPO Batch Consumption Time: 0.03695
Total Iteration Time: 5.34552

Cumulative Model Updates: 16,132
Cumulative Timesteps: 269,185,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 269185118...
Checkpoint 269185118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.09002
Policy Entropy: 1.24421
Value Function Loss: 5.68081

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.05296

Collected Steps per Second: 10,858.94606
Overall Steps per Second: 9,231.95818

Timestep Collection Time: 4.60652
Timestep Consumption Time: 0.81183
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 5.41835

Cumulative Model Updates: 16,135
Cumulative Timesteps: 269,235,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.97584
Policy Entropy: 1.24577
Value Function Loss: 5.81405

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 10,694.77291
Overall Steps per Second: 9,299.13437

Timestep Collection Time: 4.67556
Timestep Consumption Time: 0.70172
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 5.37727

Cumulative Model Updates: 16,138
Cumulative Timesteps: 269,285,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 269285144...
Checkpoint 269285144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.87362
Policy Entropy: 1.25079
Value Function Loss: 6.03999

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 9,836.40334
Overall Steps per Second: 8,425.27200

Timestep Collection Time: 5.08641
Timestep Consumption Time: 0.85191
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 5.93832

Cumulative Model Updates: 16,141
Cumulative Timesteps: 269,335,176

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.56881
Policy Entropy: 1.23940
Value Function Loss: 6.06612

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.08460

Collected Steps per Second: 10,491.30107
Overall Steps per Second: 9,028.96232

Timestep Collection Time: 4.76738
Timestep Consumption Time: 0.77213
PPO Batch Consumption Time: 0.03457
Total Iteration Time: 5.53951

Cumulative Model Updates: 16,144
Cumulative Timesteps: 269,385,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 269385192...
Checkpoint 269385192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.08120
Policy Entropy: 1.24101
Value Function Loss: 6.15005

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 10,603.90613
Overall Steps per Second: 9,065.03869

Timestep Collection Time: 4.71619
Timestep Consumption Time: 0.80061
PPO Batch Consumption Time: 0.03334
Total Iteration Time: 5.51680

Cumulative Model Updates: 16,147
Cumulative Timesteps: 269,435,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.81628
Policy Entropy: 1.23987
Value Function Loss: 5.99228

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 10,679.04114
Overall Steps per Second: 9,195.19819

Timestep Collection Time: 4.68207
Timestep Consumption Time: 0.75555
PPO Batch Consumption Time: 0.03386
Total Iteration Time: 5.43762

Cumulative Model Updates: 16,150
Cumulative Timesteps: 269,485,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 269485202...
Checkpoint 269485202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.97511
Policy Entropy: 1.23820
Value Function Loss: 5.99692

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 10,579.45045
Overall Steps per Second: 9,232.28980

Timestep Collection Time: 4.72652
Timestep Consumption Time: 0.68969
PPO Batch Consumption Time: 0.03663
Total Iteration Time: 5.41621

Cumulative Model Updates: 16,153
Cumulative Timesteps: 269,535,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.30214
Policy Entropy: 1.23612
Value Function Loss: 5.79875

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.06489

Collected Steps per Second: 10,616.38642
Overall Steps per Second: 9,107.01436

Timestep Collection Time: 4.71064
Timestep Consumption Time: 0.78073
PPO Batch Consumption Time: 0.03832
Total Iteration Time: 5.49137

Cumulative Model Updates: 16,156
Cumulative Timesteps: 269,585,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 269585216...
Checkpoint 269585216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.19817
Policy Entropy: 1.23721
Value Function Loss: 6.16580

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 10,960.58398
Overall Steps per Second: 9,399.25221

Timestep Collection Time: 4.56198
Timestep Consumption Time: 0.75780
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 5.31978

Cumulative Model Updates: 16,159
Cumulative Timesteps: 269,635,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.15876
Policy Entropy: 1.23202
Value Function Loss: 6.08725

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.07965

Collected Steps per Second: 10,741.17524
Overall Steps per Second: 9,196.90355

Timestep Collection Time: 4.65610
Timestep Consumption Time: 0.78182
PPO Batch Consumption Time: 0.03767
Total Iteration Time: 5.43792

Cumulative Model Updates: 16,162
Cumulative Timesteps: 269,685,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 269685230...
Checkpoint 269685230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.56570
Policy Entropy: 1.22377
Value Function Loss: 5.96381

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.06809

Collected Steps per Second: 10,872.79068
Overall Steps per Second: 9,320.24000

Timestep Collection Time: 4.60029
Timestep Consumption Time: 0.76631
PPO Batch Consumption Time: 0.03796
Total Iteration Time: 5.36660

Cumulative Model Updates: 16,165
Cumulative Timesteps: 269,735,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.42185
Policy Entropy: 1.22633
Value Function Loss: 5.83773

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 11,047.95404
Overall Steps per Second: 9,633.00092

Timestep Collection Time: 4.52735
Timestep Consumption Time: 0.66501
PPO Batch Consumption Time: 0.03655
Total Iteration Time: 5.19236

Cumulative Model Updates: 16,168
Cumulative Timesteps: 269,785,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 269785266...
Checkpoint 269785266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.84113
Policy Entropy: 1.23091
Value Function Loss: 5.92099

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 11,186.95392
Overall Steps per Second: 9,544.30621

Timestep Collection Time: 4.47217
Timestep Consumption Time: 0.76970
PPO Batch Consumption Time: 0.03582
Total Iteration Time: 5.24187

Cumulative Model Updates: 16,171
Cumulative Timesteps: 269,835,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.25465
Policy Entropy: 1.23355
Value Function Loss: 6.00900

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 10,812.19367
Overall Steps per Second: 9,282.75108

Timestep Collection Time: 4.62496
Timestep Consumption Time: 0.76202
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.38698

Cumulative Model Updates: 16,174
Cumulative Timesteps: 269,885,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 269885302...
Checkpoint 269885302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.90104
Policy Entropy: 1.23539
Value Function Loss: 6.17037

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.05863

Collected Steps per Second: 10,917.22020
Overall Steps per Second: 9,174.26987

Timestep Collection Time: 4.58249
Timestep Consumption Time: 0.87059
PPO Batch Consumption Time: 0.04049
Total Iteration Time: 5.45308

Cumulative Model Updates: 16,177
Cumulative Timesteps: 269,935,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.38520
Policy Entropy: 1.23532
Value Function Loss: 6.01480

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.05659

Collected Steps per Second: 10,968.39629
Overall Steps per Second: 9,375.84233

Timestep Collection Time: 4.55873
Timestep Consumption Time: 0.77433
PPO Batch Consumption Time: 0.03694
Total Iteration Time: 5.33307

Cumulative Model Updates: 16,180
Cumulative Timesteps: 269,985,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 269985332...
Checkpoint 269985332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.42066
Policy Entropy: 1.23797
Value Function Loss: 6.37983

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.04733

Collected Steps per Second: 11,006.22036
Overall Steps per Second: 9,573.48210

Timestep Collection Time: 4.54525
Timestep Consumption Time: 0.68023
PPO Batch Consumption Time: 0.03715
Total Iteration Time: 5.22548

Cumulative Model Updates: 16,183
Cumulative Timesteps: 270,035,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.95566
Policy Entropy: 1.22789
Value Function Loss: 6.05782

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.04526

Collected Steps per Second: 11,023.80601
Overall Steps per Second: 9,340.99159

Timestep Collection Time: 4.53782
Timestep Consumption Time: 0.81750
PPO Batch Consumption Time: 0.03654
Total Iteration Time: 5.35532

Cumulative Model Updates: 16,186
Cumulative Timesteps: 270,085,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 270085382...
Checkpoint 270085382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.20302
Policy Entropy: 1.23256
Value Function Loss: 6.20424

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 11,150.13738
Overall Steps per Second: 9,455.45506

Timestep Collection Time: 4.48533
Timestep Consumption Time: 0.80390
PPO Batch Consumption Time: 0.04536
Total Iteration Time: 5.28922

Cumulative Model Updates: 16,189
Cumulative Timesteps: 270,135,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.14550
Policy Entropy: 1.23300
Value Function Loss: 5.71067

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 11,296.33546
Overall Steps per Second: 9,652.38299

Timestep Collection Time: 4.42781
Timestep Consumption Time: 0.75413
PPO Batch Consumption Time: 0.03668
Total Iteration Time: 5.18193

Cumulative Model Updates: 16,192
Cumulative Timesteps: 270,185,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 270185412...
Checkpoint 270185412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.85246
Policy Entropy: 1.23890
Value Function Loss: 5.78607

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 10,097.92512
Overall Steps per Second: 8,748.62400

Timestep Collection Time: 4.95230
Timestep Consumption Time: 0.76379
PPO Batch Consumption Time: 0.03850
Total Iteration Time: 5.71610

Cumulative Model Updates: 16,195
Cumulative Timesteps: 270,235,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.52635
Policy Entropy: 1.23427
Value Function Loss: 5.84847

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 10,767.96942
Overall Steps per Second: 9,367.35030

Timestep Collection Time: 4.64544
Timestep Consumption Time: 0.69459
PPO Batch Consumption Time: 0.03838
Total Iteration Time: 5.34004

Cumulative Model Updates: 16,198
Cumulative Timesteps: 270,285,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 270285442...
Checkpoint 270285442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.90773
Policy Entropy: 1.23190
Value Function Loss: 5.99239

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.06910

Collected Steps per Second: 10,912.75999
Overall Steps per Second: 9,338.48723

Timestep Collection Time: 4.58326
Timestep Consumption Time: 0.77264
PPO Batch Consumption Time: 0.03571
Total Iteration Time: 5.35590

Cumulative Model Updates: 16,201
Cumulative Timesteps: 270,335,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.04096
Policy Entropy: 1.23229
Value Function Loss: 5.87959

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.08293
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 10,687.50978
Overall Steps per Second: 9,211.76989

Timestep Collection Time: 4.68004
Timestep Consumption Time: 0.74975
PPO Batch Consumption Time: 0.03765
Total Iteration Time: 5.42979

Cumulative Model Updates: 16,204
Cumulative Timesteps: 270,385,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 270385476...
Checkpoint 270385476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.68893
Policy Entropy: 1.23215
Value Function Loss: 5.74418

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.07028
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 10,840.46638
Overall Steps per Second: 9,287.04826

Timestep Collection Time: 4.61493
Timestep Consumption Time: 0.77193
PPO Batch Consumption Time: 0.03810
Total Iteration Time: 5.38686

Cumulative Model Updates: 16,207
Cumulative Timesteps: 270,435,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.60731
Policy Entropy: 1.23195
Value Function Loss: 5.95181

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.07919
Value Function Update Magnitude: 0.06691

Collected Steps per Second: 10,581.45284
Overall Steps per Second: 8,975.07239

Timestep Collection Time: 4.72808
Timestep Consumption Time: 0.84624
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 5.57433

Cumulative Model Updates: 16,210
Cumulative Timesteps: 270,485,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 270485534...
Checkpoint 270485534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.61799
Policy Entropy: 1.22110
Value Function Loss: 5.98660

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.07864
Value Function Update Magnitude: 0.06093

Collected Steps per Second: 10,281.12172
Overall Steps per Second: 9,029.54143

Timestep Collection Time: 4.86601
Timestep Consumption Time: 0.67447
PPO Batch Consumption Time: 0.03905
Total Iteration Time: 5.54048

Cumulative Model Updates: 16,213
Cumulative Timesteps: 270,535,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.84703
Policy Entropy: 1.21985
Value Function Loss: 5.85274

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.08129
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 10,673.00097
Overall Steps per Second: 9,167.88764

Timestep Collection Time: 4.68678
Timestep Consumption Time: 0.76944
PPO Batch Consumption Time: 0.03746
Total Iteration Time: 5.45622

Cumulative Model Updates: 16,216
Cumulative Timesteps: 270,585,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 270585584...
Checkpoint 270585584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.90508
Policy Entropy: 1.22980
Value Function Loss: 5.71957

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.06882

Collected Steps per Second: 10,406.73705
Overall Steps per Second: 8,947.23401

Timestep Collection Time: 4.80727
Timestep Consumption Time: 0.78418
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.59145

Cumulative Model Updates: 16,219
Cumulative Timesteps: 270,635,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.52330
Policy Entropy: 1.23814
Value Function Loss: 5.53687

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 10,672.14892
Overall Steps per Second: 9,146.23506

Timestep Collection Time: 4.68790
Timestep Consumption Time: 0.78211
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 5.47001

Cumulative Model Updates: 16,222
Cumulative Timesteps: 270,685,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 270685642...
Checkpoint 270685642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.44258
Policy Entropy: 1.23023
Value Function Loss: 5.80356

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.07208

Collected Steps per Second: 11,068.40614
Overall Steps per Second: 9,452.19721

Timestep Collection Time: 4.51881
Timestep Consumption Time: 0.77266
PPO Batch Consumption Time: 0.03665
Total Iteration Time: 5.29147

Cumulative Model Updates: 16,225
Cumulative Timesteps: 270,735,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.30794
Policy Entropy: 1.22826
Value Function Loss: 5.74094

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 10,682.37899
Overall Steps per Second: 9,328.64221

Timestep Collection Time: 4.68117
Timestep Consumption Time: 0.67931
PPO Batch Consumption Time: 0.03511
Total Iteration Time: 5.36048

Cumulative Model Updates: 16,228
Cumulative Timesteps: 270,785,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 270785664...
Checkpoint 270785664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.61951
Policy Entropy: 1.23663
Value Function Loss: 5.94619

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 11,703.54133
Overall Steps per Second: 9,859.31880

Timestep Collection Time: 4.27324
Timestep Consumption Time: 0.79932
PPO Batch Consumption Time: 0.03452
Total Iteration Time: 5.07256

Cumulative Model Updates: 16,231
Cumulative Timesteps: 270,835,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.66718
Policy Entropy: 1.23564
Value Function Loss: 5.70532

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.05722

Collected Steps per Second: 11,309.09564
Overall Steps per Second: 9,582.12206

Timestep Collection Time: 4.42334
Timestep Consumption Time: 0.79721
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 5.22056

Cumulative Model Updates: 16,234
Cumulative Timesteps: 270,885,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 270885700...
Checkpoint 270885700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.32077
Policy Entropy: 1.22675
Value Function Loss: 5.76128

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.06354
Value Function Update Magnitude: 0.05654

Collected Steps per Second: 11,628.34994
Overall Steps per Second: 9,887.23510

Timestep Collection Time: 4.29984
Timestep Consumption Time: 0.75719
PPO Batch Consumption Time: 0.03451
Total Iteration Time: 5.05703

Cumulative Model Updates: 16,237
Cumulative Timesteps: 270,935,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.89901
Policy Entropy: 1.21436
Value Function Loss: 5.65678

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.05647

Collected Steps per Second: 11,597.27372
Overall Steps per Second: 9,854.42200

Timestep Collection Time: 4.31326
Timestep Consumption Time: 0.76284
PPO Batch Consumption Time: 0.03429
Total Iteration Time: 5.07610

Cumulative Model Updates: 16,240
Cumulative Timesteps: 270,985,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 270985722...
Checkpoint 270985722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.68366
Policy Entropy: 1.22722
Value Function Loss: 5.90078

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05359
Policy Update Magnitude: 0.08143
Value Function Update Magnitude: 0.05111

Collected Steps per Second: 11,183.97841
Overall Steps per Second: 9,689.87744

Timestep Collection Time: 4.47318
Timestep Consumption Time: 0.68973
PPO Batch Consumption Time: 0.03893
Total Iteration Time: 5.16291

Cumulative Model Updates: 16,243
Cumulative Timesteps: 271,035,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.09874
Policy Entropy: 1.22716
Value Function Loss: 5.87515

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06460
Policy Update Magnitude: 0.08393
Value Function Update Magnitude: 0.05016

Collected Steps per Second: 10,578.15055
Overall Steps per Second: 9,079.48378

Timestep Collection Time: 4.72843
Timestep Consumption Time: 0.78048
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.50890

Cumulative Model Updates: 16,246
Cumulative Timesteps: 271,085,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 271085768...
Checkpoint 271085768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.76327
Policy Entropy: 1.22923
Value Function Loss: 5.79448

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.07427
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 10,833.95226
Overall Steps per Second: 9,271.20905

Timestep Collection Time: 4.61715
Timestep Consumption Time: 0.77826
PPO Batch Consumption Time: 0.03561
Total Iteration Time: 5.39541

Cumulative Model Updates: 16,249
Cumulative Timesteps: 271,135,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.33117
Policy Entropy: 1.22437
Value Function Loss: 5.59653

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 11,114.14529
Overall Steps per Second: 9,444.50150

Timestep Collection Time: 4.50057
Timestep Consumption Time: 0.79563
PPO Batch Consumption Time: 0.03861
Total Iteration Time: 5.29620

Cumulative Model Updates: 16,252
Cumulative Timesteps: 271,185,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 271185810...
Checkpoint 271185810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.67849
Policy Entropy: 1.22388
Value Function Loss: 5.54959

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.08134
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 11,101.68729
Overall Steps per Second: 9,481.26316

Timestep Collection Time: 4.50454
Timestep Consumption Time: 0.76986
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 5.27440

Cumulative Model Updates: 16,255
Cumulative Timesteps: 271,235,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.58336
Policy Entropy: 1.22030
Value Function Loss: 5.53957

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.07610
Value Function Update Magnitude: 0.08882

Collected Steps per Second: 11,181.55797
Overall Steps per Second: 9,706.85503

Timestep Collection Time: 4.47415
Timestep Consumption Time: 0.67973
PPO Batch Consumption Time: 0.03683
Total Iteration Time: 5.15388

Cumulative Model Updates: 16,258
Cumulative Timesteps: 271,285,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 271285846...
Checkpoint 271285846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.98367
Policy Entropy: 1.23036
Value Function Loss: 5.53269

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 10,692.22047
Overall Steps per Second: 9,062.53010

Timestep Collection Time: 4.67723
Timestep Consumption Time: 0.84109
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 5.51833

Cumulative Model Updates: 16,261
Cumulative Timesteps: 271,335,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.06286
Policy Entropy: 1.23472
Value Function Loss: 5.64145

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.07264

Collected Steps per Second: 10,829.57446
Overall Steps per Second: 9,310.69509

Timestep Collection Time: 4.61865
Timestep Consumption Time: 0.75345
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.37210

Cumulative Model Updates: 16,264
Cumulative Timesteps: 271,385,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 271385874...
Checkpoint 271385874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.64653
Policy Entropy: 1.22968
Value Function Loss: 5.64730

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 10,761.70684
Overall Steps per Second: 9,230.49411

Timestep Collection Time: 4.64759
Timestep Consumption Time: 0.77097
PPO Batch Consumption Time: 0.03574
Total Iteration Time: 5.41856

Cumulative Model Updates: 16,267
Cumulative Timesteps: 271,435,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.38743
Policy Entropy: 1.22151
Value Function Loss: 5.74170

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.05103

Collected Steps per Second: 10,870.54400
Overall Steps per Second: 9,319.67387

Timestep Collection Time: 4.60087
Timestep Consumption Time: 0.76562
PPO Batch Consumption Time: 0.03501
Total Iteration Time: 5.36650

Cumulative Model Updates: 16,270
Cumulative Timesteps: 271,485,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 271485904...
Checkpoint 271485904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.03087
Policy Entropy: 1.22883
Value Function Loss: 5.73111

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.08666
Value Function Update Magnitude: 0.04357

Collected Steps per Second: 10,788.67068
Overall Steps per Second: 9,372.86314

Timestep Collection Time: 4.63597
Timestep Consumption Time: 0.70028
PPO Batch Consumption Time: 0.03510
Total Iteration Time: 5.33626

Cumulative Model Updates: 16,273
Cumulative Timesteps: 271,535,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.90663
Policy Entropy: 1.23296
Value Function Loss: 5.86358

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.05367

Collected Steps per Second: 10,786.95594
Overall Steps per Second: 9,227.72368

Timestep Collection Time: 4.63764
Timestep Consumption Time: 0.78363
PPO Batch Consumption Time: 0.03729
Total Iteration Time: 5.42127

Cumulative Model Updates: 16,276
Cumulative Timesteps: 271,585,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 271585946...
Checkpoint 271585946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.63178
Policy Entropy: 1.23106
Value Function Loss: 5.82613

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.05696

Collected Steps per Second: 10,197.52397
Overall Steps per Second: 8,951.13338

Timestep Collection Time: 4.90531
Timestep Consumption Time: 0.68303
PPO Batch Consumption Time: 0.03834
Total Iteration Time: 5.58834

Cumulative Model Updates: 16,279
Cumulative Timesteps: 271,635,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.54787
Policy Entropy: 1.23675
Value Function Loss: 5.70149

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 10,680.86043
Overall Steps per Second: 9,198.06360

Timestep Collection Time: 4.68202
Timestep Consumption Time: 0.75478
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 5.43680

Cumulative Model Updates: 16,282
Cumulative Timesteps: 271,685,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 271685976...
Checkpoint 271685976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.71253
Policy Entropy: 1.23609
Value Function Loss: 5.66674

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.05565

Collected Steps per Second: 10,867.09469
Overall Steps per Second: 9,283.38214

Timestep Collection Time: 4.60252
Timestep Consumption Time: 0.78517
PPO Batch Consumption Time: 0.03773
Total Iteration Time: 5.38769

Cumulative Model Updates: 16,285
Cumulative Timesteps: 271,735,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.85674
Policy Entropy: 1.22424
Value Function Loss: 5.61918

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.05292

Collected Steps per Second: 10,941.90716
Overall Steps per Second: 9,383.77764

Timestep Collection Time: 4.56959
Timestep Consumption Time: 0.75876
PPO Batch Consumption Time: 0.03622
Total Iteration Time: 5.32834

Cumulative Model Updates: 16,288
Cumulative Timesteps: 271,785,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 271785992...
Checkpoint 271785992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.31674
Policy Entropy: 1.22578
Value Function Loss: 5.66321

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.05669

Collected Steps per Second: 10,645.23760
Overall Steps per Second: 9,097.72106

Timestep Collection Time: 4.69881
Timestep Consumption Time: 0.79927
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 5.49808

Cumulative Model Updates: 16,291
Cumulative Timesteps: 271,836,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.33443
Policy Entropy: 1.21883
Value Function Loss: 5.57647

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 11,034.26629
Overall Steps per Second: 9,367.31070

Timestep Collection Time: 4.53170
Timestep Consumption Time: 0.80644
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 5.33814

Cumulative Model Updates: 16,294
Cumulative Timesteps: 271,886,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 271886016...
Checkpoint 271886016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.43479
Policy Entropy: 1.22185
Value Function Loss: 5.48345

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 11,054.99522
Overall Steps per Second: 9,399.57596

Timestep Collection Time: 4.52284
Timestep Consumption Time: 0.79655
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 5.31939

Cumulative Model Updates: 16,297
Cumulative Timesteps: 271,936,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.51813
Policy Entropy: 1.21905
Value Function Loss: 5.30621

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.04125

Collected Steps per Second: 11,103.00123
Overall Steps per Second: 9,466.23337

Timestep Collection Time: 4.50329
Timestep Consumption Time: 0.77864
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 5.28193

Cumulative Model Updates: 16,300
Cumulative Timesteps: 271,986,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 271986016...
Checkpoint 271986016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.57546
Policy Entropy: 1.20759
Value Function Loss: 5.36972

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.04435

Collected Steps per Second: 11,220.20944
Overall Steps per Second: 9,512.58516

Timestep Collection Time: 4.45874
Timestep Consumption Time: 0.80040
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 5.25914

Cumulative Model Updates: 16,303
Cumulative Timesteps: 272,036,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.92226
Policy Entropy: 1.22782
Value Function Loss: 5.23717

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.08307
Value Function Update Magnitude: 0.04779

Collected Steps per Second: 11,068.90179
Overall Steps per Second: 9,521.60864

Timestep Collection Time: 4.51933
Timestep Consumption Time: 0.73441
PPO Batch Consumption Time: 0.03597
Total Iteration Time: 5.25373

Cumulative Model Updates: 16,306
Cumulative Timesteps: 272,086,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 272086068...
Checkpoint 272086068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.42235
Policy Entropy: 1.22126
Value Function Loss: 5.35154

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 11,213.71569
Overall Steps per Second: 9,683.87042

Timestep Collection Time: 4.46061
Timestep Consumption Time: 0.70468
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 5.16529

Cumulative Model Updates: 16,309
Cumulative Timesteps: 272,136,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.36968
Policy Entropy: 1.21545
Value Function Loss: 5.34877

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.04353

Collected Steps per Second: 10,491.63756
Overall Steps per Second: 8,963.64841

Timestep Collection Time: 4.76723
Timestep Consumption Time: 0.81265
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.57987

Cumulative Model Updates: 16,312
Cumulative Timesteps: 272,186,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 272186104...
Checkpoint 272186104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.16478
Policy Entropy: 1.23186
Value Function Loss: 5.54355

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.04413

Collected Steps per Second: 10,786.30572
Overall Steps per Second: 9,248.23143

Timestep Collection Time: 4.63551
Timestep Consumption Time: 0.77093
PPO Batch Consumption Time: 0.03721
Total Iteration Time: 5.40644

Cumulative Model Updates: 16,315
Cumulative Timesteps: 272,236,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.15455
Policy Entropy: 1.22565
Value Function Loss: 5.40336

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.06004

Collected Steps per Second: 11,326.91503
Overall Steps per Second: 9,548.21701

Timestep Collection Time: 4.41603
Timestep Consumption Time: 0.82264
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 5.23867

Cumulative Model Updates: 16,318
Cumulative Timesteps: 272,286,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 272286124...
Checkpoint 272286124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.12933
Policy Entropy: 1.22260
Value Function Loss: 5.61431

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 10,913.91815
Overall Steps per Second: 9,292.71059

Timestep Collection Time: 4.58369
Timestep Consumption Time: 0.79967
PPO Batch Consumption Time: 0.03609
Total Iteration Time: 5.38336

Cumulative Model Updates: 16,321
Cumulative Timesteps: 272,336,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.32725
Policy Entropy: 1.22442
Value Function Loss: 5.54646

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.05691

Collected Steps per Second: 11,354.09695
Overall Steps per Second: 9,784.97127

Timestep Collection Time: 4.40493
Timestep Consumption Time: 0.70638
PPO Batch Consumption Time: 0.03660
Total Iteration Time: 5.11131

Cumulative Model Updates: 16,324
Cumulative Timesteps: 272,386,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 272386164...
Checkpoint 272386164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.20330
Policy Entropy: 1.22962
Value Function Loss: 5.58788

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06104
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.05746

Collected Steps per Second: 10,477.70229
Overall Steps per Second: 9,021.38398

Timestep Collection Time: 4.77433
Timestep Consumption Time: 0.77072
PPO Batch Consumption Time: 0.03608
Total Iteration Time: 5.54505

Cumulative Model Updates: 16,327
Cumulative Timesteps: 272,436,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.93722
Policy Entropy: 1.22746
Value Function Loss: 5.44499

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06161
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 10,301.36467
Overall Steps per Second: 8,941.14585

Timestep Collection Time: 4.85392
Timestep Consumption Time: 0.73843
PPO Batch Consumption Time: 0.03628
Total Iteration Time: 5.59235

Cumulative Model Updates: 16,330
Cumulative Timesteps: 272,486,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 272486190...
Checkpoint 272486190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.28170
Policy Entropy: 1.21820
Value Function Loss: 5.38244

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.05998

Collected Steps per Second: 10,920.21879
Overall Steps per Second: 9,281.59260

Timestep Collection Time: 4.58086
Timestep Consumption Time: 0.80873
PPO Batch Consumption Time: 0.03711
Total Iteration Time: 5.38959

Cumulative Model Updates: 16,333
Cumulative Timesteps: 272,536,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.40433
Policy Entropy: 1.23002
Value Function Loss: 5.30460

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.05541

Collected Steps per Second: 10,840.79361
Overall Steps per Second: 9,356.54632

Timestep Collection Time: 4.61313
Timestep Consumption Time: 0.73179
PPO Batch Consumption Time: 0.03495
Total Iteration Time: 5.34492

Cumulative Model Updates: 16,336
Cumulative Timesteps: 272,586,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 272586224...
Checkpoint 272586224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.06089
Policy Entropy: 1.22385
Value Function Loss: 5.43845

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 10,958.89931
Overall Steps per Second: 9,537.14838

Timestep Collection Time: 4.56433
Timestep Consumption Time: 0.68043
PPO Batch Consumption Time: 0.03569
Total Iteration Time: 5.24475

Cumulative Model Updates: 16,339
Cumulative Timesteps: 272,636,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.33397
Policy Entropy: 1.22600
Value Function Loss: 5.43518

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.05997

Collected Steps per Second: 10,752.76816
Overall Steps per Second: 9,142.51110

Timestep Collection Time: 4.65127
Timestep Consumption Time: 0.81922
PPO Batch Consumption Time: 0.03543
Total Iteration Time: 5.47049

Cumulative Model Updates: 16,342
Cumulative Timesteps: 272,686,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 272686258...
Checkpoint 272686258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.90872
Policy Entropy: 1.21828
Value Function Loss: 5.35520

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 10,462.68465
Overall Steps per Second: 8,984.00623

Timestep Collection Time: 4.77965
Timestep Consumption Time: 0.78668
PPO Batch Consumption Time: 0.03674
Total Iteration Time: 5.56634

Cumulative Model Updates: 16,345
Cumulative Timesteps: 272,736,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.93640
Policy Entropy: 1.22934
Value Function Loss: 5.36923

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 10,924.94225
Overall Steps per Second: 9,347.36661

Timestep Collection Time: 4.57687
Timestep Consumption Time: 0.77245
PPO Batch Consumption Time: 0.03482
Total Iteration Time: 5.34931

Cumulative Model Updates: 16,348
Cumulative Timesteps: 272,786,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 272786268...
Checkpoint 272786268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.32219
Policy Entropy: 1.23161
Value Function Loss: 5.48524

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 10,852.92878
Overall Steps per Second: 9,278.63294

Timestep Collection Time: 4.60945
Timestep Consumption Time: 0.78208
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 5.39153

Cumulative Model Updates: 16,351
Cumulative Timesteps: 272,836,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.91559
Policy Entropy: 1.22923
Value Function Loss: 5.83771

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 10,508.75641
Overall Steps per Second: 9,094.72571

Timestep Collection Time: 4.76003
Timestep Consumption Time: 0.74008
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 5.50011

Cumulative Model Updates: 16,354
Cumulative Timesteps: 272,886,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 272886316...
Checkpoint 272886316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.11100
Policy Entropy: 1.23045
Value Function Loss: 5.59424

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 10,796.98153
Overall Steps per Second: 9,198.21948

Timestep Collection Time: 4.63185
Timestep Consumption Time: 0.80507
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.43692

Cumulative Model Updates: 16,357
Cumulative Timesteps: 272,936,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.12871
Policy Entropy: 1.23105
Value Function Loss: 5.65370

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05423
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.06531

Collected Steps per Second: 11,330.13763
Overall Steps per Second: 9,689.86635

Timestep Collection Time: 4.41424
Timestep Consumption Time: 0.74723
PPO Batch Consumption Time: 0.03731
Total Iteration Time: 5.16147

Cumulative Model Updates: 16,360
Cumulative Timesteps: 272,986,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 272986340...
Checkpoint 272986340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.03478
Policy Entropy: 1.23205
Value Function Loss: 5.47450

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 11,027.87431
Overall Steps per Second: 9,376.17291

Timestep Collection Time: 4.53505
Timestep Consumption Time: 0.79889
PPO Batch Consumption Time: 0.03720
Total Iteration Time: 5.33395

Cumulative Model Updates: 16,363
Cumulative Timesteps: 273,036,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.94183
Policy Entropy: 1.23119
Value Function Loss: 5.65572

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.07067
Value Function Update Magnitude: 0.06635

Collected Steps per Second: 11,700.79997
Overall Steps per Second: 9,910.98665

Timestep Collection Time: 4.27321
Timestep Consumption Time: 0.77169
PPO Batch Consumption Time: 0.03432
Total Iteration Time: 5.04491

Cumulative Model Updates: 16,366
Cumulative Timesteps: 273,086,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 273086352...
Checkpoint 273086352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.97678
Policy Entropy: 1.24024
Value Function Loss: 5.50815

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.06036

Collected Steps per Second: 11,592.69309
Overall Steps per Second: 9,965.53997

Timestep Collection Time: 4.31496
Timestep Consumption Time: 0.70454
PPO Batch Consumption Time: 0.03750
Total Iteration Time: 5.01950

Cumulative Model Updates: 16,369
Cumulative Timesteps: 273,136,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.58771
Policy Entropy: 1.23682
Value Function Loss: 5.60809

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 11,741.68196
Overall Steps per Second: 9,930.11536

Timestep Collection Time: 4.25987
Timestep Consumption Time: 0.77713
PPO Batch Consumption Time: 0.03473
Total Iteration Time: 5.03700

Cumulative Model Updates: 16,372
Cumulative Timesteps: 273,186,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 273186392...
Checkpoint 273186392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.76211
Policy Entropy: 1.24026
Value Function Loss: 5.66933

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.06317

Collected Steps per Second: 11,812.96245
Overall Steps per Second: 10,057.93152

Timestep Collection Time: 4.23484
Timestep Consumption Time: 0.73895
PPO Batch Consumption Time: 0.03410
Total Iteration Time: 4.97379

Cumulative Model Updates: 16,375
Cumulative Timesteps: 273,236,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.02485
Policy Entropy: 1.23677
Value Function Loss: 5.68471

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 11,245.71404
Overall Steps per Second: 9,575.76945

Timestep Collection Time: 4.44845
Timestep Consumption Time: 0.77578
PPO Batch Consumption Time: 0.03872
Total Iteration Time: 5.22423

Cumulative Model Updates: 16,378
Cumulative Timesteps: 273,286,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 273286444...
Checkpoint 273286444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.93913
Policy Entropy: 1.23830
Value Function Loss: 5.60145

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 10,334.37274
Overall Steps per Second: 8,898.03861

Timestep Collection Time: 4.83880
Timestep Consumption Time: 0.78109
PPO Batch Consumption Time: 0.03908
Total Iteration Time: 5.61989

Cumulative Model Updates: 16,381
Cumulative Timesteps: 273,336,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.41855
Policy Entropy: 1.24164
Value Function Loss: 5.43338

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05064
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 10,852.66370
Overall Steps per Second: 9,409.11938

Timestep Collection Time: 4.60938
Timestep Consumption Time: 0.70717
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 5.31654

Cumulative Model Updates: 16,384
Cumulative Timesteps: 273,386,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 273386474...
Checkpoint 273386474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.32884
Policy Entropy: 1.23937
Value Function Loss: 5.36013

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.05816

Collected Steps per Second: 10,825.90422
Overall Steps per Second: 9,264.99062

Timestep Collection Time: 4.62095
Timestep Consumption Time: 0.77851
PPO Batch Consumption Time: 0.03594
Total Iteration Time: 5.39947

Cumulative Model Updates: 16,387
Cumulative Timesteps: 273,436,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.59158
Policy Entropy: 1.23247
Value Function Loss: 5.42223

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.05764

Collected Steps per Second: 10,930.56966
Overall Steps per Second: 9,375.97688

Timestep Collection Time: 4.57506
Timestep Consumption Time: 0.75857
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 5.33363

Cumulative Model Updates: 16,390
Cumulative Timesteps: 273,486,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 273486508...
Checkpoint 273486508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.34790
Policy Entropy: 1.23667
Value Function Loss: 5.39133

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 11,080.36628
Overall Steps per Second: 9,479.97819

Timestep Collection Time: 4.51519
Timestep Consumption Time: 0.76224
PPO Batch Consumption Time: 0.03610
Total Iteration Time: 5.27744

Cumulative Model Updates: 16,393
Cumulative Timesteps: 273,536,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.85850
Policy Entropy: 1.22986
Value Function Loss: 5.31438

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 10,457.36635
Overall Steps per Second: 8,994.15768

Timestep Collection Time: 4.78285
Timestep Consumption Time: 0.77809
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 5.56094

Cumulative Model Updates: 16,396
Cumulative Timesteps: 273,586,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 273586554...
Checkpoint 273586554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.87818
Policy Entropy: 1.22438
Value Function Loss: 5.41073

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.08409
Value Function Update Magnitude: 0.06031

Collected Steps per Second: 10,578.29612
Overall Steps per Second: 9,244.27933

Timestep Collection Time: 4.72798
Timestep Consumption Time: 0.68228
PPO Batch Consumption Time: 0.03588
Total Iteration Time: 5.41026

Cumulative Model Updates: 16,399
Cumulative Timesteps: 273,636,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.71591
Policy Entropy: 1.21350
Value Function Loss: 5.54961

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.09294
Value Function Update Magnitude: 0.07515

Collected Steps per Second: 10,687.63347
Overall Steps per Second: 9,214.41478

Timestep Collection Time: 4.68092
Timestep Consumption Time: 0.74840
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.42932

Cumulative Model Updates: 16,402
Cumulative Timesteps: 273,686,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 273686596...
Checkpoint 273686596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.33264
Policy Entropy: 1.23476
Value Function Loss: 5.87605

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.08450
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 10,709.82752
Overall Steps per Second: 9,214.77105

Timestep Collection Time: 4.67085
Timestep Consumption Time: 0.75783
PPO Batch Consumption Time: 0.03786
Total Iteration Time: 5.42868

Cumulative Model Updates: 16,405
Cumulative Timesteps: 273,736,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.10674
Policy Entropy: 1.22343
Value Function Loss: 5.90905

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.07584
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 11,125.86651
Overall Steps per Second: 9,507.94250

Timestep Collection Time: 4.49583
Timestep Consumption Time: 0.76504
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 5.26086

Cumulative Model Updates: 16,408
Cumulative Timesteps: 273,786,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 273786640...
Checkpoint 273786640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.26739
Policy Entropy: 1.23672
Value Function Loss: 5.70234

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.06144

Collected Steps per Second: 10,625.62167
Overall Steps per Second: 9,158.57350

Timestep Collection Time: 4.70617
Timestep Consumption Time: 0.75385
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 5.46002

Cumulative Model Updates: 16,411
Cumulative Timesteps: 273,836,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.65052
Policy Entropy: 1.24152
Value Function Loss: 5.41301

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.05357

Collected Steps per Second: 10,107.70251
Overall Steps per Second: 8,869.29537

Timestep Collection Time: 4.94771
Timestep Consumption Time: 0.69084
PPO Batch Consumption Time: 0.03672
Total Iteration Time: 5.63855

Cumulative Model Updates: 16,414
Cumulative Timesteps: 273,886,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 273886656...
Checkpoint 273886656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.87943
Policy Entropy: 1.22509
Value Function Loss: 5.33322

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.07855
Value Function Update Magnitude: 0.04664

Collected Steps per Second: 10,636.44229
Overall Steps per Second: 8,766.03190

Timestep Collection Time: 4.70345
Timestep Consumption Time: 1.00358
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 5.70703

Cumulative Model Updates: 16,417
Cumulative Timesteps: 273,936,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.12150
Policy Entropy: 1.23649
Value Function Loss: 5.22971

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.03973

Collected Steps per Second: 6,100.10879
Overall Steps per Second: 5,433.00831

Timestep Collection Time: 8.19953
Timestep Consumption Time: 1.00679
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 9.20632

Cumulative Model Updates: 16,420
Cumulative Timesteps: 273,986,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 273986702...
Checkpoint 273986702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.45928
Policy Entropy: 1.23727
Value Function Loss: 5.33433

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.06987
Policy Update Magnitude: 0.08280
Value Function Update Magnitude: 0.05037

Collected Steps per Second: 8,843.50555
Overall Steps per Second: 7,575.84281

Timestep Collection Time: 5.65748
Timestep Consumption Time: 0.94666
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.60415

Cumulative Model Updates: 16,423
Cumulative Timesteps: 274,036,734

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.00266
Policy Entropy: 1.23631
Value Function Loss: 5.26652

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.06232

Collected Steps per Second: 8,504.32966
Overall Steps per Second: 7,329.99315

Timestep Collection Time: 5.88265
Timestep Consumption Time: 0.94246
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 6.82511

Cumulative Model Updates: 16,426
Cumulative Timesteps: 274,086,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 274086762...
Checkpoint 274086762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.56159
Policy Entropy: 1.23636
Value Function Loss: 5.39233

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 8,372.41134
Overall Steps per Second: 7,383.08514

Timestep Collection Time: 5.97391
Timestep Consumption Time: 0.80050
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.77440

Cumulative Model Updates: 16,429
Cumulative Timesteps: 274,136,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.54631
Policy Entropy: 1.24093
Value Function Loss: 5.33542

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 8,768.65906
Overall Steps per Second: 7,614.13237

Timestep Collection Time: 5.70418
Timestep Consumption Time: 0.86492
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.56910

Cumulative Model Updates: 16,432
Cumulative Timesteps: 274,186,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 274186796...
Checkpoint 274186796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.09536
Policy Entropy: 1.24270
Value Function Loss: 5.10205

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.07339
Value Function Update Magnitude: 0.06865

Collected Steps per Second: 8,767.37468
Overall Steps per Second: 7,646.72445

Timestep Collection Time: 5.70456
Timestep Consumption Time: 0.83602
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 6.54058

Cumulative Model Updates: 16,435
Cumulative Timesteps: 274,236,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.51557
Policy Entropy: 1.23735
Value Function Loss: 5.29128

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 8,801.11772
Overall Steps per Second: 7,636.54189

Timestep Collection Time: 5.68314
Timestep Consumption Time: 0.86668
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.54982

Cumulative Model Updates: 16,438
Cumulative Timesteps: 274,286,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 274286828...
Checkpoint 274286828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.07854
Policy Entropy: 1.23268
Value Function Loss: 5.20180

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.07254
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 8,450.33520
Overall Steps per Second: 7,365.03305

Timestep Collection Time: 5.91740
Timestep Consumption Time: 0.87198
PPO Batch Consumption Time: 0.04973
Total Iteration Time: 6.78938

Cumulative Model Updates: 16,441
Cumulative Timesteps: 274,336,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.52496
Policy Entropy: 1.24277
Value Function Loss: 5.21888

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.07111
Value Function Update Magnitude: 0.05382

Collected Steps per Second: 8,598.64923
Overall Steps per Second: 7,600.77834

Timestep Collection Time: 5.81510
Timestep Consumption Time: 0.76344
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.57854

Cumulative Model Updates: 16,444
Cumulative Timesteps: 274,386,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 274386834...
Checkpoint 274386834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.04023
Policy Entropy: 1.23822
Value Function Loss: 5.05560

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.05632

Collected Steps per Second: 8,671.91690
Overall Steps per Second: 7,565.38237

Timestep Collection Time: 5.76804
Timestep Consumption Time: 0.84365
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.61169

Cumulative Model Updates: 16,447
Cumulative Timesteps: 274,436,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.40114
Policy Entropy: 1.23354
Value Function Loss: 5.03761

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.06408
Value Function Update Magnitude: 0.05950

Collected Steps per Second: 8,680.90398
Overall Steps per Second: 7,537.48291

Timestep Collection Time: 5.76253
Timestep Consumption Time: 0.87416
PPO Batch Consumption Time: 0.05052
Total Iteration Time: 6.63670

Cumulative Model Updates: 16,450
Cumulative Timesteps: 274,486,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 274486878...
Checkpoint 274486878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.08987
Policy Entropy: 1.24523
Value Function Loss: 5.03336

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 8,429.51522
Overall Steps per Second: 7,364.87723

Timestep Collection Time: 5.93344
Timestep Consumption Time: 0.85771
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 6.79115

Cumulative Model Updates: 16,453
Cumulative Timesteps: 274,536,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.10236
Policy Entropy: 1.24173
Value Function Loss: 5.05169

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 8,620.17690
Overall Steps per Second: 7,543.20234

Timestep Collection Time: 5.80197
Timestep Consumption Time: 0.82837
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.63034

Cumulative Model Updates: 16,456
Cumulative Timesteps: 274,586,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 274586908...
Checkpoint 274586908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.43480
Policy Entropy: 1.23648
Value Function Loss: 5.10719

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06271
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 8,607.86472
Overall Steps per Second: 7,527.08461

Timestep Collection Time: 5.81236
Timestep Consumption Time: 0.83457
PPO Batch Consumption Time: 0.04770
Total Iteration Time: 6.64693

Cumulative Model Updates: 16,459
Cumulative Timesteps: 274,636,940

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.42629
Policy Entropy: 1.22500
Value Function Loss: 5.20338

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.07027
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 8,650.39515
Overall Steps per Second: 7,534.26067

Timestep Collection Time: 5.78170
Timestep Consumption Time: 0.85651
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.63821

Cumulative Model Updates: 16,462
Cumulative Timesteps: 274,686,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 274686954...
Checkpoint 274686954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.77413
Policy Entropy: 1.23314
Value Function Loss: 5.36017

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.06894

Collected Steps per Second: 8,603.59243
Overall Steps per Second: 7,441.30369

Timestep Collection Time: 5.81315
Timestep Consumption Time: 0.90798
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.72113

Cumulative Model Updates: 16,465
Cumulative Timesteps: 274,736,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.12932
Policy Entropy: 1.23617
Value Function Loss: 5.58102

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.08062

Collected Steps per Second: 8,701.83359
Overall Steps per Second: 7,540.58295

Timestep Collection Time: 5.74752
Timestep Consumption Time: 0.88512
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.63264

Cumulative Model Updates: 16,468
Cumulative Timesteps: 274,786,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 274786982...
Checkpoint 274786982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.03201
Policy Entropy: 1.23540
Value Function Loss: 5.57665

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 8,895.58915
Overall Steps per Second: 7,685.33148

Timestep Collection Time: 5.62234
Timestep Consumption Time: 0.88538
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 6.50772

Cumulative Model Updates: 16,471
Cumulative Timesteps: 274,836,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.23384
Policy Entropy: 1.21748
Value Function Loss: 5.39899

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 8,639.85585
Overall Steps per Second: 7,635.97188

Timestep Collection Time: 5.79014
Timestep Consumption Time: 0.76122
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 6.55136

Cumulative Model Updates: 16,474
Cumulative Timesteps: 274,887,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 274887022...
Checkpoint 274887022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.71607
Policy Entropy: 1.23866
Value Function Loss: 5.19210

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 8,924.51034
Overall Steps per Second: 7,700.25955

Timestep Collection Time: 5.60524
Timestep Consumption Time: 0.89117
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.49640

Cumulative Model Updates: 16,477
Cumulative Timesteps: 274,937,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.07890
Policy Entropy: 1.22880
Value Function Loss: 5.12188

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 8,648.47981
Overall Steps per Second: 7,546.70372

Timestep Collection Time: 5.78321
Timestep Consumption Time: 0.84432
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.62753

Cumulative Model Updates: 16,480
Cumulative Timesteps: 274,987,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 274987062...
Checkpoint 274987062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.20803
Policy Entropy: 1.23186
Value Function Loss: 5.16005

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 9,153.81057
Overall Steps per Second: 7,856.00390

Timestep Collection Time: 5.46417
Timestep Consumption Time: 0.90268
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 6.36685

Cumulative Model Updates: 16,483
Cumulative Timesteps: 275,037,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.03949
Policy Entropy: 1.23246
Value Function Loss: 5.05038

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 9,121.16278
Overall Steps per Second: 7,881.10898

Timestep Collection Time: 5.48417
Timestep Consumption Time: 0.86291
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 6.34708

Cumulative Model Updates: 16,486
Cumulative Timesteps: 275,087,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 275087102...
Checkpoint 275087102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.22514
Policy Entropy: 1.22923
Value Function Loss: 5.09980

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 9,087.63919
Overall Steps per Second: 7,951.57025

Timestep Collection Time: 5.50308
Timestep Consumption Time: 0.78624
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.28932

Cumulative Model Updates: 16,489
Cumulative Timesteps: 275,137,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.43326
Policy Entropy: 1.22351
Value Function Loss: 4.92982

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 9,028.91220
Overall Steps per Second: 7,814.97595

Timestep Collection Time: 5.53843
Timestep Consumption Time: 0.86031
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 6.39874

Cumulative Model Updates: 16,492
Cumulative Timesteps: 275,187,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 275187118...
Checkpoint 275187118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.48044
Policy Entropy: 1.22141
Value Function Loss: 4.91847

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.06959

Collected Steps per Second: 8,558.76105
Overall Steps per Second: 7,440.62045

Timestep Collection Time: 5.84243
Timestep Consumption Time: 0.87797
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.72041

Cumulative Model Updates: 16,495
Cumulative Timesteps: 275,237,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.50901
Policy Entropy: 1.23234
Value Function Loss: 5.01247

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.08103

Collected Steps per Second: 8,985.29572
Overall Steps per Second: 7,772.45144

Timestep Collection Time: 5.56665
Timestep Consumption Time: 0.86864
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.43529

Cumulative Model Updates: 16,498
Cumulative Timesteps: 275,287,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 275287140...
Checkpoint 275287140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.59812
Policy Entropy: 1.23121
Value Function Loss: 5.11667

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 8,618.78061
Overall Steps per Second: 7,525.22210

Timestep Collection Time: 5.80268
Timestep Consumption Time: 0.84324
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.64592

Cumulative Model Updates: 16,501
Cumulative Timesteps: 275,337,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.52076
Policy Entropy: 1.22458
Value Function Loss: 5.44794

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.08799

Collected Steps per Second: 8,928.80972
Overall Steps per Second: 7,832.84273

Timestep Collection Time: 5.60164
Timestep Consumption Time: 0.78378
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 6.38542

Cumulative Model Updates: 16,504
Cumulative Timesteps: 275,387,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 275387168...
Checkpoint 275387168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.36341
Policy Entropy: 1.24030
Value Function Loss: 5.26541

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.07571

Collected Steps per Second: 8,613.61533
Overall Steps per Second: 7,442.78046

Timestep Collection Time: 5.80755
Timestep Consumption Time: 0.91359
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.72114

Cumulative Model Updates: 16,507
Cumulative Timesteps: 275,437,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.81663
Policy Entropy: 1.22975
Value Function Loss: 5.27754

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 8,964.21541
Overall Steps per Second: 7,754.45475

Timestep Collection Time: 5.58041
Timestep Consumption Time: 0.87059
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 6.45100

Cumulative Model Updates: 16,510
Cumulative Timesteps: 275,487,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 275487216...
Checkpoint 275487216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.12267
Policy Entropy: 1.23144
Value Function Loss: 4.95944

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.06455

Collected Steps per Second: 8,909.49813
Overall Steps per Second: 7,715.87834

Timestep Collection Time: 5.61401
Timestep Consumption Time: 0.86847
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.48248

Cumulative Model Updates: 16,513
Cumulative Timesteps: 275,537,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.08010
Policy Entropy: 1.22893
Value Function Loss: 5.00156

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 9,048.44199
Overall Steps per Second: 7,850.49282

Timestep Collection Time: 5.52869
Timestep Consumption Time: 0.84365
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.37234

Cumulative Model Updates: 16,516
Cumulative Timesteps: 275,587,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 275587260...
Checkpoint 275587260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.85584
Policy Entropy: 1.23506
Value Function Loss: 5.04175

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 8,591.41081
Overall Steps per Second: 7,596.94864

Timestep Collection Time: 5.82326
Timestep Consumption Time: 0.76228
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.58554

Cumulative Model Updates: 16,519
Cumulative Timesteps: 275,637,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.22373
Policy Entropy: 1.22935
Value Function Loss: 5.04705

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 8,517.86682
Overall Steps per Second: 7,433.94892

Timestep Collection Time: 5.87330
Timestep Consumption Time: 0.85637
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.72967

Cumulative Model Updates: 16,522
Cumulative Timesteps: 275,687,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 275687318...
Checkpoint 275687318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.95686
Policy Entropy: 1.23132
Value Function Loss: 5.03280

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.06896

Collected Steps per Second: 8,874.38791
Overall Steps per Second: 7,756.98916

Timestep Collection Time: 5.63487
Timestep Consumption Time: 0.81171
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 6.44657

Cumulative Model Updates: 16,525
Cumulative Timesteps: 275,737,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.69970
Policy Entropy: 1.22994
Value Function Loss: 5.03822

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 8,891.39824
Overall Steps per Second: 7,740.08263

Timestep Collection Time: 5.62589
Timestep Consumption Time: 0.83683
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.46272

Cumulative Model Updates: 16,528
Cumulative Timesteps: 275,787,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 275787346...
Checkpoint 275787346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.52052
Policy Entropy: 1.21896
Value Function Loss: 5.32101

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 8,783.94966
Overall Steps per Second: 7,619.51132

Timestep Collection Time: 5.69402
Timestep Consumption Time: 0.87018
PPO Batch Consumption Time: 0.05181
Total Iteration Time: 6.56420

Cumulative Model Updates: 16,531
Cumulative Timesteps: 275,837,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.45643
Policy Entropy: 1.22574
Value Function Loss: 5.32316

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.05344

Collected Steps per Second: 8,789.12675
Overall Steps per Second: 7,647.82687

Timestep Collection Time: 5.68885
Timestep Consumption Time: 0.84896
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.53780

Cumulative Model Updates: 16,534
Cumulative Timesteps: 275,887,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 275887362...
Checkpoint 275887362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.61234
Policy Entropy: 1.23084
Value Function Loss: 5.17961

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.06033

Collected Steps per Second: 8,872.61378
Overall Steps per Second: 7,707.74240

Timestep Collection Time: 5.63735
Timestep Consumption Time: 0.85197
PPO Batch Consumption Time: 0.04868
Total Iteration Time: 6.48932

Cumulative Model Updates: 16,537
Cumulative Timesteps: 275,937,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.31556
Policy Entropy: 1.23324
Value Function Loss: 4.98777

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.05827

Collected Steps per Second: 8,981.74951
Overall Steps per Second: 7,810.41829

Timestep Collection Time: 5.56751
Timestep Consumption Time: 0.83496
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 6.40247

Cumulative Model Updates: 16,540
Cumulative Timesteps: 275,987,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 275987386...
Checkpoint 275987386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.60396
Policy Entropy: 1.22192
Value Function Loss: 5.24738

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.05194

Collected Steps per Second: 9,152.67375
Overall Steps per Second: 7,920.92240

Timestep Collection Time: 5.46507
Timestep Consumption Time: 0.84985
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.31492

Cumulative Model Updates: 16,543
Cumulative Timesteps: 276,037,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.97910
Policy Entropy: 1.22687
Value Function Loss: 5.32343

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.04316

Collected Steps per Second: 8,777.83423
Overall Steps per Second: 7,677.71554

Timestep Collection Time: 5.69617
Timestep Consumption Time: 0.81619
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.51235

Cumulative Model Updates: 16,546
Cumulative Timesteps: 276,087,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 276087406...
Checkpoint 276087406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.94629
Policy Entropy: 1.22327
Value Function Loss: 5.55686

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.04453

Collected Steps per Second: 8,524.77945
Overall Steps per Second: 7,527.84667

Timestep Collection Time: 5.86807
Timestep Consumption Time: 0.77712
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 6.64519

Cumulative Model Updates: 16,549
Cumulative Timesteps: 276,137,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.25699
Policy Entropy: 1.21768
Value Function Loss: 5.58630

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.05770

Collected Steps per Second: 8,918.86285
Overall Steps per Second: 7,699.65757

Timestep Collection Time: 5.60789
Timestep Consumption Time: 0.88798
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.49587

Cumulative Model Updates: 16,552
Cumulative Timesteps: 276,187,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 276187446...
Checkpoint 276187446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.88700
Policy Entropy: 1.22120
Value Function Loss: 5.54167

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 8,930.21274
Overall Steps per Second: 7,812.31116

Timestep Collection Time: 5.60255
Timestep Consumption Time: 0.80170
PPO Batch Consumption Time: 0.04476
Total Iteration Time: 6.40425

Cumulative Model Updates: 16,555
Cumulative Timesteps: 276,237,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.72157
Policy Entropy: 1.22421
Value Function Loss: 5.42442

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.05437

Collected Steps per Second: 8,942.88752
Overall Steps per Second: 7,741.86025

Timestep Collection Time: 5.59417
Timestep Consumption Time: 0.86785
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 6.46201

Cumulative Model Updates: 16,558
Cumulative Timesteps: 276,287,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 276287506...
Checkpoint 276287506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.51398
Policy Entropy: 1.22915
Value Function Loss: 5.20294

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.05399

Collected Steps per Second: 8,705.93082
Overall Steps per Second: 7,521.82919

Timestep Collection Time: 5.74505
Timestep Consumption Time: 0.90440
PPO Batch Consumption Time: 0.04949
Total Iteration Time: 6.64945

Cumulative Model Updates: 16,561
Cumulative Timesteps: 276,337,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.81909
Policy Entropy: 1.22698
Value Function Loss: 5.05914

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 8,500.34351
Overall Steps per Second: 7,548.85576

Timestep Collection Time: 5.88564
Timestep Consumption Time: 0.74185
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.62749

Cumulative Model Updates: 16,564
Cumulative Timesteps: 276,387,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 276387552...
Checkpoint 276387552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.79521
Policy Entropy: 1.21765
Value Function Loss: 5.22476

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.06043

Collected Steps per Second: 8,826.80023
Overall Steps per Second: 7,683.27341

Timestep Collection Time: 5.66661
Timestep Consumption Time: 0.84338
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.50999

Cumulative Model Updates: 16,567
Cumulative Timesteps: 276,437,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.33312
Policy Entropy: 1.21481
Value Function Loss: 5.23350

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07178
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.05712

Collected Steps per Second: 8,654.64416
Overall Steps per Second: 7,532.85380

Timestep Collection Time: 5.78025
Timestep Consumption Time: 0.86079
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.64104

Cumulative Model Updates: 16,570
Cumulative Timesteps: 276,487,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 276487596...
Checkpoint 276487596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.44800
Policy Entropy: 1.21748
Value Function Loss: 5.49253

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.04805

Collected Steps per Second: 9,170.89835
Overall Steps per Second: 7,915.66478

Timestep Collection Time: 5.45421
Timestep Consumption Time: 0.86491
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.31912

Cumulative Model Updates: 16,573
Cumulative Timesteps: 276,537,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.25537
Policy Entropy: 1.22937
Value Function Loss: 5.39020

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 8,730.84762
Overall Steps per Second: 7,496.59574

Timestep Collection Time: 5.72957
Timestep Consumption Time: 0.94333
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 6.67290

Cumulative Model Updates: 16,576
Cumulative Timesteps: 276,587,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 276587640...
Checkpoint 276587640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.15475
Policy Entropy: 1.23260
Value Function Loss: 5.45104

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 8,862.26076
Overall Steps per Second: 7,797.96455

Timestep Collection Time: 5.64326
Timestep Consumption Time: 0.77021
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.41347

Cumulative Model Updates: 16,579
Cumulative Timesteps: 276,637,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.92143
Policy Entropy: 1.22152
Value Function Loss: 5.39267

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 8,793.28709
Overall Steps per Second: 7,622.41830

Timestep Collection Time: 5.68934
Timestep Consumption Time: 0.87393
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 6.56327

Cumulative Model Updates: 16,582
Cumulative Timesteps: 276,687,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 276687680...
Checkpoint 276687680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.90592
Policy Entropy: 1.22188
Value Function Loss: 5.18193

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 8,710.48773
Overall Steps per Second: 7,564.75544

Timestep Collection Time: 5.74021
Timestep Consumption Time: 0.86939
PPO Batch Consumption Time: 0.04950
Total Iteration Time: 6.60960

Cumulative Model Updates: 16,585
Cumulative Timesteps: 276,737,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.38236
Policy Entropy: 1.22076
Value Function Loss: 5.09982

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 9,539.23002
Overall Steps per Second: 8,208.40770

Timestep Collection Time: 5.24361
Timestep Consumption Time: 0.85014
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.09375

Cumulative Model Updates: 16,588
Cumulative Timesteps: 276,787,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 276787700...
Checkpoint 276787700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.20211
Policy Entropy: 1.22498
Value Function Loss: 5.12991

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.06897

Collected Steps per Second: 8,842.52153
Overall Steps per Second: 7,718.31552

Timestep Collection Time: 5.65789
Timestep Consumption Time: 0.82410
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.48198

Cumulative Model Updates: 16,591
Cumulative Timesteps: 276,837,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.86291
Policy Entropy: 1.22162
Value Function Loss: 5.37300

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 9,499.13334
Overall Steps per Second: 8,221.03205

Timestep Collection Time: 5.26511
Timestep Consumption Time: 0.81855
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 6.08366

Cumulative Model Updates: 16,594
Cumulative Timesteps: 276,887,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 276887744...
Checkpoint 276887744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.92600
Policy Entropy: 1.21808
Value Function Loss: 5.34524

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.06387

Collected Steps per Second: 9,382.85188
Overall Steps per Second: 8,022.32224

Timestep Collection Time: 5.32994
Timestep Consumption Time: 0.90392
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 6.23386

Cumulative Model Updates: 16,597
Cumulative Timesteps: 276,937,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.09111
Policy Entropy: 1.21235
Value Function Loss: 5.29890

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.05978

Collected Steps per Second: 9,245.23656
Overall Steps per Second: 7,983.74142

Timestep Collection Time: 5.41100
Timestep Consumption Time: 0.85498
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.26598

Cumulative Model Updates: 16,600
Cumulative Timesteps: 276,987,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 276987780...
Checkpoint 276987780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.63397
Policy Entropy: 1.21454
Value Function Loss: 5.02504

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.06503
Value Function Update Magnitude: 0.06654

Collected Steps per Second: 8,938.92124
Overall Steps per Second: 7,631.15069

Timestep Collection Time: 5.59508
Timestep Consumption Time: 0.95884
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 6.55393

Cumulative Model Updates: 16,603
Cumulative Timesteps: 277,037,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.10955
Policy Entropy: 1.21961
Value Function Loss: 5.08755

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 8,489.18340
Overall Steps per Second: 7,397.98252

Timestep Collection Time: 5.89055
Timestep Consumption Time: 0.86886
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.75941

Cumulative Model Updates: 16,606
Cumulative Timesteps: 277,087,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 277087800...
Checkpoint 277087800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.55852
Policy Entropy: 1.22201
Value Function Loss: 5.06812

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.05979

Collected Steps per Second: 9,032.68577
Overall Steps per Second: 7,977.16375

Timestep Collection Time: 5.53833
Timestep Consumption Time: 0.73282
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 6.27115

Cumulative Model Updates: 16,609
Cumulative Timesteps: 277,137,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.20447
Policy Entropy: 1.20935
Value Function Loss: 4.98889

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 8,957.01507
Overall Steps per Second: 7,738.81440

Timestep Collection Time: 5.58222
Timestep Consumption Time: 0.87872
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.46094

Cumulative Model Updates: 16,612
Cumulative Timesteps: 277,187,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 277187826...
Checkpoint 277187826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.18518
Policy Entropy: 1.20956
Value Function Loss: 5.13899

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 8,896.67230
Overall Steps per Second: 7,810.74919

Timestep Collection Time: 5.62210
Timestep Consumption Time: 0.78164
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 6.40374

Cumulative Model Updates: 16,615
Cumulative Timesteps: 277,237,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.34084
Policy Entropy: 1.21104
Value Function Loss: 4.93962

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 8,906.99419
Overall Steps per Second: 7,719.71399

Timestep Collection Time: 5.61446
Timestep Consumption Time: 0.86350
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.47796

Cumulative Model Updates: 16,618
Cumulative Timesteps: 277,287,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 277287852...
Checkpoint 277287852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.10696
Policy Entropy: 1.21578
Value Function Loss: 5.08491

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.08807
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 8,792.48254
Overall Steps per Second: 7,699.01783

Timestep Collection Time: 5.68986
Timestep Consumption Time: 0.80811
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.49797

Cumulative Model Updates: 16,621
Cumulative Timesteps: 277,337,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.27633
Policy Entropy: 1.21450
Value Function Loss: 5.11079

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.08599
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 8,807.48672
Overall Steps per Second: 7,718.07195

Timestep Collection Time: 5.67926
Timestep Consumption Time: 0.80163
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.48089

Cumulative Model Updates: 16,624
Cumulative Timesteps: 277,387,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 277387900...
Checkpoint 277387900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.78946
Policy Entropy: 1.22631
Value Function Loss: 5.40428

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 9,038.27155
Overall Steps per Second: 7,809.81617

Timestep Collection Time: 5.53292
Timestep Consumption Time: 0.87031
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.40322

Cumulative Model Updates: 16,627
Cumulative Timesteps: 277,437,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.58019
Policy Entropy: 1.22399
Value Function Loss: 5.34754

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.06847

Collected Steps per Second: 8,858.36909
Overall Steps per Second: 7,691.34512

Timestep Collection Time: 5.64664
Timestep Consumption Time: 0.85678
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.50341

Cumulative Model Updates: 16,630
Cumulative Timesteps: 277,487,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 277487928...
Checkpoint 277487928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.79801
Policy Entropy: 1.21636
Value Function Loss: 5.00530

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.06306

Collected Steps per Second: 8,993.32661
Overall Steps per Second: 7,782.69006

Timestep Collection Time: 5.56123
Timestep Consumption Time: 0.86508
PPO Batch Consumption Time: 0.04550
Total Iteration Time: 6.42631

Cumulative Model Updates: 16,633
Cumulative Timesteps: 277,537,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.48784
Policy Entropy: 1.22158
Value Function Loss: 5.10872

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 8,804.23374
Overall Steps per Second: 7,712.00253

Timestep Collection Time: 5.67931
Timestep Consumption Time: 0.80435
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.48366

Cumulative Model Updates: 16,636
Cumulative Timesteps: 277,587,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 277587944...
Checkpoint 277587944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.31122
Policy Entropy: 1.21622
Value Function Loss: 5.19795

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.05393

Collected Steps per Second: 8,860.96667
Overall Steps per Second: 7,816.71433

Timestep Collection Time: 5.64498
Timestep Consumption Time: 0.75413
PPO Batch Consumption Time: 0.04819
Total Iteration Time: 6.39911

Cumulative Model Updates: 16,639
Cumulative Timesteps: 277,637,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.98042
Policy Entropy: 1.22159
Value Function Loss: 5.39609

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.05956

Collected Steps per Second: 8,702.71278
Overall Steps per Second: 7,586.94790

Timestep Collection Time: 5.74602
Timestep Consumption Time: 0.84503
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.59106

Cumulative Model Updates: 16,642
Cumulative Timesteps: 277,687,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 277687970...
Checkpoint 277687970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.65750
Policy Entropy: 1.22185
Value Function Loss: 5.20319

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.06802
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 9,002.83139
Overall Steps per Second: 7,656.11114

Timestep Collection Time: 5.55536
Timestep Consumption Time: 0.97720
PPO Batch Consumption Time: 0.04913
Total Iteration Time: 6.53256

Cumulative Model Updates: 16,645
Cumulative Timesteps: 277,737,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.03451
Policy Entropy: 1.22185
Value Function Loss: 5.03380

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.07728
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 8,911.16296
Overall Steps per Second: 7,770.64257

Timestep Collection Time: 5.61318
Timestep Consumption Time: 0.82386
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.43705

Cumulative Model Updates: 16,648
Cumulative Timesteps: 277,788,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 277788004...
Checkpoint 277788004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.55763
Policy Entropy: 1.21400
Value Function Loss: 5.11473

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.08959
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,904.41328
Overall Steps per Second: 7,744.05060

Timestep Collection Time: 5.61811
Timestep Consumption Time: 0.84181
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.45993

Cumulative Model Updates: 16,651
Cumulative Timesteps: 277,838,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.43990
Policy Entropy: 1.21681
Value Function Loss: 4.95530

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 8,990.84377
Overall Steps per Second: 7,859.17814

Timestep Collection Time: 5.56210
Timestep Consumption Time: 0.80090
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.36301

Cumulative Model Updates: 16,654
Cumulative Timesteps: 277,888,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 277888038...
Checkpoint 277888038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.57212
Policy Entropy: 1.21603
Value Function Loss: 4.93593

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.06090

Collected Steps per Second: 8,967.55652
Overall Steps per Second: 7,783.91101

Timestep Collection Time: 5.57610
Timestep Consumption Time: 0.84792
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.42402

Cumulative Model Updates: 16,657
Cumulative Timesteps: 277,938,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.72670
Policy Entropy: 1.21188
Value Function Loss: 4.63922

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 8,726.35860
Overall Steps per Second: 7,626.94020

Timestep Collection Time: 5.73275
Timestep Consumption Time: 0.82637
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.55912

Cumulative Model Updates: 16,660
Cumulative Timesteps: 277,988,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 277988068...
Checkpoint 277988068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.21909
Policy Entropy: 1.20018
Value Function Loss: 4.68601

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 8,959.16767
Overall Steps per Second: 7,781.31213

Timestep Collection Time: 5.58422
Timestep Consumption Time: 0.84528
PPO Batch Consumption Time: 0.04779
Total Iteration Time: 6.42951

Cumulative Model Updates: 16,663
Cumulative Timesteps: 278,038,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.70188
Policy Entropy: 1.19942
Value Function Loss: 4.81058

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.05305

Collected Steps per Second: 9,139.91088
Overall Steps per Second: 7,884.04442

Timestep Collection Time: 5.47204
Timestep Consumption Time: 0.87165
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.34370

Cumulative Model Updates: 16,666
Cumulative Timesteps: 278,088,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 278088112...
Checkpoint 278088112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.47005
Policy Entropy: 1.19182
Value Function Loss: 4.91061

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.06651
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 8,740.05976
Overall Steps per Second: 7,722.88568

Timestep Collection Time: 5.72239
Timestep Consumption Time: 0.75369
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.47608

Cumulative Model Updates: 16,669
Cumulative Timesteps: 278,138,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.68800
Policy Entropy: 1.18169
Value Function Loss: 4.88581

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 8,880.45918
Overall Steps per Second: 7,687.32447

Timestep Collection Time: 5.63214
Timestep Consumption Time: 0.87415
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 6.50629

Cumulative Model Updates: 16,672
Cumulative Timesteps: 278,188,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 278188142...
Checkpoint 278188142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.59423
Policy Entropy: 1.18071
Value Function Loss: 4.79894

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.06881
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 8,474.50692
Overall Steps per Second: 7,421.67269

Timestep Collection Time: 5.90194
Timestep Consumption Time: 0.83725
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.73918

Cumulative Model Updates: 16,675
Cumulative Timesteps: 278,238,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.61015
Policy Entropy: 1.17751
Value Function Loss: 4.99371

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 8,862.52029
Overall Steps per Second: 7,687.53014

Timestep Collection Time: 5.64490
Timestep Consumption Time: 0.86279
PPO Batch Consumption Time: 0.04946
Total Iteration Time: 6.50768

Cumulative Model Updates: 16,678
Cumulative Timesteps: 278,288,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 278288186...
Checkpoint 278288186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.57066
Policy Entropy: 1.19187
Value Function Loss: 5.29530

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.04363

Collected Steps per Second: 8,669.73359
Overall Steps per Second: 7,536.49427

Timestep Collection Time: 5.76904
Timestep Consumption Time: 0.86747
PPO Batch Consumption Time: 0.04763
Total Iteration Time: 6.63651

Cumulative Model Updates: 16,681
Cumulative Timesteps: 278,338,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.52482
Policy Entropy: 1.19319
Value Function Loss: 5.22514

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.03947

Collected Steps per Second: 8,868.40389
Overall Steps per Second: 7,816.90707

Timestep Collection Time: 5.64138
Timestep Consumption Time: 0.75885
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 6.40023

Cumulative Model Updates: 16,684
Cumulative Timesteps: 278,388,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 278388232...
Checkpoint 278388232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.74646
Policy Entropy: 1.19192
Value Function Loss: 5.08120

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07098
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.04077

Collected Steps per Second: 8,436.40132
Overall Steps per Second: 7,314.86615

Timestep Collection Time: 5.92717
Timestep Consumption Time: 0.90877
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.83594

Cumulative Model Updates: 16,687
Cumulative Timesteps: 278,438,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.72811
Policy Entropy: 1.18270
Value Function Loss: 4.90528

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.05432

Collected Steps per Second: 8,605.59265
Overall Steps per Second: 7,510.71058

Timestep Collection Time: 5.81064
Timestep Consumption Time: 0.84705
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 6.65769

Cumulative Model Updates: 16,690
Cumulative Timesteps: 278,488,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 278488240...
Checkpoint 278488240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.69475
Policy Entropy: 1.19638
Value Function Loss: 4.99969

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 9,015.06601
Overall Steps per Second: 7,775.87991

Timestep Collection Time: 5.54805
Timestep Consumption Time: 0.88415
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 6.43220

Cumulative Model Updates: 16,693
Cumulative Timesteps: 278,538,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.43197
Policy Entropy: 1.19105
Value Function Loss: 5.06674

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.05238

Collected Steps per Second: 8,588.11824
Overall Steps per Second: 7,462.61176

Timestep Collection Time: 5.82502
Timestep Consumption Time: 0.87853
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.70355

Cumulative Model Updates: 16,696
Cumulative Timesteps: 278,588,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 278588282...
Checkpoint 278588282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.77083
Policy Entropy: 1.18751
Value Function Loss: 5.06826

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.04753

Collected Steps per Second: 8,929.09604
Overall Steps per Second: 7,852.09249

Timestep Collection Time: 5.60281
Timestep Consumption Time: 0.76849
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.37130

Cumulative Model Updates: 16,699
Cumulative Timesteps: 278,638,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.67962
Policy Entropy: 1.17751
Value Function Loss: 5.00525

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 8,750.11799
Overall Steps per Second: 7,586.16162

Timestep Collection Time: 5.71467
Timestep Consumption Time: 0.87681
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.59148

Cumulative Model Updates: 16,702
Cumulative Timesteps: 278,688,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 278688314...
Checkpoint 278688314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.42072
Policy Entropy: 1.17959
Value Function Loss: 4.76940

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.04937

Collected Steps per Second: 9,219.10704
Overall Steps per Second: 7,919.38227

Timestep Collection Time: 5.42374
Timestep Consumption Time: 0.89014
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.31388

Cumulative Model Updates: 16,705
Cumulative Timesteps: 278,738,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.59837
Policy Entropy: 1.18948
Value Function Loss: 4.81518

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 9,344.21170
Overall Steps per Second: 8,154.56839

Timestep Collection Time: 5.35347
Timestep Consumption Time: 0.78100
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 6.13448

Cumulative Model Updates: 16,708
Cumulative Timesteps: 278,788,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 278788340...
Checkpoint 278788340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.57691
Policy Entropy: 1.18823
Value Function Loss: 5.12976

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.05411

Collected Steps per Second: 8,925.47137
Overall Steps per Second: 7,763.90455

Timestep Collection Time: 5.60531
Timestep Consumption Time: 0.83862
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.44392

Cumulative Model Updates: 16,711
Cumulative Timesteps: 278,838,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.21622
Policy Entropy: 1.17701
Value Function Loss: 5.24023

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.05008

Collected Steps per Second: 8,759.53066
Overall Steps per Second: 7,532.44834

Timestep Collection Time: 5.71126
Timestep Consumption Time: 0.93040
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 6.64167

Cumulative Model Updates: 16,714
Cumulative Timesteps: 278,888,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 278888398...
Checkpoint 278888398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.30851
Policy Entropy: 1.16444
Value Function Loss: 5.02852

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 9,052.76403
Overall Steps per Second: 7,869.00744

Timestep Collection Time: 5.52561
Timestep Consumption Time: 0.83123
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 6.35684

Cumulative Model Updates: 16,717
Cumulative Timesteps: 278,938,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.77785
Policy Entropy: 1.18578
Value Function Loss: 5.12337

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 8,811.61127
Overall Steps per Second: 7,647.95516

Timestep Collection Time: 5.67615
Timestep Consumption Time: 0.86364
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.53979

Cumulative Model Updates: 16,720
Cumulative Timesteps: 278,988,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 278988436...
Checkpoint 278988436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.03905
Policy Entropy: 1.15548
Value Function Loss: 5.32589

Mean KL Divergence: 0.03341
SB3 Clip Fraction: 0.20735
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.05277

Collected Steps per Second: 8,880.63685
Overall Steps per Second: 7,836.52015

Timestep Collection Time: 5.63158
Timestep Consumption Time: 0.75034
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 6.38191

Cumulative Model Updates: 16,723
Cumulative Timesteps: 279,038,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.86170
Policy Entropy: 1.17496
Value Function Loss: 5.57987

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.04114

Collected Steps per Second: 8,851.40281
Overall Steps per Second: 7,697.12128

Timestep Collection Time: 5.65086
Timestep Consumption Time: 0.84742
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 6.49827

Cumulative Model Updates: 16,726
Cumulative Timesteps: 279,088,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 279088466...
Checkpoint 279088466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.71380
Policy Entropy: 1.16495
Value Function Loss: 5.22264

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.03376

Collected Steps per Second: 8,605.71799
Overall Steps per Second: 7,503.06209

Timestep Collection Time: 5.81241
Timestep Consumption Time: 0.85420
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.66661

Cumulative Model Updates: 16,729
Cumulative Timesteps: 279,138,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.35124
Policy Entropy: 1.16759
Value Function Loss: 5.46164

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.04173

Collected Steps per Second: 8,805.58448
Overall Steps per Second: 7,739.05147

Timestep Collection Time: 5.68071
Timestep Consumption Time: 0.78287
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.46358

Cumulative Model Updates: 16,732
Cumulative Timesteps: 279,188,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 279188508...
Checkpoint 279188508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.97570
Policy Entropy: 1.18528
Value Function Loss: 5.13786

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 8,754.83130
Overall Steps per Second: 7,631.34680

Timestep Collection Time: 5.71456
Timestep Consumption Time: 0.84130
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 6.55585

Cumulative Model Updates: 16,735
Cumulative Timesteps: 279,238,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.82808
Policy Entropy: 1.18295
Value Function Loss: 5.11548

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 8,856.92596
Overall Steps per Second: 7,845.10672

Timestep Collection Time: 5.64846
Timestep Consumption Time: 0.72851
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.37697

Cumulative Model Updates: 16,738
Cumulative Timesteps: 279,288,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 279288566...
Checkpoint 279288566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.87851
Policy Entropy: 1.17111
Value Function Loss: 4.89569

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 8,785.17844
Overall Steps per Second: 7,613.42996

Timestep Collection Time: 5.69209
Timestep Consumption Time: 0.87604
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 6.56813

Cumulative Model Updates: 16,741
Cumulative Timesteps: 279,338,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.85717
Policy Entropy: 1.14689
Value Function Loss: 4.95232

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.07784

Collected Steps per Second: 8,646.00658
Overall Steps per Second: 7,512.31116

Timestep Collection Time: 5.78579
Timestep Consumption Time: 0.87314
PPO Batch Consumption Time: 0.04847
Total Iteration Time: 6.65894

Cumulative Model Updates: 16,744
Cumulative Timesteps: 279,388,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 279388596...
Checkpoint 279388596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.24949
Policy Entropy: 1.16517
Value Function Loss: 5.24023

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 8,842.62631
Overall Steps per Second: 7,857.00453

Timestep Collection Time: 5.65443
Timestep Consumption Time: 0.70932
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.36375

Cumulative Model Updates: 16,747
Cumulative Timesteps: 279,438,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.71092
Policy Entropy: 1.17910
Value Function Loss: 5.32421

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 8,832.28321
Overall Steps per Second: 7,685.96605

Timestep Collection Time: 5.66399
Timestep Consumption Time: 0.84475
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.50875

Cumulative Model Updates: 16,750
Cumulative Timesteps: 279,488,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 279488622...
Checkpoint 279488622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.83799
Policy Entropy: 1.15743
Value Function Loss: 5.43343

Mean KL Divergence: 0.03843
SB3 Clip Fraction: 0.18979
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.08566

Collected Steps per Second: 8,688.46582
Overall Steps per Second: 7,631.69078

Timestep Collection Time: 5.75499
Timestep Consumption Time: 0.79690
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.55189

Cumulative Model Updates: 16,753
Cumulative Timesteps: 279,538,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.00538
Policy Entropy: 1.17509
Value Function Loss: 5.23307

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 8,956.63607
Overall Steps per Second: 7,730.27839

Timestep Collection Time: 5.58379
Timestep Consumption Time: 0.88583
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 6.46962

Cumulative Model Updates: 16,756
Cumulative Timesteps: 279,588,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 279588636...
Checkpoint 279588636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.64769
Policy Entropy: 1.15140
Value Function Loss: 5.13237

Mean KL Divergence: 0.03604
SB3 Clip Fraction: 0.20515
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 8,938.70321
Overall Steps per Second: 7,746.97162

Timestep Collection Time: 5.59634
Timestep Consumption Time: 0.86090
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.45723

Cumulative Model Updates: 16,759
Cumulative Timesteps: 279,638,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.46309
Policy Entropy: 1.15997
Value Function Loss: 4.90040

Mean KL Divergence: 0.02629
SB3 Clip Fraction: 0.18742
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 8,913.46987
Overall Steps per Second: 7,827.98084

Timestep Collection Time: 5.61218
Timestep Consumption Time: 0.77823
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.39041

Cumulative Model Updates: 16,762
Cumulative Timesteps: 279,688,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 279688684...
Checkpoint 279688684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.49426
Policy Entropy: 1.14682
Value Function Loss: 4.98874

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 9,005.93779
Overall Steps per Second: 7,805.00795

Timestep Collection Time: 5.55345
Timestep Consumption Time: 0.85449
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 6.40794

Cumulative Model Updates: 16,765
Cumulative Timesteps: 279,738,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.52285
Policy Entropy: 1.14226
Value Function Loss: 4.92609

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.05002

Collected Steps per Second: 9,032.59000
Overall Steps per Second: 7,860.95019

Timestep Collection Time: 5.53817
Timestep Consumption Time: 0.82544
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 6.36361

Cumulative Model Updates: 16,768
Cumulative Timesteps: 279,788,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 279788722...
Checkpoint 279788722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.67663
Policy Entropy: 1.16435
Value Function Loss: 4.91427

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.05027

Collected Steps per Second: 8,572.38913
Overall Steps per Second: 7,547.91037

Timestep Collection Time: 5.83618
Timestep Consumption Time: 0.79215
PPO Batch Consumption Time: 0.04743
Total Iteration Time: 6.62832

Cumulative Model Updates: 16,771
Cumulative Timesteps: 279,838,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.98365
Policy Entropy: 1.18203
Value Function Loss: 4.93758

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 8,914.04601
Overall Steps per Second: 7,722.62192

Timestep Collection Time: 5.61159
Timestep Consumption Time: 0.86574
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.47733

Cumulative Model Updates: 16,774
Cumulative Timesteps: 279,888,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 279888774...
Checkpoint 279888774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.07831
Policy Entropy: 1.19476
Value Function Loss: 5.11171

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 8,829.83079
Overall Steps per Second: 7,685.91986

Timestep Collection Time: 5.66398
Timestep Consumption Time: 0.84298
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.50696

Cumulative Model Updates: 16,777
Cumulative Timesteps: 279,938,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.96333
Policy Entropy: 1.18721
Value Function Loss: 5.26625

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 8,744.17902
Overall Steps per Second: 7,595.36859

Timestep Collection Time: 5.71809
Timestep Consumption Time: 0.86487
PPO Batch Consumption Time: 0.05018
Total Iteration Time: 6.58296

Cumulative Model Updates: 16,780
Cumulative Timesteps: 279,988,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 279988786...
Checkpoint 279988786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.36488
Policy Entropy: 1.18595
Value Function Loss: 5.32012

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.08646
Value Function Update Magnitude: 0.04516

Collected Steps per Second: 8,842.16778
Overall Steps per Second: 7,663.68099

Timestep Collection Time: 5.65721
Timestep Consumption Time: 0.86994
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 6.52715

Cumulative Model Updates: 16,783
Cumulative Timesteps: 280,038,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.44181
Policy Entropy: 1.17084
Value Function Loss: 5.08580

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.08202
Value Function Update Magnitude: 0.03933

Collected Steps per Second: 8,524.71861
Overall Steps per Second: 7,573.21303

Timestep Collection Time: 5.86647
Timestep Consumption Time: 0.73707
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 6.60354

Cumulative Model Updates: 16,786
Cumulative Timesteps: 280,088,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 280088818...
Checkpoint 280088818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.09536
Policy Entropy: 1.17507
Value Function Loss: 5.31912

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.08392
Value Function Update Magnitude: 0.03952

Collected Steps per Second: 8,912.11674
Overall Steps per Second: 7,697.79110

Timestep Collection Time: 5.61303
Timestep Consumption Time: 0.88546
PPO Batch Consumption Time: 0.05099
Total Iteration Time: 6.49849

Cumulative Model Updates: 16,789
Cumulative Timesteps: 280,138,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.48620
Policy Entropy: 1.17742
Value Function Loss: 5.07084

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.08063
Value Function Update Magnitude: 0.03833

Collected Steps per Second: 8,904.41760
Overall Steps per Second: 7,786.37304

Timestep Collection Time: 5.61586
Timestep Consumption Time: 0.80638
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.42225

Cumulative Model Updates: 16,792
Cumulative Timesteps: 280,188,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 280188848...
Checkpoint 280188848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.20751
Policy Entropy: 1.18078
Value Function Loss: 5.38610

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 8,999.62063
Overall Steps per Second: 7,764.19523

Timestep Collection Time: 5.55757
Timestep Consumption Time: 0.88431
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.44188

Cumulative Model Updates: 16,795
Cumulative Timesteps: 280,238,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.57808
Policy Entropy: 1.17859
Value Function Loss: 5.09602

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.08533
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 8,500.93983
Overall Steps per Second: 7,416.63582

Timestep Collection Time: 5.88547
Timestep Consumption Time: 0.86045
PPO Batch Consumption Time: 0.04645
Total Iteration Time: 6.74592

Cumulative Model Updates: 16,798
Cumulative Timesteps: 280,288,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 280288896...
Checkpoint 280288896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.32207
Policy Entropy: 1.15798
Value Function Loss: 5.03055

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.08033
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 8,880.57505
Overall Steps per Second: 7,785.44706

Timestep Collection Time: 5.63184
Timestep Consumption Time: 0.79219
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.42404

Cumulative Model Updates: 16,801
Cumulative Timesteps: 280,338,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.82238
Policy Entropy: 1.17059
Value Function Loss: 4.84504

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.04533

Collected Steps per Second: 8,520.63694
Overall Steps per Second: 7,410.35037

Timestep Collection Time: 5.87092
Timestep Consumption Time: 0.87964
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.75056

Cumulative Model Updates: 16,804
Cumulative Timesteps: 280,388,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 280388934...
Checkpoint 280388934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.00321
Policy Entropy: 1.16669
Value Function Loss: 4.96914

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.04927

Collected Steps per Second: 8,773.55226
Overall Steps per Second: 7,569.41769

Timestep Collection Time: 5.70077
Timestep Consumption Time: 0.90687
PPO Batch Consumption Time: 0.04713
Total Iteration Time: 6.60764

Cumulative Model Updates: 16,807
Cumulative Timesteps: 280,438,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.52763
Policy Entropy: 1.17955
Value Function Loss: 4.92199

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.07173
Value Function Update Magnitude: 0.04756

Collected Steps per Second: 9,054.80020
Overall Steps per Second: 7,797.56544

Timestep Collection Time: 5.52480
Timestep Consumption Time: 0.89079
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.41559

Cumulative Model Updates: 16,810
Cumulative Timesteps: 280,488,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 280488976...
Checkpoint 280488976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.60240
Policy Entropy: 1.17421
Value Function Loss: 4.69566

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.04339

Collected Steps per Second: 8,719.37398
Overall Steps per Second: 7,521.88182

Timestep Collection Time: 5.73550
Timestep Consumption Time: 0.91310
PPO Batch Consumption Time: 0.05141
Total Iteration Time: 6.64860

Cumulative Model Updates: 16,813
Cumulative Timesteps: 280,538,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.77470
Policy Entropy: 1.19926
Value Function Loss: 4.68145

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.04425

Collected Steps per Second: 9,092.53350
Overall Steps per Second: 7,993.33536

Timestep Collection Time: 5.50188
Timestep Consumption Time: 0.75659
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.25846

Cumulative Model Updates: 16,816
Cumulative Timesteps: 280,589,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 280589012...
Checkpoint 280589012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.98119
Policy Entropy: 1.20225
Value Function Loss: 4.94124

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.06136

Collected Steps per Second: 9,342.43356
Overall Steps per Second: 8,044.53623

Timestep Collection Time: 5.35192
Timestep Consumption Time: 0.86347
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.21540

Cumulative Model Updates: 16,819
Cumulative Timesteps: 280,639,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.04911
Policy Entropy: 1.18318
Value Function Loss: 5.17443

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.07603

Collected Steps per Second: 9,245.19268
Overall Steps per Second: 7,985.68911

Timestep Collection Time: 5.41038
Timestep Consumption Time: 0.85333
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 6.26370

Cumulative Model Updates: 16,822
Cumulative Timesteps: 280,689,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 280689032...
Checkpoint 280689032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.78817
Policy Entropy: 1.16399
Value Function Loss: 5.04591

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 8,786.12757
Overall Steps per Second: 7,476.79019

Timestep Collection Time: 5.69284
Timestep Consumption Time: 0.99693
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 6.68977

Cumulative Model Updates: 16,825
Cumulative Timesteps: 280,739,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.13982
Policy Entropy: 1.15838
Value Function Loss: 4.90910

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.08075

Collected Steps per Second: 8,656.44246
Overall Steps per Second: 7,502.50203

Timestep Collection Time: 5.77789
Timestep Consumption Time: 0.88868
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 6.66658

Cumulative Model Updates: 16,828
Cumulative Timesteps: 280,789,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 280789066...
Checkpoint 280789066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.63846
Policy Entropy: 1.17270
Value Function Loss: 4.73602

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 8,850.90128
Overall Steps per Second: 7,734.61389

Timestep Collection Time: 5.65118
Timestep Consumption Time: 0.81560
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.46677

Cumulative Model Updates: 16,831
Cumulative Timesteps: 280,839,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.29183
Policy Entropy: 1.14650
Value Function Loss: 4.87609

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 8,285.42760
Overall Steps per Second: 7,231.36404

Timestep Collection Time: 6.03590
Timestep Consumption Time: 0.87981
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.91571

Cumulative Model Updates: 16,834
Cumulative Timesteps: 280,889,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 280889094...
Checkpoint 280889094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.41481
Policy Entropy: 1.16568
Value Function Loss: 5.09978

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 8,469.28072
Overall Steps per Second: 7,415.91542

Timestep Collection Time: 5.90534
Timestep Consumption Time: 0.83880
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.74414

Cumulative Model Updates: 16,837
Cumulative Timesteps: 280,939,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.57323
Policy Entropy: 1.16025
Value Function Loss: 5.30274

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 8,604.74546
Overall Steps per Second: 7,417.61103

Timestep Collection Time: 5.81284
Timestep Consumption Time: 0.93030
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.74314

Cumulative Model Updates: 16,840
Cumulative Timesteps: 280,989,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 280989126...
Checkpoint 280989126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.60213
Policy Entropy: 1.15560
Value Function Loss: 5.14961

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 8,895.52582
Overall Steps per Second: 7,766.83202

Timestep Collection Time: 5.62148
Timestep Consumption Time: 0.81693
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 6.43840

Cumulative Model Updates: 16,843
Cumulative Timesteps: 281,039,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.93353
Policy Entropy: 1.17532
Value Function Loss: 4.85881

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.06303

Collected Steps per Second: 8,837.48641
Overall Steps per Second: 7,793.34339

Timestep Collection Time: 5.65953
Timestep Consumption Time: 0.75826
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 6.41778

Cumulative Model Updates: 16,846
Cumulative Timesteps: 281,089,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 281089148...
Checkpoint 281089148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.14076
Policy Entropy: 1.17592
Value Function Loss: 4.86567

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.05471

Collected Steps per Second: 8,874.51627
Overall Steps per Second: 7,706.32882

Timestep Collection Time: 5.63411
Timestep Consumption Time: 0.85406
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 6.48817

Cumulative Model Updates: 16,849
Cumulative Timesteps: 281,139,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.74329
Policy Entropy: 1.16725
Value Function Loss: 4.95288

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.05588

Collected Steps per Second: 8,665.57477
Overall Steps per Second: 7,449.50843

Timestep Collection Time: 5.77227
Timestep Consumption Time: 0.94227
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 6.71454

Cumulative Model Updates: 16,852
Cumulative Timesteps: 281,189,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281189168...
Checkpoint 281189168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.32294
Policy Entropy: 1.16237
Value Function Loss: 4.82999

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 8,762.51375
Overall Steps per Second: 7,626.11391

Timestep Collection Time: 5.70795
Timestep Consumption Time: 0.85057
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.55852

Cumulative Model Updates: 16,855
Cumulative Timesteps: 281,239,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.65156
Policy Entropy: 1.17060
Value Function Loss: 4.77983

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 8,781.06699
Overall Steps per Second: 7,705.76581

Timestep Collection Time: 5.69680
Timestep Consumption Time: 0.79496
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 6.49176

Cumulative Model Updates: 16,858
Cumulative Timesteps: 281,289,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 281289208...
Checkpoint 281289208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.99571
Policy Entropy: 1.18172
Value Function Loss: 4.50205

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.06089

Collected Steps per Second: 8,761.24541
Overall Steps per Second: 7,718.00830

Timestep Collection Time: 5.70695
Timestep Consumption Time: 0.77140
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.47836

Cumulative Model Updates: 16,861
Cumulative Timesteps: 281,339,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.31938
Policy Entropy: 1.17042
Value Function Loss: 4.60797

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.05570

Collected Steps per Second: 8,680.81638
Overall Steps per Second: 7,581.33035

Timestep Collection Time: 5.76098
Timestep Consumption Time: 0.83549
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.59647

Cumulative Model Updates: 16,864
Cumulative Timesteps: 281,389,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 281389218...
Checkpoint 281389218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.74193
Policy Entropy: 1.16024
Value Function Loss: 4.37727

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.04993

Collected Steps per Second: 8,599.16787
Overall Steps per Second: 7,518.50191

Timestep Collection Time: 5.81684
Timestep Consumption Time: 0.83608
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 6.65292

Cumulative Model Updates: 16,867
Cumulative Timesteps: 281,439,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.17947
Policy Entropy: 1.18532
Value Function Loss: 4.64715

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 9,189.72759
Overall Steps per Second: 7,940.55444

Timestep Collection Time: 5.44412
Timestep Consumption Time: 0.85645
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.30057

Cumulative Model Updates: 16,870
Cumulative Timesteps: 281,489,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 281489268...
Checkpoint 281489268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.94960
Policy Entropy: 1.16644
Value Function Loss: 4.71035

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 8,994.31556
Overall Steps per Second: 7,816.52586

Timestep Collection Time: 5.56196
Timestep Consumption Time: 0.83807
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.40003

Cumulative Model Updates: 16,873
Cumulative Timesteps: 281,539,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.04634
Policy Entropy: 1.16934
Value Function Loss: 4.75723

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 8,810.29876
Overall Steps per Second: 7,799.85840

Timestep Collection Time: 5.67699
Timestep Consumption Time: 0.73543
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.41242

Cumulative Model Updates: 16,876
Cumulative Timesteps: 281,589,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 281589310...
Checkpoint 281589310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.73236
Policy Entropy: 1.16886
Value Function Loss: 4.62199

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 8,819.45426
Overall Steps per Second: 7,595.37833

Timestep Collection Time: 5.67110
Timestep Consumption Time: 0.91396
PPO Batch Consumption Time: 0.05226
Total Iteration Time: 6.58506

Cumulative Model Updates: 16,879
Cumulative Timesteps: 281,639,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.64501
Policy Entropy: 1.16772
Value Function Loss: 4.71679

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.04915

Collected Steps per Second: 8,819.41821
Overall Steps per Second: 7,714.86743

Timestep Collection Time: 5.67180
Timestep Consumption Time: 0.81204
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.48384

Cumulative Model Updates: 16,882
Cumulative Timesteps: 281,689,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 281689348...
Checkpoint 281689348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.79050
Policy Entropy: 1.16087
Value Function Loss: 4.74031

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 9,099.17909
Overall Steps per Second: 7,887.07674

Timestep Collection Time: 5.49720
Timestep Consumption Time: 0.84482
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.34202

Cumulative Model Updates: 16,885
Cumulative Timesteps: 281,739,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.39185
Policy Entropy: 1.17457
Value Function Loss: 4.59177

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 8,969.24564
Overall Steps per Second: 7,754.22246

Timestep Collection Time: 5.57773
Timestep Consumption Time: 0.87398
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.45171

Cumulative Model Updates: 16,888
Cumulative Timesteps: 281,789,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 281789396...
Checkpoint 281789396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.47478
Policy Entropy: 1.17458
Value Function Loss: 4.50572

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.05836

Collected Steps per Second: 8,871.24476
Overall Steps per Second: 7,877.92250

Timestep Collection Time: 5.63934
Timestep Consumption Time: 0.71106
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.35041

Cumulative Model Updates: 16,891
Cumulative Timesteps: 281,839,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.14038
Policy Entropy: 1.16357
Value Function Loss: 4.43118

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 8,693.77235
Overall Steps per Second: 7,578.70121

Timestep Collection Time: 5.75124
Timestep Consumption Time: 0.84619
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.59744

Cumulative Model Updates: 16,894
Cumulative Timesteps: 281,889,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 281889424...
Checkpoint 281889424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.70624
Policy Entropy: 1.18150
Value Function Loss: 4.33330

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.04835

Collected Steps per Second: 8,630.52848
Overall Steps per Second: 7,582.99852

Timestep Collection Time: 5.79478
Timestep Consumption Time: 0.80050
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 6.59528

Cumulative Model Updates: 16,897
Cumulative Timesteps: 281,939,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.12971
Policy Entropy: 1.17949
Value Function Loss: 4.06163

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.05372

Collected Steps per Second: 9,097.37573
Overall Steps per Second: 7,866.88167

Timestep Collection Time: 5.49829
Timestep Consumption Time: 0.86001
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.35830

Cumulative Model Updates: 16,900
Cumulative Timesteps: 281,989,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281989456...
Checkpoint 281989456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.43490
Policy Entropy: 1.18289
Value Function Loss: 4.26411

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.04892

Collected Steps per Second: 8,815.12786
Overall Steps per Second: 7,693.73094

Timestep Collection Time: 5.67434
Timestep Consumption Time: 0.82706
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 6.50140

Cumulative Model Updates: 16,903
Cumulative Timesteps: 282,039,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.48014
Policy Entropy: 1.18112
Value Function Loss: 4.64653

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.04952

Collected Steps per Second: 8,759.42353
Overall Steps per Second: 7,734.37392

Timestep Collection Time: 5.71088
Timestep Consumption Time: 0.75687
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.46775

Cumulative Model Updates: 16,906
Cumulative Timesteps: 282,089,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 282089500...
Checkpoint 282089500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.32073
Policy Entropy: 1.18618
Value Function Loss: 4.94175

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.04297

Collected Steps per Second: 8,703.38147
Overall Steps per Second: 7,536.81831

Timestep Collection Time: 5.74719
Timestep Consumption Time: 0.88956
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.63675

Cumulative Model Updates: 16,909
Cumulative Timesteps: 282,139,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.14686
Policy Entropy: 1.19027
Value Function Loss: 4.71301

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.04047

Collected Steps per Second: 8,810.93443
Overall Steps per Second: 7,655.76641

Timestep Collection Time: 5.67499
Timestep Consumption Time: 0.85629
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.53129

Cumulative Model Updates: 16,912
Cumulative Timesteps: 282,189,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 282189522...
Checkpoint 282189522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.90710
Policy Entropy: 1.15749
Value Function Loss: 4.53678

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.04080

Collected Steps per Second: 9,068.65882
Overall Steps per Second: 7,793.35132

Timestep Collection Time: 5.51548
Timestep Consumption Time: 0.90256
PPO Batch Consumption Time: 0.05067
Total Iteration Time: 6.41803

Cumulative Model Updates: 16,915
Cumulative Timesteps: 282,239,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.99348
Policy Entropy: 1.18832
Value Function Loss: 4.45735

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.05104

Collected Steps per Second: 8,918.19413
Overall Steps per Second: 7,685.02187

Timestep Collection Time: 5.60719
Timestep Consumption Time: 0.89975
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.50694

Cumulative Model Updates: 16,918
Cumulative Timesteps: 282,289,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 282289546...
Checkpoint 282289546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.77494
Policy Entropy: 1.16654
Value Function Loss: 4.46403

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 9,371.29054
Overall Steps per Second: 8,035.69856

Timestep Collection Time: 5.33737
Timestep Consumption Time: 0.88711
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 6.22447

Cumulative Model Updates: 16,921
Cumulative Timesteps: 282,339,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.44111
Policy Entropy: 1.17306
Value Function Loss: 4.42159

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 8,914.45955
Overall Steps per Second: 7,704.00678

Timestep Collection Time: 5.60976
Timestep Consumption Time: 0.88141
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.49117

Cumulative Model Updates: 16,924
Cumulative Timesteps: 282,389,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 282389572...
Checkpoint 282389572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.23589
Policy Entropy: 1.17048
Value Function Loss: 4.47635

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.04528

Collected Steps per Second: 9,320.73942
Overall Steps per Second: 8,041.06937

Timestep Collection Time: 5.36503
Timestep Consumption Time: 0.85380
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 6.21882

Cumulative Model Updates: 16,927
Cumulative Timesteps: 282,439,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.09014
Policy Entropy: 1.18477
Value Function Loss: 4.65883

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 9,458.77023
Overall Steps per Second: 8,100.31476

Timestep Collection Time: 5.28927
Timestep Consumption Time: 0.88703
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.17630

Cumulative Model Updates: 16,930
Cumulative Timesteps: 282,489,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 282489608...
Checkpoint 282489608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.80651
Policy Entropy: 1.18211
Value Function Loss: 4.57173

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.04405

Collected Steps per Second: 9,230.29248
Overall Steps per Second: 7,973.25099

Timestep Collection Time: 5.41933
Timestep Consumption Time: 0.85440
PPO Batch Consumption Time: 0.04765
Total Iteration Time: 6.27373

Cumulative Model Updates: 16,933
Cumulative Timesteps: 282,539,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.26044
Policy Entropy: 1.17869
Value Function Loss: 4.60596

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 8,434.81550
Overall Steps per Second: 7,508.52918

Timestep Collection Time: 5.92900
Timestep Consumption Time: 0.73143
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.66043

Cumulative Model Updates: 16,936
Cumulative Timesteps: 282,589,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 282589640...
Checkpoint 282589640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.69566
Policy Entropy: 1.16832
Value Function Loss: 4.42531

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.06548

Collected Steps per Second: 8,726.22288
Overall Steps per Second: 7,562.63172

Timestep Collection Time: 5.73146
Timestep Consumption Time: 0.88185
PPO Batch Consumption Time: 0.04680
Total Iteration Time: 6.61331

Cumulative Model Updates: 16,939
Cumulative Timesteps: 282,639,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.16567
Policy Entropy: 1.17813
Value Function Loss: 4.52035

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.06949

Collected Steps per Second: 8,921.97904
Overall Steps per Second: 7,794.60452

Timestep Collection Time: 5.60481
Timestep Consumption Time: 0.81065
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.41546

Cumulative Model Updates: 16,942
Cumulative Timesteps: 282,689,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 282689660...
Checkpoint 282689660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.90934
Policy Entropy: 1.17758
Value Function Loss: 4.45081

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.07899

Collected Steps per Second: 9,019.67038
Overall Steps per Second: 7,782.14136

Timestep Collection Time: 5.54566
Timestep Consumption Time: 0.88188
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 6.42754

Cumulative Model Updates: 16,945
Cumulative Timesteps: 282,739,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.65647
Policy Entropy: 1.17929
Value Function Loss: 4.63025

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 8,890.85460
Overall Steps per Second: 7,767.09151

Timestep Collection Time: 5.62443
Timestep Consumption Time: 0.81376
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 6.43819

Cumulative Model Updates: 16,948
Cumulative Timesteps: 282,789,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 282789686...
Checkpoint 282789686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.24557
Policy Entropy: 1.15844
Value Function Loss: 4.62394

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.06572

Collected Steps per Second: 8,702.16360
Overall Steps per Second: 7,696.59648

Timestep Collection Time: 5.74616
Timestep Consumption Time: 0.75074
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.49690

Cumulative Model Updates: 16,951
Cumulative Timesteps: 282,839,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.51916
Policy Entropy: 1.17192
Value Function Loss: 4.77184

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 8,708.52637
Overall Steps per Second: 7,595.53716

Timestep Collection Time: 5.74334
Timestep Consumption Time: 0.84158
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.58492

Cumulative Model Updates: 16,954
Cumulative Timesteps: 282,889,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 282889706...
Checkpoint 282889706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.58021
Policy Entropy: 1.16350
Value Function Loss: 4.68709

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.05402

Collected Steps per Second: 8,782.38183
Overall Steps per Second: 7,597.16263

Timestep Collection Time: 5.69663
Timestep Consumption Time: 0.88872
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.58535

Cumulative Model Updates: 16,957
Cumulative Timesteps: 282,939,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.52718
Policy Entropy: 1.16413
Value Function Loss: 4.65731

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 9,105.81415
Overall Steps per Second: 7,921.29648

Timestep Collection Time: 5.49429
Timestep Consumption Time: 0.82159
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.31589

Cumulative Model Updates: 16,960
Cumulative Timesteps: 282,989,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 282989766...
Checkpoint 282989766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.97750
Policy Entropy: 1.15094
Value Function Loss: 4.62423

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.04661

Collected Steps per Second: 8,538.40350
Overall Steps per Second: 7,409.13363

Timestep Collection Time: 5.85941
Timestep Consumption Time: 0.89307
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 6.75248

Cumulative Model Updates: 16,963
Cumulative Timesteps: 283,039,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.62818
Policy Entropy: 1.16766
Value Function Loss: 4.63749

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 8,893.97622
Overall Steps per Second: 7,855.13169

Timestep Collection Time: 5.62268
Timestep Consumption Time: 0.74360
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 6.36628

Cumulative Model Updates: 16,966
Cumulative Timesteps: 283,089,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 283089804...
Checkpoint 283089804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.94853
Policy Entropy: 1.17329
Value Function Loss: 4.51592

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.07689
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 8,730.00563
Overall Steps per Second: 7,578.73918

Timestep Collection Time: 5.73035
Timestep Consumption Time: 0.87048
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 6.60083

Cumulative Model Updates: 16,969
Cumulative Timesteps: 283,139,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.78747
Policy Entropy: 1.16753
Value Function Loss: 4.57505

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.05687

Collected Steps per Second: 8,914.85363
Overall Steps per Second: 7,763.59542

Timestep Collection Time: 5.61041
Timestep Consumption Time: 0.83196
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.44238

Cumulative Model Updates: 16,972
Cumulative Timesteps: 283,189,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 283189846...
Checkpoint 283189846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.38291
Policy Entropy: 1.16686
Value Function Loss: 4.54523

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 8,899.05836
Overall Steps per Second: 7,692.18870

Timestep Collection Time: 5.62127
Timestep Consumption Time: 0.88195
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.50322

Cumulative Model Updates: 16,975
Cumulative Timesteps: 283,239,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.23928
Policy Entropy: 1.16289
Value Function Loss: 4.69843

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.05609

Collected Steps per Second: 8,766.80673
Overall Steps per Second: 7,657.86998

Timestep Collection Time: 5.70652
Timestep Consumption Time: 0.82636
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.53289

Cumulative Model Updates: 16,978
Cumulative Timesteps: 283,289,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 283289898...
Checkpoint 283289898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.15441
Policy Entropy: 1.17465
Value Function Loss: 4.60576

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.05665

Collected Steps per Second: 8,746.84940
Overall Steps per Second: 7,707.49059

Timestep Collection Time: 5.71680
Timestep Consumption Time: 0.77091
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.48771

Cumulative Model Updates: 16,981
Cumulative Timesteps: 283,339,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.70208
Policy Entropy: 1.16750
Value Function Loss: 4.63685

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 9,180.75204
Overall Steps per Second: 7,949.49319

Timestep Collection Time: 5.44879
Timestep Consumption Time: 0.84394
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 6.29273

Cumulative Model Updates: 16,984
Cumulative Timesteps: 283,389,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 283389926...
Checkpoint 283389926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.02656
Policy Entropy: 1.16037
Value Function Loss: 4.52015

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.04353

Collected Steps per Second: 9,092.47380
Overall Steps per Second: 7,885.58730

Timestep Collection Time: 5.49971
Timestep Consumption Time: 0.84173
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.34144

Cumulative Model Updates: 16,987
Cumulative Timesteps: 283,439,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.89956
Policy Entropy: 1.14561
Value Function Loss: 4.49752

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.05510

Collected Steps per Second: 8,938.48415
Overall Steps per Second: 7,742.60293

Timestep Collection Time: 5.59580
Timestep Consumption Time: 0.86430
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 6.46010

Cumulative Model Updates: 16,990
Cumulative Timesteps: 283,489,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 283489950...
Checkpoint 283489950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.22653
Policy Entropy: 1.14601
Value Function Loss: 4.55209

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.05064

Collected Steps per Second: 8,234.45146
Overall Steps per Second: 7,252.22460

Timestep Collection Time: 6.07448
Timestep Consumption Time: 0.82272
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 6.89719

Cumulative Model Updates: 16,993
Cumulative Timesteps: 283,539,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.07738
Policy Entropy: 1.14935
Value Function Loss: 4.56804

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 8,902.37249
Overall Steps per Second: 7,808.25854

Timestep Collection Time: 5.61940
Timestep Consumption Time: 0.78741
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.40681

Cumulative Model Updates: 16,996
Cumulative Timesteps: 283,589,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 283589996...
Checkpoint 283589996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.69705
Policy Entropy: 1.16380
Value Function Loss: 4.54965

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.04815

Collected Steps per Second: 9,034.74415
Overall Steps per Second: 7,821.69745

Timestep Collection Time: 5.53574
Timestep Consumption Time: 0.85852
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.39426

Cumulative Model Updates: 16,999
Cumulative Timesteps: 283,640,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.54819
Policy Entropy: 1.17170
Value Function Loss: 4.60824

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.04661

Collected Steps per Second: 8,916.46089
Overall Steps per Second: 7,869.91747

Timestep Collection Time: 5.61052
Timestep Consumption Time: 0.74609
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.35661

Cumulative Model Updates: 17,002
Cumulative Timesteps: 283,690,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 283690036...
Checkpoint 283690036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.67240
Policy Entropy: 1.16242
Value Function Loss: 4.55586

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.04772

Collected Steps per Second: 8,721.71680
Overall Steps per Second: 7,583.18153

Timestep Collection Time: 5.73511
Timestep Consumption Time: 0.86107
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 6.59618

Cumulative Model Updates: 17,005
Cumulative Timesteps: 283,740,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.63563
Policy Entropy: 1.15816
Value Function Loss: 4.68700

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.05107

Collected Steps per Second: 8,792.92392
Overall Steps per Second: 7,696.93770

Timestep Collection Time: 5.68798
Timestep Consumption Time: 0.80993
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.49791

Cumulative Model Updates: 17,008
Cumulative Timesteps: 283,790,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 283790070...
Checkpoint 283790070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.21133
Policy Entropy: 1.17830
Value Function Loss: 4.60775

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.05703

Collected Steps per Second: 9,020.61137
Overall Steps per Second: 7,660.06023

Timestep Collection Time: 5.54353
Timestep Consumption Time: 0.98462
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 6.52815

Cumulative Model Updates: 17,011
Cumulative Timesteps: 283,840,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.26287
Policy Entropy: 1.17590
Value Function Loss: 4.46380

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.05157

Collected Steps per Second: 8,737.79430
Overall Steps per Second: 7,586.02501

Timestep Collection Time: 5.72273
Timestep Consumption Time: 0.86887
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 6.59159

Cumulative Model Updates: 17,014
Cumulative Timesteps: 283,890,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 283890080...
Checkpoint 283890080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.32917
Policy Entropy: 1.17608
Value Function Loss: 4.36097

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.05838

Collected Steps per Second: 8,966.70028
Overall Steps per Second: 7,840.63788

Timestep Collection Time: 5.57819
Timestep Consumption Time: 0.80113
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.37933

Cumulative Model Updates: 17,017
Cumulative Timesteps: 283,940,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.78444
Policy Entropy: 1.17237
Value Function Loss: 4.48740

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 8,511.49597
Overall Steps per Second: 7,363.92978

Timestep Collection Time: 5.87441
Timestep Consumption Time: 0.91544
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 6.78985

Cumulative Model Updates: 17,020
Cumulative Timesteps: 283,990,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 283990098...
Checkpoint 283990098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.21497
Policy Entropy: 1.17983
Value Function Loss: 4.69984

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.05684

Collected Steps per Second: 8,656.10455
Overall Steps per Second: 7,520.30876

Timestep Collection Time: 5.77881
Timestep Consumption Time: 0.87278
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 6.65159

Cumulative Model Updates: 17,023
Cumulative Timesteps: 284,040,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.63287
Policy Entropy: 1.18289
Value Function Loss: 4.58135

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.04552

Collected Steps per Second: 8,753.27259
Overall Steps per Second: 7,589.49828

Timestep Collection Time: 5.71558
Timestep Consumption Time: 0.87643
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.59200

Cumulative Model Updates: 17,026
Cumulative Timesteps: 284,090,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 284090150...
Checkpoint 284090150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.01571
Policy Entropy: 1.16820
Value Function Loss: 4.67638

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.03757

Collected Steps per Second: 8,745.95258
Overall Steps per Second: 7,644.55225

Timestep Collection Time: 5.71945
Timestep Consumption Time: 0.82404
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.54348

Cumulative Model Updates: 17,029
Cumulative Timesteps: 284,140,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.03573
Policy Entropy: 1.16828
Value Function Loss: 4.75707

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.04089

Collected Steps per Second: 9,105.27073
Overall Steps per Second: 7,812.68521

Timestep Collection Time: 5.49418
Timestep Consumption Time: 0.90900
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.40318

Cumulative Model Updates: 17,032
Cumulative Timesteps: 284,190,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 284190198...
Checkpoint 284190198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.21905
Policy Entropy: 1.16542
Value Function Loss: 4.74204

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.04225

Collected Steps per Second: 9,114.56174
Overall Steps per Second: 7,882.67444

Timestep Collection Time: 5.48814
Timestep Consumption Time: 0.85767
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 6.34582

Cumulative Model Updates: 17,035
Cumulative Timesteps: 284,240,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.60943
Policy Entropy: 1.15218
Value Function Loss: 4.52554

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 9,163.67453
Overall Steps per Second: 8,037.44938

Timestep Collection Time: 5.45764
Timestep Consumption Time: 0.76474
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.22237

Cumulative Model Updates: 17,038
Cumulative Timesteps: 284,290,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 284290232...
Checkpoint 284290232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.36294
Policy Entropy: 1.15724
Value Function Loss: 4.52342

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 9,326.07733
Overall Steps per Second: 8,008.07867

Timestep Collection Time: 5.36174
Timestep Consumption Time: 0.88245
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.24419

Cumulative Model Updates: 17,041
Cumulative Timesteps: 284,340,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.58616
Policy Entropy: 1.17066
Value Function Loss: 4.65828

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.04856

Collected Steps per Second: 9,236.93325
Overall Steps per Second: 8,031.35830

Timestep Collection Time: 5.41500
Timestep Consumption Time: 0.81284
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.22784

Cumulative Model Updates: 17,044
Cumulative Timesteps: 284,390,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 284390254...
Checkpoint 284390254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.70621
Policy Entropy: 1.17060
Value Function Loss: 4.62429

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.04020
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 8,905.47457
Overall Steps per Second: 7,710.38402

Timestep Collection Time: 5.61475
Timestep Consumption Time: 0.87027
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 6.48502

Cumulative Model Updates: 17,047
Cumulative Timesteps: 284,440,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.68801
Policy Entropy: 1.15742
Value Function Loss: 4.72715

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.05492

Collected Steps per Second: 8,962.94186
Overall Steps per Second: 7,766.38416

Timestep Collection Time: 5.58053
Timestep Consumption Time: 0.85979
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.44032

Cumulative Model Updates: 17,050
Cumulative Timesteps: 284,490,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 284490274...
Checkpoint 284490274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.32132
Policy Entropy: 1.16100
Value Function Loss: 4.52377

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 8,783.01476
Overall Steps per Second: 7,719.42556

Timestep Collection Time: 5.69281
Timestep Consumption Time: 0.78436
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.47717

Cumulative Model Updates: 17,053
Cumulative Timesteps: 284,540,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.49040
Policy Entropy: 1.16023
Value Function Loss: 4.54589

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.05557

Collected Steps per Second: 8,995.61253
Overall Steps per Second: 7,787.75445

Timestep Collection Time: 5.56049
Timestep Consumption Time: 0.86242
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.42290

Cumulative Model Updates: 17,056
Cumulative Timesteps: 284,590,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 284590294...
Checkpoint 284590294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.25337
Policy Entropy: 1.16676
Value Function Loss: 4.38660

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.04525

Collected Steps per Second: 8,853.28289
Overall Steps per Second: 7,663.68366

Timestep Collection Time: 5.65033
Timestep Consumption Time: 0.87708
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.52741

Cumulative Model Updates: 17,059
Cumulative Timesteps: 284,640,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.30559
Policy Entropy: 1.16094
Value Function Loss: 4.50688

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.03920

Collected Steps per Second: 8,788.48098
Overall Steps per Second: 7,674.23919

Timestep Collection Time: 5.69245
Timestep Consumption Time: 0.82650
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.51895

Cumulative Model Updates: 17,062
Cumulative Timesteps: 284,690,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 284690346...
Checkpoint 284690346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.11890
Policy Entropy: 1.16541
Value Function Loss: 4.54004

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.04302

Collected Steps per Second: 8,744.23609
Overall Steps per Second: 7,626.58449

Timestep Collection Time: 5.72034
Timestep Consumption Time: 0.83830
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 6.55864

Cumulative Model Updates: 17,065
Cumulative Timesteps: 284,740,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.76319
Policy Entropy: 1.15171
Value Function Loss: 4.31243

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.03887

Collected Steps per Second: 8,725.99314
Overall Steps per Second: 7,736.34322

Timestep Collection Time: 5.73138
Timestep Consumption Time: 0.73317
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 6.46455

Cumulative Model Updates: 17,068
Cumulative Timesteps: 284,790,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 284790378...
Checkpoint 284790378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.06922
Policy Entropy: 1.17033
Value Function Loss: 4.47467

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.04348

Collected Steps per Second: 8,771.82213
Overall Steps per Second: 7,580.56280

Timestep Collection Time: 5.70189
Timestep Consumption Time: 0.89603
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 6.59793

Cumulative Model Updates: 17,071
Cumulative Timesteps: 284,840,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.39490
Policy Entropy: 1.15766
Value Function Loss: 4.52445

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.03757

Collected Steps per Second: 8,553.47311
Overall Steps per Second: 7,446.51871

Timestep Collection Time: 5.84581
Timestep Consumption Time: 0.86900
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.71482

Cumulative Model Updates: 17,074
Cumulative Timesteps: 284,890,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 284890396...
Checkpoint 284890396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.10305
Policy Entropy: 1.15106
Value Function Loss: 4.79641

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.03529

Collected Steps per Second: 9,223.71311
Overall Steps per Second: 7,944.61943

Timestep Collection Time: 5.42146
Timestep Consumption Time: 0.87286
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.29432

Cumulative Model Updates: 17,077
Cumulative Timesteps: 284,940,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.15857
Policy Entropy: 1.15755
Value Function Loss: 4.68212

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.03474

Collected Steps per Second: 8,985.13482
Overall Steps per Second: 7,842.76263

Timestep Collection Time: 5.56630
Timestep Consumption Time: 0.81078
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.37709

Cumulative Model Updates: 17,080
Cumulative Timesteps: 284,990,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 284990416...
Checkpoint 284990416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.14341
Policy Entropy: 1.16253
Value Function Loss: 4.85317

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.03399

Collected Steps per Second: 8,962.95483
Overall Steps per Second: 7,863.93808

Timestep Collection Time: 5.57986
Timestep Consumption Time: 0.77981
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.35966

Cumulative Model Updates: 17,083
Cumulative Timesteps: 285,040,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.13213
Policy Entropy: 1.15197
Value Function Loss: 4.68176

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.03411

Collected Steps per Second: 8,885.98873
Overall Steps per Second: 7,711.86508

Timestep Collection Time: 5.62729
Timestep Consumption Time: 0.85675
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 6.48403

Cumulative Model Updates: 17,086
Cumulative Timesteps: 285,090,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 285090432...
Checkpoint 285090432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.88961
Policy Entropy: 1.13676
Value Function Loss: 4.57155

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.15372
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.03426

Collected Steps per Second: 8,625.79445
Overall Steps per Second: 7,505.62378

Timestep Collection Time: 5.79796
Timestep Consumption Time: 0.86531
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.66327

Cumulative Model Updates: 17,089
Cumulative Timesteps: 285,140,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.70865
Policy Entropy: 1.13657
Value Function Loss: 4.29682

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 8,822.15965
Overall Steps per Second: 7,652.06013

Timestep Collection Time: 5.66800
Timestep Consumption Time: 0.86671
PPO Batch Consumption Time: 0.04776
Total Iteration Time: 6.53471

Cumulative Model Updates: 17,092
Cumulative Timesteps: 285,190,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 285190448...
Checkpoint 285190448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.89867
Policy Entropy: 1.14445
Value Function Loss: 4.49982

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.03343

Collected Steps per Second: 8,823.49974
Overall Steps per Second: 7,585.08603

Timestep Collection Time: 5.66895
Timestep Consumption Time: 0.92557
PPO Batch Consumption Time: 0.04821
Total Iteration Time: 6.59452

Cumulative Model Updates: 17,095
Cumulative Timesteps: 285,240,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.96485
Policy Entropy: 1.14118
Value Function Loss: 4.47820

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.03701

Collected Steps per Second: 8,878.53261
Overall Steps per Second: 7,834.18610

Timestep Collection Time: 5.63471
Timestep Consumption Time: 0.75114
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.38586

Cumulative Model Updates: 17,098
Cumulative Timesteps: 285,290,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 285290496...
Checkpoint 285290496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.37730
Policy Entropy: 1.14550
Value Function Loss: 4.67823

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.03725

Collected Steps per Second: 8,836.64432
Overall Steps per Second: 7,440.03584

Timestep Collection Time: 5.65916
Timestep Consumption Time: 1.06231
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.72147

Cumulative Model Updates: 17,101
Cumulative Timesteps: 285,340,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.10962
Policy Entropy: 1.15865
Value Function Loss: 4.52714

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.03478

Collected Steps per Second: 8,966.58463
Overall Steps per Second: 7,729.39741

Timestep Collection Time: 5.57849
Timestep Consumption Time: 0.89291
PPO Batch Consumption Time: 0.04697
Total Iteration Time: 6.47140

Cumulative Model Updates: 17,104
Cumulative Timesteps: 285,390,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 285390524...
Checkpoint 285390524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.51394
Policy Entropy: 1.15558
Value Function Loss: 4.50138

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 9,008.58723
Overall Steps per Second: 7,789.25106

Timestep Collection Time: 5.55137
Timestep Consumption Time: 0.86902
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 6.42039

Cumulative Model Updates: 17,107
Cumulative Timesteps: 285,440,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.78877
Policy Entropy: 1.14720
Value Function Loss: 4.37940

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 8,918.04372
Overall Steps per Second: 7,742.41689

Timestep Collection Time: 5.60706
Timestep Consumption Time: 0.85139
PPO Batch Consumption Time: 0.04844
Total Iteration Time: 6.45845

Cumulative Model Updates: 17,110
Cumulative Timesteps: 285,490,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 285490538...
Checkpoint 285490538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.08352
Policy Entropy: 1.13083
Value Function Loss: 4.51964

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 8,892.03258
Overall Steps per Second: 7,814.99353

Timestep Collection Time: 5.62481
Timestep Consumption Time: 0.77519
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 6.40001

Cumulative Model Updates: 17,113
Cumulative Timesteps: 285,540,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.42376
Policy Entropy: 1.14217
Value Function Loss: 4.58708

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 8,645.39783
Overall Steps per Second: 7,543.87654

Timestep Collection Time: 5.78435
Timestep Consumption Time: 0.84460
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.62895

Cumulative Model Updates: 17,116
Cumulative Timesteps: 285,590,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 285590562...
Checkpoint 285590562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.16269
Policy Entropy: 1.14781
Value Function Loss: 4.55449

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.04966

Collected Steps per Second: 8,698.67093
Overall Steps per Second: 7,666.55611

Timestep Collection Time: 5.74869
Timestep Consumption Time: 0.77392
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.52262

Cumulative Model Updates: 17,119
Cumulative Timesteps: 285,640,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.29218
Policy Entropy: 1.15516
Value Function Loss: 4.60019

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.03980

Collected Steps per Second: 8,880.31242
Overall Steps per Second: 7,683.94973

Timestep Collection Time: 5.63381
Timestep Consumption Time: 0.87716
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.51097

Cumulative Model Updates: 17,122
Cumulative Timesteps: 285,690,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 285690598...
Checkpoint 285690598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.98842
Policy Entropy: 1.15589
Value Function Loss: 4.40123

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 8,858.16487
Overall Steps per Second: 7,598.38863

Timestep Collection Time: 5.64541
Timestep Consumption Time: 0.93598
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.58140

Cumulative Model Updates: 17,125
Cumulative Timesteps: 285,740,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.88586
Policy Entropy: 1.16751
Value Function Loss: 4.42452

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 9,063.23436
Overall Steps per Second: 7,820.78508

Timestep Collection Time: 5.51944
Timestep Consumption Time: 0.87685
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 6.39629

Cumulative Model Updates: 17,128
Cumulative Timesteps: 285,790,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 285790630...
Checkpoint 285790630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.53604
Policy Entropy: 1.16387
Value Function Loss: 4.22077

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 8,538.66403
Overall Steps per Second: 7,397.43474

Timestep Collection Time: 5.85665
Timestep Consumption Time: 0.90353
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.76018

Cumulative Model Updates: 17,131
Cumulative Timesteps: 285,840,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.35222
Policy Entropy: 1.16111
Value Function Loss: 4.23725

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 8,942.81419
Overall Steps per Second: 7,837.25521

Timestep Collection Time: 5.59332
Timestep Consumption Time: 0.78902
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.38234

Cumulative Model Updates: 17,134
Cumulative Timesteps: 285,890,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 285890658...
Checkpoint 285890658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.74031
Policy Entropy: 1.15244
Value Function Loss: 4.11769

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 8,610.84009
Overall Steps per Second: 7,469.63110

Timestep Collection Time: 5.80710
Timestep Consumption Time: 0.88721
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.69431

Cumulative Model Updates: 17,137
Cumulative Timesteps: 285,940,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.27989
Policy Entropy: 1.17945
Value Function Loss: 4.27846

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.06161

Collected Steps per Second: 8,889.94825
Overall Steps per Second: 7,828.33150

Timestep Collection Time: 5.62770
Timestep Consumption Time: 0.76318
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 6.39089

Cumulative Model Updates: 17,140
Cumulative Timesteps: 285,990,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 285990692...
Checkpoint 285990692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.07659
Policy Entropy: 1.17927
Value Function Loss: 4.26364

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.04975

Collected Steps per Second: 8,881.52836
Overall Steps per Second: 7,683.87895

Timestep Collection Time: 5.63124
Timestep Consumption Time: 0.87771
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.50895

Cumulative Model Updates: 17,143
Cumulative Timesteps: 286,040,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.62713
Policy Entropy: 1.17303
Value Function Loss: 4.52992

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.05379

Collected Steps per Second: 9,219.83298
Overall Steps per Second: 7,955.00021

Timestep Collection Time: 5.42374
Timestep Consumption Time: 0.86237
PPO Batch Consumption Time: 0.04569
Total Iteration Time: 6.28611

Cumulative Model Updates: 17,146
Cumulative Timesteps: 286,090,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 286090712...
Checkpoint 286090712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.48822
Policy Entropy: 1.15793
Value Function Loss: 4.49525

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.06550

Collected Steps per Second: 9,212.49470
Overall Steps per Second: 7,970.83166

Timestep Collection Time: 5.42958
Timestep Consumption Time: 0.84580
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 6.27538

Cumulative Model Updates: 17,149
Cumulative Timesteps: 286,140,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.29893
Policy Entropy: 1.16430
Value Function Loss: 4.41024

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 9,415.15130
Overall Steps per Second: 8,147.67067

Timestep Collection Time: 5.31229
Timestep Consumption Time: 0.82640
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.13869

Cumulative Model Updates: 17,152
Cumulative Timesteps: 286,190,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 286190748...
Checkpoint 286190748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.23836
Policy Entropy: 1.16996
Value Function Loss: 4.28659

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 8,887.98862
Overall Steps per Second: 7,792.32766

Timestep Collection Time: 5.62895
Timestep Consumption Time: 0.79147
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 6.42042

Cumulative Model Updates: 17,155
Cumulative Timesteps: 286,240,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.98049
Policy Entropy: 1.14866
Value Function Loss: 4.37941

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 8,655.64268
Overall Steps per Second: 7,531.57937

Timestep Collection Time: 5.77889
Timestep Consumption Time: 0.86248
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.64137

Cumulative Model Updates: 17,158
Cumulative Timesteps: 286,290,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 286290798...
Checkpoint 286290798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.14636
Policy Entropy: 1.16166
Value Function Loss: 4.45249

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.07643

Collected Steps per Second: 8,766.08311
Overall Steps per Second: 7,591.63563

Timestep Collection Time: 5.70631
Timestep Consumption Time: 0.88278
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.58909

Cumulative Model Updates: 17,161
Cumulative Timesteps: 286,340,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.50548
Policy Entropy: 1.16728
Value Function Loss: 4.38053

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.07019

Collected Steps per Second: 9,108.12989
Overall Steps per Second: 7,875.88604

Timestep Collection Time: 5.48982
Timestep Consumption Time: 0.85893
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 6.34875

Cumulative Model Updates: 17,164
Cumulative Timesteps: 286,390,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 286390822...
Checkpoint 286390822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.10999
Policy Entropy: 1.13848
Value Function Loss: 4.37983

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 8,852.88935
Overall Steps per Second: 7,577.64491

Timestep Collection Time: 5.64945
Timestep Consumption Time: 0.95075
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 6.60020

Cumulative Model Updates: 17,167
Cumulative Timesteps: 286,440,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.93915
Policy Entropy: 1.16638
Value Function Loss: 4.40420

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 8,727.15876
Overall Steps per Second: 7,637.25074

Timestep Collection Time: 5.73291
Timestep Consumption Time: 0.81814
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.55105

Cumulative Model Updates: 17,170
Cumulative Timesteps: 286,490,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 286490868...
Checkpoint 286490868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.81709
Policy Entropy: 1.16155
Value Function Loss: 4.32635

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.05513

Collected Steps per Second: 8,767.81404
Overall Steps per Second: 7,578.16254

Timestep Collection Time: 5.70610
Timestep Consumption Time: 0.89577
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.60186

Cumulative Model Updates: 17,173
Cumulative Timesteps: 286,540,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.81021
Policy Entropy: 1.16925
Value Function Loss: 4.42332

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 8,796.90845
Overall Steps per Second: 7,766.97124

Timestep Collection Time: 5.68609
Timestep Consumption Time: 0.75400
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 6.44009

Cumulative Model Updates: 17,176
Cumulative Timesteps: 286,590,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 286590918...
Checkpoint 286590918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.73064
Policy Entropy: 1.16522
Value Function Loss: 4.49654

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.05782

Collected Steps per Second: 9,000.44702
Overall Steps per Second: 7,818.54206

Timestep Collection Time: 5.55861
Timestep Consumption Time: 0.84028
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.39889

Cumulative Model Updates: 17,179
Cumulative Timesteps: 286,640,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.65559
Policy Entropy: 1.17608
Value Function Loss: 4.58104

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 8,729.99952
Overall Steps per Second: 7,663.38173

Timestep Collection Time: 5.73104
Timestep Consumption Time: 0.79767
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.52871

Cumulative Model Updates: 17,182
Cumulative Timesteps: 286,690,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 286690980...
Checkpoint 286690980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.22357
Policy Entropy: 1.17209
Value Function Loss: 4.39222

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 8,615.86639
Overall Steps per Second: 7,477.49961

Timestep Collection Time: 5.80394
Timestep Consumption Time: 0.88359
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 6.68753

Cumulative Model Updates: 17,185
Cumulative Timesteps: 286,740,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.88896
Policy Entropy: 1.16616
Value Function Loss: 4.31367

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 8,907.72441
Overall Steps per Second: 7,775.40747

Timestep Collection Time: 5.61355
Timestep Consumption Time: 0.81749
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.43105

Cumulative Model Updates: 17,188
Cumulative Timesteps: 286,790,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 286790990...
Checkpoint 286790990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.74818
Policy Entropy: 1.15795
Value Function Loss: 4.46369

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.06494

Collected Steps per Second: 8,717.22530
Overall Steps per Second: 7,672.28964

Timestep Collection Time: 5.73669
Timestep Consumption Time: 0.78131
PPO Batch Consumption Time: 0.04596
Total Iteration Time: 6.51800

Cumulative Model Updates: 17,191
Cumulative Timesteps: 286,840,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.72962
Policy Entropy: 1.18226
Value Function Loss: 4.75334

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07343

Collected Steps per Second: 9,099.39545
Overall Steps per Second: 7,913.55742

Timestep Collection Time: 5.49663
Timestep Consumption Time: 0.82366
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.32029

Cumulative Model Updates: 17,194
Cumulative Timesteps: 286,891,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 286891014...
Checkpoint 286891014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.77311
Policy Entropy: 1.17540
Value Function Loss: 4.70929

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 8,850.95109
Overall Steps per Second: 7,749.56599

Timestep Collection Time: 5.65047
Timestep Consumption Time: 0.80306
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.45352

Cumulative Model Updates: 17,197
Cumulative Timesteps: 286,941,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.32599
Policy Entropy: 1.15312
Value Function Loss: 4.61453

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 8,756.59088
Overall Steps per Second: 7,631.83806

Timestep Collection Time: 5.71113
Timestep Consumption Time: 0.84169
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.55281

Cumulative Model Updates: 17,200
Cumulative Timesteps: 286,991,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 286991036...
Checkpoint 286991036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.87510
Policy Entropy: 1.17015
Value Function Loss: 4.44771

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.06494

Collected Steps per Second: 9,019.12036
Overall Steps per Second: 7,757.48142

Timestep Collection Time: 5.54688
Timestep Consumption Time: 0.90212
PPO Batch Consumption Time: 0.05007
Total Iteration Time: 6.44900

Cumulative Model Updates: 17,203
Cumulative Timesteps: 287,041,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.87021
Policy Entropy: 1.16004
Value Function Loss: 4.56748

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.06014

Collected Steps per Second: 9,077.37328
Overall Steps per Second: 7,984.40946

Timestep Collection Time: 5.50996
Timestep Consumption Time: 0.75424
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 6.26421

Cumulative Model Updates: 17,206
Cumulative Timesteps: 287,091,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 287091080...
Checkpoint 287091080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.78437
Policy Entropy: 1.15308
Value Function Loss: 4.57628

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 8,939.78479
Overall Steps per Second: 7,728.62187

Timestep Collection Time: 5.59298
Timestep Consumption Time: 0.87648
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 6.46946

Cumulative Model Updates: 17,209
Cumulative Timesteps: 287,141,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.45003
Policy Entropy: 1.16377
Value Function Loss: 4.50211

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.06337

Collected Steps per Second: 8,845.48885
Overall Steps per Second: 7,671.29046

Timestep Collection Time: 5.65599
Timestep Consumption Time: 0.86573
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 6.52172

Cumulative Model Updates: 17,212
Cumulative Timesteps: 287,191,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 287191110...
Checkpoint 287191110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.87198
Policy Entropy: 1.16282
Value Function Loss: 4.52154

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.05541

Collected Steps per Second: 8,916.29108
Overall Steps per Second: 7,728.65513

Timestep Collection Time: 5.60928
Timestep Consumption Time: 0.86196
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.47124

Cumulative Model Updates: 17,215
Cumulative Timesteps: 287,241,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.52012
Policy Entropy: 1.16123
Value Function Loss: 4.57620

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.05566

Collected Steps per Second: 8,778.04975
Overall Steps per Second: 7,633.55739

Timestep Collection Time: 5.69967
Timestep Consumption Time: 0.85455
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.55422

Cumulative Model Updates: 17,218
Cumulative Timesteps: 287,291,156

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 287291156...
Checkpoint 287291156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.13759
Policy Entropy: 1.14994
Value Function Loss: 4.55509

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.05530

Collected Steps per Second: 8,973.35200
Overall Steps per Second: 7,761.78301

Timestep Collection Time: 5.57562
Timestep Consumption Time: 0.87032
PPO Batch Consumption Time: 0.04840
Total Iteration Time: 6.44594

Cumulative Model Updates: 17,221
Cumulative Timesteps: 287,341,188

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.67090
Policy Entropy: 1.15980
Value Function Loss: 4.55102

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.05616

Collected Steps per Second: 8,752.97282
Overall Steps per Second: 7,603.10971

Timestep Collection Time: 5.71394
Timestep Consumption Time: 0.86415
PPO Batch Consumption Time: 0.04838
Total Iteration Time: 6.57810

Cumulative Model Updates: 17,224
Cumulative Timesteps: 287,391,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 287391202...
Checkpoint 287391202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.90766
Policy Entropy: 1.17275
Value Function Loss: 4.37129

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.05112

Collected Steps per Second: 8,729.95448
Overall Steps per Second: 7,594.43004

Timestep Collection Time: 5.72901
Timestep Consumption Time: 0.85661
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.58562

Cumulative Model Updates: 17,227
Cumulative Timesteps: 287,441,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.68799
Policy Entropy: 1.15594
Value Function Loss: 4.39637

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 8,725.73980
Overall Steps per Second: 7,587.75197

Timestep Collection Time: 5.73155
Timestep Consumption Time: 0.85960
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.59115

Cumulative Model Updates: 17,230
Cumulative Timesteps: 287,491,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 287491228...
Checkpoint 287491228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.52855
Policy Entropy: 1.16217
Value Function Loss: 4.18778

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 8,922.43866
Overall Steps per Second: 7,764.04433

Timestep Collection Time: 5.60587
Timestep Consumption Time: 0.83639
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.44226

Cumulative Model Updates: 17,233
Cumulative Timesteps: 287,541,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.85205
Policy Entropy: 1.16461
Value Function Loss: 4.25893

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.06879

Collected Steps per Second: 9,022.89362
Overall Steps per Second: 7,719.04635

Timestep Collection Time: 5.54279
Timestep Consumption Time: 0.93625
PPO Batch Consumption Time: 0.04873
Total Iteration Time: 6.47904

Cumulative Model Updates: 17,236
Cumulative Timesteps: 287,591,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 287591258...
Checkpoint 287591258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.64737
Policy Entropy: 1.16847
Value Function Loss: 4.27562

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 8,933.17128
Overall Steps per Second: 7,750.29639

Timestep Collection Time: 5.59801
Timestep Consumption Time: 0.85439
PPO Batch Consumption Time: 0.04825
Total Iteration Time: 6.45240

Cumulative Model Updates: 17,239
Cumulative Timesteps: 287,641,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.10722
Policy Entropy: 1.16206
Value Function Loss: 4.35855

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 8,872.99011
Overall Steps per Second: 7,644.25727

Timestep Collection Time: 5.63688
Timestep Consumption Time: 0.90607
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.54295

Cumulative Model Updates: 17,242
Cumulative Timesteps: 287,691,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 287691282...
Checkpoint 287691282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.44755
Policy Entropy: 1.15371
Value Function Loss: 4.23859

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.08842

Collected Steps per Second: 8,734.49663
Overall Steps per Second: 7,639.30586

Timestep Collection Time: 5.72580
Timestep Consumption Time: 0.82087
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.54667

Cumulative Model Updates: 17,245
Cumulative Timesteps: 287,741,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.54832
Policy Entropy: 1.15916
Value Function Loss: 4.02730

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 8,935.29971
Overall Steps per Second: 7,681.34410

Timestep Collection Time: 5.59936
Timestep Consumption Time: 0.91408
PPO Batch Consumption Time: 0.05276
Total Iteration Time: 6.51344

Cumulative Model Updates: 17,248
Cumulative Timesteps: 287,791,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 287791326...
Checkpoint 287791326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.84099
Policy Entropy: 1.15974
Value Function Loss: 4.12763

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 8,976.73109
Overall Steps per Second: 7,752.03303

Timestep Collection Time: 5.57152
Timestep Consumption Time: 0.88021
PPO Batch Consumption Time: 0.04708
Total Iteration Time: 6.45173

Cumulative Model Updates: 17,251
Cumulative Timesteps: 287,841,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.00960
Policy Entropy: 1.14034
Value Function Loss: 4.24614

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 8,718.13643
Overall Steps per Second: 7,561.26876

Timestep Collection Time: 5.73746
Timestep Consumption Time: 0.87783
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.61529

Cumulative Model Updates: 17,254
Cumulative Timesteps: 287,891,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 287891360...
Checkpoint 287891360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.03538
Policy Entropy: 1.14351
Value Function Loss: 4.30427

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.04480
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 9,175.54545
Overall Steps per Second: 7,892.14068

Timestep Collection Time: 5.45167
Timestep Consumption Time: 0.88654
PPO Batch Consumption Time: 0.04846
Total Iteration Time: 6.33820

Cumulative Model Updates: 17,257
Cumulative Timesteps: 287,941,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.48689
Policy Entropy: 1.15333
Value Function Loss: 4.33399

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 8,920.93941
Overall Steps per Second: 7,846.86220

Timestep Collection Time: 5.60748
Timestep Consumption Time: 0.76755
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 6.37503

Cumulative Model Updates: 17,260
Cumulative Timesteps: 287,991,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 287991406...
Checkpoint 287991406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.54459
Policy Entropy: 1.16314
Value Function Loss: 4.35457

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 9,128.68261
Overall Steps per Second: 7,812.75591

Timestep Collection Time: 5.47899
Timestep Consumption Time: 0.92284
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.40184

Cumulative Model Updates: 17,263
Cumulative Timesteps: 288,041,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.86442
Policy Entropy: 1.14310
Value Function Loss: 4.56217

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.05507

Collected Steps per Second: 9,129.65863
Overall Steps per Second: 7,899.88541

Timestep Collection Time: 5.47688
Timestep Consumption Time: 0.85258
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.32946

Cumulative Model Updates: 17,266
Cumulative Timesteps: 288,091,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 288091424...
Checkpoint 288091424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.50608
Policy Entropy: 1.13155
Value Function Loss: 4.50375

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.15969
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.04691

Collected Steps per Second: 8,743.30328
Overall Steps per Second: 7,550.62040

Timestep Collection Time: 5.72095
Timestep Consumption Time: 0.90367
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 6.62462

Cumulative Model Updates: 17,269
Cumulative Timesteps: 288,141,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.18103
Policy Entropy: 1.15698
Value Function Loss: 4.49858

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.04272

Collected Steps per Second: 8,958.70457
Overall Steps per Second: 7,770.07900

Timestep Collection Time: 5.58183
Timestep Consumption Time: 0.85388
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.43571

Cumulative Model Updates: 17,272
Cumulative Timesteps: 288,191,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 288191450...
Checkpoint 288191450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.37754
Policy Entropy: 1.15291
Value Function Loss: 4.45320

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.04958

Collected Steps per Second: 8,904.67939
Overall Steps per Second: 7,794.47008

Timestep Collection Time: 5.61727
Timestep Consumption Time: 0.80010
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 6.41737

Cumulative Model Updates: 17,275
Cumulative Timesteps: 288,241,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.83584
Policy Entropy: 1.14007
Value Function Loss: 4.46726

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.07164
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 9,054.40940
Overall Steps per Second: 7,825.83123

Timestep Collection Time: 5.52438
Timestep Consumption Time: 0.86727
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 6.39165

Cumulative Model Updates: 17,278
Cumulative Timesteps: 288,291,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 288291490...
Checkpoint 288291490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.55268
Policy Entropy: 1.15835
Value Function Loss: 4.52955

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.04890

Collected Steps per Second: 8,698.10739
Overall Steps per Second: 7,455.78776

Timestep Collection Time: 5.75137
Timestep Consumption Time: 0.95832
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 6.70969

Cumulative Model Updates: 17,281
Cumulative Timesteps: 288,341,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.49068
Policy Entropy: 1.15934
Value Function Loss: 4.38454

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.05693

Collected Steps per Second: 9,124.80652
Overall Steps per Second: 7,906.22535

Timestep Collection Time: 5.48264
Timestep Consumption Time: 0.84504
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.32767

Cumulative Model Updates: 17,284
Cumulative Timesteps: 288,391,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 288391544...
Checkpoint 288391544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.41193
Policy Entropy: 1.14989
Value Function Loss: 4.29194

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.06660

Collected Steps per Second: 8,766.38999
Overall Steps per Second: 7,510.21033

Timestep Collection Time: 5.70588
Timestep Consumption Time: 0.95438
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.66027

Cumulative Model Updates: 17,287
Cumulative Timesteps: 288,441,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.76590
Policy Entropy: 1.15237
Value Function Loss: 4.44863

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.06437

Collected Steps per Second: 8,959.40979
Overall Steps per Second: 7,791.95696

Timestep Collection Time: 5.58184
Timestep Consumption Time: 0.83632
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.41816

Cumulative Model Updates: 17,290
Cumulative Timesteps: 288,491,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 288491574...
Checkpoint 288491574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.99372
Policy Entropy: 1.17198
Value Function Loss: 4.32077

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 8,890.26990
Overall Steps per Second: 7,708.22965

Timestep Collection Time: 5.62615
Timestep Consumption Time: 0.86276
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.48891

Cumulative Model Updates: 17,293
Cumulative Timesteps: 288,541,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.61128
Policy Entropy: 1.17266
Value Function Loss: 4.35313

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.04753

Collected Steps per Second: 8,828.77608
Overall Steps per Second: 7,665.28477

Timestep Collection Time: 5.66511
Timestep Consumption Time: 0.85989
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.52500

Cumulative Model Updates: 17,296
Cumulative Timesteps: 288,591,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 288591608...
Checkpoint 288591608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.25562
Policy Entropy: 1.15477
Value Function Loss: 4.01243

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.04530

Collected Steps per Second: 8,974.45530
Overall Steps per Second: 7,802.49692

Timestep Collection Time: 5.57271
Timestep Consumption Time: 0.83704
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.40974

Cumulative Model Updates: 17,299
Cumulative Timesteps: 288,641,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.64124
Policy Entropy: 1.13761
Value Function Loss: 4.14781

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.04542

Collected Steps per Second: 8,601.45097
Overall Steps per Second: 7,547.31726

Timestep Collection Time: 5.81623
Timestep Consumption Time: 0.81235
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.62858

Cumulative Model Updates: 17,302
Cumulative Timesteps: 288,691,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 288691648...
Checkpoint 288691648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.25166
Policy Entropy: 1.16042
Value Function Loss: 4.16587

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.05052

Collected Steps per Second: 8,808.81434
Overall Steps per Second: 7,732.64161

Timestep Collection Time: 5.67863
Timestep Consumption Time: 0.79031
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.46894

Cumulative Model Updates: 17,305
Cumulative Timesteps: 288,741,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.27561
Policy Entropy: 1.14277
Value Function Loss: 4.32421

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.04704

Collected Steps per Second: 8,928.89237
Overall Steps per Second: 7,772.54804

Timestep Collection Time: 5.60293
Timestep Consumption Time: 0.83356
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.43650

Cumulative Model Updates: 17,308
Cumulative Timesteps: 288,791,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 288791698...
Checkpoint 288791698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653.77564
Policy Entropy: 1.15417
Value Function Loss: 4.23837

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.04844

Collected Steps per Second: 8,752.28502
Overall Steps per Second: 7,627.82752

Timestep Collection Time: 5.71576
Timestep Consumption Time: 0.84259
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.55835

Cumulative Model Updates: 17,311
Cumulative Timesteps: 288,841,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.55870
Policy Entropy: 1.14964
Value Function Loss: 4.27385

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.04098

Collected Steps per Second: 9,236.80241
Overall Steps per Second: 8,001.15669

Timestep Collection Time: 5.41594
Timestep Consumption Time: 0.83640
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.25235

Cumulative Model Updates: 17,314
Cumulative Timesteps: 288,891,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 288891750...
Checkpoint 288891750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.43460
Policy Entropy: 1.15870
Value Function Loss: 4.54110

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.04050

Collected Steps per Second: 9,045.40133
Overall Steps per Second: 7,828.15061

Timestep Collection Time: 5.53055
Timestep Consumption Time: 0.85998
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 6.39053

Cumulative Model Updates: 17,317
Cumulative Timesteps: 288,941,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.37675
Policy Entropy: 1.14694
Value Function Loss: 4.60984

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.03932

Collected Steps per Second: 8,824.52380
Overall Steps per Second: 7,780.49906

Timestep Collection Time: 5.66648
Timestep Consumption Time: 0.76036
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.42684

Cumulative Model Updates: 17,320
Cumulative Timesteps: 288,991,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 288991780...
Checkpoint 288991780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.23150
Policy Entropy: 1.14680
Value Function Loss: 4.57704

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.04552

Collected Steps per Second: 8,781.90803
Overall Steps per Second: 7,574.24855

Timestep Collection Time: 5.69557
Timestep Consumption Time: 0.90812
PPO Batch Consumption Time: 0.04735
Total Iteration Time: 6.60369

Cumulative Model Updates: 17,323
Cumulative Timesteps: 289,041,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.44626
Policy Entropy: 1.14097
Value Function Loss: 4.40192

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.05669

Collected Steps per Second: 9,050.26397
Overall Steps per Second: 7,886.19947

Timestep Collection Time: 5.52713
Timestep Consumption Time: 0.81585
PPO Batch Consumption Time: 0.04223
Total Iteration Time: 6.34298

Cumulative Model Updates: 17,326
Cumulative Timesteps: 289,091,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 289091820...
Checkpoint 289091820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.30007
Policy Entropy: 1.16224
Value Function Loss: 4.52506

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.06199

Collected Steps per Second: 9,160.36685
Overall Steps per Second: 7,913.09279

Timestep Collection Time: 5.46048
Timestep Consumption Time: 0.86069
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 6.32117

Cumulative Model Updates: 17,329
Cumulative Timesteps: 289,141,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.25326
Policy Entropy: 1.15802
Value Function Loss: 4.45151

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 8,854.18807
Overall Steps per Second: 7,696.42592

Timestep Collection Time: 5.64795
Timestep Consumption Time: 0.84961
PPO Batch Consumption Time: 0.04599
Total Iteration Time: 6.49756

Cumulative Model Updates: 17,332
Cumulative Timesteps: 289,191,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 289191848...
Checkpoint 289191848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.54847
Policy Entropy: 1.14448
Value Function Loss: 4.44968

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.07672
Value Function Update Magnitude: 0.05427

Collected Steps per Second: 8,925.69457
Overall Steps per Second: 7,842.07481

Timestep Collection Time: 5.60382
Timestep Consumption Time: 0.77434
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.37816

Cumulative Model Updates: 17,335
Cumulative Timesteps: 289,241,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.88194
Policy Entropy: 1.14009
Value Function Loss: 4.35133

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.07225
Value Function Update Magnitude: 0.04391

Collected Steps per Second: 8,714.75970
Overall Steps per Second: 7,619.37755

Timestep Collection Time: 5.74015
Timestep Consumption Time: 0.82522
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.56537

Cumulative Model Updates: 17,338
Cumulative Timesteps: 289,291,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 289291890...
Checkpoint 289291890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.79753
Policy Entropy: 1.14399
Value Function Loss: 4.45827

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.07904
Value Function Update Magnitude: 0.03843

Collected Steps per Second: 8,909.86209
Overall Steps per Second: 7,712.75300

Timestep Collection Time: 5.61355
Timestep Consumption Time: 0.87129
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 6.48484

Cumulative Model Updates: 17,341
Cumulative Timesteps: 289,341,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.54971
Policy Entropy: 1.15851
Value Function Loss: 4.43237

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.03947

Collected Steps per Second: 8,973.19585
Overall Steps per Second: 7,807.90439

Timestep Collection Time: 5.57460
Timestep Consumption Time: 0.83198
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.40658

Cumulative Model Updates: 17,344
Cumulative Timesteps: 289,391,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 289391928...
Checkpoint 289391928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.53222
Policy Entropy: 1.15728
Value Function Loss: 4.49163

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.07739
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 8,847.66441
Overall Steps per Second: 7,666.45730

Timestep Collection Time: 5.65347
Timestep Consumption Time: 0.87106
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.52453

Cumulative Model Updates: 17,347
Cumulative Timesteps: 289,441,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.98492
Policy Entropy: 1.16853
Value Function Loss: 4.25892

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 8,840.82171
Overall Steps per Second: 7,773.27052

Timestep Collection Time: 5.65762
Timestep Consumption Time: 0.77700
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 6.43461

Cumulative Model Updates: 17,350
Cumulative Timesteps: 289,491,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 289491966...
Checkpoint 289491966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.83778
Policy Entropy: 1.16516
Value Function Loss: 4.22876

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.07017
Value Function Update Magnitude: 0.06800

Collected Steps per Second: 8,588.97900
Overall Steps per Second: 7,486.68743

Timestep Collection Time: 5.82141
Timestep Consumption Time: 0.85711
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 6.67852

Cumulative Model Updates: 17,353
Cumulative Timesteps: 289,541,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.63401
Policy Entropy: 1.16306
Value Function Loss: 4.14267

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.06856

Collected Steps per Second: 8,928.04774
Overall Steps per Second: 7,752.01273

Timestep Collection Time: 5.60078
Timestep Consumption Time: 0.84968
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.45045

Cumulative Model Updates: 17,356
Cumulative Timesteps: 289,591,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 289591970...
Checkpoint 289591970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.74550
Policy Entropy: 1.16966
Value Function Loss: 4.26471

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.06821
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 9,084.36679
Overall Steps per Second: 7,806.38480

Timestep Collection Time: 5.50418
Timestep Consumption Time: 0.90109
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.40527

Cumulative Model Updates: 17,359
Cumulative Timesteps: 289,641,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.02230
Policy Entropy: 1.17392
Value Function Loss: 4.20836

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 8,922.90682
Overall Steps per Second: 7,735.50908

Timestep Collection Time: 5.60356
Timestep Consumption Time: 0.86014
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 6.46370

Cumulative Model Updates: 17,362
Cumulative Timesteps: 289,691,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 289691972...
Checkpoint 289691972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.89080
Policy Entropy: 1.13683
Value Function Loss: 4.16196

Mean KL Divergence: 0.03126
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.08139
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 8,449.56226
Overall Steps per Second: 7,400.73020

Timestep Collection Time: 5.91912
Timestep Consumption Time: 0.83886
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.75798

Cumulative Model Updates: 17,365
Cumulative Timesteps: 289,741,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.51373
Policy Entropy: 1.16756
Value Function Loss: 4.24354

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.07268
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 9,074.06899
Overall Steps per Second: 7,783.42723

Timestep Collection Time: 5.51109
Timestep Consumption Time: 0.91384
PPO Batch Consumption Time: 0.05082
Total Iteration Time: 6.42493

Cumulative Model Updates: 17,368
Cumulative Timesteps: 289,791,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 289791994...
Checkpoint 289791994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.84251
Policy Entropy: 1.15897
Value Function Loss: 4.22562

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 8,821.06842
Overall Steps per Second: 7,547.87074

Timestep Collection Time: 5.66893
Timestep Consumption Time: 0.95625
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 6.62518

Cumulative Model Updates: 17,371
Cumulative Timesteps: 289,842,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.84691
Policy Entropy: 1.16316
Value Function Loss: 4.41225

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 9,336.74517
Overall Steps per Second: 8,060.64576

Timestep Collection Time: 5.35668
Timestep Consumption Time: 0.84803
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.20471

Cumulative Model Updates: 17,374
Cumulative Timesteps: 289,892,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 289892014...
Checkpoint 289892014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.76308
Policy Entropy: 1.16587
Value Function Loss: 4.36644

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 8,827.87306
Overall Steps per Second: 7,696.94579

Timestep Collection Time: 5.66614
Timestep Consumption Time: 0.83254
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 6.49868

Cumulative Model Updates: 17,377
Cumulative Timesteps: 289,942,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.69476
Policy Entropy: 1.16834
Value Function Loss: 4.41525

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.06908

Collected Steps per Second: 8,727.46181
Overall Steps per Second: 7,739.64262

Timestep Collection Time: 5.73110
Timestep Consumption Time: 0.73147
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.46257

Cumulative Model Updates: 17,380
Cumulative Timesteps: 289,992,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 289992052...
Checkpoint 289992052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.65970
Policy Entropy: 1.12163
Value Function Loss: 4.39130

Mean KL Divergence: 0.07549
SB3 Clip Fraction: 0.21723
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 8,958.81097
Overall Steps per Second: 7,763.37422

Timestep Collection Time: 5.58221
Timestep Consumption Time: 0.85957
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 6.44179

Cumulative Model Updates: 17,383
Cumulative Timesteps: 290,042,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.12213
Policy Entropy: 1.15119
Value Function Loss: 4.52132

Mean KL Divergence: 0.03865
SB3 Clip Fraction: 0.19141
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 8,525.34129
Overall Steps per Second: 7,443.18223

Timestep Collection Time: 5.86674
Timestep Consumption Time: 0.85296
PPO Batch Consumption Time: 0.04793
Total Iteration Time: 6.71971

Cumulative Model Updates: 17,386
Cumulative Timesteps: 290,092,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 290092078...
Checkpoint 290092078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.79821
Policy Entropy: 1.13431
Value Function Loss: 4.45811

Mean KL Divergence: 0.04334
SB3 Clip Fraction: 0.22312
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.06646

Collected Steps per Second: 8,907.28021
Overall Steps per Second: 7,781.97163

Timestep Collection Time: 5.61608
Timestep Consumption Time: 0.81211
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.42819

Cumulative Model Updates: 17,389
Cumulative Timesteps: 290,142,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.59247
Policy Entropy: 1.16799
Value Function Loss: 4.47825

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.19644
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.05935

Collected Steps per Second: 8,650.89186
Overall Steps per Second: 7,541.61469

Timestep Collection Time: 5.78206
Timestep Consumption Time: 0.85047
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.63253

Cumulative Model Updates: 17,392
Cumulative Timesteps: 290,192,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 290192122...
Checkpoint 290192122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.21123
Policy Entropy: 1.14887
Value Function Loss: 4.35702

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 8,789.33964
Overall Steps per Second: 7,805.73739

Timestep Collection Time: 5.69053
Timestep Consumption Time: 0.71706
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.40759

Cumulative Model Updates: 17,395
Cumulative Timesteps: 290,242,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.05865
Policy Entropy: 1.17562
Value Function Loss: 4.59538

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.08779

Collected Steps per Second: 8,932.29089
Overall Steps per Second: 7,787.20684

Timestep Collection Time: 5.60013
Timestep Consumption Time: 0.82348
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.42361

Cumulative Model Updates: 17,398
Cumulative Timesteps: 290,292,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 290292160...
Checkpoint 290292160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.94120
Policy Entropy: 1.16853
Value Function Loss: 4.45091

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 8,722.40835
Overall Steps per Second: 7,631.52394

Timestep Collection Time: 5.73443
Timestep Consumption Time: 0.81970
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.55413

Cumulative Model Updates: 17,401
Cumulative Timesteps: 290,342,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.59191
Policy Entropy: 1.16718
Value Function Loss: 4.45295

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.09193

Collected Steps per Second: 9,092.09345
Overall Steps per Second: 7,864.70110

Timestep Collection Time: 5.50126
Timestep Consumption Time: 0.85855
PPO Batch Consumption Time: 0.04449
Total Iteration Time: 6.35981

Cumulative Model Updates: 17,404
Cumulative Timesteps: 290,392,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 290392196...
Checkpoint 290392196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.95349
Policy Entropy: 1.16772
Value Function Loss: 4.41095

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.08415

Collected Steps per Second: 8,605.12423
Overall Steps per Second: 7,551.30540

Timestep Collection Time: 5.81212
Timestep Consumption Time: 0.81111
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.62323

Cumulative Model Updates: 17,407
Cumulative Timesteps: 290,442,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.62375
Policy Entropy: 1.17104
Value Function Loss: 4.52997

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.08258

Collected Steps per Second: 8,713.74702
Overall Steps per Second: 7,685.98788

Timestep Collection Time: 5.74081
Timestep Consumption Time: 0.76765
PPO Batch Consumption Time: 0.05027
Total Iteration Time: 6.50847

Cumulative Model Updates: 17,410
Cumulative Timesteps: 290,492,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 290492234...
Checkpoint 290492234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.93733
Policy Entropy: 1.16842
Value Function Loss: 4.56360

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.08434

Collected Steps per Second: 8,758.33250
Overall Steps per Second: 7,632.76063

Timestep Collection Time: 5.71113
Timestep Consumption Time: 0.84220
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 6.55333

Cumulative Model Updates: 17,413
Cumulative Timesteps: 290,542,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.87127
Policy Entropy: 1.16970
Value Function Loss: 4.60007

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05973
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.07193

Collected Steps per Second: 8,774.94075
Overall Steps per Second: 7,630.25670

Timestep Collection Time: 5.70146
Timestep Consumption Time: 0.85533
PPO Batch Consumption Time: 0.04987
Total Iteration Time: 6.55679

Cumulative Model Updates: 17,416
Cumulative Timesteps: 290,592,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 290592284...
Checkpoint 290592284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.48864
Policy Entropy: 1.16732
Value Function Loss: 4.75252

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.06380

Collected Steps per Second: 9,172.64391
Overall Steps per Second: 7,882.66400

Timestep Collection Time: 5.45339
Timestep Consumption Time: 0.89243
PPO Batch Consumption Time: 0.04776
Total Iteration Time: 6.34582

Cumulative Model Updates: 17,419
Cumulative Timesteps: 290,642,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.43859
Policy Entropy: 1.17263
Value Function Loss: 4.59164

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.06102

Collected Steps per Second: 9,050.63457
Overall Steps per Second: 7,914.10240

Timestep Collection Time: 5.52668
Timestep Consumption Time: 0.79368
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.32036

Cumulative Model Updates: 17,422
Cumulative Timesteps: 290,692,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 290692326...
Checkpoint 290692326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.11219
Policy Entropy: 1.17203
Value Function Loss: 4.50732

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.05982

Collected Steps per Second: 8,781.87874
Overall Steps per Second: 7,730.28927

Timestep Collection Time: 5.69400
Timestep Consumption Time: 0.77458
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.46858

Cumulative Model Updates: 17,425
Cumulative Timesteps: 290,742,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.97338
Policy Entropy: 1.18198
Value Function Loss: 4.47272

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 8,893.14060
Overall Steps per Second: 7,756.19717

Timestep Collection Time: 5.62389
Timestep Consumption Time: 0.82438
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 6.44826

Cumulative Model Updates: 17,428
Cumulative Timesteps: 290,792,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 290792344...
Checkpoint 290792344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.26014
Policy Entropy: 1.18186
Value Function Loss: 4.60552

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.06447

Collected Steps per Second: 8,862.01975
Overall Steps per Second: 7,740.78791

Timestep Collection Time: 5.64431
Timestep Consumption Time: 0.81756
PPO Batch Consumption Time: 0.04374
Total Iteration Time: 6.46187

Cumulative Model Updates: 17,431
Cumulative Timesteps: 290,842,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.75585
Policy Entropy: 1.18522
Value Function Loss: 4.52711

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.06046

Collected Steps per Second: 8,749.84216
Overall Steps per Second: 7,613.97848

Timestep Collection Time: 5.71530
Timestep Consumption Time: 0.85262
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.56792

Cumulative Model Updates: 17,434
Cumulative Timesteps: 290,892,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 290892372...
Checkpoint 290892372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.81211
Policy Entropy: 1.18781
Value Function Loss: 4.38749

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 8,874.76274
Overall Steps per Second: 7,767.58484

Timestep Collection Time: 5.63576
Timestep Consumption Time: 0.80331
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.43907

Cumulative Model Updates: 17,437
Cumulative Timesteps: 290,942,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.34223
Policy Entropy: 1.17495
Value Function Loss: 4.03740

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 8,244.01710
Overall Steps per Second: 7,288.54338

Timestep Collection Time: 6.06646
Timestep Consumption Time: 0.79527
PPO Batch Consumption Time: 0.04843
Total Iteration Time: 6.86173

Cumulative Model Updates: 17,440
Cumulative Timesteps: 290,992,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 290992400...
Checkpoint 290992400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.77508
Policy Entropy: 1.16945
Value Function Loss: 4.15170

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 8,884.72747
Overall Steps per Second: 7,634.34162

Timestep Collection Time: 5.63056
Timestep Consumption Time: 0.92220
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 6.55276

Cumulative Model Updates: 17,443
Cumulative Timesteps: 291,042,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.87741
Policy Entropy: 1.16049
Value Function Loss: 4.18297

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.08585

Collected Steps per Second: 8,731.24113
Overall Steps per Second: 7,610.98070

Timestep Collection Time: 5.72794
Timestep Consumption Time: 0.84310
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 6.57103

Cumulative Model Updates: 17,446
Cumulative Timesteps: 291,092,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 291092438...
Checkpoint 291092438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.75745
Policy Entropy: 1.17391
Value Function Loss: 4.45168

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 8,715.23898
Overall Steps per Second: 7,604.52111

Timestep Collection Time: 5.73891
Timestep Consumption Time: 0.83823
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 6.57714

Cumulative Model Updates: 17,449
Cumulative Timesteps: 291,142,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.22306
Policy Entropy: 1.17367
Value Function Loss: 4.46385

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 8,587.33586
Overall Steps per Second: 7,530.70157

Timestep Collection Time: 5.82416
Timestep Consumption Time: 0.81719
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 6.64135

Cumulative Model Updates: 17,452
Cumulative Timesteps: 291,192,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 291192468...
Checkpoint 291192468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.66713
Policy Entropy: 1.17139
Value Function Loss: 4.38115

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 8,865.82561
Overall Steps per Second: 7,828.29579

Timestep Collection Time: 5.63963
Timestep Consumption Time: 0.74745
PPO Batch Consumption Time: 0.04571
Total Iteration Time: 6.38709

Cumulative Model Updates: 17,455
Cumulative Timesteps: 291,242,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.05202
Policy Entropy: 1.16951
Value Function Loss: 4.30982

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 8,846.74703
Overall Steps per Second: 7,611.56962

Timestep Collection Time: 5.65202
Timestep Consumption Time: 0.91719
PPO Batch Consumption Time: 0.05009
Total Iteration Time: 6.56921

Cumulative Model Updates: 17,458
Cumulative Timesteps: 291,292,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 291292470...
Checkpoint 291292470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.82891
Policy Entropy: 1.17886
Value Function Loss: 4.30839

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 8,757.18351
Overall Steps per Second: 7,572.87289

Timestep Collection Time: 5.71234
Timestep Consumption Time: 0.89334
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 6.60568

Cumulative Model Updates: 17,461
Cumulative Timesteps: 291,342,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.66474
Policy Entropy: 1.17768
Value Function Loss: 4.48995

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 8,762.47784
Overall Steps per Second: 7,611.72310

Timestep Collection Time: 5.70752
Timestep Consumption Time: 0.86287
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.57039

Cumulative Model Updates: 17,464
Cumulative Timesteps: 291,392,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 291392506...
Checkpoint 291392506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.13932
Policy Entropy: 1.17631
Value Function Loss: 4.55817

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 8,870.47689
Overall Steps per Second: 7,686.66274

Timestep Collection Time: 5.63893
Timestep Consumption Time: 0.86845
PPO Batch Consumption Time: 0.05008
Total Iteration Time: 6.50738

Cumulative Model Updates: 17,467
Cumulative Timesteps: 291,442,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.27979
Policy Entropy: 1.16423
Value Function Loss: 4.43481

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.06231

Collected Steps per Second: 8,999.97652
Overall Steps per Second: 7,870.75906

Timestep Collection Time: 5.55801
Timestep Consumption Time: 0.79741
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.35542

Cumulative Model Updates: 17,470
Cumulative Timesteps: 291,492,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 291492548...
Checkpoint 291492548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.26631
Policy Entropy: 1.18033
Value Function Loss: 4.55398

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 9,166.01810
Overall Steps per Second: 7,917.48763

Timestep Collection Time: 5.45537
Timestep Consumption Time: 0.86027
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.31564

Cumulative Model Updates: 17,473
Cumulative Timesteps: 291,542,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.67990
Policy Entropy: 1.18549
Value Function Loss: 4.52374

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,797.36780
Overall Steps per Second: 7,740.13254

Timestep Collection Time: 5.68352
Timestep Consumption Time: 0.77632
PPO Batch Consumption Time: 0.04739
Total Iteration Time: 6.45984

Cumulative Model Updates: 17,476
Cumulative Timesteps: 291,592,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 291592552...
Checkpoint 291592552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.11874
Policy Entropy: 1.18562
Value Function Loss: 4.52559

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 9,155.69661
Overall Steps per Second: 7,867.09314

Timestep Collection Time: 5.46152
Timestep Consumption Time: 0.89458
PPO Batch Consumption Time: 0.05149
Total Iteration Time: 6.35610

Cumulative Model Updates: 17,479
Cumulative Timesteps: 291,642,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.08457
Policy Entropy: 1.16657
Value Function Loss: 4.31627

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.07075
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 9,230.00598
Overall Steps per Second: 7,990.11605

Timestep Collection Time: 5.41971
Timestep Consumption Time: 0.84102
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.26074

Cumulative Model Updates: 17,482
Cumulative Timesteps: 291,692,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 291692580...
Checkpoint 291692580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.33004
Policy Entropy: 1.17494
Value Function Loss: 4.33627

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.06385

Collected Steps per Second: 9,341.83886
Overall Steps per Second: 8,069.08604

Timestep Collection Time: 5.35462
Timestep Consumption Time: 0.84459
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 6.19922

Cumulative Model Updates: 17,485
Cumulative Timesteps: 291,742,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.73618
Policy Entropy: 1.18606
Value Function Loss: 4.50301

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 8,959.23992
Overall Steps per Second: 7,793.93554

Timestep Collection Time: 5.58239
Timestep Consumption Time: 0.83465
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 6.41704

Cumulative Model Updates: 17,488
Cumulative Timesteps: 291,792,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 291792616...
Checkpoint 291792616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.77763
Policy Entropy: 1.15637
Value Function Loss: 4.42300

Mean KL Divergence: 0.06275
SB3 Clip Fraction: 0.21526
Policy Update Magnitude: 0.06879
Value Function Update Magnitude: 0.08126

Collected Steps per Second: 8,432.77716
Overall Steps per Second: 7,390.02984

Timestep Collection Time: 5.93304
Timestep Consumption Time: 0.83716
PPO Batch Consumption Time: 0.05023
Total Iteration Time: 6.77020

Cumulative Model Updates: 17,491
Cumulative Timesteps: 291,842,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.93385
Policy Entropy: 1.17757
Value Function Loss: 4.40505

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 8,786.11748
Overall Steps per Second: 7,655.64980

Timestep Collection Time: 5.69262
Timestep Consumption Time: 0.84060
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.53321

Cumulative Model Updates: 17,494
Cumulative Timesteps: 291,892,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 291892664...
Checkpoint 291892664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.06683
Policy Entropy: 1.14682
Value Function Loss: 4.37548

Mean KL Divergence: 0.03873
SB3 Clip Fraction: 0.19503
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 8,767.53316
Overall Steps per Second: 7,653.59325

Timestep Collection Time: 5.70468
Timestep Consumption Time: 0.83029
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.53497

Cumulative Model Updates: 17,497
Cumulative Timesteps: 291,942,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.19327
Policy Entropy: 1.15569
Value Function Loss: 4.43218

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.08209

Collected Steps per Second: 8,769.47569
Overall Steps per Second: 7,666.37728

Timestep Collection Time: 5.70502
Timestep Consumption Time: 0.82088
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.52590

Cumulative Model Updates: 17,500
Cumulative Timesteps: 291,992,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 291992710...
Checkpoint 291992710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.67831
Policy Entropy: 1.16472
Value Function Loss: 4.26220

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 8,625.73298
Overall Steps per Second: 7,544.15603

Timestep Collection Time: 5.79684
Timestep Consumption Time: 0.83107
PPO Batch Consumption Time: 0.04721
Total Iteration Time: 6.62791

Cumulative Model Updates: 17,503
Cumulative Timesteps: 292,042,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.22881
Policy Entropy: 1.15583
Value Function Loss: 4.29369

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 9,050.65909
Overall Steps per Second: 7,923.66370

Timestep Collection Time: 5.52490
Timestep Consumption Time: 0.78582
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.31072

Cumulative Model Updates: 17,506
Cumulative Timesteps: 292,092,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 292092716...
Checkpoint 292092716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.37497
Policy Entropy: 1.15823
Value Function Loss: 4.13884

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 8,812.79247
Overall Steps per Second: 7,683.61301

Timestep Collection Time: 5.67425
Timestep Consumption Time: 0.83388
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 6.50814

Cumulative Model Updates: 17,509
Cumulative Timesteps: 292,142,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.91643
Policy Entropy: 1.16113
Value Function Loss: 4.10862

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.06762

Collected Steps per Second: 8,880.01207
Overall Steps per Second: 7,770.67110

Timestep Collection Time: 5.63355
Timestep Consumption Time: 0.80425
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.43780

Cumulative Model Updates: 17,512
Cumulative Timesteps: 292,192,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 292192748...
Checkpoint 292192748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.28462
Policy Entropy: 1.16949
Value Function Loss: 4.16862

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 9,014.83020
Overall Steps per Second: 7,806.15157

Timestep Collection Time: 5.54730
Timestep Consumption Time: 0.85893
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.40623

Cumulative Model Updates: 17,515
Cumulative Timesteps: 292,242,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.63370
Policy Entropy: 1.14975
Value Function Loss: 4.31079

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.06622

Collected Steps per Second: 8,716.79718
Overall Steps per Second: 7,586.21363

Timestep Collection Time: 5.73835
Timestep Consumption Time: 0.85519
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.59354

Cumulative Model Updates: 17,518
Cumulative Timesteps: 292,292,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 292292776...
Checkpoint 292292776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.59885
Policy Entropy: 1.13911
Value Function Loss: 4.46120

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 8,720.08798
Overall Steps per Second: 7,716.87228

Timestep Collection Time: 5.73389
Timestep Consumption Time: 0.74542
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.47931

Cumulative Model Updates: 17,521
Cumulative Timesteps: 292,342,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.20529
Policy Entropy: 1.14939
Value Function Loss: 4.45938

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 8,787.02896
Overall Steps per Second: 7,663.13382

Timestep Collection Time: 5.69180
Timestep Consumption Time: 0.83477
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.52657

Cumulative Model Updates: 17,524
Cumulative Timesteps: 292,392,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 292392790...
Checkpoint 292392790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.71135
Policy Entropy: 1.15494
Value Function Loss: 4.54704

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.07811
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 8,864.61625
Overall Steps per Second: 7,862.96339

Timestep Collection Time: 5.64198
Timestep Consumption Time: 0.71872
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 6.36071

Cumulative Model Updates: 17,527
Cumulative Timesteps: 292,442,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.26518
Policy Entropy: 1.15132
Value Function Loss: 4.43362

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.08086
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 8,911.24189
Overall Steps per Second: 7,640.75093

Timestep Collection Time: 5.61201
Timestep Consumption Time: 0.93316
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 6.54517

Cumulative Model Updates: 17,530
Cumulative Timesteps: 292,492,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 292492814...
Checkpoint 292492814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.87496
Policy Entropy: 1.14647
Value Function Loss: 4.50612

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.04577

Collected Steps per Second: 8,912.51132
Overall Steps per Second: 7,833.09416

Timestep Collection Time: 5.61323
Timestep Consumption Time: 0.77352
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.38675

Cumulative Model Updates: 17,533
Cumulative Timesteps: 292,542,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.54748
Policy Entropy: 1.14206
Value Function Loss: 4.59739

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.04102

Collected Steps per Second: 9,109.40372
Overall Steps per Second: 8,058.59452

Timestep Collection Time: 5.49103
Timestep Consumption Time: 0.71601
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 6.20704

Cumulative Model Updates: 17,536
Cumulative Timesteps: 292,592,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 292592862...
Checkpoint 292592862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.56986
Policy Entropy: 1.14729
Value Function Loss: 4.65871

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.04517

Collected Steps per Second: 8,913.14705
Overall Steps per Second: 7,739.40754

Timestep Collection Time: 5.61171
Timestep Consumption Time: 0.85106
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 6.46277

Cumulative Model Updates: 17,539
Cumulative Timesteps: 292,642,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.34143
Policy Entropy: 1.16018
Value Function Loss: 4.67628

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.05344

Collected Steps per Second: 8,807.92422
Overall Steps per Second: 7,770.25681

Timestep Collection Time: 5.67830
Timestep Consumption Time: 0.75830
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.43660

Cumulative Model Updates: 17,542
Cumulative Timesteps: 292,692,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 292692894...
Checkpoint 292692894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.49499
Policy Entropy: 1.15157
Value Function Loss: 4.30738

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.05245

Collected Steps per Second: 8,696.10679
Overall Steps per Second: 7,549.81105

Timestep Collection Time: 5.74970
Timestep Consumption Time: 0.87298
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.62268

Cumulative Model Updates: 17,545
Cumulative Timesteps: 292,742,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.24586
Policy Entropy: 1.14161
Value Function Loss: 4.26937

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.15512
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,856.20781
Overall Steps per Second: 7,688.19973

Timestep Collection Time: 5.64643
Timestep Consumption Time: 0.85782
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.50425

Cumulative Model Updates: 17,548
Cumulative Timesteps: 292,792,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 292792900...
Checkpoint 292792900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.88329
Policy Entropy: 1.16070
Value Function Loss: 4.20346

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 8,936.90703
Overall Steps per Second: 7,787.91535

Timestep Collection Time: 5.59701
Timestep Consumption Time: 0.82576
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.42277

Cumulative Model Updates: 17,551
Cumulative Timesteps: 292,842,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.59925
Policy Entropy: 1.15700
Value Function Loss: 4.39733

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 8,684.86871
Overall Steps per Second: 7,555.89394

Timestep Collection Time: 5.76059
Timestep Consumption Time: 0.86073
PPO Batch Consumption Time: 0.03974
Total Iteration Time: 6.62132

Cumulative Model Updates: 17,554
Cumulative Timesteps: 292,892,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 292892950...
Checkpoint 292892950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.87431
Policy Entropy: 1.14726
Value Function Loss: 4.31320

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06666

Collected Steps per Second: 8,861.06644
Overall Steps per Second: 7,831.25371

Timestep Collection Time: 5.64356
Timestep Consumption Time: 0.74213
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 6.38570

Cumulative Model Updates: 17,557
Cumulative Timesteps: 292,942,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.73014
Policy Entropy: 1.12637
Value Function Loss: 4.12285

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.06217

Collected Steps per Second: 8,696.04185
Overall Steps per Second: 7,584.44877

Timestep Collection Time: 5.75066
Timestep Consumption Time: 0.84283
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 6.59349

Cumulative Model Updates: 17,560
Cumulative Timesteps: 292,992,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 292992966...
Checkpoint 292992966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.24040
Policy Entropy: 1.14758
Value Function Loss: 4.39438

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.05391

Collected Steps per Second: 8,798.23623
Overall Steps per Second: 7,792.71084

Timestep Collection Time: 5.68409
Timestep Consumption Time: 0.73344
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.41754

Cumulative Model Updates: 17,563
Cumulative Timesteps: 293,042,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.91678
Policy Entropy: 1.13187
Value Function Loss: 4.41294

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 8,801.06304
Overall Steps per Second: 7,686.83254

Timestep Collection Time: 5.68113
Timestep Consumption Time: 0.82350
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.50463

Cumulative Model Updates: 17,566
Cumulative Timesteps: 293,092,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 293092976...
Checkpoint 293092976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.96277
Policy Entropy: 1.14854
Value Function Loss: 4.61702

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.04537

Collected Steps per Second: 8,741.15641
Overall Steps per Second: 7,610.74431

Timestep Collection Time: 5.72304
Timestep Consumption Time: 0.85003
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.57308

Cumulative Model Updates: 17,569
Cumulative Timesteps: 293,143,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.77979
Policy Entropy: 1.13866
Value Function Loss: 4.49507

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.04411

Collected Steps per Second: 8,887.74522
Overall Steps per Second: 7,735.96690

Timestep Collection Time: 5.62865
Timestep Consumption Time: 0.83803
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 6.46668

Cumulative Model Updates: 17,572
Cumulative Timesteps: 293,193,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 293193028...
Checkpoint 293193028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.55607
Policy Entropy: 1.16690
Value Function Loss: 4.50039

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.16601
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.04960

Collected Steps per Second: 8,830.54534
Overall Steps per Second: 7,654.81064

Timestep Collection Time: 5.66488
Timestep Consumption Time: 0.87009
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.53498

Cumulative Model Updates: 17,575
Cumulative Timesteps: 293,243,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.90718
Policy Entropy: 1.14026
Value Function Loss: 4.37219

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.18521
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 8,841.07583
Overall Steps per Second: 7,789.76517

Timestep Collection Time: 5.65768
Timestep Consumption Time: 0.76356
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.42125

Cumulative Model Updates: 17,578
Cumulative Timesteps: 293,293,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 293293072...
Checkpoint 293293072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.68287
Policy Entropy: 1.15130
Value Function Loss: 4.35960

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.04051

Collected Steps per Second: 8,724.67587
Overall Steps per Second: 7,565.86329

Timestep Collection Time: 5.73202
Timestep Consumption Time: 0.87793
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.60995

Cumulative Model Updates: 17,581
Cumulative Timesteps: 293,343,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.59776
Policy Entropy: 1.15257
Value Function Loss: 4.37147

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.03930

Collected Steps per Second: 9,019.31648
Overall Steps per Second: 7,885.98797

Timestep Collection Time: 5.54587
Timestep Consumption Time: 0.79702
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 6.34290

Cumulative Model Updates: 17,584
Cumulative Timesteps: 293,393,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 293393102...
Checkpoint 293393102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.50168
Policy Entropy: 1.14566
Value Function Loss: 4.36425

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.04381

Collected Steps per Second: 8,919.50013
Overall Steps per Second: 7,714.21539

Timestep Collection Time: 5.60726
Timestep Consumption Time: 0.87609
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.48336

Cumulative Model Updates: 17,587
Cumulative Timesteps: 293,443,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.85373
Policy Entropy: 1.13466
Value Function Loss: 4.33664

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.04455

Collected Steps per Second: 9,128.34757
Overall Steps per Second: 7,844.56801

Timestep Collection Time: 5.47876
Timestep Consumption Time: 0.89661
PPO Batch Consumption Time: 0.04815
Total Iteration Time: 6.37537

Cumulative Model Updates: 17,590
Cumulative Timesteps: 293,493,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 293493128...
Checkpoint 293493128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.67324
Policy Entropy: 1.15727
Value Function Loss: 4.24353

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 9,269.36757
Overall Steps per Second: 7,968.91508

Timestep Collection Time: 5.39692
Timestep Consumption Time: 0.88073
PPO Batch Consumption Time: 0.04930
Total Iteration Time: 6.27764

Cumulative Model Updates: 17,593
Cumulative Timesteps: 293,543,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.24396
Policy Entropy: 1.15584
Value Function Loss: 4.32384

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 9,074.61976
Overall Steps per Second: 7,806.43939

Timestep Collection Time: 5.51142
Timestep Consumption Time: 0.89535
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.40676

Cumulative Model Updates: 17,596
Cumulative Timesteps: 293,593,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 293593168...
Checkpoint 293593168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.53875
Policy Entropy: 1.14657
Value Function Loss: 4.47307

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.06895

Collected Steps per Second: 8,670.25430
Overall Steps per Second: 7,515.09369

Timestep Collection Time: 5.76984
Timestep Consumption Time: 0.88689
PPO Batch Consumption Time: 0.04980
Total Iteration Time: 6.65674

Cumulative Model Updates: 17,599
Cumulative Timesteps: 293,643,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.21360
Policy Entropy: 1.12603
Value Function Loss: 4.46698

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.16311
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 8,879.71402
Overall Steps per Second: 7,708.94649

Timestep Collection Time: 5.63104
Timestep Consumption Time: 0.85519
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 6.48623

Cumulative Model Updates: 17,602
Cumulative Timesteps: 293,693,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 293693196...
Checkpoint 293693196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.37765
Policy Entropy: 1.14372
Value Function Loss: 4.36038

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.04595

Collected Steps per Second: 9,057.79544
Overall Steps per Second: 7,868.42520

Timestep Collection Time: 5.52011
Timestep Consumption Time: 0.83440
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 6.35451

Cumulative Model Updates: 17,605
Cumulative Timesteps: 293,743,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.28545
Policy Entropy: 1.14089
Value Function Loss: 4.49087

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 9,046.32430
Overall Steps per Second: 7,813.59473

Timestep Collection Time: 5.52910
Timestep Consumption Time: 0.87231
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.40141

Cumulative Model Updates: 17,608
Cumulative Timesteps: 293,793,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 293793214...
Checkpoint 293793214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.47694
Policy Entropy: 1.13425
Value Function Loss: 4.47490

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.05763

Collected Steps per Second: 8,927.94588
Overall Steps per Second: 7,776.80707

Timestep Collection Time: 5.60084
Timestep Consumption Time: 0.82905
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.42989

Cumulative Model Updates: 17,611
Cumulative Timesteps: 293,843,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.32675
Policy Entropy: 1.13856
Value Function Loss: 4.48090

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.06701

Collected Steps per Second: 8,594.32529
Overall Steps per Second: 7,593.70635

Timestep Collection Time: 5.82058
Timestep Consumption Time: 0.76698
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.58756

Cumulative Model Updates: 17,614
Cumulative Timesteps: 293,893,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 293893242...
Checkpoint 293893242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.35058
Policy Entropy: 1.15294
Value Function Loss: 4.28375

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06695

Collected Steps per Second: 9,018.19072
Overall Steps per Second: 7,841.08595

Timestep Collection Time: 5.54745
Timestep Consumption Time: 0.83278
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.38024

Cumulative Model Updates: 17,617
Cumulative Timesteps: 293,943,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.22592
Policy Entropy: 1.13222
Value Function Loss: 4.19076

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 8,596.81644
Overall Steps per Second: 7,513.55231

Timestep Collection Time: 5.81611
Timestep Consumption Time: 0.83854
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.65464

Cumulative Model Updates: 17,620
Cumulative Timesteps: 293,993,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 293993270...
Checkpoint 293993270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.40816
Policy Entropy: 1.12781
Value Function Loss: 4.33701

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 9,122.02198
Overall Steps per Second: 7,917.64409

Timestep Collection Time: 5.48343
Timestep Consumption Time: 0.83410
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 6.31754

Cumulative Model Updates: 17,623
Cumulative Timesteps: 294,043,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.62203
Policy Entropy: 1.12913
Value Function Loss: 4.30062

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.06068

Collected Steps per Second: 8,990.81394
Overall Steps per Second: 7,824.95135

Timestep Collection Time: 5.56368
Timestep Consumption Time: 0.82895
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.39263

Cumulative Model Updates: 17,626
Cumulative Timesteps: 294,093,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 294093312...
Checkpoint 294093312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.97055
Policy Entropy: 1.15232
Value Function Loss: 4.37150

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.05815

Collected Steps per Second: 8,815.12982
Overall Steps per Second: 7,759.63786

Timestep Collection Time: 5.67479
Timestep Consumption Time: 0.77190
PPO Batch Consumption Time: 0.04959
Total Iteration Time: 6.44669

Cumulative Model Updates: 17,629
Cumulative Timesteps: 294,143,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.47483
Policy Entropy: 1.13071
Value Function Loss: 4.15616

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 8,719.44928
Overall Steps per Second: 7,594.67415

Timestep Collection Time: 5.73522
Timestep Consumption Time: 0.84939
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.58461

Cumulative Model Updates: 17,632
Cumulative Timesteps: 294,193,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 294193344...
Checkpoint 294193344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.21498
Policy Entropy: 1.14561
Value Function Loss: 4.26132

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.05901

Collected Steps per Second: 8,885.68678
Overall Steps per Second: 7,758.23114

Timestep Collection Time: 5.63018
Timestep Consumption Time: 0.81820
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.44838

Cumulative Model Updates: 17,635
Cumulative Timesteps: 294,243,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.70429
Policy Entropy: 1.13825
Value Function Loss: 4.28869

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 9,060.31994
Overall Steps per Second: 7,859.10972

Timestep Collection Time: 5.52056
Timestep Consumption Time: 0.84378
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 6.36433

Cumulative Model Updates: 17,638
Cumulative Timesteps: 294,293,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 294293390...
Checkpoint 294293390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.50387
Policy Entropy: 1.14743
Value Function Loss: 4.36268

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 8,848.11181
Overall Steps per Second: 7,605.61234

Timestep Collection Time: 5.65296
Timestep Consumption Time: 0.92350
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 6.57646

Cumulative Model Updates: 17,641
Cumulative Timesteps: 294,343,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.81485
Policy Entropy: 1.12538
Value Function Loss: 4.44264

Mean KL Divergence: 0.03474
SB3 Clip Fraction: 0.20284
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 8,951.45067
Overall Steps per Second: 7,932.35937

Timestep Collection Time: 5.58881
Timestep Consumption Time: 0.71801
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 6.30682

Cumulative Model Updates: 17,644
Cumulative Timesteps: 294,393,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 294393436...
Checkpoint 294393436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.96709
Policy Entropy: 1.14829
Value Function Loss: 4.31466

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 9,030.15836
Overall Steps per Second: 7,830.84253

Timestep Collection Time: 5.53988
Timestep Consumption Time: 0.84845
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.38833

Cumulative Model Updates: 17,647
Cumulative Timesteps: 294,443,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.94126
Policy Entropy: 1.13186
Value Function Loss: 4.45965

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 9,202.32209
Overall Steps per Second: 7,986.58734

Timestep Collection Time: 5.43515
Timestep Consumption Time: 0.82735
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.26250

Cumulative Model Updates: 17,650
Cumulative Timesteps: 294,493,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 294493478...
Checkpoint 294493478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.61079
Policy Entropy: 1.12682
Value Function Loss: 4.41153

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 8,869.89151
Overall Steps per Second: 7,658.38876

Timestep Collection Time: 5.63863
Timestep Consumption Time: 0.89199
PPO Batch Consumption Time: 0.05122
Total Iteration Time: 6.53062

Cumulative Model Updates: 17,653
Cumulative Timesteps: 294,543,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.18430
Policy Entropy: 1.13615
Value Function Loss: 4.43810

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.07628

Collected Steps per Second: 8,824.92356
Overall Steps per Second: 7,709.68094

Timestep Collection Time: 5.66758
Timestep Consumption Time: 0.81984
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.48743

Cumulative Model Updates: 17,656
Cumulative Timesteps: 294,593,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 294593508...
Checkpoint 294593508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.73641
Policy Entropy: 1.13509
Value Function Loss: 4.27822

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.07869

Collected Steps per Second: 8,731.59154
Overall Steps per Second: 7,693.03927

Timestep Collection Time: 5.72885
Timestep Consumption Time: 0.77339
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 6.50224

Cumulative Model Updates: 17,659
Cumulative Timesteps: 294,643,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.04970
Policy Entropy: 1.12856
Value Function Loss: 4.14150

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 8,848.34929
Overall Steps per Second: 7,678.42452

Timestep Collection Time: 5.65371
Timestep Consumption Time: 0.86143
PPO Batch Consumption Time: 0.04708
Total Iteration Time: 6.51514

Cumulative Model Updates: 17,662
Cumulative Timesteps: 294,693,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 294693556...
Checkpoint 294693556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.23088
Policy Entropy: 1.13076
Value Function Loss: 4.18195

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 8,584.11527
Overall Steps per Second: 7,470.01242

Timestep Collection Time: 5.82658
Timestep Consumption Time: 0.86900
PPO Batch Consumption Time: 0.05204
Total Iteration Time: 6.69557

Cumulative Model Updates: 17,665
Cumulative Timesteps: 294,743,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.26054
Policy Entropy: 1.13098
Value Function Loss: 4.17720

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 9,148.59065
Overall Steps per Second: 7,865.19850

Timestep Collection Time: 5.46729
Timestep Consumption Time: 0.89212
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.35941

Cumulative Model Updates: 17,668
Cumulative Timesteps: 294,793,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 294793590...
Checkpoint 294793590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.08608
Policy Entropy: 1.13534
Value Function Loss: 4.20062

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.09352

Collected Steps per Second: 8,760.84129
Overall Steps per Second: 7,648.37743

Timestep Collection Time: 5.71018
Timestep Consumption Time: 0.83055
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.54073

Cumulative Model Updates: 17,671
Cumulative Timesteps: 294,843,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.93048
Policy Entropy: 1.12319
Value Function Loss: 4.06952

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 8,618.86996
Overall Steps per Second: 7,608.17031

Timestep Collection Time: 5.80146
Timestep Consumption Time: 0.77069
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.57215

Cumulative Model Updates: 17,674
Cumulative Timesteps: 294,893,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 294893618...
Checkpoint 294893618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.84219
Policy Entropy: 1.12543
Value Function Loss: 4.14196

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 8,935.07450
Overall Steps per Second: 7,768.06226

Timestep Collection Time: 5.59749
Timestep Consumption Time: 0.84092
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.43841

Cumulative Model Updates: 17,677
Cumulative Timesteps: 294,943,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.69508
Policy Entropy: 1.12838
Value Function Loss: 4.15897

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.07984

Collected Steps per Second: 8,850.27024
Overall Steps per Second: 7,712.91977

Timestep Collection Time: 5.65203
Timestep Consumption Time: 0.83345
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 6.48548

Cumulative Model Updates: 17,680
Cumulative Timesteps: 294,993,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 294993654...
Checkpoint 294993654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.75553
Policy Entropy: 1.13461
Value Function Loss: 4.23145

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.07414

Collected Steps per Second: 9,007.82168
Overall Steps per Second: 7,762.00017

Timestep Collection Time: 5.55340
Timestep Consumption Time: 0.89133
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.44473

Cumulative Model Updates: 17,683
Cumulative Timesteps: 295,043,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.54901
Policy Entropy: 1.14555
Value Function Loss: 4.17999

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.06999

Collected Steps per Second: 8,848.38002
Overall Steps per Second: 7,680.58459

Timestep Collection Time: 5.65392
Timestep Consumption Time: 0.85965
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.51357

Cumulative Model Updates: 17,686
Cumulative Timesteps: 295,093,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 295093706...
Checkpoint 295093706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.77757
Policy Entropy: 1.14888
Value Function Loss: 4.24737

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 8,697.98779
Overall Steps per Second: 7,580.02197

Timestep Collection Time: 5.74915
Timestep Consumption Time: 0.84793
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 6.59708

Cumulative Model Updates: 17,689
Cumulative Timesteps: 295,143,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.75302
Policy Entropy: 1.15286
Value Function Loss: 4.19886

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.06930

Collected Steps per Second: 8,525.87327
Overall Steps per Second: 7,380.63723

Timestep Collection Time: 5.86685
Timestep Consumption Time: 0.91034
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.77719

Cumulative Model Updates: 17,692
Cumulative Timesteps: 295,193,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 295193732...
Checkpoint 295193732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.33404
Policy Entropy: 1.13779
Value Function Loss: 4.32421

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.07251

Collected Steps per Second: 9,017.43493
Overall Steps per Second: 7,811.24462

Timestep Collection Time: 5.54659
Timestep Consumption Time: 0.85649
PPO Batch Consumption Time: 0.05113
Total Iteration Time: 6.40308

Cumulative Model Updates: 17,695
Cumulative Timesteps: 295,243,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.76685
Policy Entropy: 1.12795
Value Function Loss: 4.28466

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 9,001.73035
Overall Steps per Second: 7,804.18936

Timestep Collection Time: 5.55715
Timestep Consumption Time: 0.85274
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.40989

Cumulative Model Updates: 17,698
Cumulative Timesteps: 295,293,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 295293772...
Checkpoint 295293772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.78475
Policy Entropy: 1.13008
Value Function Loss: 4.29281

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.06383

Collected Steps per Second: 9,106.31576
Overall Steps per Second: 7,877.61179

Timestep Collection Time: 5.49201
Timestep Consumption Time: 0.85661
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 6.34862

Cumulative Model Updates: 17,701
Cumulative Timesteps: 295,343,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.08918
Policy Entropy: 1.13442
Value Function Loss: 4.24679

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.05875

Collected Steps per Second: 9,387.87374
Overall Steps per Second: 8,163.03431

Timestep Collection Time: 5.32836
Timestep Consumption Time: 0.79951
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 6.12787

Cumulative Model Updates: 17,704
Cumulative Timesteps: 295,393,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 295393806...
Checkpoint 295393806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.49536
Policy Entropy: 1.11906
Value Function Loss: 4.12765

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 9,284.61069
Overall Steps per Second: 7,960.96593

Timestep Collection Time: 5.38698
Timestep Consumption Time: 0.89568
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 6.28265

Cumulative Model Updates: 17,707
Cumulative Timesteps: 295,443,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.67521
Policy Entropy: 1.09850
Value Function Loss: 4.11701

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.06910

Collected Steps per Second: 8,761.77550
Overall Steps per Second: 7,494.42589

Timestep Collection Time: 5.70935
Timestep Consumption Time: 0.96548
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 6.67483

Cumulative Model Updates: 17,710
Cumulative Timesteps: 295,493,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 295493846...
Checkpoint 295493846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.90285
Policy Entropy: 1.12139
Value Function Loss: 4.24216

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 8,977.52438
Overall Steps per Second: 7,785.41120

Timestep Collection Time: 5.57080
Timestep Consumption Time: 0.85301
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.42381

Cumulative Model Updates: 17,713
Cumulative Timesteps: 295,543,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.79308
Policy Entropy: 1.12178
Value Function Loss: 4.54176

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 9,043.21698
Overall Steps per Second: 7,886.43533

Timestep Collection Time: 5.53232
Timestep Consumption Time: 0.81148
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.34380

Cumulative Model Updates: 17,716
Cumulative Timesteps: 295,593,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 295593888...
Checkpoint 295593888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.75637
Policy Entropy: 1.14702
Value Function Loss: 4.83355

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.05952

Collected Steps per Second: 8,876.84507
Overall Steps per Second: 7,823.91240

Timestep Collection Time: 5.63601
Timestep Consumption Time: 0.75849
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 6.39450

Cumulative Model Updates: 17,719
Cumulative Timesteps: 295,643,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.61624
Policy Entropy: 1.12723
Value Function Loss: 4.66578

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.06024

Collected Steps per Second: 8,906.77040
Overall Steps per Second: 7,675.17670

Timestep Collection Time: 5.61708
Timestep Consumption Time: 0.90134
PPO Batch Consumption Time: 0.04815
Total Iteration Time: 6.51842

Cumulative Model Updates: 17,722
Cumulative Timesteps: 295,693,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 295693948...
Checkpoint 295693948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.67396
Policy Entropy: 1.12915
Value Function Loss: 4.34040

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 8,645.56797
Overall Steps per Second: 7,547.34328

Timestep Collection Time: 5.78447
Timestep Consumption Time: 0.84171
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 6.62617

Cumulative Model Updates: 17,725
Cumulative Timesteps: 295,743,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.12234
Policy Entropy: 1.13374
Value Function Loss: 4.18957

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.06776

Collected Steps per Second: 8,918.50246
Overall Steps per Second: 7,788.22009

Timestep Collection Time: 5.60722
Timestep Consumption Time: 0.81376
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.42098

Cumulative Model Updates: 17,728
Cumulative Timesteps: 295,793,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 295793966...
Checkpoint 295793966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.54640
Policy Entropy: 1.14601
Value Function Loss: 4.29053

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.05863

Collected Steps per Second: 8,887.97514
Overall Steps per Second: 7,767.07906

Timestep Collection Time: 5.62760
Timestep Consumption Time: 0.81214
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.43974

Cumulative Model Updates: 17,731
Cumulative Timesteps: 295,843,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.59354
Policy Entropy: 1.13099
Value Function Loss: 4.43107

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.06147

Collected Steps per Second: 9,091.43550
Overall Steps per Second: 8,013.16323

Timestep Collection Time: 5.50210
Timestep Consumption Time: 0.74038
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 6.24248

Cumulative Model Updates: 17,734
Cumulative Timesteps: 295,894,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 295894006...
Checkpoint 295894006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.57197
Policy Entropy: 1.11953
Value Function Loss: 4.29400

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.06539

Collected Steps per Second: 8,722.70033
Overall Steps per Second: 7,588.53400

Timestep Collection Time: 5.73332
Timestep Consumption Time: 0.85689
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.59021

Cumulative Model Updates: 17,737
Cumulative Timesteps: 295,944,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.17442
Policy Entropy: 1.13767
Value Function Loss: 4.21524

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 8,609.14978
Overall Steps per Second: 7,536.86720

Timestep Collection Time: 5.80917
Timestep Consumption Time: 0.82648
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.63565

Cumulative Model Updates: 17,740
Cumulative Timesteps: 295,994,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 295994028...
Checkpoint 295994028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.02981
Policy Entropy: 1.15084
Value Function Loss: 3.98896

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.05864

Collected Steps per Second: 8,891.99978
Overall Steps per Second: 7,665.47376

Timestep Collection Time: 5.62641
Timestep Consumption Time: 0.90026
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.52667

Cumulative Model Updates: 17,743
Cumulative Timesteps: 296,044,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.61479
Policy Entropy: 1.10590
Value Function Loss: 4.08716

Mean KL Divergence: 0.08377
SB3 Clip Fraction: 0.22155
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 8,776.25288
Overall Steps per Second: 7,662.43723

Timestep Collection Time: 5.69833
Timestep Consumption Time: 0.82831
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 6.52664

Cumulative Model Updates: 17,746
Cumulative Timesteps: 296,094,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 296094068...
Checkpoint 296094068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.10393
Policy Entropy: 1.14423
Value Function Loss: 3.98336

Mean KL Divergence: 0.04833
SB3 Clip Fraction: 0.19835
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 8,727.80907
Overall Steps per Second: 7,725.26474

Timestep Collection Time: 5.72881
Timestep Consumption Time: 0.74346
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.47227

Cumulative Model Updates: 17,749
Cumulative Timesteps: 296,144,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.15171
Policy Entropy: 1.12841
Value Function Loss: 4.04273

Mean KL Divergence: 0.04829
SB3 Clip Fraction: 0.22089
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 8,890.84062
Overall Steps per Second: 7,682.97169

Timestep Collection Time: 5.62646
Timestep Consumption Time: 0.88456
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 6.51102

Cumulative Model Updates: 17,752
Cumulative Timesteps: 296,194,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 296194092...
Checkpoint 296194092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.08868
Policy Entropy: 1.14477
Value Function Loss: 4.01782

Mean KL Divergence: 0.03583
SB3 Clip Fraction: 0.17173
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.06070

Collected Steps per Second: 8,766.08692
Overall Steps per Second: 7,722.40486

Timestep Collection Time: 5.70403
Timestep Consumption Time: 0.77090
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.47493

Cumulative Model Updates: 17,755
Cumulative Timesteps: 296,244,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.97098
Policy Entropy: 1.13065
Value Function Loss: 4.16413

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 9,073.93420
Overall Steps per Second: 7,822.90057

Timestep Collection Time: 5.51183
Timestep Consumption Time: 0.88145
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 6.39328

Cumulative Model Updates: 17,758
Cumulative Timesteps: 296,294,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 296294108...
Checkpoint 296294108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.29727
Policy Entropy: 1.11378
Value Function Loss: 4.32939

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06720

Collected Steps per Second: 8,999.75424
Overall Steps per Second: 7,844.85147

Timestep Collection Time: 5.55837
Timestep Consumption Time: 0.81829
PPO Batch Consumption Time: 0.05158
Total Iteration Time: 6.37667

Cumulative Model Updates: 17,761
Cumulative Timesteps: 296,344,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.07695
Policy Entropy: 1.14448
Value Function Loss: 4.40232

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.06916

Collected Steps per Second: 8,811.91793
Overall Steps per Second: 7,823.33375

Timestep Collection Time: 5.67572
Timestep Consumption Time: 0.71720
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.39293

Cumulative Model Updates: 17,764
Cumulative Timesteps: 296,394,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 296394146...
Checkpoint 296394146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.53942
Policy Entropy: 1.14861
Value Function Loss: 4.26979

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.06531

Collected Steps per Second: 8,510.23755
Overall Steps per Second: 7,379.36923

Timestep Collection Time: 5.87833
Timestep Consumption Time: 0.90084
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 6.77917

Cumulative Model Updates: 17,767
Cumulative Timesteps: 296,444,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.05493
Policy Entropy: 1.12381
Value Function Loss: 4.34424

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 8,907.11945
Overall Steps per Second: 7,776.28874

Timestep Collection Time: 5.61641
Timestep Consumption Time: 0.81674
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.43315

Cumulative Model Updates: 17,770
Cumulative Timesteps: 296,494,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 296494198...
Checkpoint 296494198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.05896
Policy Entropy: 1.14060
Value Function Loss: 4.29007

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 9,040.29062
Overall Steps per Second: 7,809.27422

Timestep Collection Time: 5.53257
Timestep Consumption Time: 0.87213
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 6.40469

Cumulative Model Updates: 17,773
Cumulative Timesteps: 296,544,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.38435
Policy Entropy: 1.13714
Value Function Loss: 4.40494

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.06924

Collected Steps per Second: 8,772.01567
Overall Steps per Second: 7,617.41631

Timestep Collection Time: 5.70200
Timestep Consumption Time: 0.86427
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.56627

Cumulative Model Updates: 17,776
Cumulative Timesteps: 296,594,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 296594232...
Checkpoint 296594232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.83156
Policy Entropy: 1.15669
Value Function Loss: 4.46367

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.06074

Collected Steps per Second: 8,847.80705
Overall Steps per Second: 7,802.97554

Timestep Collection Time: 5.65360
Timestep Consumption Time: 0.75703
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.41063

Cumulative Model Updates: 17,779
Cumulative Timesteps: 296,644,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.49710
Policy Entropy: 1.15161
Value Function Loss: 4.54034

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 8,590.82478
Overall Steps per Second: 7,464.72114

Timestep Collection Time: 5.82226
Timestep Consumption Time: 0.87833
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.70059

Cumulative Model Updates: 17,782
Cumulative Timesteps: 296,694,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 296694272...
Checkpoint 296694272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.31471
Policy Entropy: 1.16970
Value Function Loss: 4.36541

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.08062

Collected Steps per Second: 8,928.85630
Overall Steps per Second: 7,793.20035

Timestep Collection Time: 5.60094
Timestep Consumption Time: 0.81619
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.41713

Cumulative Model Updates: 17,785
Cumulative Timesteps: 296,744,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.72178
Policy Entropy: 1.15969
Value Function Loss: 4.23391

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.09062

Collected Steps per Second: 8,888.88541
Overall Steps per Second: 7,721.64052

Timestep Collection Time: 5.62838
Timestep Consumption Time: 0.85082
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.47919

Cumulative Model Updates: 17,788
Cumulative Timesteps: 296,794,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 296794312...
Checkpoint 296794312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.30305
Policy Entropy: 1.14300
Value Function Loss: 4.16141

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.08815

Collected Steps per Second: 8,774.61557
Overall Steps per Second: 7,585.19224

Timestep Collection Time: 5.70099
Timestep Consumption Time: 0.89396
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 6.59495

Cumulative Model Updates: 17,791
Cumulative Timesteps: 296,844,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.25718
Policy Entropy: 1.13506
Value Function Loss: 4.15462

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 8,542.04992
Overall Steps per Second: 7,544.96037

Timestep Collection Time: 5.85597
Timestep Consumption Time: 0.77388
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.62986

Cumulative Model Updates: 17,794
Cumulative Timesteps: 296,894,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 296894358...
Checkpoint 296894358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.23842
Policy Entropy: 1.15284
Value Function Loss: 4.18314

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 8,772.06891
Overall Steps per Second: 7,563.10552

Timestep Collection Time: 5.70151
Timestep Consumption Time: 0.91139
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.61289

Cumulative Model Updates: 17,797
Cumulative Timesteps: 296,944,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.02672
Policy Entropy: 1.16485
Value Function Loss: 4.29306

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 8,663.22062
Overall Steps per Second: 7,569.00499

Timestep Collection Time: 5.77476
Timestep Consumption Time: 0.83483
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 6.60959

Cumulative Model Updates: 17,800
Cumulative Timesteps: 296,994,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 296994400...
Checkpoint 296994400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.27322
Policy Entropy: 1.14512
Value Function Loss: 4.28337

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 9,111.01476
Overall Steps per Second: 7,786.78450

Timestep Collection Time: 5.49072
Timestep Consumption Time: 0.93376
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.42447

Cumulative Model Updates: 17,803
Cumulative Timesteps: 297,044,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.89821
Policy Entropy: 1.14565
Value Function Loss: 4.28530

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.09403

Collected Steps per Second: 9,337.66007
Overall Steps per Second: 8,051.33294

Timestep Collection Time: 5.35702
Timestep Consumption Time: 0.85587
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.21288

Cumulative Model Updates: 17,806
Cumulative Timesteps: 297,094,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 297094448...
Checkpoint 297094448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.79020
Policy Entropy: 1.15395
Value Function Loss: 4.15710

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 8,982.81235
Overall Steps per Second: 7,909.33610

Timestep Collection Time: 5.56752
Timestep Consumption Time: 0.75564
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.32316

Cumulative Model Updates: 17,809
Cumulative Timesteps: 297,144,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.10045
Policy Entropy: 1.16583
Value Function Loss: 4.17781

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 9,525.29021
Overall Steps per Second: 8,202.53839

Timestep Collection Time: 5.24918
Timestep Consumption Time: 0.84649
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 6.09567

Cumulative Model Updates: 17,812
Cumulative Timesteps: 297,194,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 297194460...
Checkpoint 297194460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.25016
Policy Entropy: 1.16516
Value Function Loss: 4.14812

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.07982
Value Function Update Magnitude: 0.10343

Collected Steps per Second: 9,065.95296
Overall Steps per Second: 7,845.50853

Timestep Collection Time: 5.51823
Timestep Consumption Time: 0.85841
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.37664

Cumulative Model Updates: 17,815
Cumulative Timesteps: 297,244,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.60516
Policy Entropy: 1.17237
Value Function Loss: 4.38241

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.06813
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 9,298.78775
Overall Steps per Second: 7,966.06463

Timestep Collection Time: 5.37920
Timestep Consumption Time: 0.89994
PPO Batch Consumption Time: 0.05052
Total Iteration Time: 6.27914

Cumulative Model Updates: 17,818
Cumulative Timesteps: 297,294,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 297294508...
Checkpoint 297294508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.38292
Policy Entropy: 1.17042
Value Function Loss: 4.41452

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.09457

Collected Steps per Second: 8,884.02901
Overall Steps per Second: 7,653.77989

Timestep Collection Time: 5.63123
Timestep Consumption Time: 0.90515
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 6.53638

Cumulative Model Updates: 17,821
Cumulative Timesteps: 297,344,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.96869
Policy Entropy: 1.17715
Value Function Loss: 4.32993

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.06859
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 8,797.91781
Overall Steps per Second: 7,743.00362

Timestep Collection Time: 5.68498
Timestep Consumption Time: 0.77453
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 6.45951

Cumulative Model Updates: 17,824
Cumulative Timesteps: 297,394,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 297394552...
Checkpoint 297394552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.41367
Policy Entropy: 1.15988
Value Function Loss: 4.00723

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.09846

Collected Steps per Second: 8,684.53422
Overall Steps per Second: 7,555.11099

Timestep Collection Time: 5.75989
Timestep Consumption Time: 0.86105
PPO Batch Consumption Time: 0.04859
Total Iteration Time: 6.62095

Cumulative Model Updates: 17,827
Cumulative Timesteps: 297,444,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.78821
Policy Entropy: 1.16654
Value Function Loss: 3.84986

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.08848

Collected Steps per Second: 8,961.72875
Overall Steps per Second: 7,798.54336

Timestep Collection Time: 5.58218
Timestep Consumption Time: 0.83261
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.41479

Cumulative Model Updates: 17,830
Cumulative Timesteps: 297,494,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 297494600...
Checkpoint 297494600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.28589
Policy Entropy: 1.15479
Value Function Loss: 3.80372

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 8,799.17692
Overall Steps per Second: 7,696.50783

Timestep Collection Time: 5.68462
Timestep Consumption Time: 0.81443
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 6.49905

Cumulative Model Updates: 17,833
Cumulative Timesteps: 297,544,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.59543
Policy Entropy: 1.16720
Value Function Loss: 3.89248

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 8,673.21764
Overall Steps per Second: 7,605.19033

Timestep Collection Time: 5.76510
Timestep Consumption Time: 0.80962
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.57472

Cumulative Model Updates: 17,836
Cumulative Timesteps: 297,594,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 297594622...
Checkpoint 297594622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.25337
Policy Entropy: 1.17316
Value Function Loss: 4.06193

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 8,644.04385
Overall Steps per Second: 7,688.92230

Timestep Collection Time: 5.78734
Timestep Consumption Time: 0.71891
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.50624

Cumulative Model Updates: 17,839
Cumulative Timesteps: 297,644,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.55274
Policy Entropy: 1.16172
Value Function Loss: 4.29301

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 8,861.95784
Overall Steps per Second: 7,655.50017

Timestep Collection Time: 5.64345
Timestep Consumption Time: 0.88937
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.53282

Cumulative Model Updates: 17,842
Cumulative Timesteps: 297,694,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 297694660...
Checkpoint 297694660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.90541
Policy Entropy: 1.16216
Value Function Loss: 4.25709

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 8,676.20693
Overall Steps per Second: 7,602.83823

Timestep Collection Time: 5.76611
Timestep Consumption Time: 0.81406
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.58017

Cumulative Model Updates: 17,845
Cumulative Timesteps: 297,744,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.11436
Policy Entropy: 1.16939
Value Function Loss: 4.28499

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.06170

Collected Steps per Second: 8,729.46123
Overall Steps per Second: 7,610.99402

Timestep Collection Time: 5.72910
Timestep Consumption Time: 0.84192
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.57102

Cumulative Model Updates: 17,848
Cumulative Timesteps: 297,794,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 297794700...
Checkpoint 297794700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.12999
Policy Entropy: 1.17435
Value Function Loss: 4.27220

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 8,794.69055
Overall Steps per Second: 7,699.16904

Timestep Collection Time: 5.68616
Timestep Consumption Time: 0.80909
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.49525

Cumulative Model Updates: 17,851
Cumulative Timesteps: 297,844,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.56167
Policy Entropy: 1.15930
Value Function Loss: 4.28223

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.05593

Collected Steps per Second: 8,843.23813
Overall Steps per Second: 7,815.09730

Timestep Collection Time: 5.65404
Timestep Consumption Time: 0.74384
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.39787

Cumulative Model Updates: 17,854
Cumulative Timesteps: 297,894,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 297894708...
Checkpoint 297894708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.10520
Policy Entropy: 1.15712
Value Function Loss: 4.08614

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.05975

Collected Steps per Second: 8,551.24119
Overall Steps per Second: 7,358.48839

Timestep Collection Time: 5.84710
Timestep Consumption Time: 0.94777
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.79487

Cumulative Model Updates: 17,857
Cumulative Timesteps: 297,944,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.79639
Policy Entropy: 1.15671
Value Function Loss: 4.21922

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 8,663.88097
Overall Steps per Second: 7,451.50266

Timestep Collection Time: 5.77293
Timestep Consumption Time: 0.93927
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.71220

Cumulative Model Updates: 17,860
Cumulative Timesteps: 297,994,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 297994724...
Checkpoint 297994724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.50783
Policy Entropy: 1.16072
Value Function Loss: 4.43884

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 9,015.03870
Overall Steps per Second: 7,734.45643

Timestep Collection Time: 5.54762
Timestep Consumption Time: 0.91851
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.46613

Cumulative Model Updates: 17,863
Cumulative Timesteps: 298,044,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.52036
Policy Entropy: 1.15564
Value Function Loss: 4.50178

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.07935

Collected Steps per Second: 9,023.29155
Overall Steps per Second: 7,844.84834

Timestep Collection Time: 5.54365
Timestep Consumption Time: 0.83276
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 6.37641

Cumulative Model Updates: 17,866
Cumulative Timesteps: 298,094,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 298094758...
Checkpoint 298094758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.39306
Policy Entropy: 1.15869
Value Function Loss: 4.32778

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 8,904.34149
Overall Steps per Second: 7,866.18692

Timestep Collection Time: 5.61591
Timestep Consumption Time: 0.74117
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 6.35708

Cumulative Model Updates: 17,869
Cumulative Timesteps: 298,144,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.55863
Policy Entropy: 1.16144
Value Function Loss: 4.28227

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 9,125.17185
Overall Steps per Second: 7,956.22543

Timestep Collection Time: 5.48242
Timestep Consumption Time: 0.80549
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.28791

Cumulative Model Updates: 17,872
Cumulative Timesteps: 298,194,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 298194792...
Checkpoint 298194792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.22542
Policy Entropy: 1.15510
Value Function Loss: 4.28444

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.08699

Collected Steps per Second: 8,845.30534
Overall Steps per Second: 7,664.65172

Timestep Collection Time: 5.65498
Timestep Consumption Time: 0.87109
PPO Batch Consumption Time: 0.04763
Total Iteration Time: 6.52606

Cumulative Model Updates: 17,875
Cumulative Timesteps: 298,244,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.98450
Policy Entropy: 1.16113
Value Function Loss: 4.28938

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.07786

Collected Steps per Second: 8,930.39117
Overall Steps per Second: 7,766.04993

Timestep Collection Time: 5.60177
Timestep Consumption Time: 0.83986
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.44163

Cumulative Model Updates: 17,878
Cumulative Timesteps: 298,294,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 298294838...
Checkpoint 298294838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.98847
Policy Entropy: 1.16620
Value Function Loss: 4.21945

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 8,969.46133
Overall Steps per Second: 7,822.48049

Timestep Collection Time: 5.57625
Timestep Consumption Time: 0.81763
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.39388

Cumulative Model Updates: 17,881
Cumulative Timesteps: 298,344,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.87850
Policy Entropy: 1.16914
Value Function Loss: 4.25263

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.08328

Collected Steps per Second: 8,845.65369
Overall Steps per Second: 7,798.67540

Timestep Collection Time: 5.65340
Timestep Consumption Time: 0.75897
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.41237

Cumulative Model Updates: 17,884
Cumulative Timesteps: 298,394,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 298394862...
Checkpoint 298394862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.58029
Policy Entropy: 1.18555
Value Function Loss: 4.33450

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 9,018.96431
Overall Steps per Second: 7,840.38138

Timestep Collection Time: 5.54587
Timestep Consumption Time: 0.83367
PPO Batch Consumption Time: 0.03903
Total Iteration Time: 6.37954

Cumulative Model Updates: 17,887
Cumulative Timesteps: 298,444,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.02021
Policy Entropy: 1.17782
Value Function Loss: 4.44344

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 8,899.08715
Overall Steps per Second: 7,640.60283

Timestep Collection Time: 5.62170
Timestep Consumption Time: 0.92595
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.54765

Cumulative Model Updates: 17,890
Cumulative Timesteps: 298,494,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 298494908...
Checkpoint 298494908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.34794
Policy Entropy: 1.17073
Value Function Loss: 4.48756

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 8,944.84056
Overall Steps per Second: 7,764.33938

Timestep Collection Time: 5.59160
Timestep Consumption Time: 0.85016
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.44176

Cumulative Model Updates: 17,893
Cumulative Timesteps: 298,544,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.01126
Policy Entropy: 1.16127
Value Function Loss: 4.60301

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.05899

Collected Steps per Second: 8,923.44118
Overall Steps per Second: 7,742.21918

Timestep Collection Time: 5.60524
Timestep Consumption Time: 0.85518
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.46042

Cumulative Model Updates: 17,896
Cumulative Timesteps: 298,594,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 298594942...
Checkpoint 298594942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.09402
Policy Entropy: 1.17737
Value Function Loss: 4.42535

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 8,703.25305
Overall Steps per Second: 7,671.64183

Timestep Collection Time: 5.74705
Timestep Consumption Time: 0.77281
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 6.51986

Cumulative Model Updates: 17,899
Cumulative Timesteps: 298,644,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.53838
Policy Entropy: 1.17963
Value Function Loss: 4.37915

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 8,921.54458
Overall Steps per Second: 7,668.98691

Timestep Collection Time: 5.60643
Timestep Consumption Time: 0.91568
PPO Batch Consumption Time: 0.04583
Total Iteration Time: 6.52211

Cumulative Model Updates: 17,902
Cumulative Timesteps: 298,694,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 298694978...
Checkpoint 298694978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.21732
Policy Entropy: 1.17513
Value Function Loss: 4.06497

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 8,580.33980
Overall Steps per Second: 7,381.94048

Timestep Collection Time: 5.83100
Timestep Consumption Time: 0.94662
PPO Batch Consumption Time: 0.04913
Total Iteration Time: 6.77762

Cumulative Model Updates: 17,905
Cumulative Timesteps: 298,745,010

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.27687
Policy Entropy: 1.15927
Value Function Loss: 4.05760

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.09049

Collected Steps per Second: 9,080.60021
Overall Steps per Second: 7,775.75986

Timestep Collection Time: 5.50779
Timestep Consumption Time: 0.92425
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.43204

Cumulative Model Updates: 17,908
Cumulative Timesteps: 298,795,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 298795024...
Checkpoint 298795024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.70096
Policy Entropy: 1.16958
Value Function Loss: 3.96874

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 8,812.89715
Overall Steps per Second: 7,635.64735

Timestep Collection Time: 5.67532
Timestep Consumption Time: 0.87501
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.55033

Cumulative Model Updates: 17,911
Cumulative Timesteps: 298,845,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.35334
Policy Entropy: 1.17060
Value Function Loss: 4.05043

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 8,812.05681
Overall Steps per Second: 7,739.50289

Timestep Collection Time: 5.67654
Timestep Consumption Time: 0.78666
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 6.46321

Cumulative Model Updates: 17,914
Cumulative Timesteps: 298,895,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 298895062...
Checkpoint 298895062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.14161
Policy Entropy: 1.16767
Value Function Loss: 4.23296

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.06269

Collected Steps per Second: 8,920.64448
Overall Steps per Second: 7,668.91266

Timestep Collection Time: 5.60520
Timestep Consumption Time: 0.91489
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.52009

Cumulative Model Updates: 17,917
Cumulative Timesteps: 298,945,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.70635
Policy Entropy: 1.16455
Value Function Loss: 4.43232

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.05129

Collected Steps per Second: 8,800.52258
Overall Steps per Second: 7,635.08692

Timestep Collection Time: 5.68421
Timestep Consumption Time: 0.86765
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 6.55186

Cumulative Model Updates: 17,920
Cumulative Timesteps: 298,995,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 298995088...
Checkpoint 298995088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.32550
Policy Entropy: 1.17946
Value Function Loss: 4.41531

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 9,098.79347
Overall Steps per Second: 7,870.78242

Timestep Collection Time: 5.49567
Timestep Consumption Time: 0.85744
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 6.35312

Cumulative Model Updates: 17,923
Cumulative Timesteps: 299,045,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.85858
Policy Entropy: 1.17569
Value Function Loss: 4.32557

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.05003

Collected Steps per Second: 9,228.34155
Overall Steps per Second: 7,944.80388

Timestep Collection Time: 5.42069
Timestep Consumption Time: 0.87575
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.29644

Cumulative Model Updates: 17,926
Cumulative Timesteps: 299,095,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 299095116...
Checkpoint 299095116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.27515
Policy Entropy: 1.16481
Value Function Loss: 4.18297

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 9,115.81117
Overall Steps per Second: 8,020.66367

Timestep Collection Time: 5.48498
Timestep Consumption Time: 0.74892
PPO Batch Consumption Time: 0.04823
Total Iteration Time: 6.23390

Cumulative Model Updates: 17,929
Cumulative Timesteps: 299,145,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.47572
Policy Entropy: 1.16416
Value Function Loss: 4.14594

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 8,601.36109
Overall Steps per Second: 7,480.27006

Timestep Collection Time: 5.81652
Timestep Consumption Time: 0.87174
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.68826

Cumulative Model Updates: 17,932
Cumulative Timesteps: 299,195,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 299195146...
Checkpoint 299195146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.41314
Policy Entropy: 1.17117
Value Function Loss: 4.18136

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.06508

Collected Steps per Second: 8,729.65075
Overall Steps per Second: 7,487.70209

Timestep Collection Time: 5.72784
Timestep Consumption Time: 0.95005
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.67788

Cumulative Model Updates: 17,935
Cumulative Timesteps: 299,245,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.38301
Policy Entropy: 1.16579
Value Function Loss: 4.12208

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.06821

Collected Steps per Second: 8,688.94541
Overall Steps per Second: 7,578.27270

Timestep Collection Time: 5.75720
Timestep Consumption Time: 0.84378
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.60098

Cumulative Model Updates: 17,938
Cumulative Timesteps: 299,295,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 299295172...
Checkpoint 299295172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.54657
Policy Entropy: 1.17092
Value Function Loss: 4.25310

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 8,956.43991
Overall Steps per Second: 7,802.20232

Timestep Collection Time: 5.58436
Timestep Consumption Time: 0.82614
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.41050

Cumulative Model Updates: 17,941
Cumulative Timesteps: 299,345,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.17085
Policy Entropy: 1.17675
Value Function Loss: 4.28750

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 8,725.24407
Overall Steps per Second: 7,767.52995

Timestep Collection Time: 5.73371
Timestep Consumption Time: 0.70695
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.44066

Cumulative Model Updates: 17,944
Cumulative Timesteps: 299,395,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 299395216...
Checkpoint 299395216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.14433
Policy Entropy: 1.17883
Value Function Loss: 4.17674

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.07888

Collected Steps per Second: 8,585.76249
Overall Steps per Second: 7,439.68882

Timestep Collection Time: 5.82523
Timestep Consumption Time: 0.89737
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.72259

Cumulative Model Updates: 17,947
Cumulative Timesteps: 299,445,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.01054
Policy Entropy: 1.17063
Value Function Loss: 4.06872

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 9,056.10375
Overall Steps per Second: 7,902.62554

Timestep Collection Time: 5.52180
Timestep Consumption Time: 0.80597
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.32777

Cumulative Model Updates: 17,950
Cumulative Timesteps: 299,495,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 299495236...
Checkpoint 299495236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.09821
Policy Entropy: 1.16143
Value Function Loss: 4.14866

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.09717

Collected Steps per Second: 8,989.35337
Overall Steps per Second: 7,824.45721

Timestep Collection Time: 5.56414
Timestep Consumption Time: 0.82838
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 6.39252

Cumulative Model Updates: 17,953
Cumulative Timesteps: 299,545,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.88046
Policy Entropy: 1.16979
Value Function Loss: 4.16794

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.08666

Collected Steps per Second: 9,059.84732
Overall Steps per Second: 7,894.40729

Timestep Collection Time: 5.52129
Timestep Consumption Time: 0.81510
PPO Batch Consumption Time: 0.04903
Total Iteration Time: 6.33638

Cumulative Model Updates: 17,956
Cumulative Timesteps: 299,595,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 299595276...
Checkpoint 299595276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.01898
Policy Entropy: 1.17886
Value Function Loss: 4.06949

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.08063

Collected Steps per Second: 8,856.23335
Overall Steps per Second: 7,801.53438

Timestep Collection Time: 5.64777
Timestep Consumption Time: 0.76353
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.41130

Cumulative Model Updates: 17,959
Cumulative Timesteps: 299,645,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.24869
Policy Entropy: 1.18402
Value Function Loss: 3.90876

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 8,768.71476
Overall Steps per Second: 7,596.45386

Timestep Collection Time: 5.70232
Timestep Consumption Time: 0.87996
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 6.58228

Cumulative Model Updates: 17,962
Cumulative Timesteps: 299,695,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 299695296...
Checkpoint 299695296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.05486
Policy Entropy: 1.18788
Value Function Loss: 4.08356

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 8,615.08295
Overall Steps per Second: 7,489.90710

Timestep Collection Time: 5.80447
Timestep Consumption Time: 0.87198
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 6.67645

Cumulative Model Updates: 17,965
Cumulative Timesteps: 299,745,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.20447
Policy Entropy: 1.18662
Value Function Loss: 4.34087

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.06916
Value Function Update Magnitude: 0.08447

Collected Steps per Second: 9,019.40509
Overall Steps per Second: 7,854.16686

Timestep Collection Time: 5.54471
Timestep Consumption Time: 0.82261
PPO Batch Consumption Time: 0.04863
Total Iteration Time: 6.36732

Cumulative Model Updates: 17,968
Cumulative Timesteps: 299,795,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 299795312...
Checkpoint 299795312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.59960
Policy Entropy: 1.17567
Value Function Loss: 4.39356

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06201
Policy Update Magnitude: 0.07392
Value Function Update Magnitude: 0.08773

Collected Steps per Second: 9,050.45135
Overall Steps per Second: 7,805.96305

Timestep Collection Time: 5.52525
Timestep Consumption Time: 0.88088
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.40613

Cumulative Model Updates: 17,971
Cumulative Timesteps: 299,845,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.01894
Policy Entropy: 1.16789
Value Function Loss: 4.33015

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 8,949.27023
Overall Steps per Second: 7,938.46959

Timestep Collection Time: 5.58749
Timestep Consumption Time: 0.71145
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.29895

Cumulative Model Updates: 17,974
Cumulative Timesteps: 299,895,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 299895322...
Checkpoint 299895322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.18082
Policy Entropy: 1.15945
Value Function Loss: 4.27644

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.07976

Collected Steps per Second: 8,956.72345
Overall Steps per Second: 7,808.67461

Timestep Collection Time: 5.58508
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.04774
Total Iteration Time: 6.40621

Cumulative Model Updates: 17,977
Cumulative Timesteps: 299,945,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.61038
Policy Entropy: 1.18046
Value Function Loss: 4.13197

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 9,346.88593
Overall Steps per Second: 8,120.63815

Timestep Collection Time: 5.35216
Timestep Consumption Time: 0.80820
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.16035

Cumulative Model Updates: 17,980
Cumulative Timesteps: 299,995,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 299995372...
Checkpoint 299995372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.69371
Policy Entropy: 1.18385
Value Function Loss: 4.23612

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 9,161.92615
Overall Steps per Second: 7,976.23533

Timestep Collection Time: 5.45802
Timestep Consumption Time: 0.81135
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.26937

Cumulative Model Updates: 17,983
Cumulative Timesteps: 300,045,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.29160
Policy Entropy: 1.16850
Value Function Loss: 4.18613

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 8,545.59918
Overall Steps per Second: 7,370.91274

Timestep Collection Time: 5.85401
Timestep Consumption Time: 0.93294
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.78695

Cumulative Model Updates: 17,986
Cumulative Timesteps: 300,095,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 300095404...
Checkpoint 300095404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.03341
Policy Entropy: 1.17842
Value Function Loss: 4.21119

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 8,107.21384
Overall Steps per Second: 7,136.09768

Timestep Collection Time: 6.17055
Timestep Consumption Time: 0.83972
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 7.01027

Cumulative Model Updates: 17,989
Cumulative Timesteps: 300,145,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.66982
Policy Entropy: 1.18290
Value Function Loss: 4.20309

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.06246

Collected Steps per Second: 8,674.09359
Overall Steps per Second: 7,476.07633

Timestep Collection Time: 5.76544
Timestep Consumption Time: 0.92389
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 6.68934

Cumulative Model Updates: 17,992
Cumulative Timesteps: 300,195,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 300195440...
Checkpoint 300195440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.73506
Policy Entropy: 1.17616
Value Function Loss: 4.17203

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.06429

Collected Steps per Second: 8,222.77553
Overall Steps per Second: 7,050.29702

Timestep Collection Time: 6.08262
Timestep Consumption Time: 1.01155
PPO Batch Consumption Time: 0.04724
Total Iteration Time: 7.09417

Cumulative Model Updates: 17,995
Cumulative Timesteps: 300,245,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.39212
Policy Entropy: 1.16678
Value Function Loss: 4.22996

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 8,615.86156
Overall Steps per Second: 7,481.65610

Timestep Collection Time: 5.80511
Timestep Consumption Time: 0.88004
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 6.68515

Cumulative Model Updates: 17,998
Cumulative Timesteps: 300,295,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 300295472...
Checkpoint 300295472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.62686
Policy Entropy: 1.16873
Value Function Loss: 4.20810

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 8,399.58690
Overall Steps per Second: 7,184.48898

Timestep Collection Time: 5.95291
Timestep Consumption Time: 1.00680
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.95972

Cumulative Model Updates: 18,001
Cumulative Timesteps: 300,345,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.70900
Policy Entropy: 1.17834
Value Function Loss: 4.06941

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.06613

Collected Steps per Second: 8,154.47432
Overall Steps per Second: 7,085.11016

Timestep Collection Time: 6.13430
Timestep Consumption Time: 0.92586
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 7.06016

Cumulative Model Updates: 18,004
Cumulative Timesteps: 300,395,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 300395496...
Checkpoint 300395496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.05375
Policy Entropy: 1.15910
Value Function Loss: 4.16345

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.06000

Collected Steps per Second: 9,021.47687
Overall Steps per Second: 7,840.11506

Timestep Collection Time: 5.54521
Timestep Consumption Time: 0.83556
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 6.38077

Cumulative Model Updates: 18,007
Cumulative Timesteps: 300,445,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.87421
Policy Entropy: 1.17889
Value Function Loss: 4.04912

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 8,787.44920
Overall Steps per Second: 7,584.94242

Timestep Collection Time: 5.69175
Timestep Consumption Time: 0.90236
PPO Batch Consumption Time: 0.05252
Total Iteration Time: 6.59412

Cumulative Model Updates: 18,010
Cumulative Timesteps: 300,495,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 300495538...
Checkpoint 300495538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.60789
Policy Entropy: 1.16755
Value Function Loss: 3.98783

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 8,857.60661
Overall Steps per Second: 7,619.67564

Timestep Collection Time: 5.64599
Timestep Consumption Time: 0.91728
PPO Batch Consumption Time: 0.04882
Total Iteration Time: 6.56327

Cumulative Model Updates: 18,013
Cumulative Timesteps: 300,545,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.52068
Policy Entropy: 1.16232
Value Function Loss: 3.72546

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 8,755.19879
Overall Steps per Second: 7,632.18242

Timestep Collection Time: 5.71089
Timestep Consumption Time: 0.84031
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.55121

Cumulative Model Updates: 18,016
Cumulative Timesteps: 300,595,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 300595548...
Checkpoint 300595548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.37071
Policy Entropy: 1.15864
Value Function Loss: 3.64368

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.06603
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 9,004.38766
Overall Steps per Second: 7,901.20785

Timestep Collection Time: 5.55374
Timestep Consumption Time: 0.77542
PPO Batch Consumption Time: 0.04562
Total Iteration Time: 6.32916

Cumulative Model Updates: 18,019
Cumulative Timesteps: 300,645,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.72650
Policy Entropy: 1.16442
Value Function Loss: 3.78326

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 8,937.59246
Overall Steps per Second: 7,709.25175

Timestep Collection Time: 5.59793
Timestep Consumption Time: 0.89194
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.48986

Cumulative Model Updates: 18,022
Cumulative Timesteps: 300,695,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 300695588...
Checkpoint 300695588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.08357
Policy Entropy: 1.15170
Value Function Loss: 3.92228

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.05967

Collected Steps per Second: 8,862.20468
Overall Steps per Second: 7,728.83629

Timestep Collection Time: 5.64442
Timestep Consumption Time: 0.82771
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.47213

Cumulative Model Updates: 18,025
Cumulative Timesteps: 300,745,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.13045
Policy Entropy: 1.15537
Value Function Loss: 4.09009

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 9,256.20446
Overall Steps per Second: 7,897.33552

Timestep Collection Time: 5.40438
Timestep Consumption Time: 0.92991
PPO Batch Consumption Time: 0.04974
Total Iteration Time: 6.33429

Cumulative Model Updates: 18,028
Cumulative Timesteps: 300,795,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 300795634...
Checkpoint 300795634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.06463
Policy Entropy: 1.16450
Value Function Loss: 4.19657

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 9,211.00238
Overall Steps per Second: 7,902.60368

Timestep Collection Time: 5.43133
Timestep Consumption Time: 0.89924
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 6.33057

Cumulative Model Updates: 18,031
Cumulative Timesteps: 300,845,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.40636
Policy Entropy: 1.14274
Value Function Loss: 4.14783

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.07634

Collected Steps per Second: 8,901.62931
Overall Steps per Second: 7,802.57482

Timestep Collection Time: 5.61740
Timestep Consumption Time: 0.79126
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 6.40865

Cumulative Model Updates: 18,034
Cumulative Timesteps: 300,895,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 300895666...
Checkpoint 300895666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.45324
Policy Entropy: 1.13526
Value Function Loss: 4.07492

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.06798

Collected Steps per Second: 9,165.26054
Overall Steps per Second: 7,850.70652

Timestep Collection Time: 5.45844
Timestep Consumption Time: 0.91398
PPO Batch Consumption Time: 0.04808
Total Iteration Time: 6.37242

Cumulative Model Updates: 18,037
Cumulative Timesteps: 300,945,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.99746
Policy Entropy: 1.14514
Value Function Loss: 3.91344

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.05897

Collected Steps per Second: 8,958.79278
Overall Steps per Second: 7,786.42003

Timestep Collection Time: 5.58356
Timestep Consumption Time: 0.84070
PPO Batch Consumption Time: 0.04716
Total Iteration Time: 6.42426

Cumulative Model Updates: 18,040
Cumulative Timesteps: 300,995,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 300995716...
Checkpoint 300995716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.28662
Policy Entropy: 1.14717
Value Function Loss: 3.93300

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.06860
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 8,642.74737
Overall Steps per Second: 7,519.08467

Timestep Collection Time: 5.78682
Timestep Consumption Time: 0.86479
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.65161

Cumulative Model Updates: 18,043
Cumulative Timesteps: 301,045,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.68898
Policy Entropy: 1.13930
Value Function Loss: 3.94805

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.06931
Value Function Update Magnitude: 0.05015

Collected Steps per Second: 9,013.02754
Overall Steps per Second: 7,842.19967

Timestep Collection Time: 5.55063
Timestep Consumption Time: 0.82870
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.37933

Cumulative Model Updates: 18,046
Cumulative Timesteps: 301,095,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 301095758...
Checkpoint 301095758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.89863
Policy Entropy: 1.14254
Value Function Loss: 4.04827

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.06286
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 8,868.37292
Overall Steps per Second: 7,859.95898

Timestep Collection Time: 5.64027
Timestep Consumption Time: 0.72363
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.36390

Cumulative Model Updates: 18,049
Cumulative Timesteps: 301,145,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.06612
Policy Entropy: 1.14528
Value Function Loss: 4.03823

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.05727

Collected Steps per Second: 9,101.52265
Overall Steps per Second: 7,845.19665

Timestep Collection Time: 5.49468
Timestep Consumption Time: 0.87992
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.37460

Cumulative Model Updates: 18,052
Cumulative Timesteps: 301,195,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 301195788...
Checkpoint 301195788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.49627
Policy Entropy: 1.15511
Value Function Loss: 3.79931

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.06440

Collected Steps per Second: 8,787.18795
Overall Steps per Second: 7,687.27313

Timestep Collection Time: 5.69079
Timestep Consumption Time: 0.81425
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.50504

Cumulative Model Updates: 18,055
Cumulative Timesteps: 301,245,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.63300
Policy Entropy: 1.16272
Value Function Loss: 3.63500

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 8,840.21196
Overall Steps per Second: 7,718.11290

Timestep Collection Time: 5.65665
Timestep Consumption Time: 0.82239
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.47904

Cumulative Model Updates: 18,058
Cumulative Timesteps: 301,295,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 301295800...
Checkpoint 301295800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.85508
Policy Entropy: 1.14972
Value Function Loss: 3.67262

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 8,763.73233
Overall Steps per Second: 7,657.08480

Timestep Collection Time: 5.70853
Timestep Consumption Time: 0.82503
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.53356

Cumulative Model Updates: 18,061
Cumulative Timesteps: 301,345,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.60534
Policy Entropy: 1.14513
Value Function Loss: 3.99809

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 8,965.31671
Overall Steps per Second: 7,936.01576

Timestep Collection Time: 5.57972
Timestep Consumption Time: 0.72369
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.30341

Cumulative Model Updates: 18,064
Cumulative Timesteps: 301,395,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 301395852...
Checkpoint 301395852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.82389
Policy Entropy: 1.14714
Value Function Loss: 4.05293

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.05893

Collected Steps per Second: 8,845.63742
Overall Steps per Second: 7,685.42604

Timestep Collection Time: 5.65454
Timestep Consumption Time: 0.85362
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.50816

Cumulative Model Updates: 18,067
Cumulative Timesteps: 301,445,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.46945
Policy Entropy: 1.15179
Value Function Loss: 3.89045

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 8,727.57025
Overall Steps per Second: 7,657.93719

Timestep Collection Time: 5.73264
Timestep Consumption Time: 0.80071
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.53335

Cumulative Model Updates: 18,070
Cumulative Timesteps: 301,495,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 301495902...
Checkpoint 301495902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.99353
Policy Entropy: 1.14467
Value Function Loss: 3.83903

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 9,059.63627
Overall Steps per Second: 7,841.31872

Timestep Collection Time: 5.52097
Timestep Consumption Time: 0.85780
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.37877

Cumulative Model Updates: 18,073
Cumulative Timesteps: 301,545,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.83219
Policy Entropy: 1.13752
Value Function Loss: 4.00935

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.06245

Collected Steps per Second: 8,863.97347
Overall Steps per Second: 7,733.55457

Timestep Collection Time: 5.64284
Timestep Consumption Time: 0.82482
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.46766

Cumulative Model Updates: 18,076
Cumulative Timesteps: 301,595,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 301595938...
Checkpoint 301595938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.76861
Policy Entropy: 1.15576
Value Function Loss: 4.15687

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 8,855.23359
Overall Steps per Second: 7,775.89179

Timestep Collection Time: 5.64909
Timestep Consumption Time: 0.78413
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.43322

Cumulative Model Updates: 18,079
Cumulative Timesteps: 301,645,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.29544
Policy Entropy: 1.15549
Value Function Loss: 4.05832

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 9,044.30015
Overall Steps per Second: 7,878.27535

Timestep Collection Time: 5.53011
Timestep Consumption Time: 0.81848
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.34860

Cumulative Model Updates: 18,082
Cumulative Timesteps: 301,695,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 301695978...
Checkpoint 301695978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.45962
Policy Entropy: 1.15189
Value Function Loss: 4.02570

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 8,917.35149
Overall Steps per Second: 7,815.71824

Timestep Collection Time: 5.60705
Timestep Consumption Time: 0.79032
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.39736

Cumulative Model Updates: 18,085
Cumulative Timesteps: 301,745,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.31140
Policy Entropy: 1.14766
Value Function Loss: 4.01167

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 9,282.71589
Overall Steps per Second: 8,048.13706

Timestep Collection Time: 5.38851
Timestep Consumption Time: 0.82659
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.21510

Cumulative Model Updates: 18,088
Cumulative Timesteps: 301,795,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 301795998...
Checkpoint 301795998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.92146
Policy Entropy: 1.15660
Value Function Loss: 4.08253

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.06217

Collected Steps per Second: 9,109.13630
Overall Steps per Second: 7,891.10203

Timestep Collection Time: 5.49119
Timestep Consumption Time: 0.84759
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.33879

Cumulative Model Updates: 18,091
Cumulative Timesteps: 301,846,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.67271
Policy Entropy: 1.15891
Value Function Loss: 4.06157

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 8,950.07700
Overall Steps per Second: 7,932.11885

Timestep Collection Time: 5.58721
Timestep Consumption Time: 0.71703
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.30424

Cumulative Model Updates: 18,094
Cumulative Timesteps: 301,896,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 301896024...
Checkpoint 301896024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.92533
Policy Entropy: 1.16393
Value Function Loss: 4.09008

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 8,988.08413
Overall Steps per Second: 7,757.38213

Timestep Collection Time: 5.56314
Timestep Consumption Time: 0.88259
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.44573

Cumulative Model Updates: 18,097
Cumulative Timesteps: 301,946,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.28424
Policy Entropy: 1.15783
Value Function Loss: 3.99890

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 8,723.95770
Overall Steps per Second: 7,604.07064

Timestep Collection Time: 5.73134
Timestep Consumption Time: 0.84408
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.57543

Cumulative Model Updates: 18,100
Cumulative Timesteps: 301,996,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 301996026...
Checkpoint 301996026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.23769
Policy Entropy: 1.16993
Value Function Loss: 4.02453

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.08047

Collected Steps per Second: 9,233.88395
Overall Steps per Second: 7,946.55106

Timestep Collection Time: 5.41657
Timestep Consumption Time: 0.87748
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.29405

Cumulative Model Updates: 18,103
Cumulative Timesteps: 302,046,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.61517
Policy Entropy: 1.17215
Value Function Loss: 4.02275

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.08648

Collected Steps per Second: 8,938.97876
Overall Steps per Second: 7,716.00581

Timestep Collection Time: 5.59393
Timestep Consumption Time: 0.88663
PPO Batch Consumption Time: 0.04330
Total Iteration Time: 6.48056

Cumulative Model Updates: 18,106
Cumulative Timesteps: 302,096,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 302096046...
Checkpoint 302096046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.43315
Policy Entropy: 1.16150
Value Function Loss: 4.05402

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.08699

Collected Steps per Second: 8,704.78290
Overall Steps per Second: 7,648.39413

Timestep Collection Time: 5.74420
Timestep Consumption Time: 0.79338
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 6.53758

Cumulative Model Updates: 18,109
Cumulative Timesteps: 302,146,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.09820
Policy Entropy: 1.15235
Value Function Loss: 4.03875

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 8,720.50338
Overall Steps per Second: 7,575.99745

Timestep Collection Time: 5.73430
Timestep Consumption Time: 0.86628
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.60058

Cumulative Model Updates: 18,112
Cumulative Timesteps: 302,196,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 302196054...
Checkpoint 302196054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.10856
Policy Entropy: 1.16544
Value Function Loss: 3.96019

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 8,700.14845
Overall Steps per Second: 7,632.82754

Timestep Collection Time: 5.74795
Timestep Consumption Time: 0.80375
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 6.55170

Cumulative Model Updates: 18,115
Cumulative Timesteps: 302,246,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.77946
Policy Entropy: 1.17034
Value Function Loss: 4.09611

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.07083

Collected Steps per Second: 9,083.34511
Overall Steps per Second: 7,821.53954

Timestep Collection Time: 5.50612
Timestep Consumption Time: 0.88827
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.39439

Cumulative Model Updates: 18,118
Cumulative Timesteps: 302,296,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 302296076...
Checkpoint 302296076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.99528
Policy Entropy: 1.14581
Value Function Loss: 3.97514

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 8,781.60992
Overall Steps per Second: 7,646.72825

Timestep Collection Time: 5.69508
Timestep Consumption Time: 0.84523
PPO Batch Consumption Time: 0.04858
Total Iteration Time: 6.54031

Cumulative Model Updates: 18,121
Cumulative Timesteps: 302,346,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.33394
Policy Entropy: 1.15819
Value Function Loss: 4.11682

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.06237

Collected Steps per Second: 8,935.16069
Overall Steps per Second: 7,772.79511

Timestep Collection Time: 5.59609
Timestep Consumption Time: 0.83686
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 6.43295

Cumulative Model Updates: 18,124
Cumulative Timesteps: 302,396,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 302396090...
Checkpoint 302396090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.86882
Policy Entropy: 1.15847
Value Function Loss: 4.05318

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.05289

Collected Steps per Second: 8,489.19466
Overall Steps per Second: 7,390.42249

Timestep Collection Time: 5.89008
Timestep Consumption Time: 0.87571
PPO Batch Consumption Time: 0.04045
Total Iteration Time: 6.76578

Cumulative Model Updates: 18,127
Cumulative Timesteps: 302,446,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.99890
Policy Entropy: 1.14544
Value Function Loss: 4.16255

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.04236

Collected Steps per Second: 8,890.81305
Overall Steps per Second: 7,736.78405

Timestep Collection Time: 5.62671
Timestep Consumption Time: 0.83929
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.46599

Cumulative Model Updates: 18,130
Cumulative Timesteps: 302,496,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 302496118...
Checkpoint 302496118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.45075
Policy Entropy: 1.14080
Value Function Loss: 4.00089

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.04150

Collected Steps per Second: 8,983.49099
Overall Steps per Second: 7,766.12295

Timestep Collection Time: 5.56844
Timestep Consumption Time: 0.87287
PPO Batch Consumption Time: 0.04330
Total Iteration Time: 6.44131

Cumulative Model Updates: 18,133
Cumulative Timesteps: 302,546,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.87074
Policy Entropy: 1.14879
Value Function Loss: 3.82395

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.05472

Collected Steps per Second: 8,849.98787
Overall Steps per Second: 7,700.35117

Timestep Collection Time: 5.65086
Timestep Consumption Time: 0.84365
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 6.49451

Cumulative Model Updates: 18,136
Cumulative Timesteps: 302,596,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 302596152...
Checkpoint 302596152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.51916
Policy Entropy: 1.15908
Value Function Loss: 3.91715

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.07231

Collected Steps per Second: 9,134.65814
Overall Steps per Second: 7,871.73779

Timestep Collection Time: 5.47607
Timestep Consumption Time: 0.87857
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.35463

Cumulative Model Updates: 18,139
Cumulative Timesteps: 302,646,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.30651
Policy Entropy: 1.14163
Value Function Loss: 4.00460

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 9,120.02246
Overall Steps per Second: 7,830.99574

Timestep Collection Time: 5.48595
Timestep Consumption Time: 0.90302
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 6.38897

Cumulative Model Updates: 18,142
Cumulative Timesteps: 302,696,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 302696206...
Checkpoint 302696206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.86283
Policy Entropy: 1.13729
Value Function Loss: 4.18558

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.05875

Collected Steps per Second: 9,074.64322
Overall Steps per Second: 7,869.00262

Timestep Collection Time: 5.51338
Timestep Consumption Time: 0.84473
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 6.35811

Cumulative Model Updates: 18,145
Cumulative Timesteps: 302,746,238

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.14548
Policy Entropy: 1.14417
Value Function Loss: 4.13956

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.05668

Collected Steps per Second: 9,480.97680
Overall Steps per Second: 8,123.21100

Timestep Collection Time: 5.27541
Timestep Consumption Time: 0.88177
PPO Batch Consumption Time: 0.04779
Total Iteration Time: 6.15717

Cumulative Model Updates: 18,148
Cumulative Timesteps: 302,796,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 302796254...
Checkpoint 302796254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.26948
Policy Entropy: 1.14417
Value Function Loss: 4.05287

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 9,141.96876
Overall Steps per Second: 7,890.63277

Timestep Collection Time: 5.47256
Timestep Consumption Time: 0.86787
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.34043

Cumulative Model Updates: 18,151
Cumulative Timesteps: 302,846,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.32593
Policy Entropy: 1.12237
Value Function Loss: 4.03488

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 8,729.02916
Overall Steps per Second: 7,682.97903

Timestep Collection Time: 5.72962
Timestep Consumption Time: 0.78010
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.50971

Cumulative Model Updates: 18,154
Cumulative Timesteps: 302,896,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 302896298...
Checkpoint 302896298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.98936
Policy Entropy: 1.13568
Value Function Loss: 3.95649

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.06252

Collected Steps per Second: 8,775.81289
Overall Steps per Second: 7,622.07960

Timestep Collection Time: 5.69793
Timestep Consumption Time: 0.86248
PPO Batch Consumption Time: 0.04899
Total Iteration Time: 6.56041

Cumulative Model Updates: 18,157
Cumulative Timesteps: 302,946,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.19578
Policy Entropy: 1.14026
Value Function Loss: 3.88957

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 8,768.80424
Overall Steps per Second: 7,692.80545

Timestep Collection Time: 5.70363
Timestep Consumption Time: 0.79777
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.50140

Cumulative Model Updates: 18,160
Cumulative Timesteps: 302,996,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 302996316...
Checkpoint 302996316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.20995
Policy Entropy: 1.12819
Value Function Loss: 3.65569

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 9,021.16061
Overall Steps per Second: 7,753.55926

Timestep Collection Time: 5.54541
Timestep Consumption Time: 0.90660
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 6.45200

Cumulative Model Updates: 18,163
Cumulative Timesteps: 303,046,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.03070
Policy Entropy: 1.11453
Value Function Loss: 3.60665

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.08440

Collected Steps per Second: 8,844.59862
Overall Steps per Second: 7,622.21838

Timestep Collection Time: 5.65498
Timestep Consumption Time: 0.90689
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.56187

Cumulative Model Updates: 18,166
Cumulative Timesteps: 303,096,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 303096358...
Checkpoint 303096358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.39970
Policy Entropy: 1.13495
Value Function Loss: 3.52664

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07324

Collected Steps per Second: 8,637.58131
Overall Steps per Second: 7,651.87945

Timestep Collection Time: 5.79005
Timestep Consumption Time: 0.74586
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 6.53591

Cumulative Model Updates: 18,169
Cumulative Timesteps: 303,146,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.01216
Policy Entropy: 1.13109
Value Function Loss: 3.57066

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.07787
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 8,849.28742
Overall Steps per Second: 7,728.76549

Timestep Collection Time: 5.65175
Timestep Consumption Time: 0.81940
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.47115

Cumulative Model Updates: 18,172
Cumulative Timesteps: 303,196,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 303196384...
Checkpoint 303196384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.93700
Policy Entropy: 1.13069
Value Function Loss: 3.76572

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.08206
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 8,652.94527
Overall Steps per Second: 7,610.57763

Timestep Collection Time: 5.78023
Timestep Consumption Time: 0.79168
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 6.57191

Cumulative Model Updates: 18,175
Cumulative Timesteps: 303,246,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.85368
Policy Entropy: 1.11841
Value Function Loss: 3.88347

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.08001
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 9,100.94429
Overall Steps per Second: 7,904.53968

Timestep Collection Time: 5.49701
Timestep Consumption Time: 0.83201
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.32902

Cumulative Model Updates: 18,178
Cumulative Timesteps: 303,296,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 303296428...
Checkpoint 303296428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.73494
Policy Entropy: 1.11519
Value Function Loss: 4.05091

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.15586
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 8,587.35769
Overall Steps per Second: 7,500.54041

Timestep Collection Time: 5.82577
Timestep Consumption Time: 0.84415
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.66992

Cumulative Model Updates: 18,181
Cumulative Timesteps: 303,346,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.14045
Policy Entropy: 1.13287
Value Function Loss: 4.03824

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.08795

Collected Steps per Second: 8,709.04959
Overall Steps per Second: 7,683.61120

Timestep Collection Time: 5.74322
Timestep Consumption Time: 0.76648
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.50970

Cumulative Model Updates: 18,184
Cumulative Timesteps: 303,396,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 303396474...
Checkpoint 303396474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.90516
Policy Entropy: 1.14452
Value Function Loss: 3.91083

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.09061

Collected Steps per Second: 8,856.47292
Overall Steps per Second: 7,682.97692

Timestep Collection Time: 5.64739
Timestep Consumption Time: 0.86258
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 6.50998

Cumulative Model Updates: 18,187
Cumulative Timesteps: 303,446,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.28319
Policy Entropy: 1.12196
Value Function Loss: 3.97310

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 8,775.58188
Overall Steps per Second: 7,671.57568

Timestep Collection Time: 5.69854
Timestep Consumption Time: 0.82007
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.51861

Cumulative Model Updates: 18,190
Cumulative Timesteps: 303,496,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 303496498...
Checkpoint 303496498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.03685
Policy Entropy: 1.14211
Value Function Loss: 3.92130

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.08616

Collected Steps per Second: 8,844.73024
Overall Steps per Second: 7,637.56443

Timestep Collection Time: 5.65444
Timestep Consumption Time: 0.89372
PPO Batch Consumption Time: 0.04897
Total Iteration Time: 6.54816

Cumulative Model Updates: 18,193
Cumulative Timesteps: 303,546,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.12179
Policy Entropy: 1.13995
Value Function Loss: 4.15269

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08624

Collected Steps per Second: 8,596.56837
Overall Steps per Second: 7,522.05583

Timestep Collection Time: 5.81883
Timestep Consumption Time: 0.83121
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.65004

Cumulative Model Updates: 18,196
Cumulative Timesteps: 303,596,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 303596532...
Checkpoint 303596532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.19058
Policy Entropy: 1.12575
Value Function Loss: 4.07136

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.08497

Collected Steps per Second: 8,720.01160
Overall Steps per Second: 7,726.30087

Timestep Collection Time: 5.73623
Timestep Consumption Time: 0.73776
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.47399

Cumulative Model Updates: 18,199
Cumulative Timesteps: 303,646,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.66815
Policy Entropy: 1.12240
Value Function Loss: 4.06372

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 9,103.20046
Overall Steps per Second: 7,858.49160

Timestep Collection Time: 5.49521
Timestep Consumption Time: 0.87039
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 6.36560

Cumulative Model Updates: 18,202
Cumulative Timesteps: 303,696,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 303696576...
Checkpoint 303696576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.52733
Policy Entropy: 1.13590
Value Function Loss: 3.83775

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.07797

Collected Steps per Second: 8,884.24246
Overall Steps per Second: 7,740.05043

Timestep Collection Time: 5.62974
Timestep Consumption Time: 0.83223
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.46197

Cumulative Model Updates: 18,205
Cumulative Timesteps: 303,746,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.65278
Policy Entropy: 1.15621
Value Function Loss: 3.88932

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 9,082.55055
Overall Steps per Second: 7,670.35940

Timestep Collection Time: 5.50770
Timestep Consumption Time: 1.01402
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.52173

Cumulative Model Updates: 18,208
Cumulative Timesteps: 303,796,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 303796616...
Checkpoint 303796616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.05579
Policy Entropy: 1.14550
Value Function Loss: 3.87903

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 8,625.23644
Overall Steps per Second: 7,567.33978

Timestep Collection Time: 5.79833
Timestep Consumption Time: 0.81059
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.60893

Cumulative Model Updates: 18,211
Cumulative Timesteps: 303,846,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.80186
Policy Entropy: 1.13876
Value Function Loss: 4.06304

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 8,780.48871
Overall Steps per Second: 7,741.07131

Timestep Collection Time: 5.69809
Timestep Consumption Time: 0.76510
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 6.46319

Cumulative Model Updates: 18,214
Cumulative Timesteps: 303,896,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 303896660...
Checkpoint 303896660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.91015
Policy Entropy: 1.14269
Value Function Loss: 3.98343

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 9,028.14762
Overall Steps per Second: 7,853.04181

Timestep Collection Time: 5.53934
Timestep Consumption Time: 0.82889
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 6.36823

Cumulative Model Updates: 18,217
Cumulative Timesteps: 303,946,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.88865
Policy Entropy: 1.13969
Value Function Loss: 3.94200

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 8,787.96602
Overall Steps per Second: 7,687.85868

Timestep Collection Time: 5.69233
Timestep Consumption Time: 0.81455
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 6.50688

Cumulative Model Updates: 18,220
Cumulative Timesteps: 303,996,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 303996694...
Checkpoint 303996694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.33261
Policy Entropy: 1.13466
Value Function Loss: 3.90790

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.06139

Collected Steps per Second: 8,854.78226
Overall Steps per Second: 7,738.13979

Timestep Collection Time: 5.64757
Timestep Consumption Time: 0.81497
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 6.46254

Cumulative Model Updates: 18,223
Cumulative Timesteps: 304,046,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.05443
Policy Entropy: 1.13157
Value Function Loss: 3.91607

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.05873

Collected Steps per Second: 8,791.67835
Overall Steps per Second: 7,716.06486

Timestep Collection Time: 5.68970
Timestep Consumption Time: 0.79314
PPO Batch Consumption Time: 0.03966
Total Iteration Time: 6.48284

Cumulative Model Updates: 18,226
Cumulative Timesteps: 304,096,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 304096724...
Checkpoint 304096724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.10545
Policy Entropy: 1.14291
Value Function Loss: 3.89354

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.05344

Collected Steps per Second: 8,890.12254
Overall Steps per Second: 7,785.44334

Timestep Collection Time: 5.62737
Timestep Consumption Time: 0.79847
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 6.42584

Cumulative Model Updates: 18,229
Cumulative Timesteps: 304,146,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.37409
Policy Entropy: 1.13958
Value Function Loss: 3.77761

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 8,862.67687
Overall Steps per Second: 7,687.27314

Timestep Collection Time: 5.64457
Timestep Consumption Time: 0.86307
PPO Batch Consumption Time: 0.04832
Total Iteration Time: 6.50764

Cumulative Model Updates: 18,232
Cumulative Timesteps: 304,196,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 304196778...
Checkpoint 304196778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.03318
Policy Entropy: 1.12349
Value Function Loss: 3.80890

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.07467
Value Function Update Magnitude: 0.06026

Collected Steps per Second: 8,733.18181
Overall Steps per Second: 7,604.76679

Timestep Collection Time: 5.72781
Timestep Consumption Time: 0.84991
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.57772

Cumulative Model Updates: 18,235
Cumulative Timesteps: 304,246,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.27287
Policy Entropy: 1.10955
Value Function Loss: 3.82032

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 8,767.61518
Overall Steps per Second: 7,573.43391

Timestep Collection Time: 5.70395
Timestep Consumption Time: 0.89940
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 6.60335

Cumulative Model Updates: 18,238
Cumulative Timesteps: 304,296,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 304296810...
Checkpoint 304296810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.24179
Policy Entropy: 1.12907
Value Function Loss: 3.91718

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.07170
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 8,646.79163
Overall Steps per Second: 7,515.38518

Timestep Collection Time: 5.78527
Timestep Consumption Time: 0.87095
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 6.65621

Cumulative Model Updates: 18,241
Cumulative Timesteps: 304,346,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.21181
Policy Entropy: 1.13570
Value Function Loss: 3.85945

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.06537

Collected Steps per Second: 8,739.00281
Overall Steps per Second: 7,708.80385

Timestep Collection Time: 5.72422
Timestep Consumption Time: 0.76498
PPO Batch Consumption Time: 0.04055
Total Iteration Time: 6.48920

Cumulative Model Updates: 18,244
Cumulative Timesteps: 304,396,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 304396858...
Checkpoint 304396858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.72083
Policy Entropy: 1.11607
Value Function Loss: 3.85060

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 8,914.64111
Overall Steps per Second: 7,679.62878

Timestep Collection Time: 5.60898
Timestep Consumption Time: 0.90202
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.51099

Cumulative Model Updates: 18,247
Cumulative Timesteps: 304,446,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.09072
Policy Entropy: 1.10844
Value Function Loss: 3.96837

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.05184

Collected Steps per Second: 8,747.49522
Overall Steps per Second: 7,631.76112

Timestep Collection Time: 5.71867
Timestep Consumption Time: 0.83605
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.55471

Cumulative Model Updates: 18,250
Cumulative Timesteps: 304,496,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 304496884...
Checkpoint 304496884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.29424
Policy Entropy: 1.11872
Value Function Loss: 3.88741

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 9,241.20601
Overall Steps per Second: 7,981.53587

Timestep Collection Time: 5.41228
Timestep Consumption Time: 0.85418
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.26646

Cumulative Model Updates: 18,253
Cumulative Timesteps: 304,546,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.49425
Policy Entropy: 1.12786
Value Function Loss: 3.88612

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.05523

Collected Steps per Second: 9,208.39402
Overall Steps per Second: 7,949.13595

Timestep Collection Time: 5.43200
Timestep Consumption Time: 0.86051
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.29251

Cumulative Model Updates: 18,256
Cumulative Timesteps: 304,596,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 304596920...
Checkpoint 304596920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.25673
Policy Entropy: 1.10423
Value Function Loss: 3.75958

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.05349

Collected Steps per Second: 9,022.47896
Overall Steps per Second: 7,905.08911

Timestep Collection Time: 5.54260
Timestep Consumption Time: 0.78345
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.32605

Cumulative Model Updates: 18,259
Cumulative Timesteps: 304,646,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.33010
Policy Entropy: 1.09835
Value Function Loss: 3.78455

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.05245

Collected Steps per Second: 9,479.71727
Overall Steps per Second: 8,142.48307

Timestep Collection Time: 5.27632
Timestep Consumption Time: 0.86653
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.14284

Cumulative Model Updates: 18,262
Cumulative Timesteps: 304,696,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 304696946...
Checkpoint 304696946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.01075
Policy Entropy: 1.10908
Value Function Loss: 3.87308

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 8,407.93115
Overall Steps per Second: 7,391.71213

Timestep Collection Time: 5.94843
Timestep Consumption Time: 0.81780
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.76623

Cumulative Model Updates: 18,265
Cumulative Timesteps: 304,746,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.27584
Policy Entropy: 1.12232
Value Function Loss: 4.04729

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.05103

Collected Steps per Second: 8,923.85464
Overall Steps per Second: 7,740.59520

Timestep Collection Time: 5.60498
Timestep Consumption Time: 0.85680
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.46178

Cumulative Model Updates: 18,268
Cumulative Timesteps: 304,796,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 304796978...
Checkpoint 304796978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.26532
Policy Entropy: 1.11177
Value Function Loss: 4.25430

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.04441

Collected Steps per Second: 8,525.05268
Overall Steps per Second: 7,483.43944

Timestep Collection Time: 5.86530
Timestep Consumption Time: 0.81639
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 6.68169

Cumulative Model Updates: 18,271
Cumulative Timesteps: 304,846,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.74323
Policy Entropy: 1.11012
Value Function Loss: 4.29182

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.04031

Collected Steps per Second: 8,582.94318
Overall Steps per Second: 7,535.69514

Timestep Collection Time: 5.82877
Timestep Consumption Time: 0.81003
PPO Batch Consumption Time: 0.05013
Total Iteration Time: 6.63880

Cumulative Model Updates: 18,274
Cumulative Timesteps: 304,897,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 304897008...
Checkpoint 304897008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.68696
Policy Entropy: 1.11928
Value Function Loss: 4.28961

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.03921

Collected Steps per Second: 8,517.31175
Overall Steps per Second: 7,221.11250

Timestep Collection Time: 5.87274
Timestep Consumption Time: 1.05417
PPO Batch Consumption Time: 0.05050
Total Iteration Time: 6.92691

Cumulative Model Updates: 18,277
Cumulative Timesteps: 304,947,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.67951
Policy Entropy: 1.12329
Value Function Loss: 4.32311

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.03921

Collected Steps per Second: 8,833.98327
Overall Steps per Second: 7,624.13575

Timestep Collection Time: 5.66200
Timestep Consumption Time: 0.89848
PPO Batch Consumption Time: 0.04756
Total Iteration Time: 6.56048

Cumulative Model Updates: 18,280
Cumulative Timesteps: 304,997,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 304997046...
Checkpoint 304997046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.45560
Policy Entropy: 1.10406
Value Function Loss: 4.20036

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.04859

Collected Steps per Second: 8,893.37449
Overall Steps per Second: 7,763.14578

Timestep Collection Time: 5.62531
Timestep Consumption Time: 0.81898
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.44429

Cumulative Model Updates: 18,283
Cumulative Timesteps: 305,047,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.00226
Policy Entropy: 1.10938
Value Function Loss: 4.18796

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 8,832.35463
Overall Steps per Second: 7,681.67375

Timestep Collection Time: 5.66282
Timestep Consumption Time: 0.84826
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.51108

Cumulative Model Updates: 18,286
Cumulative Timesteps: 305,097,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 305097090...
Checkpoint 305097090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.96238
Policy Entropy: 1.12366
Value Function Loss: 3.92024

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 8,716.24206
Overall Steps per Second: 7,745.24105

Timestep Collection Time: 5.73642
Timestep Consumption Time: 0.71916
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.45558

Cumulative Model Updates: 18,289
Cumulative Timesteps: 305,147,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.65898
Policy Entropy: 1.10676
Value Function Loss: 3.84755

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 8,442.37690
Overall Steps per Second: 7,345.47656

Timestep Collection Time: 5.92345
Timestep Consumption Time: 0.88455
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.80800

Cumulative Model Updates: 18,292
Cumulative Timesteps: 305,197,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 305197098...
Checkpoint 305197098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.68770
Policy Entropy: 1.11695
Value Function Loss: 3.90437

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 8,832.25897
Overall Steps per Second: 7,698.61326

Timestep Collection Time: 5.66378
Timestep Consumption Time: 0.83401
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.49779

Cumulative Model Updates: 18,295
Cumulative Timesteps: 305,247,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.78029
Policy Entropy: 1.11713
Value Function Loss: 4.02390

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 8,800.89627
Overall Steps per Second: 7,624.92177

Timestep Collection Time: 5.68374
Timestep Consumption Time: 0.87659
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.56033

Cumulative Model Updates: 18,298
Cumulative Timesteps: 305,297,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 305297144...
Checkpoint 305297144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.68022
Policy Entropy: 1.12918
Value Function Loss: 4.24485

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 8,939.97987
Overall Steps per Second: 7,789.38512

Timestep Collection Time: 5.59509
Timestep Consumption Time: 0.82647
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.42156

Cumulative Model Updates: 18,301
Cumulative Timesteps: 305,347,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.16146
Policy Entropy: 1.11085
Value Function Loss: 4.13903

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.09536

Collected Steps per Second: 8,946.76789
Overall Steps per Second: 7,907.33628

Timestep Collection Time: 5.59018
Timestep Consumption Time: 0.73484
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.32501

Cumulative Model Updates: 18,304
Cumulative Timesteps: 305,397,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 305397178...
Checkpoint 305397178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.78105
Policy Entropy: 1.10979
Value Function Loss: 3.98913

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 8,673.90793
Overall Steps per Second: 7,534.98569

Timestep Collection Time: 5.76465
Timestep Consumption Time: 0.87133
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.63598

Cumulative Model Updates: 18,307
Cumulative Timesteps: 305,447,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.43886
Policy Entropy: 1.11496
Value Function Loss: 3.82041

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 8,782.60840
Overall Steps per Second: 7,599.78452

Timestep Collection Time: 5.69307
Timestep Consumption Time: 0.88606
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.57913

Cumulative Model Updates: 18,310
Cumulative Timesteps: 305,497,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 305497180...
Checkpoint 305497180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.24423
Policy Entropy: 1.12481
Value Function Loss: 3.83571

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 9,249.19997
Overall Steps per Second: 7,968.04712

Timestep Collection Time: 5.40674
Timestep Consumption Time: 0.86933
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.27607

Cumulative Model Updates: 18,313
Cumulative Timesteps: 305,547,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.24164
Policy Entropy: 1.11500
Value Function Loss: 4.03266

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 9,090.16552
Overall Steps per Second: 7,900.51195

Timestep Collection Time: 5.50045
Timestep Consumption Time: 0.82825
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.32870

Cumulative Model Updates: 18,316
Cumulative Timesteps: 305,597,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 305597188...
Checkpoint 305597188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.29777
Policy Entropy: 1.10938
Value Function Loss: 4.12216

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 8,501.87793
Overall Steps per Second: 7,547.29280

Timestep Collection Time: 5.88317
Timestep Consumption Time: 0.74411
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.62728

Cumulative Model Updates: 18,319
Cumulative Timesteps: 305,647,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.06033
Policy Entropy: 1.11100
Value Function Loss: 4.27323

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 8,751.94003
Overall Steps per Second: 7,570.82573

Timestep Collection Time: 5.71485
Timestep Consumption Time: 0.89157
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.60641

Cumulative Model Updates: 18,322
Cumulative Timesteps: 305,697,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 305697222...
Checkpoint 305697222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.93069
Policy Entropy: 1.12347
Value Function Loss: 4.21952

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.06076

Collected Steps per Second: 8,850.92844
Overall Steps per Second: 7,629.94303

Timestep Collection Time: 5.65025
Timestep Consumption Time: 0.90418
PPO Batch Consumption Time: 0.04948
Total Iteration Time: 6.55444

Cumulative Model Updates: 18,325
Cumulative Timesteps: 305,747,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.29554
Policy Entropy: 1.08098
Value Function Loss: 4.24175

Mean KL Divergence: 0.06283
SB3 Clip Fraction: 0.24058
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.05581

Collected Steps per Second: 8,979.94739
Overall Steps per Second: 7,795.97745

Timestep Collection Time: 5.56974
Timestep Consumption Time: 0.84587
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.41562

Cumulative Model Updates: 18,328
Cumulative Timesteps: 305,797,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 305797248...
Checkpoint 305797248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.92199
Policy Entropy: 1.11525
Value Function Loss: 4.14287

Mean KL Divergence: 0.04270
SB3 Clip Fraction: 0.21564
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.05685

Collected Steps per Second: 8,692.27123
Overall Steps per Second: 7,544.83560

Timestep Collection Time: 5.75270
Timestep Consumption Time: 0.87488
PPO Batch Consumption Time: 0.04729
Total Iteration Time: 6.62758

Cumulative Model Updates: 18,331
Cumulative Timesteps: 305,847,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.04355
Policy Entropy: 1.09801
Value Function Loss: 4.14496

Mean KL Divergence: 0.04891
SB3 Clip Fraction: 0.21447
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.04713

Collected Steps per Second: 8,621.49154
Overall Steps per Second: 7,575.92035

Timestep Collection Time: 5.80317
Timestep Consumption Time: 0.80091
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.60408

Cumulative Model Updates: 18,334
Cumulative Timesteps: 305,897,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 305897284...
Checkpoint 305897284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.67693
Policy Entropy: 1.12820
Value Function Loss: 4.19319

Mean KL Divergence: 0.04858
SB3 Clip Fraction: 0.20953
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.03992

Collected Steps per Second: 8,703.98114
Overall Steps per Second: 7,635.91067

Timestep Collection Time: 5.74611
Timestep Consumption Time: 0.80373
PPO Batch Consumption Time: 0.04223
Total Iteration Time: 6.54984

Cumulative Model Updates: 18,337
Cumulative Timesteps: 305,947,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.63463
Policy Entropy: 1.10637
Value Function Loss: 4.18312

Mean KL Divergence: 0.04283
SB3 Clip Fraction: 0.18851
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.04821

Collected Steps per Second: 8,661.41113
Overall Steps per Second: 7,539.35199

Timestep Collection Time: 5.77273
Timestep Consumption Time: 0.85914
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.63187

Cumulative Model Updates: 18,340
Cumulative Timesteps: 305,997,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 305997298...
Checkpoint 305997298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.15173
Policy Entropy: 1.12552
Value Function Loss: 4.02292

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 9,005.61409
Overall Steps per Second: 7,812.43789

Timestep Collection Time: 5.55387
Timestep Consumption Time: 0.84823
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.40210

Cumulative Model Updates: 18,343
Cumulative Timesteps: 306,047,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.63107
Policy Entropy: 1.10036
Value Function Loss: 3.79597

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 8,701.54848
Overall Steps per Second: 7,526.17409

Timestep Collection Time: 5.74656
Timestep Consumption Time: 0.89745
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.64401

Cumulative Model Updates: 18,346
Cumulative Timesteps: 306,097,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 306097318...
Checkpoint 306097318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.14775
Policy Entropy: 1.10973
Value Function Loss: 3.77561

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.08901

Collected Steps per Second: 8,724.55673
Overall Steps per Second: 7,683.67445

Timestep Collection Time: 5.73347
Timestep Consumption Time: 0.77669
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.51017

Cumulative Model Updates: 18,349
Cumulative Timesteps: 306,147,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.37110
Policy Entropy: 1.11513
Value Function Loss: 3.66677

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 8,792.96616
Overall Steps per Second: 7,630.35080

Timestep Collection Time: 5.68682
Timestep Consumption Time: 0.86648
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 6.55330

Cumulative Model Updates: 18,352
Cumulative Timesteps: 306,197,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 306197344...
Checkpoint 306197344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.40070
Policy Entropy: 1.12606
Value Function Loss: 3.66969

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 8,603.13522
Overall Steps per Second: 7,470.11737

Timestep Collection Time: 5.81555
Timestep Consumption Time: 0.88206
PPO Batch Consumption Time: 0.04820
Total Iteration Time: 6.69762

Cumulative Model Updates: 18,355
Cumulative Timesteps: 306,247,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.02966
Policy Entropy: 1.10136
Value Function Loss: 3.80461

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 9,163.15953
Overall Steps per Second: 7,873.43136

Timestep Collection Time: 5.45882
Timestep Consumption Time: 0.89420
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 6.35301

Cumulative Model Updates: 18,358
Cumulative Timesteps: 306,297,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 306297396...
Checkpoint 306297396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.55625
Policy Entropy: 1.11725
Value Function Loss: 3.92647

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.05498

Collected Steps per Second: 8,934.53500
Overall Steps per Second: 7,768.49445

Timestep Collection Time: 5.59872
Timestep Consumption Time: 0.84036
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.43909

Cumulative Model Updates: 18,361
Cumulative Timesteps: 306,347,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.33957
Policy Entropy: 1.11719
Value Function Loss: 4.02036

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.04802

Collected Steps per Second: 8,957.82841
Overall Steps per Second: 7,839.82026

Timestep Collection Time: 5.58350
Timestep Consumption Time: 0.79624
PPO Batch Consumption Time: 0.05116
Total Iteration Time: 6.37974

Cumulative Model Updates: 18,364
Cumulative Timesteps: 306,397,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 306397434...
Checkpoint 306397434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.04907
Policy Entropy: 1.11676
Value Function Loss: 3.89325

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.04289

Collected Steps per Second: 9,321.53404
Overall Steps per Second: 7,954.64295

Timestep Collection Time: 5.36435
Timestep Consumption Time: 0.92179
PPO Batch Consumption Time: 0.04702
Total Iteration Time: 6.28614

Cumulative Model Updates: 18,367
Cumulative Timesteps: 306,447,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.72236
Policy Entropy: 1.11134
Value Function Loss: 3.93053

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 8,942.67646
Overall Steps per Second: 7,725.63251

Timestep Collection Time: 5.59318
Timestep Consumption Time: 0.88111
PPO Batch Consumption Time: 0.04853
Total Iteration Time: 6.47429

Cumulative Model Updates: 18,370
Cumulative Timesteps: 306,497,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 306497456...
Checkpoint 306497456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.60574
Policy Entropy: 1.11877
Value Function Loss: 3.88665

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 8,977.58129
Overall Steps per Second: 7,789.43992

Timestep Collection Time: 5.56965
Timestep Consumption Time: 0.84955
PPO Batch Consumption Time: 0.05007
Total Iteration Time: 6.41920

Cumulative Model Updates: 18,373
Cumulative Timesteps: 306,547,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.68569
Policy Entropy: 1.12018
Value Function Loss: 3.95964

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.06656

Collected Steps per Second: 8,423.55222
Overall Steps per Second: 7,334.83130

Timestep Collection Time: 5.93882
Timestep Consumption Time: 0.88151
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.82033

Cumulative Model Updates: 18,376
Cumulative Timesteps: 306,597,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 306597484...
Checkpoint 306597484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.05187
Policy Entropy: 1.11380
Value Function Loss: 3.94569

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 8,788.86608
Overall Steps per Second: 7,772.39014

Timestep Collection Time: 5.69266
Timestep Consumption Time: 0.74449
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.43714

Cumulative Model Updates: 18,379
Cumulative Timesteps: 306,647,516

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.34775
Policy Entropy: 1.09616
Value Function Loss: 3.97042

Mean KL Divergence: 0.03448
SB3 Clip Fraction: 0.16408
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.06799

Collected Steps per Second: 8,992.43844
Overall Steps per Second: 7,815.01811

Timestep Collection Time: 5.56245
Timestep Consumption Time: 0.83805
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.40050

Cumulative Model Updates: 18,382
Cumulative Timesteps: 306,697,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 306697536...
Checkpoint 306697536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716.79564
Policy Entropy: 1.12909
Value Function Loss: 3.83240

Mean KL Divergence: 0.03011
SB3 Clip Fraction: 0.18057
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.06822

Collected Steps per Second: 8,979.83945
Overall Steps per Second: 7,782.44855

Timestep Collection Time: 5.56825
Timestep Consumption Time: 0.85672
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.42497

Cumulative Model Updates: 18,385
Cumulative Timesteps: 306,747,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.66329
Policy Entropy: 1.08954
Value Function Loss: 3.70457

Mean KL Divergence: 0.06327
SB3 Clip Fraction: 0.24586
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 8,718.68526
Overall Steps per Second: 7,597.04029

Timestep Collection Time: 5.73504
Timestep Consumption Time: 0.84673
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 6.58177

Cumulative Model Updates: 18,388
Cumulative Timesteps: 306,797,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 306797540...
Checkpoint 306797540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.78734
Policy Entropy: 1.12174
Value Function Loss: 3.97428

Mean KL Divergence: 0.04968
SB3 Clip Fraction: 0.24058
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 8,832.13516
Overall Steps per Second: 7,724.49340

Timestep Collection Time: 5.66386
Timestep Consumption Time: 0.81216
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.47602

Cumulative Model Updates: 18,391
Cumulative Timesteps: 306,847,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.08419
Policy Entropy: 1.10423
Value Function Loss: 3.94927

Mean KL Divergence: 0.04526
SB3 Clip Fraction: 0.21097
Policy Update Magnitude: 0.04193
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 8,937.94076
Overall Steps per Second: 7,907.17935

Timestep Collection Time: 5.59681
Timestep Consumption Time: 0.72959
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 6.32640

Cumulative Model Updates: 18,394
Cumulative Timesteps: 306,897,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 306897588...
Checkpoint 306897588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.23246
Policy Entropy: 1.12704
Value Function Loss: 4.04130

Mean KL Divergence: 0.03640
SB3 Clip Fraction: 0.19819
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.06416

Collected Steps per Second: 8,789.39557
Overall Steps per Second: 7,683.46225

Timestep Collection Time: 5.68958
Timestep Consumption Time: 0.81894
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.50852

Cumulative Model Updates: 18,397
Cumulative Timesteps: 306,947,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.37490
Policy Entropy: 1.09254
Value Function Loss: 3.79281

Mean KL Divergence: 0.03915
SB3 Clip Fraction: 0.21440
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 8,781.75511
Overall Steps per Second: 7,625.05995

Timestep Collection Time: 5.69681
Timestep Consumption Time: 0.86419
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.56100

Cumulative Model Updates: 18,400
Cumulative Timesteps: 306,997,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 306997624...
Checkpoint 306997624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.35699
Policy Entropy: 1.12421
Value Function Loss: 4.07530

Mean KL Divergence: 0.03004
SB3 Clip Fraction: 0.18299
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 8,766.90416
Overall Steps per Second: 7,687.59354

Timestep Collection Time: 5.70441
Timestep Consumption Time: 0.80088
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.50529

Cumulative Model Updates: 18,403
Cumulative Timesteps: 307,047,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.77172
Policy Entropy: 1.09698
Value Function Loss: 4.03488

Mean KL Divergence: 0.03117
SB3 Clip Fraction: 0.20011
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.05711

Collected Steps per Second: 8,881.74449
Overall Steps per Second: 7,768.57080

Timestep Collection Time: 5.62952
Timestep Consumption Time: 0.80667
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.43619

Cumulative Model Updates: 18,406
Cumulative Timesteps: 307,097,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 307097634...
Checkpoint 307097634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.70734
Policy Entropy: 1.12775
Value Function Loss: 4.45454

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.06251

Collected Steps per Second: 8,886.77043
Overall Steps per Second: 7,832.09168

Timestep Collection Time: 5.62882
Timestep Consumption Time: 0.75798
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.38680

Cumulative Model Updates: 18,409
Cumulative Timesteps: 307,147,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.85898
Policy Entropy: 1.12403
Value Function Loss: 4.36405

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 8,885.15360
Overall Steps per Second: 7,715.38040

Timestep Collection Time: 5.62872
Timestep Consumption Time: 0.85340
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 6.48212

Cumulative Model Updates: 18,412
Cumulative Timesteps: 307,197,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 307197668...
Checkpoint 307197668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.93525
Policy Entropy: 1.12403
Value Function Loss: 4.40459

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.06633

Collected Steps per Second: 8,946.75634
Overall Steps per Second: 7,654.48550

Timestep Collection Time: 5.59108
Timestep Consumption Time: 0.94392
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 6.53499

Cumulative Model Updates: 18,415
Cumulative Timesteps: 307,247,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.96090
Policy Entropy: 1.10309
Value Function Loss: 3.99078

Mean KL Divergence: 0.04191
SB3 Clip Fraction: 0.21917
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.05968

Collected Steps per Second: 9,230.46269
Overall Steps per Second: 8,055.82147

Timestep Collection Time: 5.41728
Timestep Consumption Time: 0.78991
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 6.20719

Cumulative Model Updates: 18,418
Cumulative Timesteps: 307,297,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 307297694...
Checkpoint 307297694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.89308
Policy Entropy: 1.13664
Value Function Loss: 3.98074

Mean KL Divergence: 0.03427
SB3 Clip Fraction: 0.20653
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 9,191.51375
Overall Steps per Second: 7,998.56633

Timestep Collection Time: 5.44198
Timestep Consumption Time: 0.81164
PPO Batch Consumption Time: 0.04742
Total Iteration Time: 6.25362

Cumulative Model Updates: 18,421
Cumulative Timesteps: 307,347,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.69521
Policy Entropy: 1.11411
Value Function Loss: 4.10454

Mean KL Divergence: 0.03426
SB3 Clip Fraction: 0.20938
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.05800

Collected Steps per Second: 8,859.07800
Overall Steps per Second: 7,812.19873

Timestep Collection Time: 5.64596
Timestep Consumption Time: 0.75659
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.40255

Cumulative Model Updates: 18,424
Cumulative Timesteps: 307,397,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 307397732...
Checkpoint 307397732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.18395
Policy Entropy: 1.14870
Value Function Loss: 4.25436

Mean KL Divergence: 0.04035
SB3 Clip Fraction: 0.22157
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 8,964.59822
Overall Steps per Second: 7,727.83211

Timestep Collection Time: 5.57950
Timestep Consumption Time: 0.89295
PPO Batch Consumption Time: 0.04784
Total Iteration Time: 6.47245

Cumulative Model Updates: 18,427
Cumulative Timesteps: 307,447,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.51828
Policy Entropy: 1.11120
Value Function Loss: 4.16994

Mean KL Divergence: 0.04696
SB3 Clip Fraction: 0.22247
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.06189

Collected Steps per Second: 8,711.62369
Overall Steps per Second: 7,616.92087

Timestep Collection Time: 5.74152
Timestep Consumption Time: 0.82517
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.56670

Cumulative Model Updates: 18,430
Cumulative Timesteps: 307,497,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 307497768...
Checkpoint 307497768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.04952
Policy Entropy: 1.13858
Value Function Loss: 4.11809

Mean KL Divergence: 0.03759
SB3 Clip Fraction: 0.20225
Policy Update Magnitude: 0.03979
Value Function Update Magnitude: 0.05850

Collected Steps per Second: 8,860.68264
Overall Steps per Second: 7,739.37960

Timestep Collection Time: 5.64584
Timestep Consumption Time: 0.81799
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 6.46383

Cumulative Model Updates: 18,433
Cumulative Timesteps: 307,547,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.94258
Policy Entropy: 1.11640
Value Function Loss: 4.09510

Mean KL Divergence: 0.03994
SB3 Clip Fraction: 0.18867
Policy Update Magnitude: 0.04077
Value Function Update Magnitude: 0.06807

Collected Steps per Second: 8,830.37994
Overall Steps per Second: 7,709.97570

Timestep Collection Time: 5.66521
Timestep Consumption Time: 0.82326
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.48848

Cumulative Model Updates: 18,436
Cumulative Timesteps: 307,597,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 307597820...
Checkpoint 307597820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.39121
Policy Entropy: 1.14507
Value Function Loss: 4.16005

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.06454

Collected Steps per Second: 8,903.85663
Overall Steps per Second: 7,862.42062

Timestep Collection Time: 5.61712
Timestep Consumption Time: 0.74403
PPO Batch Consumption Time: 0.04374
Total Iteration Time: 6.36115

Cumulative Model Updates: 18,439
Cumulative Timesteps: 307,647,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.96192
Policy Entropy: 1.12748
Value Function Loss: 4.25096

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 8,970.57906
Overall Steps per Second: 7,724.50763

Timestep Collection Time: 5.57556
Timestep Consumption Time: 0.89942
PPO Batch Consumption Time: 0.04571
Total Iteration Time: 6.47498

Cumulative Model Updates: 18,442
Cumulative Timesteps: 307,697,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 307697850...
Checkpoint 307697850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.66198
Policy Entropy: 1.13909
Value Function Loss: 4.08300

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.05168

Collected Steps per Second: 8,665.22466
Overall Steps per Second: 7,582.06386

Timestep Collection Time: 5.77181
Timestep Consumption Time: 0.82455
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.59636

Cumulative Model Updates: 18,445
Cumulative Timesteps: 307,747,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.01195
Policy Entropy: 1.13914
Value Function Loss: 4.12868

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 8,889.68910
Overall Steps per Second: 7,723.37038

Timestep Collection Time: 5.62742
Timestep Consumption Time: 0.84981
PPO Batch Consumption Time: 0.04862
Total Iteration Time: 6.47722

Cumulative Model Updates: 18,448
Cumulative Timesteps: 307,797,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 307797890...
Checkpoint 307797890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.78352
Policy Entropy: 1.12201
Value Function Loss: 3.98993

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.15963
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.07242

Collected Steps per Second: 8,857.28157
Overall Steps per Second: 7,683.30290

Timestep Collection Time: 5.64665
Timestep Consumption Time: 0.86279
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.50944

Cumulative Model Updates: 18,451
Cumulative Timesteps: 307,847,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.10222
Policy Entropy: 1.14190
Value Function Loss: 4.36349

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.06748

Collected Steps per Second: 8,844.61333
Overall Steps per Second: 7,797.63777

Timestep Collection Time: 5.65587
Timestep Consumption Time: 0.75940
PPO Batch Consumption Time: 0.04783
Total Iteration Time: 6.41528

Cumulative Model Updates: 18,454
Cumulative Timesteps: 307,897,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 307897928...
Checkpoint 307897928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.14816
Policy Entropy: 1.13747
Value Function Loss: 4.37996

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.06859

Collected Steps per Second: 8,592.24107
Overall Steps per Second: 7,427.95703

Timestep Collection Time: 5.82200
Timestep Consumption Time: 0.91256
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.73456

Cumulative Model Updates: 18,457
Cumulative Timesteps: 307,947,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.38152
Policy Entropy: 1.13095
Value Function Loss: 4.42622

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.08650

Collected Steps per Second: 8,921.25855
Overall Steps per Second: 7,754.57916

Timestep Collection Time: 5.60728
Timestep Consumption Time: 0.84362
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.45090

Cumulative Model Updates: 18,460
Cumulative Timesteps: 307,997,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 307997976...
Checkpoint 307997976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.77837
Policy Entropy: 1.13326
Value Function Loss: 4.09570

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 8,743.30364
Overall Steps per Second: 7,575.78672

Timestep Collection Time: 5.72164
Timestep Consumption Time: 0.88177
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.60341

Cumulative Model Updates: 18,463
Cumulative Timesteps: 308,048,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.88504
Policy Entropy: 1.13848
Value Function Loss: 4.01971

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 8,876.65621
Overall Steps per Second: 7,744.82529

Timestep Collection Time: 5.63365
Timestep Consumption Time: 0.82330
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.45696

Cumulative Model Updates: 18,466
Cumulative Timesteps: 308,098,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 308098010...
Checkpoint 308098010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.95700
Policy Entropy: 1.14716
Value Function Loss: 3.94493

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.09273

Collected Steps per Second: 9,200.46241
Overall Steps per Second: 7,982.18372

Timestep Collection Time: 5.43625
Timestep Consumption Time: 0.82971
PPO Batch Consumption Time: 0.04997
Total Iteration Time: 6.26595

Cumulative Model Updates: 18,469
Cumulative Timesteps: 308,148,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.38488
Policy Entropy: 1.13916
Value Function Loss: 3.78316

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 8,608.53765
Overall Steps per Second: 7,515.53289

Timestep Collection Time: 5.80981
Timestep Consumption Time: 0.84494
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 6.65475

Cumulative Model Updates: 18,472
Cumulative Timesteps: 308,198,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 308198040...
Checkpoint 308198040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.61295
Policy Entropy: 1.14981
Value Function Loss: 3.84070

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 8,929.54636
Overall Steps per Second: 7,720.26662

Timestep Collection Time: 5.60297
Timestep Consumption Time: 0.87763
PPO Batch Consumption Time: 0.04838
Total Iteration Time: 6.48061

Cumulative Model Updates: 18,475
Cumulative Timesteps: 308,248,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.92077
Policy Entropy: 1.14765
Value Function Loss: 3.90071

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 9,236.46088
Overall Steps per Second: 7,933.43816

Timestep Collection Time: 5.41636
Timestep Consumption Time: 0.88961
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 6.30597

Cumulative Model Updates: 18,478
Cumulative Timesteps: 308,298,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 308298100...
Checkpoint 308298100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.25842
Policy Entropy: 1.15436
Value Function Loss: 3.99074

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 9,371.46380
Overall Steps per Second: 8,074.56675

Timestep Collection Time: 5.33535
Timestep Consumption Time: 0.85694
PPO Batch Consumption Time: 0.04785
Total Iteration Time: 6.19228

Cumulative Model Updates: 18,481
Cumulative Timesteps: 308,348,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.82099
Policy Entropy: 1.13688
Value Function Loss: 4.00307

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.07946
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 8,990.44729
Overall Steps per Second: 7,919.65591

Timestep Collection Time: 5.56391
Timestep Consumption Time: 0.75228
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 6.31618

Cumulative Model Updates: 18,484
Cumulative Timesteps: 308,398,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 308398122...
Checkpoint 308398122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.32092
Policy Entropy: 1.15096
Value Function Loss: 3.98983

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.07507

Collected Steps per Second: 8,649.99584
Overall Steps per Second: 7,492.83174

Timestep Collection Time: 5.78197
Timestep Consumption Time: 0.89294
PPO Batch Consumption Time: 0.05138
Total Iteration Time: 6.67491

Cumulative Model Updates: 18,487
Cumulative Timesteps: 308,448,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.98669
Policy Entropy: 1.14921
Value Function Loss: 3.97999

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.07408

Collected Steps per Second: 8,978.65631
Overall Steps per Second: 7,822.93370

Timestep Collection Time: 5.57099
Timestep Consumption Time: 0.82303
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.39402

Cumulative Model Updates: 18,490
Cumulative Timesteps: 308,498,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 308498156...
Checkpoint 308498156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.42001
Policy Entropy: 1.14901
Value Function Loss: 4.00418

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.06519
Value Function Update Magnitude: 0.06215

Collected Steps per Second: 8,973.21374
Overall Steps per Second: 7,792.69092

Timestep Collection Time: 5.57281
Timestep Consumption Time: 0.84423
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 6.41704

Cumulative Model Updates: 18,493
Cumulative Timesteps: 308,548,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.75403
Policy Entropy: 1.12452
Value Function Loss: 4.04072

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 8,949.83758
Overall Steps per Second: 7,739.05545

Timestep Collection Time: 5.58781
Timestep Consumption Time: 0.87422
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.46203

Cumulative Model Updates: 18,496
Cumulative Timesteps: 308,598,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 308598172...
Checkpoint 308598172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.21029
Policy Entropy: 1.11849
Value Function Loss: 4.17539

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 8,494.78432
Overall Steps per Second: 7,547.28776

Timestep Collection Time: 5.88950
Timestep Consumption Time: 0.73938
PPO Batch Consumption Time: 0.04425
Total Iteration Time: 6.62887

Cumulative Model Updates: 18,499
Cumulative Timesteps: 308,648,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.16306
Policy Entropy: 1.12876
Value Function Loss: 4.07151

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.05900

Collected Steps per Second: 8,993.04932
Overall Steps per Second: 7,796.85856

Timestep Collection Time: 5.56029
Timestep Consumption Time: 0.85306
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.41335

Cumulative Model Updates: 18,502
Cumulative Timesteps: 308,698,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 308698206...
Checkpoint 308698206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.22804
Policy Entropy: 1.13786
Value Function Loss: 3.98105

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 8,682.01075
Overall Steps per Second: 7,624.53372

Timestep Collection Time: 5.76180
Timestep Consumption Time: 0.79913
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 6.56093

Cumulative Model Updates: 18,505
Cumulative Timesteps: 308,748,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.30889
Policy Entropy: 1.12609
Value Function Loss: 3.86399

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.05574

Collected Steps per Second: 8,984.55229
Overall Steps per Second: 7,821.97356

Timestep Collection Time: 5.56644
Timestep Consumption Time: 0.82734
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.39378

Cumulative Model Updates: 18,508
Cumulative Timesteps: 308,798,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 308798242...
Checkpoint 308798242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.87112
Policy Entropy: 1.10808
Value Function Loss: 4.01327

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.16373
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.06891

Collected Steps per Second: 8,791.14975
Overall Steps per Second: 7,689.81619

Timestep Collection Time: 5.68754
Timestep Consumption Time: 0.81457
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.50211

Cumulative Model Updates: 18,511
Cumulative Timesteps: 308,848,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.22653
Policy Entropy: 1.11794
Value Function Loss: 3.84367

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.07580

Collected Steps per Second: 8,521.74746
Overall Steps per Second: 7,548.99043

Timestep Collection Time: 5.87110
Timestep Consumption Time: 0.75654
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.62764

Cumulative Model Updates: 18,514
Cumulative Timesteps: 308,898,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 308898274...
Checkpoint 308898274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.31647
Policy Entropy: 1.11976
Value Function Loss: 3.88217

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 8,818.88200
Overall Steps per Second: 7,672.61626

Timestep Collection Time: 5.67147
Timestep Consumption Time: 0.84730
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 6.51877

Cumulative Model Updates: 18,517
Cumulative Timesteps: 308,948,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.36004
Policy Entropy: 1.11353
Value Function Loss: 3.68342

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.07133

Collected Steps per Second: 8,810.39528
Overall Steps per Second: 7,680.22122

Timestep Collection Time: 5.67648
Timestep Consumption Time: 0.83532
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.51179

Cumulative Model Updates: 18,520
Cumulative Timesteps: 308,998,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 308998302...
Checkpoint 308998302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.53494
Policy Entropy: 1.10275
Value Function Loss: 3.83335

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.06203

Collected Steps per Second: 9,252.03126
Overall Steps per Second: 7,973.54882

Timestep Collection Time: 5.40465
Timestep Consumption Time: 0.86658
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 6.27124

Cumulative Model Updates: 18,523
Cumulative Timesteps: 309,048,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.36527
Policy Entropy: 1.11916
Value Function Loss: 3.84547

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.05678

Collected Steps per Second: 8,897.73919
Overall Steps per Second: 7,589.27700

Timestep Collection Time: 5.62120
Timestep Consumption Time: 0.96915
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.59035

Cumulative Model Updates: 18,526
Cumulative Timesteps: 309,098,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 309098322...
Checkpoint 309098322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.85112
Policy Entropy: 1.11555
Value Function Loss: 3.86483

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.05441

Collected Steps per Second: 9,040.55669
Overall Steps per Second: 7,948.07411

Timestep Collection Time: 5.53174
Timestep Consumption Time: 0.76035
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.29209

Cumulative Model Updates: 18,529
Cumulative Timesteps: 309,148,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.77112
Policy Entropy: 1.11125
Value Function Loss: 3.86046

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.05378

Collected Steps per Second: 8,846.21146
Overall Steps per Second: 7,698.49429

Timestep Collection Time: 5.65530
Timestep Consumption Time: 0.84311
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.49841

Cumulative Model Updates: 18,532
Cumulative Timesteps: 309,198,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 309198360...
Checkpoint 309198360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.17952
Policy Entropy: 1.10054
Value Function Loss: 3.87830

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.05546

Collected Steps per Second: 9,101.17373
Overall Steps per Second: 7,928.53208

Timestep Collection Time: 5.49380
Timestep Consumption Time: 0.81254
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.30634

Cumulative Model Updates: 18,535
Cumulative Timesteps: 309,248,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.63861
Policy Entropy: 1.10483
Value Function Loss: 3.98932

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 9,084.84129
Overall Steps per Second: 7,801.22770

Timestep Collection Time: 5.50521
Timestep Consumption Time: 0.90583
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 6.41104

Cumulative Model Updates: 18,538
Cumulative Timesteps: 309,298,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 309298374...
Checkpoint 309298374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.76780
Policy Entropy: 1.10895
Value Function Loss: 3.93877

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 8,886.36789
Overall Steps per Second: 7,736.66427

Timestep Collection Time: 5.62705
Timestep Consumption Time: 0.83620
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.46325

Cumulative Model Updates: 18,541
Cumulative Timesteps: 309,348,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.09273
Policy Entropy: 1.08729
Value Function Loss: 3.94225

Mean KL Divergence: 0.03761
SB3 Clip Fraction: 0.18573
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 8,867.74440
Overall Steps per Second: 7,815.04561

Timestep Collection Time: 5.64089
Timestep Consumption Time: 0.75984
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.40073

Cumulative Model Updates: 18,544
Cumulative Timesteps: 309,398,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 309398400...
Checkpoint 309398400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.35948
Policy Entropy: 1.12672
Value Function Loss: 3.91690

Mean KL Divergence: 0.03331
SB3 Clip Fraction: 0.20531
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.07740

Collected Steps per Second: 8,770.97983
Overall Steps per Second: 7,619.00154

Timestep Collection Time: 5.70176
Timestep Consumption Time: 0.86209
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 6.56385

Cumulative Model Updates: 18,547
Cumulative Timesteps: 309,448,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.01689
Policy Entropy: 1.11120
Value Function Loss: 3.99119

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.14532
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.08304

Collected Steps per Second: 9,031.10886
Overall Steps per Second: 7,758.96528

Timestep Collection Time: 5.53797
Timestep Consumption Time: 0.90799
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.44596

Cumulative Model Updates: 18,550
Cumulative Timesteps: 309,498,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 309498424...
Checkpoint 309498424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.52497
Policy Entropy: 1.13194
Value Function Loss: 3.91403

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.07221

Collected Steps per Second: 9,014.42627
Overall Steps per Second: 7,821.49356

Timestep Collection Time: 5.54866
Timestep Consumption Time: 0.84628
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 6.39494

Cumulative Model Updates: 18,553
Cumulative Timesteps: 309,548,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.47700
Policy Entropy: 1.13141
Value Function Loss: 3.90703

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 8,309.76110
Overall Steps per Second: 7,278.03531

Timestep Collection Time: 6.01895
Timestep Consumption Time: 0.85324
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.87218

Cumulative Model Updates: 18,556
Cumulative Timesteps: 309,598,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 309598458...
Checkpoint 309598458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.14640
Policy Entropy: 1.12922
Value Function Loss: 3.84530

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.06233

Collected Steps per Second: 8,541.10284
Overall Steps per Second: 7,532.80003

Timestep Collection Time: 5.85685
Timestep Consumption Time: 0.78397
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.64082

Cumulative Model Updates: 18,559
Cumulative Timesteps: 309,648,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.21915
Policy Entropy: 1.11772
Value Function Loss: 3.96938

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.06671
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 8,902.82618
Overall Steps per Second: 7,710.55229

Timestep Collection Time: 5.61754
Timestep Consumption Time: 0.86863
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 6.48618

Cumulative Model Updates: 18,562
Cumulative Timesteps: 309,698,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 309698494...
Checkpoint 309698494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.87122
Policy Entropy: 1.11368
Value Function Loss: 3.98503

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 8,850.04933
Overall Steps per Second: 7,744.05996

Timestep Collection Time: 5.65014
Timestep Consumption Time: 0.80694
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.45708

Cumulative Model Updates: 18,565
Cumulative Timesteps: 309,748,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.59152
Policy Entropy: 1.12323
Value Function Loss: 4.09043

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.03859

Collected Steps per Second: 8,851.13271
Overall Steps per Second: 7,657.66226

Timestep Collection Time: 5.65125
Timestep Consumption Time: 0.88077
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.53202

Cumulative Model Updates: 18,568
Cumulative Timesteps: 309,798,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 309798518...
Checkpoint 309798518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.85023
Policy Entropy: 1.12863
Value Function Loss: 4.04512

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.04745

Collected Steps per Second: 8,807.25182
Overall Steps per Second: 7,666.92922

Timestep Collection Time: 5.68055
Timestep Consumption Time: 0.84488
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.52543

Cumulative Model Updates: 18,571
Cumulative Timesteps: 309,848,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.77334
Policy Entropy: 1.13233
Value Function Loss: 3.85874

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.04722

Collected Steps per Second: 8,771.50011
Overall Steps per Second: 7,717.05025

Timestep Collection Time: 5.70347
Timestep Consumption Time: 0.77932
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.48279

Cumulative Model Updates: 18,574
Cumulative Timesteps: 309,898,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 309898576...
Checkpoint 309898576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.97750
Policy Entropy: 1.13273
Value Function Loss: 3.81766

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.07102
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 8,697.13078
Overall Steps per Second: 7,576.62323

Timestep Collection Time: 5.74925
Timestep Consumption Time: 0.85026
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.59951

Cumulative Model Updates: 18,577
Cumulative Timesteps: 309,948,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.08467
Policy Entropy: 1.14967
Value Function Loss: 3.88383

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 8,875.87756
Overall Steps per Second: 7,756.83017

Timestep Collection Time: 5.63550
Timestep Consumption Time: 0.81301
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.44851

Cumulative Model Updates: 18,580
Cumulative Timesteps: 309,998,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 309998598...
Checkpoint 309998598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.04634
Policy Entropy: 1.13692
Value Function Loss: 4.05238

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.06357

Collected Steps per Second: 9,048.45368
Overall Steps per Second: 7,786.77707

Timestep Collection Time: 5.52757
Timestep Consumption Time: 0.89562
PPO Batch Consumption Time: 0.04781
Total Iteration Time: 6.42320

Cumulative Model Updates: 18,583
Cumulative Timesteps: 310,048,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.58125
Policy Entropy: 1.13898
Value Function Loss: 4.03834

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.06211

Collected Steps per Second: 9,075.26181
Overall Steps per Second: 7,801.47442

Timestep Collection Time: 5.51191
Timestep Consumption Time: 0.89996
PPO Batch Consumption Time: 0.04924
Total Iteration Time: 6.41186

Cumulative Model Updates: 18,586
Cumulative Timesteps: 310,098,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 310098636...
Checkpoint 310098636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.53092
Policy Entropy: 1.14399
Value Function Loss: 3.97844

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.08428

Collected Steps per Second: 9,219.22525
Overall Steps per Second: 8,015.14064

Timestep Collection Time: 5.42562
Timestep Consumption Time: 0.81507
PPO Batch Consumption Time: 0.05274
Total Iteration Time: 6.24069

Cumulative Model Updates: 18,589
Cumulative Timesteps: 310,148,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.00971
Policy Entropy: 1.14553
Value Function Loss: 4.13158

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 9,025.87345
Overall Steps per Second: 7,769.02498

Timestep Collection Time: 5.54074
Timestep Consumption Time: 0.89636
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.43710

Cumulative Model Updates: 18,592
Cumulative Timesteps: 310,198,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 310198666...
Checkpoint 310198666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.76814
Policy Entropy: 1.14192
Value Function Loss: 4.25796

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 8,872.09142
Overall Steps per Second: 7,605.80102

Timestep Collection Time: 5.63588
Timestep Consumption Time: 0.93832
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.57419

Cumulative Model Updates: 18,595
Cumulative Timesteps: 310,248,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.40575
Policy Entropy: 1.14349
Value Function Loss: 4.28084

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.07035

Collected Steps per Second: 8,443.44914
Overall Steps per Second: 7,496.51510

Timestep Collection Time: 5.92175
Timestep Consumption Time: 0.74802
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.66977

Cumulative Model Updates: 18,598
Cumulative Timesteps: 310,298,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 310298668...
Checkpoint 310298668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.53018
Policy Entropy: 1.15300
Value Function Loss: 4.14917

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.06503

Collected Steps per Second: 8,697.73090
Overall Steps per Second: 7,591.98591

Timestep Collection Time: 5.75184
Timestep Consumption Time: 0.83774
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.58958

Cumulative Model Updates: 18,601
Cumulative Timesteps: 310,348,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.24408
Policy Entropy: 1.16121
Value Function Loss: 4.15568

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.05700

Collected Steps per Second: 8,814.39357
Overall Steps per Second: 7,690.14500

Timestep Collection Time: 5.67413
Timestep Consumption Time: 0.82952
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.50365

Cumulative Model Updates: 18,604
Cumulative Timesteps: 310,398,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 310398710...
Checkpoint 310398710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.19742
Policy Entropy: 1.14111
Value Function Loss: 4.12804

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 8,939.52475
Overall Steps per Second: 7,743.43509

Timestep Collection Time: 5.59582
Timestep Consumption Time: 0.86436
PPO Batch Consumption Time: 0.04609
Total Iteration Time: 6.46018

Cumulative Model Updates: 18,607
Cumulative Timesteps: 310,448,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.05120
Policy Entropy: 1.13548
Value Function Loss: 4.08760

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.08838

Collected Steps per Second: 8,696.24490
Overall Steps per Second: 7,559.87252

Timestep Collection Time: 5.75237
Timestep Consumption Time: 0.86467
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.61704

Cumulative Model Updates: 18,610
Cumulative Timesteps: 310,498,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 310498758...
Checkpoint 310498758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.32138
Policy Entropy: 1.13635
Value Function Loss: 4.00732

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.09378

Collected Steps per Second: 8,947.57775
Overall Steps per Second: 7,920.13326

Timestep Collection Time: 5.59034
Timestep Consumption Time: 0.72521
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.31555

Cumulative Model Updates: 18,613
Cumulative Timesteps: 310,548,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.07004
Policy Entropy: 1.15041
Value Function Loss: 4.08377

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 8,658.63905
Overall Steps per Second: 7,513.95328

Timestep Collection Time: 5.77527
Timestep Consumption Time: 0.87981
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 6.65509

Cumulative Model Updates: 18,616
Cumulative Timesteps: 310,598,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 310598784...
Checkpoint 310598784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.73844
Policy Entropy: 1.11956
Value Function Loss: 4.01087

Mean KL Divergence: 0.04637
SB3 Clip Fraction: 0.17445
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.06927

Collected Steps per Second: 8,828.64309
Overall Steps per Second: 7,735.68788

Timestep Collection Time: 5.66497
Timestep Consumption Time: 0.80039
PPO Batch Consumption Time: 0.04002
Total Iteration Time: 6.46536

Cumulative Model Updates: 18,619
Cumulative Timesteps: 310,648,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.05799
Policy Entropy: 1.14192
Value Function Loss: 3.83362

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.16348
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.06209

Collected Steps per Second: 8,685.01586
Overall Steps per Second: 7,672.44950

Timestep Collection Time: 5.76050
Timestep Consumption Time: 0.76024
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 6.52073

Cumulative Model Updates: 18,622
Cumulative Timesteps: 310,698,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 310698828...
Checkpoint 310698828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.61119
Policy Entropy: 1.12519
Value Function Loss: 3.71291

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 8,627.63430
Overall Steps per Second: 7,551.94616

Timestep Collection Time: 5.79881
Timestep Consumption Time: 0.82597
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.62478

Cumulative Model Updates: 18,625
Cumulative Timesteps: 310,748,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.36640
Policy Entropy: 1.13679
Value Function Loss: 3.84484

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.05734

Collected Steps per Second: 8,635.70954
Overall Steps per Second: 7,540.77273

Timestep Collection Time: 5.78991
Timestep Consumption Time: 0.84071
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 6.63062

Cumulative Model Updates: 18,628
Cumulative Timesteps: 310,798,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 310798858...
Checkpoint 310798858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.13580
Policy Entropy: 1.14224
Value Function Loss: 4.08321

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.07418

Collected Steps per Second: 8,714.68107
Overall Steps per Second: 7,593.40775

Timestep Collection Time: 5.73928
Timestep Consumption Time: 0.84749
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.58677

Cumulative Model Updates: 18,631
Cumulative Timesteps: 310,848,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.38123
Policy Entropy: 1.15161
Value Function Loss: 4.37748

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 9,124.95711
Overall Steps per Second: 7,942.92754

Timestep Collection Time: 5.48167
Timestep Consumption Time: 0.81576
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 6.29743

Cumulative Model Updates: 18,634
Cumulative Timesteps: 310,898,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 310898894...
Checkpoint 310898894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.37952
Policy Entropy: 1.15108
Value Function Loss: 4.27607

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 8,491.01018
Overall Steps per Second: 7,445.40642

Timestep Collection Time: 5.89047
Timestep Consumption Time: 0.82723
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 6.71770

Cumulative Model Updates: 18,637
Cumulative Timesteps: 310,948,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.99885
Policy Entropy: 1.14700
Value Function Loss: 4.23042

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 8,928.96921
Overall Steps per Second: 7,775.86918

Timestep Collection Time: 5.60244
Timestep Consumption Time: 0.83080
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.43324

Cumulative Model Updates: 18,640
Cumulative Timesteps: 310,998,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 310998934...
Checkpoint 310998934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.30536
Policy Entropy: 1.13722
Value Function Loss: 4.14860

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 8,812.31927
Overall Steps per Second: 7,730.73102

Timestep Collection Time: 5.67501
Timestep Consumption Time: 0.79398
PPO Batch Consumption Time: 0.04801
Total Iteration Time: 6.46899

Cumulative Model Updates: 18,643
Cumulative Timesteps: 311,048,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.03755
Policy Entropy: 1.14913
Value Function Loss: 4.36668

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 9,069.82786
Overall Steps per Second: 7,840.52258

Timestep Collection Time: 5.51499
Timestep Consumption Time: 0.86469
PPO Batch Consumption Time: 0.04810
Total Iteration Time: 6.37968

Cumulative Model Updates: 18,646
Cumulative Timesteps: 311,098,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 311098964...
Checkpoint 311098964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.12706
Policy Entropy: 1.14847
Value Function Loss: 4.54253

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 9,047.66506
Overall Steps per Second: 7,973.03896

Timestep Collection Time: 5.52806
Timestep Consumption Time: 0.74509
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.27314

Cumulative Model Updates: 18,649
Cumulative Timesteps: 311,148,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.43107
Policy Entropy: 1.15313
Value Function Loss: 4.36391

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 8,498.57129
Overall Steps per Second: 7,407.45678

Timestep Collection Time: 5.88452
Timestep Consumption Time: 0.86679
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.75130

Cumulative Model Updates: 18,652
Cumulative Timesteps: 311,198,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 311198990...
Checkpoint 311198990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.26269
Policy Entropy: 1.14866
Value Function Loss: 4.19039

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.08150

Collected Steps per Second: 8,718.75640
Overall Steps per Second: 7,412.02052

Timestep Collection Time: 5.73752
Timestep Consumption Time: 1.01152
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 6.74904

Cumulative Model Updates: 18,655
Cumulative Timesteps: 311,249,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.51175
Policy Entropy: 1.14704
Value Function Loss: 3.91292

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.07733
Value Function Update Magnitude: 0.07855

Collected Steps per Second: 8,694.36517
Overall Steps per Second: 7,556.78046

Timestep Collection Time: 5.75384
Timestep Consumption Time: 0.86617
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 6.62002

Cumulative Model Updates: 18,658
Cumulative Timesteps: 311,299,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 311299040...
Checkpoint 311299040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.22595
Policy Entropy: 1.14979
Value Function Loss: 4.01958

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.07642
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 8,914.57970
Overall Steps per Second: 7,718.73986

Timestep Collection Time: 5.61103
Timestep Consumption Time: 0.86930
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.48033

Cumulative Model Updates: 18,661
Cumulative Timesteps: 311,349,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.92906
Policy Entropy: 1.14378
Value Function Loss: 3.99002

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.08635
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 8,841.59039
Overall Steps per Second: 7,688.12488

Timestep Collection Time: 5.65509
Timestep Consumption Time: 0.84845
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.50354

Cumulative Model Updates: 18,664
Cumulative Timesteps: 311,399,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 311399060...
Checkpoint 311399060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.10385
Policy Entropy: 1.14472
Value Function Loss: 4.19282

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.08700
Value Function Update Magnitude: 0.06173

Collected Steps per Second: 8,833.63556
Overall Steps per Second: 7,606.84802

Timestep Collection Time: 5.66335
Timestep Consumption Time: 0.91335
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.57671

Cumulative Model Updates: 18,667
Cumulative Timesteps: 311,449,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.86958
Policy Entropy: 1.13925
Value Function Loss: 4.23264

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.07941
Value Function Update Magnitude: 0.06489

Collected Steps per Second: 8,760.91916
Overall Steps per Second: 7,570.04986

Timestep Collection Time: 5.70922
Timestep Consumption Time: 0.89814
PPO Batch Consumption Time: 0.04454
Total Iteration Time: 6.60735

Cumulative Model Updates: 18,670
Cumulative Timesteps: 311,499,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 311499106...
Checkpoint 311499106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.97512
Policy Entropy: 1.14865
Value Function Loss: 4.26186

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 8,817.26949
Overall Steps per Second: 7,687.19829

Timestep Collection Time: 5.67250
Timestep Consumption Time: 0.83390
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.50640

Cumulative Model Updates: 18,673
Cumulative Timesteps: 311,549,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.13475
Policy Entropy: 1.15533
Value Function Loss: 3.93698

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.05435

Collected Steps per Second: 8,777.23728
Overall Steps per Second: 7,691.01885

Timestep Collection Time: 5.69838
Timestep Consumption Time: 0.80479
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.50317

Cumulative Model Updates: 18,676
Cumulative Timesteps: 311,599,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 311599138...
Checkpoint 311599138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.88203
Policy Entropy: 1.13961
Value Function Loss: 3.87685

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.05696

Collected Steps per Second: 8,767.31898
Overall Steps per Second: 7,562.24627

Timestep Collection Time: 5.70528
Timestep Consumption Time: 0.90916
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.61444

Cumulative Model Updates: 18,679
Cumulative Timesteps: 311,649,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.77696
Policy Entropy: 1.12563
Value Function Loss: 3.89634

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 8,707.47344
Overall Steps per Second: 7,522.48443

Timestep Collection Time: 5.74403
Timestep Consumption Time: 0.90484
PPO Batch Consumption Time: 0.04742
Total Iteration Time: 6.64887

Cumulative Model Updates: 18,682
Cumulative Timesteps: 311,699,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 311699174...
Checkpoint 311699174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.98618
Policy Entropy: 1.13481
Value Function Loss: 3.97167

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.05758

Collected Steps per Second: 8,606.37945
Overall Steps per Second: 7,601.77961

Timestep Collection Time: 5.80988
Timestep Consumption Time: 0.76779
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.57767

Cumulative Model Updates: 18,685
Cumulative Timesteps: 311,749,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.84181
Policy Entropy: 1.14571
Value Function Loss: 3.86644

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.05623

Collected Steps per Second: 8,993.71280
Overall Steps per Second: 7,778.55611

Timestep Collection Time: 5.56100
Timestep Consumption Time: 0.86873
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.42973

Cumulative Model Updates: 18,688
Cumulative Timesteps: 311,799,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 311799190...
Checkpoint 311799190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.64219
Policy Entropy: 1.13664
Value Function Loss: 3.79465

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.06409

Collected Steps per Second: 8,840.46555
Overall Steps per Second: 7,553.11991

Timestep Collection Time: 5.65694
Timestep Consumption Time: 0.96416
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 6.62111

Cumulative Model Updates: 18,691
Cumulative Timesteps: 311,849,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.77593
Policy Entropy: 1.13540
Value Function Loss: 4.03049

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 8,870.59582
Overall Steps per Second: 7,607.76254

Timestep Collection Time: 5.63818
Timestep Consumption Time: 0.93590
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 6.57407

Cumulative Model Updates: 18,694
Cumulative Timesteps: 311,899,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 311899214...
Checkpoint 311899214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.49412
Policy Entropy: 1.14149
Value Function Loss: 4.12272

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06092

Collected Steps per Second: 9,446.18760
Overall Steps per Second: 8,134.78849

Timestep Collection Time: 5.29568
Timestep Consumption Time: 0.85371
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.14939

Cumulative Model Updates: 18,697
Cumulative Timesteps: 311,949,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.49015
Policy Entropy: 1.13870
Value Function Loss: 4.20313

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.05927

Collected Steps per Second: 9,586.97576
Overall Steps per Second: 8,260.66365

Timestep Collection Time: 5.21624
Timestep Consumption Time: 0.83751
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.05375

Cumulative Model Updates: 18,700
Cumulative Timesteps: 311,999,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 311999246...
Checkpoint 311999246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.60564
Policy Entropy: 1.13024
Value Function Loss: 4.03150

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 9,078.73372
Overall Steps per Second: 7,800.21995

Timestep Collection Time: 5.51090
Timestep Consumption Time: 0.90328
PPO Batch Consumption Time: 0.04758
Total Iteration Time: 6.41418

Cumulative Model Updates: 18,703
Cumulative Timesteps: 312,049,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.62940
Policy Entropy: 1.12413
Value Function Loss: 4.01738

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.05213

Collected Steps per Second: 8,735.04037
Overall Steps per Second: 7,687.12314

Timestep Collection Time: 5.72407
Timestep Consumption Time: 0.78031
PPO Batch Consumption Time: 0.04706
Total Iteration Time: 6.50438

Cumulative Model Updates: 18,706
Cumulative Timesteps: 312,099,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 312099278...
Checkpoint 312099278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.46117
Policy Entropy: 1.10649
Value Function Loss: 4.01647

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.15979
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 8,867.77290
Overall Steps per Second: 7,686.65141

Timestep Collection Time: 5.64042
Timestep Consumption Time: 0.86670
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 6.50712

Cumulative Model Updates: 18,709
Cumulative Timesteps: 312,149,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.10843
Policy Entropy: 1.11932
Value Function Loss: 3.92438

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 8,809.47095
Overall Steps per Second: 7,684.37905

Timestep Collection Time: 5.67866
Timestep Consumption Time: 0.83143
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.51009

Cumulative Model Updates: 18,712
Cumulative Timesteps: 312,199,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 312199322...
Checkpoint 312199322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.08597
Policy Entropy: 1.12276
Value Function Loss: 4.09568

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.05707

Collected Steps per Second: 8,962.79407
Overall Steps per Second: 7,790.99537

Timestep Collection Time: 5.58152
Timestep Consumption Time: 0.83948
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.42100

Cumulative Model Updates: 18,715
Cumulative Timesteps: 312,249,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.83855
Policy Entropy: 1.11486
Value Function Loss: 3.96388

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 8,855.72312
Overall Steps per Second: 7,761.99246

Timestep Collection Time: 5.64810
Timestep Consumption Time: 0.79587
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.44396

Cumulative Model Updates: 18,718
Cumulative Timesteps: 312,299,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 312299366...
Checkpoint 312299366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.78695
Policy Entropy: 1.10376
Value Function Loss: 4.00280

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 8,655.56995
Overall Steps per Second: 7,677.05893

Timestep Collection Time: 5.77801
Timestep Consumption Time: 0.73646
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.51447

Cumulative Model Updates: 18,721
Cumulative Timesteps: 312,349,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.87481
Policy Entropy: 1.10874
Value Function Loss: 3.95718

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 8,994.16749
Overall Steps per Second: 7,811.26050

Timestep Collection Time: 5.56049
Timestep Consumption Time: 0.84206
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 6.40255

Cumulative Model Updates: 18,724
Cumulative Timesteps: 312,399,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 312399390...
Checkpoint 312399390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.31273
Policy Entropy: 1.12002
Value Function Loss: 3.98988

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.05411

Collected Steps per Second: 8,974.82301
Overall Steps per Second: 7,798.84523

Timestep Collection Time: 5.57404
Timestep Consumption Time: 0.84050
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 6.41454

Cumulative Model Updates: 18,727
Cumulative Timesteps: 312,449,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.36642
Policy Entropy: 1.08857
Value Function Loss: 3.92601

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.04313

Collected Steps per Second: 9,161.77003
Overall Steps per Second: 7,964.28363

Timestep Collection Time: 5.45899
Timestep Consumption Time: 0.82080
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.27979

Cumulative Model Updates: 18,730
Cumulative Timesteps: 312,499,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 312499430...
Checkpoint 312499430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.15543
Policy Entropy: 1.11093
Value Function Loss: 3.96959

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 8,743.95946
Overall Steps per Second: 7,471.74321

Timestep Collection Time: 5.71915
Timestep Consumption Time: 0.97380
PPO Batch Consumption Time: 0.04550
Total Iteration Time: 6.69295

Cumulative Model Updates: 18,733
Cumulative Timesteps: 312,549,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.91258
Policy Entropy: 1.10181
Value Function Loss: 3.91911

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.05902

Collected Steps per Second: 8,673.62377
Overall Steps per Second: 7,702.97043

Timestep Collection Time: 5.76714
Timestep Consumption Time: 0.72672
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 6.49386

Cumulative Model Updates: 18,736
Cumulative Timesteps: 312,599,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 312599460...
Checkpoint 312599460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.52634
Policy Entropy: 1.10740
Value Function Loss: 3.87002

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 9,040.65851
Overall Steps per Second: 7,859.17764

Timestep Collection Time: 5.53367
Timestep Consumption Time: 0.83188
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 6.36555

Cumulative Model Updates: 18,739
Cumulative Timesteps: 312,649,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.59962
Policy Entropy: 1.09065
Value Function Loss: 3.77951

Mean KL Divergence: 0.02899
SB3 Clip Fraction: 0.17166
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.06462

Collected Steps per Second: 8,715.54871
Overall Steps per Second: 7,614.92968

Timestep Collection Time: 5.74009
Timestep Consumption Time: 0.82964
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.56973

Cumulative Model Updates: 18,742
Cumulative Timesteps: 312,699,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 312699516...
Checkpoint 312699516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.12260
Policy Entropy: 1.11991
Value Function Loss: 3.78601

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.05628

Collected Steps per Second: 9,072.54469
Overall Steps per Second: 7,846.70881

Timestep Collection Time: 5.51135
Timestep Consumption Time: 0.86100
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.37235

Cumulative Model Updates: 18,745
Cumulative Timesteps: 312,749,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.32380
Policy Entropy: 1.09405
Value Function Loss: 3.76062

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 8,795.45321
Overall Steps per Second: 7,627.25211

Timestep Collection Time: 5.68680
Timestep Consumption Time: 0.87100
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 6.55780

Cumulative Model Updates: 18,748
Cumulative Timesteps: 312,799,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 312799536...
Checkpoint 312799536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.87631
Policy Entropy: 1.11866
Value Function Loss: 3.77596

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.06418

Collected Steps per Second: 8,954.46780
Overall Steps per Second: 7,809.43871

Timestep Collection Time: 5.58693
Timestep Consumption Time: 0.81916
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.40609

Cumulative Model Updates: 18,751
Cumulative Timesteps: 312,849,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.98284
Policy Entropy: 1.11942
Value Function Loss: 3.78426

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.07611
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 8,441.17113
Overall Steps per Second: 7,347.74244

Timestep Collection Time: 5.92619
Timestep Consumption Time: 0.88189
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 6.80808

Cumulative Model Updates: 18,754
Cumulative Timesteps: 312,899,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 312899588...
Checkpoint 312899588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.37780
Policy Entropy: 1.11922
Value Function Loss: 3.76191

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.07759
Value Function Update Magnitude: 0.07297

Collected Steps per Second: 8,440.95466
Overall Steps per Second: 7,322.27345

Timestep Collection Time: 5.92350
Timestep Consumption Time: 0.90498
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.82848

Cumulative Model Updates: 18,757
Cumulative Timesteps: 312,949,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.38166
Policy Entropy: 1.11750
Value Function Loss: 3.78152

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.08113
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 8,817.62374
Overall Steps per Second: 7,541.05910

Timestep Collection Time: 5.67341
Timestep Consumption Time: 0.96041
PPO Batch Consumption Time: 0.04645
Total Iteration Time: 6.63382

Cumulative Model Updates: 18,760
Cumulative Timesteps: 312,999,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 312999614...
Checkpoint 312999614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.20447
Policy Entropy: 1.12816
Value Function Loss: 3.68563

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.06600

Collected Steps per Second: 8,390.97656
Overall Steps per Second: 7,263.26880

Timestep Collection Time: 5.96021
Timestep Consumption Time: 0.92539
PPO Batch Consumption Time: 0.04812
Total Iteration Time: 6.88560

Cumulative Model Updates: 18,763
Cumulative Timesteps: 313,049,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.54318
Policy Entropy: 1.12787
Value Function Loss: 3.76311

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 8,700.77676
Overall Steps per Second: 7,633.08368

Timestep Collection Time: 5.74960
Timestep Consumption Time: 0.80424
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 6.55384

Cumulative Model Updates: 18,766
Cumulative Timesteps: 313,099,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 313099652...
Checkpoint 313099652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.34523
Policy Entropy: 1.12008
Value Function Loss: 3.80922

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 8,819.19255
Overall Steps per Second: 7,660.12008

Timestep Collection Time: 5.67013
Timestep Consumption Time: 0.85796
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.52810

Cumulative Model Updates: 18,769
Cumulative Timesteps: 313,149,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.94771
Policy Entropy: 1.08918
Value Function Loss: 3.91285

Mean KL Divergence: 0.03873
SB3 Clip Fraction: 0.18125
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 8,912.77096
Overall Steps per Second: 7,782.25822

Timestep Collection Time: 5.61172
Timestep Consumption Time: 0.81520
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.42693

Cumulative Model Updates: 18,772
Cumulative Timesteps: 313,199,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 313199674...
Checkpoint 313199674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.54504
Policy Entropy: 1.11491
Value Function Loss: 3.88731

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.17105
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 8,775.97933
Overall Steps per Second: 7,628.99736

Timestep Collection Time: 5.69942
Timestep Consumption Time: 0.85688
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.55630

Cumulative Model Updates: 18,775
Cumulative Timesteps: 313,249,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.42956
Policy Entropy: 1.07164
Value Function Loss: 3.77110

Mean KL Divergence: 0.03915
SB3 Clip Fraction: 0.21185
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 8,916.74109
Overall Steps per Second: 7,747.82916

Timestep Collection Time: 5.61012
Timestep Consumption Time: 0.84640
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.45652

Cumulative Model Updates: 18,778
Cumulative Timesteps: 313,299,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 313299716...
Checkpoint 313299716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.98860
Policy Entropy: 1.10801
Value Function Loss: 3.57049

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.17532
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.04987

Collected Steps per Second: 8,760.71979
Overall Steps per Second: 7,751.27690

Timestep Collection Time: 5.70729
Timestep Consumption Time: 0.74326
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.45055

Cumulative Model Updates: 18,781
Cumulative Timesteps: 313,349,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.68750
Policy Entropy: 1.08847
Value Function Loss: 3.48625

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.18410
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 8,994.78736
Overall Steps per Second: 7,799.59995

Timestep Collection Time: 5.55878
Timestep Consumption Time: 0.85181
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 6.41059

Cumulative Model Updates: 18,784
Cumulative Timesteps: 313,399,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 313399716...
Checkpoint 313399716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.60833
Policy Entropy: 1.11740
Value Function Loss: 3.44006

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.04668

Collected Steps per Second: 8,577.63800
Overall Steps per Second: 7,526.48818

Timestep Collection Time: 5.83261
Timestep Consumption Time: 0.81458
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.64719

Cumulative Model Updates: 18,787
Cumulative Timesteps: 313,449,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.79145
Policy Entropy: 1.13300
Value Function Loss: 3.63974

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 8,745.22629
Overall Steps per Second: 7,546.65140

Timestep Collection Time: 5.71992
Timestep Consumption Time: 0.90845
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.62837

Cumulative Model Updates: 18,790
Cumulative Timesteps: 313,499,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 313499768...
Checkpoint 313499768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.44013
Policy Entropy: 1.11991
Value Function Loss: 3.56238

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 8,845.47192
Overall Steps per Second: 7,657.46684

Timestep Collection Time: 5.65487
Timestep Consumption Time: 0.87732
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.53219

Cumulative Model Updates: 18,793
Cumulative Timesteps: 313,549,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.32847
Policy Entropy: 1.11391
Value Function Loss: 3.85234

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 8,740.51044
Overall Steps per Second: 7,691.49248

Timestep Collection Time: 5.72278
Timestep Consumption Time: 0.78051
PPO Batch Consumption Time: 0.04599
Total Iteration Time: 6.50329

Cumulative Model Updates: 18,796
Cumulative Timesteps: 313,599,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 313599808...
Checkpoint 313599808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.30625
Policy Entropy: 1.11437
Value Function Loss: 3.81413

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 8,780.46426
Overall Steps per Second: 7,638.28748

Timestep Collection Time: 5.69674
Timestep Consumption Time: 0.85185
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.54859

Cumulative Model Updates: 18,799
Cumulative Timesteps: 313,649,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.06909
Policy Entropy: 1.12330
Value Function Loss: 4.00768

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 9,079.53920
Overall Steps per Second: 7,757.36400

Timestep Collection Time: 5.50865
Timestep Consumption Time: 0.93890
PPO Batch Consumption Time: 0.05083
Total Iteration Time: 6.44755

Cumulative Model Updates: 18,802
Cumulative Timesteps: 313,699,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 313699844...
Checkpoint 313699844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.67196
Policy Entropy: 1.11687
Value Function Loss: 3.80064

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 8,976.64554
Overall Steps per Second: 7,871.63141

Timestep Collection Time: 5.57224
Timestep Consumption Time: 0.78223
PPO Batch Consumption Time: 0.04616
Total Iteration Time: 6.35446

Cumulative Model Updates: 18,805
Cumulative Timesteps: 313,749,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.55120
Policy Entropy: 1.10122
Value Function Loss: 3.86629

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.05547

Collected Steps per Second: 9,550.22124
Overall Steps per Second: 8,139.04138

Timestep Collection Time: 5.23757
Timestep Consumption Time: 0.90811
PPO Batch Consumption Time: 0.05863
Total Iteration Time: 6.14569

Cumulative Model Updates: 18,808
Cumulative Timesteps: 313,799,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 313799884...
Checkpoint 313799884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.21573
Policy Entropy: 1.11957
Value Function Loss: 3.77234

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 9,032.78181
Overall Steps per Second: 7,883.38851

Timestep Collection Time: 5.53805
Timestep Consumption Time: 0.80744
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.34549

Cumulative Model Updates: 18,811
Cumulative Timesteps: 313,849,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.76677
Policy Entropy: 1.11470
Value Function Loss: 3.72490

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.03861

Collected Steps per Second: 8,992.16096
Overall Steps per Second: 7,777.82668

Timestep Collection Time: 5.56196
Timestep Consumption Time: 0.86838
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.43033

Cumulative Model Updates: 18,814
Cumulative Timesteps: 313,899,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 313899922...
Checkpoint 313899922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.58759
Policy Entropy: 1.10860
Value Function Loss: 3.83883

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.03730

Collected Steps per Second: 8,582.67592
Overall Steps per Second: 7,468.59619

Timestep Collection Time: 5.82639
Timestep Consumption Time: 0.86911
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.69550

Cumulative Model Updates: 18,817
Cumulative Timesteps: 313,949,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.45141
Policy Entropy: 1.10138
Value Function Loss: 3.93082

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 8,719.57370
Overall Steps per Second: 7,704.92687

Timestep Collection Time: 5.73560
Timestep Consumption Time: 0.75531
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 6.49091

Cumulative Model Updates: 18,820
Cumulative Timesteps: 313,999,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 313999940...
Checkpoint 313999940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.10941
Policy Entropy: 1.11257
Value Function Loss: 4.02388

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.05472

Collected Steps per Second: 8,983.44213
Overall Steps per Second: 7,637.57717

Timestep Collection Time: 5.56580
Timestep Consumption Time: 0.98078
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.54658

Cumulative Model Updates: 18,823
Cumulative Timesteps: 314,049,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.11924
Policy Entropy: 1.11103
Value Function Loss: 3.91040

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.04874

Collected Steps per Second: 8,811.20343
Overall Steps per Second: 7,676.11556

Timestep Collection Time: 5.67686
Timestep Consumption Time: 0.83945
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.51632

Cumulative Model Updates: 18,826
Cumulative Timesteps: 314,099,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 314099960...
Checkpoint 314099960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.12624
Policy Entropy: 1.12029
Value Function Loss: 3.84110

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.04785

Collected Steps per Second: 9,092.04086
Overall Steps per Second: 7,832.15607

Timestep Collection Time: 5.50064
Timestep Consumption Time: 0.88484
PPO Batch Consumption Time: 0.04791
Total Iteration Time: 6.38547

Cumulative Model Updates: 18,829
Cumulative Timesteps: 314,149,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.47766
Policy Entropy: 1.11651
Value Function Loss: 3.85385

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.04600

Collected Steps per Second: 8,778.61364
Overall Steps per Second: 7,705.14031

Timestep Collection Time: 5.69771
Timestep Consumption Time: 0.79380
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 6.49151

Cumulative Model Updates: 18,832
Cumulative Timesteps: 314,199,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 314199990...
Checkpoint 314199990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.29068
Policy Entropy: 1.11392
Value Function Loss: 3.86808

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.04006

Collected Steps per Second: 8,689.80506
Overall Steps per Second: 7,708.06121

Timestep Collection Time: 5.75594
Timestep Consumption Time: 0.73311
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 6.48905

Cumulative Model Updates: 18,835
Cumulative Timesteps: 314,250,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.37956
Policy Entropy: 1.09025
Value Function Loss: 3.94334

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.07446
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 8,910.62656
Overall Steps per Second: 7,726.93321

Timestep Collection Time: 5.61352
Timestep Consumption Time: 0.85994
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 6.47346

Cumulative Model Updates: 18,838
Cumulative Timesteps: 314,300,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 314300028...
Checkpoint 314300028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.94579
Policy Entropy: 1.11046
Value Function Loss: 3.93865

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 8,772.47611
Overall Steps per Second: 7,662.04166

Timestep Collection Time: 5.70033
Timestep Consumption Time: 0.82613
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.52646

Cumulative Model Updates: 18,841
Cumulative Timesteps: 314,350,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.59933
Policy Entropy: 1.10937
Value Function Loss: 3.99123

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 8,979.14966
Overall Steps per Second: 7,821.89420

Timestep Collection Time: 5.56890
Timestep Consumption Time: 0.82392
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 6.39282

Cumulative Model Updates: 18,844
Cumulative Timesteps: 314,400,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 314400038...
Checkpoint 314400038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.26371
Policy Entropy: 1.11268
Value Function Loss: 4.04001

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 8,835.65501
Overall Steps per Second: 7,658.57688

Timestep Collection Time: 5.66002
Timestep Consumption Time: 0.86991
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.52993

Cumulative Model Updates: 18,847
Cumulative Timesteps: 314,450,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.23128
Policy Entropy: 1.09930
Value Function Loss: 4.06791

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 8,963.58367
Overall Steps per Second: 7,915.69801

Timestep Collection Time: 5.57902
Timestep Consumption Time: 0.73855
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.31757

Cumulative Model Updates: 18,850
Cumulative Timesteps: 314,500,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 314500056...
Checkpoint 314500056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.62172
Policy Entropy: 1.11036
Value Function Loss: 3.91240

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.04327

Collected Steps per Second: 8,717.37877
Overall Steps per Second: 7,574.40897

Timestep Collection Time: 5.73659
Timestep Consumption Time: 0.86564
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 6.60223

Cumulative Model Updates: 18,853
Cumulative Timesteps: 314,550,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.09050
Policy Entropy: 1.10469
Value Function Loss: 3.74284

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.03749

Collected Steps per Second: 9,019.30119
Overall Steps per Second: 7,855.22049

Timestep Collection Time: 5.54633
Timestep Consumption Time: 0.82192
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.36825

Cumulative Model Updates: 18,856
Cumulative Timesteps: 314,600,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 314600088...
Checkpoint 314600088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.62525
Policy Entropy: 1.08653
Value Function Loss: 3.68552

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 8,757.54007
Overall Steps per Second: 7,586.90142

Timestep Collection Time: 5.71051
Timestep Consumption Time: 0.88112
PPO Batch Consumption Time: 0.05141
Total Iteration Time: 6.59162

Cumulative Model Updates: 18,859
Cumulative Timesteps: 314,650,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.92328
Policy Entropy: 1.08355
Value Function Loss: 3.66600

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.05284

Collected Steps per Second: 9,041.14680
Overall Steps per Second: 7,887.29338

Timestep Collection Time: 5.53248
Timestep Consumption Time: 0.80936
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.34185

Cumulative Model Updates: 18,862
Cumulative Timesteps: 314,700,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 314700118...
Checkpoint 314700118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.65568
Policy Entropy: 1.09842
Value Function Loss: 3.87290

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.05020

Collected Steps per Second: 8,657.38126
Overall Steps per Second: 7,652.55989

Timestep Collection Time: 5.77796
Timestep Consumption Time: 0.75868
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 6.53664

Cumulative Model Updates: 18,865
Cumulative Timesteps: 314,750,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.08271
Policy Entropy: 1.10516
Value Function Loss: 3.93942

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.04224
Value Function Update Magnitude: 0.04643

Collected Steps per Second: 9,058.75759
Overall Steps per Second: 7,895.29709

Timestep Collection Time: 5.52062
Timestep Consumption Time: 0.81353
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.33415

Cumulative Model Updates: 18,868
Cumulative Timesteps: 314,800,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 314800150...
Checkpoint 314800150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.35501
Policy Entropy: 1.09895
Value Function Loss: 4.20804

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.03724

Collected Steps per Second: 8,699.16370
Overall Steps per Second: 7,481.17579

Timestep Collection Time: 5.74952
Timestep Consumption Time: 0.93606
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.68558

Cumulative Model Updates: 18,871
Cumulative Timesteps: 314,850,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.90531
Policy Entropy: 1.08412
Value Function Loss: 4.00505

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.04019

Collected Steps per Second: 9,131.42817
Overall Steps per Second: 7,895.74435

Timestep Collection Time: 5.47713
Timestep Consumption Time: 0.85717
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.33430

Cumulative Model Updates: 18,874
Cumulative Timesteps: 314,900,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 314900180...
Checkpoint 314900180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.15660
Policy Entropy: 1.10365
Value Function Loss: 3.93871

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.05379

Collected Steps per Second: 8,926.41161
Overall Steps per Second: 7,806.02795

Timestep Collection Time: 5.60315
Timestep Consumption Time: 0.80421
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.40736

Cumulative Model Updates: 18,877
Cumulative Timesteps: 314,950,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.41763
Policy Entropy: 1.09432
Value Function Loss: 3.83959

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.05630

Collected Steps per Second: 8,952.43740
Overall Steps per Second: 7,885.34285

Timestep Collection Time: 5.58775
Timestep Consumption Time: 0.75617
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.34392

Cumulative Model Updates: 18,880
Cumulative Timesteps: 315,000,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 315000220...
Checkpoint 315000220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.83477
Policy Entropy: 1.08533
Value Function Loss: 3.73428

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 9,081.52706
Overall Steps per Second: 7,901.07407

Timestep Collection Time: 5.50899
Timestep Consumption Time: 0.82307
PPO Batch Consumption Time: 0.04816
Total Iteration Time: 6.33205

Cumulative Model Updates: 18,883
Cumulative Timesteps: 315,050,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.30723
Policy Entropy: 1.08873
Value Function Loss: 3.74869

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.05262

Collected Steps per Second: 8,558.87656
Overall Steps per Second: 7,508.09587

Timestep Collection Time: 5.84189
Timestep Consumption Time: 0.81759
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.65948

Cumulative Model Updates: 18,886
Cumulative Timesteps: 315,100,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 315100250...
Checkpoint 315100250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.33311
Policy Entropy: 1.08816
Value Function Loss: 3.92373

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.05479

Collected Steps per Second: 9,050.67413
Overall Steps per Second: 7,871.15450

Timestep Collection Time: 5.52710
Timestep Consumption Time: 0.82826
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 6.35536

Cumulative Model Updates: 18,889
Cumulative Timesteps: 315,150,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.04128
Policy Entropy: 1.09192
Value Function Loss: 4.13350

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 8,705.23137
Overall Steps per Second: 7,596.20923

Timestep Collection Time: 5.74551
Timestep Consumption Time: 0.83883
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 6.58434

Cumulative Model Updates: 18,892
Cumulative Timesteps: 315,200,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 315200290...
Checkpoint 315200290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.29851
Policy Entropy: 1.09862
Value Function Loss: 4.09819

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 8,995.92516
Overall Steps per Second: 7,951.60028

Timestep Collection Time: 5.56074
Timestep Consumption Time: 0.73032
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 6.29106

Cumulative Model Updates: 18,895
Cumulative Timesteps: 315,250,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.59853
Policy Entropy: 1.09894
Value Function Loss: 3.87967

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.05431

Collected Steps per Second: 8,926.33836
Overall Steps per Second: 7,727.70035

Timestep Collection Time: 5.60207
Timestep Consumption Time: 0.86893
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.47101

Cumulative Model Updates: 18,898
Cumulative Timesteps: 315,300,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 315300320...
Checkpoint 315300320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.23048
Policy Entropy: 1.09296
Value Function Loss: 3.62747

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.05746

Collected Steps per Second: 8,860.66728
Overall Steps per Second: 7,682.45909

Timestep Collection Time: 5.64337
Timestep Consumption Time: 0.86549
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.50885

Cumulative Model Updates: 18,901
Cumulative Timesteps: 315,350,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.97052
Policy Entropy: 1.09514
Value Function Loss: 3.73226

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14968
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.05772

Collected Steps per Second: 8,941.18383
Overall Steps per Second: 7,809.73670

Timestep Collection Time: 5.59434
Timestep Consumption Time: 0.81049
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 6.40483

Cumulative Model Updates: 18,904
Cumulative Timesteps: 315,400,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 315400344...
Checkpoint 315400344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.79492
Policy Entropy: 1.08786
Value Function Loss: 3.65506

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.05309

Collected Steps per Second: 8,906.62935
Overall Steps per Second: 7,723.27945

Timestep Collection Time: 5.61649
Timestep Consumption Time: 0.86055
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 6.47704

Cumulative Model Updates: 18,907
Cumulative Timesteps: 315,450,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.81522
Policy Entropy: 1.08080
Value Function Loss: 3.67276

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 9,082.85915
Overall Steps per Second: 8,016.68340

Timestep Collection Time: 5.50620
Timestep Consumption Time: 0.73229
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.23849

Cumulative Model Updates: 18,910
Cumulative Timesteps: 315,500,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 315500380...
Checkpoint 315500380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.53175
Policy Entropy: 1.09403
Value Function Loss: 3.57730

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 8,678.95767
Overall Steps per Second: 7,491.60534

Timestep Collection Time: 5.76336
Timestep Consumption Time: 0.91344
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 6.67681

Cumulative Model Updates: 18,913
Cumulative Timesteps: 315,550,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.05097
Policy Entropy: 1.11128
Value Function Loss: 3.67518

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.15831
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.05987

Collected Steps per Second: 9,010.72283
Overall Steps per Second: 7,810.12706

Timestep Collection Time: 5.54894
Timestep Consumption Time: 0.85300
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 6.40194

Cumulative Model Updates: 18,916
Cumulative Timesteps: 315,600,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 315600400...
Checkpoint 315600400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.51399
Policy Entropy: 1.08906
Value Function Loss: 3.76545

Mean KL Divergence: 0.03545
SB3 Clip Fraction: 0.21501
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.05593

Collected Steps per Second: 9,130.17464
Overall Steps per Second: 7,858.35901

Timestep Collection Time: 5.47876
Timestep Consumption Time: 0.88669
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.36545

Cumulative Model Updates: 18,919
Cumulative Timesteps: 315,650,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.38346
Policy Entropy: 1.11716
Value Function Loss: 4.06304

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.16051
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 9,395.01841
Overall Steps per Second: 8,124.68261

Timestep Collection Time: 5.32346
Timestep Consumption Time: 0.83235
PPO Batch Consumption Time: 0.05048
Total Iteration Time: 6.15581

Cumulative Model Updates: 18,922
Cumulative Timesteps: 315,700,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 315700436...
Checkpoint 315700436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.20584
Policy Entropy: 1.10245
Value Function Loss: 4.03731

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 8,902.14495
Overall Steps per Second: 7,875.99356

Timestep Collection Time: 5.61977
Timestep Consumption Time: 0.73219
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.35196

Cumulative Model Updates: 18,925
Cumulative Timesteps: 315,750,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.12139
Policy Entropy: 1.09263
Value Function Loss: 3.76555

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 8,891.95229
Overall Steps per Second: 7,724.45954

Timestep Collection Time: 5.62599
Timestep Consumption Time: 0.85032
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.47631

Cumulative Model Updates: 18,928
Cumulative Timesteps: 315,800,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 315800490...
Checkpoint 315800490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.31341
Policy Entropy: 1.10127
Value Function Loss: 3.55080

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.06528

Collected Steps per Second: 8,851.90232
Overall Steps per Second: 7,721.27664

Timestep Collection Time: 5.64873
Timestep Consumption Time: 0.82714
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 6.47587

Cumulative Model Updates: 18,931
Cumulative Timesteps: 315,850,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.39743
Policy Entropy: 1.10092
Value Function Loss: 3.50119

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.04212
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 9,080.38626
Overall Steps per Second: 7,897.51127

Timestep Collection Time: 5.50681
Timestep Consumption Time: 0.82480
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.33161

Cumulative Model Updates: 18,934
Cumulative Timesteps: 315,900,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 315900496...
Checkpoint 315900496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.20094
Policy Entropy: 1.09051
Value Function Loss: 3.74389

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.06120

Collected Steps per Second: 8,545.77670
Overall Steps per Second: 7,423.34072

Timestep Collection Time: 5.85389
Timestep Consumption Time: 0.88513
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 6.73901

Cumulative Model Updates: 18,937
Cumulative Timesteps: 315,950,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.90189
Policy Entropy: 1.08339
Value Function Loss: 3.74643

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.16346
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 9,009.88124
Overall Steps per Second: 7,955.35396

Timestep Collection Time: 5.55168
Timestep Consumption Time: 0.73591
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 6.28759

Cumulative Model Updates: 18,940
Cumulative Timesteps: 316,000,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 316000542...
Checkpoint 316000542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.82088
Policy Entropy: 1.09328
Value Function Loss: 3.84673

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 8,496.30550
Overall Steps per Second: 7,444.29944

Timestep Collection Time: 5.88515
Timestep Consumption Time: 0.83167
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.71682

Cumulative Model Updates: 18,943
Cumulative Timesteps: 316,050,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.79343
Policy Entropy: 1.10292
Value Function Loss: 3.97145

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 8,966.44640
Overall Steps per Second: 7,789.52522

Timestep Collection Time: 5.57858
Timestep Consumption Time: 0.84287
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.42144

Cumulative Model Updates: 18,946
Cumulative Timesteps: 316,100,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 316100564...
Checkpoint 316100564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.39430
Policy Entropy: 1.07786
Value Function Loss: 3.90347

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.06000

Collected Steps per Second: 8,891.49680
Overall Steps per Second: 7,681.33528

Timestep Collection Time: 5.62358
Timestep Consumption Time: 0.88597
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 6.50955

Cumulative Model Updates: 18,949
Cumulative Timesteps: 316,150,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.63679
Policy Entropy: 1.10181
Value Function Loss: 3.79446

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 9,049.38426
Overall Steps per Second: 7,903.22871

Timestep Collection Time: 5.52745
Timestep Consumption Time: 0.80161
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.32906

Cumulative Model Updates: 18,952
Cumulative Timesteps: 316,200,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 316200586...
Checkpoint 316200586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.62073
Policy Entropy: 1.10087
Value Function Loss: 3.71352

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.07540

Collected Steps per Second: 8,517.23365
Overall Steps per Second: 7,570.71024

Timestep Collection Time: 5.87209
Timestep Consumption Time: 0.73416
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.60625

Cumulative Model Updates: 18,955
Cumulative Timesteps: 316,250,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.19658
Policy Entropy: 1.09402
Value Function Loss: 3.84199

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 8,860.53907
Overall Steps per Second: 7,717.39611

Timestep Collection Time: 5.64503
Timestep Consumption Time: 0.83617
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 6.48120

Cumulative Model Updates: 18,958
Cumulative Timesteps: 316,300,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 316300618...
Checkpoint 316300618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.11538
Policy Entropy: 1.07943
Value Function Loss: 3.84424

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.07719

Collected Steps per Second: 8,688.62663
Overall Steps per Second: 7,616.27021

Timestep Collection Time: 5.75626
Timestep Consumption Time: 0.81047
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.56673

Cumulative Model Updates: 18,961
Cumulative Timesteps: 316,350,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.82127
Policy Entropy: 1.08527
Value Function Loss: 3.85293

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 8,882.86975
Overall Steps per Second: 7,752.71276

Timestep Collection Time: 5.63151
Timestep Consumption Time: 0.82094
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.45245

Cumulative Model Updates: 18,964
Cumulative Timesteps: 316,400,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 316400656...
Checkpoint 316400656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.71328
Policy Entropy: 1.08848
Value Function Loss: 3.74535

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.11030

Collected Steps per Second: 8,772.53653
Overall Steps per Second: 7,660.34498

Timestep Collection Time: 5.70234
Timestep Consumption Time: 0.82791
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 6.53025

Cumulative Model Updates: 18,967
Cumulative Timesteps: 316,450,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.86192
Policy Entropy: 1.08917
Value Function Loss: 3.61282

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 8,662.09127
Overall Steps per Second: 7,683.35298

Timestep Collection Time: 5.77574
Timestep Consumption Time: 0.73574
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.51148

Cumulative Model Updates: 18,970
Cumulative Timesteps: 316,500,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 316500710...
Checkpoint 316500710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.34765
Policy Entropy: 1.09343
Value Function Loss: 3.63060

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 8,839.68683
Overall Steps per Second: 7,665.40389

Timestep Collection Time: 5.65812
Timestep Consumption Time: 0.86678
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 6.52490

Cumulative Model Updates: 18,973
Cumulative Timesteps: 316,550,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.14987
Policy Entropy: 1.09496
Value Function Loss: 3.77337

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.09461

Collected Steps per Second: 8,728.92944
Overall Steps per Second: 7,650.45089

Timestep Collection Time: 5.73106
Timestep Consumption Time: 0.80790
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.53896

Cumulative Model Updates: 18,976
Cumulative Timesteps: 316,600,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 316600752...
Checkpoint 316600752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.58782
Policy Entropy: 1.10093
Value Function Loss: 4.01238

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.08620

Collected Steps per Second: 9,112.59465
Overall Steps per Second: 7,902.69089

Timestep Collection Time: 5.48933
Timestep Consumption Time: 0.84042
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 6.32974

Cumulative Model Updates: 18,979
Cumulative Timesteps: 316,650,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.52620
Policy Entropy: 1.10340
Value Function Loss: 4.17298

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 8,751.73558
Overall Steps per Second: 7,504.93543

Timestep Collection Time: 5.71315
Timestep Consumption Time: 0.94913
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 6.66228

Cumulative Model Updates: 18,982
Cumulative Timesteps: 316,700,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 316700774...
Checkpoint 316700774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.23940
Policy Entropy: 1.10544
Value Function Loss: 3.94658

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 9,035.51389
Overall Steps per Second: 7,961.94158

Timestep Collection Time: 5.53660
Timestep Consumption Time: 0.74654
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.28314

Cumulative Model Updates: 18,985
Cumulative Timesteps: 316,750,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.98072
Policy Entropy: 1.11485
Value Function Loss: 3.90224

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07899

Collected Steps per Second: 8,924.62546
Overall Steps per Second: 7,781.53544

Timestep Collection Time: 5.60360
Timestep Consumption Time: 0.82316
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 6.42675

Cumulative Model Updates: 18,988
Cumulative Timesteps: 316,800,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 316800810...
Checkpoint 316800810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.96225
Policy Entropy: 1.10294
Value Function Loss: 3.71788

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 8,880.56011
Overall Steps per Second: 7,700.89655

Timestep Collection Time: 5.63230
Timestep Consumption Time: 0.86279
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 6.49509

Cumulative Model Updates: 18,991
Cumulative Timesteps: 316,850,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.40586
Policy Entropy: 1.09387
Value Function Loss: 3.75160

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.09691

Collected Steps per Second: 9,325.50880
Overall Steps per Second: 8,070.62866

Timestep Collection Time: 5.36443
Timestep Consumption Time: 0.83410
PPO Batch Consumption Time: 0.03959
Total Iteration Time: 6.19853

Cumulative Model Updates: 18,994
Cumulative Timesteps: 316,900,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 316900854...
Checkpoint 316900854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.06947
Policy Entropy: 1.10105
Value Function Loss: 3.66197

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.09116

Collected Steps per Second: 8,800.22456
Overall Steps per Second: 7,676.73835

Timestep Collection Time: 5.68440
Timestep Consumption Time: 0.83191
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.51631

Cumulative Model Updates: 18,997
Cumulative Timesteps: 316,950,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.46093
Policy Entropy: 1.10783
Value Function Loss: 3.66804

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 9,001.48847
Overall Steps per Second: 7,971.34269

Timestep Collection Time: 5.55619
Timestep Consumption Time: 0.71803
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 6.27423

Cumulative Model Updates: 19,000
Cumulative Timesteps: 317,000,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 317000892...
Checkpoint 317000892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.99744
Policy Entropy: 1.10924
Value Function Loss: 3.50769

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 8,961.30108
Overall Steps per Second: 7,793.22811

Timestep Collection Time: 5.58245
Timestep Consumption Time: 0.83671
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.41916

Cumulative Model Updates: 19,003
Cumulative Timesteps: 317,050,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.17177
Policy Entropy: 1.10298
Value Function Loss: 3.61440

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 9,107.69729
Overall Steps per Second: 7,946.07118

Timestep Collection Time: 5.49228
Timestep Consumption Time: 0.80291
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.29519

Cumulative Model Updates: 19,006
Cumulative Timesteps: 317,100,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 317100940...
Checkpoint 317100940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.31370
Policy Entropy: 1.10302
Value Function Loss: 3.69437

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.07487

Collected Steps per Second: 9,180.15359
Overall Steps per Second: 7,906.11392

Timestep Collection Time: 5.44806
Timestep Consumption Time: 0.87793
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.32599

Cumulative Model Updates: 19,009
Cumulative Timesteps: 317,150,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.49506
Policy Entropy: 1.11339
Value Function Loss: 3.88201

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 8,882.17597
Overall Steps per Second: 7,756.50765

Timestep Collection Time: 5.62948
Timestep Consumption Time: 0.81698
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 6.44646

Cumulative Model Updates: 19,012
Cumulative Timesteps: 317,200,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 317200956...
Checkpoint 317200956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.53940
Policy Entropy: 1.12620
Value Function Loss: 4.09567

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 8,560.57499
Overall Steps per Second: 7,593.33582

Timestep Collection Time: 5.84260
Timestep Consumption Time: 0.74423
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.58683

Cumulative Model Updates: 19,015
Cumulative Timesteps: 317,250,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.31498
Policy Entropy: 1.11056
Value Function Loss: 4.05020

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.05658

Collected Steps per Second: 8,928.25701
Overall Steps per Second: 7,706.42653

Timestep Collection Time: 5.60266
Timestep Consumption Time: 0.88828
PPO Batch Consumption Time: 0.04787
Total Iteration Time: 6.49095

Cumulative Model Updates: 19,018
Cumulative Timesteps: 317,300,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 317300994...
Checkpoint 317300994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.82315
Policy Entropy: 1.09682
Value Function Loss: 4.01053

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 8,953.10028
Overall Steps per Second: 7,765.23922

Timestep Collection Time: 5.58711
Timestep Consumption Time: 0.85467
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.44178

Cumulative Model Updates: 19,021
Cumulative Timesteps: 317,351,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.98469
Policy Entropy: 1.09749
Value Function Loss: 3.74394

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 9,135.27795
Overall Steps per Second: 7,725.74051

Timestep Collection Time: 5.47526
Timestep Consumption Time: 0.99894
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.47420

Cumulative Model Updates: 19,024
Cumulative Timesteps: 317,401,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 317401034...
Checkpoint 317401034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.53320
Policy Entropy: 1.10450
Value Function Loss: 3.76126

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 9,089.50877
Overall Steps per Second: 7,924.22413

Timestep Collection Time: 5.50327
Timestep Consumption Time: 0.80927
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.31254

Cumulative Model Updates: 19,027
Cumulative Timesteps: 317,451,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.81351
Policy Entropy: 1.11505
Value Function Loss: 3.70482

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.06243

Collected Steps per Second: 9,277.75739
Overall Steps per Second: 8,053.91840

Timestep Collection Time: 5.39204
Timestep Consumption Time: 0.81935
PPO Batch Consumption Time: 0.04879
Total Iteration Time: 6.21139

Cumulative Model Updates: 19,030
Cumulative Timesteps: 317,501,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 317501082...
Checkpoint 317501082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.29820
Policy Entropy: 1.11159
Value Function Loss: 3.72353

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 9,395.16697
Overall Steps per Second: 8,077.00161

Timestep Collection Time: 5.32444
Timestep Consumption Time: 0.86895
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 6.19339

Cumulative Model Updates: 19,033
Cumulative Timesteps: 317,551,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.06666
Policy Entropy: 1.10264
Value Function Loss: 3.72194

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 9,000.56492
Overall Steps per Second: 7,837.44527

Timestep Collection Time: 5.55632
Timestep Consumption Time: 0.82459
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.38091

Cumulative Model Updates: 19,036
Cumulative Timesteps: 317,601,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 317601116...
Checkpoint 317601116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.62581
Policy Entropy: 1.10880
Value Function Loss: 3.81755

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.06180

Collected Steps per Second: 8,864.58873
Overall Steps per Second: 7,734.95681

Timestep Collection Time: 5.64177
Timestep Consumption Time: 0.82394
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.46571

Cumulative Model Updates: 19,039
Cumulative Timesteps: 317,651,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.64994
Policy Entropy: 1.10280
Value Function Loss: 3.78663

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.05922

Collected Steps per Second: 8,871.55990
Overall Steps per Second: 7,736.38824

Timestep Collection Time: 5.63757
Timestep Consumption Time: 0.82721
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 6.46477

Cumulative Model Updates: 19,042
Cumulative Timesteps: 317,701,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 317701142...
Checkpoint 317701142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.85084
Policy Entropy: 1.11482
Value Function Loss: 3.85448

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.06105

Collected Steps per Second: 9,019.32256
Overall Steps per Second: 7,948.05134

Timestep Collection Time: 5.54654
Timestep Consumption Time: 0.74759
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 6.29412

Cumulative Model Updates: 19,045
Cumulative Timesteps: 317,751,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.49101
Policy Entropy: 1.10314
Value Function Loss: 3.75740

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 8,939.08544
Overall Steps per Second: 7,677.05616

Timestep Collection Time: 5.59543
Timestep Consumption Time: 0.91983
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.51526

Cumulative Model Updates: 19,048
Cumulative Timesteps: 317,801,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 317801186...
Checkpoint 317801186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.34748
Policy Entropy: 1.08668
Value Function Loss: 3.71366

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.05343

Collected Steps per Second: 9,025.13008
Overall Steps per Second: 7,724.38428

Timestep Collection Time: 5.54297
Timestep Consumption Time: 0.93341
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.47637

Cumulative Model Updates: 19,051
Cumulative Timesteps: 317,851,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.64994
Policy Entropy: 1.09542
Value Function Loss: 3.51321

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 8,645.28113
Overall Steps per Second: 7,542.81851

Timestep Collection Time: 5.78512
Timestep Consumption Time: 0.84556
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 6.63068

Cumulative Model Updates: 19,054
Cumulative Timesteps: 317,901,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 317901226...
Checkpoint 317901226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.09816
Policy Entropy: 1.10492
Value Function Loss: 3.60501

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 9,059.80943
Overall Steps per Second: 7,866.78689

Timestep Collection Time: 5.52175
Timestep Consumption Time: 0.83739
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 6.35914

Cumulative Model Updates: 19,057
Cumulative Timesteps: 317,951,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.08906
Policy Entropy: 1.10198
Value Function Loss: 3.63178

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 8,838.34410
Overall Steps per Second: 7,823.18030

Timestep Collection Time: 5.65875
Timestep Consumption Time: 0.73430
PPO Batch Consumption Time: 0.04355
Total Iteration Time: 6.39305

Cumulative Model Updates: 19,060
Cumulative Timesteps: 318,001,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 318001266...
Checkpoint 318001266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.15501
Policy Entropy: 1.09868
Value Function Loss: 3.75804

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.05105

Collected Steps per Second: 8,890.73074
Overall Steps per Second: 7,624.46767

Timestep Collection Time: 5.62428
Timestep Consumption Time: 0.93407
PPO Batch Consumption Time: 0.04755
Total Iteration Time: 6.55836

Cumulative Model Updates: 19,063
Cumulative Timesteps: 318,051,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.23295
Policy Entropy: 1.11101
Value Function Loss: 3.71257

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 8,584.20531
Overall Steps per Second: 7,436.07034

Timestep Collection Time: 5.82628
Timestep Consumption Time: 0.89958
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 6.72586

Cumulative Model Updates: 19,066
Cumulative Timesteps: 318,101,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 318101284...
Checkpoint 318101284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.21400
Policy Entropy: 1.11123
Value Function Loss: 3.69133

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.06905

Collected Steps per Second: 8,967.14423
Overall Steps per Second: 7,805.95034

Timestep Collection Time: 5.57770
Timestep Consumption Time: 0.82972
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 6.40742

Cumulative Model Updates: 19,069
Cumulative Timesteps: 318,151,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.39387
Policy Entropy: 1.09182
Value Function Loss: 3.48989

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 8,820.53096
Overall Steps per Second: 7,666.19757

Timestep Collection Time: 5.67018
Timestep Consumption Time: 0.85378
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 6.52396

Cumulative Model Updates: 19,072
Cumulative Timesteps: 318,201,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 318201314...
Checkpoint 318201314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.03804
Policy Entropy: 1.10855
Value Function Loss: 3.53510

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.07233

Collected Steps per Second: 8,660.09271
Overall Steps per Second: 7,629.28869

Timestep Collection Time: 5.77546
Timestep Consumption Time: 0.78033
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.55579

Cumulative Model Updates: 19,075
Cumulative Timesteps: 318,251,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.69776
Policy Entropy: 1.10851
Value Function Loss: 3.50811

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 8,662.17360
Overall Steps per Second: 7,550.41121

Timestep Collection Time: 5.77361
Timestep Consumption Time: 0.85014
PPO Batch Consumption Time: 0.04330
Total Iteration Time: 6.62375

Cumulative Model Updates: 19,078
Cumulative Timesteps: 318,301,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 318301342...
Checkpoint 318301342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.43307
Policy Entropy: 1.09802
Value Function Loss: 3.72533

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 8,573.67822
Overall Steps per Second: 7,483.69350

Timestep Collection Time: 5.83367
Timestep Consumption Time: 0.84966
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.68333

Cumulative Model Updates: 19,081
Cumulative Timesteps: 318,351,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.84340
Policy Entropy: 1.09629
Value Function Loss: 3.74470

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 9,246.16884
Overall Steps per Second: 8,026.64912

Timestep Collection Time: 5.40981
Timestep Consumption Time: 0.82193
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.23174

Cumulative Model Updates: 19,084
Cumulative Timesteps: 318,401,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 318401378...
Checkpoint 318401378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.07604
Policy Entropy: 1.11157
Value Function Loss: 3.89410

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.06958

Collected Steps per Second: 8,898.62817
Overall Steps per Second: 7,675.56191

Timestep Collection Time: 5.62132
Timestep Consumption Time: 0.89573
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.51705

Cumulative Model Updates: 19,087
Cumulative Timesteps: 318,451,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.46796
Policy Entropy: 1.11801
Value Function Loss: 3.91021

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.03954
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 8,928.56362
Overall Steps per Second: 7,874.70254

Timestep Collection Time: 5.60292
Timestep Consumption Time: 0.74983
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.35275

Cumulative Model Updates: 19,090
Cumulative Timesteps: 318,501,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 318501426...
Checkpoint 318501426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.25351
Policy Entropy: 1.10702
Value Function Loss: 3.74961

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 8,956.33358
Overall Steps per Second: 7,741.21569

Timestep Collection Time: 5.58443
Timestep Consumption Time: 0.87657
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.46100

Cumulative Model Updates: 19,093
Cumulative Timesteps: 318,551,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.71766
Policy Entropy: 1.09262
Value Function Loss: 3.49407

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 8,661.17097
Overall Steps per Second: 7,575.80831

Timestep Collection Time: 5.77335
Timestep Consumption Time: 0.82713
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.60048

Cumulative Model Updates: 19,096
Cumulative Timesteps: 318,601,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 318601446...
Checkpoint 318601446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.18824
Policy Entropy: 1.09811
Value Function Loss: 3.32938

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 8,959.47723
Overall Steps per Second: 7,763.64631

Timestep Collection Time: 5.58113
Timestep Consumption Time: 0.85966
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.44079

Cumulative Model Updates: 19,099
Cumulative Timesteps: 318,651,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.81714
Policy Entropy: 1.10600
Value Function Loss: 3.50758

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.06375

Collected Steps per Second: 9,030.84236
Overall Steps per Second: 7,862.88388

Timestep Collection Time: 5.53769
Timestep Consumption Time: 0.82257
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.36026

Cumulative Model Updates: 19,102
Cumulative Timesteps: 318,701,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 318701460...
Checkpoint 318701460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.61581
Policy Entropy: 1.11665
Value Function Loss: 3.87766

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 8,797.65092
Overall Steps per Second: 7,750.56441

Timestep Collection Time: 5.68538
Timestep Consumption Time: 0.76808
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.45347

Cumulative Model Updates: 19,105
Cumulative Timesteps: 318,751,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.01795
Policy Entropy: 1.11526
Value Function Loss: 3.95372

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.07780

Collected Steps per Second: 8,775.17479
Overall Steps per Second: 7,557.34605

Timestep Collection Time: 5.69789
Timestep Consumption Time: 0.91819
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.61608

Cumulative Model Updates: 19,108
Cumulative Timesteps: 318,801,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 318801478...
Checkpoint 318801478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.25782
Policy Entropy: 1.09754
Value Function Loss: 3.94498

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 8,413.73489
Overall Steps per Second: 7,382.05746

Timestep Collection Time: 5.94385
Timestep Consumption Time: 0.83068
PPO Batch Consumption Time: 0.04596
Total Iteration Time: 6.77453

Cumulative Model Updates: 19,111
Cumulative Timesteps: 318,851,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.17395
Policy Entropy: 1.11118
Value Function Loss: 3.82943

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 8,846.42564
Overall Steps per Second: 7,616.59125

Timestep Collection Time: 5.65381
Timestep Consumption Time: 0.91291
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.56672

Cumulative Model Updates: 19,114
Cumulative Timesteps: 318,901,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 318901504...
Checkpoint 318901504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.83654
Policy Entropy: 1.11686
Value Function Loss: 3.86397

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.15420
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.07824

Collected Steps per Second: 8,935.66878
Overall Steps per Second: 7,723.74767

Timestep Collection Time: 5.59578
Timestep Consumption Time: 0.87802
PPO Batch Consumption Time: 0.04851
Total Iteration Time: 6.47380

Cumulative Model Updates: 19,117
Cumulative Timesteps: 318,951,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.13534
Policy Entropy: 1.12343
Value Function Loss: 4.06261

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.06673

Collected Steps per Second: 8,785.07743
Overall Steps per Second: 7,704.98910

Timestep Collection Time: 5.69352
Timestep Consumption Time: 0.79812
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.49164

Cumulative Model Updates: 19,120
Cumulative Timesteps: 319,001,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 319001524...
Checkpoint 319001524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.57893
Policy Entropy: 1.11811
Value Function Loss: 3.84881

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.16379
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.05639

Collected Steps per Second: 8,567.32824
Overall Steps per Second: 7,498.21178

Timestep Collection Time: 5.83939
Timestep Consumption Time: 0.83260
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 6.67199

Cumulative Model Updates: 19,123
Cumulative Timesteps: 319,051,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.15182
Policy Entropy: 1.13421
Value Function Loss: 3.93125

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.04191
Value Function Update Magnitude: 0.06152

Collected Steps per Second: 8,895.94151
Overall Steps per Second: 7,725.84893

Timestep Collection Time: 5.62211
Timestep Consumption Time: 0.85148
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 6.47359

Cumulative Model Updates: 19,126
Cumulative Timesteps: 319,101,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 319101566...
Checkpoint 319101566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.07244
Policy Entropy: 1.12431
Value Function Loss: 3.72705

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 9,101.87301
Overall Steps per Second: 7,851.07446

Timestep Collection Time: 5.49513
Timestep Consumption Time: 0.87546
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.37059

Cumulative Model Updates: 19,129
Cumulative Timesteps: 319,151,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.77413
Policy Entropy: 1.11363
Value Function Loss: 3.70112

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.16159
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.07910

Collected Steps per Second: 8,716.15620
Overall Steps per Second: 7,616.91434

Timestep Collection Time: 5.73877
Timestep Consumption Time: 0.82820
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 6.56696

Cumulative Model Updates: 19,132
Cumulative Timesteps: 319,201,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 319201602...
Checkpoint 319201602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.81908
Policy Entropy: 1.12566
Value Function Loss: 3.61819

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.07823

Collected Steps per Second: 8,915.80700
Overall Steps per Second: 7,775.20670

Timestep Collection Time: 5.61116
Timestep Consumption Time: 0.82314
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.43430

Cumulative Model Updates: 19,135
Cumulative Timesteps: 319,251,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.78125
Policy Entropy: 1.13136
Value Function Loss: 3.75145

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.06714

Collected Steps per Second: 9,394.92981
Overall Steps per Second: 8,116.91315

Timestep Collection Time: 5.32351
Timestep Consumption Time: 0.83819
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.16170

Cumulative Model Updates: 19,138
Cumulative Timesteps: 319,301,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 319301644...
Checkpoint 319301644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.74985
Policy Entropy: 1.12236
Value Function Loss: 3.91423

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 9,054.11256
Overall Steps per Second: 7,797.29611

Timestep Collection Time: 5.52522
Timestep Consumption Time: 0.89059
PPO Batch Consumption Time: 0.04877
Total Iteration Time: 6.41581

Cumulative Model Updates: 19,141
Cumulative Timesteps: 319,351,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.38082
Policy Entropy: 1.10830
Value Function Loss: 3.91364

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.05677

Collected Steps per Second: 9,492.73532
Overall Steps per Second: 8,157.50116

Timestep Collection Time: 5.26929
Timestep Consumption Time: 0.86249
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.13178

Cumulative Model Updates: 19,144
Cumulative Timesteps: 319,401,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 319401690...
Checkpoint 319401690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.90630
Policy Entropy: 1.12326
Value Function Loss: 3.67285

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 9,101.17721
Overall Steps per Second: 7,923.00507

Timestep Collection Time: 5.49423
Timestep Consumption Time: 0.81701
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.31124

Cumulative Model Updates: 19,147
Cumulative Timesteps: 319,451,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.63630
Policy Entropy: 1.12316
Value Function Loss: 3.64634

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 8,674.73454
Overall Steps per Second: 7,678.70443

Timestep Collection Time: 5.76456
Timestep Consumption Time: 0.74774
PPO Batch Consumption Time: 0.04541
Total Iteration Time: 6.51230

Cumulative Model Updates: 19,150
Cumulative Timesteps: 319,501,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 319501700...
Checkpoint 319501700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.28660
Policy Entropy: 1.10685
Value Function Loss: 3.54871

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 9,071.46969
Overall Steps per Second: 7,833.58057

Timestep Collection Time: 5.51443
Timestep Consumption Time: 0.87141
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.38584

Cumulative Model Updates: 19,153
Cumulative Timesteps: 319,551,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.74527
Policy Entropy: 1.09462
Value Function Loss: 3.54305

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.06437

Collected Steps per Second: 8,912.82635
Overall Steps per Second: 7,716.02118

Timestep Collection Time: 5.61281
Timestep Consumption Time: 0.87058
PPO Batch Consumption Time: 0.05221
Total Iteration Time: 6.48339

Cumulative Model Updates: 19,156
Cumulative Timesteps: 319,601,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 319601750...
Checkpoint 319601750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.02195
Policy Entropy: 1.10914
Value Function Loss: 3.58747

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.06654

Collected Steps per Second: 9,113.50572
Overall Steps per Second: 7,866.19370

Timestep Collection Time: 5.48944
Timestep Consumption Time: 0.87044
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 6.35987

Cumulative Model Updates: 19,159
Cumulative Timesteps: 319,651,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.33126
Policy Entropy: 1.12940
Value Function Loss: 3.54555

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.08255

Collected Steps per Second: 8,356.71801
Overall Steps per Second: 7,300.36356

Timestep Collection Time: 5.98536
Timestep Consumption Time: 0.86608
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 6.85144

Cumulative Model Updates: 19,162
Cumulative Timesteps: 319,701,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 319701796...
Checkpoint 319701796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.85879
Policy Entropy: 1.08582
Value Function Loss: 3.60424

Mean KL Divergence: 0.08162
SB3 Clip Fraction: 0.23305
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.07805

Collected Steps per Second: 8,267.45964
Overall Steps per Second: 7,309.96331

Timestep Collection Time: 6.05047
Timestep Consumption Time: 0.79252
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.84299

Cumulative Model Updates: 19,165
Cumulative Timesteps: 319,751,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.51528
Policy Entropy: 1.12771
Value Function Loss: 3.63750

Mean KL Divergence: 0.04711
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 8,809.03433
Overall Steps per Second: 7,613.26721

Timestep Collection Time: 5.67917
Timestep Consumption Time: 0.89199
PPO Batch Consumption Time: 0.05177
Total Iteration Time: 6.57116

Cumulative Model Updates: 19,168
Cumulative Timesteps: 319,801,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 319801846...
Checkpoint 319801846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.39160
Policy Entropy: 1.10902
Value Function Loss: 3.69165

Mean KL Divergence: 0.05274
SB3 Clip Fraction: 0.21967
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 8,801.55550
Overall Steps per Second: 7,726.54950

Timestep Collection Time: 5.68127
Timestep Consumption Time: 0.79044
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.47171

Cumulative Model Updates: 19,171
Cumulative Timesteps: 319,851,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.41111
Policy Entropy: 1.13735
Value Function Loss: 3.57392

Mean KL Divergence: 0.05585
SB3 Clip Fraction: 0.21875
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 9,213.18308
Overall Steps per Second: 7,908.83030

Timestep Collection Time: 5.42939
Timestep Consumption Time: 0.89544
PPO Batch Consumption Time: 0.04880
Total Iteration Time: 6.32483

Cumulative Model Updates: 19,174
Cumulative Timesteps: 319,901,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 319901872...
Checkpoint 319901872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.66518
Policy Entropy: 1.10998
Value Function Loss: 3.57213

Mean KL Divergence: 0.04592
SB3 Clip Fraction: 0.21648
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.05842

Collected Steps per Second: 8,602.02728
Overall Steps per Second: 7,397.63128

Timestep Collection Time: 5.81351
Timestep Consumption Time: 0.94649
PPO Batch Consumption Time: 0.04947
Total Iteration Time: 6.76000

Cumulative Model Updates: 19,177
Cumulative Timesteps: 319,951,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.34110
Policy Entropy: 1.12838
Value Function Loss: 3.70202

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.17360
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.06437

Collected Steps per Second: 8,788.03260
Overall Steps per Second: 7,760.85553

Timestep Collection Time: 5.69069
Timestep Consumption Time: 0.75318
PPO Batch Consumption Time: 0.04466
Total Iteration Time: 6.44388

Cumulative Model Updates: 19,180
Cumulative Timesteps: 320,001,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 320001890...
Checkpoint 320001890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.39841
Policy Entropy: 1.11066
Value Function Loss: 3.79423

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 8,691.34759
Overall Steps per Second: 7,604.28809

Timestep Collection Time: 5.75584
Timestep Consumption Time: 0.82282
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.57866

Cumulative Model Updates: 19,183
Cumulative Timesteps: 320,051,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.94972
Policy Entropy: 1.10834
Value Function Loss: 3.82680

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 8,807.66271
Overall Steps per Second: 7,660.53304

Timestep Collection Time: 5.67846
Timestep Consumption Time: 0.85032
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 6.52879

Cumulative Model Updates: 19,186
Cumulative Timesteps: 320,101,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 320101930...
Checkpoint 320101930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.96283
Policy Entropy: 1.11849
Value Function Loss: 3.88922

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 8,928.63741
Overall Steps per Second: 7,758.64786

Timestep Collection Time: 5.60265
Timestep Consumption Time: 0.84487
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.44752

Cumulative Model Updates: 19,189
Cumulative Timesteps: 320,151,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.52784
Policy Entropy: 1.12644
Value Function Loss: 3.95979

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 8,718.53431
Overall Steps per Second: 7,615.77316

Timestep Collection Time: 5.73491
Timestep Consumption Time: 0.83041
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.56532

Cumulative Model Updates: 19,192
Cumulative Timesteps: 320,201,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 320201954...
Checkpoint 320201954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.92438
Policy Entropy: 1.10731
Value Function Loss: 4.01265

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 8,921.96072
Overall Steps per Second: 7,922.32153

Timestep Collection Time: 5.60751
Timestep Consumption Time: 0.70756
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.31507

Cumulative Model Updates: 19,195
Cumulative Timesteps: 320,251,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.26630
Policy Entropy: 1.09205
Value Function Loss: 3.94298

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.06784

Collected Steps per Second: 8,853.12185
Overall Steps per Second: 7,675.79172

Timestep Collection Time: 5.64840
Timestep Consumption Time: 0.86636
PPO Batch Consumption Time: 0.04903
Total Iteration Time: 6.51477

Cumulative Model Updates: 19,198
Cumulative Timesteps: 320,301,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 320301990...
Checkpoint 320301990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.68101
Policy Entropy: 1.09873
Value Function Loss: 3.78625

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 8,816.32989
Overall Steps per Second: 7,666.19765

Timestep Collection Time: 5.67334
Timestep Consumption Time: 0.85115
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.52449

Cumulative Model Updates: 19,201
Cumulative Timesteps: 320,352,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.61346
Policy Entropy: 1.10745
Value Function Loss: 3.59742

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 8,759.16147
Overall Steps per Second: 7,507.83933

Timestep Collection Time: 5.70922
Timestep Consumption Time: 0.95155
PPO Batch Consumption Time: 0.04948
Total Iteration Time: 6.66077

Cumulative Model Updates: 19,204
Cumulative Timesteps: 320,402,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 320402016...
Checkpoint 320402016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.60407
Policy Entropy: 1.09408
Value Function Loss: 3.45067

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.06716

Collected Steps per Second: 8,896.23608
Overall Steps per Second: 7,706.17766

Timestep Collection Time: 5.62125
Timestep Consumption Time: 0.86809
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.48934

Cumulative Model Updates: 19,207
Cumulative Timesteps: 320,452,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.98344
Policy Entropy: 1.07556
Value Function Loss: 3.56652

Mean KL Divergence: 0.03774
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 8,695.55407
Overall Steps per Second: 7,732.84546

Timestep Collection Time: 5.75282
Timestep Consumption Time: 0.71620
PPO Batch Consumption Time: 0.03912
Total Iteration Time: 6.46903

Cumulative Model Updates: 19,210
Cumulative Timesteps: 320,502,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 320502048...
Checkpoint 320502048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.43669
Policy Entropy: 1.09642
Value Function Loss: 3.55069

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.08442

Collected Steps per Second: 8,956.76641
Overall Steps per Second: 7,616.40689

Timestep Collection Time: 5.58550
Timestep Consumption Time: 0.98295
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.56845

Cumulative Model Updates: 19,213
Cumulative Timesteps: 320,552,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.87492
Policy Entropy: 1.09193
Value Function Loss: 3.60620

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.08434

Collected Steps per Second: 8,811.56346
Overall Steps per Second: 7,726.04557

Timestep Collection Time: 5.67618
Timestep Consumption Time: 0.79751
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 6.47369

Cumulative Model Updates: 19,216
Cumulative Timesteps: 320,602,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 320602092...
Checkpoint 320602092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.07707
Policy Entropy: 1.08131
Value Function Loss: 3.39805

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.09087

Collected Steps per Second: 8,808.60888
Overall Steps per Second: 7,634.20518

Timestep Collection Time: 5.67717
Timestep Consumption Time: 0.87334
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.55052

Cumulative Model Updates: 19,219
Cumulative Timesteps: 320,652,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.42299
Policy Entropy: 1.08125
Value Function Loss: 3.40916

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.07900

Collected Steps per Second: 8,821.97316
Overall Steps per Second: 7,662.21170

Timestep Collection Time: 5.66767
Timestep Consumption Time: 0.85786
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.52553

Cumulative Model Updates: 19,222
Cumulative Timesteps: 320,702,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 320702100...
Checkpoint 320702100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.88895
Policy Entropy: 1.07266
Value Function Loss: 3.28160

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.07496

Collected Steps per Second: 8,777.62661
Overall Steps per Second: 7,706.49320

Timestep Collection Time: 5.69835
Timestep Consumption Time: 0.79202
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 6.49037

Cumulative Model Updates: 19,225
Cumulative Timesteps: 320,752,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.49008
Policy Entropy: 1.09050
Value Function Loss: 3.41728

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 8,755.38082
Overall Steps per Second: 7,618.09614

Timestep Collection Time: 5.71397
Timestep Consumption Time: 0.85302
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.56700

Cumulative Model Updates: 19,228
Cumulative Timesteps: 320,802,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 320802146...
Checkpoint 320802146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.20134
Policy Entropy: 1.08849
Value Function Loss: 3.34876

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 8,777.79847
Overall Steps per Second: 7,625.92196

Timestep Collection Time: 5.69664
Timestep Consumption Time: 0.86046
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 6.55711

Cumulative Model Updates: 19,231
Cumulative Timesteps: 320,852,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.81280
Policy Entropy: 1.07387
Value Function Loss: 3.56178

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 8,974.29989
Overall Steps per Second: 7,764.73008

Timestep Collection Time: 5.57392
Timestep Consumption Time: 0.86829
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.44221

Cumulative Model Updates: 19,234
Cumulative Timesteps: 320,902,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 320902172...
Checkpoint 320902172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.53606
Policy Entropy: 1.08396
Value Function Loss: 3.74742

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.16595
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.05482

Collected Steps per Second: 8,854.96355
Overall Steps per Second: 7,682.72373

Timestep Collection Time: 5.64791
Timestep Consumption Time: 0.86176
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 6.50967

Cumulative Model Updates: 19,237
Cumulative Timesteps: 320,952,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.17992
Policy Entropy: 1.08805
Value Function Loss: 3.75489

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 8,997.55840
Overall Steps per Second: 7,918.45502

Timestep Collection Time: 5.55862
Timestep Consumption Time: 0.75751
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.31613

Cumulative Model Updates: 19,240
Cumulative Timesteps: 321,002,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 321002198...
Checkpoint 321002198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.14868
Policy Entropy: 1.11088
Value Function Loss: 3.53744

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.05867

Collected Steps per Second: 8,800.23101
Overall Steps per Second: 7,646.43050

Timestep Collection Time: 5.68462
Timestep Consumption Time: 0.85778
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.54240

Cumulative Model Updates: 19,243
Cumulative Timesteps: 321,052,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.64448
Policy Entropy: 1.06407
Value Function Loss: 3.33922

Mean KL Divergence: 0.04781
SB3 Clip Fraction: 0.22525
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 8,742.42207
Overall Steps per Second: 7,556.69899

Timestep Collection Time: 5.72267
Timestep Consumption Time: 0.89795
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.62062

Cumulative Model Updates: 19,246
Cumulative Timesteps: 321,102,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 321102254...
Checkpoint 321102254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.31530
Policy Entropy: 1.09844
Value Function Loss: 3.32251

Mean KL Divergence: 0.03748
SB3 Clip Fraction: 0.20330
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.06948

Collected Steps per Second: 9,466.07077
Overall Steps per Second: 8,157.12451

Timestep Collection Time: 5.28456
Timestep Consumption Time: 0.84800
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.13255

Cumulative Model Updates: 19,249
Cumulative Timesteps: 321,152,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.51660
Policy Entropy: 1.06280
Value Function Loss: 3.43918

Mean KL Divergence: 0.04523
SB3 Clip Fraction: 0.21826
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 9,221.27148
Overall Steps per Second: 8,001.40533

Timestep Collection Time: 5.42311
Timestep Consumption Time: 0.82679
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.24990

Cumulative Model Updates: 19,252
Cumulative Timesteps: 321,202,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 321202286...
Checkpoint 321202286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.88146
Policy Entropy: 1.10088
Value Function Loss: 3.56922

Mean KL Divergence: 0.03140
SB3 Clip Fraction: 0.19161
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.05759

Collected Steps per Second: 9,228.91171
Overall Steps per Second: 8,046.79373

Timestep Collection Time: 5.42014
Timestep Consumption Time: 0.79625
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.21639

Cumulative Model Updates: 19,255
Cumulative Timesteps: 321,252,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.05499
Policy Entropy: 1.07879
Value Function Loss: 3.62768

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 9,196.35785
Overall Steps per Second: 7,941.84288

Timestep Collection Time: 5.43998
Timestep Consumption Time: 0.85931
PPO Batch Consumption Time: 0.04522
Total Iteration Time: 6.29929

Cumulative Model Updates: 19,258
Cumulative Timesteps: 321,302,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 321302336...
Checkpoint 321302336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.68084
Policy Entropy: 1.09033
Value Function Loss: 3.65115

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 8,673.95401
Overall Steps per Second: 7,555.94280

Timestep Collection Time: 5.76438
Timestep Consumption Time: 0.85292
PPO Batch Consumption Time: 0.04073
Total Iteration Time: 6.61731

Cumulative Model Updates: 19,261
Cumulative Timesteps: 321,352,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.19749
Policy Entropy: 1.09207
Value Function Loss: 3.43584

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.06722

Collected Steps per Second: 9,009.32717
Overall Steps per Second: 7,796.68352

Timestep Collection Time: 5.55269
Timestep Consumption Time: 0.86363
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.41632

Cumulative Model Updates: 19,264
Cumulative Timesteps: 321,402,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 321402362...
Checkpoint 321402362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.85955
Policy Entropy: 1.07828
Value Function Loss: 3.41579

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 8,763.58884
Overall Steps per Second: 7,648.13375

Timestep Collection Time: 5.70908
Timestep Consumption Time: 0.83265
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 6.54173

Cumulative Model Updates: 19,267
Cumulative Timesteps: 321,452,394

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.67835
Policy Entropy: 1.07974
Value Function Loss: 3.31275

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 8,812.52650
Overall Steps per Second: 7,782.88944

Timestep Collection Time: 5.67601
Timestep Consumption Time: 0.75091
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.42692

Cumulative Model Updates: 19,270
Cumulative Timesteps: 321,502,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 321502414...
Checkpoint 321502414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.67354
Policy Entropy: 1.09039
Value Function Loss: 3.26255

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 8,761.36880
Overall Steps per Second: 7,599.17025

Timestep Collection Time: 5.70893
Timestep Consumption Time: 0.87311
PPO Batch Consumption Time: 0.05269
Total Iteration Time: 6.58203

Cumulative Model Updates: 19,273
Cumulative Timesteps: 321,552,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.53432
Policy Entropy: 1.09789
Value Function Loss: 3.38393

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.05759

Collected Steps per Second: 8,596.95191
Overall Steps per Second: 7,547.56929

Timestep Collection Time: 5.81857
Timestep Consumption Time: 0.80899
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.62756

Cumulative Model Updates: 19,276
Cumulative Timesteps: 321,602,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 321602454...
Checkpoint 321602454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.56232
Policy Entropy: 1.08069
Value Function Loss: 3.36506

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.05442

Collected Steps per Second: 8,832.13059
Overall Steps per Second: 7,609.67582

Timestep Collection Time: 5.66273
Timestep Consumption Time: 0.90969
PPO Batch Consumption Time: 0.05174
Total Iteration Time: 6.57242

Cumulative Model Updates: 19,279
Cumulative Timesteps: 321,652,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.60923
Policy Entropy: 1.07843
Value Function Loss: 3.59255

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.16679
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 8,899.78985
Overall Steps per Second: 7,774.28400

Timestep Collection Time: 5.62103
Timestep Consumption Time: 0.81377
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.43480

Cumulative Model Updates: 19,282
Cumulative Timesteps: 321,702,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 321702494...
Checkpoint 321702494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.59004
Policy Entropy: 1.08692
Value Function Loss: 3.62297

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.05950

Collected Steps per Second: 8,793.37669
Overall Steps per Second: 7,773.22521

Timestep Collection Time: 5.68860
Timestep Consumption Time: 0.74657
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 6.43517

Cumulative Model Updates: 19,285
Cumulative Timesteps: 321,752,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.48960
Policy Entropy: 1.09263
Value Function Loss: 3.87147

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 8,701.51226
Overall Steps per Second: 7,580.57560

Timestep Collection Time: 5.74751
Timestep Consumption Time: 0.84988
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 6.59739

Cumulative Model Updates: 19,288
Cumulative Timesteps: 321,802,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 321802528...
Checkpoint 321802528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.43222
Policy Entropy: 1.05409
Value Function Loss: 3.88407

Mean KL Divergence: 0.04341
SB3 Clip Fraction: 0.19687
Policy Update Magnitude: 0.08129
Value Function Update Magnitude: 0.06210

Collected Steps per Second: 8,958.48309
Overall Steps per Second: 7,778.93149

Timestep Collection Time: 5.58153
Timestep Consumption Time: 0.84635
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.42788

Cumulative Model Updates: 19,291
Cumulative Timesteps: 321,852,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.21381
Policy Entropy: 1.08180
Value Function Loss: 3.82532

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.16415
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.06748

Collected Steps per Second: 9,076.47280
Overall Steps per Second: 7,874.47089

Timestep Collection Time: 5.50985
Timestep Consumption Time: 0.84105
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.35090

Cumulative Model Updates: 19,294
Cumulative Timesteps: 321,902,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 321902540...
Checkpoint 321902540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.09651
Policy Entropy: 1.06851
Value Function Loss: 3.66770

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.06135

Collected Steps per Second: 8,957.49061
Overall Steps per Second: 7,834.45185

Timestep Collection Time: 5.58237
Timestep Consumption Time: 0.80021
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 6.38258

Cumulative Model Updates: 19,297
Cumulative Timesteps: 321,952,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.30050
Policy Entropy: 1.06250
Value Function Loss: 3.50334

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.05283

Collected Steps per Second: 8,822.22642
Overall Steps per Second: 7,767.43867

Timestep Collection Time: 5.66886
Timestep Consumption Time: 0.76981
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 6.43867

Cumulative Model Updates: 19,300
Cumulative Timesteps: 322,002,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 322002556...
Checkpoint 322002556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.36334
Policy Entropy: 1.07869
Value Function Loss: 3.34250

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.16309
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.06162

Collected Steps per Second: 8,721.85657
Overall Steps per Second: 7,621.74069

Timestep Collection Time: 5.73272
Timestep Consumption Time: 0.82746
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 6.56018

Cumulative Model Updates: 19,303
Cumulative Timesteps: 322,052,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.89200
Policy Entropy: 1.09023
Value Function Loss: 3.38737

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.16789
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 8,905.48344
Overall Steps per Second: 7,775.42018

Timestep Collection Time: 5.61721
Timestep Consumption Time: 0.81639
PPO Batch Consumption Time: 0.04646
Total Iteration Time: 6.43361

Cumulative Model Updates: 19,306
Cumulative Timesteps: 322,102,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 322102580...
Checkpoint 322102580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.55464
Policy Entropy: 1.07349
Value Function Loss: 3.44023

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 8,993.87604
Overall Steps per Second: 7,848.83573

Timestep Collection Time: 5.55978
Timestep Consumption Time: 0.81110
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.37088

Cumulative Model Updates: 19,309
Cumulative Timesteps: 322,152,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.52349
Policy Entropy: 1.07448
Value Function Loss: 3.51398

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.05706

Collected Steps per Second: 8,999.63541
Overall Steps per Second: 7,820.20489

Timestep Collection Time: 5.55778
Timestep Consumption Time: 0.83822
PPO Batch Consumption Time: 0.04680
Total Iteration Time: 6.39600

Cumulative Model Updates: 19,312
Cumulative Timesteps: 322,202,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 322202602...
Checkpoint 322202602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.00408
Policy Entropy: 1.08390
Value Function Loss: 3.54066

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.04049
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 8,929.62008
Overall Steps per Second: 7,713.98529

Timestep Collection Time: 5.60158
Timestep Consumption Time: 0.88274
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 6.48433

Cumulative Model Updates: 19,315
Cumulative Timesteps: 322,252,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.79056
Policy Entropy: 1.09514
Value Function Loss: 3.56903

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.03907
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 9,146.16691
Overall Steps per Second: 7,881.47622

Timestep Collection Time: 5.46677
Timestep Consumption Time: 0.87722
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 6.34399

Cumulative Model Updates: 19,318
Cumulative Timesteps: 322,302,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 322302622...
Checkpoint 322302622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.18423
Policy Entropy: 1.07432
Value Function Loss: 3.58533

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.07766

Collected Steps per Second: 8,734.38780
Overall Steps per Second: 7,607.45045

Timestep Collection Time: 5.72748
Timestep Consumption Time: 0.84845
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.57592

Cumulative Model Updates: 19,321
Cumulative Timesteps: 322,352,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.76757
Policy Entropy: 1.06564
Value Function Loss: 3.45530

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.17844
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 9,265.37836
Overall Steps per Second: 7,957.63006

Timestep Collection Time: 5.39946
Timestep Consumption Time: 0.88734
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.28680

Cumulative Model Updates: 19,324
Cumulative Timesteps: 322,402,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 322402676...
Checkpoint 322402676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.20367
Policy Entropy: 1.07744
Value Function Loss: 3.41423

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.03991
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 8,941.11570
Overall Steps per Second: 7,748.02177

Timestep Collection Time: 5.59483
Timestep Consumption Time: 0.86153
PPO Batch Consumption Time: 0.05249
Total Iteration Time: 6.45636

Cumulative Model Updates: 19,327
Cumulative Timesteps: 322,452,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.01466
Policy Entropy: 1.08398
Value Function Loss: 3.31305

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.03622
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 8,870.07850
Overall Steps per Second: 7,858.39835

Timestep Collection Time: 5.63783
Timestep Consumption Time: 0.72581
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.36364

Cumulative Model Updates: 19,330
Cumulative Timesteps: 322,502,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 322502708...
Checkpoint 322502708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.17246
Policy Entropy: 1.06895
Value Function Loss: 3.46674

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.09212

Collected Steps per Second: 8,953.26136
Overall Steps per Second: 7,750.37267

Timestep Collection Time: 5.58679
Timestep Consumption Time: 0.86709
PPO Batch Consumption Time: 0.04046
Total Iteration Time: 6.45388

Cumulative Model Updates: 19,333
Cumulative Timesteps: 322,552,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.61316
Policy Entropy: 1.04808
Value Function Loss: 3.63896

Mean KL Divergence: 0.03075
SB3 Clip Fraction: 0.19183
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 9,020.38197
Overall Steps per Second: 7,748.60188

Timestep Collection Time: 5.54500
Timestep Consumption Time: 0.91010
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.45510

Cumulative Model Updates: 19,336
Cumulative Timesteps: 322,602,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 322602746...
Checkpoint 322602746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.12607
Policy Entropy: 1.06966
Value Function Loss: 3.62932

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.06419

Collected Steps per Second: 9,036.10262
Overall Steps per Second: 7,823.41885

Timestep Collection Time: 5.53513
Timestep Consumption Time: 0.85798
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 6.39311

Cumulative Model Updates: 19,339
Cumulative Timesteps: 322,652,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.11210
Policy Entropy: 1.05197
Value Function Loss: 3.57112

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.16692
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.05882

Collected Steps per Second: 9,015.60378
Overall Steps per Second: 7,639.47483

Timestep Collection Time: 5.54794
Timestep Consumption Time: 0.99937
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 6.54731

Cumulative Model Updates: 19,342
Cumulative Timesteps: 322,702,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 322702780...
Checkpoint 322702780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.07250
Policy Entropy: 1.06012
Value Function Loss: 3.47399

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.03922
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 8,710.68006
Overall Steps per Second: 7,690.99209

Timestep Collection Time: 5.74329
Timestep Consumption Time: 0.76146
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.50475

Cumulative Model Updates: 19,345
Cumulative Timesteps: 322,752,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.77709
Policy Entropy: 1.07074
Value Function Loss: 3.55858

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.16356
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 9,026.59955
Overall Steps per Second: 7,818.07782

Timestep Collection Time: 5.54029
Timestep Consumption Time: 0.85642
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 6.39671

Cumulative Model Updates: 19,348
Cumulative Timesteps: 322,802,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 322802818...
Checkpoint 322802818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.65139
Policy Entropy: 1.07295
Value Function Loss: 3.63943

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16641
Policy Update Magnitude: 0.03835
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 8,802.06194
Overall Steps per Second: 7,608.80498

Timestep Collection Time: 5.68071
Timestep Consumption Time: 0.89088
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 6.57160

Cumulative Model Updates: 19,351
Cumulative Timesteps: 322,852,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.20124
Policy Entropy: 1.06331
Value Function Loss: 3.56023

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.04755

Collected Steps per Second: 9,030.26341
Overall Steps per Second: 7,836.67076

Timestep Collection Time: 5.53937
Timestep Consumption Time: 0.84369
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.38307

Cumulative Model Updates: 19,354
Cumulative Timesteps: 322,902,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 322902842...
Checkpoint 322902842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.94944
Policy Entropy: 1.05071
Value Function Loss: 3.50154

Mean KL Divergence: 0.03074
SB3 Clip Fraction: 0.18343
Policy Update Magnitude: 0.04480
Value Function Update Magnitude: 0.04278

Collected Steps per Second: 8,935.38584
Overall Steps per Second: 7,671.21848

Timestep Collection Time: 5.59909
Timestep Consumption Time: 0.92269
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.52178

Cumulative Model Updates: 19,357
Cumulative Timesteps: 322,952,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.48025
Policy Entropy: 1.07019
Value Function Loss: 3.22176

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.04389

Collected Steps per Second: 9,279.99006
Overall Steps per Second: 8,096.69901

Timestep Collection Time: 5.39031
Timestep Consumption Time: 0.78777
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 6.17807

Cumulative Model Updates: 19,360
Cumulative Timesteps: 323,002,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 323002894...
Checkpoint 323002894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.57066
Policy Entropy: 1.07058
Value Function Loss: 3.27224

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.04680

Collected Steps per Second: 9,408.30653
Overall Steps per Second: 8,068.58409

Timestep Collection Time: 5.31637
Timestep Consumption Time: 0.88274
PPO Batch Consumption Time: 0.04808
Total Iteration Time: 6.19911

Cumulative Model Updates: 19,363
Cumulative Timesteps: 323,052,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.95549
Policy Entropy: 1.05546
Value Function Loss: 3.23847

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16009
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07780

Collected Steps per Second: 9,369.38187
Overall Steps per Second: 8,002.33435

Timestep Collection Time: 5.33952
Timestep Consumption Time: 0.91216
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 6.25168

Cumulative Model Updates: 19,366
Cumulative Timesteps: 323,102,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 323102940...
Checkpoint 323102940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.62468
Policy Entropy: 1.07893
Value Function Loss: 3.44575

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 9,198.01630
Overall Steps per Second: 7,970.58715

Timestep Collection Time: 5.43704
Timestep Consumption Time: 0.83728
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.27432

Cumulative Model Updates: 19,369
Cumulative Timesteps: 323,152,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.94403
Policy Entropy: 1.09357
Value Function Loss: 3.47421

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 8,631.14814
Overall Steps per Second: 7,512.51810

Timestep Collection Time: 5.79598
Timestep Consumption Time: 0.86303
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.65902

Cumulative Model Updates: 19,372
Cumulative Timesteps: 323,202,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 323202976...
Checkpoint 323202976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.06594
Policy Entropy: 1.07873
Value Function Loss: 3.69473

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.06287

Collected Steps per Second: 8,925.61250
Overall Steps per Second: 7,834.10127

Timestep Collection Time: 5.60320
Timestep Consumption Time: 0.78068
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 6.38388

Cumulative Model Updates: 19,375
Cumulative Timesteps: 323,252,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.46617
Policy Entropy: 1.08581
Value Function Loss: 3.68490

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.06460

Collected Steps per Second: 8,982.49423
Overall Steps per Second: 7,796.29082

Timestep Collection Time: 5.56661
Timestep Consumption Time: 0.84696
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.41356

Cumulative Model Updates: 19,378
Cumulative Timesteps: 323,302,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 323302990...
Checkpoint 323302990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.48901
Policy Entropy: 1.09330
Value Function Loss: 3.65634

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 8,701.56518
Overall Steps per Second: 7,616.73793

Timestep Collection Time: 5.74724
Timestep Consumption Time: 0.81856
PPO Batch Consumption Time: 0.04323
Total Iteration Time: 6.56580

Cumulative Model Updates: 19,381
Cumulative Timesteps: 323,353,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.61061
Policy Entropy: 1.10038
Value Function Loss: 3.49035

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.06225

Collected Steps per Second: 8,793.83923
Overall Steps per Second: 7,594.43056

Timestep Collection Time: 5.68625
Timestep Consumption Time: 0.89805
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 6.58430

Cumulative Model Updates: 19,384
Cumulative Timesteps: 323,403,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 323403004...
Checkpoint 323403004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.39552
Policy Entropy: 1.08714
Value Function Loss: 3.49662

Mean KL Divergence: 0.04222
SB3 Clip Fraction: 0.17313
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 8,636.50488
Overall Steps per Second: 7,529.25002

Timestep Collection Time: 5.79123
Timestep Consumption Time: 0.85166
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 6.64289

Cumulative Model Updates: 19,387
Cumulative Timesteps: 323,453,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.34954
Policy Entropy: 1.08529
Value Function Loss: 3.65286

Mean KL Divergence: 0.03930
SB3 Clip Fraction: 0.19972
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 8,800.47081
Overall Steps per Second: 7,801.62507

Timestep Collection Time: 5.68447
Timestep Consumption Time: 0.72779
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.41225

Cumulative Model Updates: 19,390
Cumulative Timesteps: 323,503,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 323503046...
Checkpoint 323503046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.70016
Policy Entropy: 1.10037
Value Function Loss: 3.60664

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.16504
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 8,878.84988
Overall Steps per Second: 7,715.88174

Timestep Collection Time: 5.63181
Timestep Consumption Time: 0.84885
PPO Batch Consumption Time: 0.05118
Total Iteration Time: 6.48066

Cumulative Model Updates: 19,393
Cumulative Timesteps: 323,553,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.68060
Policy Entropy: 1.09517
Value Function Loss: 3.73106

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.05567

Collected Steps per Second: 8,798.52994
Overall Steps per Second: 7,714.02232

Timestep Collection Time: 5.68481
Timestep Consumption Time: 0.79922
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.48404

Cumulative Model Updates: 19,396
Cumulative Timesteps: 323,603,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 323603068...
Checkpoint 323603068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.90989
Policy Entropy: 1.09254
Value Function Loss: 3.49544

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.05928

Collected Steps per Second: 8,802.13516
Overall Steps per Second: 7,570.49681

Timestep Collection Time: 5.68271
Timestep Consumption Time: 0.92452
PPO Batch Consumption Time: 0.04735
Total Iteration Time: 6.60723

Cumulative Model Updates: 19,399
Cumulative Timesteps: 323,653,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.90907
Policy Entropy: 1.09068
Value Function Loss: 3.55716

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 9,026.15751
Overall Steps per Second: 7,845.79209

Timestep Collection Time: 5.54189
Timestep Consumption Time: 0.83375
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.37565

Cumulative Model Updates: 19,402
Cumulative Timesteps: 323,703,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 323703110...
Checkpoint 323703110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.45244
Policy Entropy: 1.10755
Value Function Loss: 3.52722

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.04574

Collected Steps per Second: 8,914.41221
Overall Steps per Second: 7,798.27218

Timestep Collection Time: 5.61024
Timestep Consumption Time: 0.80297
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 6.41322

Cumulative Model Updates: 19,405
Cumulative Timesteps: 323,753,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.95219
Policy Entropy: 1.09651
Value Function Loss: 3.59751

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.03862

Collected Steps per Second: 8,958.21090
Overall Steps per Second: 7,782.11303

Timestep Collection Time: 5.58326
Timestep Consumption Time: 0.84379
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.42705

Cumulative Model Updates: 19,408
Cumulative Timesteps: 323,803,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 323803138...
Checkpoint 323803138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.88431
Policy Entropy: 1.09521
Value Function Loss: 3.52774

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.04074

Collected Steps per Second: 8,889.96994
Overall Steps per Second: 7,665.01547

Timestep Collection Time: 5.62747
Timestep Consumption Time: 0.89933
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.52680

Cumulative Model Updates: 19,411
Cumulative Timesteps: 323,853,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.99686
Policy Entropy: 1.08134
Value Function Loss: 3.35853

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.04092

Collected Steps per Second: 8,685.91877
Overall Steps per Second: 7,646.56307

Timestep Collection Time: 5.75875
Timestep Consumption Time: 0.78276
PPO Batch Consumption Time: 0.05189
Total Iteration Time: 6.54150

Cumulative Model Updates: 19,414
Cumulative Timesteps: 323,903,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 323903186...
Checkpoint 323903186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.53217
Policy Entropy: 1.08833
Value Function Loss: 3.40402

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.04972

Collected Steps per Second: 8,954.87029
Overall Steps per Second: 7,782.60483

Timestep Collection Time: 5.58623
Timestep Consumption Time: 0.84143
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.42767

Cumulative Model Updates: 19,417
Cumulative Timesteps: 323,953,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.89514
Policy Entropy: 1.09664
Value Function Loss: 3.29176

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 9,027.09834
Overall Steps per Second: 7,947.21018

Timestep Collection Time: 5.53888
Timestep Consumption Time: 0.75264
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 6.29152

Cumulative Model Updates: 19,420
Cumulative Timesteps: 324,003,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 324003210...
Checkpoint 324003210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.67902
Policy Entropy: 1.07965
Value Function Loss: 3.49965

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 9,133.40710
Overall Steps per Second: 7,901.10855

Timestep Collection Time: 5.47572
Timestep Consumption Time: 0.85402
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.32974

Cumulative Model Updates: 19,423
Cumulative Timesteps: 324,053,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.25072
Policy Entropy: 1.09620
Value Function Loss: 3.41557

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.15524
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.03927

Collected Steps per Second: 8,926.03696
Overall Steps per Second: 7,652.73596

Timestep Collection Time: 5.60450
Timestep Consumption Time: 0.93251
PPO Batch Consumption Time: 0.04789
Total Iteration Time: 6.53701

Cumulative Model Updates: 19,426
Cumulative Timesteps: 324,103,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 324103248...
Checkpoint 324103248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.40573
Policy Entropy: 1.10120
Value Function Loss: 3.60618

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.04606

Collected Steps per Second: 8,895.69865
Overall Steps per Second: 7,735.72684

Timestep Collection Time: 5.62317
Timestep Consumption Time: 0.84319
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.46636

Cumulative Model Updates: 19,429
Cumulative Timesteps: 324,153,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.88261
Policy Entropy: 1.09760
Value Function Loss: 3.60549

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.05235

Collected Steps per Second: 8,948.78189
Overall Steps per Second: 7,759.37274

Timestep Collection Time: 5.58847
Timestep Consumption Time: 0.85664
PPO Batch Consumption Time: 0.04588
Total Iteration Time: 6.44511

Cumulative Model Updates: 19,432
Cumulative Timesteps: 324,203,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 324203280...
Checkpoint 324203280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.23220
Policy Entropy: 1.08966
Value Function Loss: 3.71565

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.17383
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.05834

Collected Steps per Second: 8,921.69510
Overall Steps per Second: 7,856.61170

Timestep Collection Time: 5.60723
Timestep Consumption Time: 0.76015
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.36738

Cumulative Model Updates: 19,435
Cumulative Timesteps: 324,253,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.04988
Policy Entropy: 1.09360
Value Function Loss: 3.54694

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.05798

Collected Steps per Second: 8,897.48165
Overall Steps per Second: 7,729.38536

Timestep Collection Time: 5.62271
Timestep Consumption Time: 0.84973
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.47244

Cumulative Model Updates: 19,438
Cumulative Timesteps: 324,303,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 324303334...
Checkpoint 324303334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.92822
Policy Entropy: 1.09939
Value Function Loss: 3.44961

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 8,630.97053
Overall Steps per Second: 7,602.85275

Timestep Collection Time: 5.79541
Timestep Consumption Time: 0.78370
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.57911

Cumulative Model Updates: 19,441
Cumulative Timesteps: 324,353,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.71582
Policy Entropy: 1.04556
Value Function Loss: 3.40662

Mean KL Divergence: 0.06569
SB3 Clip Fraction: 0.25756
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.06369

Collected Steps per Second: 8,983.12198
Overall Steps per Second: 7,737.45217

Timestep Collection Time: 5.56844
Timestep Consumption Time: 0.89648
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.46492

Cumulative Model Updates: 19,444
Cumulative Timesteps: 324,403,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 324403376...
Checkpoint 324403376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.57454
Policy Entropy: 1.08307
Value Function Loss: 3.60503

Mean KL Divergence: 0.04377
SB3 Clip Fraction: 0.24408
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 8,821.40382
Overall Steps per Second: 7,650.88732

Timestep Collection Time: 5.66803
Timestep Consumption Time: 0.86716
PPO Batch Consumption Time: 0.04996
Total Iteration Time: 6.53519

Cumulative Model Updates: 19,447
Cumulative Timesteps: 324,453,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.26321
Policy Entropy: 1.05119
Value Function Loss: 3.61730

Mean KL Divergence: 0.06441
SB3 Clip Fraction: 0.26905
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.05210

Collected Steps per Second: 8,825.39962
Overall Steps per Second: 7,768.21358

Timestep Collection Time: 5.66751
Timestep Consumption Time: 0.77130
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 6.43880

Cumulative Model Updates: 19,450
Cumulative Timesteps: 324,503,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 324503394...
Checkpoint 324503394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.77767
Policy Entropy: 1.09423
Value Function Loss: 3.55140

Mean KL Divergence: 0.05719
SB3 Clip Fraction: 0.26633
Policy Update Magnitude: 0.03578
Value Function Update Magnitude: 0.04802

Collected Steps per Second: 8,915.08868
Overall Steps per Second: 7,729.55593

Timestep Collection Time: 5.60982
Timestep Consumption Time: 0.86041
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.47023

Cumulative Model Updates: 19,453
Cumulative Timesteps: 324,553,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.44759
Policy Entropy: 1.07311
Value Function Loss: 3.38912

Mean KL Divergence: 0.04782
SB3 Clip Fraction: 0.22582
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.04648

Collected Steps per Second: 8,631.24812
Overall Steps per Second: 7,513.55385

Timestep Collection Time: 5.79499
Timestep Consumption Time: 0.86205
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.65704

Cumulative Model Updates: 19,456
Cumulative Timesteps: 324,603,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 324603424...
Checkpoint 324603424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.16517
Policy Entropy: 1.10280
Value Function Loss: 3.34897

Mean KL Divergence: 0.04530
SB3 Clip Fraction: 0.22327
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.04772

Collected Steps per Second: 8,913.50856
Overall Steps per Second: 7,675.75021

Timestep Collection Time: 5.61148
Timestep Consumption Time: 0.90488
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 6.51637

Cumulative Model Updates: 19,459
Cumulative Timesteps: 324,653,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.81289
Policy Entropy: 1.08542
Value Function Loss: 3.45450

Mean KL Divergence: 0.02585
SB3 Clip Fraction: 0.18473
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.04962

Collected Steps per Second: 8,840.61875
Overall Steps per Second: 7,734.72285

Timestep Collection Time: 5.65865
Timestep Consumption Time: 0.80906
PPO Batch Consumption Time: 0.04019
Total Iteration Time: 6.46772

Cumulative Model Updates: 19,462
Cumulative Timesteps: 324,703,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 324703468...
Checkpoint 324703468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.12254
Policy Entropy: 1.09685
Value Function Loss: 3.52833

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.05191

Collected Steps per Second: 8,852.94321
Overall Steps per Second: 7,719.69769

Timestep Collection Time: 5.65055
Timestep Consumption Time: 0.82950
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 6.48005

Cumulative Model Updates: 19,465
Cumulative Timesteps: 324,753,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.54900
Policy Entropy: 1.10458
Value Function Loss: 3.60515

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.05189

Collected Steps per Second: 9,213.16963
Overall Steps per Second: 7,835.77185

Timestep Collection Time: 5.42853
Timestep Consumption Time: 0.95425
PPO Batch Consumption Time: 0.04924
Total Iteration Time: 6.38278

Cumulative Model Updates: 19,468
Cumulative Timesteps: 324,803,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 324803506...
Checkpoint 324803506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.47498
Policy Entropy: 1.08388
Value Function Loss: 3.55470

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.05117

Collected Steps per Second: 8,812.51431
Overall Steps per Second: 7,653.89715

Timestep Collection Time: 5.67398
Timestep Consumption Time: 0.85890
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 6.53288

Cumulative Model Updates: 19,471
Cumulative Timesteps: 324,853,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.57531
Policy Entropy: 1.09941
Value Function Loss: 3.63409

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.16189
Policy Update Magnitude: 0.04077
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 9,422.17386
Overall Steps per Second: 8,135.69384

Timestep Collection Time: 5.30854
Timestep Consumption Time: 0.83943
PPO Batch Consumption Time: 0.04843
Total Iteration Time: 6.14797

Cumulative Model Updates: 19,474
Cumulative Timesteps: 324,903,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 324903526...
Checkpoint 324903526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.59372
Policy Entropy: 1.09667
Value Function Loss: 3.48715

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.05307

Collected Steps per Second: 9,154.14359
Overall Steps per Second: 7,919.71622

Timestep Collection Time: 5.46310
Timestep Consumption Time: 0.85152
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 6.31462

Cumulative Model Updates: 19,477
Cumulative Timesteps: 324,953,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.69079
Policy Entropy: 1.09129
Value Function Loss: 3.59745

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.05198

Collected Steps per Second: 8,923.65265
Overall Steps per Second: 7,828.62003

Timestep Collection Time: 5.60443
Timestep Consumption Time: 0.78392
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 6.38835

Cumulative Model Updates: 19,480
Cumulative Timesteps: 325,003,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 325003548...
Checkpoint 325003548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.82057
Policy Entropy: 1.09953
Value Function Loss: 3.46753

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.05157

Collected Steps per Second: 8,520.84504
Overall Steps per Second: 7,452.97667

Timestep Collection Time: 5.86796
Timestep Consumption Time: 0.84077
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.70873

Cumulative Model Updates: 19,483
Cumulative Timesteps: 325,053,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.88246
Policy Entropy: 1.10743
Value Function Loss: 3.45927

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.05435

Collected Steps per Second: 8,802.03315
Overall Steps per Second: 7,683.44383

Timestep Collection Time: 5.68096
Timestep Consumption Time: 0.82706
PPO Batch Consumption Time: 0.04766
Total Iteration Time: 6.50802

Cumulative Model Updates: 19,486
Cumulative Timesteps: 325,103,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 325103552...
Checkpoint 325103552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.05153
Policy Entropy: 1.10649
Value Function Loss: 3.30306

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.05271

Collected Steps per Second: 8,931.81211
Overall Steps per Second: 7,745.40965

Timestep Collection Time: 5.59819
Timestep Consumption Time: 0.85750
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.45569

Cumulative Model Updates: 19,489
Cumulative Timesteps: 325,153,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.61796
Policy Entropy: 1.08397
Value Function Loss: 3.40521

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.04854

Collected Steps per Second: 9,027.65468
Overall Steps per Second: 7,861.48351

Timestep Collection Time: 5.54142
Timestep Consumption Time: 0.82201
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 6.36343

Cumulative Model Updates: 19,492
Cumulative Timesteps: 325,203,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 325203580...
Checkpoint 325203580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.93997
Policy Entropy: 1.08039
Value Function Loss: 3.41892

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 8,886.66627
Overall Steps per Second: 7,827.02990

Timestep Collection Time: 5.62821
Timestep Consumption Time: 0.76196
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 6.39016

Cumulative Model Updates: 19,495
Cumulative Timesteps: 325,253,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.73051
Policy Entropy: 1.09299
Value Function Loss: 3.54984

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 8,640.76378
Overall Steps per Second: 7,550.41634

Timestep Collection Time: 5.78953
Timestep Consumption Time: 0.83606
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 6.62559

Cumulative Model Updates: 19,498
Cumulative Timesteps: 325,303,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 325303622...
Checkpoint 325303622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.61574
Policy Entropy: 1.10333
Value Function Loss: 3.70972

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.05373

Collected Steps per Second: 8,734.75323
Overall Steps per Second: 7,671.25226

Timestep Collection Time: 5.72632
Timestep Consumption Time: 0.79387
PPO Batch Consumption Time: 0.04744
Total Iteration Time: 6.52019

Cumulative Model Updates: 19,501
Cumulative Timesteps: 325,353,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.75405
Policy Entropy: 1.09892
Value Function Loss: 3.79372

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.04743

Collected Steps per Second: 9,074.76563
Overall Steps per Second: 7,892.07262

Timestep Collection Time: 5.51155
Timestep Consumption Time: 0.82595
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.33750

Cumulative Model Updates: 19,504
Cumulative Timesteps: 325,403,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 325403656...
Checkpoint 325403656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.02287
Policy Entropy: 1.09109
Value Function Loss: 3.79976

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.05550

Collected Steps per Second: 8,832.26270
Overall Steps per Second: 7,664.89731

Timestep Collection Time: 5.66106
Timestep Consumption Time: 0.86218
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.52324

Cumulative Model Updates: 19,507
Cumulative Timesteps: 325,453,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.74565
Policy Entropy: 1.09478
Value Function Loss: 3.67941

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.06077

Collected Steps per Second: 8,482.16503
Overall Steps per Second: 7,521.33663

Timestep Collection Time: 5.89755
Timestep Consumption Time: 0.75339
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 6.65095

Cumulative Model Updates: 19,510
Cumulative Timesteps: 325,503,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 325503680...
Checkpoint 325503680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.18432
Policy Entropy: 1.10398
Value Function Loss: 3.68035

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 8,966.97937
Overall Steps per Second: 7,794.54840

Timestep Collection Time: 5.57646
Timestep Consumption Time: 0.83879
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 6.41525

Cumulative Model Updates: 19,513
Cumulative Timesteps: 325,553,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.78531
Policy Entropy: 1.11754
Value Function Loss: 3.70923

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 8,727.41188
Overall Steps per Second: 7,620.64220

Timestep Collection Time: 5.73045
Timestep Consumption Time: 0.83225
PPO Batch Consumption Time: 0.05043
Total Iteration Time: 6.56270

Cumulative Model Updates: 19,516
Cumulative Timesteps: 325,603,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 325603696...
Checkpoint 325603696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.68485
Policy Entropy: 1.11487
Value Function Loss: 3.54792

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.04359

Collected Steps per Second: 8,988.37395
Overall Steps per Second: 7,778.81140

Timestep Collection Time: 5.56474
Timestep Consumption Time: 0.86529
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.43003

Cumulative Model Updates: 19,519
Cumulative Timesteps: 325,653,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.24308
Policy Entropy: 1.11346
Value Function Loss: 3.41961

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.04640

Collected Steps per Second: 9,014.15784
Overall Steps per Second: 7,843.59986

Timestep Collection Time: 5.54994
Timestep Consumption Time: 0.82826
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.37819

Cumulative Model Updates: 19,522
Cumulative Timesteps: 325,703,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 325703742...
Checkpoint 325703742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.42302
Policy Entropy: 1.12609
Value Function Loss: 3.32207

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.05478

Collected Steps per Second: 8,663.50868
Overall Steps per Second: 7,651.19148

Timestep Collection Time: 5.77156
Timestep Consumption Time: 0.76363
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.53519

Cumulative Model Updates: 19,525
Cumulative Timesteps: 325,753,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.45105
Policy Entropy: 1.12447
Value Function Loss: 3.39430

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 8,987.49862
Overall Steps per Second: 7,735.32443

Timestep Collection Time: 5.56618
Timestep Consumption Time: 0.90104
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 6.46721

Cumulative Model Updates: 19,528
Cumulative Timesteps: 325,803,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 325803770...
Checkpoint 325803770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.13995
Policy Entropy: 1.12762
Value Function Loss: 3.51442

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.06865

Collected Steps per Second: 8,415.28775
Overall Steps per Second: 7,375.46856

Timestep Collection Time: 5.94394
Timestep Consumption Time: 0.83800
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 6.78194

Cumulative Model Updates: 19,531
Cumulative Timesteps: 325,853,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.44195
Policy Entropy: 1.10907
Value Function Loss: 3.53295

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.06846

Collected Steps per Second: 9,198.06100
Overall Steps per Second: 7,926.01762

Timestep Collection Time: 5.43832
Timestep Consumption Time: 0.87279
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.31111

Cumulative Model Updates: 19,534
Cumulative Timesteps: 325,903,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 325903812...
Checkpoint 325903812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.05606
Policy Entropy: 1.10071
Value Function Loss: 3.57251

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 8,703.01972
Overall Steps per Second: 7,281.17868

Timestep Collection Time: 5.74812
Timestep Consumption Time: 1.12247
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 6.87059

Cumulative Model Updates: 19,537
Cumulative Timesteps: 325,953,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.73728
Policy Entropy: 1.11629
Value Function Loss: 3.47716

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.05909

Collected Steps per Second: 8,922.64255
Overall Steps per Second: 7,765.82451

Timestep Collection Time: 5.60619
Timestep Consumption Time: 0.83511
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 6.44130

Cumulative Model Updates: 19,540
Cumulative Timesteps: 326,003,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 326003860...
Checkpoint 326003860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.00184
Policy Entropy: 1.11441
Value Function Loss: 3.39465

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 8,934.95616
Overall Steps per Second: 7,691.55390

Timestep Collection Time: 5.59846
Timestep Consumption Time: 0.90504
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.50350

Cumulative Model Updates: 19,543
Cumulative Timesteps: 326,053,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.40624
Policy Entropy: 1.09411
Value Function Loss: 3.28648

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.06489

Collected Steps per Second: 8,769.38486
Overall Steps per Second: 7,647.51233

Timestep Collection Time: 5.70165
Timestep Consumption Time: 0.83642
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.53807

Cumulative Model Updates: 19,546
Cumulative Timesteps: 326,103,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 326103882...
Checkpoint 326103882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.38881
Policy Entropy: 1.08253
Value Function Loss: 3.49397

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.07022
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 8,874.05979
Overall Steps per Second: 7,735.30297

Timestep Collection Time: 5.63553
Timestep Consumption Time: 0.82964
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.46516

Cumulative Model Updates: 19,549
Cumulative Timesteps: 326,153,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.68789
Policy Entropy: 1.09012
Value Function Loss: 3.66403

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 8,752.10804
Overall Steps per Second: 7,661.05411

Timestep Collection Time: 5.71474
Timestep Consumption Time: 0.81387
PPO Batch Consumption Time: 0.04090
Total Iteration Time: 6.52861

Cumulative Model Updates: 19,552
Cumulative Timesteps: 326,203,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 326203908...
Checkpoint 326203908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.02245
Policy Entropy: 1.11186
Value Function Loss: 3.70954

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 8,695.33860
Overall Steps per Second: 7,655.38936

Timestep Collection Time: 5.75136
Timestep Consumption Time: 0.78130
PPO Batch Consumption Time: 0.04862
Total Iteration Time: 6.53265

Cumulative Model Updates: 19,555
Cumulative Timesteps: 326,253,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.84094
Policy Entropy: 1.12460
Value Function Loss: 3.72252

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.05510

Collected Steps per Second: 8,998.24434
Overall Steps per Second: 7,815.10796

Timestep Collection Time: 5.55864
Timestep Consumption Time: 0.84153
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.40017

Cumulative Model Updates: 19,558
Cumulative Timesteps: 326,303,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 326303936...
Checkpoint 326303936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.70846
Policy Entropy: 1.12831
Value Function Loss: 3.48211

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 8,761.91619
Overall Steps per Second: 7,566.96427

Timestep Collection Time: 5.70880
Timestep Consumption Time: 0.90152
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 6.61031

Cumulative Model Updates: 19,561
Cumulative Timesteps: 326,353,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.67043
Policy Entropy: 1.12195
Value Function Loss: 3.54464

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.05565

Collected Steps per Second: 8,898.29254
Overall Steps per Second: 7,739.68382

Timestep Collection Time: 5.62108
Timestep Consumption Time: 0.84146
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.46254

Cumulative Model Updates: 19,564
Cumulative Timesteps: 326,403,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 326403974...
Checkpoint 326403974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.39736
Policy Entropy: 1.12411
Value Function Loss: 3.50700

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 8,549.26848
Overall Steps per Second: 7,495.44134

Timestep Collection Time: 5.85033
Timestep Consumption Time: 0.82253
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.67286

Cumulative Model Updates: 19,567
Cumulative Timesteps: 326,453,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.02123
Policy Entropy: 1.12125
Value Function Loss: 3.65862

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.06664

Collected Steps per Second: 8,930.18753
Overall Steps per Second: 7,835.74285

Timestep Collection Time: 5.60100
Timestep Consumption Time: 0.78231
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.38331

Cumulative Model Updates: 19,570
Cumulative Timesteps: 326,504,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 326504008...
Checkpoint 326504008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.41588
Policy Entropy: 1.11770
Value Function Loss: 3.66768

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 8,835.49351
Overall Steps per Second: 7,630.84412

Timestep Collection Time: 5.66103
Timestep Consumption Time: 0.89368
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 6.55471

Cumulative Model Updates: 19,573
Cumulative Timesteps: 326,554,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.63019
Policy Entropy: 1.12236
Value Function Loss: 3.82977

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 9,058.76124
Overall Steps per Second: 7,855.41711

Timestep Collection Time: 5.52261
Timestep Consumption Time: 0.84599
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.36860

Cumulative Model Updates: 19,576
Cumulative Timesteps: 326,604,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 326604054...
Checkpoint 326604054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.19282
Policy Entropy: 1.12287
Value Function Loss: 3.83021

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.09571

Collected Steps per Second: 9,039.83683
Overall Steps per Second: 7,795.20189

Timestep Collection Time: 5.53218
Timestep Consumption Time: 0.88331
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.41548

Cumulative Model Updates: 19,579
Cumulative Timesteps: 326,654,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.61214
Policy Entropy: 1.13712
Value Function Loss: 3.81356

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 9,054.05225
Overall Steps per Second: 7,773.24669

Timestep Collection Time: 5.52526
Timestep Consumption Time: 0.91040
PPO Batch Consumption Time: 0.06575
Total Iteration Time: 6.43566

Cumulative Model Updates: 19,582
Cumulative Timesteps: 326,704,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 326704090...
Checkpoint 326704090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.59576
Policy Entropy: 1.13488
Value Function Loss: 3.77421

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 9,187.17900
Overall Steps per Second: 7,997.36756

Timestep Collection Time: 5.44324
Timestep Consumption Time: 0.80982
PPO Batch Consumption Time: 0.05895
Total Iteration Time: 6.25306

Cumulative Model Updates: 19,585
Cumulative Timesteps: 326,754,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.14954
Policy Entropy: 1.13782
Value Function Loss: 3.91818

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 9,466.92813
Overall Steps per Second: 8,084.69366

Timestep Collection Time: 5.28302
Timestep Consumption Time: 0.90323
PPO Batch Consumption Time: 0.04932
Total Iteration Time: 6.18626

Cumulative Model Updates: 19,588
Cumulative Timesteps: 326,804,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 326804112...
Checkpoint 326804112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.40720
Policy Entropy: 1.13470
Value Function Loss: 4.01824

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.15506
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 8,957.61036
Overall Steps per Second: 7,787.95675

Timestep Collection Time: 5.58207
Timestep Consumption Time: 0.83836
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 6.42043

Cumulative Model Updates: 19,591
Cumulative Timesteps: 326,854,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.03728
Policy Entropy: 1.14610
Value Function Loss: 3.96300

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.07176

Collected Steps per Second: 8,893.67479
Overall Steps per Second: 7,765.35128

Timestep Collection Time: 5.62467
Timestep Consumption Time: 0.81728
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.44195

Cumulative Model Updates: 19,594
Cumulative Timesteps: 326,904,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 326904138...
Checkpoint 326904138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.13841
Policy Entropy: 1.14787
Value Function Loss: 3.81383

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 9,047.17704
Overall Steps per Second: 7,910.95251

Timestep Collection Time: 5.52769
Timestep Consumption Time: 0.79392
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.32162

Cumulative Model Updates: 19,597
Cumulative Timesteps: 326,954,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.16534
Policy Entropy: 1.15060
Value Function Loss: 3.85593

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 8,763.30235
Overall Steps per Second: 7,705.94126

Timestep Collection Time: 5.70607
Timestep Consumption Time: 0.78295
PPO Batch Consumption Time: 0.05201
Total Iteration Time: 6.48902

Cumulative Model Updates: 19,600
Cumulative Timesteps: 327,004,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 327004152...
Checkpoint 327004152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.30797
Policy Entropy: 1.15335
Value Function Loss: 3.72449

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 8,872.93678
Overall Steps per Second: 7,708.17211

Timestep Collection Time: 5.63804
Timestep Consumption Time: 0.85195
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.49000

Cumulative Model Updates: 19,603
Cumulative Timesteps: 327,054,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.17543
Policy Entropy: 1.14894
Value Function Loss: 3.61270

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 8,805.23063
Overall Steps per Second: 7,706.74655

Timestep Collection Time: 5.67981
Timestep Consumption Time: 0.80957
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.48938

Cumulative Model Updates: 19,606
Cumulative Timesteps: 327,104,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 327104190...
Checkpoint 327104190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.82921
Policy Entropy: 1.16379
Value Function Loss: 3.64955

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.08215

Collected Steps per Second: 8,730.91746
Overall Steps per Second: 7,608.62598

Timestep Collection Time: 5.72929
Timestep Consumption Time: 0.84509
PPO Batch Consumption Time: 0.04758
Total Iteration Time: 6.57438

Cumulative Model Updates: 19,609
Cumulative Timesteps: 327,154,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.15991
Policy Entropy: 1.15803
Value Function Loss: 3.70635

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 8,901.29664
Overall Steps per Second: 7,782.72821

Timestep Collection Time: 5.61986
Timestep Consumption Time: 0.80771
PPO Batch Consumption Time: 0.03952
Total Iteration Time: 6.42757

Cumulative Model Updates: 19,612
Cumulative Timesteps: 327,204,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 327204236...
Checkpoint 327204236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.64354
Policy Entropy: 1.16540
Value Function Loss: 3.90144

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.06860

Collected Steps per Second: 8,702.18699
Overall Steps per Second: 7,690.54804

Timestep Collection Time: 5.74821
Timestep Consumption Time: 0.75614
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.50435

Cumulative Model Updates: 19,615
Cumulative Timesteps: 327,254,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.94993
Policy Entropy: 1.14189
Value Function Loss: 3.88706

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 8,809.98387
Overall Steps per Second: 7,699.52225

Timestep Collection Time: 5.67856
Timestep Consumption Time: 0.81899
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.49755

Cumulative Model Updates: 19,618
Cumulative Timesteps: 327,304,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 327304286...
Checkpoint 327304286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.18046
Policy Entropy: 1.12873
Value Function Loss: 3.75983

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.17159
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.05907

Collected Steps per Second: 8,667.87626
Overall Steps per Second: 7,574.84124

Timestep Collection Time: 5.76981
Timestep Consumption Time: 0.83257
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 6.60238

Cumulative Model Updates: 19,621
Cumulative Timesteps: 327,354,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.39780
Policy Entropy: 1.14893
Value Function Loss: 3.85791

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.05706

Collected Steps per Second: 8,900.80012
Overall Steps per Second: 7,652.00486

Timestep Collection Time: 5.62017
Timestep Consumption Time: 0.91720
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 6.53737

Cumulative Model Updates: 19,624
Cumulative Timesteps: 327,404,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 327404322...
Checkpoint 327404322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.39620
Policy Entropy: 1.13401
Value Function Loss: 3.62246

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.06244

Collected Steps per Second: 8,977.81580
Overall Steps per Second: 7,780.96394

Timestep Collection Time: 5.57196
Timestep Consumption Time: 0.85707
PPO Batch Consumption Time: 0.05219
Total Iteration Time: 6.42902

Cumulative Model Updates: 19,627
Cumulative Timesteps: 327,454,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.66752
Policy Entropy: 1.11647
Value Function Loss: 3.52286

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.05483

Collected Steps per Second: 9,091.73515
Overall Steps per Second: 8,023.09756

Timestep Collection Time: 5.50038
Timestep Consumption Time: 0.73262
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 6.23300

Cumulative Model Updates: 19,630
Cumulative Timesteps: 327,504,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 327504354...
Checkpoint 327504354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.21875
Policy Entropy: 1.11090
Value Function Loss: 3.40621

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.05194

Collected Steps per Second: 9,014.40997
Overall Steps per Second: 7,806.10452

Timestep Collection Time: 5.54956
Timestep Consumption Time: 0.85902
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 6.40857

Cumulative Model Updates: 19,633
Cumulative Timesteps: 327,554,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.88132
Policy Entropy: 1.12183
Value Function Loss: 3.47490

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.05690

Collected Steps per Second: 8,857.72838
Overall Steps per Second: 7,714.40487

Timestep Collection Time: 5.64818
Timestep Consumption Time: 0.83710
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.48527

Cumulative Model Updates: 19,636
Cumulative Timesteps: 327,604,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 327604410...
Checkpoint 327604410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.36857
Policy Entropy: 1.13975
Value Function Loss: 3.62419

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 9,373.83860
Overall Steps per Second: 8,016.79578

Timestep Collection Time: 5.33570
Timestep Consumption Time: 0.90320
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.23890

Cumulative Model Updates: 19,639
Cumulative Timesteps: 327,654,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.94351
Policy Entropy: 1.15503
Value Function Loss: 3.55649

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.06159

Collected Steps per Second: 9,047.90537
Overall Steps per Second: 7,861.45786

Timestep Collection Time: 5.52658
Timestep Consumption Time: 0.83407
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 6.36065

Cumulative Model Updates: 19,642
Cumulative Timesteps: 327,704,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 327704430...
Checkpoint 327704430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.09268
Policy Entropy: 1.10941
Value Function Loss: 3.63827

Mean KL Divergence: 0.06790
SB3 Clip Fraction: 0.23672
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.05091

Collected Steps per Second: 8,992.35475
Overall Steps per Second: 7,910.20606

Timestep Collection Time: 5.56117
Timestep Consumption Time: 0.76079
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 6.32196

Cumulative Model Updates: 19,645
Cumulative Timesteps: 327,754,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.94352
Policy Entropy: 1.13880
Value Function Loss: 3.60709

Mean KL Divergence: 0.03870
SB3 Clip Fraction: 0.20541
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.05713

Collected Steps per Second: 9,159.63566
Overall Steps per Second: 7,879.72029

Timestep Collection Time: 5.46135
Timestep Consumption Time: 0.88710
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.34845

Cumulative Model Updates: 19,648
Cumulative Timesteps: 327,804,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 327804462...
Checkpoint 327804462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.93293
Policy Entropy: 1.11117
Value Function Loss: 3.50812

Mean KL Divergence: 0.06079
SB3 Clip Fraction: 0.23912
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.07503

Collected Steps per Second: 8,706.46799
Overall Steps per Second: 7,639.21956

Timestep Collection Time: 5.74561
Timestep Consumption Time: 0.80270
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.54831

Cumulative Model Updates: 19,651
Cumulative Timesteps: 327,854,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.51946
Policy Entropy: 1.12835
Value Function Loss: 3.40823

Mean KL Divergence: 0.03936
SB3 Clip Fraction: 0.21300
Policy Update Magnitude: 0.03795
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 9,106.06745
Overall Steps per Second: 7,828.67958

Timestep Collection Time: 5.49370
Timestep Consumption Time: 0.89639
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.39009

Cumulative Model Updates: 19,654
Cumulative Timesteps: 327,904,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 327904512...
Checkpoint 327904512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.90563
Policy Entropy: 1.09429
Value Function Loss: 3.27930

Mean KL Divergence: 0.05881
SB3 Clip Fraction: 0.25239
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 9,097.58093
Overall Steps per Second: 7,870.65976

Timestep Collection Time: 5.49882
Timestep Consumption Time: 0.85719
PPO Batch Consumption Time: 0.05039
Total Iteration Time: 6.35601

Cumulative Model Updates: 19,657
Cumulative Timesteps: 327,954,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.51685
Policy Entropy: 1.11225
Value Function Loss: 3.39555

Mean KL Divergence: 0.04014
SB3 Clip Fraction: 0.22906
Policy Update Magnitude: 0.03606
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 8,789.84840
Overall Steps per Second: 7,782.06436

Timestep Collection Time: 5.69066
Timestep Consumption Time: 0.73694
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.42760

Cumulative Model Updates: 19,660
Cumulative Timesteps: 328,004,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 328004558...
Checkpoint 328004558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.95942
Policy Entropy: 1.08764
Value Function Loss: 3.41568

Mean KL Divergence: 0.05342
SB3 Clip Fraction: 0.25935
Policy Update Magnitude: 0.03699
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 8,794.67612
Overall Steps per Second: 7,669.44993

Timestep Collection Time: 5.68776
Timestep Consumption Time: 0.83448
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.52224

Cumulative Model Updates: 19,663
Cumulative Timesteps: 328,054,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.73422
Policy Entropy: 1.11859
Value Function Loss: 3.63741

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.18999
Policy Update Magnitude: 0.03540
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 8,893.62564
Overall Steps per Second: 7,772.24147

Timestep Collection Time: 5.62448
Timestep Consumption Time: 0.81150
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.43598

Cumulative Model Updates: 19,666
Cumulative Timesteps: 328,104,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 328104602...
Checkpoint 328104602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.89544
Policy Entropy: 1.10567
Value Function Loss: 3.67343

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.17807
Policy Update Magnitude: 0.03907
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 9,043.18071
Overall Steps per Second: 7,808.44514

Timestep Collection Time: 5.53058
Timestep Consumption Time: 0.87454
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 6.40512

Cumulative Model Updates: 19,669
Cumulative Timesteps: 328,154,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.40524
Policy Entropy: 1.11992
Value Function Loss: 3.80335

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 9,062.65205
Overall Steps per Second: 7,824.49962

Timestep Collection Time: 5.52046
Timestep Consumption Time: 0.87356
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.39402

Cumulative Model Updates: 19,672
Cumulative Timesteps: 328,204,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 328204646...
Checkpoint 328204646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.79177
Policy Entropy: 1.12064
Value Function Loss: 3.63692

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.03957
Value Function Update Magnitude: 0.05954

Collected Steps per Second: 8,804.88382
Overall Steps per Second: 7,747.04528

Timestep Collection Time: 5.68139
Timestep Consumption Time: 0.77578
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.45717

Cumulative Model Updates: 19,675
Cumulative Timesteps: 328,254,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.67817
Policy Entropy: 1.10223
Value Function Loss: 3.35252

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.06974

Collected Steps per Second: 8,632.63150
Overall Steps per Second: 7,510.37137

Timestep Collection Time: 5.79244
Timestep Consumption Time: 0.86555
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.65799

Cumulative Model Updates: 19,678
Cumulative Timesteps: 328,304,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 328304674...
Checkpoint 328304674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.60329
Policy Entropy: 1.10640
Value Function Loss: 3.22487

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.15582
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 8,988.19817
Overall Steps per Second: 7,850.17273

Timestep Collection Time: 5.56597
Timestep Consumption Time: 0.80689
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.37285

Cumulative Model Updates: 19,681
Cumulative Timesteps: 328,354,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.84785
Policy Entropy: 1.10088
Value Function Loss: 3.25411

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.07757

Collected Steps per Second: 9,002.26628
Overall Steps per Second: 7,740.88275

Timestep Collection Time: 5.55727
Timestep Consumption Time: 0.90556
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.46283

Cumulative Model Updates: 19,684
Cumulative Timesteps: 328,404,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 328404730...
Checkpoint 328404730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.13851
Policy Entropy: 1.09036
Value Function Loss: 3.40716

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 8,959.17048
Overall Steps per Second: 7,782.35209

Timestep Collection Time: 5.58199
Timestep Consumption Time: 0.84409
PPO Batch Consumption Time: 0.04909
Total Iteration Time: 6.42608

Cumulative Model Updates: 19,687
Cumulative Timesteps: 328,454,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.19615
Policy Entropy: 1.05630
Value Function Loss: 3.33231

Mean KL Divergence: 0.04585
SB3 Clip Fraction: 0.22461
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 9,380.97585
Overall Steps per Second: 8,053.97053

Timestep Collection Time: 5.33015
Timestep Consumption Time: 0.87822
PPO Batch Consumption Time: 0.04864
Total Iteration Time: 6.20837

Cumulative Model Updates: 19,690
Cumulative Timesteps: 328,504,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 328504742...
Checkpoint 328504742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.30010
Policy Entropy: 1.10401
Value Function Loss: 3.23906

Mean KL Divergence: 0.04392
SB3 Clip Fraction: 0.23595
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.08173

Collected Steps per Second: 9,084.71860
Overall Steps per Second: 7,856.40923

Timestep Collection Time: 5.50375
Timestep Consumption Time: 0.86048
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.36423

Cumulative Model Updates: 19,693
Cumulative Timesteps: 328,554,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.46027
Policy Entropy: 1.08583
Value Function Loss: 3.29703

Mean KL Divergence: 0.04587
SB3 Clip Fraction: 0.22590
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 9,274.75719
Overall Steps per Second: 7,999.97582

Timestep Collection Time: 5.39313
Timestep Consumption Time: 0.85939
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 6.25252

Cumulative Model Updates: 19,696
Cumulative Timesteps: 328,604,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 328604762...
Checkpoint 328604762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.42957
Policy Entropy: 1.11708
Value Function Loss: 3.45864

Mean KL Divergence: 0.03877
SB3 Clip Fraction: 0.21493
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.06892

Collected Steps per Second: 9,406.96376
Overall Steps per Second: 8,085.61134

Timestep Collection Time: 5.31798
Timestep Consumption Time: 0.86906
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.18704

Cumulative Model Updates: 19,699
Cumulative Timesteps: 328,654,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.26656
Policy Entropy: 1.09104
Value Function Loss: 3.61715

Mean KL Divergence: 0.05892
SB3 Clip Fraction: 0.23583
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.07120

Collected Steps per Second: 9,191.87290
Overall Steps per Second: 7,933.55105

Timestep Collection Time: 5.44133
Timestep Consumption Time: 0.86304
PPO Batch Consumption Time: 0.04960
Total Iteration Time: 6.30436

Cumulative Model Updates: 19,702
Cumulative Timesteps: 328,704,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 328704804...
Checkpoint 328704804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.66709
Policy Entropy: 1.12485
Value Function Loss: 3.66912

Mean KL Divergence: 0.04049
SB3 Clip Fraction: 0.22723
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 8,906.69746
Overall Steps per Second: 7,841.04833

Timestep Collection Time: 5.61622
Timestep Consumption Time: 0.76328
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.37950

Cumulative Model Updates: 19,705
Cumulative Timesteps: 328,754,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.37073
Policy Entropy: 1.09756
Value Function Loss: 3.44767

Mean KL Divergence: 0.03987
SB3 Clip Fraction: 0.22247
Policy Update Magnitude: 0.03968
Value Function Update Magnitude: 0.06959

Collected Steps per Second: 8,921.43182
Overall Steps per Second: 7,742.86241

Timestep Collection Time: 5.60605
Timestep Consumption Time: 0.85332
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 6.45937

Cumulative Model Updates: 19,708
Cumulative Timesteps: 328,804,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 328804840...
Checkpoint 328804840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.42574
Policy Entropy: 1.11996
Value Function Loss: 3.53884

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 8,771.52305
Overall Steps per Second: 7,648.85708

Timestep Collection Time: 5.70163
Timestep Consumption Time: 0.83686
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 6.53849

Cumulative Model Updates: 19,711
Cumulative Timesteps: 328,854,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.88944
Policy Entropy: 1.10103
Value Function Loss: 3.51128

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 8,971.95731
Overall Steps per Second: 7,899.47676

Timestep Collection Time: 5.57470
Timestep Consumption Time: 0.75686
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 6.33156

Cumulative Model Updates: 19,714
Cumulative Timesteps: 328,904,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 328904868...
Checkpoint 328904868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.07638
Policy Entropy: 1.10034
Value Function Loss: 3.70863

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14817
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.06952

Collected Steps per Second: 8,855.00032
Overall Steps per Second: 7,717.60971

Timestep Collection Time: 5.64992
Timestep Consumption Time: 0.83266
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 6.48258

Cumulative Model Updates: 19,717
Cumulative Timesteps: 328,954,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.92732
Policy Entropy: 1.11009
Value Function Loss: 3.73218

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.06337

Collected Steps per Second: 8,530.91247
Overall Steps per Second: 7,517.10147

Timestep Collection Time: 5.86362
Timestep Consumption Time: 0.79081
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 6.65443

Cumulative Model Updates: 19,720
Cumulative Timesteps: 329,004,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 329004920...
Checkpoint 329004920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.82732
Policy Entropy: 1.12059
Value Function Loss: 3.64691

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 8,925.16593
Overall Steps per Second: 7,731.45172

Timestep Collection Time: 5.60438
Timestep Consumption Time: 0.86530
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 6.46968

Cumulative Model Updates: 19,723
Cumulative Timesteps: 329,054,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.66809
Policy Entropy: 1.11674
Value Function Loss: 3.69821

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 8,697.60857
Overall Steps per Second: 7,533.15475

Timestep Collection Time: 5.75147
Timestep Consumption Time: 0.88905
PPO Batch Consumption Time: 0.05181
Total Iteration Time: 6.64051

Cumulative Model Updates: 19,726
Cumulative Timesteps: 329,104,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 329104964...
Checkpoint 329104964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.47632
Policy Entropy: 1.11307
Value Function Loss: 3.67623

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 8,911.68898
Overall Steps per Second: 7,850.34536

Timestep Collection Time: 5.61218
Timestep Consumption Time: 0.75875
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.37093

Cumulative Model Updates: 19,729
Cumulative Timesteps: 329,154,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.69229
Policy Entropy: 1.12441
Value Function Loss: 3.88625

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.08840

Collected Steps per Second: 8,943.44998
Overall Steps per Second: 7,559.22287

Timestep Collection Time: 5.59314
Timestep Consumption Time: 1.02420
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 6.61735

Cumulative Model Updates: 19,732
Cumulative Timesteps: 329,205,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 329205000...
Checkpoint 329205000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.33032
Policy Entropy: 1.12352
Value Function Loss: 3.93732

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 8,797.37666
Overall Steps per Second: 7,675.94639

Timestep Collection Time: 5.68533
Timestep Consumption Time: 0.83061
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 6.51594

Cumulative Model Updates: 19,735
Cumulative Timesteps: 329,255,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.28730
Policy Entropy: 1.11714
Value Function Loss: 3.79340

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.09190

Collected Steps per Second: 9,149.77403
Overall Steps per Second: 7,948.74444

Timestep Collection Time: 5.46789
Timestep Consumption Time: 0.82618
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.29408

Cumulative Model Updates: 19,738
Cumulative Timesteps: 329,305,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 329305046...
Checkpoint 329305046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.31065
Policy Entropy: 1.11993
Value Function Loss: 3.62801

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 8,947.20975
Overall Steps per Second: 7,804.18471

Timestep Collection Time: 5.59035
Timestep Consumption Time: 0.81878
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.40913

Cumulative Model Updates: 19,741
Cumulative Timesteps: 329,355,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.47705
Policy Entropy: 1.11777
Value Function Loss: 3.36157

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 8,859.49328
Overall Steps per Second: 7,830.59169

Timestep Collection Time: 5.64547
Timestep Consumption Time: 0.74179
PPO Batch Consumption Time: 0.04503
Total Iteration Time: 6.38726

Cumulative Model Updates: 19,744
Cumulative Timesteps: 329,405,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 329405080...
Checkpoint 329405080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.90195
Policy Entropy: 1.11813
Value Function Loss: 3.30996

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.07481

Collected Steps per Second: 8,722.76938
Overall Steps per Second: 7,584.71723

Timestep Collection Time: 5.73350
Timestep Consumption Time: 0.86029
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.59379

Cumulative Model Updates: 19,747
Cumulative Timesteps: 329,455,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.97057
Policy Entropy: 1.11060
Value Function Loss: 3.31523

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.06855

Collected Steps per Second: 9,005.58948
Overall Steps per Second: 7,849.22838

Timestep Collection Time: 5.55211
Timestep Consumption Time: 0.81795
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.37005

Cumulative Model Updates: 19,750
Cumulative Timesteps: 329,505,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 329505092...
Checkpoint 329505092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.15521
Policy Entropy: 1.10776
Value Function Loss: 3.56182

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.06175

Collected Steps per Second: 9,013.41118
Overall Steps per Second: 7,968.63046

Timestep Collection Time: 5.54906
Timestep Consumption Time: 0.72755
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.27661

Cumulative Model Updates: 19,753
Cumulative Timesteps: 329,555,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.52618
Policy Entropy: 1.11633
Value Function Loss: 3.76208

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.06260

Collected Steps per Second: 9,008.20551
Overall Steps per Second: 7,810.22889

Timestep Collection Time: 5.55338
Timestep Consumption Time: 0.85181
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 6.40519

Cumulative Model Updates: 19,756
Cumulative Timesteps: 329,605,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 329605134...
Checkpoint 329605134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.11776
Policy Entropy: 1.12642
Value Function Loss: 3.73231

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 8,831.70078
Overall Steps per Second: 7,800.32150

Timestep Collection Time: 5.66346
Timestep Consumption Time: 0.74884
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.41230

Cumulative Model Updates: 19,759
Cumulative Timesteps: 329,655,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.85365
Policy Entropy: 1.11018
Value Function Loss: 3.66993

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.11054
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 8,773.95872
Overall Steps per Second: 7,639.82359

Timestep Collection Time: 5.70096
Timestep Consumption Time: 0.84631
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.54727

Cumulative Model Updates: 19,762
Cumulative Timesteps: 329,705,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 329705172...
Checkpoint 329705172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.55420
Policy Entropy: 1.10933
Value Function Loss: 3.43078

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.09485

Collected Steps per Second: 8,890.96396
Overall Steps per Second: 7,751.74552

Timestep Collection Time: 5.62571
Timestep Consumption Time: 0.82677
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.45248

Cumulative Model Updates: 19,765
Cumulative Timesteps: 329,755,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.11213
Policy Entropy: 1.11199
Value Function Loss: 3.49093

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 8,823.86592
Overall Steps per Second: 7,779.15559

Timestep Collection Time: 5.66894
Timestep Consumption Time: 0.76132
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 6.43026

Cumulative Model Updates: 19,768
Cumulative Timesteps: 329,805,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 329805212...
Checkpoint 329805212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.88190
Policy Entropy: 1.11460
Value Function Loss: 3.39990

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.08263

Collected Steps per Second: 8,711.35762
Overall Steps per Second: 7,612.37077

Timestep Collection Time: 5.73963
Timestep Consumption Time: 0.82862
PPO Batch Consumption Time: 0.04812
Total Iteration Time: 6.56826

Cumulative Model Updates: 19,771
Cumulative Timesteps: 329,855,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.69633
Policy Entropy: 1.10847
Value Function Loss: 3.43640

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 8,830.55937
Overall Steps per Second: 7,702.34092

Timestep Collection Time: 5.66487
Timestep Consumption Time: 0.82978
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 6.49465

Cumulative Model Updates: 19,774
Cumulative Timesteps: 329,905,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 329905236...
Checkpoint 329905236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.33595
Policy Entropy: 1.09678
Value Function Loss: 3.26485

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.18028
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.06809

Collected Steps per Second: 8,799.75373
Overall Steps per Second: 7,672.21256

Timestep Collection Time: 5.68516
Timestep Consumption Time: 0.83552
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.52067

Cumulative Model Updates: 19,777
Cumulative Timesteps: 329,955,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.52748
Policy Entropy: 1.11606
Value Function Loss: 3.22762

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 8,518.99161
Overall Steps per Second: 7,393.66956

Timestep Collection Time: 5.87276
Timestep Consumption Time: 0.89384
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 6.76660

Cumulative Model Updates: 19,780
Cumulative Timesteps: 330,005,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 330005294...
Checkpoint 330005294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.49214
Policy Entropy: 1.11320
Value Function Loss: 3.27982

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 9,143.23384
Overall Steps per Second: 7,918.20385

Timestep Collection Time: 5.47071
Timestep Consumption Time: 0.84638
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.31709

Cumulative Model Updates: 19,783
Cumulative Timesteps: 330,055,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.15971
Policy Entropy: 1.09634
Value Function Loss: 3.40363

Mean KL Divergence: 0.03477
SB3 Clip Fraction: 0.18637
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 8,823.45018
Overall Steps per Second: 7,685.15959

Timestep Collection Time: 5.66853
Timestep Consumption Time: 0.83960
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 6.50813

Cumulative Model Updates: 19,786
Cumulative Timesteps: 330,105,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 330105330...
Checkpoint 330105330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.83962
Policy Entropy: 1.12697
Value Function Loss: 3.38377

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.07620

Collected Steps per Second: 8,559.65874
Overall Steps per Second: 7,541.75494

Timestep Collection Time: 5.84276
Timestep Consumption Time: 0.78859
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.63135

Cumulative Model Updates: 19,789
Cumulative Timesteps: 330,155,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.07005
Policy Entropy: 1.11718
Value Function Loss: 3.40804

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.07721

Collected Steps per Second: 8,848.83819
Overall Steps per Second: 7,668.76491

Timestep Collection Time: 5.65295
Timestep Consumption Time: 0.86988
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.52282

Cumulative Model Updates: 19,792
Cumulative Timesteps: 330,205,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 330205364...
Checkpoint 330205364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.63518
Policy Entropy: 1.11602
Value Function Loss: 3.36599

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.07024

Collected Steps per Second: 8,683.50753
Overall Steps per Second: 7,537.88791

Timestep Collection Time: 5.76150
Timestep Consumption Time: 0.87564
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 6.63714

Cumulative Model Updates: 19,795
Cumulative Timesteps: 330,255,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.98931
Policy Entropy: 1.12318
Value Function Loss: 3.45851

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 8,986.82681
Overall Steps per Second: 7,770.57732

Timestep Collection Time: 5.56659
Timestep Consumption Time: 0.87128
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 6.43787

Cumulative Model Updates: 19,798
Cumulative Timesteps: 330,305,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 330305420...
Checkpoint 330305420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.69618
Policy Entropy: 1.11008
Value Function Loss: 3.51165

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 9,465.57597
Overall Steps per Second: 8,121.11989

Timestep Collection Time: 5.28336
Timestep Consumption Time: 0.87466
PPO Batch Consumption Time: 0.05038
Total Iteration Time: 6.15802

Cumulative Model Updates: 19,801
Cumulative Timesteps: 330,355,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.07612
Policy Entropy: 1.09170
Value Function Loss: 3.45845

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 9,113.94097
Overall Steps per Second: 7,999.19909

Timestep Collection Time: 5.48895
Timestep Consumption Time: 0.76492
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.25388

Cumulative Model Updates: 19,804
Cumulative Timesteps: 330,405,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 330405456...
Checkpoint 330405456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.99771
Policy Entropy: 1.09426
Value Function Loss: 3.33326

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16329
Policy Update Magnitude: 0.04187
Value Function Update Magnitude: 0.05750

Collected Steps per Second: 9,009.51178
Overall Steps per Second: 7,770.13001

Timestep Collection Time: 5.55302
Timestep Consumption Time: 0.88574
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 6.43876

Cumulative Model Updates: 19,807
Cumulative Timesteps: 330,455,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.34337
Policy Entropy: 1.10161
Value Function Loss: 3.22545

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 9,265.42171
Overall Steps per Second: 8,030.72459

Timestep Collection Time: 5.39814
Timestep Consumption Time: 0.82995
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.22808

Cumulative Model Updates: 19,810
Cumulative Timesteps: 330,505,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 330505502...
Checkpoint 330505502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.54523
Policy Entropy: 1.11901
Value Function Loss: 3.32378

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06253

Collected Steps per Second: 9,344.06768
Overall Steps per Second: 8,067.97505

Timestep Collection Time: 5.35184
Timestep Consumption Time: 0.84649
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 6.19833

Cumulative Model Updates: 19,813
Cumulative Timesteps: 330,555,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.73092
Policy Entropy: 1.07222
Value Function Loss: 3.30858

Mean KL Divergence: 0.04105
SB3 Clip Fraction: 0.19648
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 8,731.13900
Overall Steps per Second: 7,587.20277

Timestep Collection Time: 5.72800
Timestep Consumption Time: 0.86362
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.59163

Cumulative Model Updates: 19,816
Cumulative Timesteps: 330,605,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 330605522...
Checkpoint 330605522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.51073
Policy Entropy: 1.09810
Value Function Loss: 3.32534

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 8,785.30383
Overall Steps per Second: 7,735.38283

Timestep Collection Time: 5.69132
Timestep Consumption Time: 0.77248
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 6.46380

Cumulative Model Updates: 19,819
Cumulative Timesteps: 330,655,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.72554
Policy Entropy: 1.09333
Value Function Loss: 3.37633

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 8,881.79548
Overall Steps per Second: 7,707.39839

Timestep Collection Time: 5.63264
Timestep Consumption Time: 0.85826
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.49091

Cumulative Model Updates: 19,822
Cumulative Timesteps: 330,705,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 330705550...
Checkpoint 330705550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.61504
Policy Entropy: 1.08075
Value Function Loss: 3.30652

Mean KL Divergence: 0.03214
SB3 Clip Fraction: 0.20752
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.08915

Collected Steps per Second: 8,668.73041
Overall Steps per Second: 7,587.13509

Timestep Collection Time: 5.76947
Timestep Consumption Time: 0.82248
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.59195

Cumulative Model Updates: 19,825
Cumulative Timesteps: 330,755,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.57048
Policy Entropy: 1.09366
Value Function Loss: 3.45308

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.08900

Collected Steps per Second: 8,967.34347
Overall Steps per Second: 7,794.89256

Timestep Collection Time: 5.57779
Timestep Consumption Time: 0.83897
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.41677

Cumulative Model Updates: 19,828
Cumulative Timesteps: 330,805,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 330805582...
Checkpoint 330805582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.07666
Policy Entropy: 1.09453
Value Function Loss: 3.27048

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 8,632.30588
Overall Steps per Second: 7,583.00334

Timestep Collection Time: 5.79451
Timestep Consumption Time: 0.80182
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.59633

Cumulative Model Updates: 19,831
Cumulative Timesteps: 330,855,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.25693
Policy Entropy: 1.08455
Value Function Loss: 3.36092

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.07073

Collected Steps per Second: 8,999.12588
Overall Steps per Second: 7,905.02630

Timestep Collection Time: 5.55921
Timestep Consumption Time: 0.76943
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 6.32863

Cumulative Model Updates: 19,834
Cumulative Timesteps: 330,905,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 330905630...
Checkpoint 330905630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.42179
Policy Entropy: 1.08394
Value Function Loss: 3.09441

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.18875
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 8,843.11277
Overall Steps per Second: 7,710.73467

Timestep Collection Time: 5.65638
Timestep Consumption Time: 0.83068
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.48706

Cumulative Model Updates: 19,837
Cumulative Timesteps: 330,955,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.29611
Policy Entropy: 1.09290
Value Function Loss: 3.23653

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 8,934.76232
Overall Steps per Second: 7,774.62043

Timestep Collection Time: 5.59881
Timestep Consumption Time: 0.83546
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 6.43427

Cumulative Model Updates: 19,840
Cumulative Timesteps: 331,005,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 331005674...
Checkpoint 331005674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.79853
Policy Entropy: 1.09973
Value Function Loss: 3.23325

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 8,936.60414
Overall Steps per Second: 7,603.18980

Timestep Collection Time: 5.59743
Timestep Consumption Time: 0.98165
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 6.57908

Cumulative Model Updates: 19,843
Cumulative Timesteps: 331,055,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.00454
Policy Entropy: 1.09922
Value Function Loss: 3.30755

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.05917

Collected Steps per Second: 8,690.34056
Overall Steps per Second: 7,609.91973

Timestep Collection Time: 5.75605
Timestep Consumption Time: 0.81722
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 6.57326

Cumulative Model Updates: 19,846
Cumulative Timesteps: 331,105,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 331105718...
Checkpoint 331105718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.96495
Policy Entropy: 1.09627
Value Function Loss: 3.20021

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.05770

Collected Steps per Second: 8,849.92087
Overall Steps per Second: 7,824.10579

Timestep Collection Time: 5.65045
Timestep Consumption Time: 0.74083
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.39127

Cumulative Model Updates: 19,849
Cumulative Timesteps: 331,155,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.08272
Policy Entropy: 1.08191
Value Function Loss: 3.26483

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.05350

Collected Steps per Second: 8,965.24617
Overall Steps per Second: 7,803.58812

Timestep Collection Time: 5.57843
Timestep Consumption Time: 0.83042
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.40885

Cumulative Model Updates: 19,852
Cumulative Timesteps: 331,205,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 331205736...
Checkpoint 331205736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.24731
Policy Entropy: 1.09332
Value Function Loss: 3.19184

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 8,743.58855
Overall Steps per Second: 7,638.79733

Timestep Collection Time: 5.72168
Timestep Consumption Time: 0.82752
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.54920

Cumulative Model Updates: 19,855
Cumulative Timesteps: 331,255,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.32664
Policy Entropy: 1.08895
Value Function Loss: 3.24486

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.05180

Collected Steps per Second: 8,791.90347
Overall Steps per Second: 7,634.50394

Timestep Collection Time: 5.68842
Timestep Consumption Time: 0.86237
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.55079

Cumulative Model Updates: 19,858
Cumulative Timesteps: 331,305,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 331305776...
Checkpoint 331305776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.70878
Policy Entropy: 1.08163
Value Function Loss: 3.18159

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 8,759.02199
Overall Steps per Second: 7,588.39216

Timestep Collection Time: 5.71114
Timestep Consumption Time: 0.88103
PPO Batch Consumption Time: 0.04832
Total Iteration Time: 6.59217

Cumulative Model Updates: 19,861
Cumulative Timesteps: 331,355,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.09488
Policy Entropy: 1.08159
Value Function Loss: 3.29165

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.04988

Collected Steps per Second: 8,672.76917
Overall Steps per Second: 7,674.98010

Timestep Collection Time: 5.76817
Timestep Consumption Time: 0.74989
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.51806

Cumulative Model Updates: 19,864
Cumulative Timesteps: 331,405,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 331405826...
Checkpoint 331405826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.54377
Policy Entropy: 1.08554
Value Function Loss: 3.36290

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.05738

Collected Steps per Second: 8,943.76512
Overall Steps per Second: 7,727.82221

Timestep Collection Time: 5.59272
Timestep Consumption Time: 0.87999
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.47272

Cumulative Model Updates: 19,867
Cumulative Timesteps: 331,455,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.40489
Policy Entropy: 1.09473
Value Function Loss: 3.42363

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 8,703.83101
Overall Steps per Second: 7,596.36221

Timestep Collection Time: 5.74644
Timestep Consumption Time: 0.83777
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.58420

Cumulative Model Updates: 19,870
Cumulative Timesteps: 331,505,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 331505862...
Checkpoint 331505862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.67718
Policy Entropy: 1.08214
Value Function Loss: 3.43515

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.05130

Collected Steps per Second: 8,765.56320
Overall Steps per Second: 7,610.02264

Timestep Collection Time: 5.70437
Timestep Consumption Time: 0.86618
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.57055

Cumulative Model Updates: 19,873
Cumulative Timesteps: 331,555,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.14104
Policy Entropy: 1.08060
Value Function Loss: 3.37494

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15879
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.06341

Collected Steps per Second: 8,855.27538
Overall Steps per Second: 7,741.50603

Timestep Collection Time: 5.64680
Timestep Consumption Time: 0.81240
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.45921

Cumulative Model Updates: 19,876
Cumulative Timesteps: 331,605,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 331605868...
Checkpoint 331605868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.24213
Policy Entropy: 1.09828
Value Function Loss: 3.28330

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 8,859.06887
Overall Steps per Second: 7,805.16080

Timestep Collection Time: 5.64709
Timestep Consumption Time: 0.76251
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 6.40961

Cumulative Model Updates: 19,879
Cumulative Timesteps: 331,655,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.65573
Policy Entropy: 1.10596
Value Function Loss: 3.40224

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.06466

Collected Steps per Second: 8,876.29873
Overall Steps per Second: 7,747.74291

Timestep Collection Time: 5.63523
Timestep Consumption Time: 0.82084
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.45607

Cumulative Model Updates: 19,882
Cumulative Timesteps: 331,705,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 331705916...
Checkpoint 331705916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.26323
Policy Entropy: 1.08773
Value Function Loss: 3.39019

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 8,536.63779
Overall Steps per Second: 7,476.94439

Timestep Collection Time: 5.85992
Timestep Consumption Time: 0.83052
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 6.69043

Cumulative Model Updates: 19,885
Cumulative Timesteps: 331,755,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.60922
Policy Entropy: 1.06328
Value Function Loss: 3.53345

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.18789
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 9,001.10754
Overall Steps per Second: 7,794.77426

Timestep Collection Time: 5.55798
Timestep Consumption Time: 0.86016
PPO Batch Consumption Time: 0.04974
Total Iteration Time: 6.41815

Cumulative Model Updates: 19,888
Cumulative Timesteps: 331,805,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 331805968...
Checkpoint 331805968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.04661
Policy Entropy: 1.08524
Value Function Loss: 3.53348

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 8,828.46764
Overall Steps per Second: 7,712.02218

Timestep Collection Time: 5.66576
Timestep Consumption Time: 0.82021
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.48598

Cumulative Model Updates: 19,891
Cumulative Timesteps: 331,855,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.40683
Policy Entropy: 1.08059
Value Function Loss: 3.51599

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.05771

Collected Steps per Second: 8,902.72238
Overall Steps per Second: 7,845.77078

Timestep Collection Time: 5.61851
Timestep Consumption Time: 0.75690
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 6.37541

Cumulative Model Updates: 19,894
Cumulative Timesteps: 331,906,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 331906008...
Checkpoint 331906008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.69019
Policy Entropy: 1.07759
Value Function Loss: 3.36726

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 8,708.67478
Overall Steps per Second: 7,578.68443

Timestep Collection Time: 5.74232
Timestep Consumption Time: 0.85619
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.59851

Cumulative Model Updates: 19,897
Cumulative Timesteps: 331,956,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.36365
Policy Entropy: 1.07548
Value Function Loss: 3.24084

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 8,812.42652
Overall Steps per Second: 7,545.12410

Timestep Collection Time: 5.67653
Timestep Consumption Time: 0.95345
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.62998

Cumulative Model Updates: 19,900
Cumulative Timesteps: 332,006,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 332006040...
Checkpoint 332006040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.83431
Policy Entropy: 1.07277
Value Function Loss: 3.17020

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 8,880.14075
Overall Steps per Second: 7,667.87781

Timestep Collection Time: 5.63279
Timestep Consumption Time: 0.89052
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 6.52332

Cumulative Model Updates: 19,903
Cumulative Timesteps: 332,056,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.74594
Policy Entropy: 1.08330
Value Function Loss: 3.24267

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.04881

Collected Steps per Second: 8,800.09733
Overall Steps per Second: 7,563.38246

Timestep Collection Time: 5.68357
Timestep Consumption Time: 0.92934
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.61291

Cumulative Model Updates: 19,906
Cumulative Timesteps: 332,106,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 332106076...
Checkpoint 332106076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.70336
Policy Entropy: 1.08328
Value Function Loss: 3.32482

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.05272

Collected Steps per Second: 8,617.61625
Overall Steps per Second: 7,611.93721

Timestep Collection Time: 5.80509
Timestep Consumption Time: 0.76696
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.57205

Cumulative Model Updates: 19,909
Cumulative Timesteps: 332,156,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.63378
Policy Entropy: 1.08781
Value Function Loss: 3.40747

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.05226

Collected Steps per Second: 9,254.78757
Overall Steps per Second: 7,807.06428

Timestep Collection Time: 5.40499
Timestep Consumption Time: 1.00229
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 6.40727

Cumulative Model Updates: 19,912
Cumulative Timesteps: 332,206,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 332206124...
Checkpoint 332206124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.02755
Policy Entropy: 1.07509
Value Function Loss: 3.31518

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.06506

Collected Steps per Second: 9,148.70092
Overall Steps per Second: 7,923.93818

Timestep Collection Time: 5.46722
Timestep Consumption Time: 0.84504
PPO Batch Consumption Time: 0.04685
Total Iteration Time: 6.31227

Cumulative Model Updates: 19,915
Cumulative Timesteps: 332,256,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.87701
Policy Entropy: 1.08507
Value Function Loss: 3.15911

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 9,225.89279
Overall Steps per Second: 7,949.84980

Timestep Collection Time: 5.41953
Timestep Consumption Time: 0.86990
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.28943

Cumulative Model Updates: 19,918
Cumulative Timesteps: 332,306,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 332306142...
Checkpoint 332306142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.87407
Policy Entropy: 1.08368
Value Function Loss: 3.11928

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.05279

Collected Steps per Second: 9,074.50645
Overall Steps per Second: 7,825.43279

Timestep Collection Time: 5.51347
Timestep Consumption Time: 0.88004
PPO Batch Consumption Time: 0.04643
Total Iteration Time: 6.39351

Cumulative Model Updates: 19,921
Cumulative Timesteps: 332,356,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.82127
Policy Entropy: 1.07251
Value Function Loss: 3.14956

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.05418

Collected Steps per Second: 9,039.12258
Overall Steps per Second: 7,935.78396

Timestep Collection Time: 5.53394
Timestep Consumption Time: 0.76940
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 6.30335

Cumulative Model Updates: 19,924
Cumulative Timesteps: 332,406,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 332406196...
Checkpoint 332406196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768.26303
Policy Entropy: 1.06019
Value Function Loss: 3.23655

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.19442
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.05269

Collected Steps per Second: 8,732.54064
Overall Steps per Second: 7,635.12347

Timestep Collection Time: 5.72777
Timestep Consumption Time: 0.82327
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.55104

Cumulative Model Updates: 19,927
Cumulative Timesteps: 332,456,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.75586
Policy Entropy: 1.08296
Value Function Loss: 3.32746

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.05407

Collected Steps per Second: 8,836.09069
Overall Steps per Second: 7,721.63506

Timestep Collection Time: 5.65861
Timestep Consumption Time: 0.81670
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 6.47531

Cumulative Model Updates: 19,930
Cumulative Timesteps: 332,506,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 332506214...
Checkpoint 332506214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.98997
Policy Entropy: 1.07294
Value Function Loss: 3.35649

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 8,805.72705
Overall Steps per Second: 7,786.77898

Timestep Collection Time: 5.68130
Timestep Consumption Time: 0.74343
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.42474

Cumulative Model Updates: 19,933
Cumulative Timesteps: 332,556,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.93158
Policy Entropy: 1.07213
Value Function Loss: 3.42358

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.19071
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 8,831.16510
Overall Steps per Second: 7,668.01671

Timestep Collection Time: 5.66177
Timestep Consumption Time: 0.85882
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.52059

Cumulative Model Updates: 19,936
Cumulative Timesteps: 332,606,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 332606242...
Checkpoint 332606242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.90507
Policy Entropy: 1.07866
Value Function Loss: 3.40984

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 8,779.72742
Overall Steps per Second: 7,759.64618

Timestep Collection Time: 5.69722
Timestep Consumption Time: 0.74895
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.44617

Cumulative Model Updates: 19,939
Cumulative Timesteps: 332,656,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.28165
Policy Entropy: 1.09099
Value Function Loss: 3.31243

Mean KL Divergence: 0.02584
SB3 Clip Fraction: 0.19981
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 8,387.33502
Overall Steps per Second: 7,302.01206

Timestep Collection Time: 5.96518
Timestep Consumption Time: 0.88663
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 6.85181

Cumulative Model Updates: 19,942
Cumulative Timesteps: 332,706,294

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 332706294...
Checkpoint 332706294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.67059
Policy Entropy: 1.04617
Value Function Loss: 3.12926

Mean KL Divergence: 0.08728
SB3 Clip Fraction: 0.28422
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.06522

Collected Steps per Second: 8,552.38453
Overall Steps per Second: 7,509.97152

Timestep Collection Time: 5.84890
Timestep Consumption Time: 0.81185
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 6.66074

Cumulative Model Updates: 19,945
Cumulative Timesteps: 332,756,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.79674
Policy Entropy: 1.07055
Value Function Loss: 3.19589

Mean KL Divergence: 0.03783
SB3 Clip Fraction: 0.21220
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.06153

Collected Steps per Second: 8,683.82167
Overall Steps per Second: 7,517.84952

Timestep Collection Time: 5.75991
Timestep Consumption Time: 0.89333
PPO Batch Consumption Time: 0.04919
Total Iteration Time: 6.65323

Cumulative Model Updates: 19,948
Cumulative Timesteps: 332,806,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 332806334...
Checkpoint 332806334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.32431
Policy Entropy: 1.05021
Value Function Loss: 3.35929

Mean KL Divergence: 0.07126
SB3 Clip Fraction: 0.26579
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.05509

Collected Steps per Second: 8,466.16426
Overall Steps per Second: 7,430.27999

Timestep Collection Time: 5.90752
Timestep Consumption Time: 0.82359
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 6.73111

Cumulative Model Updates: 19,951
Cumulative Timesteps: 332,856,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.14097
Policy Entropy: 1.08622
Value Function Loss: 3.40791

Mean KL Divergence: 0.04699
SB3 Clip Fraction: 0.25547
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 8,735.34674
Overall Steps per Second: 7,656.75595

Timestep Collection Time: 5.72662
Timestep Consumption Time: 0.80670
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.53332

Cumulative Model Updates: 19,954
Cumulative Timesteps: 332,906,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 332906372...
Checkpoint 332906372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.18907
Policy Entropy: 1.04900
Value Function Loss: 3.39991

Mean KL Divergence: 0.05971
SB3 Clip Fraction: 0.25768
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 8,872.14565
Overall Steps per Second: 7,732.87979

Timestep Collection Time: 5.63719
Timestep Consumption Time: 0.83051
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.46771

Cumulative Model Updates: 19,957
Cumulative Timesteps: 332,956,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.73496
Policy Entropy: 1.08059
Value Function Loss: 3.32460

Mean KL Divergence: 0.04569
SB3 Clip Fraction: 0.23330
Policy Update Magnitude: 0.03764
Value Function Update Magnitude: 0.06949

Collected Steps per Second: 8,979.99931
Overall Steps per Second: 7,770.80312

Timestep Collection Time: 5.57105
Timestep Consumption Time: 0.86690
PPO Batch Consumption Time: 0.04888
Total Iteration Time: 6.43794

Cumulative Model Updates: 19,960
Cumulative Timesteps: 333,006,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 333006414...
Checkpoint 333006414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.11015
Policy Entropy: 1.05382
Value Function Loss: 3.45478

Mean KL Divergence: 0.05784
SB3 Clip Fraction: 0.25447
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.08356

Collected Steps per Second: 8,928.18072
Overall Steps per Second: 7,760.15124

Timestep Collection Time: 5.60114
Timestep Consumption Time: 0.84306
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 6.44420

Cumulative Model Updates: 19,963
Cumulative Timesteps: 333,056,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.77883
Policy Entropy: 1.09142
Value Function Loss: 3.49250

Mean KL Divergence: 0.03876
SB3 Clip Fraction: 0.22039
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 9,230.00340
Overall Steps per Second: 7,949.31267

Timestep Collection Time: 5.41993
Timestep Consumption Time: 0.87319
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.29312

Cumulative Model Updates: 19,966
Cumulative Timesteps: 333,106,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 333106448...
Checkpoint 333106448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.68605
Policy Entropy: 1.05732
Value Function Loss: 3.50781

Mean KL Divergence: 0.05307
SB3 Clip Fraction: 0.24281
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.07121

Collected Steps per Second: 8,630.00641
Overall Steps per Second: 7,598.71447

Timestep Collection Time: 5.79629
Timestep Consumption Time: 0.78667
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.58296

Cumulative Model Updates: 19,969
Cumulative Timesteps: 333,156,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.60697
Policy Entropy: 1.09117
Value Function Loss: 3.36347

Mean KL Divergence: 0.03917
SB3 Clip Fraction: 0.23149
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 9,076.70542
Overall Steps per Second: 7,775.82849

Timestep Collection Time: 5.50927
Timestep Consumption Time: 0.92169
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.43095

Cumulative Model Updates: 19,972
Cumulative Timesteps: 333,206,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 333206476...
Checkpoint 333206476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.15238
Policy Entropy: 1.04877
Value Function Loss: 3.16468

Mean KL Divergence: 0.06658
SB3 Clip Fraction: 0.27267
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.06078

Collected Steps per Second: 9,076.85994
Overall Steps per Second: 7,897.25468

Timestep Collection Time: 5.51182
Timestep Consumption Time: 0.82329
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.33511

Cumulative Model Updates: 19,975
Cumulative Timesteps: 333,256,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.90760
Policy Entropy: 1.08489
Value Function Loss: 3.29877

Mean KL Divergence: 0.04313
SB3 Clip Fraction: 0.24455
Policy Update Magnitude: 0.03821
Value Function Update Magnitude: 0.05167

Collected Steps per Second: 9,277.89419
Overall Steps per Second: 7,993.64703

Timestep Collection Time: 5.39002
Timestep Consumption Time: 0.86595
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.25597

Cumulative Model Updates: 19,978
Cumulative Timesteps: 333,306,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 333306514...
Checkpoint 333306514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.11992
Policy Entropy: 1.07399
Value Function Loss: 3.48642

Mean KL Divergence: 0.04320
SB3 Clip Fraction: 0.23861
Policy Update Magnitude: 0.03592
Value Function Update Magnitude: 0.05469

Collected Steps per Second: 8,801.01295
Overall Steps per Second: 7,510.96331

Timestep Collection Time: 5.68344
Timestep Consumption Time: 0.97616
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.65960

Cumulative Model Updates: 19,981
Cumulative Timesteps: 333,356,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.34450
Policy Entropy: 1.09877
Value Function Loss: 3.57842

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.22603
Policy Update Magnitude: 0.03717
Value Function Update Magnitude: 0.05164

Collected Steps per Second: 8,793.16361
Overall Steps per Second: 7,760.35466

Timestep Collection Time: 5.68851
Timestep Consumption Time: 0.75707
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.44558

Cumulative Model Updates: 19,984
Cumulative Timesteps: 333,406,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 333406554...
Checkpoint 333406554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.42407
Policy Entropy: 1.07425
Value Function Loss: 3.46371

Mean KL Divergence: 0.03275
SB3 Clip Fraction: 0.22457
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.05129

Collected Steps per Second: 8,776.85739
Overall Steps per Second: 7,618.36866

Timestep Collection Time: 5.69817
Timestep Consumption Time: 0.86649
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.56466

Cumulative Model Updates: 19,987
Cumulative Timesteps: 333,456,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.24397
Policy Entropy: 1.09368
Value Function Loss: 3.57140

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.17348
Policy Update Magnitude: 0.04132
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 8,754.21450
Overall Steps per Second: 7,612.37459

Timestep Collection Time: 5.71222
Timestep Consumption Time: 0.85682
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 6.56904

Cumulative Model Updates: 19,990
Cumulative Timesteps: 333,506,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 333506572...
Checkpoint 333506572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.67391
Policy Entropy: 1.08152
Value Function Loss: 3.61792

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.04722

Collected Steps per Second: 9,020.78279
Overall Steps per Second: 7,870.61412

Timestep Collection Time: 5.54431
Timestep Consumption Time: 0.81021
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.35452

Cumulative Model Updates: 19,993
Cumulative Timesteps: 333,556,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.01381
Policy Entropy: 1.07398
Value Function Loss: 3.58766

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.04699

Collected Steps per Second: 8,628.99392
Overall Steps per Second: 7,574.32345

Timestep Collection Time: 5.79511
Timestep Consumption Time: 0.80693
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 6.60204

Cumulative Model Updates: 19,996
Cumulative Timesteps: 333,606,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 333606592...
Checkpoint 333606592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.99615
Policy Entropy: 1.07374
Value Function Loss: 3.49881

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.04419

Collected Steps per Second: 8,693.46864
Overall Steps per Second: 7,682.56477

Timestep Collection Time: 5.75213
Timestep Consumption Time: 0.75689
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.50902

Cumulative Model Updates: 19,999
Cumulative Timesteps: 333,656,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722.69937
Policy Entropy: 1.09112
Value Function Loss: 3.45275

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.17797
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.04679

Collected Steps per Second: 8,683.98887
Overall Steps per Second: 7,464.02749

Timestep Collection Time: 5.75980
Timestep Consumption Time: 0.94141
PPO Batch Consumption Time: 0.04991
Total Iteration Time: 6.70121

Cumulative Model Updates: 20,002
Cumulative Timesteps: 333,706,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 333706616...
Checkpoint 333706616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.79201
Policy Entropy: 1.05662
Value Function Loss: 3.47178

Mean KL Divergence: 0.03727
SB3 Clip Fraction: 0.22425
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 8,798.12896
Overall Steps per Second: 7,719.83599

Timestep Collection Time: 5.68416
Timestep Consumption Time: 0.79395
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.47812

Cumulative Model Updates: 20,005
Cumulative Timesteps: 333,756,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.62574
Policy Entropy: 1.07844
Value Function Loss: 3.50087

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16874
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 8,914.47733
Overall Steps per Second: 7,679.82843

Timestep Collection Time: 5.61177
Timestep Consumption Time: 0.90218
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 6.51395

Cumulative Model Updates: 20,008
Cumulative Timesteps: 333,806,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 333806652...
Checkpoint 333806652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.94151
Policy Entropy: 1.05964
Value Function Loss: 3.35218

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.04533

Collected Steps per Second: 8,650.42760
Overall Steps per Second: 7,537.81832

Timestep Collection Time: 5.78052
Timestep Consumption Time: 0.85323
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.63375

Cumulative Model Updates: 20,011
Cumulative Timesteps: 333,856,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.04191
Policy Entropy: 1.05854
Value Function Loss: 3.31528

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.04675

Collected Steps per Second: 8,863.15576
Overall Steps per Second: 7,790.25944

Timestep Collection Time: 5.64291
Timestep Consumption Time: 0.77716
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.42007

Cumulative Model Updates: 20,014
Cumulative Timesteps: 333,906,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 333906670...
Checkpoint 333906670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.24318
Policy Entropy: 1.07734
Value Function Loss: 3.16410

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16273
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 8,750.27501
Overall Steps per Second: 7,628.53625

Timestep Collection Time: 5.71616
Timestep Consumption Time: 0.84053
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.55670

Cumulative Model Updates: 20,017
Cumulative Timesteps: 333,956,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.03608
Policy Entropy: 1.07719
Value Function Loss: 3.32343

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 8,869.07549
Overall Steps per Second: 7,650.72869

Timestep Collection Time: 5.63937
Timestep Consumption Time: 0.89805
PPO Batch Consumption Time: 0.04994
Total Iteration Time: 6.53742

Cumulative Model Updates: 20,020
Cumulative Timesteps: 334,006,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 334006704...
Checkpoint 334006704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.41161
Policy Entropy: 1.07002
Value Function Loss: 3.29031

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.05755

Collected Steps per Second: 8,777.96830
Overall Steps per Second: 7,681.34346

Timestep Collection Time: 5.69927
Timestep Consumption Time: 0.81365
PPO Batch Consumption Time: 0.03913
Total Iteration Time: 6.51292

Cumulative Model Updates: 20,023
Cumulative Timesteps: 334,056,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.96686
Policy Entropy: 1.06422
Value Function Loss: 3.48460

Mean KL Divergence: 0.02996
SB3 Clip Fraction: 0.21588
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.06223

Collected Steps per Second: 9,069.68476
Overall Steps per Second: 7,817.69861

Timestep Collection Time: 5.51486
Timestep Consumption Time: 0.88319
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.39805

Cumulative Model Updates: 20,026
Cumulative Timesteps: 334,106,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 334106750...
Checkpoint 334106750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.85689
Policy Entropy: 1.08687
Value Function Loss: 3.45132

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.19616
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.06180

Collected Steps per Second: 9,250.94027
Overall Steps per Second: 8,101.49107

Timestep Collection Time: 5.40486
Timestep Consumption Time: 0.76685
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.17170

Cumulative Model Updates: 20,029
Cumulative Timesteps: 334,156,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.37585
Policy Entropy: 1.07465
Value Function Loss: 3.45949

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.05500

Collected Steps per Second: 9,429.07144
Overall Steps per Second: 8,100.64138

Timestep Collection Time: 5.30508
Timestep Consumption Time: 0.86998
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.17507

Cumulative Model Updates: 20,032
Cumulative Timesteps: 334,206,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 334206772...
Checkpoint 334206772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.06520
Policy Entropy: 1.08235
Value Function Loss: 3.25966

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.17455
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 8,825.20518
Overall Steps per Second: 7,679.09302

Timestep Collection Time: 5.66695
Timestep Consumption Time: 0.84580
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 6.51275

Cumulative Model Updates: 20,035
Cumulative Timesteps: 334,256,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.53111
Policy Entropy: 1.09166
Value Function Loss: 3.23949

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 8,879.62073
Overall Steps per Second: 7,680.95556

Timestep Collection Time: 5.63132
Timestep Consumption Time: 0.87881
PPO Batch Consumption Time: 0.05169
Total Iteration Time: 6.51013

Cumulative Model Updates: 20,038
Cumulative Timesteps: 334,306,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 334306788...
Checkpoint 334306788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.47128
Policy Entropy: 1.07932
Value Function Loss: 3.31136

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 8,899.50483
Overall Steps per Second: 7,786.06838

Timestep Collection Time: 5.61964
Timestep Consumption Time: 0.80363
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.42327

Cumulative Model Updates: 20,041
Cumulative Timesteps: 334,356,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.47674
Policy Entropy: 1.07138
Value Function Loss: 3.37307

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.04299

Collected Steps per Second: 9,097.68501
Overall Steps per Second: 8,005.53591

Timestep Collection Time: 5.49700
Timestep Consumption Time: 0.74992
PPO Batch Consumption Time: 0.04466
Total Iteration Time: 6.24693

Cumulative Model Updates: 20,044
Cumulative Timesteps: 334,406,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 334406810...
Checkpoint 334406810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.12845
Policy Entropy: 1.07391
Value Function Loss: 3.44267

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 8,969.71833
Overall Steps per Second: 7,768.48637

Timestep Collection Time: 5.57632
Timestep Consumption Time: 0.86226
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.43858

Cumulative Model Updates: 20,047
Cumulative Timesteps: 334,456,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.63977
Policy Entropy: 1.08452
Value Function Loss: 3.50231

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.04907

Collected Steps per Second: 8,985.06599
Overall Steps per Second: 7,803.61461

Timestep Collection Time: 5.56746
Timestep Consumption Time: 0.84290
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.41036

Cumulative Model Updates: 20,050
Cumulative Timesteps: 334,506,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 334506852...
Checkpoint 334506852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.22206
Policy Entropy: 1.09013
Value Function Loss: 3.42573

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 8,835.18548
Overall Steps per Second: 7,738.30896

Timestep Collection Time: 5.66168
Timestep Consumption Time: 0.80252
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.46420

Cumulative Model Updates: 20,053
Cumulative Timesteps: 334,556,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.16836
Policy Entropy: 1.09043
Value Function Loss: 3.42449

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 9,092.44830
Overall Steps per Second: 7,853.83470

Timestep Collection Time: 5.50105
Timestep Consumption Time: 0.86756
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 6.36861

Cumulative Model Updates: 20,056
Cumulative Timesteps: 334,606,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 334606892...
Checkpoint 334606892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.19335
Policy Entropy: 1.08703
Value Function Loss: 3.44670

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.05499

Collected Steps per Second: 8,763.88853
Overall Steps per Second: 7,779.12269

Timestep Collection Time: 5.70706
Timestep Consumption Time: 0.72246
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.42952

Cumulative Model Updates: 20,059
Cumulative Timesteps: 334,656,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.68075
Policy Entropy: 1.08636
Value Function Loss: 3.60110

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 8,884.72477
Overall Steps per Second: 7,702.82797

Timestep Collection Time: 5.63011
Timestep Consumption Time: 0.86387
PPO Batch Consumption Time: 0.04918
Total Iteration Time: 6.49398

Cumulative Model Updates: 20,062
Cumulative Timesteps: 334,706,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 334706930...
Checkpoint 334706930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.73089
Policy Entropy: 1.09726
Value Function Loss: 3.51324

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.04047

Collected Steps per Second: 8,480.55487
Overall Steps per Second: 7,482.50708

Timestep Collection Time: 5.89773
Timestep Consumption Time: 0.78666
PPO Batch Consumption Time: 0.03887
Total Iteration Time: 6.68439

Cumulative Model Updates: 20,065
Cumulative Timesteps: 334,756,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.62415
Policy Entropy: 1.10887
Value Function Loss: 3.58766

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 9,016.73746
Overall Steps per Second: 7,812.05940

Timestep Collection Time: 5.54591
Timestep Consumption Time: 0.85522
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.40113

Cumulative Model Updates: 20,068
Cumulative Timesteps: 334,806,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 334806952...
Checkpoint 334806952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.35749
Policy Entropy: 1.09768
Value Function Loss: 3.41136

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.04854

Collected Steps per Second: 8,923.20764
Overall Steps per Second: 7,803.56813

Timestep Collection Time: 5.60538
Timestep Consumption Time: 0.80425
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.40963

Cumulative Model Updates: 20,071
Cumulative Timesteps: 334,856,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.86931
Policy Entropy: 1.07282
Value Function Loss: 3.39388

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.19195
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.04938

Collected Steps per Second: 8,978.98676
Overall Steps per Second: 7,860.83326

Timestep Collection Time: 5.56989
Timestep Consumption Time: 0.79228
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 6.36218

Cumulative Model Updates: 20,074
Cumulative Timesteps: 334,906,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 334906982...
Checkpoint 334906982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.57843
Policy Entropy: 1.07978
Value Function Loss: 3.16990

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 8,853.26673
Overall Steps per Second: 7,651.76953

Timestep Collection Time: 5.64989
Timestep Consumption Time: 0.88716
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.53705

Cumulative Model Updates: 20,077
Cumulative Timesteps: 334,957,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.37696
Policy Entropy: 1.09037
Value Function Loss: 3.23289

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.16003
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.05705

Collected Steps per Second: 8,544.64258
Overall Steps per Second: 7,442.45501

Timestep Collection Time: 5.85185
Timestep Consumption Time: 0.86663
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 6.71848

Cumulative Model Updates: 20,080
Cumulative Timesteps: 335,007,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 335007004...
Checkpoint 335007004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.58784
Policy Entropy: 1.06922
Value Function Loss: 3.22384

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.05213

Collected Steps per Second: 9,180.06218
Overall Steps per Second: 7,944.38164

Timestep Collection Time: 5.44898
Timestep Consumption Time: 0.84754
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.29653

Cumulative Model Updates: 20,083
Cumulative Timesteps: 335,057,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.86393
Policy Entropy: 1.06940
Value Function Loss: 3.42527

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.05104

Collected Steps per Second: 8,807.36734
Overall Steps per Second: 7,733.34413

Timestep Collection Time: 5.67911
Timestep Consumption Time: 0.78873
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.46784

Cumulative Model Updates: 20,086
Cumulative Timesteps: 335,107,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 335107044...
Checkpoint 335107044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.24923
Policy Entropy: 1.08005
Value Function Loss: 3.38573

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 8,999.09901
Overall Steps per Second: 7,824.72516

Timestep Collection Time: 5.55922
Timestep Consumption Time: 0.83436
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 6.39358

Cumulative Model Updates: 20,089
Cumulative Timesteps: 335,157,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.84653
Policy Entropy: 1.08486
Value Function Loss: 3.46958

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 8,792.89147
Overall Steps per Second: 7,502.80662

Timestep Collection Time: 5.69005
Timestep Consumption Time: 0.97839
PPO Batch Consumption Time: 0.04666
Total Iteration Time: 6.66844

Cumulative Model Updates: 20,092
Cumulative Timesteps: 335,207,104

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 335207104...
Checkpoint 335207104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.04349
Policy Entropy: 1.08282
Value Function Loss: 3.37542

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.05160

Collected Steps per Second: 8,703.84509
Overall Steps per Second: 7,618.98496

Timestep Collection Time: 5.74780
Timestep Consumption Time: 0.81842
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.56623

Cumulative Model Updates: 20,095
Cumulative Timesteps: 335,257,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.60493
Policy Entropy: 1.08932
Value Function Loss: 3.44733

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.05612

Collected Steps per Second: 8,829.24311
Overall Steps per Second: 7,671.40664

Timestep Collection Time: 5.66549
Timestep Consumption Time: 0.85509
PPO Batch Consumption Time: 0.04701
Total Iteration Time: 6.52058

Cumulative Model Updates: 20,098
Cumulative Timesteps: 335,307,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 335307154...
Checkpoint 335307154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.94628
Policy Entropy: 1.09412
Value Function Loss: 3.55827

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 8,899.89289
Overall Steps per Second: 7,755.69306

Timestep Collection Time: 5.62074
Timestep Consumption Time: 0.82923
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.44997

Cumulative Model Updates: 20,101
Cumulative Timesteps: 335,357,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.49071
Policy Entropy: 1.09671
Value Function Loss: 3.52298

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 8,783.28253
Overall Steps per Second: 7,753.53181

Timestep Collection Time: 5.69491
Timestep Consumption Time: 0.75634
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.45125

Cumulative Model Updates: 20,104
Cumulative Timesteps: 335,407,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 335407198...
Checkpoint 335407198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.47035
Policy Entropy: 1.07568
Value Function Loss: 3.41768

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.04052

Collected Steps per Second: 8,672.61701
Overall Steps per Second: 7,588.82126

Timestep Collection Time: 5.76827
Timestep Consumption Time: 0.82379
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 6.59206

Cumulative Model Updates: 20,107
Cumulative Timesteps: 335,457,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.02198
Policy Entropy: 1.06411
Value Function Loss: 3.25380

Mean KL Divergence: 0.02640
SB3 Clip Fraction: 0.19260
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.03405

Collected Steps per Second: 8,929.08895
Overall Steps per Second: 7,792.88342

Timestep Collection Time: 5.60192
Timestep Consumption Time: 0.81676
PPO Batch Consumption Time: 0.03949
Total Iteration Time: 6.41868

Cumulative Model Updates: 20,110
Cumulative Timesteps: 335,507,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 335507244...
Checkpoint 335507244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.49674
Policy Entropy: 1.09719
Value Function Loss: 3.35257

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.04027

Collected Steps per Second: 8,841.77846
Overall Steps per Second: 7,674.31627

Timestep Collection Time: 5.65746
Timestep Consumption Time: 0.86065
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.51811

Cumulative Model Updates: 20,113
Cumulative Timesteps: 335,557,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.84414
Policy Entropy: 1.07295
Value Function Loss: 3.37722

Mean KL Divergence: 0.02727
SB3 Clip Fraction: 0.19117
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.03919

Collected Steps per Second: 8,993.75002
Overall Steps per Second: 7,775.91465

Timestep Collection Time: 5.56275
Timestep Consumption Time: 0.87122
PPO Batch Consumption Time: 0.04355
Total Iteration Time: 6.43397

Cumulative Model Updates: 20,116
Cumulative Timesteps: 335,607,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 335607296...
Checkpoint 335607296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.92152
Policy Entropy: 1.09973
Value Function Loss: 3.60606

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.04201
Value Function Update Magnitude: 0.03860

Collected Steps per Second: 8,778.89526
Overall Steps per Second: 7,711.17555

Timestep Collection Time: 5.69844
Timestep Consumption Time: 0.78903
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 6.48747

Cumulative Model Updates: 20,119
Cumulative Timesteps: 335,657,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.78408
Policy Entropy: 1.09835
Value Function Loss: 3.49462

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.03776

Collected Steps per Second: 8,577.05969
Overall Steps per Second: 7,458.04662

Timestep Collection Time: 5.83253
Timestep Consumption Time: 0.87512
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 6.70765

Cumulative Model Updates: 20,122
Cumulative Timesteps: 335,707,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 335707348...
Checkpoint 335707348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.33824
Policy Entropy: 1.08938
Value Function Loss: 3.59307

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.03833

Collected Steps per Second: 8,588.68616
Overall Steps per Second: 7,484.13437

Timestep Collection Time: 5.82348
Timestep Consumption Time: 0.85946
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 6.68294

Cumulative Model Updates: 20,125
Cumulative Timesteps: 335,757,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.03155
Policy Entropy: 1.07017
Value Function Loss: 3.34543

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.16586
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.03451

Collected Steps per Second: 9,069.00527
Overall Steps per Second: 7,792.91967

Timestep Collection Time: 5.51527
Timestep Consumption Time: 0.90312
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.41839

Cumulative Model Updates: 20,128
Cumulative Timesteps: 335,807,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 335807382...
Checkpoint 335807382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.23278
Policy Entropy: 1.08839
Value Function Loss: 3.60416

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.05967

Collected Steps per Second: 8,725.85568
Overall Steps per Second: 7,586.80999

Timestep Collection Time: 5.73216
Timestep Consumption Time: 0.86060
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.59276

Cumulative Model Updates: 20,131
Cumulative Timesteps: 335,857,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.40089
Policy Entropy: 1.09582
Value Function Loss: 3.58847

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 8,910.15789
Overall Steps per Second: 7,833.28823

Timestep Collection Time: 5.61180
Timestep Consumption Time: 0.77147
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.38327

Cumulative Model Updates: 20,134
Cumulative Timesteps: 335,907,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 335907402...
Checkpoint 335907402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.58592
Policy Entropy: 1.08224
Value Function Loss: 3.49358

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 9,120.28109
Overall Steps per Second: 7,819.99319

Timestep Collection Time: 5.48404
Timestep Consumption Time: 0.91187
PPO Batch Consumption Time: 0.04772
Total Iteration Time: 6.39591

Cumulative Model Updates: 20,137
Cumulative Timesteps: 335,957,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.92823
Policy Entropy: 1.07486
Value Function Loss: 3.35560

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 9,351.22082
Overall Steps per Second: 8,024.43587

Timestep Collection Time: 5.34903
Timestep Consumption Time: 0.88443
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 6.23346

Cumulative Model Updates: 20,140
Cumulative Timesteps: 336,007,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 336007438...
Checkpoint 336007438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.24723
Policy Entropy: 1.08118
Value Function Loss: 3.16413

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 9,358.91944
Overall Steps per Second: 8,041.51830

Timestep Collection Time: 5.34485
Timestep Consumption Time: 0.87562
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.22047

Cumulative Model Updates: 20,143
Cumulative Timesteps: 336,057,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.82247
Policy Entropy: 1.08850
Value Function Loss: 3.21185

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.04786

Collected Steps per Second: 8,881.99653
Overall Steps per Second: 7,715.46979

Timestep Collection Time: 5.63072
Timestep Consumption Time: 0.85133
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.48204

Cumulative Model Updates: 20,146
Cumulative Timesteps: 336,107,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 336107472...
Checkpoint 336107472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.92975
Policy Entropy: 1.08692
Value Function Loss: 3.22374

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.04004

Collected Steps per Second: 8,557.11287
Overall Steps per Second: 7,574.16397

Timestep Collection Time: 5.84543
Timestep Consumption Time: 0.75860
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.60403

Cumulative Model Updates: 20,149
Cumulative Timesteps: 336,157,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.09739
Policy Entropy: 1.07512
Value Function Loss: 3.46578

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.03552

Collected Steps per Second: 8,911.18361
Overall Steps per Second: 7,708.73690

Timestep Collection Time: 5.61384
Timestep Consumption Time: 0.87568
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 6.48952

Cumulative Model Updates: 20,152
Cumulative Timesteps: 336,207,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 336207518...
Checkpoint 336207518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.29479
Policy Entropy: 1.06842
Value Function Loss: 3.56259

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.03385

Collected Steps per Second: 8,881.68600
Overall Steps per Second: 7,734.95737

Timestep Collection Time: 5.63181
Timestep Consumption Time: 0.83493
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 6.46675

Cumulative Model Updates: 20,155
Cumulative Timesteps: 336,257,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.50455
Policy Entropy: 1.10112
Value Function Loss: 3.47334

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.03222

Collected Steps per Second: 8,949.77067
Overall Steps per Second: 7,753.85618

Timestep Collection Time: 5.58696
Timestep Consumption Time: 0.86170
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 6.44866

Cumulative Model Updates: 20,158
Cumulative Timesteps: 336,307,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 336307540...
Checkpoint 336307540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.29391
Policy Entropy: 1.09289
Value Function Loss: 3.50296

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.03569

Collected Steps per Second: 8,867.53284
Overall Steps per Second: 7,638.91958

Timestep Collection Time: 5.64058
Timestep Consumption Time: 0.90721
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.54778

Cumulative Model Updates: 20,161
Cumulative Timesteps: 336,357,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.63523
Policy Entropy: 1.09039
Value Function Loss: 3.50753

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.03483

Collected Steps per Second: 8,829.64935
Overall Steps per Second: 7,830.77191

Timestep Collection Time: 5.66432
Timestep Consumption Time: 0.72253
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.38685

Cumulative Model Updates: 20,164
Cumulative Timesteps: 336,407,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 336407572...
Checkpoint 336407572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.08408
Policy Entropy: 1.08279
Value Function Loss: 3.55878

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.17045
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.03398

Collected Steps per Second: 8,878.29477
Overall Steps per Second: 7,667.35444

Timestep Collection Time: 5.63306
Timestep Consumption Time: 0.88966
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.52272

Cumulative Model Updates: 20,167
Cumulative Timesteps: 336,457,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.78338
Policy Entropy: 1.09887
Value Function Loss: 3.68638

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.03711

Collected Steps per Second: 8,517.00216
Overall Steps per Second: 7,445.24345

Timestep Collection Time: 5.87131
Timestep Consumption Time: 0.84519
PPO Batch Consumption Time: 0.04977
Total Iteration Time: 6.71650

Cumulative Model Updates: 20,170
Cumulative Timesteps: 336,507,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 336507590...
Checkpoint 336507590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.69316
Policy Entropy: 1.10473
Value Function Loss: 3.57350

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.03692

Collected Steps per Second: 9,092.64192
Overall Steps per Second: 7,917.42651

Timestep Collection Time: 5.50071
Timestep Consumption Time: 0.81649
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.31720

Cumulative Model Updates: 20,173
Cumulative Timesteps: 336,557,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.02211
Policy Entropy: 1.08442
Value Function Loss: 3.69182

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.04839

Collected Steps per Second: 8,550.16410
Overall Steps per Second: 7,469.24097

Timestep Collection Time: 5.84995
Timestep Consumption Time: 0.84658
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 6.69653

Cumulative Model Updates: 20,176
Cumulative Timesteps: 336,607,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 336607624...
Checkpoint 336607624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.05547
Policy Entropy: 1.08990
Value Function Loss: 3.49219

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 8,559.85094
Overall Steps per Second: 7,505.68189

Timestep Collection Time: 5.84403
Timestep Consumption Time: 0.82079
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.66482

Cumulative Model Updates: 20,179
Cumulative Timesteps: 336,657,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.53647
Policy Entropy: 1.09749
Value Function Loss: 3.52914

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.18233
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 8,849.60450
Overall Steps per Second: 7,612.62880

Timestep Collection Time: 5.65133
Timestep Consumption Time: 0.91828
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.56961

Cumulative Model Updates: 20,182
Cumulative Timesteps: 336,707,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 336707660...
Checkpoint 336707660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.20167
Policy Entropy: 1.06876
Value Function Loss: 3.43466

Mean KL Divergence: 0.04106
SB3 Clip Fraction: 0.20555
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 8,802.52309
Overall Steps per Second: 7,664.24392

Timestep Collection Time: 5.68360
Timestep Consumption Time: 0.84412
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.52771

Cumulative Model Updates: 20,185
Cumulative Timesteps: 336,757,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.78100
Policy Entropy: 1.08918
Value Function Loss: 3.46269

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.05176

Collected Steps per Second: 9,225.03203
Overall Steps per Second: 7,992.96941

Timestep Collection Time: 5.42242
Timestep Consumption Time: 0.83583
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.25825

Cumulative Model Updates: 20,188
Cumulative Timesteps: 336,807,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 336807712...
Checkpoint 336807712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.27333
Policy Entropy: 1.09416
Value Function Loss: 3.40768

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.05498

Collected Steps per Second: 8,626.89586
Overall Steps per Second: 7,589.02819

Timestep Collection Time: 5.79606
Timestep Consumption Time: 0.79266
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 6.58872

Cumulative Model Updates: 20,191
Cumulative Timesteps: 336,857,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.11648
Policy Entropy: 1.08967
Value Function Loss: 3.49199

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.16079
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 8,991.28262
Overall Steps per Second: 7,946.41853

Timestep Collection Time: 5.56228
Timestep Consumption Time: 0.73138
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 6.29365

Cumulative Model Updates: 20,194
Cumulative Timesteps: 336,907,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 336907726...
Checkpoint 336907726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.73371
Policy Entropy: 1.08662
Value Function Loss: 3.53420

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 9,027.55788
Overall Steps per Second: 7,827.97450

Timestep Collection Time: 5.54037
Timestep Consumption Time: 0.84902
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 6.38939

Cumulative Model Updates: 20,197
Cumulative Timesteps: 336,957,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.00961
Policy Entropy: 1.09011
Value Function Loss: 3.52190

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.06683

Collected Steps per Second: 9,003.75211
Overall Steps per Second: 7,791.19801

Timestep Collection Time: 5.55546
Timestep Consumption Time: 0.86460
PPO Batch Consumption Time: 0.05141
Total Iteration Time: 6.42007

Cumulative Model Updates: 20,200
Cumulative Timesteps: 337,007,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 337007762...
Checkpoint 337007762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.93524
Policy Entropy: 1.10028
Value Function Loss: 3.47731

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.15262
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 8,825.42328
Overall Steps per Second: 7,606.29491

Timestep Collection Time: 5.66613
Timestep Consumption Time: 0.90816
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 6.57429

Cumulative Model Updates: 20,203
Cumulative Timesteps: 337,057,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.50275
Policy Entropy: 1.08171
Value Function Loss: 3.46064

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 8,785.41544
Overall Steps per Second: 7,630.03390

Timestep Collection Time: 5.69398
Timestep Consumption Time: 0.86221
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 6.55620

Cumulative Model Updates: 20,206
Cumulative Timesteps: 337,107,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 337107792...
Checkpoint 337107792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.94408
Policy Entropy: 1.10126
Value Function Loss: 3.52303

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.16952
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 8,597.31185
Overall Steps per Second: 7,549.73704

Timestep Collection Time: 5.81763
Timestep Consumption Time: 0.80723
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.62487

Cumulative Model Updates: 20,209
Cumulative Timesteps: 337,157,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.43783
Policy Entropy: 1.10062
Value Function Loss: 3.55762

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.09946

Collected Steps per Second: 9,195.43797
Overall Steps per Second: 7,919.42395

Timestep Collection Time: 5.43987
Timestep Consumption Time: 0.87650
PPO Batch Consumption Time: 0.04534
Total Iteration Time: 6.31637

Cumulative Model Updates: 20,212
Cumulative Timesteps: 337,207,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 337207830...
Checkpoint 337207830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.46051
Policy Entropy: 1.09754
Value Function Loss: 3.49345

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.08450

Collected Steps per Second: 8,741.88133
Overall Steps per Second: 7,535.39242

Timestep Collection Time: 5.72280
Timestep Consumption Time: 0.91627
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 6.63907

Cumulative Model Updates: 20,215
Cumulative Timesteps: 337,257,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.49360
Policy Entropy: 1.08257
Value Function Loss: 3.46779

Mean KL Divergence: 0.03341
SB3 Clip Fraction: 0.18454
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 8,629.66507
Overall Steps per Second: 7,494.78964

Timestep Collection Time: 5.79744
Timestep Consumption Time: 0.87786
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.67530

Cumulative Model Updates: 20,218
Cumulative Timesteps: 337,307,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 337307888...
Checkpoint 337307888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.41748
Policy Entropy: 1.09559
Value Function Loss: 3.27089

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.07210

Collected Steps per Second: 8,761.69319
Overall Steps per Second: 7,611.93725

Timestep Collection Time: 5.70826
Timestep Consumption Time: 0.86221
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.57047

Cumulative Model Updates: 20,221
Cumulative Timesteps: 337,357,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.05300
Policy Entropy: 1.08097
Value Function Loss: 3.26934

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 8,748.69020
Overall Steps per Second: 7,722.76121

Timestep Collection Time: 5.71834
Timestep Consumption Time: 0.75965
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.47799

Cumulative Model Updates: 20,224
Cumulative Timesteps: 337,407,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 337407930...
Checkpoint 337407930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.72707
Policy Entropy: 1.06804
Value Function Loss: 3.21426

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.06749
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 8,889.16772
Overall Steps per Second: 7,653.06029

Timestep Collection Time: 5.62662
Timestep Consumption Time: 0.90880
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 6.53542

Cumulative Model Updates: 20,227
Cumulative Timesteps: 337,457,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.73442
Policy Entropy: 1.06636
Value Function Loss: 3.29127

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 9,035.85136
Overall Steps per Second: 7,669.59090

Timestep Collection Time: 5.53683
Timestep Consumption Time: 0.98633
PPO Batch Consumption Time: 0.04794
Total Iteration Time: 6.52316

Cumulative Model Updates: 20,230
Cumulative Timesteps: 337,507,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 337507976...
Checkpoint 337507976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686.80442
Policy Entropy: 1.08018
Value Function Loss: 3.34701

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.05217

Collected Steps per Second: 9,147.13323
Overall Steps per Second: 7,922.72833

Timestep Collection Time: 5.46860
Timestep Consumption Time: 0.84514
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 6.31373

Cumulative Model Updates: 20,233
Cumulative Timesteps: 337,557,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.32535
Policy Entropy: 1.09464
Value Function Loss: 3.42187

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.05338

Collected Steps per Second: 8,686.42553
Overall Steps per Second: 7,552.22519

Timestep Collection Time: 5.75818
Timestep Consumption Time: 0.86477
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 6.62295

Cumulative Model Updates: 20,236
Cumulative Timesteps: 337,608,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 337608016...
Checkpoint 337608016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.45705
Policy Entropy: 1.09422
Value Function Loss: 3.60630

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.07409

Collected Steps per Second: 8,956.81331
Overall Steps per Second: 7,877.25370

Timestep Collection Time: 5.58391
Timestep Consumption Time: 0.76526
PPO Batch Consumption Time: 0.04541
Total Iteration Time: 6.34917

Cumulative Model Updates: 20,239
Cumulative Timesteps: 337,658,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.15262
Policy Entropy: 1.09010
Value Function Loss: 3.50048

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 9,300.00331
Overall Steps per Second: 7,957.27508

Timestep Collection Time: 5.37806
Timestep Consumption Time: 0.90751
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.28557

Cumulative Model Updates: 20,242
Cumulative Timesteps: 337,708,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 337708046...
Checkpoint 337708046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.54580
Policy Entropy: 1.08560
Value Function Loss: 3.52983

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.07876
Value Function Update Magnitude: 0.05901

Collected Steps per Second: 9,075.94171
Overall Steps per Second: 7,836.58293

Timestep Collection Time: 5.51083
Timestep Consumption Time: 0.87154
PPO Batch Consumption Time: 0.04964
Total Iteration Time: 6.38237

Cumulative Model Updates: 20,245
Cumulative Timesteps: 337,758,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.74903
Policy Entropy: 1.08703
Value Function Loss: 3.33872

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.07544
Value Function Update Magnitude: 0.04593

Collected Steps per Second: 9,221.28644
Overall Steps per Second: 7,900.72838

Timestep Collection Time: 5.42310
Timestep Consumption Time: 0.90644
PPO Batch Consumption Time: 0.05920
Total Iteration Time: 6.32954

Cumulative Model Updates: 20,248
Cumulative Timesteps: 337,808,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 337808070...
Checkpoint 337808070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.31746
Policy Entropy: 1.08152
Value Function Loss: 3.43405

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.07462
Value Function Update Magnitude: 0.04773

Collected Steps per Second: 9,159.78029
Overall Steps per Second: 7,943.12274

Timestep Collection Time: 5.45952
Timestep Consumption Time: 0.83624
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.29576

Cumulative Model Updates: 20,251
Cumulative Timesteps: 337,858,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.77267
Policy Entropy: 1.07630
Value Function Loss: 3.48578

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.07281
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 9,113.49577
Overall Steps per Second: 7,969.24207

Timestep Collection Time: 5.48747
Timestep Consumption Time: 0.78791
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.27538

Cumulative Model Updates: 20,254
Cumulative Timesteps: 337,908,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 337908088...
Checkpoint 337908088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.71137
Policy Entropy: 1.07841
Value Function Loss: 3.55374

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.04607

Collected Steps per Second: 9,030.91117
Overall Steps per Second: 7,829.12629

Timestep Collection Time: 5.53942
Timestep Consumption Time: 0.85031
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.38973

Cumulative Model Updates: 20,257
Cumulative Timesteps: 337,958,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.38631
Policy Entropy: 1.09452
Value Function Loss: 3.65874

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 8,733.64184
Overall Steps per Second: 7,608.93343

Timestep Collection Time: 5.72819
Timestep Consumption Time: 0.84671
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.57490

Cumulative Model Updates: 20,260
Cumulative Timesteps: 338,008,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 338008142...
Checkpoint 338008142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.96350
Policy Entropy: 1.10155
Value Function Loss: 3.53793

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 8,963.84690
Overall Steps per Second: 7,739.01226

Timestep Collection Time: 5.57930
Timestep Consumption Time: 0.88302
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.46232

Cumulative Model Updates: 20,263
Cumulative Timesteps: 338,058,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.03299
Policy Entropy: 1.11098
Value Function Loss: 3.53296

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.04705

Collected Steps per Second: 9,173.33808
Overall Steps per Second: 7,981.34241

Timestep Collection Time: 5.45080
Timestep Consumption Time: 0.81406
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.26486

Cumulative Model Updates: 20,266
Cumulative Timesteps: 338,108,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 338108156...
Checkpoint 338108156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.10304
Policy Entropy: 1.09704
Value Function Loss: 3.42854

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.05449

Collected Steps per Second: 8,864.60915
Overall Steps per Second: 7,840.48996

Timestep Collection Time: 5.64176
Timestep Consumption Time: 0.73692
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 6.37868

Cumulative Model Updates: 20,269
Cumulative Timesteps: 338,158,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.78789
Policy Entropy: 1.10462
Value Function Loss: 3.35897

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.06130

Collected Steps per Second: 9,016.95179
Overall Steps per Second: 7,683.26916

Timestep Collection Time: 5.54711
Timestep Consumption Time: 0.96288
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.50999

Cumulative Model Updates: 20,272
Cumulative Timesteps: 338,208,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 338208186...
Checkpoint 338208186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.29098
Policy Entropy: 1.09776
Value Function Loss: 3.28190

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.06186

Collected Steps per Second: 8,711.73354
Overall Steps per Second: 7,633.10243

Timestep Collection Time: 5.73962
Timestep Consumption Time: 0.81106
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.55068

Cumulative Model Updates: 20,275
Cumulative Timesteps: 338,258,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.13523
Policy Entropy: 1.11559
Value Function Loss: 3.22235

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.06496

Collected Steps per Second: 9,243.60406
Overall Steps per Second: 7,976.50059

Timestep Collection Time: 5.41153
Timestep Consumption Time: 0.85965
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.27117

Cumulative Model Updates: 20,278
Cumulative Timesteps: 338,308,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 338308210...
Checkpoint 338308210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.56252
Policy Entropy: 1.11082
Value Function Loss: 3.34933

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 8,829.03595
Overall Steps per Second: 7,716.72574

Timestep Collection Time: 5.66449
Timestep Consumption Time: 0.81650
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 6.48099

Cumulative Model Updates: 20,281
Cumulative Timesteps: 338,358,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.85851
Policy Entropy: 1.11554
Value Function Loss: 3.55376

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.07119

Collected Steps per Second: 9,073.80923
Overall Steps per Second: 7,955.25397

Timestep Collection Time: 5.51169
Timestep Consumption Time: 0.77498
PPO Batch Consumption Time: 0.04666
Total Iteration Time: 6.28666

Cumulative Model Updates: 20,284
Cumulative Timesteps: 338,408,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 338408234...
Checkpoint 338408234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.28499
Policy Entropy: 1.11220
Value Function Loss: 3.53458

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.08676

Collected Steps per Second: 8,554.23186
Overall Steps per Second: 7,488.12272

Timestep Collection Time: 5.84716
Timestep Consumption Time: 0.83248
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.67964

Cumulative Model Updates: 20,287
Cumulative Timesteps: 338,458,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.69238
Policy Entropy: 1.11417
Value Function Loss: 3.41244

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 9,010.03546
Overall Steps per Second: 7,817.59031

Timestep Collection Time: 5.55048
Timestep Consumption Time: 0.84663
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 6.39711

Cumulative Model Updates: 20,290
Cumulative Timesteps: 338,508,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 338508262...
Checkpoint 338508262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.33646
Policy Entropy: 1.11116
Value Function Loss: 3.19774

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.08343

Collected Steps per Second: 8,965.99835
Overall Steps per Second: 7,779.19163

Timestep Collection Time: 5.57930
Timestep Consumption Time: 0.85119
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.43049

Cumulative Model Updates: 20,293
Cumulative Timesteps: 338,558,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.09212
Policy Entropy: 1.11108
Value Function Loss: 3.24979

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 8,920.81461
Overall Steps per Second: 7,754.22028

Timestep Collection Time: 5.60509
Timestep Consumption Time: 0.84327
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.44836

Cumulative Model Updates: 20,296
Cumulative Timesteps: 338,608,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 338608288...
Checkpoint 338608288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.25341
Policy Entropy: 1.11680
Value Function Loss: 3.15698

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.06559

Collected Steps per Second: 9,006.91836
Overall Steps per Second: 7,985.87638

Timestep Collection Time: 5.55240
Timestep Consumption Time: 0.70991
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 6.26231

Cumulative Model Updates: 20,299
Cumulative Timesteps: 338,658,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.45461
Policy Entropy: 1.12433
Value Function Loss: 3.33718

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.06131

Collected Steps per Second: 8,893.59616
Overall Steps per Second: 7,721.02635

Timestep Collection Time: 5.62270
Timestep Consumption Time: 0.85390
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.47660

Cumulative Model Updates: 20,302
Cumulative Timesteps: 338,708,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 338708304...
Checkpoint 338708304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.20888
Policy Entropy: 1.13074
Value Function Loss: 3.48824

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 8,788.79091
Overall Steps per Second: 7,594.12016

Timestep Collection Time: 5.69202
Timestep Consumption Time: 0.89544
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.58746

Cumulative Model Updates: 20,305
Cumulative Timesteps: 338,758,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.95147
Policy Entropy: 1.12771
Value Function Loss: 3.65302

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 9,215.22134
Overall Steps per Second: 7,894.33122

Timestep Collection Time: 5.42884
Timestep Consumption Time: 0.90836
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.33721

Cumulative Model Updates: 20,308
Cumulative Timesteps: 338,808,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 338808358...
Checkpoint 338808358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.91626
Policy Entropy: 1.13137
Value Function Loss: 3.63782

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 8,923.56313
Overall Steps per Second: 7,765.96477

Timestep Collection Time: 5.60516
Timestep Consumption Time: 0.83551
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.44067

Cumulative Model Updates: 20,311
Cumulative Timesteps: 338,858,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.58910
Policy Entropy: 1.13069
Value Function Loss: 3.59423

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 8,774.52014
Overall Steps per Second: 7,549.63442

Timestep Collection Time: 5.70105
Timestep Consumption Time: 0.92496
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.62602

Cumulative Model Updates: 20,314
Cumulative Timesteps: 338,908,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 338908400...
Checkpoint 338908400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.62463
Policy Entropy: 1.13863
Value Function Loss: 3.61646

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.07943

Collected Steps per Second: 9,071.53305
Overall Steps per Second: 7,838.52599

Timestep Collection Time: 5.51351
Timestep Consumption Time: 0.86728
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.38079

Cumulative Model Updates: 20,317
Cumulative Timesteps: 338,958,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.69007
Policy Entropy: 1.13666
Value Function Loss: 3.46315

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 8,893.30212
Overall Steps per Second: 7,758.42012

Timestep Collection Time: 5.62288
Timestep Consumption Time: 0.82250
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.44538

Cumulative Model Updates: 20,320
Cumulative Timesteps: 339,008,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 339008422...
Checkpoint 339008422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.84718
Policy Entropy: 1.14538
Value Function Loss: 3.40405

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.06463

Collected Steps per Second: 9,101.85016
Overall Steps per Second: 7,884.84265

Timestep Collection Time: 5.49581
Timestep Consumption Time: 0.84827
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.34407

Cumulative Model Updates: 20,323
Cumulative Timesteps: 339,058,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.59865
Policy Entropy: 1.14643
Value Function Loss: 3.37469

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 8,817.06028
Overall Steps per Second: 7,677.98951

Timestep Collection Time: 5.67128
Timestep Consumption Time: 0.84136
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.51264

Cumulative Model Updates: 20,326
Cumulative Timesteps: 339,108,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 339108448...
Checkpoint 339108448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.42440
Policy Entropy: 1.15948
Value Function Loss: 3.25088

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.06878
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 8,733.58359
Overall Steps per Second: 7,743.75629

Timestep Collection Time: 5.72732
Timestep Consumption Time: 0.73208
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 6.45940

Cumulative Model Updates: 20,329
Cumulative Timesteps: 339,158,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.15426
Policy Entropy: 1.14613
Value Function Loss: 3.10821

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 9,104.48248
Overall Steps per Second: 7,922.44639

Timestep Collection Time: 5.49290
Timestep Consumption Time: 0.81955
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.31244

Cumulative Model Updates: 20,332
Cumulative Timesteps: 339,208,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 339208478...
Checkpoint 339208478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.48588
Policy Entropy: 1.14320
Value Function Loss: 3.13561

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.06835

Collected Steps per Second: 9,140.35382
Overall Steps per Second: 7,924.58233

Timestep Collection Time: 5.47331
Timestep Consumption Time: 0.83970
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.31301

Cumulative Model Updates: 20,335
Cumulative Timesteps: 339,258,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.58077
Policy Entropy: 1.15235
Value Function Loss: 3.28928

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 9,166.06409
Overall Steps per Second: 7,940.44813

Timestep Collection Time: 5.45687
Timestep Consumption Time: 0.84227
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.29914

Cumulative Model Updates: 20,338
Cumulative Timesteps: 339,308,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 339308524...
Checkpoint 339308524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.69280
Policy Entropy: 1.15410
Value Function Loss: 3.38697

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 9,065.41527
Overall Steps per Second: 7,824.93113

Timestep Collection Time: 5.51856
Timestep Consumption Time: 0.87486
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.39341

Cumulative Model Updates: 20,341
Cumulative Timesteps: 339,358,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.32892
Policy Entropy: 1.14152
Value Function Loss: 3.31219

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 8,692.65410
Overall Steps per Second: 7,631.84036

Timestep Collection Time: 5.75267
Timestep Consumption Time: 0.79961
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.55229

Cumulative Model Updates: 20,344
Cumulative Timesteps: 339,408,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 339408558...
Checkpoint 339408558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.31039
Policy Entropy: 1.13628
Value Function Loss: 3.21264

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 9,269.92603
Overall Steps per Second: 7,947.86203

Timestep Collection Time: 5.39379
Timestep Consumption Time: 0.89721
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.29100

Cumulative Model Updates: 20,347
Cumulative Timesteps: 339,458,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.82772
Policy Entropy: 1.15363
Value Function Loss: 3.10019

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 9,029.45851
Overall Steps per Second: 7,829.60088

Timestep Collection Time: 5.53876
Timestep Consumption Time: 0.84879
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.38755

Cumulative Model Updates: 20,350
Cumulative Timesteps: 339,508,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 339508570...
Checkpoint 339508570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.16919
Policy Entropy: 1.15899
Value Function Loss: 3.25090

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 9,322.05914
Overall Steps per Second: 8,039.13446

Timestep Collection Time: 5.36534
Timestep Consumption Time: 0.85623
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.22157

Cumulative Model Updates: 20,353
Cumulative Timesteps: 339,558,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.30603
Policy Entropy: 1.15828
Value Function Loss: 3.31810

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 9,498.47007
Overall Steps per Second: 8,018.44586

Timestep Collection Time: 5.26632
Timestep Consumption Time: 0.97204
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.23837

Cumulative Model Updates: 20,356
Cumulative Timesteps: 339,608,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 339608608...
Checkpoint 339608608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.37424
Policy Entropy: 1.14021
Value Function Loss: 3.38200

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.06637

Collected Steps per Second: 9,325.03336
Overall Steps per Second: 8,120.02494

Timestep Collection Time: 5.36384
Timestep Consumption Time: 0.79599
PPO Batch Consumption Time: 0.04875
Total Iteration Time: 6.15983

Cumulative Model Updates: 20,359
Cumulative Timesteps: 339,658,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.64541
Policy Entropy: 1.14652
Value Function Loss: 3.22454

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 9,342.36578
Overall Steps per Second: 8,016.50272

Timestep Collection Time: 5.35325
Timestep Consumption Time: 0.88538
PPO Batch Consumption Time: 0.05065
Total Iteration Time: 6.23863

Cumulative Model Updates: 20,362
Cumulative Timesteps: 339,708,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 339708638...
Checkpoint 339708638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.15711
Policy Entropy: 1.14094
Value Function Loss: 3.30506

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.09243

Collected Steps per Second: 9,541.29437
Overall Steps per Second: 8,123.89017

Timestep Collection Time: 5.24122
Timestep Consumption Time: 0.91445
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.15567

Cumulative Model Updates: 20,365
Cumulative Timesteps: 339,758,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.31743
Policy Entropy: 1.12534
Value Function Loss: 3.24006

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.07904

Collected Steps per Second: 8,754.65321
Overall Steps per Second: 7,700.35563

Timestep Collection Time: 5.71445
Timestep Consumption Time: 0.78240
PPO Batch Consumption Time: 0.04921
Total Iteration Time: 6.49684

Cumulative Model Updates: 20,368
Cumulative Timesteps: 339,808,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 339808674...
Checkpoint 339808674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.16306
Policy Entropy: 1.13717
Value Function Loss: 3.14126

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.07786

Collected Steps per Second: 8,579.48066
Overall Steps per Second: 7,407.18608

Timestep Collection Time: 5.82809
Timestep Consumption Time: 0.92238
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 6.75047

Cumulative Model Updates: 20,371
Cumulative Timesteps: 339,858,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.68116
Policy Entropy: 1.13124
Value Function Loss: 3.10470

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.07993
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 9,161.45920
Overall Steps per Second: 8,072.46370

Timestep Collection Time: 5.45874
Timestep Consumption Time: 0.73640
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.19513

Cumulative Model Updates: 20,374
Cumulative Timesteps: 339,908,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 339908686...
Checkpoint 339908686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.41219
Policy Entropy: 1.13228
Value Function Loss: 3.18523

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 8,819.60190
Overall Steps per Second: 7,686.88989

Timestep Collection Time: 5.67146
Timestep Consumption Time: 0.83573
PPO Batch Consumption Time: 0.04756
Total Iteration Time: 6.50718

Cumulative Model Updates: 20,377
Cumulative Timesteps: 339,958,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.26895
Policy Entropy: 1.15319
Value Function Loss: 3.30123

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 8,607.64366
Overall Steps per Second: 7,491.47661

Timestep Collection Time: 5.80902
Timestep Consumption Time: 0.86550
PPO Batch Consumption Time: 0.04717
Total Iteration Time: 6.67452

Cumulative Model Updates: 20,380
Cumulative Timesteps: 340,008,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 340008708...
Checkpoint 340008708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.71724
Policy Entropy: 1.14171
Value Function Loss: 3.33780

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 9,002.03414
Overall Steps per Second: 7,857.34099

Timestep Collection Time: 5.55430
Timestep Consumption Time: 0.80918
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 6.36348

Cumulative Model Updates: 20,383
Cumulative Timesteps: 340,058,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.62434
Policy Entropy: 1.13811
Value Function Loss: 3.36688

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.06429

Collected Steps per Second: 8,769.27698
Overall Steps per Second: 7,698.08108

Timestep Collection Time: 5.70423
Timestep Consumption Time: 0.79375
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 6.49798

Cumulative Model Updates: 20,386
Cumulative Timesteps: 340,108,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 340108730...
Checkpoint 340108730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.97132
Policy Entropy: 1.12276
Value Function Loss: 3.34690

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.17900
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.06104

Collected Steps per Second: 8,897.13446
Overall Steps per Second: 7,850.80161

Timestep Collection Time: 5.62069
Timestep Consumption Time: 0.74911
PPO Batch Consumption Time: 0.05025
Total Iteration Time: 6.36980

Cumulative Model Updates: 20,389
Cumulative Timesteps: 340,158,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.04192
Policy Entropy: 1.13665
Value Function Loss: 3.28666

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 8,539.88399
Overall Steps per Second: 7,444.94391

Timestep Collection Time: 5.85839
Timestep Consumption Time: 0.86160
PPO Batch Consumption Time: 0.04710
Total Iteration Time: 6.72000

Cumulative Model Updates: 20,392
Cumulative Timesteps: 340,208,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 340208768...
Checkpoint 340208768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.35208
Policy Entropy: 1.13443
Value Function Loss: 3.21026

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.05574

Collected Steps per Second: 8,900.64392
Overall Steps per Second: 7,755.75252

Timestep Collection Time: 5.61825
Timestep Consumption Time: 0.82936
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 6.44760

Cumulative Model Updates: 20,395
Cumulative Timesteps: 340,258,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.09472
Policy Entropy: 1.12708
Value Function Loss: 3.26906

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.06403

Collected Steps per Second: 8,864.64487
Overall Steps per Second: 7,530.18318

Timestep Collection Time: 5.64219
Timestep Consumption Time: 0.99988
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 6.64207

Cumulative Model Updates: 20,398
Cumulative Timesteps: 340,308,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 340308790...
Checkpoint 340308790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.17408
Policy Entropy: 1.12762
Value Function Loss: 3.29203

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.08280

Collected Steps per Second: 8,852.34618
Overall Steps per Second: 7,737.53085

Timestep Collection Time: 5.65025
Timestep Consumption Time: 0.81408
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.46434

Cumulative Model Updates: 20,401
Cumulative Timesteps: 340,358,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.64083
Policy Entropy: 1.13440
Value Function Loss: 3.30791

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 8,894.35222
Overall Steps per Second: 7,879.47627

Timestep Collection Time: 5.62424
Timestep Consumption Time: 0.72440
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.34865

Cumulative Model Updates: 20,404
Cumulative Timesteps: 340,408,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 340408832...
Checkpoint 340408832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.94000
Policy Entropy: 1.13033
Value Function Loss: 3.25192

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 8,749.92507
Overall Steps per Second: 7,651.06740

Timestep Collection Time: 5.71731
Timestep Consumption Time: 0.82113
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.53843

Cumulative Model Updates: 20,407
Cumulative Timesteps: 340,458,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.57641
Policy Entropy: 1.12300
Value Function Loss: 3.16238

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 9,068.57820
Overall Steps per Second: 7,811.83488

Timestep Collection Time: 5.51641
Timestep Consumption Time: 0.88746
PPO Batch Consumption Time: 0.04947
Total Iteration Time: 6.40387

Cumulative Model Updates: 20,410
Cumulative Timesteps: 340,508,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 340508884...
Checkpoint 340508884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.33590
Policy Entropy: 1.11545
Value Function Loss: 3.10886

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 9,168.52180
Overall Steps per Second: 7,989.77176

Timestep Collection Time: 5.45519
Timestep Consumption Time: 0.80482
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.26000

Cumulative Model Updates: 20,413
Cumulative Timesteps: 340,558,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.88705
Policy Entropy: 1.11115
Value Function Loss: 3.21052

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.05793

Collected Steps per Second: 8,807.71607
Overall Steps per Second: 7,725.86518

Timestep Collection Time: 5.67752
Timestep Consumption Time: 0.79502
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 6.47254

Cumulative Model Updates: 20,416
Cumulative Timesteps: 340,608,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 340608906...
Checkpoint 340608906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.28670
Policy Entropy: 1.13080
Value Function Loss: 3.37742

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.05135

Collected Steps per Second: 8,965.34843
Overall Steps per Second: 7,918.22704

Timestep Collection Time: 5.57926
Timestep Consumption Time: 0.73781
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 6.31707

Cumulative Model Updates: 20,419
Cumulative Timesteps: 340,658,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.79534
Policy Entropy: 1.13096
Value Function Loss: 3.59780

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 8,862.58474
Overall Steps per Second: 7,715.95436

Timestep Collection Time: 5.64170
Timestep Consumption Time: 0.83838
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 6.48008

Cumulative Model Updates: 20,422
Cumulative Timesteps: 340,708,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 340708926...
Checkpoint 340708926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.74611
Policy Entropy: 1.12681
Value Function Loss: 3.54658

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.07009

Collected Steps per Second: 8,858.87633
Overall Steps per Second: 7,678.93320

Timestep Collection Time: 5.64564
Timestep Consumption Time: 0.86751
PPO Batch Consumption Time: 0.04668
Total Iteration Time: 6.51314

Cumulative Model Updates: 20,425
Cumulative Timesteps: 340,758,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.26396
Policy Entropy: 1.13252
Value Function Loss: 3.58763

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.06730
Value Function Update Magnitude: 0.08319

Collected Steps per Second: 8,895.01278
Overall Steps per Second: 7,748.38162

Timestep Collection Time: 5.62315
Timestep Consumption Time: 0.83213
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.45528

Cumulative Model Updates: 20,428
Cumulative Timesteps: 340,808,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 340808958...
Checkpoint 340808958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.93815
Policy Entropy: 1.13518
Value Function Loss: 3.39404

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.08087

Collected Steps per Second: 8,919.64835
Overall Steps per Second: 7,783.28825

Timestep Collection Time: 5.60605
Timestep Consumption Time: 0.81848
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.42453

Cumulative Model Updates: 20,431
Cumulative Timesteps: 340,858,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.42417
Policy Entropy: 1.13239
Value Function Loss: 3.36212

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 9,040.02790
Overall Steps per Second: 7,934.07501

Timestep Collection Time: 5.53339
Timestep Consumption Time: 0.77131
PPO Batch Consumption Time: 0.03961
Total Iteration Time: 6.30470

Cumulative Model Updates: 20,434
Cumulative Timesteps: 340,908,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 340908984...
Checkpoint 340908984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.74637
Policy Entropy: 1.13200
Value Function Loss: 3.23721

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.05982

Collected Steps per Second: 9,016.34213
Overall Steps per Second: 7,845.44049

Timestep Collection Time: 5.54770
Timestep Consumption Time: 0.82797
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.37568

Cumulative Model Updates: 20,437
Cumulative Timesteps: 340,959,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.14325
Policy Entropy: 1.14932
Value Function Loss: 3.49493

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.04900

Collected Steps per Second: 9,062.60993
Overall Steps per Second: 7,701.16593

Timestep Collection Time: 5.51806
Timestep Consumption Time: 0.97551
PPO Batch Consumption Time: 0.04925
Total Iteration Time: 6.49356

Cumulative Model Updates: 20,440
Cumulative Timesteps: 341,009,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 341009012...
Checkpoint 341009012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.46897
Policy Entropy: 1.15017
Value Function Loss: 3.65468

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.04800

Collected Steps per Second: 8,577.95793
Overall Steps per Second: 7,497.26015

Timestep Collection Time: 5.83006
Timestep Consumption Time: 0.84038
PPO Batch Consumption Time: 0.04654
Total Iteration Time: 6.67044

Cumulative Model Updates: 20,443
Cumulative Timesteps: 341,059,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.94730
Policy Entropy: 1.14778
Value Function Loss: 3.67271

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.03892

Collected Steps per Second: 8,963.31788
Overall Steps per Second: 7,780.60021

Timestep Collection Time: 5.57896
Timestep Consumption Time: 0.84805
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 6.42701

Cumulative Model Updates: 20,446
Cumulative Timesteps: 341,109,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 341109028...
Checkpoint 341109028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.96118
Policy Entropy: 1.13084
Value Function Loss: 3.44701

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.03287

Collected Steps per Second: 8,861.29616
Overall Steps per Second: 7,771.00148

Timestep Collection Time: 5.64477
Timestep Consumption Time: 0.79198
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 6.43675

Cumulative Model Updates: 20,449
Cumulative Timesteps: 341,159,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.78522
Policy Entropy: 1.14355
Value Function Loss: 3.34602

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.04746

Collected Steps per Second: 8,889.33366
Overall Steps per Second: 7,695.33358

Timestep Collection Time: 5.62787
Timestep Consumption Time: 0.87321
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.50108

Cumulative Model Updates: 20,452
Cumulative Timesteps: 341,209,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 341209076...
Checkpoint 341209076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.60036
Policy Entropy: 1.14127
Value Function Loss: 3.39180

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 8,735.36114
Overall Steps per Second: 7,619.82900

Timestep Collection Time: 5.72592
Timestep Consumption Time: 0.83827
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 6.56419

Cumulative Model Updates: 20,455
Cumulative Timesteps: 341,259,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.47521
Policy Entropy: 1.13974
Value Function Loss: 3.50426

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.03944

Collected Steps per Second: 9,082.62410
Overall Steps per Second: 7,829.14723

Timestep Collection Time: 5.50744
Timestep Consumption Time: 0.88176
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.38920

Cumulative Model Updates: 20,458
Cumulative Timesteps: 341,309,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 341309116...
Checkpoint 341309116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.96869
Policy Entropy: 1.13824
Value Function Loss: 3.37833

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.04287

Collected Steps per Second: 8,742.13491
Overall Steps per Second: 7,582.58520

Timestep Collection Time: 5.72263
Timestep Consumption Time: 0.87512
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 6.59775

Cumulative Model Updates: 20,461
Cumulative Timesteps: 341,359,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.84234
Policy Entropy: 1.13813
Value Function Loss: 3.27155

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.04185

Collected Steps per Second: 8,934.61902
Overall Steps per Second: 7,847.15258

Timestep Collection Time: 5.59890
Timestep Consumption Time: 0.77590
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 6.37480

Cumulative Model Updates: 20,464
Cumulative Timesteps: 341,409,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 341409168...
Checkpoint 341409168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.64543
Policy Entropy: 1.11938
Value Function Loss: 3.25069

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.04370

Collected Steps per Second: 9,645.59591
Overall Steps per Second: 8,235.81669

Timestep Collection Time: 5.18454
Timestep Consumption Time: 0.88747
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 6.07201

Cumulative Model Updates: 20,467
Cumulative Timesteps: 341,459,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.27898
Policy Entropy: 1.12578
Value Function Loss: 3.37594

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.03462

Collected Steps per Second: 8,824.80097
Overall Steps per Second: 7,649.48375

Timestep Collection Time: 5.66744
Timestep Consumption Time: 0.87078
PPO Batch Consumption Time: 0.04874
Total Iteration Time: 6.53822

Cumulative Model Updates: 20,470
Cumulative Timesteps: 341,509,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 341509190...
Checkpoint 341509190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.15006
Policy Entropy: 1.13060
Value Function Loss: 3.36408

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.02922

Collected Steps per Second: 9,449.91568
Overall Steps per Second: 8,159.52099

Timestep Collection Time: 5.29105
Timestep Consumption Time: 0.83676
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.12781

Cumulative Model Updates: 20,473
Cumulative Timesteps: 341,559,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.82874
Policy Entropy: 1.14153
Value Function Loss: 3.56863

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.03495

Collected Steps per Second: 9,097.68435
Overall Steps per Second: 7,853.97003

Timestep Collection Time: 5.49942
Timestep Consumption Time: 0.87086
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 6.37028

Cumulative Model Updates: 20,476
Cumulative Timesteps: 341,609,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 341609222...
Checkpoint 341609222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.69031
Policy Entropy: 1.13246
Value Function Loss: 3.51544

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 9,189.25720
Overall Steps per Second: 8,061.68343

Timestep Collection Time: 5.44353
Timestep Consumption Time: 0.76138
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 6.20491

Cumulative Model Updates: 20,479
Cumulative Timesteps: 341,659,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.08873
Policy Entropy: 1.12943
Value Function Loss: 3.58511

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.05339

Collected Steps per Second: 8,645.01541
Overall Steps per Second: 7,505.94008

Timestep Collection Time: 5.78669
Timestep Consumption Time: 0.87817
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 6.66485

Cumulative Model Updates: 20,482
Cumulative Timesteps: 341,709,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 341709270...
Checkpoint 341709270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.53008
Policy Entropy: 1.14316
Value Function Loss: 3.60358

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.05019

Collected Steps per Second: 8,915.38501
Overall Steps per Second: 7,763.08243

Timestep Collection Time: 5.61075
Timestep Consumption Time: 0.83282
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.44357

Cumulative Model Updates: 20,485
Cumulative Timesteps: 341,759,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.20141
Policy Entropy: 1.14007
Value Function Loss: 3.44683

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 8,960.79611
Overall Steps per Second: 7,761.46776

Timestep Collection Time: 5.58232
Timestep Consumption Time: 0.86260
PPO Batch Consumption Time: 0.04750
Total Iteration Time: 6.44492

Cumulative Model Updates: 20,488
Cumulative Timesteps: 341,809,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 341809314...
Checkpoint 341809314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.05213
Policy Entropy: 1.12786
Value Function Loss: 3.37837

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.03203

Collected Steps per Second: 9,042.81889
Overall Steps per Second: 7,812.63715

Timestep Collection Time: 5.53146
Timestep Consumption Time: 0.87099
PPO Batch Consumption Time: 0.04571
Total Iteration Time: 6.40245

Cumulative Model Updates: 20,491
Cumulative Timesteps: 341,859,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.02424
Policy Entropy: 1.12349
Value Function Loss: 3.40106

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.07321
Value Function Update Magnitude: 0.03965

Collected Steps per Second: 8,960.22146
Overall Steps per Second: 7,900.86142

Timestep Collection Time: 5.58223
Timestep Consumption Time: 0.74847
PPO Batch Consumption Time: 0.04942
Total Iteration Time: 6.33070

Cumulative Model Updates: 20,494
Cumulative Timesteps: 341,909,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 341909352...
Checkpoint 341909352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.72807
Policy Entropy: 1.13431
Value Function Loss: 3.32776

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.04134

Collected Steps per Second: 8,674.17863
Overall Steps per Second: 7,592.61734

Timestep Collection Time: 5.76447
Timestep Consumption Time: 0.82114
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 6.58561

Cumulative Model Updates: 20,497
Cumulative Timesteps: 341,959,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.84859
Policy Entropy: 1.14018
Value Function Loss: 3.33047

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.04708

Collected Steps per Second: 8,791.71339
Overall Steps per Second: 7,646.15784

Timestep Collection Time: 5.69013
Timestep Consumption Time: 0.85250
PPO Batch Consumption Time: 0.04449
Total Iteration Time: 6.54263

Cumulative Model Updates: 20,500
Cumulative Timesteps: 342,009,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 342009380...
Checkpoint 342009380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.27301
Policy Entropy: 1.13537
Value Function Loss: 3.22401

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11054
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 8,895.62530
Overall Steps per Second: 7,649.74369

Timestep Collection Time: 5.62119
Timestep Consumption Time: 0.91550
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 6.53669

Cumulative Model Updates: 20,503
Cumulative Timesteps: 342,059,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.97104
Policy Entropy: 1.12805
Value Function Loss: 3.29330

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16397
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 8,881.12229
Overall Steps per Second: 7,738.11064

Timestep Collection Time: 5.62992
Timestep Consumption Time: 0.83161
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.46153

Cumulative Model Updates: 20,506
Cumulative Timesteps: 342,109,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 342109384...
Checkpoint 342109384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.54965
Policy Entropy: 1.14755
Value Function Loss: 3.22209

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 8,846.24149
Overall Steps per Second: 7,816.28597

Timestep Collection Time: 5.65528
Timestep Consumption Time: 0.74520
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 6.40048

Cumulative Model Updates: 20,509
Cumulative Timesteps: 342,159,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.86524
Policy Entropy: 1.12550
Value Function Loss: 3.28733

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.17840
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.04530

Collected Steps per Second: 8,484.90749
Overall Steps per Second: 7,396.38045

Timestep Collection Time: 5.89352
Timestep Consumption Time: 0.86735
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.76087

Cumulative Model Updates: 20,512
Cumulative Timesteps: 342,209,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 342209418...
Checkpoint 342209418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.50914
Policy Entropy: 1.12570
Value Function Loss: 3.31285

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.18726
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.04071

Collected Steps per Second: 8,853.15963
Overall Steps per Second: 7,704.43775

Timestep Collection Time: 5.64860
Timestep Consumption Time: 0.84220
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.49080

Cumulative Model Updates: 20,515
Cumulative Timesteps: 342,259,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.86582
Policy Entropy: 1.12955
Value Function Loss: 3.42380

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.04691

Collected Steps per Second: 9,036.22941
Overall Steps per Second: 7,831.36323

Timestep Collection Time: 5.53549
Timestep Consumption Time: 0.85164
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.38714

Cumulative Model Updates: 20,518
Cumulative Timesteps: 342,309,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 342309446...
Checkpoint 342309446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.97508
Policy Entropy: 1.13974
Value Function Loss: 3.44760

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.04021
Value Function Update Magnitude: 0.04127

Collected Steps per Second: 8,909.45930
Overall Steps per Second: 7,774.21300

Timestep Collection Time: 5.61246
Timestep Consumption Time: 0.81957
PPO Batch Consumption Time: 0.04648
Total Iteration Time: 6.43203

Cumulative Model Updates: 20,521
Cumulative Timesteps: 342,359,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.26173
Policy Entropy: 1.13024
Value Function Loss: 3.42741

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.03589

Collected Steps per Second: 8,548.15353
Overall Steps per Second: 7,560.85506

Timestep Collection Time: 5.85085
Timestep Consumption Time: 0.76401
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.61486

Cumulative Model Updates: 20,524
Cumulative Timesteps: 342,409,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 342409464...
Checkpoint 342409464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 777.57460
Policy Entropy: 1.12091
Value Function Loss: 3.51925

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.03199

Collected Steps per Second: 8,892.00612
Overall Steps per Second: 7,737.89000

Timestep Collection Time: 5.62550
Timestep Consumption Time: 0.83905
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.46455

Cumulative Model Updates: 20,527
Cumulative Timesteps: 342,459,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.57949
Policy Entropy: 1.13189
Value Function Loss: 3.43489

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.04356
Value Function Update Magnitude: 0.03356

Collected Steps per Second: 8,937.03349
Overall Steps per Second: 7,733.99199

Timestep Collection Time: 5.59694
Timestep Consumption Time: 0.87062
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.46755

Cumulative Model Updates: 20,530
Cumulative Timesteps: 342,509,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 342509506...
Checkpoint 342509506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.25195
Policy Entropy: 1.12875
Value Function Loss: 3.49269

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 8,842.97957
Overall Steps per Second: 7,666.66025

Timestep Collection Time: 5.65714
Timestep Consumption Time: 0.86799
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 6.52514

Cumulative Model Updates: 20,533
Cumulative Timesteps: 342,559,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.43414
Policy Entropy: 1.12242
Value Function Loss: 3.43988

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.05456

Collected Steps per Second: 8,906.26501
Overall Steps per Second: 7,707.66064

Timestep Collection Time: 5.61650
Timestep Consumption Time: 0.87341
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 6.48991

Cumulative Model Updates: 20,536
Cumulative Timesteps: 342,609,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 342609554...
Checkpoint 342609554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.96579
Policy Entropy: 1.12666
Value Function Loss: 3.54040

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.04773

Collected Steps per Second: 8,657.27424
Overall Steps per Second: 7,609.04771

Timestep Collection Time: 5.77896
Timestep Consumption Time: 0.79611
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.57507

Cumulative Model Updates: 20,539
Cumulative Timesteps: 342,659,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.80215
Policy Entropy: 1.13131
Value Function Loss: 3.73005

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.05231

Collected Steps per Second: 8,936.81966
Overall Steps per Second: 7,707.36967

Timestep Collection Time: 5.59752
Timestep Consumption Time: 0.89289
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 6.49041

Cumulative Model Updates: 20,542
Cumulative Timesteps: 342,709,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 342709608...
Checkpoint 342709608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.57806
Policy Entropy: 1.12130
Value Function Loss: 3.65161

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.03829

Collected Steps per Second: 8,914.40293
Overall Steps per Second: 7,855.27978

Timestep Collection Time: 5.61047
Timestep Consumption Time: 0.75646
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.36693

Cumulative Model Updates: 20,545
Cumulative Timesteps: 342,759,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.11920
Policy Entropy: 1.10452
Value Function Loss: 3.59546

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.03811

Collected Steps per Second: 8,918.23583
Overall Steps per Second: 7,718.90979

Timestep Collection Time: 5.60649
Timestep Consumption Time: 0.87111
PPO Batch Consumption Time: 0.04223
Total Iteration Time: 6.47760

Cumulative Model Updates: 20,548
Cumulative Timesteps: 342,809,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 342809622...
Checkpoint 342809622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.29498
Policy Entropy: 1.11019
Value Function Loss: 3.49943

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.04360

Collected Steps per Second: 8,544.64626
Overall Steps per Second: 7,475.68702

Timestep Collection Time: 5.85372
Timestep Consumption Time: 0.83703
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.69076

Cumulative Model Updates: 20,551
Cumulative Timesteps: 342,859,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.86675
Policy Entropy: 1.11235
Value Function Loss: 3.57383

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.16466
Policy Update Magnitude: 0.04335
Value Function Update Magnitude: 0.04191

Collected Steps per Second: 9,067.76999
Overall Steps per Second: 7,795.63792

Timestep Collection Time: 5.51448
Timestep Consumption Time: 0.89988
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.41436

Cumulative Model Updates: 20,554
Cumulative Timesteps: 342,909,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342909644...
Checkpoint 342909644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.90831
Policy Entropy: 1.10013
Value Function Loss: 3.59496

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.04130
Value Function Update Magnitude: 0.03461

Collected Steps per Second: 9,004.85302
Overall Steps per Second: 7,833.84530

Timestep Collection Time: 5.55456
Timestep Consumption Time: 0.83030
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 6.38486

Cumulative Model Updates: 20,557
Cumulative Timesteps: 342,959,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.75681
Policy Entropy: 1.09144
Value Function Loss: 3.49175

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.19382
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.03180

Collected Steps per Second: 8,824.38917
Overall Steps per Second: 7,773.04366

Timestep Collection Time: 5.66883
Timestep Consumption Time: 0.76674
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 6.43557

Cumulative Model Updates: 20,560
Cumulative Timesteps: 343,009,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 343009686...
Checkpoint 343009686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.65573
Policy Entropy: 1.10763
Value Function Loss: 3.34783

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.02688

Collected Steps per Second: 8,661.04638
Overall Steps per Second: 7,544.10140

Timestep Collection Time: 5.77644
Timestep Consumption Time: 0.85523
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.63167

Cumulative Model Updates: 20,563
Cumulative Timesteps: 343,059,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.28036
Policy Entropy: 1.11211
Value Function Loss: 3.39961

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.03101

Collected Steps per Second: 8,558.30337
Overall Steps per Second: 7,535.47723

Timestep Collection Time: 5.84392
Timestep Consumption Time: 0.79322
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.63714

Cumulative Model Updates: 20,566
Cumulative Timesteps: 343,109,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 343109730...
Checkpoint 343109730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.10313
Policy Entropy: 1.09125
Value Function Loss: 3.34033

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.03241

Collected Steps per Second: 8,770.46959
Overall Steps per Second: 7,586.30039

Timestep Collection Time: 5.70323
Timestep Consumption Time: 0.89023
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.59346

Cumulative Model Updates: 20,569
Cumulative Timesteps: 343,159,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.56810
Policy Entropy: 1.09160
Value Function Loss: 3.47034

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.02433

Collected Steps per Second: 8,742.11174
Overall Steps per Second: 7,611.75797

Timestep Collection Time: 5.72127
Timestep Consumption Time: 0.84961
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.57089

Cumulative Model Updates: 20,572
Cumulative Timesteps: 343,209,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 343209766...
Checkpoint 343209766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.29846
Policy Entropy: 1.09173
Value Function Loss: 3.51389

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.02695

Collected Steps per Second: 8,861.02765
Overall Steps per Second: 7,744.52454

Timestep Collection Time: 5.64336
Timestep Consumption Time: 0.81359
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 6.45695

Cumulative Model Updates: 20,575
Cumulative Timesteps: 343,259,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.27669
Policy Entropy: 1.09968
Value Function Loss: 3.69395

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.02533

Collected Steps per Second: 9,374.08671
Overall Steps per Second: 7,971.99340

Timestep Collection Time: 5.33407
Timestep Consumption Time: 0.93814
PPO Batch Consumption Time: 0.05129
Total Iteration Time: 6.27221

Cumulative Model Updates: 20,578
Cumulative Timesteps: 343,309,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 343309774...
Checkpoint 343309774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 794.51491
Policy Entropy: 1.10117
Value Function Loss: 3.73955

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.02651

Collected Steps per Second: 8,981.84707
Overall Steps per Second: 7,879.14288

Timestep Collection Time: 5.56923
Timestep Consumption Time: 0.77943
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.34866

Cumulative Model Updates: 20,581
Cumulative Timesteps: 343,359,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.20674
Policy Entropy: 1.09269
Value Function Loss: 3.82589

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.02445

Collected Steps per Second: 9,518.90644
Overall Steps per Second: 8,104.98000

Timestep Collection Time: 5.25481
Timestep Consumption Time: 0.91671
PPO Batch Consumption Time: 0.04915
Total Iteration Time: 6.17151

Cumulative Model Updates: 20,584
Cumulative Timesteps: 343,409,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 343409816...
Checkpoint 343409816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.86227
Policy Entropy: 1.08891
Value Function Loss: 3.64720

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.18541
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.02454

Collected Steps per Second: 9,093.74753
Overall Steps per Second: 7,920.25811

Timestep Collection Time: 5.49982
Timestep Consumption Time: 0.81487
PPO Batch Consumption Time: 0.04987
Total Iteration Time: 6.31469

Cumulative Model Updates: 20,587
Cumulative Timesteps: 343,459,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.75215
Policy Entropy: 1.10094
Value Function Loss: 3.69963

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.02715

Collected Steps per Second: 9,193.95641
Overall Steps per Second: 7,958.32027

Timestep Collection Time: 5.44010
Timestep Consumption Time: 0.84465
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 6.28474

Cumulative Model Updates: 20,590
Cumulative Timesteps: 343,509,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 343509846...
Checkpoint 343509846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.30277
Policy Entropy: 1.10366
Value Function Loss: 3.58059

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.16715
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.02752

Collected Steps per Second: 8,752.56446
Overall Steps per Second: 7,644.69453

Timestep Collection Time: 5.71490
Timestep Consumption Time: 0.82820
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.54310

Cumulative Model Updates: 20,593
Cumulative Timesteps: 343,559,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.18082
Policy Entropy: 1.08707
Value Function Loss: 3.67169

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.02467

Collected Steps per Second: 8,914.62896
Overall Steps per Second: 7,862.65935

Timestep Collection Time: 5.61145
Timestep Consumption Time: 0.75077
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.36222

Cumulative Model Updates: 20,596
Cumulative Timesteps: 343,609,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 343609890...
Checkpoint 343609890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 777.33497
Policy Entropy: 1.07936
Value Function Loss: 3.57738

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.04106
Value Function Update Magnitude: 0.02660

Collected Steps per Second: 8,812.00156
Overall Steps per Second: 7,676.06420

Timestep Collection Time: 5.67590
Timestep Consumption Time: 0.83994
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.51584

Cumulative Model Updates: 20,599
Cumulative Timesteps: 343,659,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.85825
Policy Entropy: 1.09188
Value Function Loss: 3.63192

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.02932

Collected Steps per Second: 8,854.96004
Overall Steps per Second: 7,737.03113

Timestep Collection Time: 5.64994
Timestep Consumption Time: 0.81636
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.46630

Cumulative Model Updates: 20,602
Cumulative Timesteps: 343,709,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 343709936...
Checkpoint 343709936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.09946
Policy Entropy: 1.10226
Value Function Loss: 3.41705

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.02546

Collected Steps per Second: 8,749.18990
Overall Steps per Second: 7,634.56582

Timestep Collection Time: 5.71824
Timestep Consumption Time: 0.83485
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.55309

Cumulative Model Updates: 20,605
Cumulative Timesteps: 343,759,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.36139
Policy Entropy: 1.08701
Value Function Loss: 3.43714

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.03218

Collected Steps per Second: 8,763.91056
Overall Steps per Second: 7,598.85668

Timestep Collection Time: 5.70818
Timestep Consumption Time: 0.87518
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.58336

Cumulative Model Updates: 20,608
Cumulative Timesteps: 343,809,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 343809992...
Checkpoint 343809992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.40297
Policy Entropy: 1.07866
Value Function Loss: 3.44117

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.18789
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.03096

Collected Steps per Second: 9,003.62623
Overall Steps per Second: 7,940.10922

Timestep Collection Time: 5.55643
Timestep Consumption Time: 0.74424
PPO Batch Consumption Time: 0.03928
Total Iteration Time: 6.30067

Cumulative Model Updates: 20,611
Cumulative Timesteps: 343,860,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.62455
Policy Entropy: 1.09201
Value Function Loss: 3.43143

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.02702

Collected Steps per Second: 8,688.77836
Overall Steps per Second: 7,571.94693

Timestep Collection Time: 5.75593
Timestep Consumption Time: 0.84898
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.60491

Cumulative Model Updates: 20,614
Cumulative Timesteps: 343,910,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 343910032...
Checkpoint 343910032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.40781
Policy Entropy: 1.10084
Value Function Loss: 3.32587

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.02784

Collected Steps per Second: 8,857.86193
Overall Steps per Second: 7,800.53730

Timestep Collection Time: 5.64696
Timestep Consumption Time: 0.76542
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.41238

Cumulative Model Updates: 20,617
Cumulative Timesteps: 343,960,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.93874
Policy Entropy: 1.09769
Value Function Loss: 3.30586

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.02675

Collected Steps per Second: 8,728.77545
Overall Steps per Second: 7,470.37806

Timestep Collection Time: 5.73116
Timestep Consumption Time: 0.96542
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 6.69658

Cumulative Model Updates: 20,620
Cumulative Timesteps: 344,010,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 344010078...
Checkpoint 344010078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.88461
Policy Entropy: 1.07842
Value Function Loss: 3.35605

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.02443

Collected Steps per Second: 8,810.08483
Overall Steps per Second: 7,678.20169

Timestep Collection Time: 5.67804
Timestep Consumption Time: 0.83703
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.51507

Cumulative Model Updates: 20,623
Cumulative Timesteps: 344,060,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.15327
Policy Entropy: 1.08655
Value Function Loss: 3.51876

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15485
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.02453

Collected Steps per Second: 8,956.18529
Overall Steps per Second: 7,788.44877

Timestep Collection Time: 5.58541
Timestep Consumption Time: 0.83743
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 6.42285

Cumulative Model Updates: 20,626
Cumulative Timesteps: 344,110,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 344110126...
Checkpoint 344110126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.65512
Policy Entropy: 1.08417
Value Function Loss: 3.46265

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.02342

Collected Steps per Second: 8,796.33086
Overall Steps per Second: 7,667.41752

Timestep Collection Time: 5.68692
Timestep Consumption Time: 0.83731
PPO Batch Consumption Time: 0.04503
Total Iteration Time: 6.52423

Cumulative Model Updates: 20,629
Cumulative Timesteps: 344,160,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.09356
Policy Entropy: 1.07792
Value Function Loss: 3.59497

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.04210
Value Function Update Magnitude: 0.02635

Collected Steps per Second: 9,023.84961
Overall Steps per Second: 7,976.57072

Timestep Collection Time: 5.54353
Timestep Consumption Time: 0.72783
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.27137

Cumulative Model Updates: 20,632
Cumulative Timesteps: 344,210,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 344210174...
Checkpoint 344210174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.45321
Policy Entropy: 1.06184
Value Function Loss: 3.54310

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.18135
Policy Update Magnitude: 0.03695
Value Function Update Magnitude: 0.02598

Collected Steps per Second: 8,644.35502
Overall Steps per Second: 7,571.13100

Timestep Collection Time: 5.78435
Timestep Consumption Time: 0.81994
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.60430

Cumulative Model Updates: 20,635
Cumulative Timesteps: 344,260,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.99392
Policy Entropy: 1.07100
Value Function Loss: 3.66378

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.03941
Value Function Update Magnitude: 0.02659

Collected Steps per Second: 8,668.82325
Overall Steps per Second: 7,551.60031

Timestep Collection Time: 5.76918
Timestep Consumption Time: 0.85352
PPO Batch Consumption Time: 0.05234
Total Iteration Time: 6.62270

Cumulative Model Updates: 20,638
Cumulative Timesteps: 344,310,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 344310188...
Checkpoint 344310188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.61396
Policy Entropy: 1.07399
Value Function Loss: 3.48110

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.03649
Value Function Update Magnitude: 0.02541

Collected Steps per Second: 9,078.22640
Overall Steps per Second: 7,969.39487

Timestep Collection Time: 5.50923
Timestep Consumption Time: 0.76653
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.27576

Cumulative Model Updates: 20,641
Cumulative Timesteps: 344,360,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.61351
Policy Entropy: 1.06185
Value Function Loss: 3.45519

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.02736

Collected Steps per Second: 8,971.82173
Overall Steps per Second: 7,825.72675

Timestep Collection Time: 5.57546
Timestep Consumption Time: 0.81654
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.39199

Cumulative Model Updates: 20,644
Cumulative Timesteps: 344,410,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 344410224...
Checkpoint 344410224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.95085
Policy Entropy: 1.03981
Value Function Loss: 3.22235

Mean KL Divergence: 0.03057
SB3 Clip Fraction: 0.23516
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.02632

Collected Steps per Second: 8,842.85855
Overall Steps per Second: 7,662.71303

Timestep Collection Time: 5.65586
Timestep Consumption Time: 0.87107
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 6.52693

Cumulative Model Updates: 20,647
Cumulative Timesteps: 344,460,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.75542
Policy Entropy: 1.05695
Value Function Loss: 3.28843

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.03519

Collected Steps per Second: 8,614.14185
Overall Steps per Second: 7,505.57580

Timestep Collection Time: 5.80650
Timestep Consumption Time: 0.85761
PPO Batch Consumption Time: 0.04895
Total Iteration Time: 6.66411

Cumulative Model Updates: 20,650
Cumulative Timesteps: 344,510,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 344510256...
Checkpoint 344510256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.82406
Policy Entropy: 1.04724
Value Function Loss: 3.17590

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.16892
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.03963

Collected Steps per Second: 8,893.26153
Overall Steps per Second: 7,715.77623

Timestep Collection Time: 5.62223
Timestep Consumption Time: 0.85800
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.48023

Cumulative Model Updates: 20,653
Cumulative Timesteps: 344,560,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.43968
Policy Entropy: 1.04328
Value Function Loss: 3.26841

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.21263
Policy Update Magnitude: 0.03753
Value Function Update Magnitude: 0.03769

Collected Steps per Second: 8,787.23847
Overall Steps per Second: 7,757.08807

Timestep Collection Time: 5.69235
Timestep Consumption Time: 0.75595
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 6.44830

Cumulative Model Updates: 20,656
Cumulative Timesteps: 344,610,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 344610276...
Checkpoint 344610276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.72590
Policy Entropy: 1.06008
Value Function Loss: 3.25266

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.03679
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 8,812.14486
Overall Steps per Second: 7,689.43629

Timestep Collection Time: 5.67694
Timestep Consumption Time: 0.82887
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.50581

Cumulative Model Updates: 20,659
Cumulative Timesteps: 344,660,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.60439
Policy Entropy: 1.05549
Value Function Loss: 3.46442

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.18087
Policy Update Magnitude: 0.03218
Value Function Update Magnitude: 0.04208

Collected Steps per Second: 8,608.06999
Overall Steps per Second: 7,468.47061

Timestep Collection Time: 5.80874
Timestep Consumption Time: 0.88634
PPO Batch Consumption Time: 0.05208
Total Iteration Time: 6.69508

Cumulative Model Updates: 20,662
Cumulative Timesteps: 344,710,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 344710304...
Checkpoint 344710304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.40255
Policy Entropy: 1.04517
Value Function Loss: 3.33780

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.03562

Collected Steps per Second: 9,051.21309
Overall Steps per Second: 7,869.76016

Timestep Collection Time: 5.52545
Timestep Consumption Time: 0.82951
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.35496

Cumulative Model Updates: 20,665
Cumulative Timesteps: 344,760,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.80886
Policy Entropy: 1.03030
Value Function Loss: 3.22829

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.21017
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.04886

Collected Steps per Second: 8,824.92931
Overall Steps per Second: 7,642.97448

Timestep Collection Time: 5.66826
Timestep Consumption Time: 0.87657
PPO Batch Consumption Time: 0.05085
Total Iteration Time: 6.54483

Cumulative Model Updates: 20,668
Cumulative Timesteps: 344,810,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 344810338...
Checkpoint 344810338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.32817
Policy Entropy: 1.04463
Value Function Loss: 3.21129

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 8,852.03248
Overall Steps per Second: 7,756.77462

Timestep Collection Time: 5.65023
Timestep Consumption Time: 0.79781
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.44804

Cumulative Model Updates: 20,671
Cumulative Timesteps: 344,860,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.32066
Policy Entropy: 1.07025
Value Function Loss: 3.30868

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.17120
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.04144

Collected Steps per Second: 8,789.00133
Overall Steps per Second: 7,627.57732

Timestep Collection Time: 5.69098
Timestep Consumption Time: 0.86654
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.55752

Cumulative Model Updates: 20,674
Cumulative Timesteps: 344,910,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 344910372...
Checkpoint 344910372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.33208
Policy Entropy: 1.04961
Value Function Loss: 3.31132

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.03987

Collected Steps per Second: 8,731.56689
Overall Steps per Second: 7,547.71494

Timestep Collection Time: 5.72772
Timestep Consumption Time: 0.89839
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.62611

Cumulative Model Updates: 20,677
Cumulative Timesteps: 344,960,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.43228
Policy Entropy: 1.03935
Value Function Loss: 3.27984

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.04202

Collected Steps per Second: 8,939.99989
Overall Steps per Second: 7,704.93593

Timestep Collection Time: 5.59396
Timestep Consumption Time: 0.89668
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.49064

Cumulative Model Updates: 20,680
Cumulative Timesteps: 345,010,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 345010394...
Checkpoint 345010394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.98721
Policy Entropy: 1.06006
Value Function Loss: 3.35156

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 8,731.82770
Overall Steps per Second: 7,624.63018

Timestep Collection Time: 5.72893
Timestep Consumption Time: 0.83192
PPO Batch Consumption Time: 0.04832
Total Iteration Time: 6.56084

Cumulative Model Updates: 20,683
Cumulative Timesteps: 345,060,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.77021
Policy Entropy: 1.06281
Value Function Loss: 3.54246

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 8,866.90843
Overall Steps per Second: 7,830.14980

Timestep Collection Time: 5.64210
Timestep Consumption Time: 0.74705
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.38915

Cumulative Model Updates: 20,686
Cumulative Timesteps: 345,110,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 345110446...
Checkpoint 345110446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.74728
Policy Entropy: 1.04698
Value Function Loss: 3.53673

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.05592

Collected Steps per Second: 9,258.02229
Overall Steps per Second: 7,844.93561

Timestep Collection Time: 5.40223
Timestep Consumption Time: 0.97309
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 6.37532

Cumulative Model Updates: 20,689
Cumulative Timesteps: 345,160,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.33365
Policy Entropy: 1.03982
Value Function Loss: 3.40666

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.16989
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.04420

Collected Steps per Second: 9,067.38153
Overall Steps per Second: 7,870.07709

Timestep Collection Time: 5.51736
Timestep Consumption Time: 0.83938
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.35674

Cumulative Model Updates: 20,692
Cumulative Timesteps: 345,210,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 345210488...
Checkpoint 345210488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.50935
Policy Entropy: 1.05252
Value Function Loss: 3.17364

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.04057

Collected Steps per Second: 9,433.02455
Overall Steps per Second: 8,050.50833

Timestep Collection Time: 5.30095
Timestep Consumption Time: 0.91033
PPO Batch Consumption Time: 0.05012
Total Iteration Time: 6.21128

Cumulative Model Updates: 20,695
Cumulative Timesteps: 345,260,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.83212
Policy Entropy: 1.06934
Value Function Loss: 3.12467

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.18111
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.03838

Collected Steps per Second: 9,048.08263
Overall Steps per Second: 7,850.61428

Timestep Collection Time: 5.52846
Timestep Consumption Time: 0.84327
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.37173

Cumulative Model Updates: 20,698
Cumulative Timesteps: 345,310,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 345310514...
Checkpoint 345310514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.36143
Policy Entropy: 1.04155
Value Function Loss: 3.09411

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.03650

Collected Steps per Second: 8,912.51112
Overall Steps per Second: 7,832.49069

Timestep Collection Time: 5.61144
Timestep Consumption Time: 0.77376
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 6.38520

Cumulative Model Updates: 20,701
Cumulative Timesteps: 345,360,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.76245
Policy Entropy: 1.05433
Value Function Loss: 3.32383

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.19547
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.04017

Collected Steps per Second: 8,530.35644
Overall Steps per Second: 7,376.12617

Timestep Collection Time: 5.86189
Timestep Consumption Time: 0.91728
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.77917

Cumulative Model Updates: 20,704
Cumulative Timesteps: 345,410,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 345410530...
Checkpoint 345410530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.10010
Policy Entropy: 1.06143
Value Function Loss: 3.34614

Mean KL Divergence: 0.02932
SB3 Clip Fraction: 0.23413
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.03844

Collected Steps per Second: 8,641.20244
Overall Steps per Second: 7,648.29010

Timestep Collection Time: 5.78831
Timestep Consumption Time: 0.75145
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.53976

Cumulative Model Updates: 20,707
Cumulative Timesteps: 345,460,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.35227
Policy Entropy: 1.03762
Value Function Loss: 3.41229

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.04614

Collected Steps per Second: 8,720.20677
Overall Steps per Second: 7,592.30195

Timestep Collection Time: 5.73427
Timestep Consumption Time: 0.85188
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 6.58614

Cumulative Model Updates: 20,710
Cumulative Timesteps: 345,510,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 345510552...
Checkpoint 345510552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.62669
Policy Entropy: 1.03365
Value Function Loss: 3.42552

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.17139
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.04656

Collected Steps per Second: 8,704.56268
Overall Steps per Second: 7,607.24627

Timestep Collection Time: 5.74710
Timestep Consumption Time: 0.82900
PPO Batch Consumption Time: 0.04723
Total Iteration Time: 6.57610

Cumulative Model Updates: 20,713
Cumulative Timesteps: 345,560,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.66251
Policy Entropy: 1.05079
Value Function Loss: 3.43304

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.03879

Collected Steps per Second: 8,809.12895
Overall Steps per Second: 7,604.16592

Timestep Collection Time: 5.67911
Timestep Consumption Time: 0.89992
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 6.57903

Cumulative Model Updates: 20,716
Cumulative Timesteps: 345,610,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 345610606...
Checkpoint 345610606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.36023
Policy Entropy: 1.05830
Value Function Loss: 3.27579

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.03245

Collected Steps per Second: 8,656.89910
Overall Steps per Second: 7,511.73630

Timestep Collection Time: 5.77666
Timestep Consumption Time: 0.88065
PPO Batch Consumption Time: 0.05205
Total Iteration Time: 6.65732

Cumulative Model Updates: 20,719
Cumulative Timesteps: 345,660,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.72908
Policy Entropy: 1.03363
Value Function Loss: 3.23069

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.15978
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.03178

Collected Steps per Second: 8,956.61026
Overall Steps per Second: 7,884.89168

Timestep Collection Time: 5.58247
Timestep Consumption Time: 0.75877
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.34124

Cumulative Model Updates: 20,722
Cumulative Timesteps: 345,710,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 345710614...
Checkpoint 345710614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.07823
Policy Entropy: 1.02040
Value Function Loss: 3.27234

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.19226
Policy Update Magnitude: 0.03467
Value Function Update Magnitude: 0.03847

Collected Steps per Second: 8,752.13478
Overall Steps per Second: 7,628.52790

Timestep Collection Time: 5.71563
Timestep Consumption Time: 0.84186
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.55749

Cumulative Model Updates: 20,725
Cumulative Timesteps: 345,760,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.00177
Policy Entropy: 1.03437
Value Function Loss: 3.28176

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.03769

Collected Steps per Second: 8,769.22266
Overall Steps per Second: 7,576.79200

Timestep Collection Time: 5.70450
Timestep Consumption Time: 0.89777
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.60227

Cumulative Model Updates: 20,728
Cumulative Timesteps: 345,810,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 345810662...
Checkpoint 345810662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.90420
Policy Entropy: 1.04316
Value Function Loss: 3.19851

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.18510
Policy Update Magnitude: 0.03419
Value Function Update Magnitude: 0.03233

Collected Steps per Second: 8,589.07462
Overall Steps per Second: 7,536.81788

Timestep Collection Time: 5.82484
Timestep Consumption Time: 0.81324
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.63808

Cumulative Model Updates: 20,731
Cumulative Timesteps: 345,860,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.88710
Policy Entropy: 1.03236
Value Function Loss: 3.22736

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.03240

Collected Steps per Second: 8,844.55753
Overall Steps per Second: 7,673.52424

Timestep Collection Time: 5.65523
Timestep Consumption Time: 0.86303
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.51826

Cumulative Model Updates: 20,734
Cumulative Timesteps: 345,910,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 345910710...
Checkpoint 345910710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.76482
Policy Entropy: 1.01218
Value Function Loss: 3.16387

Mean KL Divergence: 0.02931
SB3 Clip Fraction: 0.22659
Policy Update Magnitude: 0.04031
Value Function Update Magnitude: 0.03262

Collected Steps per Second: 8,818.30125
Overall Steps per Second: 7,644.34986

Timestep Collection Time: 5.67003
Timestep Consumption Time: 0.87075
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 6.54078

Cumulative Model Updates: 20,737
Cumulative Timesteps: 345,960,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.80936
Policy Entropy: 1.04375
Value Function Loss: 3.17017

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.03570

Collected Steps per Second: 8,855.52705
Overall Steps per Second: 7,715.58675

Timestep Collection Time: 5.64845
Timestep Consumption Time: 0.83453
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.48298

Cumulative Model Updates: 20,740
Cumulative Timesteps: 346,010,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 346010730...
Checkpoint 346010730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.47043
Policy Entropy: 1.04594
Value Function Loss: 3.33565

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.03612

Collected Steps per Second: 8,907.51822
Overall Steps per Second: 7,597.74700

Timestep Collection Time: 5.61413
Timestep Consumption Time: 0.96782
PPO Batch Consumption Time: 0.04697
Total Iteration Time: 6.58195

Cumulative Model Updates: 20,743
Cumulative Timesteps: 346,060,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.88341
Policy Entropy: 1.02936
Value Function Loss: 3.34766

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.03278

Collected Steps per Second: 8,512.96738
Overall Steps per Second: 7,535.75177

Timestep Collection Time: 5.87574
Timestep Consumption Time: 0.76195
PPO Batch Consumption Time: 0.04831
Total Iteration Time: 6.63769

Cumulative Model Updates: 20,746
Cumulative Timesteps: 346,110,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 346110758...
Checkpoint 346110758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.95292
Policy Entropy: 1.02593
Value Function Loss: 3.44978

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.03901

Collected Steps per Second: 8,819.03009
Overall Steps per Second: 7,698.07134

Timestep Collection Time: 5.67092
Timestep Consumption Time: 0.82577
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.49669

Cumulative Model Updates: 20,749
Cumulative Timesteps: 346,160,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.39525
Policy Entropy: 1.02934
Value Function Loss: 3.45092

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.19210
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.04395

Collected Steps per Second: 9,001.09972
Overall Steps per Second: 7,840.56100

Timestep Collection Time: 5.55488
Timestep Consumption Time: 0.82222
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.37709

Cumulative Model Updates: 20,752
Cumulative Timesteps: 346,210,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 346210770...
Checkpoint 346210770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.18584
Policy Entropy: 1.04770
Value Function Loss: 3.44022

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.19041
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 8,930.93221
Overall Steps per Second: 7,734.18020

Timestep Collection Time: 5.60121
Timestep Consumption Time: 0.86671
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.46791

Cumulative Model Updates: 20,755
Cumulative Timesteps: 346,260,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.80578
Policy Entropy: 1.03971
Value Function Loss: 3.25333

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16429
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.02882

Collected Steps per Second: 8,936.38726
Overall Steps per Second: 7,636.48079

Timestep Collection Time: 5.59510
Timestep Consumption Time: 0.95242
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.54752

Cumulative Model Updates: 20,758
Cumulative Timesteps: 346,310,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 346310794...
Checkpoint 346310794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.22878
Policy Entropy: 1.03350
Value Function Loss: 3.39347

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.21151
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.03329

Collected Steps per Second: 8,641.92401
Overall Steps per Second: 7,612.39716

Timestep Collection Time: 5.78783
Timestep Consumption Time: 0.78277
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.57060

Cumulative Model Updates: 20,761
Cumulative Timesteps: 346,360,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.20692
Policy Entropy: 1.05113
Value Function Loss: 3.37169

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.17445
Policy Update Magnitude: 0.04254
Value Function Update Magnitude: 0.03498

Collected Steps per Second: 8,968.68127
Overall Steps per Second: 7,787.23082

Timestep Collection Time: 5.57652
Timestep Consumption Time: 0.84605
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.42257

Cumulative Model Updates: 20,764
Cumulative Timesteps: 346,410,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 346410826...
Checkpoint 346410826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.94207
Policy Entropy: 1.04205
Value Function Loss: 3.35313

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.04016
Value Function Update Magnitude: 0.03840

Collected Steps per Second: 8,841.23653
Overall Steps per Second: 7,702.49718

Timestep Collection Time: 5.65826
Timestep Consumption Time: 0.83652
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.49478

Cumulative Model Updates: 20,767
Cumulative Timesteps: 346,460,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.73140
Policy Entropy: 1.01849
Value Function Loss: 3.37834

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.21158
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.03675

Collected Steps per Second: 8,960.79759
Overall Steps per Second: 7,766.74050

Timestep Collection Time: 5.58142
Timestep Consumption Time: 0.85809
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.43951

Cumulative Model Updates: 20,770
Cumulative Timesteps: 346,510,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 346510866...
Checkpoint 346510866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.35760
Policy Entropy: 1.04212
Value Function Loss: 3.31485

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.04875

Collected Steps per Second: 8,705.78960
Overall Steps per Second: 7,602.67927

Timestep Collection Time: 5.74376
Timestep Consumption Time: 0.83339
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.57715

Cumulative Model Updates: 20,773
Cumulative Timesteps: 346,560,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.70061
Policy Entropy: 1.05166
Value Function Loss: 3.39064

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.18045
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.04649

Collected Steps per Second: 8,911.81809
Overall Steps per Second: 7,733.49843

Timestep Collection Time: 5.61322
Timestep Consumption Time: 0.85526
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.46848

Cumulative Model Updates: 20,776
Cumulative Timesteps: 346,610,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 346610894...
Checkpoint 346610894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.69490
Policy Entropy: 1.02970
Value Function Loss: 3.25459

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.03958

Collected Steps per Second: 8,705.37310
Overall Steps per Second: 7,582.37462

Timestep Collection Time: 5.74404
Timestep Consumption Time: 0.85073
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.59477

Cumulative Model Updates: 20,779
Cumulative Timesteps: 346,660,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.44787
Policy Entropy: 1.01373
Value Function Loss: 3.32287

Mean KL Divergence: 0.02535
SB3 Clip Fraction: 0.19952
Policy Update Magnitude: 0.03942
Value Function Update Magnitude: 0.04205

Collected Steps per Second: 8,552.20013
Overall Steps per Second: 7,412.16936

Timestep Collection Time: 5.84855
Timestep Consumption Time: 0.89954
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.74809

Cumulative Model Updates: 20,782
Cumulative Timesteps: 346,710,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 346710916...
Checkpoint 346710916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.79596
Policy Entropy: 1.03112
Value Function Loss: 3.39526

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 8,733.67203
Overall Steps per Second: 7,635.07213

Timestep Collection Time: 5.72726
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.05260
Total Iteration Time: 6.55135

Cumulative Model Updates: 20,785
Cumulative Timesteps: 346,760,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.89000
Policy Entropy: 1.03928
Value Function Loss: 3.25994

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15613
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.04216

Collected Steps per Second: 8,443.08967
Overall Steps per Second: 7,270.59473

Timestep Collection Time: 5.92461
Timestep Consumption Time: 0.95543
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 6.88004

Cumulative Model Updates: 20,788
Cumulative Timesteps: 346,810,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 346810958...
Checkpoint 346810958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.74529
Policy Entropy: 1.02213
Value Function Loss: 3.26898

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.04199

Collected Steps per Second: 9,071.18226
Overall Steps per Second: 7,874.90392

Timestep Collection Time: 5.51284
Timestep Consumption Time: 0.83746
PPO Batch Consumption Time: 0.03978
Total Iteration Time: 6.35030

Cumulative Model Updates: 20,791
Cumulative Timesteps: 346,860,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.26140
Policy Entropy: 1.01936
Value Function Loss: 3.19251

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.17456
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 8,936.41668
Overall Steps per Second: 7,729.35129

Timestep Collection Time: 5.59643
Timestep Consumption Time: 0.87397
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 6.47040

Cumulative Model Updates: 20,794
Cumulative Timesteps: 346,910,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 346910978...
Checkpoint 346910978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.38449
Policy Entropy: 1.04768
Value Function Loss: 3.20259

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 8,976.00799
Overall Steps per Second: 7,796.58880

Timestep Collection Time: 5.57286
Timestep Consumption Time: 0.84303
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.41588

Cumulative Model Updates: 20,797
Cumulative Timesteps: 346,961,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.12467
Policy Entropy: 1.07052
Value Function Loss: 3.01472

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.21722
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 9,169.02334
Overall Steps per Second: 7,993.36784

Timestep Collection Time: 5.45402
Timestep Consumption Time: 0.80217
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.25619

Cumulative Model Updates: 20,800
Cumulative Timesteps: 347,011,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 347011008...
Checkpoint 347011008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.65516
Policy Entropy: 1.03140
Value Function Loss: 3.11994

Mean KL Divergence: 0.04640
SB3 Clip Fraction: 0.25152
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.04385

Collected Steps per Second: 9,168.23149
Overall Steps per Second: 7,898.77464

Timestep Collection Time: 5.45471
Timestep Consumption Time: 0.87666
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.33136

Cumulative Model Updates: 20,803
Cumulative Timesteps: 347,061,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.61218
Policy Entropy: 1.07481
Value Function Loss: 3.18843

Mean KL Divergence: 0.05412
SB3 Clip Fraction: 0.31338
Policy Update Magnitude: 0.04056
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 9,361.31416
Overall Steps per Second: 8,100.72878

Timestep Collection Time: 5.34284
Timestep Consumption Time: 0.83142
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 6.17426

Cumulative Model Updates: 20,806
Cumulative Timesteps: 347,111,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 347111034...
Checkpoint 347111034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.47878
Policy Entropy: 1.02654
Value Function Loss: 3.11926

Mean KL Divergence: 0.06141
SB3 Clip Fraction: 0.31918
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.03861

Collected Steps per Second: 9,119.39749
Overall Steps per Second: 7,928.61702

Timestep Collection Time: 5.48523
Timestep Consumption Time: 0.82381
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.30904

Cumulative Model Updates: 20,809
Cumulative Timesteps: 347,161,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.18209
Policy Entropy: 1.05999
Value Function Loss: 3.01287

Mean KL Divergence: 0.04979
SB3 Clip Fraction: 0.28409
Policy Update Magnitude: 0.03496
Value Function Update Magnitude: 0.03664

Collected Steps per Second: 8,941.07905
Overall Steps per Second: 7,661.86877

Timestep Collection Time: 5.59373
Timestep Consumption Time: 0.93392
PPO Batch Consumption Time: 0.05416
Total Iteration Time: 6.52765

Cumulative Model Updates: 20,812
Cumulative Timesteps: 347,211,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 347211070...
Checkpoint 347211070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.56584
Policy Entropy: 1.03620
Value Function Loss: 3.01389

Mean KL Divergence: 0.05713
SB3 Clip Fraction: 0.30968
Policy Update Magnitude: 0.03556
Value Function Update Magnitude: 0.03615

Collected Steps per Second: 8,348.88065
Overall Steps per Second: 7,406.05467

Timestep Collection Time: 5.99074
Timestep Consumption Time: 0.76265
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.75339

Cumulative Model Updates: 20,815
Cumulative Timesteps: 347,261,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.14670
Policy Entropy: 1.07588
Value Function Loss: 3.12694

Mean KL Divergence: 0.04367
SB3 Clip Fraction: 0.26655
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.04656

Collected Steps per Second: 9,008.82141
Overall Steps per Second: 7,850.77241

Timestep Collection Time: 5.55145
Timestep Consumption Time: 0.81888
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 6.37033

Cumulative Model Updates: 20,818
Cumulative Timesteps: 347,311,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 347311098...
Checkpoint 347311098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.30235
Policy Entropy: 1.03766
Value Function Loss: 3.03185

Mean KL Divergence: 0.06066
SB3 Clip Fraction: 0.29922
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.04317

Collected Steps per Second: 8,888.81305
Overall Steps per Second: 7,709.19212

Timestep Collection Time: 5.62572
Timestep Consumption Time: 0.86082
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 6.48654

Cumulative Model Updates: 20,821
Cumulative Timesteps: 347,361,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.26428
Policy Entropy: 1.07428
Value Function Loss: 2.99766

Mean KL Divergence: 0.04870
SB3 Clip Fraction: 0.28033
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.04169

Collected Steps per Second: 8,888.56907
Overall Steps per Second: 7,897.46462

Timestep Collection Time: 5.62813
Timestep Consumption Time: 0.70631
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.33444

Cumulative Model Updates: 20,824
Cumulative Timesteps: 347,411,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 347411130...
Checkpoint 347411130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.65116
Policy Entropy: 1.04931
Value Function Loss: 3.04871

Mean KL Divergence: 0.04807
SB3 Clip Fraction: 0.27995
Policy Update Magnitude: 0.03559
Value Function Update Magnitude: 0.04338

Collected Steps per Second: 8,790.13370
Overall Steps per Second: 7,485.15729

Timestep Collection Time: 5.69047
Timestep Consumption Time: 0.99209
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 6.68256

Cumulative Model Updates: 20,827
Cumulative Timesteps: 347,461,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.02037
Policy Entropy: 1.07664
Value Function Loss: 3.09259

Mean KL Divergence: 0.04090
SB3 Clip Fraction: 0.24939
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 8,720.47298
Overall Steps per Second: 7,650.98871

Timestep Collection Time: 5.73386
Timestep Consumption Time: 0.80150
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 6.53536

Cumulative Model Updates: 20,830
Cumulative Timesteps: 347,511,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 347511152...
Checkpoint 347511152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.71579
Policy Entropy: 1.04448
Value Function Loss: 3.03112

Mean KL Divergence: 0.03720
SB3 Clip Fraction: 0.25853
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.05068

Collected Steps per Second: 8,756.58690
Overall Steps per Second: 7,630.77662

Timestep Collection Time: 5.71067
Timestep Consumption Time: 0.84253
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 6.55320

Cumulative Model Updates: 20,833
Cumulative Timesteps: 347,561,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.82647
Policy Entropy: 1.06053
Value Function Loss: 2.91660

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.17884
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 8,897.26722
Overall Steps per Second: 7,770.10660

Timestep Collection Time: 5.62307
Timestep Consumption Time: 0.81570
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.43878

Cumulative Model Updates: 20,836
Cumulative Timesteps: 347,611,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 347611188...
Checkpoint 347611188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.40068
Policy Entropy: 1.05290
Value Function Loss: 2.83679

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.17045
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 8,811.18854
Overall Steps per Second: 7,772.93649

Timestep Collection Time: 5.67528
Timestep Consumption Time: 0.75806
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.43335

Cumulative Model Updates: 20,839
Cumulative Timesteps: 347,661,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.73081
Policy Entropy: 1.04313
Value Function Loss: 3.03789

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.20515
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 8,661.34341
Overall Steps per Second: 7,574.39431

Timestep Collection Time: 5.77624
Timestep Consumption Time: 0.82891
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.60515

Cumulative Model Updates: 20,842
Cumulative Timesteps: 347,711,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 347711224...
Checkpoint 347711224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.40070
Policy Entropy: 1.06360
Value Function Loss: 3.02564

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.03952
Value Function Update Magnitude: 0.05587

Collected Steps per Second: 8,814.24232
Overall Steps per Second: 7,719.58473

Timestep Collection Time: 5.67559
Timestep Consumption Time: 0.80481
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 6.48040

Cumulative Model Updates: 20,845
Cumulative Timesteps: 347,761,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.51507
Policy Entropy: 1.06707
Value Function Loss: 3.06921

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 9,011.98696
Overall Steps per Second: 7,781.48376

Timestep Collection Time: 5.54950
Timestep Consumption Time: 0.87755
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.42705

Cumulative Model Updates: 20,848
Cumulative Timesteps: 347,811,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 347811262...
Checkpoint 347811262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.48986
Policy Entropy: 1.04820
Value Function Loss: 2.81510

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 8,860.32188
Overall Steps per Second: 7,773.37107

Timestep Collection Time: 5.64449
Timestep Consumption Time: 0.78927
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 6.43376

Cumulative Model Updates: 20,851
Cumulative Timesteps: 347,861,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.25649
Policy Entropy: 1.03052
Value Function Loss: 2.82078

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.21803
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 9,017.59878
Overall Steps per Second: 7,918.45592

Timestep Collection Time: 5.54693
Timestep Consumption Time: 0.76996
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.31689

Cumulative Model Updates: 20,854
Cumulative Timesteps: 347,911,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 347911294...
Checkpoint 347911294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.12076
Policy Entropy: 1.04772
Value Function Loss: 2.79861

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 8,676.56972
Overall Steps per Second: 7,596.16096

Timestep Collection Time: 5.76564
Timestep Consumption Time: 0.82005
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.58570

Cumulative Model Updates: 20,857
Cumulative Timesteps: 347,961,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.93436
Policy Entropy: 1.05710
Value Function Loss: 2.88131

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.16723
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 8,944.27683
Overall Steps per Second: 7,758.26734

Timestep Collection Time: 5.59128
Timestep Consumption Time: 0.85474
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 6.44603

Cumulative Model Updates: 20,860
Cumulative Timesteps: 348,011,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 348011330...
Checkpoint 348011330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.70105
Policy Entropy: 1.04162
Value Function Loss: 2.94058

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 9,082.59722
Overall Steps per Second: 7,858.49506

Timestep Collection Time: 5.50746
Timestep Consumption Time: 0.85789
PPO Batch Consumption Time: 0.04813
Total Iteration Time: 6.36534

Cumulative Model Updates: 20,863
Cumulative Timesteps: 348,061,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.92745
Policy Entropy: 1.02778
Value Function Loss: 2.97457

Mean KL Divergence: 0.03408
SB3 Clip Fraction: 0.20534
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.04405

Collected Steps per Second: 9,027.14899
Overall Steps per Second: 7,839.08150

Timestep Collection Time: 5.54040
Timestep Consumption Time: 0.83969
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.38008

Cumulative Model Updates: 20,866
Cumulative Timesteps: 348,111,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 348111366...
Checkpoint 348111366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.20498
Policy Entropy: 1.04830
Value Function Loss: 3.00990

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.05320

Collected Steps per Second: 8,844.78865
Overall Steps per Second: 7,742.63479

Timestep Collection Time: 5.65486
Timestep Consumption Time: 0.80496
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 6.45982

Cumulative Model Updates: 20,869
Cumulative Timesteps: 348,161,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.39271
Policy Entropy: 1.04515
Value Function Loss: 3.04485

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17846
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.05409

Collected Steps per Second: 8,955.85183
Overall Steps per Second: 7,785.23919

Timestep Collection Time: 5.58607
Timestep Consumption Time: 0.83994
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.42601

Cumulative Model Updates: 20,872
Cumulative Timesteps: 348,211,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 348211410...
Checkpoint 348211410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.82854
Policy Entropy: 1.03259
Value Function Loss: 3.00699

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 8,829.29805
Overall Steps per Second: 7,699.73070

Timestep Collection Time: 5.66614
Timestep Consumption Time: 0.83123
PPO Batch Consumption Time: 0.04771
Total Iteration Time: 6.49737

Cumulative Model Updates: 20,875
Cumulative Timesteps: 348,261,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.97445
Policy Entropy: 1.03183
Value Function Loss: 3.11126

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.17052
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 9,083.91600
Overall Steps per Second: 7,905.37710

Timestep Collection Time: 5.50622
Timestep Consumption Time: 0.82087
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.32709

Cumulative Model Updates: 20,878
Cumulative Timesteps: 348,311,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 348311456...
Checkpoint 348311456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.81090
Policy Entropy: 1.05629
Value Function Loss: 3.13043

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 8,674.36513
Overall Steps per Second: 7,533.54156

Timestep Collection Time: 5.76734
Timestep Consumption Time: 0.87336
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.64070

Cumulative Model Updates: 20,881
Cumulative Timesteps: 348,361,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.32491
Policy Entropy: 1.07034
Value Function Loss: 3.27549

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.17326
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.05213

Collected Steps per Second: 8,671.27642
Overall Steps per Second: 7,669.91488

Timestep Collection Time: 5.76824
Timestep Consumption Time: 0.75308
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.52132

Cumulative Model Updates: 20,884
Cumulative Timesteps: 348,411,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 348411502...
Checkpoint 348411502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.08969
Policy Entropy: 1.04748
Value Function Loss: 3.11562

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15522
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.05011

Collected Steps per Second: 8,904.37851
Overall Steps per Second: 7,706.27153

Timestep Collection Time: 5.61724
Timestep Consumption Time: 0.87332
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.49056

Cumulative Model Updates: 20,887
Cumulative Timesteps: 348,461,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.45235
Policy Entropy: 1.05456
Value Function Loss: 3.10599

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.04757

Collected Steps per Second: 8,772.12077
Overall Steps per Second: 7,680.60432

Timestep Collection Time: 5.70102
Timestep Consumption Time: 0.81019
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 6.51121

Cumulative Model Updates: 20,890
Cumulative Timesteps: 348,511,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 348511530...
Checkpoint 348511530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.09852
Policy Entropy: 1.05676
Value Function Loss: 2.97573

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 8,834.88317
Overall Steps per Second: 7,745.10201

Timestep Collection Time: 5.66029
Timestep Consumption Time: 0.79644
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.45673

Cumulative Model Updates: 20,893
Cumulative Timesteps: 348,561,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.85922
Policy Entropy: 1.07743
Value Function Loss: 3.02997

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 8,931.96681
Overall Steps per Second: 7,667.86260

Timestep Collection Time: 5.59899
Timestep Consumption Time: 0.92304
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.52203

Cumulative Model Updates: 20,896
Cumulative Timesteps: 348,611,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 348611548...
Checkpoint 348611548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.26587
Policy Entropy: 1.08520
Value Function Loss: 2.94636

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.18405
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.05485

Collected Steps per Second: 8,598.07127
Overall Steps per Second: 7,527.22500

Timestep Collection Time: 5.81572
Timestep Consumption Time: 0.82736
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 6.64309

Cumulative Model Updates: 20,899
Cumulative Timesteps: 348,661,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.92458
Policy Entropy: 1.07102
Value Function Loss: 2.99496

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 8,859.04850
Overall Steps per Second: 7,689.64259

Timestep Collection Time: 5.64598
Timestep Consumption Time: 0.85861
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.50459

Cumulative Model Updates: 20,902
Cumulative Timesteps: 348,711,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 348711570...
Checkpoint 348711570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.51483
Policy Entropy: 1.07246
Value Function Loss: 2.99469

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.16640
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.05573

Collected Steps per Second: 8,604.71474
Overall Steps per Second: 7,524.63416

Timestep Collection Time: 5.81170
Timestep Consumption Time: 0.83421
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.64590

Cumulative Model Updates: 20,905
Cumulative Timesteps: 348,761,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.89912
Policy Entropy: 1.08116
Value Function Loss: 3.21882

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.04056
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 9,101.42206
Overall Steps per Second: 8,006.98504

Timestep Collection Time: 5.49365
Timestep Consumption Time: 0.75090
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.24455

Cumulative Model Updates: 20,908
Cumulative Timesteps: 348,811,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 348811578...
Checkpoint 348811578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.88838
Policy Entropy: 1.09244
Value Function Loss: 3.22554

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.03820
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 8,886.17191
Overall Steps per Second: 7,733.07558

Timestep Collection Time: 5.62717
Timestep Consumption Time: 0.83908
PPO Batch Consumption Time: 0.04051
Total Iteration Time: 6.46625

Cumulative Model Updates: 20,911
Cumulative Timesteps: 348,861,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.57693
Policy Entropy: 1.08324
Value Function Loss: 3.14357

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.03909

Collected Steps per Second: 9,248.73413
Overall Steps per Second: 8,004.04740

Timestep Collection Time: 5.40831
Timestep Consumption Time: 0.84103
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.24934

Cumulative Model Updates: 20,914
Cumulative Timesteps: 348,911,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 348911602...
Checkpoint 348911602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.94397
Policy Entropy: 1.08667
Value Function Loss: 3.17735

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 9,221.56132
Overall Steps per Second: 7,881.47716

Timestep Collection Time: 5.42229
Timestep Consumption Time: 0.92195
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 6.34424

Cumulative Model Updates: 20,917
Cumulative Timesteps: 348,961,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.35887
Policy Entropy: 1.10155
Value Function Loss: 3.15305

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.04740

Collected Steps per Second: 9,182.10548
Overall Steps per Second: 7,885.18736

Timestep Collection Time: 5.44581
Timestep Consumption Time: 0.89570
PPO Batch Consumption Time: 0.04615
Total Iteration Time: 6.34151

Cumulative Model Updates: 20,920
Cumulative Timesteps: 349,011,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 349011608...
Checkpoint 349011608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.39107
Policy Entropy: 1.09069
Value Function Loss: 3.12519

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 8,874.60176
Overall Steps per Second: 7,802.44713

Timestep Collection Time: 5.63541
Timestep Consumption Time: 0.77438
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.40978

Cumulative Model Updates: 20,923
Cumulative Timesteps: 349,061,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.66527
Policy Entropy: 1.07953
Value Function Loss: 3.08240

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.04246

Collected Steps per Second: 8,669.12889
Overall Steps per Second: 7,579.09341

Timestep Collection Time: 5.76898
Timestep Consumption Time: 0.82970
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.59868

Cumulative Model Updates: 20,926
Cumulative Timesteps: 349,111,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 349111632...
Checkpoint 349111632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.12702
Policy Entropy: 1.07877
Value Function Loss: 3.12161

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.03874

Collected Steps per Second: 8,932.76817
Overall Steps per Second: 7,849.40652

Timestep Collection Time: 5.59916
Timestep Consumption Time: 0.77279
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 6.37195

Cumulative Model Updates: 20,929
Cumulative Timesteps: 349,161,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.08127
Policy Entropy: 1.08351
Value Function Loss: 3.16107

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.04082

Collected Steps per Second: 8,801.38481
Overall Steps per Second: 7,683.05057

Timestep Collection Time: 5.68274
Timestep Consumption Time: 0.82717
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 6.50991

Cumulative Model Updates: 20,932
Cumulative Timesteps: 349,211,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 349211664...
Checkpoint 349211664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.04757
Policy Entropy: 1.08989
Value Function Loss: 3.15686

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.03679

Collected Steps per Second: 8,865.46680
Overall Steps per Second: 7,844.56144

Timestep Collection Time: 5.64189
Timestep Consumption Time: 0.73425
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.37614

Cumulative Model Updates: 20,935
Cumulative Timesteps: 349,261,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.97317
Policy Entropy: 1.07666
Value Function Loss: 3.28042

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.03916

Collected Steps per Second: 8,932.74486
Overall Steps per Second: 7,665.58601

Timestep Collection Time: 5.59962
Timestep Consumption Time: 0.92565
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.52527

Cumulative Model Updates: 20,938
Cumulative Timesteps: 349,311,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 349311702...
Checkpoint 349311702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.97310
Policy Entropy: 1.06764
Value Function Loss: 3.22750

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.18395
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.03860

Collected Steps per Second: 8,767.64124
Overall Steps per Second: 7,654.00576

Timestep Collection Time: 5.70507
Timestep Consumption Time: 0.83007
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.53514

Cumulative Model Updates: 20,941
Cumulative Timesteps: 349,361,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.24004
Policy Entropy: 1.08741
Value Function Loss: 3.21657

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.16140
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.04266

Collected Steps per Second: 8,608.59467
Overall Steps per Second: 7,571.22251

Timestep Collection Time: 5.81047
Timestep Consumption Time: 0.79612
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.60659

Cumulative Model Updates: 20,944
Cumulative Timesteps: 349,411,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 349411742...
Checkpoint 349411742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.84486
Policy Entropy: 1.08876
Value Function Loss: 3.23902

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.03702

Collected Steps per Second: 8,827.42532
Overall Steps per Second: 7,709.66434

Timestep Collection Time: 5.66643
Timestep Consumption Time: 0.82153
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 6.48796

Cumulative Model Updates: 20,947
Cumulative Timesteps: 349,461,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.99747
Policy Entropy: 1.07910
Value Function Loss: 3.19077

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 8,716.28015
Overall Steps per Second: 7,604.75113

Timestep Collection Time: 5.73708
Timestep Consumption Time: 0.83855
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 6.57563

Cumulative Model Updates: 20,950
Cumulative Timesteps: 349,511,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 349511768...
Checkpoint 349511768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.88525
Policy Entropy: 1.06707
Value Function Loss: 3.24197

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.19827
Policy Update Magnitude: 0.03803
Value Function Update Magnitude: 0.03861

Collected Steps per Second: 8,508.65395
Overall Steps per Second: 7,456.86344

Timestep Collection Time: 5.87919
Timestep Consumption Time: 0.82926
PPO Batch Consumption Time: 0.04007
Total Iteration Time: 6.70845

Cumulative Model Updates: 20,953
Cumulative Timesteps: 349,561,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.93768
Policy Entropy: 1.07470
Value Function Loss: 3.31568

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.03869
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 8,746.32759
Overall Steps per Second: 7,618.46918

Timestep Collection Time: 5.71829
Timestep Consumption Time: 0.84655
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.56484

Cumulative Model Updates: 20,956
Cumulative Timesteps: 349,611,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 349611806...
Checkpoint 349611806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.64253
Policy Entropy: 1.08801
Value Function Loss: 3.29533

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.17809
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 8,926.73745
Overall Steps per Second: 7,894.12427

Timestep Collection Time: 5.60160
Timestep Consumption Time: 0.73273
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.33433

Cumulative Model Updates: 20,959
Cumulative Timesteps: 349,661,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.14744
Policy Entropy: 1.05458
Value Function Loss: 3.34767

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.16013
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.04606

Collected Steps per Second: 8,952.52648
Overall Steps per Second: 7,758.00377

Timestep Collection Time: 5.58658
Timestep Consumption Time: 0.86018
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.44676

Cumulative Model Updates: 20,962
Cumulative Timesteps: 349,711,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 349711824...
Checkpoint 349711824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.67202
Policy Entropy: 1.07361
Value Function Loss: 3.16792

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.17419
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 8,783.97678
Overall Steps per Second: 7,663.40670

Timestep Collection Time: 5.69264
Timestep Consumption Time: 0.83240
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 6.52504

Cumulative Model Updates: 20,965
Cumulative Timesteps: 349,761,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.12962
Policy Entropy: 1.07263
Value Function Loss: 3.28896

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.03802
Value Function Update Magnitude: 0.03933

Collected Steps per Second: 8,844.67819
Overall Steps per Second: 7,669.43546

Timestep Collection Time: 5.65560
Timestep Consumption Time: 0.86665
PPO Batch Consumption Time: 0.05090
Total Iteration Time: 6.52225

Cumulative Model Updates: 20,968
Cumulative Timesteps: 349,811,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 349811850...
Checkpoint 349811850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.04808
Policy Entropy: 1.05825
Value Function Loss: 3.08462

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.03994
Value Function Update Magnitude: 0.03148

Collected Steps per Second: 8,795.75777
Overall Steps per Second: 7,660.45192

Timestep Collection Time: 5.68774
Timestep Consumption Time: 0.84294
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.53069

Cumulative Model Updates: 20,971
Cumulative Timesteps: 349,861,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.39478
Policy Entropy: 1.07297
Value Function Loss: 3.26028

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.03198

Collected Steps per Second: 8,891.58411
Overall Steps per Second: 7,886.73814

Timestep Collection Time: 5.62509
Timestep Consumption Time: 0.71669
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.34179

Cumulative Model Updates: 20,974
Cumulative Timesteps: 349,911,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 349911894...
Checkpoint 349911894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.89896
Policy Entropy: 1.07778
Value Function Loss: 3.27778

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.15471
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.02893

Collected Steps per Second: 8,903.34244
Overall Steps per Second: 7,712.82801

Timestep Collection Time: 5.61677
Timestep Consumption Time: 0.86698
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.48374

Cumulative Model Updates: 20,977
Cumulative Timesteps: 349,961,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.08013
Policy Entropy: 1.08661
Value Function Loss: 3.30470

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.02716

Collected Steps per Second: 8,661.87339
Overall Steps per Second: 7,516.15249

Timestep Collection Time: 5.77427
Timestep Consumption Time: 0.88020
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 6.65447

Cumulative Model Updates: 20,980
Cumulative Timesteps: 350,011,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 350011918...
Checkpoint 350011918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.97232
Policy Entropy: 1.07629
Value Function Loss: 3.12446

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.02647

Collected Steps per Second: 8,771.36442
Overall Steps per Second: 7,573.87568

Timestep Collection Time: 5.70310
Timestep Consumption Time: 0.90171
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.60481

Cumulative Model Updates: 20,983
Cumulative Timesteps: 350,061,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.27653
Policy Entropy: 1.06245
Value Function Loss: 3.17295

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.18233
Policy Update Magnitude: 0.04270
Value Function Update Magnitude: 0.02522

Collected Steps per Second: 8,819.12172
Overall Steps per Second: 7,645.39865

Timestep Collection Time: 5.67177
Timestep Consumption Time: 0.87073
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.54250

Cumulative Model Updates: 20,986
Cumulative Timesteps: 350,111,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 350111962...
Checkpoint 350111962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.88806
Policy Entropy: 1.07029
Value Function Loss: 3.17254

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.02418

Collected Steps per Second: 8,764.00109
Overall Steps per Second: 7,732.64635

Timestep Collection Time: 5.70698
Timestep Consumption Time: 0.76118
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 6.46816

Cumulative Model Updates: 20,989
Cumulative Timesteps: 350,161,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.57470
Policy Entropy: 1.07750
Value Function Loss: 3.29229

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.03764
Value Function Update Magnitude: 0.02680

Collected Steps per Second: 8,812.54164
Overall Steps per Second: 7,616.82935

Timestep Collection Time: 5.67577
Timestep Consumption Time: 0.89100
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 6.56677

Cumulative Model Updates: 20,992
Cumulative Timesteps: 350,211,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 350211996...
Checkpoint 350211996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.14331
Policy Entropy: 1.05892
Value Function Loss: 2.94098

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.19273
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.02467

Collected Steps per Second: 8,390.89296
Overall Steps per Second: 7,371.35748

Timestep Collection Time: 5.96170
Timestep Consumption Time: 0.82457
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.78627

Cumulative Model Updates: 20,995
Cumulative Timesteps: 350,262,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.83423
Policy Entropy: 1.07247
Value Function Loss: 2.95846

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.18751
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.03593

Collected Steps per Second: 8,980.98884
Overall Steps per Second: 7,752.40605

Timestep Collection Time: 5.56977
Timestep Consumption Time: 0.88268
PPO Batch Consumption Time: 0.04781
Total Iteration Time: 6.45245

Cumulative Model Updates: 20,998
Cumulative Timesteps: 350,312,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 350312042...
Checkpoint 350312042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.82815
Policy Entropy: 1.07480
Value Function Loss: 3.09788

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.18934
Policy Update Magnitude: 0.04219
Value Function Update Magnitude: 0.03197

Collected Steps per Second: 8,774.20494
Overall Steps per Second: 7,600.80651

Timestep Collection Time: 5.70012
Timestep Consumption Time: 0.87997
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.58009

Cumulative Model Updates: 21,001
Cumulative Timesteps: 350,362,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.83506
Policy Entropy: 1.06157
Value Function Loss: 3.31169

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.02592

Collected Steps per Second: 8,901.68894
Overall Steps per Second: 7,806.70700

Timestep Collection Time: 5.61804
Timestep Consumption Time: 0.78800
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.40603

Cumulative Model Updates: 21,004
Cumulative Timesteps: 350,412,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 350412066...
Checkpoint 350412066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.61625
Policy Entropy: 1.04447
Value Function Loss: 3.42514

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.20712
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.02939

Collected Steps per Second: 8,565.93638
Overall Steps per Second: 7,348.20116

Timestep Collection Time: 5.83801
Timestep Consumption Time: 0.96747
PPO Batch Consumption Time: 0.05277
Total Iteration Time: 6.80548

Cumulative Model Updates: 21,007
Cumulative Timesteps: 350,462,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.98599
Policy Entropy: 1.05810
Value Function Loss: 3.37654

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.03682

Collected Steps per Second: 8,673.82745
Overall Steps per Second: 7,493.97549

Timestep Collection Time: 5.76677
Timestep Consumption Time: 0.90792
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.67469

Cumulative Model Updates: 21,010
Cumulative Timesteps: 350,512,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 350512094...
Checkpoint 350512094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.18668
Policy Entropy: 1.05101
Value Function Loss: 3.33409

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.03171

Collected Steps per Second: 9,059.64042
Overall Steps per Second: 7,949.58688

Timestep Collection Time: 5.51920
Timestep Consumption Time: 0.77068
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.28989

Cumulative Model Updates: 21,013
Cumulative Timesteps: 350,562,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.78197
Policy Entropy: 1.05394
Value Function Loss: 3.42905

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.03087

Collected Steps per Second: 8,770.63142
Overall Steps per Second: 7,563.11063

Timestep Collection Time: 5.70335
Timestep Consumption Time: 0.91059
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.61395

Cumulative Model Updates: 21,016
Cumulative Timesteps: 350,612,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 350612118...
Checkpoint 350612118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.60187
Policy Entropy: 1.06307
Value Function Loss: 3.58922

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.03170

Collected Steps per Second: 9,062.94725
Overall Steps per Second: 7,784.55381

Timestep Collection Time: 5.51807
Timestep Consumption Time: 0.90619
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.42426

Cumulative Model Updates: 21,019
Cumulative Timesteps: 350,662,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.64697
Policy Entropy: 1.07370
Value Function Loss: 3.55900

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.02465

Collected Steps per Second: 8,989.97538
Overall Steps per Second: 7,767.84862

Timestep Collection Time: 5.56464
Timestep Consumption Time: 0.87549
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.44014

Cumulative Model Updates: 21,022
Cumulative Timesteps: 350,712,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 350712154...
Checkpoint 350712154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.18399
Policy Entropy: 1.06302
Value Function Loss: 3.29136

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.02361

Collected Steps per Second: 8,865.71978
Overall Steps per Second: 7,693.62230

Timestep Collection Time: 5.64196
Timestep Consumption Time: 0.85953
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 6.50149

Cumulative Model Updates: 21,025
Cumulative Timesteps: 350,762,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.80673
Policy Entropy: 1.05738
Value Function Loss: 3.18391

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.20721
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.02841

Collected Steps per Second: 9,151.91342
Overall Steps per Second: 8,004.24353

Timestep Collection Time: 5.46334
Timestep Consumption Time: 0.78335
PPO Batch Consumption Time: 0.04919
Total Iteration Time: 6.24669

Cumulative Model Updates: 21,028
Cumulative Timesteps: 350,812,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 350812174...
Checkpoint 350812174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.74643
Policy Entropy: 1.08970
Value Function Loss: 3.16533

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.22072
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.02981

Collected Steps per Second: 9,195.54108
Overall Steps per Second: 7,933.78017

Timestep Collection Time: 5.43981
Timestep Consumption Time: 0.86513
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 6.30494

Cumulative Model Updates: 21,031
Cumulative Timesteps: 350,862,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.99755
Policy Entropy: 1.07289
Value Function Loss: 3.43386

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.18645
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.02929

Collected Steps per Second: 8,674.41760
Overall Steps per Second: 7,520.82394

Timestep Collection Time: 5.76615
Timestep Consumption Time: 0.88445
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 6.65060

Cumulative Model Updates: 21,034
Cumulative Timesteps: 350,912,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 350912214...
Checkpoint 350912214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.79691
Policy Entropy: 1.08326
Value Function Loss: 3.31823

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.18000
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.02829

Collected Steps per Second: 8,628.31140
Overall Steps per Second: 7,631.99103

Timestep Collection Time: 5.79580
Timestep Consumption Time: 0.75661
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 6.55242

Cumulative Model Updates: 21,037
Cumulative Timesteps: 350,962,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.73306
Policy Entropy: 1.08985
Value Function Loss: 3.38601

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.16794
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.03228

Collected Steps per Second: 8,584.11299
Overall Steps per Second: 7,463.72468

Timestep Collection Time: 5.82541
Timestep Consumption Time: 0.87446
PPO Batch Consumption Time: 0.04534
Total Iteration Time: 6.69987

Cumulative Model Updates: 21,040
Cumulative Timesteps: 351,012,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 351012228...
Checkpoint 351012228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.70974
Policy Entropy: 1.06672
Value Function Loss: 3.11742

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.17161
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.02605

Collected Steps per Second: 8,926.90761
Overall Steps per Second: 7,826.44022

Timestep Collection Time: 5.60351
Timestep Consumption Time: 0.78790
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 6.39141

Cumulative Model Updates: 21,043
Cumulative Timesteps: 351,062,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.52421
Policy Entropy: 1.05818
Value Function Loss: 3.13233

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.22688
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.03714

Collected Steps per Second: 8,764.81585
Overall Steps per Second: 7,572.68227

Timestep Collection Time: 5.70485
Timestep Consumption Time: 0.89809
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.60294

Cumulative Model Updates: 21,046
Cumulative Timesteps: 351,112,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 351112252...
Checkpoint 351112252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.14346
Policy Entropy: 1.07154
Value Function Loss: 3.08254

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.04151

Collected Steps per Second: 8,560.26317
Overall Steps per Second: 7,517.50077

Timestep Collection Time: 5.84328
Timestep Consumption Time: 0.81053
PPO Batch Consumption Time: 0.04179
Total Iteration Time: 6.65381

Cumulative Model Updates: 21,049
Cumulative Timesteps: 351,162,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.87684
Policy Entropy: 1.07974
Value Function Loss: 2.92746

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.17202
Policy Update Magnitude: 0.03757
Value Function Update Magnitude: 0.03921

Collected Steps per Second: 9,056.49334
Overall Steps per Second: 7,856.31280

Timestep Collection Time: 5.52178
Timestep Consumption Time: 0.84354
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.36533

Cumulative Model Updates: 21,052
Cumulative Timesteps: 351,212,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 351212280...
Checkpoint 351212280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.28997
Policy Entropy: 1.06402
Value Function Loss: 3.04517

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 8,878.08481
Overall Steps per Second: 7,703.12917

Timestep Collection Time: 5.63252
Timestep Consumption Time: 0.85913
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.49165

Cumulative Model Updates: 21,055
Cumulative Timesteps: 351,262,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.70475
Policy Entropy: 1.03825
Value Function Loss: 3.01811

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.22570
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.03874

Collected Steps per Second: 9,018.09286
Overall Steps per Second: 7,834.19862

Timestep Collection Time: 5.54751
Timestep Consumption Time: 0.83833
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.38585

Cumulative Model Updates: 21,058
Cumulative Timesteps: 351,312,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351312314...
Checkpoint 351312314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.15617
Policy Entropy: 1.07472
Value Function Loss: 3.19129

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.18896
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 8,677.92968
Overall Steps per Second: 7,564.39825

Timestep Collection Time: 5.76197
Timestep Consumption Time: 0.84820
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.61018

Cumulative Model Updates: 21,061
Cumulative Timesteps: 351,362,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.41891
Policy Entropy: 1.04794
Value Function Loss: 3.03183

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 8,554.68100
Overall Steps per Second: 7,422.72068

Timestep Collection Time: 5.84709
Timestep Consumption Time: 0.89168
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.73877

Cumulative Model Updates: 21,064
Cumulative Timesteps: 351,412,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 351412336...
Checkpoint 351412336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.27959
Policy Entropy: 1.05069
Value Function Loss: 3.14757

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.03903

Collected Steps per Second: 8,595.90219
Overall Steps per Second: 7,609.80639

Timestep Collection Time: 5.81673
Timestep Consumption Time: 0.75374
PPO Batch Consumption Time: 0.04785
Total Iteration Time: 6.57047

Cumulative Model Updates: 21,067
Cumulative Timesteps: 351,462,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.00483
Policy Entropy: 1.06815
Value Function Loss: 3.17686

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.03980
Value Function Update Magnitude: 0.03913

Collected Steps per Second: 8,717.20990
Overall Steps per Second: 7,595.29782

Timestep Collection Time: 5.73647
Timestep Consumption Time: 0.84734
PPO Batch Consumption Time: 0.04735
Total Iteration Time: 6.58381

Cumulative Model Updates: 21,070
Cumulative Timesteps: 351,512,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 351512342...
Checkpoint 351512342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.12977
Policy Entropy: 1.06916
Value Function Loss: 3.15433

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.03957
Value Function Update Magnitude: 0.04123

Collected Steps per Second: 8,778.69042
Overall Steps per Second: 7,682.40079

Timestep Collection Time: 5.69607
Timestep Consumption Time: 0.81284
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.50890

Cumulative Model Updates: 21,073
Cumulative Timesteps: 351,562,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.80961
Policy Entropy: 1.05332
Value Function Loss: 3.10608

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.03772

Collected Steps per Second: 8,858.77176
Overall Steps per Second: 7,659.39356

Timestep Collection Time: 5.64728
Timestep Consumption Time: 0.88430
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.53159

Cumulative Model Updates: 21,076
Cumulative Timesteps: 351,612,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351612374...
Checkpoint 351612374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.95433
Policy Entropy: 1.04247
Value Function Loss: 2.96339

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.20389
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.03777

Collected Steps per Second: 9,002.12950
Overall Steps per Second: 7,844.59580

Timestep Collection Time: 5.55469
Timestep Consumption Time: 0.81964
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.37432

Cumulative Model Updates: 21,079
Cumulative Timesteps: 351,662,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.36975
Policy Entropy: 1.05212
Value Function Loss: 3.15214

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.03687

Collected Steps per Second: 8,925.96284
Overall Steps per Second: 7,877.44777

Timestep Collection Time: 5.60477
Timestep Consumption Time: 0.74601
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.35079

Cumulative Model Updates: 21,082
Cumulative Timesteps: 351,712,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351712406...
Checkpoint 351712406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.42866
Policy Entropy: 1.06509
Value Function Loss: 3.23188

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.04028

Collected Steps per Second: 8,993.79714
Overall Steps per Second: 7,762.60333

Timestep Collection Time: 5.56139
Timestep Consumption Time: 0.88207
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.44346

Cumulative Model Updates: 21,085
Cumulative Timesteps: 351,762,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.54509
Policy Entropy: 1.05414
Value Function Loss: 3.27817

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.03996

Collected Steps per Second: 8,797.49962
Overall Steps per Second: 7,755.30285

Timestep Collection Time: 5.68684
Timestep Consumption Time: 0.76423
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 6.45107

Cumulative Model Updates: 21,088
Cumulative Timesteps: 351,812,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 351812454...
Checkpoint 351812454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.80600
Policy Entropy: 1.04179
Value Function Loss: 3.34165

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.21915
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.03761

Collected Steps per Second: 8,463.15157
Overall Steps per Second: 7,402.81993

Timestep Collection Time: 5.91033
Timestep Consumption Time: 0.84656
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 6.75688

Cumulative Model Updates: 21,091
Cumulative Timesteps: 351,862,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.14063
Policy Entropy: 1.05439
Value Function Loss: 3.11957

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.03030

Collected Steps per Second: 8,792.81059
Overall Steps per Second: 7,678.67679

Timestep Collection Time: 5.68919
Timestep Consumption Time: 0.82547
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 6.51466

Cumulative Model Updates: 21,094
Cumulative Timesteps: 351,912,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 351912498...
Checkpoint 351912498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.49715
Policy Entropy: 1.06943
Value Function Loss: 3.21773

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.18905
Policy Update Magnitude: 0.04105
Value Function Update Magnitude: 0.02597

Collected Steps per Second: 8,948.87392
Overall Steps per Second: 7,903.66717

Timestep Collection Time: 5.58908
Timestep Consumption Time: 0.73912
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.32820

Cumulative Model Updates: 21,097
Cumulative Timesteps: 351,962,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.49559
Policy Entropy: 1.03247
Value Function Loss: 3.16651

Mean KL Divergence: 0.06255
SB3 Clip Fraction: 0.27769
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.02756

Collected Steps per Second: 8,740.27218
Overall Steps per Second: 7,611.62171

Timestep Collection Time: 5.72110
Timestep Consumption Time: 0.84832
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.56943

Cumulative Model Updates: 21,100
Cumulative Timesteps: 352,012,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 352012518...
Checkpoint 352012518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.48312
Policy Entropy: 1.07825
Value Function Loss: 3.30801

Mean KL Divergence: 0.04402
SB3 Clip Fraction: 0.29257
Policy Update Magnitude: 0.03919
Value Function Update Magnitude: 0.02701

Collected Steps per Second: 8,600.30988
Overall Steps per Second: 7,506.66259

Timestep Collection Time: 5.81514
Timestep Consumption Time: 0.84721
PPO Batch Consumption Time: 0.05217
Total Iteration Time: 6.66235

Cumulative Model Updates: 21,103
Cumulative Timesteps: 352,062,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.34927
Policy Entropy: 1.03686
Value Function Loss: 3.06434

Mean KL Divergence: 0.06523
SB3 Clip Fraction: 0.30583
Policy Update Magnitude: 0.03535
Value Function Update Magnitude: 0.03143

Collected Steps per Second: 8,797.85544
Overall Steps per Second: 7,670.64651

Timestep Collection Time: 5.68661
Timestep Consumption Time: 0.83565
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.52227

Cumulative Model Updates: 21,106
Cumulative Timesteps: 352,112,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 352112560...
Checkpoint 352112560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.35991
Policy Entropy: 1.06603
Value Function Loss: 3.04136

Mean KL Divergence: 0.04510
SB3 Clip Fraction: 0.27846
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.04013

Collected Steps per Second: 8,921.42125
Overall Steps per Second: 7,781.11051

Timestep Collection Time: 5.60651
Timestep Consumption Time: 0.82163
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.42813

Cumulative Model Updates: 21,109
Cumulative Timesteps: 352,162,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.45496
Policy Entropy: 1.03973
Value Function Loss: 3.06993

Mean KL Divergence: 0.04396
SB3 Clip Fraction: 0.26367
Policy Update Magnitude: 0.03641
Value Function Update Magnitude: 0.04505

Collected Steps per Second: 8,676.69522
Overall Steps per Second: 7,702.12718

Timestep Collection Time: 5.76487
Timestep Consumption Time: 0.72944
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 6.49431

Cumulative Model Updates: 21,112
Cumulative Timesteps: 352,212,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 352212598...
Checkpoint 352212598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.52037
Policy Entropy: 1.05869
Value Function Loss: 3.21467

Mean KL Divergence: 0.02958
SB3 Clip Fraction: 0.18120
Policy Update Magnitude: 0.03889
Value Function Update Magnitude: 0.04183

Collected Steps per Second: 8,798.76984
Overall Steps per Second: 7,606.90089

Timestep Collection Time: 5.68466
Timestep Consumption Time: 0.89069
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 6.57535

Cumulative Model Updates: 21,115
Cumulative Timesteps: 352,262,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.51778
Policy Entropy: 1.05596
Value Function Loss: 3.21773

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 8,582.64198
Overall Steps per Second: 7,541.25689

Timestep Collection Time: 5.82851
Timestep Consumption Time: 0.80487
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.63338

Cumulative Model Updates: 21,118
Cumulative Timesteps: 352,312,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 352312640...
Checkpoint 352312640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.22052
Policy Entropy: 1.05232
Value Function Loss: 3.15929

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.05561

Collected Steps per Second: 8,709.66847
Overall Steps per Second: 7,556.46369

Timestep Collection Time: 5.74121
Timestep Consumption Time: 0.87618
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 6.61738

Cumulative Model Updates: 21,121
Cumulative Timesteps: 352,362,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.75564
Policy Entropy: 1.05471
Value Function Loss: 3.10128

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.04998

Collected Steps per Second: 8,785.67668
Overall Steps per Second: 7,663.05648

Timestep Collection Time: 5.69176
Timestep Consumption Time: 0.83383
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.52559

Cumulative Model Updates: 21,124
Cumulative Timesteps: 352,412,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 352412650...
Checkpoint 352412650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.19957
Policy Entropy: 1.03646
Value Function Loss: 3.11130

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.17921
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.04233

Collected Steps per Second: 8,383.21975
Overall Steps per Second: 7,417.83447

Timestep Collection Time: 5.96787
Timestep Consumption Time: 0.77668
PPO Batch Consumption Time: 0.04842
Total Iteration Time: 6.74456

Cumulative Model Updates: 21,127
Cumulative Timesteps: 352,462,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.38164
Policy Entropy: 1.05424
Value Function Loss: 3.12227

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.19869
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 9,043.82128
Overall Steps per Second: 7,801.42145

Timestep Collection Time: 5.53129
Timestep Consumption Time: 0.88087
PPO Batch Consumption Time: 0.04605
Total Iteration Time: 6.41216

Cumulative Model Updates: 21,130
Cumulative Timesteps: 352,512,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 352512704...
Checkpoint 352512704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.34681
Policy Entropy: 1.05365
Value Function Loss: 3.12558

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.04618

Collected Steps per Second: 8,794.87256
Overall Steps per Second: 7,756.58616

Timestep Collection Time: 5.68513
Timestep Consumption Time: 0.76100
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.44613

Cumulative Model Updates: 21,133
Cumulative Timesteps: 352,562,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.54418
Policy Entropy: 1.05675
Value Function Loss: 3.05750

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.17551
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.05136

Collected Steps per Second: 9,092.86601
Overall Steps per Second: 7,874.64569

Timestep Collection Time: 5.50124
Timestep Consumption Time: 0.85105
PPO Batch Consumption Time: 0.04943
Total Iteration Time: 6.35229

Cumulative Model Updates: 21,136
Cumulative Timesteps: 352,612,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 352612726...
Checkpoint 352612726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.18246
Policy Entropy: 1.04966
Value Function Loss: 2.88328

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.04279

Collected Steps per Second: 9,277.71112
Overall Steps per Second: 8,150.99492

Timestep Collection Time: 5.39055
Timestep Consumption Time: 0.74514
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.13569

Cumulative Model Updates: 21,139
Cumulative Timesteps: 352,662,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.56177
Policy Entropy: 1.05165
Value Function Loss: 2.90810

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.03683

Collected Steps per Second: 9,026.35170
Overall Steps per Second: 7,785.76465

Timestep Collection Time: 5.54155
Timestep Consumption Time: 0.88299
PPO Batch Consumption Time: 0.04719
Total Iteration Time: 6.42455

Cumulative Model Updates: 21,142
Cumulative Timesteps: 352,712,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 352712758...
Checkpoint 352712758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.90319
Policy Entropy: 1.05839
Value Function Loss: 3.03033

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.03893

Collected Steps per Second: 8,491.64442
Overall Steps per Second: 7,449.04955

Timestep Collection Time: 5.89144
Timestep Consumption Time: 0.82459
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 6.71602

Cumulative Model Updates: 21,145
Cumulative Timesteps: 352,762,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.60504
Policy Entropy: 1.07752
Value Function Loss: 3.00257

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.17846
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.04180

Collected Steps per Second: 8,565.95162
Overall Steps per Second: 7,570.71202

Timestep Collection Time: 5.83823
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.60572

Cumulative Model Updates: 21,148
Cumulative Timesteps: 352,812,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 352812796...
Checkpoint 352812796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.53811
Policy Entropy: 1.06159
Value Function Loss: 3.01910

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.05616

Collected Steps per Second: 8,796.49102
Overall Steps per Second: 7,663.71484

Timestep Collection Time: 5.68408
Timestep Consumption Time: 0.84017
PPO Batch Consumption Time: 0.04081
Total Iteration Time: 6.52425

Cumulative Model Updates: 21,151
Cumulative Timesteps: 352,862,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.33374
Policy Entropy: 1.05565
Value Function Loss: 3.16394

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.04110
Value Function Update Magnitude: 0.05299

Collected Steps per Second: 8,945.62172
Overall Steps per Second: 7,795.35785

Timestep Collection Time: 5.59134
Timestep Consumption Time: 0.82504
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.41638

Cumulative Model Updates: 21,154
Cumulative Timesteps: 352,912,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 352912814...
Checkpoint 352912814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.49674
Policy Entropy: 1.06644
Value Function Loss: 3.33587

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.15730
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.04918

Collected Steps per Second: 8,986.82730
Overall Steps per Second: 7,830.62933

Timestep Collection Time: 5.56570
Timestep Consumption Time: 0.82178
PPO Batch Consumption Time: 0.03885
Total Iteration Time: 6.38748

Cumulative Model Updates: 21,157
Cumulative Timesteps: 352,962,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.28875
Policy Entropy: 1.06602
Value Function Loss: 3.24988

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.03834
Value Function Update Magnitude: 0.04717

Collected Steps per Second: 8,483.83933
Overall Steps per Second: 7,439.39150

Timestep Collection Time: 5.89356
Timestep Consumption Time: 0.82742
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 6.72098

Cumulative Model Updates: 21,160
Cumulative Timesteps: 353,012,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 353012832...
Checkpoint 353012832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.81350
Policy Entropy: 1.06484
Value Function Loss: 3.01458

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.05175

Collected Steps per Second: 8,910.80590
Overall Steps per Second: 7,851.03570

Timestep Collection Time: 5.61476
Timestep Consumption Time: 0.75791
PPO Batch Consumption Time: 0.04606
Total Iteration Time: 6.37266

Cumulative Model Updates: 21,163
Cumulative Timesteps: 353,062,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.23417
Policy Entropy: 1.05990
Value Function Loss: 3.01602

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.05436

Collected Steps per Second: 8,757.88438
Overall Steps per Second: 7,626.54247

Timestep Collection Time: 5.70960
Timestep Consumption Time: 0.84698
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.55658

Cumulative Model Updates: 21,166
Cumulative Timesteps: 353,112,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 353112868...
Checkpoint 353112868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.70660
Policy Entropy: 1.07188
Value Function Loss: 3.12929

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 8,789.33099
Overall Steps per Second: 7,627.73389

Timestep Collection Time: 5.69008
Timestep Consumption Time: 0.86652
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 6.55660

Cumulative Model Updates: 21,169
Cumulative Timesteps: 353,162,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.88994
Policy Entropy: 1.08161
Value Function Loss: 3.20405

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.19365
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.06020

Collected Steps per Second: 8,568.76366
Overall Steps per Second: 7,423.94430

Timestep Collection Time: 5.83842
Timestep Consumption Time: 0.90032
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.73874

Cumulative Model Updates: 21,172
Cumulative Timesteps: 353,212,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 353212908...
Checkpoint 353212908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.13637
Policy Entropy: 1.05569
Value Function Loss: 3.09316

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 8,914.20031
Overall Steps per Second: 7,677.37980

Timestep Collection Time: 5.60903
Timestep Consumption Time: 0.90361
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.51264

Cumulative Model Updates: 21,175
Cumulative Timesteps: 353,262,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.41401
Policy Entropy: 1.07769
Value Function Loss: 3.14361

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.16921
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 8,821.96938
Overall Steps per Second: 7,687.87935

Timestep Collection Time: 5.66994
Timestep Consumption Time: 0.83641
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.50635

Cumulative Model Updates: 21,178
Cumulative Timesteps: 353,312,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 353312928...
Checkpoint 353312928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.77008
Policy Entropy: 1.09179
Value Function Loss: 3.07498

Mean KL Divergence: 0.02475
SB3 Clip Fraction: 0.18524
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.05925

Collected Steps per Second: 9,082.39398
Overall Steps per Second: 7,848.00544

Timestep Collection Time: 5.50604
Timestep Consumption Time: 0.86603
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.37206

Cumulative Model Updates: 21,181
Cumulative Timesteps: 353,362,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.04202
Policy Entropy: 1.06022
Value Function Loss: 3.11374

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.19073
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 8,798.21193
Overall Steps per Second: 7,650.94378

Timestep Collection Time: 5.68411
Timestep Consumption Time: 0.85234
PPO Batch Consumption Time: 0.04056
Total Iteration Time: 6.53645

Cumulative Model Updates: 21,184
Cumulative Timesteps: 353,412,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 353412946...
Checkpoint 353412946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.50052
Policy Entropy: 1.08408
Value Function Loss: 3.09481

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.04215

Collected Steps per Second: 8,410.72969
Overall Steps per Second: 7,361.56228

Timestep Collection Time: 5.94526
Timestep Consumption Time: 0.84732
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 6.79258

Cumulative Model Updates: 21,187
Cumulative Timesteps: 353,462,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.33053
Policy Entropy: 1.08764
Value Function Loss: 3.07861

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.16108
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.05728

Collected Steps per Second: 8,777.40873
Overall Steps per Second: 7,637.50145

Timestep Collection Time: 5.69713
Timestep Consumption Time: 0.85030
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.54743

Cumulative Model Updates: 21,190
Cumulative Timesteps: 353,512,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 353512956...
Checkpoint 353512956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.59118
Policy Entropy: 1.07092
Value Function Loss: 3.08245

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 8,901.14570
Overall Steps per Second: 7,730.52626

Timestep Collection Time: 5.61770
Timestep Consumption Time: 0.85068
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.46838

Cumulative Model Updates: 21,193
Cumulative Timesteps: 353,562,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.61310
Policy Entropy: 1.06539
Value Function Loss: 3.14751

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.03865
Value Function Update Magnitude: 0.06093

Collected Steps per Second: 9,223.20473
Overall Steps per Second: 7,982.78841

Timestep Collection Time: 5.42306
Timestep Consumption Time: 0.84267
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.26573

Cumulative Model Updates: 21,196
Cumulative Timesteps: 353,612,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 353612978...
Checkpoint 353612978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.54081
Policy Entropy: 1.07575
Value Function Loss: 3.20145

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.05338

Collected Steps per Second: 8,982.59954
Overall Steps per Second: 7,780.94517

Timestep Collection Time: 5.56721
Timestep Consumption Time: 0.85977
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 6.42698

Cumulative Model Updates: 21,199
Cumulative Timesteps: 353,662,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.60325
Policy Entropy: 1.09472
Value Function Loss: 3.19462

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.18987
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 8,194.04495
Overall Steps per Second: 7,184.43521

Timestep Collection Time: 6.10321
Timestep Consumption Time: 0.85767
PPO Batch Consumption Time: 0.04599
Total Iteration Time: 6.96088

Cumulative Model Updates: 21,202
Cumulative Timesteps: 353,712,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 353712996...
Checkpoint 353712996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.03675
Policy Entropy: 1.05108
Value Function Loss: 3.03219

Mean KL Divergence: 0.07665
SB3 Clip Fraction: 0.35249
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.03632

Collected Steps per Second: 8,586.15318
Overall Steps per Second: 7,397.75874

Timestep Collection Time: 5.82682
Timestep Consumption Time: 0.93604
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.76286

Cumulative Model Updates: 21,205
Cumulative Timesteps: 353,763,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.18816
Policy Entropy: 1.08231
Value Function Loss: 2.89430

Mean KL Divergence: 0.03520
SB3 Clip Fraction: 0.24481
Policy Update Magnitude: 0.03827
Value Function Update Magnitude: 0.03787

Collected Steps per Second: 8,918.72312
Overall Steps per Second: 7,808.64703

Timestep Collection Time: 5.60865
Timestep Consumption Time: 0.79732
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.40598

Cumulative Model Updates: 21,208
Cumulative Timesteps: 353,813,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 353813048...
Checkpoint 353813048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.86237
Policy Entropy: 1.04955
Value Function Loss: 2.85597

Mean KL Divergence: 0.05257
SB3 Clip Fraction: 0.32028
Policy Update Magnitude: 0.03683
Value Function Update Magnitude: 0.03762

Collected Steps per Second: 8,927.22417
Overall Steps per Second: 7,833.93474

Timestep Collection Time: 5.60398
Timestep Consumption Time: 0.78208
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.38606

Cumulative Model Updates: 21,211
Cumulative Timesteps: 353,863,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.50260
Policy Entropy: 1.08195
Value Function Loss: 2.76491

Mean KL Divergence: 0.03712
SB3 Clip Fraction: 0.25656
Policy Update Magnitude: 0.03498
Value Function Update Magnitude: 0.03477

Collected Steps per Second: 8,553.69745
Overall Steps per Second: 7,452.02302

Timestep Collection Time: 5.84730
Timestep Consumption Time: 0.86444
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.71173

Cumulative Model Updates: 21,214
Cumulative Timesteps: 353,913,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 353913092...
Checkpoint 353913092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.94384
Policy Entropy: 1.05178
Value Function Loss: 2.78743

Mean KL Divergence: 0.04415
SB3 Clip Fraction: 0.28479
Policy Update Magnitude: 0.03478
Value Function Update Magnitude: 0.03297

Collected Steps per Second: 8,765.90380
Overall Steps per Second: 7,684.48418

Timestep Collection Time: 5.70711
Timestep Consumption Time: 0.80315
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 6.51026

Cumulative Model Updates: 21,217
Cumulative Timesteps: 353,963,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.65683
Policy Entropy: 1.07480
Value Function Loss: 2.79902

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.17940
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.02899

Collected Steps per Second: 8,978.58286
Overall Steps per Second: 7,795.68696

Timestep Collection Time: 5.56903
Timestep Consumption Time: 0.84503
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.41406

Cumulative Model Updates: 21,220
Cumulative Timesteps: 354,013,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 354013122...
Checkpoint 354013122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.84345
Policy Entropy: 1.06365
Value Function Loss: 2.91367

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.19486
Policy Update Magnitude: 0.03284
Value Function Update Magnitude: 0.03560

Collected Steps per Second: 8,695.63887
Overall Steps per Second: 7,577.76423

Timestep Collection Time: 5.75254
Timestep Consumption Time: 0.84862
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.60116

Cumulative Model Updates: 21,223
Cumulative Timesteps: 354,063,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.23345
Policy Entropy: 1.05846
Value Function Loss: 3.04733

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.17953
Policy Update Magnitude: 0.03216
Value Function Update Magnitude: 0.03744

Collected Steps per Second: 8,717.75905
Overall Steps per Second: 7,718.88468

Timestep Collection Time: 5.73680
Timestep Consumption Time: 0.74238
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 6.47917

Cumulative Model Updates: 21,226
Cumulative Timesteps: 354,113,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 354113156...
Checkpoint 354113156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.96178
Policy Entropy: 1.06533
Value Function Loss: 3.01721

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 8,754.98110
Overall Steps per Second: 7,591.39490

Timestep Collection Time: 5.71378
Timestep Consumption Time: 0.87579
PPO Batch Consumption Time: 0.04922
Total Iteration Time: 6.58957

Cumulative Model Updates: 21,229
Cumulative Timesteps: 354,163,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.56531
Policy Entropy: 1.06740
Value Function Loss: 2.98746

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.03582
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 8,681.85923
Overall Steps per Second: 7,583.15289

Timestep Collection Time: 5.76029
Timestep Consumption Time: 0.83460
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.59488

Cumulative Model Updates: 21,232
Cumulative Timesteps: 354,213,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 354213190...
Checkpoint 354213190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.86491
Policy Entropy: 1.05347
Value Function Loss: 3.22933

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.03950
Value Function Update Magnitude: 0.03917

Collected Steps per Second: 8,886.29887
Overall Steps per Second: 7,694.28129

Timestep Collection Time: 5.62844
Timestep Consumption Time: 0.87197
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 6.50041

Cumulative Model Updates: 21,235
Cumulative Timesteps: 354,263,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.67288
Policy Entropy: 1.05266
Value Function Loss: 3.12933

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.04064
Value Function Update Magnitude: 0.03068

Collected Steps per Second: 9,125.51908
Overall Steps per Second: 7,865.40722

Timestep Collection Time: 5.47958
Timestep Consumption Time: 0.87788
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.35746

Cumulative Model Updates: 21,238
Cumulative Timesteps: 354,313,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 354313210...
Checkpoint 354313210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.99993
Policy Entropy: 1.06013
Value Function Loss: 3.41815

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.16898
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.03147

Collected Steps per Second: 8,869.32776
Overall Steps per Second: 7,725.11718

Timestep Collection Time: 5.63898
Timestep Consumption Time: 0.83522
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 6.47421

Cumulative Model Updates: 21,241
Cumulative Timesteps: 354,363,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.31857
Policy Entropy: 1.07006
Value Function Loss: 3.36294

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.19215
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.02652

Collected Steps per Second: 9,105.83510
Overall Steps per Second: 7,779.64582

Timestep Collection Time: 5.49340
Timestep Consumption Time: 0.93646
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.42986

Cumulative Model Updates: 21,244
Cumulative Timesteps: 354,413,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 354413246...
Checkpoint 354413246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.96980
Policy Entropy: 1.05894
Value Function Loss: 3.19043

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.02240

Collected Steps per Second: 9,197.10258
Overall Steps per Second: 7,997.33103

Timestep Collection Time: 5.43954
Timestep Consumption Time: 0.81605
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 6.25559

Cumulative Model Updates: 21,247
Cumulative Timesteps: 354,463,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.35000
Policy Entropy: 1.04887
Value Function Loss: 2.97785

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.02210

Collected Steps per Second: 9,552.37206
Overall Steps per Second: 8,176.97645

Timestep Collection Time: 5.23640
Timestep Consumption Time: 0.88078
PPO Batch Consumption Time: 0.04731
Total Iteration Time: 6.11718

Cumulative Model Updates: 21,250
Cumulative Timesteps: 354,513,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 354513294...
Checkpoint 354513294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.33143
Policy Entropy: 1.05929
Value Function Loss: 3.06965

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.02328

Collected Steps per Second: 8,987.09348
Overall Steps per Second: 7,733.37380

Timestep Collection Time: 5.56576
Timestep Consumption Time: 0.90231
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 6.46807

Cumulative Model Updates: 21,253
Cumulative Timesteps: 354,563,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.87674
Policy Entropy: 1.06486
Value Function Loss: 3.24877

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.18571
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.02084

Collected Steps per Second: 8,443.67358
Overall Steps per Second: 7,491.42835

Timestep Collection Time: 5.92349
Timestep Consumption Time: 0.75294
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.67643

Cumulative Model Updates: 21,256
Cumulative Timesteps: 354,613,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 354613330...
Checkpoint 354613330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.40527
Policy Entropy: 1.05847
Value Function Loss: 3.09680

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.01895

Collected Steps per Second: 8,842.97179
Overall Steps per Second: 7,686.15918

Timestep Collection Time: 5.65556
Timestep Consumption Time: 0.85120
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.50676

Cumulative Model Updates: 21,259
Cumulative Timesteps: 354,663,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.50666
Policy Entropy: 1.04451
Value Function Loss: 3.13745

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.16938
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.02360

Collected Steps per Second: 8,959.13523
Overall Steps per Second: 7,812.40824

Timestep Collection Time: 5.58290
Timestep Consumption Time: 0.81947
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.40238

Cumulative Model Updates: 21,262
Cumulative Timesteps: 354,713,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 354713360...
Checkpoint 354713360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.30420
Policy Entropy: 1.05826
Value Function Loss: 3.02371

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.01937

Collected Steps per Second: 9,011.66315
Overall Steps per Second: 7,813.08708

Timestep Collection Time: 5.54837
Timestep Consumption Time: 0.85115
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.39952

Cumulative Model Updates: 21,265
Cumulative Timesteps: 354,763,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.92947
Policy Entropy: 1.07388
Value Function Loss: 3.14791

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.18657
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.02113

Collected Steps per Second: 8,998.53183
Overall Steps per Second: 7,829.11349

Timestep Collection Time: 5.55957
Timestep Consumption Time: 0.83042
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 6.39000

Cumulative Model Updates: 21,268
Cumulative Timesteps: 354,813,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 354813388...
Checkpoint 354813388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.57612
Policy Entropy: 1.03264
Value Function Loss: 3.00272

Mean KL Divergence: 0.06562
SB3 Clip Fraction: 0.32979
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.01936

Collected Steps per Second: 8,277.58766
Overall Steps per Second: 7,318.80100

Timestep Collection Time: 6.04210
Timestep Consumption Time: 0.79153
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 6.83363

Cumulative Model Updates: 21,271
Cumulative Timesteps: 354,863,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.32620
Policy Entropy: 1.07516
Value Function Loss: 2.90279

Mean KL Divergence: 0.05101
SB3 Clip Fraction: 0.30870
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.02141

Collected Steps per Second: 8,713.46243
Overall Steps per Second: 7,494.63260

Timestep Collection Time: 5.74100
Timestep Consumption Time: 0.93364
PPO Batch Consumption Time: 0.04898
Total Iteration Time: 6.67464

Cumulative Model Updates: 21,274
Cumulative Timesteps: 354,913,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 354913426...
Checkpoint 354913426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.49193
Policy Entropy: 1.04740
Value Function Loss: 2.67944

Mean KL Divergence: 0.05105
SB3 Clip Fraction: 0.33238
Policy Update Magnitude: 0.04025
Value Function Update Magnitude: 0.02221

Collected Steps per Second: 8,777.27100
Overall Steps per Second: 7,655.51698

Timestep Collection Time: 5.69722
Timestep Consumption Time: 0.83481
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.53202

Cumulative Model Updates: 21,277
Cumulative Timesteps: 354,963,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.35638
Policy Entropy: 1.07721
Value Function Loss: 2.65194

Mean KL Divergence: 0.04753
SB3 Clip Fraction: 0.30157
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.02896

Collected Steps per Second: 8,743.30831
Overall Steps per Second: 7,653.09885

Timestep Collection Time: 5.72140
Timestep Consumption Time: 0.81503
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 6.53644

Cumulative Model Updates: 21,280
Cumulative Timesteps: 355,013,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 355013456...
Checkpoint 355013456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.55840
Policy Entropy: 1.04442
Value Function Loss: 2.68783

Mean KL Divergence: 0.06622
SB3 Clip Fraction: 0.36539
Policy Update Magnitude: 0.03693
Value Function Update Magnitude: 0.02406

Collected Steps per Second: 8,506.09830
Overall Steps per Second: 7,423.67872

Timestep Collection Time: 5.88190
Timestep Consumption Time: 0.85762
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 6.73952

Cumulative Model Updates: 21,283
Cumulative Timesteps: 355,063,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.12940
Policy Entropy: 1.07376
Value Function Loss: 2.77499

Mean KL Divergence: 0.04325
SB3 Clip Fraction: 0.28295
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.02704

Collected Steps per Second: 8,675.94648
Overall Steps per Second: 7,589.85706

Timestep Collection Time: 5.76421
Timestep Consumption Time: 0.82484
PPO Batch Consumption Time: 0.04979
Total Iteration Time: 6.58906

Cumulative Model Updates: 21,286
Cumulative Timesteps: 355,113,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 355113498...
Checkpoint 355113498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.76161
Policy Entropy: 1.04853
Value Function Loss: 2.73528

Mean KL Divergence: 0.04474
SB3 Clip Fraction: 0.29906
Policy Update Magnitude: 0.03204
Value Function Update Magnitude: 0.02581

Collected Steps per Second: 8,679.99175
Overall Steps per Second: 7,540.55851

Timestep Collection Time: 5.76130
Timestep Consumption Time: 0.87057
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 6.63187

Cumulative Model Updates: 21,289
Cumulative Timesteps: 355,163,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.55811
Policy Entropy: 1.07105
Value Function Loss: 2.70354

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.21957
Policy Update Magnitude: 0.03495
Value Function Update Magnitude: 0.03354

Collected Steps per Second: 8,760.34864
Overall Steps per Second: 7,521.32687

Timestep Collection Time: 5.70754
Timestep Consumption Time: 0.94023
PPO Batch Consumption Time: 0.04704
Total Iteration Time: 6.64776

Cumulative Model Updates: 21,292
Cumulative Timesteps: 355,213,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 355213506...
Checkpoint 355213506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.99207
Policy Entropy: 1.03783
Value Function Loss: 2.66905

Mean KL Divergence: 0.04893
SB3 Clip Fraction: 0.33524
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 8,861.75801
Overall Steps per Second: 7,845.32122

Timestep Collection Time: 5.64267
Timestep Consumption Time: 0.73106
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.37374

Cumulative Model Updates: 21,295
Cumulative Timesteps: 355,263,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.62191
Policy Entropy: 1.06140
Value Function Loss: 2.50857

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.18390
Policy Update Magnitude: 0.03846
Value Function Update Magnitude: 0.03059

Collected Steps per Second: 8,688.52419
Overall Steps per Second: 7,534.99373

Timestep Collection Time: 5.75564
Timestep Consumption Time: 0.88113
PPO Batch Consumption Time: 0.05217
Total Iteration Time: 6.63677

Cumulative Model Updates: 21,298
Cumulative Timesteps: 355,313,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 355313518...
Checkpoint 355313518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.83350
Policy Entropy: 1.04364
Value Function Loss: 2.60004

Mean KL Divergence: 0.02695
SB3 Clip Fraction: 0.21311
Policy Update Magnitude: 0.03559
Value Function Update Magnitude: 0.03100

Collected Steps per Second: 8,841.94931
Overall Steps per Second: 7,734.74944

Timestep Collection Time: 5.65667
Timestep Consumption Time: 0.80973
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 6.46640

Cumulative Model Updates: 21,301
Cumulative Timesteps: 355,363,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.70017
Policy Entropy: 1.05288
Value Function Loss: 2.86172

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.19607
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.03466

Collected Steps per Second: 8,905.71503
Overall Steps per Second: 7,846.82757

Timestep Collection Time: 5.61639
Timestep Consumption Time: 0.75790
PPO Batch Consumption Time: 0.05137
Total Iteration Time: 6.37430

Cumulative Model Updates: 21,304
Cumulative Timesteps: 355,413,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 355413552...
Checkpoint 355413552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.77777
Policy Entropy: 1.06194
Value Function Loss: 2.99641

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.04013
Value Function Update Magnitude: 0.03295

Collected Steps per Second: 8,936.89762
Overall Steps per Second: 7,664.67951

Timestep Collection Time: 5.59680
Timestep Consumption Time: 0.92898
PPO Batch Consumption Time: 0.05257
Total Iteration Time: 6.52578

Cumulative Model Updates: 21,307
Cumulative Timesteps: 355,463,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.46016
Policy Entropy: 1.04973
Value Function Loss: 2.92827

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.19385
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.04050

Collected Steps per Second: 8,702.09753
Overall Steps per Second: 7,493.89211

Timestep Collection Time: 5.74758
Timestep Consumption Time: 0.92666
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.67424

Cumulative Model Updates: 21,310
Cumulative Timesteps: 355,513,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 355513586...
Checkpoint 355513586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.55548
Policy Entropy: 1.04298
Value Function Loss: 2.93758

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.20372
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.04706

Collected Steps per Second: 8,998.51873
Overall Steps per Second: 7,796.13352

Timestep Collection Time: 5.55847
Timestep Consumption Time: 0.85727
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.41574

Cumulative Model Updates: 21,313
Cumulative Timesteps: 355,563,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.86169
Policy Entropy: 1.05276
Value Function Loss: 2.83166

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.04033

Collected Steps per Second: 8,766.70690
Overall Steps per Second: 7,597.53590

Timestep Collection Time: 5.70545
Timestep Consumption Time: 0.87800
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 6.58345

Cumulative Model Updates: 21,316
Cumulative Timesteps: 355,613,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 355613622...
Checkpoint 355613622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.47031
Policy Entropy: 1.06103
Value Function Loss: 2.77677

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.04424

Collected Steps per Second: 8,707.24170
Overall Steps per Second: 7,698.23675

Timestep Collection Time: 5.74327
Timestep Consumption Time: 0.75277
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.49603

Cumulative Model Updates: 21,319
Cumulative Timesteps: 355,663,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.61200
Policy Entropy: 1.03822
Value Function Loss: 2.56673

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 8,652.34074
Overall Steps per Second: 7,513.17657

Timestep Collection Time: 5.77948
Timestep Consumption Time: 0.87630
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.65577

Cumulative Model Updates: 21,322
Cumulative Timesteps: 355,713,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 355713636...
Checkpoint 355713636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.40379
Policy Entropy: 1.04812
Value Function Loss: 2.51076

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.06211

Collected Steps per Second: 8,490.21187
Overall Steps per Second: 7,450.80963

Timestep Collection Time: 5.89078
Timestep Consumption Time: 0.82178
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 6.71256

Cumulative Model Updates: 21,325
Cumulative Timesteps: 355,763,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.25566
Policy Entropy: 1.04647
Value Function Loss: 2.52476

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.06141

Collected Steps per Second: 8,709.13197
Overall Steps per Second: 7,615.76676

Timestep Collection Time: 5.74432
Timestep Consumption Time: 0.82469
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.56900

Cumulative Model Updates: 21,328
Cumulative Timesteps: 355,813,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 355813678...
Checkpoint 355813678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.31070
Policy Entropy: 1.05271
Value Function Loss: 2.72491

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.05792

Collected Steps per Second: 8,815.23720
Overall Steps per Second: 7,655.30984

Timestep Collection Time: 5.67449
Timestep Consumption Time: 0.85980
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.53429

Cumulative Model Updates: 21,331
Cumulative Timesteps: 355,863,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.17502
Policy Entropy: 1.06094
Value Function Loss: 3.02528

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.05458

Collected Steps per Second: 8,858.45322
Overall Steps per Second: 7,786.20717

Timestep Collection Time: 5.64636
Timestep Consumption Time: 0.77757
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.42392

Cumulative Model Updates: 21,334
Cumulative Timesteps: 355,913,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 355913718...
Checkpoint 355913718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.67686
Policy Entropy: 1.05965
Value Function Loss: 3.16234

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.05163

Collected Steps per Second: 8,719.06398
Overall Steps per Second: 7,490.74046

Timestep Collection Time: 5.73731
Timestep Consumption Time: 0.94080
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.67811

Cumulative Model Updates: 21,337
Cumulative Timesteps: 355,963,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.54423
Policy Entropy: 1.05852
Value Function Loss: 3.02027

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.04432

Collected Steps per Second: 8,908.66217
Overall Steps per Second: 7,708.92882

Timestep Collection Time: 5.61521
Timestep Consumption Time: 0.87389
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.48910

Cumulative Model Updates: 21,340
Cumulative Timesteps: 356,013,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 356013766...
Checkpoint 356013766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.20543
Policy Entropy: 1.05971
Value Function Loss: 2.76597

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.06821
Value Function Update Magnitude: 0.05464

Collected Steps per Second: 8,761.23733
Overall Steps per Second: 7,463.29470

Timestep Collection Time: 5.70970
Timestep Consumption Time: 0.99297
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.70267

Cumulative Model Updates: 21,343
Cumulative Timesteps: 356,063,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.92316
Policy Entropy: 1.06549
Value Function Loss: 2.73188

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.06600

Collected Steps per Second: 8,895.40475
Overall Steps per Second: 7,707.58424

Timestep Collection Time: 5.62088
Timestep Consumption Time: 0.86624
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.48712

Cumulative Model Updates: 21,346
Cumulative Timesteps: 356,113,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 356113790...
Checkpoint 356113790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.61438
Policy Entropy: 1.05581
Value Function Loss: 2.79003

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06354

Collected Steps per Second: 9,055.47674
Overall Steps per Second: 7,942.52525

Timestep Collection Time: 5.52461
Timestep Consumption Time: 0.77414
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.29875

Cumulative Model Updates: 21,349
Cumulative Timesteps: 356,163,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.56483
Policy Entropy: 1.06550
Value Function Loss: 2.85934

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.05798

Collected Steps per Second: 8,881.43631
Overall Steps per Second: 7,711.39735

Timestep Collection Time: 5.63062
Timestep Consumption Time: 0.85433
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.48495

Cumulative Model Updates: 21,352
Cumulative Timesteps: 356,213,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 356213826...
Checkpoint 356213826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.78762
Policy Entropy: 1.07145
Value Function Loss: 2.88066

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.18633
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.04912

Collected Steps per Second: 9,197.72374
Overall Steps per Second: 8,040.84672

Timestep Collection Time: 5.43895
Timestep Consumption Time: 0.78253
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.22148

Cumulative Model Updates: 21,355
Cumulative Timesteps: 356,263,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.30787
Policy Entropy: 1.05045
Value Function Loss: 2.90378

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.18680
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.04387

Collected Steps per Second: 9,172.10667
Overall Steps per Second: 7,806.29961

Timestep Collection Time: 5.45153
Timestep Consumption Time: 0.95381
PPO Batch Consumption Time: 0.05285
Total Iteration Time: 6.40534

Cumulative Model Updates: 21,358
Cumulative Timesteps: 356,313,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 356313854...
Checkpoint 356313854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.55884
Policy Entropy: 1.07694
Value Function Loss: 2.98868

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.19471
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.04220

Collected Steps per Second: 9,133.30976
Overall Steps per Second: 7,897.52771

Timestep Collection Time: 5.47534
Timestep Consumption Time: 0.85677
PPO Batch Consumption Time: 0.04580
Total Iteration Time: 6.33211

Cumulative Model Updates: 21,361
Cumulative Timesteps: 356,363,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.24964
Policy Entropy: 1.07769
Value Function Loss: 3.20313

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.04324

Collected Steps per Second: 8,643.88047
Overall Steps per Second: 7,641.31436

Timestep Collection Time: 5.78629
Timestep Consumption Time: 0.75918
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.54547

Cumulative Model Updates: 21,364
Cumulative Timesteps: 356,413,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 356413878...
Checkpoint 356413878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.39125
Policy Entropy: 1.05599
Value Function Loss: 3.09128

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.16215
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 8,461.03221
Overall Steps per Second: 7,389.84664

Timestep Collection Time: 5.91015
Timestep Consumption Time: 0.85670
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.76685

Cumulative Model Updates: 21,367
Cumulative Timesteps: 356,463,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.00428
Policy Entropy: 1.04580
Value Function Loss: 3.06753

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.17747
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 8,945.53864
Overall Steps per Second: 7,770.68445

Timestep Collection Time: 5.59072
Timestep Consumption Time: 0.84526
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 6.43598

Cumulative Model Updates: 21,370
Cumulative Timesteps: 356,513,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 356513896...
Checkpoint 356513896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.91289
Policy Entropy: 1.06556
Value Function Loss: 3.01510

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.03593

Collected Steps per Second: 8,881.12243
Overall Steps per Second: 7,716.42266

Timestep Collection Time: 5.63059
Timestep Consumption Time: 0.84987
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.48046

Cumulative Model Updates: 21,373
Cumulative Timesteps: 356,563,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.22386
Policy Entropy: 1.08049
Value Function Loss: 3.00284

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.03326

Collected Steps per Second: 8,699.62699
Overall Steps per Second: 7,620.74684

Timestep Collection Time: 5.74990
Timestep Consumption Time: 0.81402
PPO Batch Consumption Time: 0.04070
Total Iteration Time: 6.56392

Cumulative Model Updates: 21,376
Cumulative Timesteps: 356,613,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 356613924...
Checkpoint 356613924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.69730
Policy Entropy: 1.06380
Value Function Loss: 2.94202

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 8,619.43023
Overall Steps per Second: 7,618.64802

Timestep Collection Time: 5.80247
Timestep Consumption Time: 0.76221
PPO Batch Consumption Time: 0.04999
Total Iteration Time: 6.56468

Cumulative Model Updates: 21,379
Cumulative Timesteps: 356,663,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.20556
Policy Entropy: 1.05343
Value Function Loss: 2.86543

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.19895
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.02964

Collected Steps per Second: 8,702.32890
Overall Steps per Second: 7,643.66435

Timestep Collection Time: 5.74559
Timestep Consumption Time: 0.79578
PPO Batch Consumption Time: 0.03947
Total Iteration Time: 6.54137

Cumulative Model Updates: 21,382
Cumulative Timesteps: 356,713,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 356713938...
Checkpoint 356713938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.39513
Policy Entropy: 1.06484
Value Function Loss: 2.97646

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.03123

Collected Steps per Second: 8,836.14363
Overall Steps per Second: 7,837.24628

Timestep Collection Time: 5.66016
Timestep Consumption Time: 0.72142
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.38158

Cumulative Model Updates: 21,385
Cumulative Timesteps: 356,763,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.91548
Policy Entropy: 1.06651
Value Function Loss: 2.92938

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.17011
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.02768

Collected Steps per Second: 8,821.30089
Overall Steps per Second: 7,679.90186

Timestep Collection Time: 5.66969
Timestep Consumption Time: 0.84264
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.51232

Cumulative Model Updates: 21,388
Cumulative Timesteps: 356,813,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 356813966...
Checkpoint 356813966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.97656
Policy Entropy: 1.06080
Value Function Loss: 2.88015

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.03230

Collected Steps per Second: 8,890.98131
Overall Steps per Second: 7,665.43327

Timestep Collection Time: 5.62368
Timestep Consumption Time: 0.89911
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 6.52279

Cumulative Model Updates: 21,391
Cumulative Timesteps: 356,863,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.66184
Policy Entropy: 1.04827
Value Function Loss: 2.85326

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.20359
Policy Update Magnitude: 0.04382
Value Function Update Magnitude: 0.02930

Collected Steps per Second: 8,482.66812
Overall Steps per Second: 7,507.14304

Timestep Collection Time: 5.89555
Timestep Consumption Time: 0.76610
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.66166

Cumulative Model Updates: 21,394
Cumulative Timesteps: 356,913,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 356913976...
Checkpoint 356913976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.01098
Policy Entropy: 1.07527
Value Function Loss: 2.82068

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.21909
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.03252

Collected Steps per Second: 8,713.99905
Overall Steps per Second: 7,576.74006

Timestep Collection Time: 5.73973
Timestep Consumption Time: 0.86153
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 6.60126

Cumulative Model Updates: 21,397
Cumulative Timesteps: 356,963,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.85521
Policy Entropy: 1.05361
Value Function Loss: 2.93379

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.03240

Collected Steps per Second: 8,849.84760
Overall Steps per Second: 7,708.28419

Timestep Collection Time: 5.65298
Timestep Consumption Time: 0.83718
PPO Batch Consumption Time: 0.04788
Total Iteration Time: 6.49016

Cumulative Model Updates: 21,400
Cumulative Timesteps: 357,014,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 357014020...
Checkpoint 357014020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.28127
Policy Entropy: 1.04281
Value Function Loss: 3.11819

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.16133
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.03106

Collected Steps per Second: 8,981.88035
Overall Steps per Second: 7,822.77300

Timestep Collection Time: 5.56743
Timestep Consumption Time: 0.82493
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.39236

Cumulative Model Updates: 21,403
Cumulative Timesteps: 357,064,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.14604
Policy Entropy: 1.06408
Value Function Loss: 3.04954

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.18438
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.02490

Collected Steps per Second: 8,826.16693
Overall Steps per Second: 7,669.58578

Timestep Collection Time: 5.66497
Timestep Consumption Time: 0.85428
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 6.51926

Cumulative Model Updates: 21,406
Cumulative Timesteps: 357,114,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 357114026...
Checkpoint 357114026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.90570
Policy Entropy: 1.06352
Value Function Loss: 2.98099

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.17373
Policy Update Magnitude: 0.03955
Value Function Update Magnitude: 0.02423

Collected Steps per Second: 8,862.41197
Overall Steps per Second: 7,787.13972

Timestep Collection Time: 5.64248
Timestep Consumption Time: 0.77913
PPO Batch Consumption Time: 0.05294
Total Iteration Time: 6.42161

Cumulative Model Updates: 21,409
Cumulative Timesteps: 357,164,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.98206
Policy Entropy: 1.05263
Value Function Loss: 2.79238

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.02172

Collected Steps per Second: 9,183.67819
Overall Steps per Second: 7,938.61931

Timestep Collection Time: 5.44488
Timestep Consumption Time: 0.85395
PPO Batch Consumption Time: 0.04862
Total Iteration Time: 6.29883

Cumulative Model Updates: 21,412
Cumulative Timesteps: 357,214,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 357214036...
Checkpoint 357214036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.66041
Policy Entropy: 1.02989
Value Function Loss: 2.83341

Mean KL Divergence: 0.03346
SB3 Clip Fraction: 0.25789
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.02912

Collected Steps per Second: 9,057.74452
Overall Steps per Second: 7,773.18400

Timestep Collection Time: 5.52301
Timestep Consumption Time: 0.91271
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.43572

Cumulative Model Updates: 21,415
Cumulative Timesteps: 357,264,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.03241
Policy Entropy: 1.05043
Value Function Loss: 2.76139

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.02665

Collected Steps per Second: 9,127.95317
Overall Steps per Second: 7,907.90290

Timestep Collection Time: 5.48119
Timestep Consumption Time: 0.84565
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 6.32684

Cumulative Model Updates: 21,418
Cumulative Timesteps: 357,314,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 357314094...
Checkpoint 357314094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.88204
Policy Entropy: 1.04925
Value Function Loss: 2.71944

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.02116

Collected Steps per Second: 8,605.89612
Overall Steps per Second: 7,451.22983

Timestep Collection Time: 5.81043
Timestep Consumption Time: 0.90040
PPO Batch Consumption Time: 0.04444
Total Iteration Time: 6.71084

Cumulative Model Updates: 21,421
Cumulative Timesteps: 357,364,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.23245
Policy Entropy: 1.03160
Value Function Loss: 2.69420

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.02253

Collected Steps per Second: 8,948.01782
Overall Steps per Second: 7,823.01490

Timestep Collection Time: 5.59074
Timestep Consumption Time: 0.80399
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.39472

Cumulative Model Updates: 21,424
Cumulative Timesteps: 357,414,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357414124...
Checkpoint 357414124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.29218
Policy Entropy: 1.03461
Value Function Loss: 2.79254

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.17200
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.02122

Collected Steps per Second: 8,659.55843
Overall Steps per Second: 7,551.49279

Timestep Collection Time: 5.77489
Timestep Consumption Time: 0.84738
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 6.62227

Cumulative Model Updates: 21,427
Cumulative Timesteps: 357,464,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.14987
Policy Entropy: 1.04901
Value Function Loss: 2.96440

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.02881

Collected Steps per Second: 9,000.23081
Overall Steps per Second: 7,769.77498

Timestep Collection Time: 5.55830
Timestep Consumption Time: 0.88024
PPO Batch Consumption Time: 0.04713
Total Iteration Time: 6.43854

Cumulative Model Updates: 21,430
Cumulative Timesteps: 357,514,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357514158...
Checkpoint 357514158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.50756
Policy Entropy: 1.05619
Value Function Loss: 3.07626

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.02924

Collected Steps per Second: 9,045.71814
Overall Steps per Second: 7,837.85808

Timestep Collection Time: 5.53035
Timestep Consumption Time: 0.85226
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 6.38261

Cumulative Model Updates: 21,433
Cumulative Timesteps: 357,564,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.26107
Policy Entropy: 1.05089
Value Function Loss: 2.92104

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.17188
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.02533

Collected Steps per Second: 8,664.65816
Overall Steps per Second: 7,585.17542

Timestep Collection Time: 5.77357
Timestep Consumption Time: 0.82166
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.59523

Cumulative Model Updates: 21,436
Cumulative Timesteps: 357,614,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357614210...
Checkpoint 357614210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.46338
Policy Entropy: 1.03424
Value Function Loss: 2.93971

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.20559
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.02411

Collected Steps per Second: 8,900.02563
Overall Steps per Second: 7,705.96873

Timestep Collection Time: 5.61976
Timestep Consumption Time: 0.87079
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.49055

Cumulative Model Updates: 21,439
Cumulative Timesteps: 357,664,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.71875
Policy Entropy: 1.04280
Value Function Loss: 2.98196

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.03926
Value Function Update Magnitude: 0.02086

Collected Steps per Second: 8,802.76052
Overall Steps per Second: 7,664.50394

Timestep Collection Time: 5.68322
Timestep Consumption Time: 0.84402
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 6.52723

Cumulative Model Updates: 21,442
Cumulative Timesteps: 357,714,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 357714254...
Checkpoint 357714254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.80058
Policy Entropy: 1.04786
Value Function Loss: 3.03025

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.15568
Policy Update Magnitude: 0.03729
Value Function Update Magnitude: 0.02781

Collected Steps per Second: 8,893.25017
Overall Steps per Second: 7,848.16844

Timestep Collection Time: 5.62404
Timestep Consumption Time: 0.74891
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.37295

Cumulative Model Updates: 21,445
Cumulative Timesteps: 357,764,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.91452
Policy Entropy: 1.00118
Value Function Loss: 2.81300

Mean KL Divergence: 0.06948
SB3 Clip Fraction: 0.34525
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.02454

Collected Steps per Second: 8,653.24162
Overall Steps per Second: 7,495.17107

Timestep Collection Time: 5.78049
Timestep Consumption Time: 0.89314
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.67363

Cumulative Model Updates: 21,448
Cumulative Timesteps: 357,814,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 357814290...
Checkpoint 357814290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.22934
Policy Entropy: 1.04763
Value Function Loss: 2.88058

Mean KL Divergence: 0.04078
SB3 Clip Fraction: 0.29239
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.02364

Collected Steps per Second: 9,011.31981
Overall Steps per Second: 7,835.46912

Timestep Collection Time: 5.55013
Timestep Consumption Time: 0.83290
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.38303

Cumulative Model Updates: 21,451
Cumulative Timesteps: 357,864,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.20396
Policy Entropy: 1.01219
Value Function Loss: 3.00501

Mean KL Divergence: 0.05920
SB3 Clip Fraction: 0.31629
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.03018

Collected Steps per Second: 8,859.69758
Overall Steps per Second: 7,657.59626

Timestep Collection Time: 5.64579
Timestep Consumption Time: 0.88629
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.53208

Cumulative Model Updates: 21,454
Cumulative Timesteps: 357,914,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 357914324...
Checkpoint 357914324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.75669
Policy Entropy: 1.05819
Value Function Loss: 3.03819

Mean KL Divergence: 0.04500
SB3 Clip Fraction: 0.30387
Policy Update Magnitude: 0.03319
Value Function Update Magnitude: 0.02941

Collected Steps per Second: 8,826.37117
Overall Steps per Second: 7,646.58431

Timestep Collection Time: 5.66530
Timestep Consumption Time: 0.87410
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.53939

Cumulative Model Updates: 21,457
Cumulative Timesteps: 357,964,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.02776
Policy Entropy: 1.03869
Value Function Loss: 2.94990

Mean KL Divergence: 0.04711
SB3 Clip Fraction: 0.29787
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.03549

Collected Steps per Second: 9,421.24030
Overall Steps per Second: 8,139.51409

Timestep Collection Time: 5.30949
Timestep Consumption Time: 0.83608
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 6.14558

Cumulative Model Updates: 21,460
Cumulative Timesteps: 358,014,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 358014350...
Checkpoint 358014350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.75482
Policy Entropy: 1.06905
Value Function Loss: 2.92145

Mean KL Divergence: 0.04179
SB3 Clip Fraction: 0.28638
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.03818

Collected Steps per Second: 9,032.08297
Overall Steps per Second: 7,792.31437

Timestep Collection Time: 5.53582
Timestep Consumption Time: 0.88076
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 6.41658

Cumulative Model Updates: 21,463
Cumulative Timesteps: 358,064,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.67760
Policy Entropy: 1.03899
Value Function Loss: 2.96499

Mean KL Divergence: 0.04323
SB3 Clip Fraction: 0.27839
Policy Update Magnitude: 0.03222
Value Function Update Magnitude: 0.03054

Collected Steps per Second: 9,282.96063
Overall Steps per Second: 8,014.05304

Timestep Collection Time: 5.38686
Timestep Consumption Time: 0.85293
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.23979

Cumulative Model Updates: 21,466
Cumulative Timesteps: 358,114,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 358114356...
Checkpoint 358114356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.60536
Policy Entropy: 1.06455
Value Function Loss: 2.90496

Mean KL Divergence: 0.03645
SB3 Clip Fraction: 0.24962
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.03215

Collected Steps per Second: 8,983.68208
Overall Steps per Second: 7,891.61534

Timestep Collection Time: 5.56787
Timestep Consumption Time: 0.77050
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.33837

Cumulative Model Updates: 21,469
Cumulative Timesteps: 358,164,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.59585
Policy Entropy: 1.02936
Value Function Loss: 2.97515

Mean KL Divergence: 0.05080
SB3 Clip Fraction: 0.34261
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.03042

Collected Steps per Second: 9,246.39258
Overall Steps per Second: 7,976.54067

Timestep Collection Time: 5.41054
Timestep Consumption Time: 0.86135
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.27189

Cumulative Model Updates: 21,472
Cumulative Timesteps: 358,214,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 358214404...
Checkpoint 358214404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.48877
Policy Entropy: 1.06136
Value Function Loss: 2.80518

Mean KL Divergence: 0.04442
SB3 Clip Fraction: 0.30025
Policy Update Magnitude: 0.03494
Value Function Update Magnitude: 0.02748

Collected Steps per Second: 9,034.95347
Overall Steps per Second: 7,907.10444

Timestep Collection Time: 5.53650
Timestep Consumption Time: 0.78971
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.32621

Cumulative Model Updates: 21,475
Cumulative Timesteps: 358,264,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.80712
Policy Entropy: 1.02209
Value Function Loss: 2.88179

Mean KL Divergence: 0.05354
SB3 Clip Fraction: 0.33607
Policy Update Magnitude: 0.03267
Value Function Update Magnitude: 0.02885

Collected Steps per Second: 8,641.87359
Overall Steps per Second: 7,494.48739

Timestep Collection Time: 5.78810
Timestep Consumption Time: 0.88614
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.67424

Cumulative Model Updates: 21,478
Cumulative Timesteps: 358,314,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 358314446...
Checkpoint 358314446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.90547
Policy Entropy: 1.05094
Value Function Loss: 2.88239

Mean KL Divergence: 0.03790
SB3 Clip Fraction: 0.26609
Policy Update Magnitude: 0.02878
Value Function Update Magnitude: 0.02526

Collected Steps per Second: 8,640.12013
Overall Steps per Second: 7,528.32537

Timestep Collection Time: 5.78881
Timestep Consumption Time: 0.85490
PPO Batch Consumption Time: 0.04712
Total Iteration Time: 6.64371

Cumulative Model Updates: 21,481
Cumulative Timesteps: 358,364,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.91773
Policy Entropy: 1.02442
Value Function Loss: 2.96066

Mean KL Divergence: 0.04985
SB3 Clip Fraction: 0.31024
Policy Update Magnitude: 0.03051
Value Function Update Magnitude: 0.03140

Collected Steps per Second: 8,600.24763
Overall Steps per Second: 7,619.56989

Timestep Collection Time: 5.81611
Timestep Consumption Time: 0.74856
PPO Batch Consumption Time: 0.04661
Total Iteration Time: 6.56467

Cumulative Model Updates: 21,484
Cumulative Timesteps: 358,414,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 358414482...
Checkpoint 358414482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.93128
Policy Entropy: 1.04844
Value Function Loss: 2.73551

Mean KL Divergence: 0.03209
SB3 Clip Fraction: 0.25828
Policy Update Magnitude: 0.03124
Value Function Update Magnitude: 0.03016

Collected Steps per Second: 9,110.83980
Overall Steps per Second: 7,889.64688

Timestep Collection Time: 5.49148
Timestep Consumption Time: 0.84999
PPO Batch Consumption Time: 0.04374
Total Iteration Time: 6.34148

Cumulative Model Updates: 21,487
Cumulative Timesteps: 358,464,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.43006
Policy Entropy: 1.01843
Value Function Loss: 2.61327

Mean KL Divergence: 0.03306
SB3 Clip Fraction: 0.23222
Policy Update Magnitude: 0.03865
Value Function Update Magnitude: 0.02986

Collected Steps per Second: 8,542.34546
Overall Steps per Second: 7,506.63323

Timestep Collection Time: 5.85413
Timestep Consumption Time: 0.80771
PPO Batch Consumption Time: 0.04335
Total Iteration Time: 6.66184

Cumulative Model Updates: 21,490
Cumulative Timesteps: 358,514,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 358514522...
Checkpoint 358514522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.32699
Policy Entropy: 1.04091
Value Function Loss: 2.72290

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.22178
Policy Update Magnitude: 0.04013
Value Function Update Magnitude: 0.03270

Collected Steps per Second: 8,964.30780
Overall Steps per Second: 7,781.14272

Timestep Collection Time: 5.57768
Timestep Consumption Time: 0.84812
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.42579

Cumulative Model Updates: 21,493
Cumulative Timesteps: 358,564,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.64231
Policy Entropy: 1.03005
Value Function Loss: 2.68572

Mean KL Divergence: 0.02814
SB3 Clip Fraction: 0.17273
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.02911

Collected Steps per Second: 8,969.98739
Overall Steps per Second: 7,814.44918

Timestep Collection Time: 5.57704
Timestep Consumption Time: 0.82469
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 6.40173

Cumulative Model Updates: 21,496
Cumulative Timesteps: 358,614,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 358614548...
Checkpoint 358614548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.63442
Policy Entropy: 1.02712
Value Function Loss: 2.77792

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.02367

Collected Steps per Second: 9,009.36724
Overall Steps per Second: 7,927.86021

Timestep Collection Time: 5.55289
Timestep Consumption Time: 0.75752
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.31040

Cumulative Model Updates: 21,499
Cumulative Timesteps: 358,664,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.06687
Policy Entropy: 1.01970
Value Function Loss: 2.77184

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.19998
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.02357

Collected Steps per Second: 8,631.97934
Overall Steps per Second: 7,513.34482

Timestep Collection Time: 5.79473
Timestep Consumption Time: 0.86276
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.65749

Cumulative Model Updates: 21,502
Cumulative Timesteps: 358,714,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 358714596...
Checkpoint 358714596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.25393
Policy Entropy: 1.03861
Value Function Loss: 2.92687

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.17201
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.02739

Collected Steps per Second: 8,587.20889
Overall Steps per Second: 7,477.10123

Timestep Collection Time: 5.82355
Timestep Consumption Time: 0.86461
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.68815

Cumulative Model Updates: 21,505
Cumulative Timesteps: 358,764,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.78265
Policy Entropy: 1.04631
Value Function Loss: 2.83366

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17569
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.02986

Collected Steps per Second: 9,016.41023
Overall Steps per Second: 7,872.69689

Timestep Collection Time: 5.54766
Timestep Consumption Time: 0.80594
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.35360

Cumulative Model Updates: 21,508
Cumulative Timesteps: 358,814,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 358814624...
Checkpoint 358814624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.10309
Policy Entropy: 1.03360
Value Function Loss: 2.82030

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.02770

Collected Steps per Second: 8,777.73051
Overall Steps per Second: 7,683.21368

Timestep Collection Time: 5.69806
Timestep Consumption Time: 0.81172
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 6.50978

Cumulative Model Updates: 21,511
Cumulative Timesteps: 358,864,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.98735
Policy Entropy: 1.01608
Value Function Loss: 2.68546

Mean KL Divergence: 0.03215
SB3 Clip Fraction: 0.22790
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.02637

Collected Steps per Second: 9,003.08965
Overall Steps per Second: 7,952.45296

Timestep Collection Time: 5.55454
Timestep Consumption Time: 0.73384
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 6.28837

Cumulative Model Updates: 21,514
Cumulative Timesteps: 358,914,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 358914648...
Checkpoint 358914648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.46003
Policy Entropy: 1.02449
Value Function Loss: 2.78633

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.02920

Collected Steps per Second: 8,878.39154
Overall Steps per Second: 7,683.58146

Timestep Collection Time: 5.63368
Timestep Consumption Time: 0.87605
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.50972

Cumulative Model Updates: 21,517
Cumulative Timesteps: 358,964,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.53245
Policy Entropy: 1.02172
Value Function Loss: 2.69465

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.02587

Collected Steps per Second: 8,969.35559
Overall Steps per Second: 7,671.75396

Timestep Collection Time: 5.57677
Timestep Consumption Time: 0.94326
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.52002

Cumulative Model Updates: 21,520
Cumulative Timesteps: 359,014,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 359014686...
Checkpoint 359014686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.00768
Policy Entropy: 1.01769
Value Function Loss: 2.65395

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.16800
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.02879

Collected Steps per Second: 9,088.97475
Overall Steps per Second: 7,905.13634

Timestep Collection Time: 5.50293
Timestep Consumption Time: 0.82409
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 6.32703

Cumulative Model Updates: 21,523
Cumulative Timesteps: 359,064,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.93295
Policy Entropy: 1.01671
Value Function Loss: 2.60777

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.18801
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.02944

Collected Steps per Second: 8,851.94950
Overall Steps per Second: 7,724.62261

Timestep Collection Time: 5.65164
Timestep Consumption Time: 0.82480
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.47643

Cumulative Model Updates: 21,526
Cumulative Timesteps: 359,114,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 359114730...
Checkpoint 359114730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.56085
Policy Entropy: 1.02485
Value Function Loss: 2.59510

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.02563

Collected Steps per Second: 8,769.88129
Overall Steps per Second: 7,751.63682

Timestep Collection Time: 5.70156
Timestep Consumption Time: 0.74895
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 6.45051

Cumulative Model Updates: 21,529
Cumulative Timesteps: 359,164,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.25764
Policy Entropy: 1.02606
Value Function Loss: 2.68547

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.03025

Collected Steps per Second: 8,625.92687
Overall Steps per Second: 7,447.31892

Timestep Collection Time: 5.79671
Timestep Consumption Time: 0.91738
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.71409

Cumulative Model Updates: 21,532
Cumulative Timesteps: 359,214,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 359214734...
Checkpoint 359214734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.65724
Policy Entropy: 1.03333
Value Function Loss: 2.77703

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 8,919.41760
Overall Steps per Second: 7,782.65909

Timestep Collection Time: 5.60821
Timestep Consumption Time: 0.81915
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 6.42737

Cumulative Model Updates: 21,535
Cumulative Timesteps: 359,264,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.06107
Policy Entropy: 1.02932
Value Function Loss: 2.90433

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.02505

Collected Steps per Second: 8,637.02257
Overall Steps per Second: 7,589.28346

Timestep Collection Time: 5.79019
Timestep Consumption Time: 0.79937
PPO Batch Consumption Time: 0.04870
Total Iteration Time: 6.58955

Cumulative Model Updates: 21,538
Cumulative Timesteps: 359,314,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 359314766...
Checkpoint 359314766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.11582
Policy Entropy: 1.05099
Value Function Loss: 3.11235

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.02461

Collected Steps per Second: 8,978.93461
Overall Steps per Second: 7,807.09101

Timestep Collection Time: 5.57171
Timestep Consumption Time: 0.83631
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 6.40802

Cumulative Model Updates: 21,541
Cumulative Timesteps: 359,364,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.41264
Policy Entropy: 1.05259
Value Function Loss: 2.97120

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.18169
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 8,732.14922
Overall Steps per Second: 7,617.13832

Timestep Collection Time: 5.72894
Timestep Consumption Time: 0.83861
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.56756

Cumulative Model Updates: 21,544
Cumulative Timesteps: 359,414,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 359414820...
Checkpoint 359414820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.14861
Policy Entropy: 1.04757
Value Function Loss: 2.85634

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.17121
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.03383

Collected Steps per Second: 8,881.72617
Overall Steps per Second: 7,704.42254

Timestep Collection Time: 5.63089
Timestep Consumption Time: 0.86045
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.49134

Cumulative Model Updates: 21,547
Cumulative Timesteps: 359,464,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.57300
Policy Entropy: 1.04905
Value Function Loss: 2.70866

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.03477

Collected Steps per Second: 8,768.88298
Overall Steps per Second: 7,619.05400

Timestep Collection Time: 5.70449
Timestep Consumption Time: 0.86089
PPO Batch Consumption Time: 0.04774
Total Iteration Time: 6.56538

Cumulative Model Updates: 21,550
Cumulative Timesteps: 359,514,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 359514854...
Checkpoint 359514854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.33938
Policy Entropy: 1.04786
Value Function Loss: 2.72130

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.03757

Collected Steps per Second: 9,051.37762
Overall Steps per Second: 7,931.78487

Timestep Collection Time: 5.52623
Timestep Consumption Time: 0.78004
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.30627

Cumulative Model Updates: 21,553
Cumulative Timesteps: 359,564,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.62311
Policy Entropy: 1.05151
Value Function Loss: 2.68214

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.03967

Collected Steps per Second: 8,846.13952
Overall Steps per Second: 7,628.40189

Timestep Collection Time: 5.65512
Timestep Consumption Time: 0.90274
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.55786

Cumulative Model Updates: 21,556
Cumulative Timesteps: 359,614,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 359614900...
Checkpoint 359614900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.65628
Policy Entropy: 1.05936
Value Function Loss: 2.82618

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 8,426.18308
Overall Steps per Second: 7,328.31356

Timestep Collection Time: 5.93460
Timestep Consumption Time: 0.88907
PPO Batch Consumption Time: 0.04868
Total Iteration Time: 6.82367

Cumulative Model Updates: 21,559
Cumulative Timesteps: 359,664,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.58029
Policy Entropy: 1.06280
Value Function Loss: 2.74611

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.03490

Collected Steps per Second: 9,033.40083
Overall Steps per Second: 7,782.07768

Timestep Collection Time: 5.53767
Timestep Consumption Time: 0.89043
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.42810

Cumulative Model Updates: 21,562
Cumulative Timesteps: 359,714,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 359714930...
Checkpoint 359714930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.51924
Policy Entropy: 1.04430
Value Function Loss: 2.75335

Mean KL Divergence: 0.02670
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.03626

Collected Steps per Second: 8,649.25707
Overall Steps per Second: 7,477.35942

Timestep Collection Time: 5.78408
Timestep Consumption Time: 0.90652
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.69060

Cumulative Model Updates: 21,565
Cumulative Timesteps: 359,764,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.45525
Policy Entropy: 1.05918
Value Function Loss: 2.81900

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.03389

Collected Steps per Second: 8,850.05441
Overall Steps per Second: 7,790.78876

Timestep Collection Time: 5.65285
Timestep Consumption Time: 0.76858
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 6.42143

Cumulative Model Updates: 21,568
Cumulative Timesteps: 359,814,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 359814986...
Checkpoint 359814986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.12375
Policy Entropy: 1.06530
Value Function Loss: 2.65147

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.02900

Collected Steps per Second: 9,035.22090
Overall Steps per Second: 7,767.33745

Timestep Collection Time: 5.53545
Timestep Consumption Time: 0.90357
PPO Batch Consumption Time: 0.04913
Total Iteration Time: 6.43901

Cumulative Model Updates: 21,571
Cumulative Timesteps: 359,865,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.65731
Policy Entropy: 1.04258
Value Function Loss: 2.53072

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.20248
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.03026

Collected Steps per Second: 9,028.78982
Overall Steps per Second: 7,818.77441

Timestep Collection Time: 5.53895
Timestep Consumption Time: 0.85719
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.39614

Cumulative Model Updates: 21,574
Cumulative Timesteps: 359,915,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 359915010...
Checkpoint 359915010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.32069
Policy Entropy: 1.05615
Value Function Loss: 2.36577

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.18063
Policy Update Magnitude: 0.04053
Value Function Update Magnitude: 0.03701

Collected Steps per Second: 9,184.94716
Overall Steps per Second: 8,063.73710

Timestep Collection Time: 5.44391
Timestep Consumption Time: 0.75694
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.20085

Cumulative Model Updates: 21,577
Cumulative Timesteps: 359,965,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.48657
Policy Entropy: 1.05680
Value Function Loss: 2.51884

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.17151
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.04469

Collected Steps per Second: 9,090.22947
Overall Steps per Second: 7,854.43828

Timestep Collection Time: 5.50305
Timestep Consumption Time: 0.86583
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.36888

Cumulative Model Updates: 21,580
Cumulative Timesteps: 360,015,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 360015036...
Checkpoint 360015036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.06081
Policy Entropy: 1.07052
Value Function Loss: 2.81446

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.18510
Policy Update Magnitude: 0.03777
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 9,072.98436
Overall Steps per Second: 7,951.01208

Timestep Collection Time: 5.51351
Timestep Consumption Time: 0.77801
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.29153

Cumulative Model Updates: 21,583
Cumulative Timesteps: 360,065,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.46920
Policy Entropy: 1.03085
Value Function Loss: 2.99156

Mean KL Divergence: 0.04542
SB3 Clip Fraction: 0.28921
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.03656

Collected Steps per Second: 8,783.86352
Overall Steps per Second: 7,487.14197

Timestep Collection Time: 5.69271
Timestep Consumption Time: 0.98594
PPO Batch Consumption Time: 0.04589
Total Iteration Time: 6.67865

Cumulative Model Updates: 21,586
Cumulative Timesteps: 360,115,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 360115064...
Checkpoint 360115064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.73311
Policy Entropy: 1.07050
Value Function Loss: 2.76207

Mean KL Divergence: 0.03001
SB3 Clip Fraction: 0.25242
Policy Update Magnitude: 0.04046
Value Function Update Magnitude: 0.03305

Collected Steps per Second: 8,812.08391
Overall Steps per Second: 7,650.20107

Timestep Collection Time: 5.67675
Timestep Consumption Time: 0.86216
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 6.53891

Cumulative Model Updates: 21,589
Cumulative Timesteps: 360,165,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.31032
Policy Entropy: 1.02026
Value Function Loss: 2.62235

Mean KL Divergence: 0.07650
SB3 Clip Fraction: 0.37805
Policy Update Magnitude: 0.03708
Value Function Update Magnitude: 0.03716

Collected Steps per Second: 8,860.60876
Overall Steps per Second: 7,654.78016

Timestep Collection Time: 5.64498
Timestep Consumption Time: 0.88923
PPO Batch Consumption Time: 0.05070
Total Iteration Time: 6.53422

Cumulative Model Updates: 21,592
Cumulative Timesteps: 360,215,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 360215106...
Checkpoint 360215106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.42423
Policy Entropy: 1.05517
Value Function Loss: 2.52689

Mean KL Divergence: 0.04570
SB3 Clip Fraction: 0.30089
Policy Update Magnitude: 0.03281
Value Function Update Magnitude: 0.04306

Collected Steps per Second: 8,881.91454
Overall Steps per Second: 7,722.34296

Timestep Collection Time: 5.62964
Timestep Consumption Time: 0.84534
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.47498

Cumulative Model Updates: 21,595
Cumulative Timesteps: 360,265,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.11588
Policy Entropy: 1.02375
Value Function Loss: 2.39331

Mean KL Divergence: 0.05719
SB3 Clip Fraction: 0.32706
Policy Update Magnitude: 0.03180
Value Function Update Magnitude: 0.05967

Collected Steps per Second: 8,937.62818
Overall Steps per Second: 7,874.59907

Timestep Collection Time: 5.59567
Timestep Consumption Time: 0.75539
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.35105

Cumulative Model Updates: 21,598
Cumulative Timesteps: 360,315,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 360315120...
Checkpoint 360315120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.88881
Policy Entropy: 1.05120
Value Function Loss: 2.18896

Mean KL Divergence: 0.03865
SB3 Clip Fraction: 0.25454
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 8,413.49881
Overall Steps per Second: 7,367.94051

Timestep Collection Time: 5.94616
Timestep Consumption Time: 0.84380
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 6.78996

Cumulative Model Updates: 21,601
Cumulative Timesteps: 360,365,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.99805
Policy Entropy: 1.02674
Value Function Loss: 2.15086

Mean KL Divergence: 0.04078
SB3 Clip Fraction: 0.27408
Policy Update Magnitude: 0.03444
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 8,667.26777
Overall Steps per Second: 7,502.65625

Timestep Collection Time: 5.77206
Timestep Consumption Time: 0.89598
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.66804

Cumulative Model Updates: 21,604
Cumulative Timesteps: 360,415,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 360415176...
Checkpoint 360415176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.79444
Policy Entropy: 1.04314
Value Function Loss: 2.20089

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.20777
Policy Update Magnitude: 0.03217
Value Function Update Magnitude: 0.05860

Collected Steps per Second: 8,865.28170
Overall Steps per Second: 7,724.13103

Timestep Collection Time: 5.64178
Timestep Consumption Time: 0.83351
PPO Batch Consumption Time: 0.04780
Total Iteration Time: 6.47529

Cumulative Model Updates: 21,607
Cumulative Timesteps: 360,465,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.42600
Policy Entropy: 1.04170
Value Function Loss: 2.29772

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.04342
Value Function Update Magnitude: 0.05666

Collected Steps per Second: 8,829.23004
Overall Steps per Second: 7,706.52806

Timestep Collection Time: 5.66346
Timestep Consumption Time: 0.82506
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.48853

Cumulative Model Updates: 21,610
Cumulative Timesteps: 360,515,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 360515196...
Checkpoint 360515196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.69555
Policy Entropy: 1.01847
Value Function Loss: 2.46339

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.20119
Policy Update Magnitude: 0.03703
Value Function Update Magnitude: 0.04776

Collected Steps per Second: 8,764.91917
Overall Steps per Second: 7,738.68543

Timestep Collection Time: 5.70798
Timestep Consumption Time: 0.75694
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.46492

Cumulative Model Updates: 21,613
Cumulative Timesteps: 360,565,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.39829
Policy Entropy: 1.01704
Value Function Loss: 2.43215

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.18455
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.03929

Collected Steps per Second: 8,595.02816
Overall Steps per Second: 7,504.48171

Timestep Collection Time: 5.81732
Timestep Consumption Time: 0.84537
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.66269

Cumulative Model Updates: 21,616
Cumulative Timesteps: 360,615,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 360615226...
Checkpoint 360615226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.04475
Policy Entropy: 1.03610
Value Function Loss: 2.67006

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.03712
Value Function Update Magnitude: 0.03046

Collected Steps per Second: 8,649.48889
Overall Steps per Second: 7,470.98754

Timestep Collection Time: 5.78416
Timestep Consumption Time: 0.91241
PPO Batch Consumption Time: 0.05150
Total Iteration Time: 6.69657

Cumulative Model Updates: 21,619
Cumulative Timesteps: 360,665,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.61916
Policy Entropy: 1.04609
Value Function Loss: 2.64486

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.03442
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 8,701.74472
Overall Steps per Second: 7,562.82881

Timestep Collection Time: 5.74643
Timestep Consumption Time: 0.86538
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.61181

Cumulative Model Updates: 21,622
Cumulative Timesteps: 360,715,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 360715260...
Checkpoint 360715260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.98650
Policy Entropy: 1.02140
Value Function Loss: 2.71670

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.03028

Collected Steps per Second: 8,995.63197
Overall Steps per Second: 7,766.12519

Timestep Collection Time: 5.56137
Timestep Consumption Time: 0.88046
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 6.44182

Cumulative Model Updates: 21,625
Cumulative Timesteps: 360,765,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.73383
Policy Entropy: 1.04282
Value Function Loss: 2.71964

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.21320
Policy Update Magnitude: 0.04228
Value Function Update Magnitude: 0.02987

Collected Steps per Second: 8,535.66372
Overall Steps per Second: 7,576.51469

Timestep Collection Time: 5.86012
Timestep Consumption Time: 0.74186
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.60198

Cumulative Model Updates: 21,628
Cumulative Timesteps: 360,815,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 360815308...
Checkpoint 360815308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.90543
Policy Entropy: 1.03689
Value Function Loss: 2.68941

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.20998
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.03210

Collected Steps per Second: 9,021.66191
Overall Steps per Second: 7,813.56920

Timestep Collection Time: 5.54244
Timestep Consumption Time: 0.85694
PPO Batch Consumption Time: 0.05138
Total Iteration Time: 6.39938

Cumulative Model Updates: 21,631
Cumulative Timesteps: 360,865,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.12815
Policy Entropy: 1.04092
Value Function Loss: 2.67563

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.17813
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.03244

Collected Steps per Second: 8,912.38332
Overall Steps per Second: 7,778.98937

Timestep Collection Time: 5.61264
Timestep Consumption Time: 0.81776
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.43040

Cumulative Model Updates: 21,634
Cumulative Timesteps: 360,915,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 360915332...
Checkpoint 360915332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.64827
Policy Entropy: 1.03700
Value Function Loss: 2.58836

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.17085
Policy Update Magnitude: 0.03833
Value Function Update Magnitude: 0.03828

Collected Steps per Second: 8,927.31800
Overall Steps per Second: 7,856.77564

Timestep Collection Time: 5.60392
Timestep Consumption Time: 0.76357
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 6.36750

Cumulative Model Updates: 21,637
Cumulative Timesteps: 360,965,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.48863
Policy Entropy: 1.05573
Value Function Loss: 2.73899

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.05030

Collected Steps per Second: 8,947.59887
Overall Steps per Second: 7,793.71767

Timestep Collection Time: 5.59122
Timestep Consumption Time: 0.82780
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.41902

Cumulative Model Updates: 21,640
Cumulative Timesteps: 361,015,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 361015388...
Checkpoint 361015388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.72113
Policy Entropy: 1.07772
Value Function Loss: 3.00215

Mean KL Divergence: 0.03242
SB3 Clip Fraction: 0.29325
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 8,634.90620
Overall Steps per Second: 7,538.35657

Timestep Collection Time: 5.79230
Timestep Consumption Time: 0.84256
PPO Batch Consumption Time: 0.04001
Total Iteration Time: 6.63487

Cumulative Model Updates: 21,643
Cumulative Timesteps: 361,065,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.19801
Policy Entropy: 1.05970
Value Function Loss: 2.94663

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.18433
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 8,917.04898
Overall Steps per Second: 7,744.47320

Timestep Collection Time: 5.60970
Timestep Consumption Time: 0.84935
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.45906

Cumulative Model Updates: 21,646
Cumulative Timesteps: 361,115,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 361115426...
Checkpoint 361115426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.32660
Policy Entropy: 1.07734
Value Function Loss: 3.21061

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.19841
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05026

Collected Steps per Second: 8,665.02809
Overall Steps per Second: 7,536.96471

Timestep Collection Time: 5.77309
Timestep Consumption Time: 0.86406
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.63715

Cumulative Model Updates: 21,649
Cumulative Timesteps: 361,165,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.57455
Policy Entropy: 1.10317
Value Function Loss: 3.01180

Mean KL Divergence: 0.05142
SB3 Clip Fraction: 0.29830
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.04111

Collected Steps per Second: 8,983.11511
Overall Steps per Second: 7,894.09852

Timestep Collection Time: 5.56867
Timestep Consumption Time: 0.76822
PPO Batch Consumption Time: 0.03986
Total Iteration Time: 6.33689

Cumulative Model Updates: 21,652
Cumulative Timesteps: 361,215,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 361215474...
Checkpoint 361215474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.96136
Policy Entropy: 1.08964
Value Function Loss: 2.88396

Mean KL Divergence: 0.03192
SB3 Clip Fraction: 0.20006
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.03713

Collected Steps per Second: 8,610.06235
Overall Steps per Second: 7,477.57572

Timestep Collection Time: 5.81018
Timestep Consumption Time: 0.87996
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 6.69014

Cumulative Model Updates: 21,655
Cumulative Timesteps: 361,265,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.15145
Policy Entropy: 1.10809
Value Function Loss: 2.69233

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.18490
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.03831

Collected Steps per Second: 9,012.03361
Overall Steps per Second: 7,771.01689

Timestep Collection Time: 5.55058
Timestep Consumption Time: 0.88642
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.43700

Cumulative Model Updates: 21,658
Cumulative Timesteps: 361,315,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 361315522...
Checkpoint 361315522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.00490
Policy Entropy: 1.10517
Value Function Loss: 2.75249

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.03505

Collected Steps per Second: 8,626.53167
Overall Steps per Second: 7,648.91192

Timestep Collection Time: 5.79955
Timestep Consumption Time: 0.74125
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.54080

Cumulative Model Updates: 21,661
Cumulative Timesteps: 361,365,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.44686
Policy Entropy: 1.10604
Value Function Loss: 2.75486

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 9,068.46881
Overall Steps per Second: 7,785.00222

Timestep Collection Time: 5.51626
Timestep Consumption Time: 0.90943
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 6.42569

Cumulative Model Updates: 21,664
Cumulative Timesteps: 361,415,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 361415576...
Checkpoint 361415576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.07877
Policy Entropy: 1.11526
Value Function Loss: 2.69154

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 8,702.42973
Overall Steps per Second: 7,554.03100

Timestep Collection Time: 5.74851
Timestep Consumption Time: 0.87392
PPO Batch Consumption Time: 0.04814
Total Iteration Time: 6.62242

Cumulative Model Updates: 21,667
Cumulative Timesteps: 361,465,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.66651
Policy Entropy: 1.11847
Value Function Loss: 2.64231

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.04140

Collected Steps per Second: 8,825.69451
Overall Steps per Second: 7,611.04765

Timestep Collection Time: 5.66664
Timestep Consumption Time: 0.90434
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.57097

Cumulative Model Updates: 21,670
Cumulative Timesteps: 361,515,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 361515614...
Checkpoint 361515614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.62566
Policy Entropy: 1.12304
Value Function Loss: 2.73121

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.06655
Value Function Update Magnitude: 0.03779

Collected Steps per Second: 8,618.44729
Overall Steps per Second: 7,516.06663

Timestep Collection Time: 5.80476
Timestep Consumption Time: 0.85138
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.65614

Cumulative Model Updates: 21,673
Cumulative Timesteps: 361,565,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.67457
Policy Entropy: 1.11726
Value Function Loss: 2.81397

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 8,900.84970
Overall Steps per Second: 7,763.55904

Timestep Collection Time: 5.61946
Timestep Consumption Time: 0.82320
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.44266

Cumulative Model Updates: 21,676
Cumulative Timesteps: 361,615,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 361615660...
Checkpoint 361615660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.08997
Policy Entropy: 1.11641
Value Function Loss: 2.86678

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.05196

Collected Steps per Second: 8,883.92661
Overall Steps per Second: 7,684.17825

Timestep Collection Time: 5.62949
Timestep Consumption Time: 0.87895
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 6.50844

Cumulative Model Updates: 21,679
Cumulative Timesteps: 361,665,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.33884
Policy Entropy: 1.10419
Value Function Loss: 2.76754

Mean KL Divergence: 0.03177
SB3 Clip Fraction: 0.19977
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.04602

Collected Steps per Second: 8,896.18405
Overall Steps per Second: 7,525.12094

Timestep Collection Time: 5.62309
Timestep Consumption Time: 1.02452
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.64760

Cumulative Model Updates: 21,682
Cumulative Timesteps: 361,715,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 361715696...
Checkpoint 361715696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.17327
Policy Entropy: 1.11297
Value Function Loss: 2.67567

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.05178

Collected Steps per Second: 9,189.48996
Overall Steps per Second: 8,067.88649

Timestep Collection Time: 5.44383
Timestep Consumption Time: 0.75680
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.20063

Cumulative Model Updates: 21,685
Cumulative Timesteps: 361,765,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.70262
Policy Entropy: 1.11471
Value Function Loss: 2.47708

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.05127

Collected Steps per Second: 9,052.91449
Overall Steps per Second: 7,802.40786

Timestep Collection Time: 5.52397
Timestep Consumption Time: 0.88534
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.40930

Cumulative Model Updates: 21,688
Cumulative Timesteps: 361,815,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 361815730...
Checkpoint 361815730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.09738
Policy Entropy: 1.08664
Value Function Loss: 2.43519

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.20063
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 9,313.31087
Overall Steps per Second: 8,112.13544

Timestep Collection Time: 5.37167
Timestep Consumption Time: 0.79539
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.16706

Cumulative Model Updates: 21,691
Cumulative Timesteps: 361,865,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.04484
Policy Entropy: 1.10834
Value Function Loss: 2.40729

Mean KL Divergence: 0.02541
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.04404

Collected Steps per Second: 9,040.81556
Overall Steps per Second: 7,851.58662

Timestep Collection Time: 5.53269
Timestep Consumption Time: 0.83800
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.37069

Cumulative Model Updates: 21,694
Cumulative Timesteps: 361,915,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 361915778...
Checkpoint 361915778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.64320
Policy Entropy: 1.10384
Value Function Loss: 2.44189

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.04601

Collected Steps per Second: 8,685.66798
Overall Steps per Second: 7,523.00982

Timestep Collection Time: 5.75684
Timestep Consumption Time: 0.88970
PPO Batch Consumption Time: 0.04770
Total Iteration Time: 6.64654

Cumulative Model Updates: 21,697
Cumulative Timesteps: 361,965,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.10272
Policy Entropy: 1.09847
Value Function Loss: 2.49889

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 9,014.41896
Overall Steps per Second: 7,927.39974

Timestep Collection Time: 5.54867
Timestep Consumption Time: 0.76084
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.30951

Cumulative Model Updates: 21,700
Cumulative Timesteps: 362,015,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 362015798...
Checkpoint 362015798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.48716
Policy Entropy: 1.07770
Value Function Loss: 2.45953

Mean KL Divergence: 0.03224
SB3 Clip Fraction: 0.25702
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.04832

Collected Steps per Second: 8,885.71531
Overall Steps per Second: 7,622.10064

Timestep Collection Time: 5.62701
Timestep Consumption Time: 0.93286
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.55987

Cumulative Model Updates: 21,703
Cumulative Timesteps: 362,065,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.39302
Policy Entropy: 1.10207
Value Function Loss: 2.40369

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 8,621.08824
Overall Steps per Second: 7,535.26963

Timestep Collection Time: 5.80066
Timestep Consumption Time: 0.83586
PPO Batch Consumption Time: 0.04908
Total Iteration Time: 6.63652

Cumulative Model Updates: 21,706
Cumulative Timesteps: 362,115,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 362115806...
Checkpoint 362115806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.21797
Policy Entropy: 1.09049
Value Function Loss: 2.49702

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.15831
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.04992

Collected Steps per Second: 9,169.32788
Overall Steps per Second: 7,911.76519

Timestep Collection Time: 5.45318
Timestep Consumption Time: 0.86677
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.31996

Cumulative Model Updates: 21,709
Cumulative Timesteps: 362,165,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.51148
Policy Entropy: 1.07094
Value Function Loss: 2.45951

Mean KL Divergence: 0.03869
SB3 Clip Fraction: 0.25685
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.04557

Collected Steps per Second: 8,362.84194
Overall Steps per Second: 7,337.48781

Timestep Collection Time: 5.98122
Timestep Consumption Time: 0.83583
PPO Batch Consumption Time: 0.04121
Total Iteration Time: 6.81705

Cumulative Model Updates: 21,712
Cumulative Timesteps: 362,215,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 362215828...
Checkpoint 362215828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.61105
Policy Entropy: 1.08204
Value Function Loss: 2.50405

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15458
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.03999

Collected Steps per Second: 8,687.78772
Overall Steps per Second: 7,690.35233

Timestep Collection Time: 5.75590
Timestep Consumption Time: 0.74654
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.50243

Cumulative Model Updates: 21,715
Cumulative Timesteps: 362,265,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.41525
Policy Entropy: 1.07953
Value Function Loss: 2.23848

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.03447

Collected Steps per Second: 8,597.27506
Overall Steps per Second: 7,412.22590

Timestep Collection Time: 5.81766
Timestep Consumption Time: 0.93011
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 6.74777

Cumulative Model Updates: 21,718
Cumulative Timesteps: 362,315,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 362315850...
Checkpoint 362315850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.13000
Policy Entropy: 1.06102
Value Function Loss: 2.12166

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.20318
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.03397

Collected Steps per Second: 8,665.81973
Overall Steps per Second: 7,576.49519

Timestep Collection Time: 5.77026
Timestep Consumption Time: 0.82963
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 6.59989

Cumulative Model Updates: 21,721
Cumulative Timesteps: 362,365,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.94014
Policy Entropy: 1.07101
Value Function Loss: 2.23613

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.18713
Policy Update Magnitude: 0.03767
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 8,893.67887
Overall Steps per Second: 7,671.58901

Timestep Collection Time: 5.62489
Timestep Consumption Time: 0.89605
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 6.52094

Cumulative Model Updates: 21,724
Cumulative Timesteps: 362,415,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 362415880...
Checkpoint 362415880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.64136
Policy Entropy: 1.06044
Value Function Loss: 2.35512

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.17301
Policy Update Magnitude: 0.03705
Value Function Update Magnitude: 0.03340

Collected Steps per Second: 8,793.51989
Overall Steps per Second: 7,664.44380

Timestep Collection Time: 5.68760
Timestep Consumption Time: 0.83786
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 6.52546

Cumulative Model Updates: 21,727
Cumulative Timesteps: 362,465,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.23506
Policy Entropy: 1.04203
Value Function Loss: 2.41676

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.22950
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.03596

Collected Steps per Second: 8,863.06410
Overall Steps per Second: 7,769.86484

Timestep Collection Time: 5.64274
Timestep Consumption Time: 0.79392
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.43666

Cumulative Model Updates: 21,730
Cumulative Timesteps: 362,515,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 362515906...
Checkpoint 362515906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.21978
Policy Entropy: 1.03684
Value Function Loss: 2.28513

Mean KL Divergence: 0.03808
SB3 Clip Fraction: 0.21619
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.03507

Collected Steps per Second: 8,485.63436
Overall Steps per Second: 7,414.34401

Timestep Collection Time: 5.89514
Timestep Consumption Time: 0.85178
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 6.74692

Cumulative Model Updates: 21,733
Cumulative Timesteps: 362,565,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.53145
Policy Entropy: 1.04600
Value Function Loss: 2.36856

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.16686
Policy Update Magnitude: 0.03807
Value Function Update Magnitude: 0.04034

Collected Steps per Second: 8,874.76509
Overall Steps per Second: 7,823.66968

Timestep Collection Time: 5.63418
Timestep Consumption Time: 0.75694
PPO Batch Consumption Time: 0.04730
Total Iteration Time: 6.39112

Cumulative Model Updates: 21,736
Cumulative Timesteps: 362,615,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 362615932...
Checkpoint 362615932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.83650
Policy Entropy: 1.05688
Value Function Loss: 2.37181

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.03497

Collected Steps per Second: 8,807.83658
Overall Steps per Second: 7,718.08529

Timestep Collection Time: 5.67835
Timestep Consumption Time: 0.80175
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.48010

Cumulative Model Updates: 21,739
Cumulative Timesteps: 362,665,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.45827
Policy Entropy: 1.05401
Value Function Loss: 2.26133

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.17663
Policy Update Magnitude: 0.03892
Value Function Update Magnitude: 0.03669

Collected Steps per Second: 8,997.88450
Overall Steps per Second: 7,767.43399

Timestep Collection Time: 5.55797
Timestep Consumption Time: 0.88045
PPO Batch Consumption Time: 0.04872
Total Iteration Time: 6.43842

Cumulative Model Updates: 21,742
Cumulative Timesteps: 362,715,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 362715956...
Checkpoint 362715956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.95141
Policy Entropy: 1.06379
Value Function Loss: 2.19601

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 9,102.83534
Overall Steps per Second: 7,894.01224

Timestep Collection Time: 5.49521
Timestep Consumption Time: 0.84149
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.33670

Cumulative Model Updates: 21,745
Cumulative Timesteps: 362,765,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.91174
Policy Entropy: 1.05969
Value Function Loss: 2.24065

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.04026

Collected Steps per Second: 9,049.15391
Overall Steps per Second: 7,853.64067

Timestep Collection Time: 5.52759
Timestep Consumption Time: 0.84143
PPO Batch Consumption Time: 0.03985
Total Iteration Time: 6.36902

Cumulative Model Updates: 21,748
Cumulative Timesteps: 362,815,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 362815998...
Checkpoint 362815998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.79989
Policy Entropy: 1.06592
Value Function Loss: 2.17121

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.21173
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.04440

Collected Steps per Second: 8,864.50972
Overall Steps per Second: 7,678.19487

Timestep Collection Time: 5.64205
Timestep Consumption Time: 0.87172
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.51377

Cumulative Model Updates: 21,751
Cumulative Timesteps: 362,866,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.97654
Policy Entropy: 1.04796
Value Function Loss: 2.24304

Mean KL Divergence: 0.04343
SB3 Clip Fraction: 0.31046
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.04064

Collected Steps per Second: 8,728.16708
Overall Steps per Second: 7,526.41551

Timestep Collection Time: 5.73064
Timestep Consumption Time: 0.91502
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.64566

Cumulative Model Updates: 21,754
Cumulative Timesteps: 362,916,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 362916030...
Checkpoint 362916030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.79284
Policy Entropy: 1.07125
Value Function Loss: 2.24615

Mean KL Divergence: 0.03130
SB3 Clip Fraction: 0.19433
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 8,975.56290
Overall Steps per Second: 7,820.50813

Timestep Collection Time: 5.57269
Timestep Consumption Time: 0.82306
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.39575

Cumulative Model Updates: 21,757
Cumulative Timesteps: 362,966,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.50702
Policy Entropy: 1.04709
Value Function Loss: 2.52907

Mean KL Divergence: 0.03797
SB3 Clip Fraction: 0.19641
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.04092

Collected Steps per Second: 9,069.82389
Overall Steps per Second: 7,785.69192

Timestep Collection Time: 5.51279
Timestep Consumption Time: 0.90925
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 6.42204

Cumulative Model Updates: 21,760
Cumulative Timesteps: 363,016,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 363016048...
Checkpoint 363016048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.59475
Policy Entropy: 1.05700
Value Function Loss: 2.55584

Mean KL Divergence: 0.02738
SB3 Clip Fraction: 0.20677
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.03831

Collected Steps per Second: 8,767.85287
Overall Steps per Second: 7,652.42386

Timestep Collection Time: 5.70516
Timestep Consumption Time: 0.83159
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.53675

Cumulative Model Updates: 21,763
Cumulative Timesteps: 363,066,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.36006
Policy Entropy: 1.06176
Value Function Loss: 2.51357

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.18342
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.03530

Collected Steps per Second: 8,564.44247
Overall Steps per Second: 7,594.43454

Timestep Collection Time: 5.84066
Timestep Consumption Time: 0.74601
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.58667

Cumulative Model Updates: 21,766
Cumulative Timesteps: 363,116,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 363116092...
Checkpoint 363116092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.61417
Policy Entropy: 1.07766
Value Function Loss: 2.44652

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.20639
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.03320

Collected Steps per Second: 8,962.63879
Overall Steps per Second: 7,767.27296

Timestep Collection Time: 5.58162
Timestep Consumption Time: 0.85900
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.44061

Cumulative Model Updates: 21,769
Cumulative Timesteps: 363,166,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.45483
Policy Entropy: 1.07224
Value Function Loss: 2.23174

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.17341
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.03821

Collected Steps per Second: 8,629.43276
Overall Steps per Second: 7,574.37124

Timestep Collection Time: 5.79412
Timestep Consumption Time: 0.80708
PPO Batch Consumption Time: 0.04562
Total Iteration Time: 6.60121

Cumulative Model Updates: 21,772
Cumulative Timesteps: 363,216,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 363216118...
Checkpoint 363216118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.93989
Policy Entropy: 1.05922
Value Function Loss: 2.36533

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.21547
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.03468

Collected Steps per Second: 8,941.58990
Overall Steps per Second: 7,747.32874

Timestep Collection Time: 5.59185
Timestep Consumption Time: 0.86199
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.45384

Cumulative Model Updates: 21,775
Cumulative Timesteps: 363,266,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.44685
Policy Entropy: 1.07446
Value Function Loss: 2.41113

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.04225
Value Function Update Magnitude: 0.02949

Collected Steps per Second: 8,650.30059
Overall Steps per Second: 7,534.35476

Timestep Collection Time: 5.78176
Timestep Consumption Time: 0.85636
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.63813

Cumulative Model Updates: 21,778
Cumulative Timesteps: 363,316,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 363316132...
Checkpoint 363316132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.48148
Policy Entropy: 1.07726
Value Function Loss: 2.53160

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.02770

Collected Steps per Second: 8,559.66251
Overall Steps per Second: 7,555.03823

Timestep Collection Time: 5.84135
Timestep Consumption Time: 0.77675
PPO Batch Consumption Time: 0.04885
Total Iteration Time: 6.61810

Cumulative Model Updates: 21,781
Cumulative Timesteps: 363,366,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.20359
Policy Entropy: 1.06009
Value Function Loss: 2.50423

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16167
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.04360

Collected Steps per Second: 8,860.38345
Overall Steps per Second: 7,674.80188

Timestep Collection Time: 5.64468
Timestep Consumption Time: 0.87197
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.51665

Cumulative Model Updates: 21,784
Cumulative Timesteps: 363,416,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 363416146...
Checkpoint 363416146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.19455
Policy Entropy: 1.06172
Value Function Loss: 2.59551

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.16414
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.04360

Collected Steps per Second: 8,838.62487
Overall Steps per Second: 7,700.03621

Timestep Collection Time: 5.66016
Timestep Consumption Time: 0.83696
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.49711

Cumulative Model Updates: 21,787
Cumulative Timesteps: 363,466,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.80489
Policy Entropy: 1.06465
Value Function Loss: 2.67820

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.04100
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 9,245.94937
Overall Steps per Second: 8,011.34305

Timestep Collection Time: 5.40972
Timestep Consumption Time: 0.83368
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.24340

Cumulative Model Updates: 21,790
Cumulative Timesteps: 363,516,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 363516192...
Checkpoint 363516192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.19138
Policy Entropy: 1.07725
Value Function Loss: 2.73035

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 8,496.04048
Overall Steps per Second: 7,401.43453

Timestep Collection Time: 5.88674
Timestep Consumption Time: 0.87060
PPO Batch Consumption Time: 0.04983
Total Iteration Time: 6.75734

Cumulative Model Updates: 21,793
Cumulative Timesteps: 363,566,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.44641
Policy Entropy: 1.07665
Value Function Loss: 2.75506

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.17888
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 8,978.95199
Overall Steps per Second: 7,876.25416

Timestep Collection Time: 5.56902
Timestep Consumption Time: 0.77968
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.34870

Cumulative Model Updates: 21,796
Cumulative Timesteps: 363,616,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 363616210...
Checkpoint 363616210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.21897
Policy Entropy: 1.08684
Value Function Loss: 2.53194

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.04380

Collected Steps per Second: 9,149.03495
Overall Steps per Second: 7,881.86232

Timestep Collection Time: 5.46768
Timestep Consumption Time: 0.87904
PPO Batch Consumption Time: 0.03946
Total Iteration Time: 6.34672

Cumulative Model Updates: 21,799
Cumulative Timesteps: 363,666,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.39581
Policy Entropy: 1.08424
Value Function Loss: 2.58945

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 8,964.52334
Overall Steps per Second: 7,836.17149

Timestep Collection Time: 5.57843
Timestep Consumption Time: 0.80325
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 6.38169

Cumulative Model Updates: 21,802
Cumulative Timesteps: 363,716,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 363716242...
Checkpoint 363716242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.36691
Policy Entropy: 1.08715
Value Function Loss: 2.35682

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 8,994.10764
Overall Steps per Second: 7,799.07003

Timestep Collection Time: 5.55986
Timestep Consumption Time: 0.85193
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.41179

Cumulative Model Updates: 21,805
Cumulative Timesteps: 363,766,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.19805
Policy Entropy: 1.08968
Value Function Loss: 2.43882

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.07031
Value Function Update Magnitude: 0.05413

Collected Steps per Second: 8,580.85435
Overall Steps per Second: 7,484.40812

Timestep Collection Time: 5.82809
Timestep Consumption Time: 0.85380
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.68189

Cumulative Model Updates: 21,808
Cumulative Timesteps: 363,816,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 363816258...
Checkpoint 363816258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.50977
Policy Entropy: 1.07473
Value Function Loss: 2.14348

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.22595
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 8,942.18407
Overall Steps per Second: 7,879.85052

Timestep Collection Time: 5.59282
Timestep Consumption Time: 0.75400
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 6.34682

Cumulative Model Updates: 21,811
Cumulative Timesteps: 363,866,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.45063
Policy Entropy: 1.08717
Value Function Loss: 2.24261

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.04052

Collected Steps per Second: 8,817.89191
Overall Steps per Second: 7,649.81012

Timestep Collection Time: 5.67210
Timestep Consumption Time: 0.86610
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.53820

Cumulative Model Updates: 21,814
Cumulative Timesteps: 363,916,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 363916286...
Checkpoint 363916286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.25167
Policy Entropy: 1.08932
Value Function Loss: 2.26639

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.03531

Collected Steps per Second: 8,810.72743
Overall Steps per Second: 7,695.57586

Timestep Collection Time: 5.67649
Timestep Consumption Time: 0.82257
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.49906

Cumulative Model Updates: 21,817
Cumulative Timesteps: 363,966,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.06949
Policy Entropy: 1.07351
Value Function Loss: 2.33471

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.17000
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.03169

Collected Steps per Second: 9,003.97553
Overall Steps per Second: 7,825.59329

Timestep Collection Time: 5.55488
Timestep Consumption Time: 0.83646
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 6.39134

Cumulative Model Updates: 21,820
Cumulative Timesteps: 364,016,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 364016316...
Checkpoint 364016316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.33778
Policy Entropy: 1.06523
Value Function Loss: 2.53264

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.19963
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 8,866.64630
Overall Steps per Second: 7,665.80275

Timestep Collection Time: 5.64227
Timestep Consumption Time: 0.88386
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.52613

Cumulative Model Updates: 21,823
Cumulative Timesteps: 364,066,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.04036
Policy Entropy: 1.07578
Value Function Loss: 2.67287

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.03943
Value Function Update Magnitude: 0.04077

Collected Steps per Second: 9,134.62058
Overall Steps per Second: 7,910.24192

Timestep Collection Time: 5.47368
Timestep Consumption Time: 0.84724
PPO Batch Consumption Time: 0.04804
Total Iteration Time: 6.32092

Cumulative Model Updates: 21,826
Cumulative Timesteps: 364,116,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364116344...
Checkpoint 364116344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.19854
Policy Entropy: 1.08606
Value Function Loss: 2.74365

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.17235
Policy Update Magnitude: 0.03723
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 9,028.74532
Overall Steps per Second: 7,816.90320

Timestep Collection Time: 5.54053
Timestep Consumption Time: 0.85894
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.39947

Cumulative Model Updates: 21,829
Cumulative Timesteps: 364,166,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.60420
Policy Entropy: 1.05246
Value Function Loss: 2.44645

Mean KL Divergence: 0.03738
SB3 Clip Fraction: 0.23803
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.04376

Collected Steps per Second: 9,028.81635
Overall Steps per Second: 7,848.79255

Timestep Collection Time: 5.54026
Timestep Consumption Time: 0.83295
PPO Batch Consumption Time: 0.04596
Total Iteration Time: 6.37321

Cumulative Model Updates: 21,832
Cumulative Timesteps: 364,216,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 364216390...
Checkpoint 364216390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.73102
Policy Entropy: 1.07745
Value Function Loss: 2.55401

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.04562
Value Function Update Magnitude: 0.03832

Collected Steps per Second: 8,599.07115
Overall Steps per Second: 7,611.43804

Timestep Collection Time: 5.81458
Timestep Consumption Time: 0.75448
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 6.56906

Cumulative Model Updates: 21,835
Cumulative Timesteps: 364,266,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.06823
Policy Entropy: 1.07634
Value Function Loss: 2.40271

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 8,639.79025
Overall Steps per Second: 7,490.56312

Timestep Collection Time: 5.78949
Timestep Consumption Time: 0.88824
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.67774

Cumulative Model Updates: 21,838
Cumulative Timesteps: 364,316,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 364316410...
Checkpoint 364316410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.39154
Policy Entropy: 1.06548
Value Function Loss: 2.31300

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.19211
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 8,632.52551
Overall Steps per Second: 7,471.10315

Timestep Collection Time: 5.79274
Timestep Consumption Time: 0.90051
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.69326

Cumulative Model Updates: 21,841
Cumulative Timesteps: 364,366,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.57115
Policy Entropy: 1.06807
Value Function Loss: 2.34276

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.21364
Policy Update Magnitude: 0.04040
Value Function Update Magnitude: 0.05135

Collected Steps per Second: 9,045.02957
Overall Steps per Second: 7,889.47578

Timestep Collection Time: 5.52922
Timestep Consumption Time: 0.80985
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.33908

Cumulative Model Updates: 21,844
Cumulative Timesteps: 364,416,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 364416428...
Checkpoint 364416428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.58389
Policy Entropy: 1.08520
Value Function Loss: 2.62390

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.05234

Collected Steps per Second: 9,112.85944
Overall Steps per Second: 7,932.39573

Timestep Collection Time: 5.48917
Timestep Consumption Time: 0.81687
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.30604

Cumulative Model Updates: 21,847
Cumulative Timesteps: 364,466,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.19150
Policy Entropy: 1.10140
Value Function Loss: 2.88063

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.20842
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 8,721.03318
Overall Steps per Second: 7,693.67365

Timestep Collection Time: 5.73510
Timestep Consumption Time: 0.76583
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.50093

Cumulative Model Updates: 21,850
Cumulative Timesteps: 364,516,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 364516466...
Checkpoint 364516466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.01800
Policy Entropy: 1.08779
Value Function Loss: 2.47902

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.04623

Collected Steps per Second: 8,892.85122
Overall Steps per Second: 7,726.42833

Timestep Collection Time: 5.62384
Timestep Consumption Time: 0.84901
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.47285

Cumulative Model Updates: 21,853
Cumulative Timesteps: 364,566,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.54520
Policy Entropy: 1.08777
Value Function Loss: 2.32507

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.04212

Collected Steps per Second: 9,016.64360
Overall Steps per Second: 7,834.05830

Timestep Collection Time: 5.54730
Timestep Consumption Time: 0.83739
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.38469

Cumulative Model Updates: 21,856
Cumulative Timesteps: 364,616,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 364616496...
Checkpoint 364616496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.43542
Policy Entropy: 1.09444
Value Function Loss: 2.48011

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.03479

Collected Steps per Second: 8,868.04652
Overall Steps per Second: 7,667.00760

Timestep Collection Time: 5.64048
Timestep Consumption Time: 0.88358
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.52406

Cumulative Model Updates: 21,859
Cumulative Timesteps: 364,666,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.02009
Policy Entropy: 1.10305
Value Function Loss: 2.91581

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 8,766.56791
Overall Steps per Second: 7,508.32113

Timestep Collection Time: 5.70349
Timestep Consumption Time: 0.95579
PPO Batch Consumption Time: 0.04878
Total Iteration Time: 6.65928

Cumulative Model Updates: 21,862
Cumulative Timesteps: 364,716,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364716516...
Checkpoint 364716516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.54677
Policy Entropy: 1.10547
Value Function Loss: 2.77435

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.04986

Collected Steps per Second: 8,895.84963
Overall Steps per Second: 7,838.94388

Timestep Collection Time: 5.62150
Timestep Consumption Time: 0.75793
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.37943

Cumulative Model Updates: 21,865
Cumulative Timesteps: 364,766,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.80276
Policy Entropy: 1.11097
Value Function Loss: 2.66778

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.07447
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 8,798.67419
Overall Steps per Second: 7,718.31237

Timestep Collection Time: 5.68472
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 6.48043

Cumulative Model Updates: 21,868
Cumulative Timesteps: 364,816,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 364816542...
Checkpoint 364816542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.92195
Policy Entropy: 1.11389
Value Function Loss: 2.36138

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.07532
Value Function Update Magnitude: 0.05865

Collected Steps per Second: 8,739.08006
Overall Steps per Second: 7,726.40185

Timestep Collection Time: 5.72417
Timestep Consumption Time: 0.75025
PPO Batch Consumption Time: 0.04618
Total Iteration Time: 6.47442

Cumulative Model Updates: 21,871
Cumulative Timesteps: 364,866,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.00684
Policy Entropy: 1.11887
Value Function Loss: 2.41164

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.07516
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 9,155.07796
Overall Steps per Second: 7,914.93720

Timestep Collection Time: 5.46167
Timestep Consumption Time: 0.85575
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 6.31742

Cumulative Model Updates: 21,874
Cumulative Timesteps: 364,916,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 364916568...
Checkpoint 364916568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.92549
Policy Entropy: 1.11618
Value Function Loss: 2.27063

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 8,744.15419
Overall Steps per Second: 7,558.29716

Timestep Collection Time: 5.72154
Timestep Consumption Time: 0.89768
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.61922

Cumulative Model Updates: 21,877
Cumulative Timesteps: 364,966,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.89915
Policy Entropy: 1.12021
Value Function Loss: 2.36211

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.15823
Policy Update Magnitude: 0.06910
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 8,817.80546
Overall Steps per Second: 7,815.69699

Timestep Collection Time: 5.67035
Timestep Consumption Time: 0.72704
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 6.39738

Cumulative Model Updates: 21,880
Cumulative Timesteps: 365,016,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 365016598...
Checkpoint 365016598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.71597
Policy Entropy: 1.11522
Value Function Loss: 2.53192

Mean KL Divergence: 0.02768
SB3 Clip Fraction: 0.20244
Policy Update Magnitude: 0.06760
Value Function Update Magnitude: 0.06277

Collected Steps per Second: 8,782.84629
Overall Steps per Second: 7,606.23478

Timestep Collection Time: 5.69428
Timestep Consumption Time: 0.88085
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.57513

Cumulative Model Updates: 21,883
Cumulative Timesteps: 365,066,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.50015
Policy Entropy: 1.14202
Value Function Loss: 2.64302

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 8,935.27142
Overall Steps per Second: 7,685.14046

Timestep Collection Time: 5.59916
Timestep Consumption Time: 0.91081
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.50997

Cumulative Model Updates: 21,886
Cumulative Timesteps: 365,116,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 365116640...
Checkpoint 365116640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.76533
Policy Entropy: 1.14118
Value Function Loss: 2.48709

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 8,650.08847
Overall Steps per Second: 7,442.64475

Timestep Collection Time: 5.78029
Timestep Consumption Time: 0.93775
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 6.71804

Cumulative Model Updates: 21,889
Cumulative Timesteps: 365,166,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.25727
Policy Entropy: 1.12367
Value Function Loss: 2.29102

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 8,659.00302
Overall Steps per Second: 7,572.17998

Timestep Collection Time: 5.77457
Timestep Consumption Time: 0.82881
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 6.60338

Cumulative Model Updates: 21,892
Cumulative Timesteps: 365,216,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 365216642...
Checkpoint 365216642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.91711
Policy Entropy: 1.10677
Value Function Loss: 2.27646

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.20421
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.05094

Collected Steps per Second: 8,690.18443
Overall Steps per Second: 7,671.33255

Timestep Collection Time: 5.75661
Timestep Consumption Time: 0.76455
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 6.52116

Cumulative Model Updates: 21,895
Cumulative Timesteps: 365,266,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.82649
Policy Entropy: 1.11136
Value Function Loss: 2.34055

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 8,818.80466
Overall Steps per Second: 7,586.61476

Timestep Collection Time: 5.67220
Timestep Consumption Time: 0.92126
PPO Batch Consumption Time: 0.05097
Total Iteration Time: 6.59345

Cumulative Model Updates: 21,898
Cumulative Timesteps: 365,316,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 365316690...
Checkpoint 365316690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 976.69543
Policy Entropy: 1.13341
Value Function Loss: 2.37771

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.17737
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.04729

Collected Steps per Second: 9,021.81172
Overall Steps per Second: 7,879.98119

Timestep Collection Time: 5.54478
Timestep Consumption Time: 0.80345
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 6.34824

Cumulative Model Updates: 21,901
Cumulative Timesteps: 365,366,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.16051
Policy Entropy: 1.08451
Value Function Loss: 2.31914

Mean KL Divergence: 0.06294
SB3 Clip Fraction: 0.33422
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.04849

Collected Steps per Second: 8,873.11226
Overall Steps per Second: 7,686.41634

Timestep Collection Time: 5.63748
Timestep Consumption Time: 0.87036
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.50784

Cumulative Model Updates: 21,904
Cumulative Timesteps: 365,416,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 365416736...
Checkpoint 365416736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.25862
Policy Entropy: 1.10964
Value Function Loss: 2.30998

Mean KL Divergence: 0.03644
SB3 Clip Fraction: 0.25466
Policy Update Magnitude: 0.04031
Value Function Update Magnitude: 0.04347

Collected Steps per Second: 9,276.25483
Overall Steps per Second: 8,017.45506

Timestep Collection Time: 5.39312
Timestep Consumption Time: 0.84676
PPO Batch Consumption Time: 0.04574
Total Iteration Time: 6.23989

Cumulative Model Updates: 21,907
Cumulative Timesteps: 365,466,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.03988
Policy Entropy: 1.09012
Value Function Loss: 2.36765

Mean KL Divergence: 0.03962
SB3 Clip Fraction: 0.28175
Policy Update Magnitude: 0.03853
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 9,235.23657
Overall Steps per Second: 8,078.74074

Timestep Collection Time: 5.41448
Timestep Consumption Time: 0.77510
PPO Batch Consumption Time: 0.04756
Total Iteration Time: 6.18958

Cumulative Model Updates: 21,910
Cumulative Timesteps: 365,516,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 365516768...
Checkpoint 365516768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.73094
Policy Entropy: 1.11315
Value Function Loss: 2.35183

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.18935
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.05693

Collected Steps per Second: 9,032.10161
Overall Steps per Second: 7,801.33320

Timestep Collection Time: 5.53802
Timestep Consumption Time: 0.87370
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.41172

Cumulative Model Updates: 21,913
Cumulative Timesteps: 365,566,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.71025
Policy Entropy: 1.10073
Value Function Loss: 2.31714

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.04674

Collected Steps per Second: 8,659.60314
Overall Steps per Second: 7,520.64945

Timestep Collection Time: 5.77532
Timestep Consumption Time: 0.87464
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.64996

Cumulative Model Updates: 21,916
Cumulative Timesteps: 365,616,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 365616800...
Checkpoint 365616800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.69582
Policy Entropy: 1.08059
Value Function Loss: 2.38894

Mean KL Divergence: 0.03106
SB3 Clip Fraction: 0.21689
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.04563

Collected Steps per Second: 8,658.49765
Overall Steps per Second: 7,544.19296

Timestep Collection Time: 5.77745
Timestep Consumption Time: 0.85335
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.63080

Cumulative Model Updates: 21,919
Cumulative Timesteps: 365,666,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.29143
Policy Entropy: 1.09596
Value Function Loss: 2.44461

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.04438

Collected Steps per Second: 8,915.47581
Overall Steps per Second: 7,751.34032

Timestep Collection Time: 5.61024
Timestep Consumption Time: 0.84257
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 6.45282

Cumulative Model Updates: 21,922
Cumulative Timesteps: 365,716,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 365716842...
Checkpoint 365716842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.29328
Policy Entropy: 1.09130
Value Function Loss: 2.49511

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.03696

Collected Steps per Second: 8,882.46807
Overall Steps per Second: 7,837.28602

Timestep Collection Time: 5.63154
Timestep Consumption Time: 0.75102
PPO Batch Consumption Time: 0.04223
Total Iteration Time: 6.38257

Cumulative Model Updates: 21,925
Cumulative Timesteps: 365,766,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.18676
Policy Entropy: 1.08949
Value Function Loss: 2.21335

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.03846

Collected Steps per Second: 8,690.97042
Overall Steps per Second: 7,585.74232

Timestep Collection Time: 5.75425
Timestep Consumption Time: 0.83838
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.59263

Cumulative Model Updates: 21,928
Cumulative Timesteps: 365,816,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 365816874...
Checkpoint 365816874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.98274
Policy Entropy: 1.05586
Value Function Loss: 2.32688

Mean KL Divergence: 0.04399
SB3 Clip Fraction: 0.31804
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.03550

Collected Steps per Second: 8,542.19209
Overall Steps per Second: 7,407.67804

Timestep Collection Time: 5.85564
Timestep Consumption Time: 0.89681
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.75245

Cumulative Model Updates: 21,931
Cumulative Timesteps: 365,866,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.57708
Policy Entropy: 1.08317
Value Function Loss: 2.32986

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.19319
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 8,977.72622
Overall Steps per Second: 7,747.66204

Timestep Collection Time: 5.57112
Timestep Consumption Time: 0.88450
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 6.45562

Cumulative Model Updates: 21,934
Cumulative Timesteps: 365,916,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 365916910...
Checkpoint 365916910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.17480
Policy Entropy: 1.06160
Value Function Loss: 2.45499

Mean KL Divergence: 0.02814
SB3 Clip Fraction: 0.22603
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.04045

Collected Steps per Second: 9,084.28094
Overall Steps per Second: 7,851.89817

Timestep Collection Time: 5.50599
Timestep Consumption Time: 0.86418
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.37018

Cumulative Model Updates: 21,937
Cumulative Timesteps: 365,966,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.02452
Policy Entropy: 1.07417
Value Function Loss: 2.30426

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.18255
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.03830

Collected Steps per Second: 8,970.09939
Overall Steps per Second: 7,932.39709

Timestep Collection Time: 5.57497
Timestep Consumption Time: 0.72931
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 6.30427

Cumulative Model Updates: 21,940
Cumulative Timesteps: 366,016,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 366016936...
Checkpoint 366016936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.78519
Policy Entropy: 1.07933
Value Function Loss: 2.19637

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.18885
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.04163

Collected Steps per Second: 8,860.02045
Overall Steps per Second: 7,637.28580

Timestep Collection Time: 5.64378
Timestep Consumption Time: 0.90357
PPO Batch Consumption Time: 0.04974
Total Iteration Time: 6.54735

Cumulative Model Updates: 21,943
Cumulative Timesteps: 366,066,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.78817
Policy Entropy: 1.08333
Value Function Loss: 2.22263

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 8,690.93417
Overall Steps per Second: 7,617.51063

Timestep Collection Time: 5.75519
Timestep Consumption Time: 0.81099
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 6.56619

Cumulative Model Updates: 21,946
Cumulative Timesteps: 366,116,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366116958...
Checkpoint 366116958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.53625
Policy Entropy: 1.08558
Value Function Loss: 2.29811

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 8,994.62189
Overall Steps per Second: 7,808.92953

Timestep Collection Time: 5.56066
Timestep Consumption Time: 0.84432
PPO Batch Consumption Time: 0.04764
Total Iteration Time: 6.40498

Cumulative Model Updates: 21,949
Cumulative Timesteps: 366,166,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.79650
Policy Entropy: 1.08816
Value Function Loss: 2.39876

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.04580

Collected Steps per Second: 8,814.23841
Overall Steps per Second: 7,661.76984

Timestep Collection Time: 5.67491
Timestep Consumption Time: 0.85361
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.52852

Cumulative Model Updates: 21,952
Cumulative Timesteps: 366,216,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 366216994...
Checkpoint 366216994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.11855
Policy Entropy: 1.10304
Value Function Loss: 2.47610

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.17635
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.03969

Collected Steps per Second: 8,553.00272
Overall Steps per Second: 7,583.63562

Timestep Collection Time: 5.84613
Timestep Consumption Time: 0.74727
PPO Batch Consumption Time: 0.04911
Total Iteration Time: 6.59341

Cumulative Model Updates: 21,955
Cumulative Timesteps: 366,266,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.60189
Policy Entropy: 1.07687
Value Function Loss: 2.27870

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.21375
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.03610

Collected Steps per Second: 8,945.54752
Overall Steps per Second: 7,790.34720

Timestep Collection Time: 5.59116
Timestep Consumption Time: 0.82909
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.42025

Cumulative Model Updates: 21,958
Cumulative Timesteps: 366,317,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 366317012...
Checkpoint 366317012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.16625
Policy Entropy: 1.08729
Value Function Loss: 2.22696

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15909
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.03874

Collected Steps per Second: 8,809.62284
Overall Steps per Second: 7,735.78805

Timestep Collection Time: 5.67675
Timestep Consumption Time: 0.78801
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.46476

Cumulative Model Updates: 21,961
Cumulative Timesteps: 366,367,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.47826
Policy Entropy: 1.09705
Value Function Loss: 2.50019

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.04162

Collected Steps per Second: 9,170.68770
Overall Steps per Second: 7,930.69318

Timestep Collection Time: 5.45412
Timestep Consumption Time: 0.85277
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.30689

Cumulative Model Updates: 21,964
Cumulative Timesteps: 366,417,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366417040...
Checkpoint 366417040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.94196
Policy Entropy: 1.08456
Value Function Loss: 2.42884

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.19306
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.04149

Collected Steps per Second: 8,996.68569
Overall Steps per Second: 7,733.35228

Timestep Collection Time: 5.55871
Timestep Consumption Time: 0.90808
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.46679

Cumulative Model Updates: 21,967
Cumulative Timesteps: 366,467,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.36073
Policy Entropy: 1.09282
Value Function Loss: 2.59789

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.18611
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.06669

Collected Steps per Second: 9,046.11503
Overall Steps per Second: 7,893.30250

Timestep Collection Time: 5.52723
Timestep Consumption Time: 0.80725
PPO Batch Consumption Time: 0.04960
Total Iteration Time: 6.33448

Cumulative Model Updates: 21,970
Cumulative Timesteps: 366,517,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 366517050...
Checkpoint 366517050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.75688
Policy Entropy: 1.09344
Value Function Loss: 2.60882

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.18517
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.05572

Collected Steps per Second: 8,707.57005
Overall Steps per Second: 7,568.82412

Timestep Collection Time: 5.74512
Timestep Consumption Time: 0.86437
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.60948

Cumulative Model Updates: 21,973
Cumulative Timesteps: 366,567,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.16058
Policy Entropy: 1.10924
Value Function Loss: 2.73770

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.04901

Collected Steps per Second: 8,925.81902
Overall Steps per Second: 7,744.03822

Timestep Collection Time: 5.60419
Timestep Consumption Time: 0.85523
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.45942

Cumulative Model Updates: 21,976
Cumulative Timesteps: 366,617,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 366617098...
Checkpoint 366617098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.40041
Policy Entropy: 1.08838
Value Function Loss: 2.64446

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 8,939.90054
Overall Steps per Second: 7,738.95050

Timestep Collection Time: 5.59447
Timestep Consumption Time: 0.86816
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 6.46263

Cumulative Model Updates: 21,979
Cumulative Timesteps: 366,667,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.34589
Policy Entropy: 1.07878
Value Function Loss: 2.42737

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.16521
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.05205

Collected Steps per Second: 8,740.08372
Overall Steps per Second: 7,526.19541

Timestep Collection Time: 5.72077
Timestep Consumption Time: 0.92269
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.64346

Cumulative Model Updates: 21,982
Cumulative Timesteps: 366,717,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 366717112...
Checkpoint 366717112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.37842
Policy Entropy: 1.08740
Value Function Loss: 2.60995

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.04884

Collected Steps per Second: 8,848.37257
Overall Steps per Second: 7,694.66468

Timestep Collection Time: 5.65347
Timestep Consumption Time: 0.84766
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.50113

Cumulative Model Updates: 21,985
Cumulative Timesteps: 366,767,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.02566
Policy Entropy: 1.08964
Value Function Loss: 2.39854

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.04078
Value Function Update Magnitude: 0.04452

Collected Steps per Second: 8,759.14505
Overall Steps per Second: 7,642.01541

Timestep Collection Time: 5.71129
Timestep Consumption Time: 0.83489
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 6.54618

Cumulative Model Updates: 21,988
Cumulative Timesteps: 366,817,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 366817162...
Checkpoint 366817162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.76920
Policy Entropy: 1.06695
Value Function Loss: 2.31541

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.17142
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.03864

Collected Steps per Second: 8,826.44091
Overall Steps per Second: 7,675.88483

Timestep Collection Time: 5.66638
Timestep Consumption Time: 0.84935
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.51573

Cumulative Model Updates: 21,991
Cumulative Timesteps: 366,867,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.07207
Policy Entropy: 1.08572
Value Function Loss: 2.21679

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.20183
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.04046

Collected Steps per Second: 8,751.46628
Overall Steps per Second: 7,723.97517

Timestep Collection Time: 5.71539
Timestep Consumption Time: 0.76030
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.47568

Cumulative Model Updates: 21,994
Cumulative Timesteps: 366,917,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 366917194...
Checkpoint 366917194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.87092
Policy Entropy: 1.07712
Value Function Loss: 2.24446

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.18706
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.04475

Collected Steps per Second: 8,789.83147
Overall Steps per Second: 7,636.14397

Timestep Collection Time: 5.68839
Timestep Consumption Time: 0.85942
PPO Batch Consumption Time: 0.03999
Total Iteration Time: 6.54781

Cumulative Model Updates: 21,997
Cumulative Timesteps: 366,967,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.60120
Policy Entropy: 1.06853
Value Function Loss: 2.15653

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.18515
Policy Update Magnitude: 0.04092
Value Function Update Magnitude: 0.04009

Collected Steps per Second: 8,603.33330
Overall Steps per Second: 7,418.23977

Timestep Collection Time: 5.81472
Timestep Consumption Time: 0.92893
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.74365

Cumulative Model Updates: 22,000
Cumulative Timesteps: 367,017,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 367017220...
Checkpoint 367017220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.19506
Policy Entropy: 1.06301
Value Function Loss: 2.15381

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.19155
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.03852

Collected Steps per Second: 9,084.11276
Overall Steps per Second: 7,865.02263

Timestep Collection Time: 5.50632
Timestep Consumption Time: 0.85349
PPO Batch Consumption Time: 0.04018
Total Iteration Time: 6.35980

Cumulative Model Updates: 22,003
Cumulative Timesteps: 367,067,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.63582
Policy Entropy: 1.06667
Value Function Loss: 2.19037

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.03454

Collected Steps per Second: 8,722.37596
Overall Steps per Second: 7,646.28590

Timestep Collection Time: 5.73422
Timestep Consumption Time: 0.80700
PPO Batch Consumption Time: 0.04051
Total Iteration Time: 6.54121

Cumulative Model Updates: 22,006
Cumulative Timesteps: 367,117,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 367117256...
Checkpoint 367117256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.21070
Policy Entropy: 1.06820
Value Function Loss: 2.17094

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.19307
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.04535

Collected Steps per Second: 8,577.55378
Overall Steps per Second: 7,547.62185

Timestep Collection Time: 5.83243
Timestep Consumption Time: 0.79588
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 6.62831

Cumulative Model Updates: 22,009
Cumulative Timesteps: 367,167,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.20894
Policy Entropy: 1.04206
Value Function Loss: 1.98094

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.20693
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.04112

Collected Steps per Second: 9,039.98498
Overall Steps per Second: 7,823.51521

Timestep Collection Time: 5.53187
Timestep Consumption Time: 0.86014
PPO Batch Consumption Time: 0.04721
Total Iteration Time: 6.39201

Cumulative Model Updates: 22,012
Cumulative Timesteps: 367,217,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 367217292...
Checkpoint 367217292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.99035
Policy Entropy: 1.06111
Value Function Loss: 1.99529

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.16749
Policy Update Magnitude: 0.04035
Value Function Update Magnitude: 0.04368

Collected Steps per Second: 8,734.50586
Overall Steps per Second: 7,673.37845

Timestep Collection Time: 5.72625
Timestep Consumption Time: 0.79187
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 6.51812

Cumulative Model Updates: 22,015
Cumulative Timesteps: 367,267,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.45321
Policy Entropy: 1.04938
Value Function Loss: 1.86962

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.17739
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 9,248.18172
Overall Steps per Second: 7,947.85690

Timestep Collection Time: 5.40993
Timestep Consumption Time: 0.88510
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.29503

Cumulative Model Updates: 22,018
Cumulative Timesteps: 367,317,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 367317340...
Checkpoint 367317340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.53363
Policy Entropy: 1.04386
Value Function Loss: 1.86753

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.20569
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.04858

Collected Steps per Second: 9,328.45531
Overall Steps per Second: 8,049.70302

Timestep Collection Time: 5.36080
Timestep Consumption Time: 0.85160
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 6.21240

Cumulative Model Updates: 22,021
Cumulative Timesteps: 367,367,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.65928
Policy Entropy: 1.04392
Value Function Loss: 1.95373

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.19427
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.04403

Collected Steps per Second: 8,921.53615
Overall Steps per Second: 7,807.78679

Timestep Collection Time: 5.60733
Timestep Consumption Time: 0.79986
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 6.40719

Cumulative Model Updates: 22,024
Cumulative Timesteps: 367,417,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 367417374...
Checkpoint 367417374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.40912
Policy Entropy: 1.05077
Value Function Loss: 2.19455

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.04030

Collected Steps per Second: 8,994.34660
Overall Steps per Second: 7,786.51995

Timestep Collection Time: 5.56083
Timestep Consumption Time: 0.86258
PPO Batch Consumption Time: 0.04434
Total Iteration Time: 6.42341

Cumulative Model Updates: 22,027
Cumulative Timesteps: 367,467,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.86617
Policy Entropy: 1.06688
Value Function Loss: 2.26355

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.18023
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.03366

Collected Steps per Second: 8,769.78032
Overall Steps per Second: 7,673.35696

Timestep Collection Time: 5.70185
Timestep Consumption Time: 0.81472
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.51657

Cumulative Model Updates: 22,030
Cumulative Timesteps: 367,517,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 367517394...
Checkpoint 367517394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.80322
Policy Entropy: 1.05034
Value Function Loss: 2.20784

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.02743

Collected Steps per Second: 9,152.13937
Overall Steps per Second: 7,896.07602

Timestep Collection Time: 5.46539
Timestep Consumption Time: 0.86940
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.33479

Cumulative Model Updates: 22,033
Cumulative Timesteps: 367,567,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.44723
Policy Entropy: 1.04717
Value Function Loss: 2.25762

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.21050
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.02428

Collected Steps per Second: 8,761.06606
Overall Steps per Second: 7,558.45371

Timestep Collection Time: 5.71004
Timestep Consumption Time: 0.90851
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.61855

Cumulative Model Updates: 22,036
Cumulative Timesteps: 367,617,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 367617440...
Checkpoint 367617440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.13078
Policy Entropy: 1.05470
Value Function Loss: 2.28898

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.03464

Collected Steps per Second: 8,440.43475
Overall Steps per Second: 7,502.25662

Timestep Collection Time: 5.92529
Timestep Consumption Time: 0.74097
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.66626

Cumulative Model Updates: 22,039
Cumulative Timesteps: 367,667,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.23505
Policy Entropy: 1.06587
Value Function Loss: 2.30761

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.04356
Value Function Update Magnitude: 0.03902

Collected Steps per Second: 8,569.31892
Overall Steps per Second: 7,481.49934

Timestep Collection Time: 5.83780
Timestep Consumption Time: 0.84882
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.68663

Cumulative Model Updates: 22,042
Cumulative Timesteps: 367,717,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 367717478...
Checkpoint 367717478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.54950
Policy Entropy: 1.02663
Value Function Loss: 2.16021

Mean KL Divergence: 0.03029
SB3 Clip Fraction: 0.22168
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.03771

Collected Steps per Second: 8,875.74826
Overall Steps per Second: 7,785.95594

Timestep Collection Time: 5.63355
Timestep Consumption Time: 0.78852
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.42208

Cumulative Model Updates: 22,045
Cumulative Timesteps: 367,767,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.45736
Policy Entropy: 1.05345
Value Function Loss: 2.19851

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.18316
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.04926

Collected Steps per Second: 9,159.95543
Overall Steps per Second: 7,957.23942

Timestep Collection Time: 5.46094
Timestep Consumption Time: 0.82541
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 6.28635

Cumulative Model Updates: 22,048
Cumulative Timesteps: 367,817,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 367817502...
Checkpoint 367817502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.09253
Policy Entropy: 1.04908
Value Function Loss: 2.08273

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.17667
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.04633

Collected Steps per Second: 8,808.45358
Overall Steps per Second: 7,703.90177

Timestep Collection Time: 5.67773
Timestep Consumption Time: 0.81405
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.49178

Cumulative Model Updates: 22,051
Cumulative Timesteps: 367,867,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.68441
Policy Entropy: 1.04201
Value Function Loss: 2.16850

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 8,829.71311
Overall Steps per Second: 7,738.14846

Timestep Collection Time: 5.66451
Timestep Consumption Time: 0.79905
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 6.46356

Cumulative Model Updates: 22,054
Cumulative Timesteps: 367,917,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 367917530...
Checkpoint 367917530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.90229
Policy Entropy: 1.02220
Value Function Loss: 2.09367

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.20647
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.04525

Collected Steps per Second: 8,674.87751
Overall Steps per Second: 7,586.70309

Timestep Collection Time: 5.76585
Timestep Consumption Time: 0.82701
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.59285

Cumulative Model Updates: 22,057
Cumulative Timesteps: 367,967,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.46704
Policy Entropy: 1.04360
Value Function Loss: 2.13272

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.04132

Collected Steps per Second: 8,998.64419
Overall Steps per Second: 7,835.96897

Timestep Collection Time: 5.55839
Timestep Consumption Time: 0.82474
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.38313

Cumulative Model Updates: 22,060
Cumulative Timesteps: 368,017,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 368017566...
Checkpoint 368017566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.63813
Policy Entropy: 1.04716
Value Function Loss: 2.15633

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.17055
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.03727

Collected Steps per Second: 8,902.32807
Overall Steps per Second: 7,716.76878

Timestep Collection Time: 5.61741
Timestep Consumption Time: 0.86303
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 6.48043

Cumulative Model Updates: 22,063
Cumulative Timesteps: 368,067,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.88241
Policy Entropy: 1.03869
Value Function Loss: 2.04473

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16460
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.04524

Collected Steps per Second: 8,890.74067
Overall Steps per Second: 7,682.54900

Timestep Collection Time: 5.62630
Timestep Consumption Time: 0.88482
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.51112

Cumulative Model Updates: 22,066
Cumulative Timesteps: 368,117,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 368117596...
Checkpoint 368117596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.11156
Policy Entropy: 1.02153
Value Function Loss: 2.07669

Mean KL Divergence: 0.03622
SB3 Clip Fraction: 0.24273
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 9,044.13353
Overall Steps per Second: 7,948.28346

Timestep Collection Time: 5.52977
Timestep Consumption Time: 0.76240
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.29218

Cumulative Model Updates: 22,069
Cumulative Timesteps: 368,167,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.01978
Policy Entropy: 1.04825
Value Function Loss: 2.09341

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.05563

Collected Steps per Second: 8,654.62543
Overall Steps per Second: 7,543.43548

Timestep Collection Time: 5.78049
Timestep Consumption Time: 0.85150
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 6.63199

Cumulative Model Updates: 22,072
Cumulative Timesteps: 368,217,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 368217636...
Checkpoint 368217636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.67815
Policy Entropy: 1.02393
Value Function Loss: 2.03188

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.18819
Policy Update Magnitude: 0.03933
Value Function Update Magnitude: 0.04748

Collected Steps per Second: 8,942.29508
Overall Steps per Second: 7,791.35918

Timestep Collection Time: 5.59364
Timestep Consumption Time: 0.82629
PPO Batch Consumption Time: 0.04051
Total Iteration Time: 6.41993

Cumulative Model Updates: 22,075
Cumulative Timesteps: 368,267,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.54595
Policy Entropy: 1.02383
Value Function Loss: 1.92866

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.18473
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.04815

Collected Steps per Second: 8,996.11887
Overall Steps per Second: 7,793.40128

Timestep Collection Time: 5.56106
Timestep Consumption Time: 0.85821
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.41928

Cumulative Model Updates: 22,078
Cumulative Timesteps: 368,317,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 368317684...
Checkpoint 368317684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.69127
Policy Entropy: 1.04707
Value Function Loss: 1.79087

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.18492
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.04713

Collected Steps per Second: 8,855.80305
Overall Steps per Second: 7,711.66704

Timestep Collection Time: 5.64737
Timestep Consumption Time: 0.83787
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.48524

Cumulative Model Updates: 22,081
Cumulative Timesteps: 368,367,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.08540
Policy Entropy: 1.05514
Value Function Loss: 1.82160

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.18128
Policy Update Magnitude: 0.04164
Value Function Update Magnitude: 0.04598

Collected Steps per Second: 8,604.09531
Overall Steps per Second: 7,606.07608

Timestep Collection Time: 5.81165
Timestep Consumption Time: 0.76257
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.57422

Cumulative Model Updates: 22,084
Cumulative Timesteps: 368,417,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 368417700...
Checkpoint 368417700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.71769
Policy Entropy: 1.04553
Value Function Loss: 1.92175

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.04534

Collected Steps per Second: 8,918.58454
Overall Steps per Second: 7,707.79109

Timestep Collection Time: 5.60941
Timestep Consumption Time: 0.88117
PPO Batch Consumption Time: 0.04466
Total Iteration Time: 6.49058

Cumulative Model Updates: 22,087
Cumulative Timesteps: 368,467,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.61648
Policy Entropy: 1.04371
Value Function Loss: 2.13702

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.19293
Policy Update Magnitude: 0.04100
Value Function Update Magnitude: 0.04704

Collected Steps per Second: 8,736.08432
Overall Steps per Second: 7,733.59080

Timestep Collection Time: 5.72545
Timestep Consumption Time: 0.74218
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 6.46763

Cumulative Model Updates: 22,090
Cumulative Timesteps: 368,517,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 368517746...
Checkpoint 368517746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.88921
Policy Entropy: 1.05063
Value Function Loss: 2.36643

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.17107
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 8,923.49584
Overall Steps per Second: 7,762.41647

Timestep Collection Time: 5.60386
Timestep Consumption Time: 0.83821
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 6.44207

Cumulative Model Updates: 22,093
Cumulative Timesteps: 368,567,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.76465
Policy Entropy: 1.05371
Value Function Loss: 2.32161

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.17279
Policy Update Magnitude: 0.03894
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 8,883.60864
Overall Steps per Second: 7,773.22061

Timestep Collection Time: 5.63104
Timestep Consumption Time: 0.80438
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.43543

Cumulative Model Updates: 22,096
Cumulative Timesteps: 368,617,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 368617776...
Checkpoint 368617776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.90676
Policy Entropy: 1.02590
Value Function Loss: 2.20251

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.18602
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 8,510.56532
Overall Steps per Second: 7,559.08042

Timestep Collection Time: 5.87764
Timestep Consumption Time: 0.73984
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 6.61747

Cumulative Model Updates: 22,099
Cumulative Timesteps: 368,667,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.59529
Policy Entropy: 1.05132
Value Function Loss: 1.97094

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.23221
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.05612

Collected Steps per Second: 8,712.74566
Overall Steps per Second: 7,615.91893

Timestep Collection Time: 5.74056
Timestep Consumption Time: 0.82674
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 6.56730

Cumulative Model Updates: 22,102
Cumulative Timesteps: 368,717,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 368717814...
Checkpoint 368717814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.24116
Policy Entropy: 1.03929
Value Function Loss: 1.80931

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.20999
Policy Update Magnitude: 0.04034
Value Function Update Magnitude: 0.04966

Collected Steps per Second: 8,606.67670
Overall Steps per Second: 7,504.34536

Timestep Collection Time: 5.81014
Timestep Consumption Time: 0.85347
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.66361

Cumulative Model Updates: 22,105
Cumulative Timesteps: 368,767,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.15143
Policy Entropy: 1.04120
Value Function Loss: 1.73241

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.19702
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.04270

Collected Steps per Second: 8,907.48753
Overall Steps per Second: 7,757.54047

Timestep Collection Time: 5.61460
Timestep Consumption Time: 0.83229
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.44689

Cumulative Model Updates: 22,108
Cumulative Timesteps: 368,817,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 368817832...
Checkpoint 368817832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.94339
Policy Entropy: 1.02714
Value Function Loss: 1.79020

Mean KL Divergence: 0.03136
SB3 Clip Fraction: 0.23737
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 8,594.30721
Overall Steps per Second: 7,469.07686

Timestep Collection Time: 5.81780
Timestep Consumption Time: 0.87646
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.69427

Cumulative Model Updates: 22,111
Cumulative Timesteps: 368,867,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.93136
Policy Entropy: 1.05964
Value Function Loss: 1.82282

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.23347
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.04117

Collected Steps per Second: 8,882.59044
Overall Steps per Second: 7,783.34508

Timestep Collection Time: 5.63214
Timestep Consumption Time: 0.79543
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.42757

Cumulative Model Updates: 22,114
Cumulative Timesteps: 368,917,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 368917860...
Checkpoint 368917860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.12100
Policy Entropy: 1.05522
Value Function Loss: 2.00499

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.18652
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 8,812.32010
Overall Steps per Second: 7,585.58578

Timestep Collection Time: 5.67637
Timestep Consumption Time: 0.91798
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.59435

Cumulative Model Updates: 22,117
Cumulative Timesteps: 368,967,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.29294
Policy Entropy: 1.04258
Value Function Loss: 1.93241

Mean KL Divergence: 0.03518
SB3 Clip Fraction: 0.28173
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.03922

Collected Steps per Second: 9,001.16549
Overall Steps per Second: 7,780.06338

Timestep Collection Time: 5.55528
Timestep Consumption Time: 0.87192
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.42720

Cumulative Model Updates: 22,120
Cumulative Timesteps: 369,017,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 369017886...
Checkpoint 369017886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.90677
Policy Entropy: 1.06260
Value Function Loss: 1.86658

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.21720
Policy Update Magnitude: 0.04031
Value Function Update Magnitude: 0.04318

Collected Steps per Second: 9,068.18458
Overall Steps per Second: 7,763.80997

Timestep Collection Time: 5.51687
Timestep Consumption Time: 0.92687
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 6.44374

Cumulative Model Updates: 22,123
Cumulative Timesteps: 369,067,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.82731
Policy Entropy: 1.04899
Value Function Loss: 1.80358

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.18274
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.04038

Collected Steps per Second: 9,362.83258
Overall Steps per Second: 8,037.69159

Timestep Collection Time: 5.34155
Timestep Consumption Time: 0.88064
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.22218

Cumulative Model Updates: 22,126
Cumulative Timesteps: 369,117,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 369117926...
Checkpoint 369117926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.66258
Policy Entropy: 1.04096
Value Function Loss: 1.76795

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.04745

Collected Steps per Second: 9,188.72147
Overall Steps per Second: 8,072.06526

Timestep Collection Time: 5.44319
Timestep Consumption Time: 0.75299
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 6.19618

Cumulative Model Updates: 22,129
Cumulative Timesteps: 369,167,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.81894
Policy Entropy: 1.06062
Value Function Loss: 1.98012

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.20373
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.04496

Collected Steps per Second: 9,168.14150
Overall Steps per Second: 7,869.52564

Timestep Collection Time: 5.45410
Timestep Consumption Time: 0.90003
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.35413

Cumulative Model Updates: 22,132
Cumulative Timesteps: 369,217,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 369217946...
Checkpoint 369217946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.64799
Policy Entropy: 1.05977
Value Function Loss: 1.95970

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.21677
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 9,179.57688
Overall Steps per Second: 7,946.12662

Timestep Collection Time: 5.44818
Timestep Consumption Time: 0.84570
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.29388

Cumulative Model Updates: 22,135
Cumulative Timesteps: 369,267,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.31885
Policy Entropy: 1.03909
Value Function Loss: 2.12527

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.23745
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.04200

Collected Steps per Second: 9,149.21700
Overall Steps per Second: 7,965.26946

Timestep Collection Time: 5.46801
Timestep Consumption Time: 0.81276
PPO Batch Consumption Time: 0.04176
Total Iteration Time: 6.28077

Cumulative Model Updates: 22,138
Cumulative Timesteps: 369,317,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 369317986...
Checkpoint 369317986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.92547
Policy Entropy: 1.06266
Value Function Loss: 2.46732

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.20264
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 8,620.91788
Overall Steps per Second: 7,572.69392

Timestep Collection Time: 5.80193
Timestep Consumption Time: 0.80311
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.60505

Cumulative Model Updates: 22,141
Cumulative Timesteps: 369,368,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.03120
Policy Entropy: 1.07115
Value Function Loss: 2.52625

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.20198
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.03702

Collected Steps per Second: 9,068.54037
Overall Steps per Second: 7,961.78876

Timestep Collection Time: 5.51533
Timestep Consumption Time: 0.76667
PPO Batch Consumption Time: 0.04487
Total Iteration Time: 6.28201

Cumulative Model Updates: 22,144
Cumulative Timesteps: 369,418,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 369418020...
Checkpoint 369418020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.03114
Policy Entropy: 1.05886
Value Function Loss: 2.58335

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.04863

Collected Steps per Second: 8,854.81732
Overall Steps per Second: 7,653.98281

Timestep Collection Time: 5.64913
Timestep Consumption Time: 0.88629
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 6.53542

Cumulative Model Updates: 22,147
Cumulative Timesteps: 369,468,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.15859
Policy Entropy: 1.04595
Value Function Loss: 2.53877

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.20742
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.04969

Collected Steps per Second: 8,979.29118
Overall Steps per Second: 7,659.46767

Timestep Collection Time: 5.56993
Timestep Consumption Time: 0.95977
PPO Batch Consumption Time: 0.04885
Total Iteration Time: 6.52970

Cumulative Model Updates: 22,150
Cumulative Timesteps: 369,518,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 369518056...
Checkpoint 369518056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.17642
Policy Entropy: 1.06108
Value Function Loss: 2.52163

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.05747

Collected Steps per Second: 8,925.17903
Overall Steps per Second: 7,712.17051

Timestep Collection Time: 5.60549
Timestep Consumption Time: 0.88166
PPO Batch Consumption Time: 0.05402
Total Iteration Time: 6.48715

Cumulative Model Updates: 22,153
Cumulative Timesteps: 369,568,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.88791
Policy Entropy: 1.07813
Value Function Loss: 2.49599

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 7,678.74060
Overall Steps per Second: 6,754.42522

Timestep Collection Time: 6.51435
Timestep Consumption Time: 0.89146
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 7.40581

Cumulative Model Updates: 22,156
Cumulative Timesteps: 369,618,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 369618108...
Checkpoint 369618108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.42852
Policy Entropy: 1.05576
Value Function Loss: 2.03982

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 8,337.10598
Overall Steps per Second: 7,361.56389

Timestep Collection Time: 5.99800
Timestep Consumption Time: 0.79485
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.79285

Cumulative Model Updates: 22,159
Cumulative Timesteps: 369,668,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.54079
Policy Entropy: 1.03342
Value Function Loss: 1.96568

Mean KL Divergence: 0.03702
SB3 Clip Fraction: 0.21955
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 8,523.41542
Overall Steps per Second: 7,366.78978

Timestep Collection Time: 5.86807
Timestep Consumption Time: 0.92132
PPO Batch Consumption Time: 0.04980
Total Iteration Time: 6.78939

Cumulative Model Updates: 22,162
Cumulative Timesteps: 369,718,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 369718130...
Checkpoint 369718130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.75010
Policy Entropy: 1.06830
Value Function Loss: 1.90279

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 8,197.70116
Overall Steps per Second: 7,178.73389

Timestep Collection Time: 6.10000
Timestep Consumption Time: 0.86585
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 6.96585

Cumulative Model Updates: 22,165
Cumulative Timesteps: 369,768,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.53159
Policy Entropy: 1.04840
Value Function Loss: 2.02162

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.19989
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.04606

Collected Steps per Second: 8,132.59023
Overall Steps per Second: 7,226.99596

Timestep Collection Time: 6.14909
Timestep Consumption Time: 0.77052
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.91961

Cumulative Model Updates: 22,168
Cumulative Timesteps: 369,818,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 369818144...
Checkpoint 369818144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.25506
Policy Entropy: 1.05797
Value Function Loss: 2.19891

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.19147
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.05935

Collected Steps per Second: 8,249.24990
Overall Steps per Second: 7,210.80545

Timestep Collection Time: 6.06455
Timestep Consumption Time: 0.87337
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.93792

Cumulative Model Updates: 22,171
Cumulative Timesteps: 369,868,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.60036
Policy Entropy: 1.07702
Value Function Loss: 2.16587

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.18412
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.04447

Collected Steps per Second: 8,427.55300
Overall Steps per Second: 7,367.50063

Timestep Collection Time: 5.93624
Timestep Consumption Time: 0.85412
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.79036

Cumulative Model Updates: 22,174
Cumulative Timesteps: 369,918,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 369918200...
Checkpoint 369918200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.97851
Policy Entropy: 1.08263
Value Function Loss: 2.21445

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.03789
Value Function Update Magnitude: 0.03584

Collected Steps per Second: 8,422.50411
Overall Steps per Second: 7,366.35538

Timestep Collection Time: 5.93980
Timestep Consumption Time: 0.85162
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 6.79142

Cumulative Model Updates: 22,177
Cumulative Timesteps: 369,968,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.56455
Policy Entropy: 1.05551
Value Function Loss: 2.10721

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16728
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.03117

Collected Steps per Second: 7,996.97669
Overall Steps per Second: 6,961.12959

Timestep Collection Time: 6.25486
Timestep Consumption Time: 0.93075
PPO Batch Consumption Time: 0.05425
Total Iteration Time: 7.18562

Cumulative Model Updates: 22,180
Cumulative Timesteps: 370,018,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 370018248...
Checkpoint 370018248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.49408
Policy Entropy: 1.03117
Value Function Loss: 2.03883

Mean KL Divergence: 0.03913
SB3 Clip Fraction: 0.27197
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.04622

Collected Steps per Second: 8,367.05927
Overall Steps per Second: 7,405.89232

Timestep Collection Time: 5.97797
Timestep Consumption Time: 0.77584
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.75381

Cumulative Model Updates: 22,183
Cumulative Timesteps: 370,068,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.90715
Policy Entropy: 1.03481
Value Function Loss: 2.12502

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.18329
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.06813

Collected Steps per Second: 8,371.66357
Overall Steps per Second: 7,300.70471

Timestep Collection Time: 5.97444
Timestep Consumption Time: 0.87641
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.85085

Cumulative Model Updates: 22,186
Cumulative Timesteps: 370,118,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370118282...
Checkpoint 370118282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.90614
Policy Entropy: 1.03732
Value Function Loss: 2.06645

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.17781
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.07992

Collected Steps per Second: 8,184.31164
Overall Steps per Second: 7,103.18381

Timestep Collection Time: 6.11072
Timestep Consumption Time: 0.93007
PPO Batch Consumption Time: 0.05047
Total Iteration Time: 7.04079

Cumulative Model Updates: 22,189
Cumulative Timesteps: 370,168,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.33004
Policy Entropy: 1.01282
Value Function Loss: 1.95825

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.06636

Collected Steps per Second: 8,161.57245
Overall Steps per Second: 7,074.01292

Timestep Collection Time: 6.12995
Timestep Consumption Time: 0.94242
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 7.07236

Cumulative Model Updates: 22,192
Cumulative Timesteps: 370,218,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 370218324...
Checkpoint 370218324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.26057
Policy Entropy: 1.00567
Value Function Loss: 1.77073

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.05128

Collected Steps per Second: 8,120.17218
Overall Steps per Second: 7,056.62531

Timestep Collection Time: 6.15898
Timestep Consumption Time: 0.92826
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 7.08724

Cumulative Model Updates: 22,195
Cumulative Timesteps: 370,268,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.09906
Policy Entropy: 0.99963
Value Function Loss: 1.74001

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.21533
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.04711

Collected Steps per Second: 8,087.10009
Overall Steps per Second: 7,110.15015

Timestep Collection Time: 6.18466
Timestep Consumption Time: 0.84979
PPO Batch Consumption Time: 0.04764
Total Iteration Time: 7.03445

Cumulative Model Updates: 22,198
Cumulative Timesteps: 370,318,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370318352...
Checkpoint 370318352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.25507
Policy Entropy: 1.02064
Value Function Loss: 1.93499

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.20767
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.04581

Collected Steps per Second: 8,451.69411
Overall Steps per Second: 7,368.14416

Timestep Collection Time: 5.91787
Timestep Consumption Time: 0.87027
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 6.78814

Cumulative Model Updates: 22,201
Cumulative Timesteps: 370,368,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.76402
Policy Entropy: 1.01885
Value Function Loss: 2.04454

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.17689
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.04075

Collected Steps per Second: 8,082.49869
Overall Steps per Second: 6,978.01989

Timestep Collection Time: 6.18843
Timestep Consumption Time: 0.97950
PPO Batch Consumption Time: 0.04962
Total Iteration Time: 7.16794

Cumulative Model Updates: 22,204
Cumulative Timesteps: 370,418,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 370418386...
Checkpoint 370418386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.18193
Policy Entropy: 1.01758
Value Function Loss: 2.16136

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.03981

Collected Steps per Second: 8,234.06976
Overall Steps per Second: 7,260.86708

Timestep Collection Time: 6.07427
Timestep Consumption Time: 0.81416
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.88843

Cumulative Model Updates: 22,207
Cumulative Timesteps: 370,468,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.28833
Policy Entropy: 1.01077
Value Function Loss: 2.13826

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.19748
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.03848

Collected Steps per Second: 8,421.67174
Overall Steps per Second: 7,231.51961

Timestep Collection Time: 5.93991
Timestep Consumption Time: 0.97758
PPO Batch Consumption Time: 0.05074
Total Iteration Time: 6.91749

Cumulative Model Updates: 22,210
Cumulative Timesteps: 370,518,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 370518426...
Checkpoint 370518426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.33471
Policy Entropy: 1.02732
Value Function Loss: 2.31300

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.18303
Policy Update Magnitude: 0.04228
Value Function Update Magnitude: 0.04316

Collected Steps per Second: 7,861.58160
Overall Steps per Second: 6,949.32439

Timestep Collection Time: 6.36310
Timestep Consumption Time: 0.83530
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 7.19840

Cumulative Model Updates: 22,213
Cumulative Timesteps: 370,568,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.88420
Policy Entropy: 1.03425
Value Function Loss: 2.36498

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.20287
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.04103

Collected Steps per Second: 8,365.56093
Overall Steps per Second: 7,283.25979

Timestep Collection Time: 5.97904
Timestep Consumption Time: 0.88849
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.86753

Cumulative Model Updates: 22,216
Cumulative Timesteps: 370,618,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 370618468...
Checkpoint 370618468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.64683
Policy Entropy: 1.02177
Value Function Loss: 2.13258

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.04314

Collected Steps per Second: 8,094.43859
Overall Steps per Second: 7,082.15879

Timestep Collection Time: 6.17782
Timestep Consumption Time: 0.88302
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 7.06084

Cumulative Model Updates: 22,219
Cumulative Timesteps: 370,668,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.57973
Policy Entropy: 1.01183
Value Function Loss: 2.06731

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.16595
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 8,314.16917
Overall Steps per Second: 7,358.18529

Timestep Collection Time: 6.01383
Timestep Consumption Time: 0.78132
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.79515

Cumulative Model Updates: 22,222
Cumulative Timesteps: 370,718,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 370718474...
Checkpoint 370718474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.14565
Policy Entropy: 1.03165
Value Function Loss: 1.95248

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.19887
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.04847

Collected Steps per Second: 8,344.63405
Overall Steps per Second: 7,273.70455

Timestep Collection Time: 5.99571
Timestep Consumption Time: 0.88277
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.87848

Cumulative Model Updates: 22,225
Cumulative Timesteps: 370,768,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.78347
Policy Entropy: 1.03271
Value Function Loss: 2.13917

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.18359
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.04354

Collected Steps per Second: 8,308.24637
Overall Steps per Second: 7,111.98397

Timestep Collection Time: 6.02052
Timestep Consumption Time: 1.01267
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 7.03320

Cumulative Model Updates: 22,228
Cumulative Timesteps: 370,818,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 370818526...
Checkpoint 370818526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.67656
Policy Entropy: 1.02301
Value Function Loss: 2.14279

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.03879

Collected Steps per Second: 8,062.17554
Overall Steps per Second: 7,167.64933

Timestep Collection Time: 6.20502
Timestep Consumption Time: 0.77439
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.97942

Cumulative Model Updates: 22,231
Cumulative Timesteps: 370,868,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.75124
Policy Entropy: 0.98866
Value Function Loss: 2.20086

Mean KL Divergence: 0.04797
SB3 Clip Fraction: 0.30975
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.03231

Collected Steps per Second: 8,537.51967
Overall Steps per Second: 7,424.82076

Timestep Collection Time: 5.85931
Timestep Consumption Time: 0.87809
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.73740

Cumulative Model Updates: 22,234
Cumulative Timesteps: 370,918,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 370918576...
Checkpoint 370918576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.40930
Policy Entropy: 1.03083
Value Function Loss: 2.15018

Mean KL Divergence: 0.04089
SB3 Clip Fraction: 0.31006
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.02861

Collected Steps per Second: 8,457.31436
Overall Steps per Second: 7,353.34803

Timestep Collection Time: 5.91299
Timestep Consumption Time: 0.88772
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.80071

Cumulative Model Updates: 22,237
Cumulative Timesteps: 370,968,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.03697
Policy Entropy: 0.98560
Value Function Loss: 2.16811

Mean KL Divergence: 0.07124
SB3 Clip Fraction: 0.35293
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.02672

Collected Steps per Second: 8,751.33334
Overall Steps per Second: 7,550.21978

Timestep Collection Time: 5.71593
Timestep Consumption Time: 0.90931
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.62524

Cumulative Model Updates: 22,240
Cumulative Timesteps: 371,018,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371018606...
Checkpoint 371018606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.51639
Policy Entropy: 1.03157
Value Function Loss: 2.14527

Mean KL Divergence: 0.05235
SB3 Clip Fraction: 0.32820
Policy Update Magnitude: 0.03435
Value Function Update Magnitude: 0.02971

Collected Steps per Second: 8,833.88761
Overall Steps per Second: 7,653.03760

Timestep Collection Time: 5.66002
Timestep Consumption Time: 0.87333
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 6.53335

Cumulative Model Updates: 22,243
Cumulative Timesteps: 371,068,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.63122
Policy Entropy: 1.00957
Value Function Loss: 2.23669

Mean KL Divergence: 0.05417
SB3 Clip Fraction: 0.29271
Policy Update Magnitude: 0.03277
Value Function Update Magnitude: 0.02667

Collected Steps per Second: 8,837.48189
Overall Steps per Second: 7,837.57968

Timestep Collection Time: 5.65976
Timestep Consumption Time: 0.72206
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.38182

Cumulative Model Updates: 22,246
Cumulative Timesteps: 371,118,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 371118624...
Checkpoint 371118624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.42661
Policy Entropy: 1.03272
Value Function Loss: 2.11513

Mean KL Divergence: 0.04199
SB3 Clip Fraction: 0.22001
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.03599

Collected Steps per Second: 8,979.41278
Overall Steps per Second: 7,720.36243

Timestep Collection Time: 5.57074
Timestep Consumption Time: 0.90849
PPO Batch Consumption Time: 0.05189
Total Iteration Time: 6.47923

Cumulative Model Updates: 22,249
Cumulative Timesteps: 371,168,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.46411
Policy Entropy: 1.01178
Value Function Loss: 2.05253

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.20859
Policy Update Magnitude: 0.03789
Value Function Update Magnitude: 0.03250

Collected Steps per Second: 8,753.86697
Overall Steps per Second: 7,658.31574

Timestep Collection Time: 5.71222
Timestep Consumption Time: 0.81715
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.52937

Cumulative Model Updates: 22,252
Cumulative Timesteps: 371,218,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 371218650...
Checkpoint 371218650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.35624
Policy Entropy: 1.00522
Value Function Loss: 1.83715

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.19435
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.02949

Collected Steps per Second: 8,896.84732
Overall Steps per Second: 7,762.99388

Timestep Collection Time: 5.62177
Timestep Consumption Time: 0.82111
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 6.44288

Cumulative Model Updates: 22,255
Cumulative Timesteps: 371,268,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.65033
Policy Entropy: 1.02300
Value Function Loss: 1.80481

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.02875

Collected Steps per Second: 8,383.93325
Overall Steps per Second: 7,336.07460

Timestep Collection Time: 5.96593
Timestep Consumption Time: 0.85215
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.81809

Cumulative Model Updates: 22,258
Cumulative Timesteps: 371,318,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 371318684...
Checkpoint 371318684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.04499
Policy Entropy: 1.02743
Value Function Loss: 1.90850

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.03596

Collected Steps per Second: 8,636.20176
Overall Steps per Second: 7,690.43217

Timestep Collection Time: 5.78958
Timestep Consumption Time: 0.71200
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.50159

Cumulative Model Updates: 22,261
Cumulative Timesteps: 371,368,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.45233
Policy Entropy: 1.03908
Value Function Loss: 2.00645

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.02679

Collected Steps per Second: 8,741.05497
Overall Steps per Second: 7,623.36266

Timestep Collection Time: 5.72265
Timestep Consumption Time: 0.83902
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.56167

Cumulative Model Updates: 22,264
Cumulative Timesteps: 371,418,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371418706...
Checkpoint 371418706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.79705
Policy Entropy: 1.03684
Value Function Loss: 2.11539

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.02923

Collected Steps per Second: 8,628.29525
Overall Steps per Second: 7,530.62815

Timestep Collection Time: 5.79836
Timestep Consumption Time: 0.84517
PPO Batch Consumption Time: 0.04884
Total Iteration Time: 6.64354

Cumulative Model Updates: 22,267
Cumulative Timesteps: 371,468,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.19617
Policy Entropy: 1.02998
Value Function Loss: 2.16062

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.03141

Collected Steps per Second: 8,858.02588
Overall Steps per Second: 7,712.56166

Timestep Collection Time: 5.64663
Timestep Consumption Time: 0.83863
PPO Batch Consumption Time: 0.04599
Total Iteration Time: 6.48526

Cumulative Model Updates: 22,270
Cumulative Timesteps: 371,518,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 371518754...
Checkpoint 371518754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.83698
Policy Entropy: 1.00775
Value Function Loss: 2.17232

Mean KL Divergence: 0.03887
SB3 Clip Fraction: 0.27039
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.02860

Collected Steps per Second: 8,588.63981
Overall Steps per Second: 7,482.65896

Timestep Collection Time: 5.82234
Timestep Consumption Time: 0.86058
PPO Batch Consumption Time: 0.04789
Total Iteration Time: 6.68292

Cumulative Model Updates: 22,273
Cumulative Timesteps: 371,568,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.01369
Policy Entropy: 1.02653
Value Function Loss: 2.21110

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.18809
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 8,586.96147
Overall Steps per Second: 7,599.81936

Timestep Collection Time: 5.82371
Timestep Consumption Time: 0.75644
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.58016

Cumulative Model Updates: 22,276
Cumulative Timesteps: 371,618,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 371618768...
Checkpoint 371618768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.54045
Policy Entropy: 1.03501
Value Function Loss: 2.25478

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.19374
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.02858

Collected Steps per Second: 8,543.63218
Overall Steps per Second: 7,436.79774

Timestep Collection Time: 5.85442
Timestep Consumption Time: 0.87133
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 6.72574

Cumulative Model Updates: 22,279
Cumulative Timesteps: 371,668,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.68119
Policy Entropy: 1.02363
Value Function Loss: 2.20737

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.17807
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.02538

Collected Steps per Second: 8,641.66293
Overall Steps per Second: 7,606.89020

Timestep Collection Time: 5.78639
Timestep Consumption Time: 0.78713
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 6.57351

Cumulative Model Updates: 22,282
Cumulative Timesteps: 371,718,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 371718790...
Checkpoint 371718790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.92773
Policy Entropy: 1.02175
Value Function Loss: 2.19236

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.19487
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.02680

Collected Steps per Second: 8,673.59739
Overall Steps per Second: 7,548.69553

Timestep Collection Time: 5.76623
Timestep Consumption Time: 0.85928
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 6.62552

Cumulative Model Updates: 22,285
Cumulative Timesteps: 371,768,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.97094
Policy Entropy: 1.03592
Value Function Loss: 2.24780

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.19849
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.02646

Collected Steps per Second: 8,792.66590
Overall Steps per Second: 7,645.14480

Timestep Collection Time: 5.68701
Timestep Consumption Time: 0.85361
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.54062

Cumulative Model Updates: 22,288
Cumulative Timesteps: 371,818,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 371818808...
Checkpoint 371818808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.23237
Policy Entropy: 1.02893
Value Function Loss: 2.17441

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.03465
Value Function Update Magnitude: 0.02548

Collected Steps per Second: 8,918.93642
Overall Steps per Second: 7,828.90173

Timestep Collection Time: 5.60762
Timestep Consumption Time: 0.78076
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 6.38838

Cumulative Model Updates: 22,291
Cumulative Timesteps: 371,868,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.18550
Policy Entropy: 1.01741
Value Function Loss: 2.03862

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.18639
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.02585

Collected Steps per Second: 8,803.73268
Overall Steps per Second: 7,690.26688

Timestep Collection Time: 5.68191
Timestep Consumption Time: 0.82268
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.50459

Cumulative Model Updates: 22,294
Cumulative Timesteps: 371,918,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371918844...
Checkpoint 371918844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.46555
Policy Entropy: 1.00704
Value Function Loss: 1.98139

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.25129
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.02655

Collected Steps per Second: 8,677.20290
Overall Steps per Second: 7,563.66482

Timestep Collection Time: 5.76269
Timestep Consumption Time: 0.84839
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 6.61108

Cumulative Model Updates: 22,297
Cumulative Timesteps: 371,968,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.73870
Policy Entropy: 1.00962
Value Function Loss: 1.99224

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.19600
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.02924

Collected Steps per Second: 8,583.83614
Overall Steps per Second: 7,467.14233

Timestep Collection Time: 5.82490
Timestep Consumption Time: 0.87110
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.69600

Cumulative Model Updates: 22,300
Cumulative Timesteps: 372,018,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 372018848...
Checkpoint 372018848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.36278
Policy Entropy: 1.01494
Value Function Loss: 1.99512

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.23660
Policy Update Magnitude: 0.03623
Value Function Update Magnitude: 0.02488

Collected Steps per Second: 8,771.36723
Overall Steps per Second: 7,605.53574

Timestep Collection Time: 5.70196
Timestep Consumption Time: 0.87404
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.57600

Cumulative Model Updates: 22,303
Cumulative Timesteps: 372,068,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.21275
Policy Entropy: 0.97592
Value Function Loss: 1.84642

Mean KL Divergence: 0.02819
SB3 Clip Fraction: 0.24615
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.02315

Collected Steps per Second: 8,834.46505
Overall Steps per Second: 7,786.20515

Timestep Collection Time: 5.66214
Timestep Consumption Time: 0.76230
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.42444

Cumulative Model Updates: 22,306
Cumulative Timesteps: 372,118,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 372118884...
Checkpoint 372118884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.08320
Policy Entropy: 1.00456
Value Function Loss: 1.86047

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.21463
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.03086

Collected Steps per Second: 8,338.15593
Overall Steps per Second: 7,319.89704

Timestep Collection Time: 5.99677
Timestep Consumption Time: 0.83420
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 6.83097

Cumulative Model Updates: 22,309
Cumulative Timesteps: 372,168,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.45303
Policy Entropy: 1.00510
Value Function Loss: 1.79545

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.19169
Policy Update Magnitude: 0.03798
Value Function Update Magnitude: 0.02943

Collected Steps per Second: 7,920.26440
Overall Steps per Second: 6,603.55355

Timestep Collection Time: 6.31646
Timestep Consumption Time: 1.25947
PPO Batch Consumption Time: 0.05268
Total Iteration Time: 7.57592

Cumulative Model Updates: 22,312
Cumulative Timesteps: 372,218,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 372218914...
Checkpoint 372218914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.82002
Policy Entropy: 0.99309
Value Function Loss: 1.73110

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.17825
Policy Update Magnitude: 0.03778
Value Function Update Magnitude: 0.03073

Collected Steps per Second: 8,536.10158
Overall Steps per Second: 7,393.68256

Timestep Collection Time: 5.85982
Timestep Consumption Time: 0.90542
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 6.76523

Cumulative Model Updates: 22,315
Cumulative Timesteps: 372,268,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.68278
Policy Entropy: 0.98747
Value Function Loss: 1.79514

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.20084
Policy Update Magnitude: 0.03472
Value Function Update Magnitude: 0.03321

Collected Steps per Second: 8,836.12978
Overall Steps per Second: 7,694.45277

Timestep Collection Time: 5.65926
Timestep Consumption Time: 0.83970
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.49897

Cumulative Model Updates: 22,318
Cumulative Timesteps: 372,318,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 372318940...
Checkpoint 372318940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.08106
Policy Entropy: 0.99489
Value Function Loss: 1.90429

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.19014
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.03962

Collected Steps per Second: 8,964.36512
Overall Steps per Second: 7,861.12670

Timestep Collection Time: 5.58009
Timestep Consumption Time: 0.78312
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.36321

Cumulative Model Updates: 22,321
Cumulative Timesteps: 372,368,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.50818
Policy Entropy: 0.99548
Value Function Loss: 2.02272

Mean KL Divergence: 0.02598
SB3 Clip Fraction: 0.23243
Policy Update Magnitude: 0.03294
Value Function Update Magnitude: 0.03530

Collected Steps per Second: 8,777.50023
Overall Steps per Second: 7,587.59328

Timestep Collection Time: 5.69866
Timestep Consumption Time: 0.89368
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.59234

Cumulative Model Updates: 22,324
Cumulative Timesteps: 372,418,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 372418982...
Checkpoint 372418982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.12139
Policy Entropy: 0.98181
Value Function Loss: 1.92583

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.17654
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.03126

Collected Steps per Second: 8,428.89620
Overall Steps per Second: 7,366.39547

Timestep Collection Time: 5.93221
Timestep Consumption Time: 0.85564
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.78785

Cumulative Model Updates: 22,327
Cumulative Timesteps: 372,468,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.15259
Policy Entropy: 0.95967
Value Function Loss: 1.91635

Mean KL Divergence: 0.03249
SB3 Clip Fraction: 0.27497
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.02989

Collected Steps per Second: 8,713.27593
Overall Steps per Second: 7,685.54421

Timestep Collection Time: 5.73860
Timestep Consumption Time: 0.76738
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.50598

Cumulative Model Updates: 22,330
Cumulative Timesteps: 372,518,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 372518986...
Checkpoint 372518986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.90709
Policy Entropy: 0.97102
Value Function Loss: 1.80160

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.20087
Policy Update Magnitude: 0.03607
Value Function Update Magnitude: 0.03068

Collected Steps per Second: 8,862.20860
Overall Steps per Second: 7,684.89574

Timestep Collection Time: 5.64442
Timestep Consumption Time: 0.86471
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.50913

Cumulative Model Updates: 22,333
Cumulative Timesteps: 372,569,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.13826
Policy Entropy: 0.97113
Value Function Loss: 1.80687

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.23749
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.02815

Collected Steps per Second: 8,992.98748
Overall Steps per Second: 7,644.31755

Timestep Collection Time: 5.56233
Timestep Consumption Time: 0.98135
PPO Batch Consumption Time: 0.05011
Total Iteration Time: 6.54368

Cumulative Model Updates: 22,336
Cumulative Timesteps: 372,619,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 372619030...
Checkpoint 372619030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.14420
Policy Entropy: 0.94654
Value Function Loss: 1.68203

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.19067
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.02869

Collected Steps per Second: 8,449.13453
Overall Steps per Second: 7,340.24562

Timestep Collection Time: 5.92061
Timestep Consumption Time: 0.89442
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.81503

Cumulative Model Updates: 22,339
Cumulative Timesteps: 372,669,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.54780
Policy Entropy: 0.91919
Value Function Loss: 1.73289

Mean KL Divergence: 0.04851
SB3 Clip Fraction: 0.31065
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.02989

Collected Steps per Second: 8,955.30732
Overall Steps per Second: 7,754.81655

Timestep Collection Time: 5.58462
Timestep Consumption Time: 0.86453
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.44915

Cumulative Model Updates: 22,342
Cumulative Timesteps: 372,719,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 372719066...
Checkpoint 372719066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.82543
Policy Entropy: 0.96122
Value Function Loss: 1.70033

Mean KL Divergence: 0.03914
SB3 Clip Fraction: 0.28421
Policy Update Magnitude: 0.04206
Value Function Update Magnitude: 0.03941

Collected Steps per Second: 8,805.83989
Overall Steps per Second: 7,750.14848

Timestep Collection Time: 5.67919
Timestep Consumption Time: 0.77359
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.45278

Cumulative Model Updates: 22,345
Cumulative Timesteps: 372,769,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.74188
Policy Entropy: 0.92942
Value Function Loss: 1.78496

Mean KL Divergence: 0.04232
SB3 Clip Fraction: 0.30309
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.04312

Collected Steps per Second: 9,044.11746
Overall Steps per Second: 7,715.74504

Timestep Collection Time: 5.52846
Timestep Consumption Time: 0.95180
PPO Batch Consumption Time: 0.05093
Total Iteration Time: 6.48026

Cumulative Model Updates: 22,348
Cumulative Timesteps: 372,819,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 372819076...
Checkpoint 372819076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.91437
Policy Entropy: 0.96648
Value Function Loss: 1.70140

Mean KL Divergence: 0.03887
SB3 Clip Fraction: 0.28349
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.04011

Collected Steps per Second: 8,559.79776
Overall Steps per Second: 7,488.01246

Timestep Collection Time: 5.84173
Timestep Consumption Time: 0.83615
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.67787

Cumulative Model Updates: 22,351
Cumulative Timesteps: 372,869,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.61972
Policy Entropy: 0.97272
Value Function Loss: 1.73576

Mean KL Divergence: 0.03073
SB3 Clip Fraction: 0.24764
Policy Update Magnitude: 0.03843
Value Function Update Magnitude: 0.03573

Collected Steps per Second: 8,843.04367
Overall Steps per Second: 7,706.00427

Timestep Collection Time: 5.65439
Timestep Consumption Time: 0.83432
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.48871

Cumulative Model Updates: 22,354
Cumulative Timesteps: 372,919,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 372919082...
Checkpoint 372919082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.22719
Policy Entropy: 0.96199
Value Function Loss: 1.77090

Mean KL Divergence: 0.02825
SB3 Clip Fraction: 0.25231
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.03805

Collected Steps per Second: 8,760.84179
Overall Steps per Second: 7,623.67706

Timestep Collection Time: 5.70973
Timestep Consumption Time: 0.85168
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.56140

Cumulative Model Updates: 22,357
Cumulative Timesteps: 372,969,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.11926
Policy Entropy: 0.95827
Value Function Loss: 1.94209

Mean KL Divergence: 0.03414
SB3 Clip Fraction: 0.29409
Policy Update Magnitude: 0.03175
Value Function Update Magnitude: 0.03580

Collected Steps per Second: 8,608.59677
Overall Steps per Second: 7,597.31963

Timestep Collection Time: 5.80884
Timestep Consumption Time: 0.77321
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.58206

Cumulative Model Updates: 22,360
Cumulative Timesteps: 373,019,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 373019110...
Checkpoint 373019110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.64366
Policy Entropy: 0.96802
Value Function Loss: 2.11457

Mean KL Divergence: 0.03061
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.03999
Value Function Update Magnitude: 0.03367

Collected Steps per Second: 8,594.69767
Overall Steps per Second: 7,523.79595

Timestep Collection Time: 5.81847
Timestep Consumption Time: 0.82817
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.64664

Cumulative Model Updates: 22,363
Cumulative Timesteps: 373,069,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.12696
Policy Entropy: 0.98573
Value Function Loss: 2.12270

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.25612
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.04350

Collected Steps per Second: 8,339.68707
Overall Steps per Second: 7,274.23889

Timestep Collection Time: 5.99687
Timestep Consumption Time: 0.87835
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 6.87522

Cumulative Model Updates: 22,366
Cumulative Timesteps: 373,119,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 373119130...
Checkpoint 373119130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.90372
Policy Entropy: 0.95478
Value Function Loss: 1.97149

Mean KL Divergence: 0.02754
SB3 Clip Fraction: 0.22441
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.03823

Collected Steps per Second: 8,991.96803
Overall Steps per Second: 7,816.29659

Timestep Collection Time: 5.56274
Timestep Consumption Time: 0.83671
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 6.39945

Cumulative Model Updates: 22,369
Cumulative Timesteps: 373,169,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.33995
Policy Entropy: 0.97532
Value Function Loss: 2.01109

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.24761
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.03911

Collected Steps per Second: 8,797.42726
Overall Steps per Second: 7,679.30217

Timestep Collection Time: 5.68530
Timestep Consumption Time: 0.82779
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 6.51309

Cumulative Model Updates: 22,372
Cumulative Timesteps: 373,219,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 373219166...
Checkpoint 373219166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.18755
Policy Entropy: 0.97613
Value Function Loss: 2.01832

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.25629
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.03772

Collected Steps per Second: 8,684.13876
Overall Steps per Second: 7,709.65035

Timestep Collection Time: 5.76039
Timestep Consumption Time: 0.72810
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.48849

Cumulative Model Updates: 22,375
Cumulative Timesteps: 373,269,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.77039
Policy Entropy: 0.97007
Value Function Loss: 1.97923

Mean KL Divergence: 0.02589
SB3 Clip Fraction: 0.21745
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.03708

Collected Steps per Second: 8,757.60746
Overall Steps per Second: 7,583.02559

Timestep Collection Time: 5.71092
Timestep Consumption Time: 0.88460
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.59552

Cumulative Model Updates: 22,378
Cumulative Timesteps: 373,319,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 373319204...
Checkpoint 373319204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.49234
Policy Entropy: 0.96817
Value Function Loss: 1.97291

Mean KL Divergence: 0.03554
SB3 Clip Fraction: 0.29320
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.03435

Collected Steps per Second: 8,325.19818
Overall Steps per Second: 7,314.69815

Timestep Collection Time: 6.00634
Timestep Consumption Time: 0.82976
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 6.83610

Cumulative Model Updates: 22,381
Cumulative Timesteps: 373,369,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.70756
Policy Entropy: 0.98671
Value Function Loss: 2.10658

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.20966
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.03274

Collected Steps per Second: 8,854.07644
Overall Steps per Second: 7,644.45727

Timestep Collection Time: 5.64960
Timestep Consumption Time: 0.89396
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.54356

Cumulative Model Updates: 22,384
Cumulative Timesteps: 373,419,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 373419230...
Checkpoint 373419230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.37784
Policy Entropy: 1.00905
Value Function Loss: 2.05412

Mean KL Divergence: 0.03112
SB3 Clip Fraction: 0.21843
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.03755

Collected Steps per Second: 8,755.35644
Overall Steps per Second: 7,655.53527

Timestep Collection Time: 5.71102
Timestep Consumption Time: 0.82047
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.53148

Cumulative Model Updates: 22,387
Cumulative Timesteps: 373,469,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.23344
Policy Entropy: 0.99065
Value Function Loss: 1.92682

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.20572
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.03702

Collected Steps per Second: 8,786.07849
Overall Steps per Second: 7,712.26769

Timestep Collection Time: 5.69287
Timestep Consumption Time: 0.79264
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 6.48551

Cumulative Model Updates: 22,390
Cumulative Timesteps: 373,519,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 373519250...
Checkpoint 373519250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.43099
Policy Entropy: 0.97351
Value Function Loss: 1.88079

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.27105
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.03572

Collected Steps per Second: 8,868.91813
Overall Steps per Second: 7,496.51734

Timestep Collection Time: 5.63767
Timestep Consumption Time: 1.03210
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 6.66976

Cumulative Model Updates: 22,393
Cumulative Timesteps: 373,569,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.58688
Policy Entropy: 0.99368
Value Function Loss: 2.02081

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.16855
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.03806

Collected Steps per Second: 8,820.57736
Overall Steps per Second: 7,703.81104

Timestep Collection Time: 5.67083
Timestep Consumption Time: 0.82206
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 6.49289

Cumulative Model Updates: 22,396
Cumulative Timesteps: 373,619,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 373619270...
Checkpoint 373619270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.77921
Policy Entropy: 1.00069
Value Function Loss: 2.02413

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.21367
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.03370

Collected Steps per Second: 8,857.62274
Overall Steps per Second: 7,800.08211

Timestep Collection Time: 5.64689
Timestep Consumption Time: 0.76561
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 6.41250

Cumulative Model Updates: 22,399
Cumulative Timesteps: 373,669,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.33957
Policy Entropy: 0.97808
Value Function Loss: 1.81119

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.03107

Collected Steps per Second: 8,999.89576
Overall Steps per Second: 7,793.22816

Timestep Collection Time: 5.55740
Timestep Consumption Time: 0.86048
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.41788

Cumulative Model Updates: 22,402
Cumulative Timesteps: 373,719,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 373719304...
Checkpoint 373719304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.61789
Policy Entropy: 0.97054
Value Function Loss: 1.87811

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.23857
Policy Update Magnitude: 0.03952
Value Function Update Magnitude: 0.02991

Collected Steps per Second: 8,828.57806
Overall Steps per Second: 7,782.21571

Timestep Collection Time: 5.66547
Timestep Consumption Time: 0.76175
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.42722

Cumulative Model Updates: 22,405
Cumulative Timesteps: 373,769,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.90506
Policy Entropy: 0.99100
Value Function Loss: 2.04845

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.03177

Collected Steps per Second: 8,496.31372
Overall Steps per Second: 7,376.88452

Timestep Collection Time: 5.88538
Timestep Consumption Time: 0.89310
PPO Batch Consumption Time: 0.04870
Total Iteration Time: 6.77847

Cumulative Model Updates: 22,408
Cumulative Timesteps: 373,819,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 373819326...
Checkpoint 373819326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.72636
Policy Entropy: 1.01822
Value Function Loss: 2.10266

Mean KL Divergence: 0.03025
SB3 Clip Fraction: 0.27477
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.03134

Collected Steps per Second: 8,827.82094
Overall Steps per Second: 7,788.40066

Timestep Collection Time: 5.66595
Timestep Consumption Time: 0.75616
PPO Batch Consumption Time: 0.04772
Total Iteration Time: 6.42211

Cumulative Model Updates: 22,411
Cumulative Timesteps: 373,869,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.06593
Policy Entropy: 0.98487
Value Function Loss: 2.12423

Mean KL Divergence: 0.03578
SB3 Clip Fraction: 0.26640
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.03391

Collected Steps per Second: 8,653.90364
Overall Steps per Second: 7,507.19967

Timestep Collection Time: 5.77774
Timestep Consumption Time: 0.88253
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.66027

Cumulative Model Updates: 22,414
Cumulative Timesteps: 373,919,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 373919344...
Checkpoint 373919344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.02149
Policy Entropy: 1.02077
Value Function Loss: 2.02124

Mean KL Divergence: 0.03272
SB3 Clip Fraction: 0.26923
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.03059

Collected Steps per Second: 8,916.34378
Overall Steps per Second: 7,746.11363

Timestep Collection Time: 5.60768
Timestep Consumption Time: 0.84717
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.45485

Cumulative Model Updates: 22,417
Cumulative Timesteps: 373,969,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.09571
Policy Entropy: 0.98798
Value Function Loss: 1.94467

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.23929
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 8,601.11804
Overall Steps per Second: 7,583.69201

Timestep Collection Time: 5.81366
Timestep Consumption Time: 0.77996
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 6.59362

Cumulative Model Updates: 22,420
Cumulative Timesteps: 374,019,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 374019348...
Checkpoint 374019348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.30560
Policy Entropy: 1.03481
Value Function Loss: 2.10667

Mean KL Divergence: 0.04616
SB3 Clip Fraction: 0.30265
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.05012

Collected Steps per Second: 8,555.41545
Overall Steps per Second: 7,415.21001

Timestep Collection Time: 5.84776
Timestep Consumption Time: 0.89919
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.74694

Cumulative Model Updates: 22,423
Cumulative Timesteps: 374,069,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.58216
Policy Entropy: 1.02834
Value Function Loss: 2.17350

Mean KL Divergence: 0.03431
SB3 Clip Fraction: 0.27189
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.04541

Collected Steps per Second: 8,693.42905
Overall Steps per Second: 7,603.06141

Timestep Collection Time: 5.75492
Timestep Consumption Time: 0.82532
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.58024

Cumulative Model Updates: 22,426
Cumulative Timesteps: 374,119,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 374119408...
Checkpoint 374119408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.00595
Policy Entropy: 1.03849
Value Function Loss: 2.21889

Mean KL Divergence: 0.02944
SB3 Clip Fraction: 0.22661
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.03538

Collected Steps per Second: 8,616.15586
Overall Steps per Second: 7,445.44785

Timestep Collection Time: 5.80468
Timestep Consumption Time: 0.91272
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 6.71739

Cumulative Model Updates: 22,429
Cumulative Timesteps: 374,169,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.75396
Policy Entropy: 0.99591
Value Function Loss: 2.01488

Mean KL Divergence: 0.05638
SB3 Clip Fraction: 0.34300
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 8,810.17894
Overall Steps per Second: 7,635.62972

Timestep Collection Time: 5.67684
Timestep Consumption Time: 0.87324
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.55008

Cumulative Model Updates: 22,432
Cumulative Timesteps: 374,219,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 374219436...
Checkpoint 374219436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.18496
Policy Entropy: 1.04175
Value Function Loss: 2.06817

Mean KL Divergence: 0.03763
SB3 Clip Fraction: 0.28563
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 8,452.32210
Overall Steps per Second: 7,473.19151

Timestep Collection Time: 5.91837
Timestep Consumption Time: 0.77542
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.69379

Cumulative Model Updates: 22,435
Cumulative Timesteps: 374,269,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.48138
Policy Entropy: 0.99443
Value Function Loss: 2.25385

Mean KL Divergence: 0.05990
SB3 Clip Fraction: 0.36079
Policy Update Magnitude: 0.03828
Value Function Update Magnitude: 0.04944

Collected Steps per Second: 8,922.53814
Overall Steps per Second: 7,723.94741

Timestep Collection Time: 5.60536
Timestep Consumption Time: 0.86983
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 6.47519

Cumulative Model Updates: 22,438
Cumulative Timesteps: 374,319,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 374319474...
Checkpoint 374319474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.83220
Policy Entropy: 1.03182
Value Function Loss: 2.19600

Mean KL Divergence: 0.03901
SB3 Clip Fraction: 0.26768
Policy Update Magnitude: 0.03484
Value Function Update Magnitude: 0.03880

Collected Steps per Second: 8,828.18664
Overall Steps per Second: 7,643.06148

Timestep Collection Time: 5.66526
Timestep Consumption Time: 0.87845
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.54371

Cumulative Model Updates: 22,441
Cumulative Timesteps: 374,369,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.11561
Policy Entropy: 0.99899
Value Function Loss: 2.31098

Mean KL Divergence: 0.03703
SB3 Clip Fraction: 0.25843
Policy Update Magnitude: 0.03887
Value Function Update Magnitude: 0.03808

Collected Steps per Second: 8,677.57961
Overall Steps per Second: 7,593.81652

Timestep Collection Time: 5.76497
Timestep Consumption Time: 0.82276
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 6.58773

Cumulative Model Updates: 22,444
Cumulative Timesteps: 374,419,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 374419514...
Checkpoint 374419514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.16017
Policy Entropy: 1.01590
Value Function Loss: 2.18788

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.24163
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.03737

Collected Steps per Second: 8,399.61133
Overall Steps per Second: 7,278.38955

Timestep Collection Time: 5.95337
Timestep Consumption Time: 0.91711
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 6.87048

Cumulative Model Updates: 22,447
Cumulative Timesteps: 374,469,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.07057
Policy Entropy: 1.00853
Value Function Loss: 2.09678

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.24048
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.03193

Collected Steps per Second: 8,873.49391
Overall Steps per Second: 7,589.42307

Timestep Collection Time: 5.63791
Timestep Consumption Time: 0.95389
PPO Batch Consumption Time: 0.05845
Total Iteration Time: 6.59181

Cumulative Model Updates: 22,450
Cumulative Timesteps: 374,519,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 374519548...
Checkpoint 374519548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.92996
Policy Entropy: 1.01645
Value Function Loss: 2.11760

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.20299
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.03441

Collected Steps per Second: 9,060.34788
Overall Steps per Second: 7,818.99673

Timestep Collection Time: 5.51855
Timestep Consumption Time: 0.87613
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 6.39468

Cumulative Model Updates: 22,453
Cumulative Timesteps: 374,569,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.51778
Policy Entropy: 1.00020
Value Function Loss: 1.85889

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.17404
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.03092

Collected Steps per Second: 9,174.19429
Overall Steps per Second: 7,919.50650

Timestep Collection Time: 5.45160
Timestep Consumption Time: 0.86370
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 6.31529

Cumulative Model Updates: 22,456
Cumulative Timesteps: 374,619,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 374619562...
Checkpoint 374619562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.88525
Policy Entropy: 0.99708
Value Function Loss: 1.90233

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.19244
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.03939

Collected Steps per Second: 8,928.54912
Overall Steps per Second: 7,875.56048

Timestep Collection Time: 5.60270
Timestep Consumption Time: 0.74910
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.35180

Cumulative Model Updates: 22,459
Cumulative Timesteps: 374,669,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.32824
Policy Entropy: 1.00435
Value Function Loss: 1.89409

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.19809
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.04320

Collected Steps per Second: 8,432.32071
Overall Steps per Second: 7,386.39028

Timestep Collection Time: 5.93146
Timestep Consumption Time: 0.83991
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.77137

Cumulative Model Updates: 22,462
Cumulative Timesteps: 374,719,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 374719602...
Checkpoint 374719602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.33025
Policy Entropy: 1.01741
Value Function Loss: 2.14897

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.19741
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.03755

Collected Steps per Second: 8,731.40350
Overall Steps per Second: 7,643.51242

Timestep Collection Time: 5.72829
Timestep Consumption Time: 0.81530
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.54359

Cumulative Model Updates: 22,465
Cumulative Timesteps: 374,769,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.24796
Policy Entropy: 0.99298
Value Function Loss: 2.10325

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.18791
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 8,827.60049
Overall Steps per Second: 7,775.40563

Timestep Collection Time: 5.66428
Timestep Consumption Time: 0.76651
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 6.43079

Cumulative Model Updates: 22,468
Cumulative Timesteps: 374,819,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 374819620...
Checkpoint 374819620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.83298
Policy Entropy: 0.99169
Value Function Loss: 2.21740

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.20885
Policy Update Magnitude: 0.03820
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 8,778.37063
Overall Steps per Second: 7,668.56504

Timestep Collection Time: 5.69764
Timestep Consumption Time: 0.82457
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.52221

Cumulative Model Updates: 22,471
Cumulative Timesteps: 374,869,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.58130
Policy Entropy: 1.00990
Value Function Loss: 2.27408

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.17952
Policy Update Magnitude: 0.03756
Value Function Update Magnitude: 0.04711

Collected Steps per Second: 8,733.64717
Overall Steps per Second: 7,613.98549

Timestep Collection Time: 5.72819
Timestep Consumption Time: 0.84235
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.57054

Cumulative Model Updates: 22,474
Cumulative Timesteps: 374,919,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 374919664...
Checkpoint 374919664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.75568
Policy Entropy: 1.01121
Value Function Loss: 2.19004

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.20165
Policy Update Magnitude: 0.03533
Value Function Update Magnitude: 0.04196

Collected Steps per Second: 8,652.80623
Overall Steps per Second: 7,546.16915

Timestep Collection Time: 5.78101
Timestep Consumption Time: 0.84778
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.62879

Cumulative Model Updates: 22,477
Cumulative Timesteps: 374,969,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.32376
Policy Entropy: 0.99756
Value Function Loss: 1.98727

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.20023
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.04140

Collected Steps per Second: 8,621.53137
Overall Steps per Second: 7,546.29984

Timestep Collection Time: 5.80199
Timestep Consumption Time: 0.82669
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.62868

Cumulative Model Updates: 22,480
Cumulative Timesteps: 375,019,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 375019708...
Checkpoint 375019708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.24979
Policy Entropy: 0.97497
Value Function Loss: 1.92422

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.26787
Policy Update Magnitude: 0.04021
Value Function Update Magnitude: 0.03702

Collected Steps per Second: 8,765.23319
Overall Steps per Second: 7,695.09817

Timestep Collection Time: 5.70435
Timestep Consumption Time: 0.79329
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.49764

Cumulative Model Updates: 22,483
Cumulative Timesteps: 375,069,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.62081
Policy Entropy: 0.98733
Value Function Loss: 2.09519

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.18890
Policy Update Magnitude: 0.03753
Value Function Update Magnitude: 0.03965

Collected Steps per Second: 8,852.30314
Overall Steps per Second: 7,673.68874

Timestep Collection Time: 5.65051
Timestep Consumption Time: 0.86787
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.51838

Cumulative Model Updates: 22,486
Cumulative Timesteps: 375,119,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 375119728...
Checkpoint 375119728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.32580
Policy Entropy: 0.99333
Value Function Loss: 2.04137

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.19454
Policy Update Magnitude: 0.03398
Value Function Update Magnitude: 0.03562

Collected Steps per Second: 8,612.57928
Overall Steps per Second: 7,452.00251

Timestep Collection Time: 5.80546
Timestep Consumption Time: 0.90414
PPO Batch Consumption Time: 0.05133
Total Iteration Time: 6.70961

Cumulative Model Updates: 22,489
Cumulative Timesteps: 375,169,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.47712
Policy Entropy: 0.97179
Value Function Loss: 1.71783

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.03889
Value Function Update Magnitude: 0.03379

Collected Steps per Second: 8,853.13261
Overall Steps per Second: 7,696.66209

Timestep Collection Time: 5.65020
Timestep Consumption Time: 0.84898
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.49918

Cumulative Model Updates: 22,492
Cumulative Timesteps: 375,219,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 375219750...
Checkpoint 375219750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.95430
Policy Entropy: 0.93524
Value Function Loss: 1.51900

Mean KL Divergence: 0.05723
SB3 Clip Fraction: 0.31445
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 8,832.33934
Overall Steps per Second: 7,670.65309

Timestep Collection Time: 5.66169
Timestep Consumption Time: 0.85744
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.51913

Cumulative Model Updates: 22,495
Cumulative Timesteps: 375,269,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.12231
Policy Entropy: 0.98181
Value Function Loss: 1.55222

Mean KL Divergence: 0.04146
SB3 Clip Fraction: 0.28189
Policy Update Magnitude: 0.03649
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 8,728.61680
Overall Steps per Second: 7,706.00165

Timestep Collection Time: 5.73149
Timestep Consumption Time: 0.76059
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.49208

Cumulative Model Updates: 22,498
Cumulative Timesteps: 375,319,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 375319784...
Checkpoint 375319784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.70475
Policy Entropy: 0.93758
Value Function Loss: 1.88285

Mean KL Divergence: 0.05718
SB3 Clip Fraction: 0.35161
Policy Update Magnitude: 0.03370
Value Function Update Magnitude: 0.05282

Collected Steps per Second: 8,740.29857
Overall Steps per Second: 7,576.11295

Timestep Collection Time: 5.72086
Timestep Consumption Time: 0.87910
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 6.59995

Cumulative Model Updates: 22,501
Cumulative Timesteps: 375,369,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.10000
Policy Entropy: 1.00016
Value Function Loss: 2.01720

Mean KL Divergence: 0.05410
SB3 Clip Fraction: 0.34328
Policy Update Magnitude: 0.03333
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 8,580.10929
Overall Steps per Second: 7,509.83928

Timestep Collection Time: 5.82743
Timestep Consumption Time: 0.83050
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 6.65793

Cumulative Model Updates: 22,504
Cumulative Timesteps: 375,419,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 375419786...
Checkpoint 375419786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.21802
Policy Entropy: 0.94041
Value Function Loss: 2.19003

Mean KL Divergence: 0.07418
SB3 Clip Fraction: 0.41703
Policy Update Magnitude: 0.03291
Value Function Update Magnitude: 0.05328

Collected Steps per Second: 8,647.19799
Overall Steps per Second: 7,523.32807

Timestep Collection Time: 5.78569
Timestep Consumption Time: 0.86429
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.64998

Cumulative Model Updates: 22,507
Cumulative Timesteps: 375,469,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.13920
Policy Entropy: 0.97943
Value Function Loss: 2.02647

Mean KL Divergence: 0.05540
SB3 Clip Fraction: 0.36921
Policy Update Magnitude: 0.02949
Value Function Update Magnitude: 0.04422

Collected Steps per Second: 8,828.97001
Overall Steps per Second: 7,664.44847

Timestep Collection Time: 5.66363
Timestep Consumption Time: 0.86052
PPO Batch Consumption Time: 0.05069
Total Iteration Time: 6.52415

Cumulative Model Updates: 22,510
Cumulative Timesteps: 375,519,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 375519820...
Checkpoint 375519820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.20322
Policy Entropy: 0.95689
Value Function Loss: 1.84765

Mean KL Divergence: 0.05695
SB3 Clip Fraction: 0.37671
Policy Update Magnitude: 0.03301
Value Function Update Magnitude: 0.03842

Collected Steps per Second: 8,710.72370
Overall Steps per Second: 7,553.59664

Timestep Collection Time: 5.74051
Timestep Consumption Time: 0.87938
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.61989

Cumulative Model Updates: 22,513
Cumulative Timesteps: 375,569,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.17242
Policy Entropy: 0.98461
Value Function Loss: 1.67235

Mean KL Divergence: 0.05982
SB3 Clip Fraction: 0.36189
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.04418

Collected Steps per Second: 8,959.04257
Overall Steps per Second: 7,627.94706

Timestep Collection Time: 5.58095
Timestep Consumption Time: 0.97389
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.55484

Cumulative Model Updates: 22,516
Cumulative Timesteps: 375,619,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 375619824...
Checkpoint 375619824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.86568
Policy Entropy: 0.96840
Value Function Loss: 1.66206

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.25352
Policy Update Magnitude: 0.03598
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 8,755.36241
Overall Steps per Second: 7,653.54381

Timestep Collection Time: 5.71238
Timestep Consumption Time: 0.82237
PPO Batch Consumption Time: 0.04648
Total Iteration Time: 6.53475

Cumulative Model Updates: 22,519
Cumulative Timesteps: 375,669,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.09343
Policy Entropy: 0.97472
Value Function Loss: 1.80301

Mean KL Divergence: 0.03543
SB3 Clip Fraction: 0.28790
Policy Update Magnitude: 0.03719
Value Function Update Magnitude: 0.06354

Collected Steps per Second: 8,780.89728
Overall Steps per Second: 7,693.20226

Timestep Collection Time: 5.69555
Timestep Consumption Time: 0.80526
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 6.50080

Cumulative Model Updates: 22,522
Cumulative Timesteps: 375,719,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 375719850...
Checkpoint 375719850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.44075
Policy Entropy: 0.97987
Value Function Loss: 1.96106

Mean KL Divergence: 0.03747
SB3 Clip Fraction: 0.27625
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 8,912.26935
Overall Steps per Second: 7,752.89736

Timestep Collection Time: 5.61339
Timestep Consumption Time: 0.83943
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.45281

Cumulative Model Updates: 22,525
Cumulative Timesteps: 375,769,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.32169
Policy Entropy: 0.98413
Value Function Loss: 2.08714

Mean KL Divergence: 0.03724
SB3 Clip Fraction: 0.27629
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.05308

Collected Steps per Second: 8,874.12294
Overall Steps per Second: 7,724.97101

Timestep Collection Time: 5.63549
Timestep Consumption Time: 0.83832
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.47381

Cumulative Model Updates: 22,528
Cumulative Timesteps: 375,819,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 375819888...
Checkpoint 375819888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.37444
Policy Entropy: 1.01203
Value Function Loss: 2.12546

Mean KL Divergence: 0.04944
SB3 Clip Fraction: 0.28807
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.04809

Collected Steps per Second: 8,563.68010
Overall Steps per Second: 7,427.57002

Timestep Collection Time: 5.84141
Timestep Consumption Time: 0.89349
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.73491

Cumulative Model Updates: 22,531
Cumulative Timesteps: 375,869,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.86941
Policy Entropy: 1.01980
Value Function Loss: 2.13837

Mean KL Divergence: 0.03185
SB3 Clip Fraction: 0.26451
Policy Update Magnitude: 0.04206
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 8,669.76739
Overall Steps per Second: 7,551.64744

Timestep Collection Time: 5.76924
Timestep Consumption Time: 0.85421
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.62346

Cumulative Model Updates: 22,534
Cumulative Timesteps: 375,919,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 375919930...
Checkpoint 375919930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.00757
Policy Entropy: 1.01238
Value Function Loss: 2.04829

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.03794

Collected Steps per Second: 8,699.11659
Overall Steps per Second: 7,706.26696

Timestep Collection Time: 5.74863
Timestep Consumption Time: 0.74063
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.48926

Cumulative Model Updates: 22,537
Cumulative Timesteps: 375,969,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.34635
Policy Entropy: 0.98648
Value Function Loss: 2.03504

Mean KL Divergence: 0.02865
SB3 Clip Fraction: 0.20151
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.03583

Collected Steps per Second: 8,583.35665
Overall Steps per Second: 7,488.96133

Timestep Collection Time: 5.82802
Timestep Consumption Time: 0.85168
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.67970

Cumulative Model Updates: 22,540
Cumulative Timesteps: 376,019,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 376019962...
Checkpoint 376019962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.24140
Policy Entropy: 1.03175
Value Function Loss: 2.09597

Mean KL Divergence: 0.03465
SB3 Clip Fraction: 0.27428
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.03969

Collected Steps per Second: 8,858.44132
Overall Steps per Second: 7,609.81753

Timestep Collection Time: 5.64456
Timestep Consumption Time: 0.92616
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 6.57072

Cumulative Model Updates: 22,543
Cumulative Timesteps: 376,069,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.34633
Policy Entropy: 1.01008
Value Function Loss: 2.16358

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.21622
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.03670

Collected Steps per Second: 8,489.79123
Overall Steps per Second: 7,480.62843

Timestep Collection Time: 5.89178
Timestep Consumption Time: 0.79482
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.68660

Cumulative Model Updates: 22,546
Cumulative Timesteps: 376,119,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 376119984...
Checkpoint 376119984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.88243
Policy Entropy: 1.02926
Value Function Loss: 2.12553

Mean KL Divergence: 0.02785
SB3 Clip Fraction: 0.20339
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.03664

Collected Steps per Second: 8,809.64391
Overall Steps per Second: 7,620.52760

Timestep Collection Time: 5.67560
Timestep Consumption Time: 0.88563
PPO Batch Consumption Time: 0.04473
Total Iteration Time: 6.56123

Cumulative Model Updates: 22,549
Cumulative Timesteps: 376,169,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.91108
Policy Entropy: 1.04350
Value Function Loss: 2.29219

Mean KL Divergence: 0.02857
SB3 Clip Fraction: 0.19294
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.03513

Collected Steps per Second: 8,593.70306
Overall Steps per Second: 7,474.65437

Timestep Collection Time: 5.82147
Timestep Consumption Time: 0.87155
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.69302

Cumulative Model Updates: 22,552
Cumulative Timesteps: 376,220,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 376220012...
Checkpoint 376220012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.64952
Policy Entropy: 1.05354
Value Function Loss: 2.21448

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.03742

Collected Steps per Second: 9,140.06055
Overall Steps per Second: 8,047.09321

Timestep Collection Time: 5.47196
Timestep Consumption Time: 0.74321
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.21516

Cumulative Model Updates: 22,555
Cumulative Timesteps: 376,270,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.00177
Policy Entropy: 1.03622
Value Function Loss: 2.31493

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.17875
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.03220

Collected Steps per Second: 8,761.65999
Overall Steps per Second: 7,568.66146

Timestep Collection Time: 5.70988
Timestep Consumption Time: 0.90001
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 6.60989

Cumulative Model Updates: 22,558
Cumulative Timesteps: 376,320,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 376320054...
Checkpoint 376320054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.75925
Policy Entropy: 1.04703
Value Function Loss: 2.02929

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.17317
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.02894

Collected Steps per Second: 9,172.50645
Overall Steps per Second: 7,875.87299

Timestep Collection Time: 5.45282
Timestep Consumption Time: 0.89772
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 6.35053

Cumulative Model Updates: 22,561
Cumulative Timesteps: 376,370,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.14222
Policy Entropy: 1.06459
Value Function Loss: 2.23097

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.17285
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.04442

Collected Steps per Second: 8,992.21605
Overall Steps per Second: 7,744.62876

Timestep Collection Time: 5.56303
Timestep Consumption Time: 0.89615
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.45919

Cumulative Model Updates: 22,564
Cumulative Timesteps: 376,420,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 376420094...
Checkpoint 376420094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.53170
Policy Entropy: 1.06465
Value Function Loss: 2.17058

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.17822
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.04390

Collected Steps per Second: 9,056.26669
Overall Steps per Second: 7,847.41936

Timestep Collection Time: 5.52303
Timestep Consumption Time: 0.85079
PPO Batch Consumption Time: 0.04765
Total Iteration Time: 6.37382

Cumulative Model Updates: 22,567
Cumulative Timesteps: 376,470,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.01622
Policy Entropy: 1.04850
Value Function Loss: 1.99699

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.05236

Collected Steps per Second: 8,948.89838
Overall Steps per Second: 7,878.76064

Timestep Collection Time: 5.58974
Timestep Consumption Time: 0.75923
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.34897

Cumulative Model Updates: 22,570
Cumulative Timesteps: 376,520,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 376520134...
Checkpoint 376520134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.58735
Policy Entropy: 1.01286
Value Function Loss: 1.93569

Mean KL Divergence: 0.04296
SB3 Clip Fraction: 0.26062
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.05306

Collected Steps per Second: 8,484.03048
Overall Steps per Second: 7,397.82722

Timestep Collection Time: 5.89460
Timestep Consumption Time: 0.86549
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 6.76009

Cumulative Model Updates: 22,573
Cumulative Timesteps: 376,570,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.01445
Policy Entropy: 1.05719
Value Function Loss: 1.87859

Mean KL Divergence: 0.04571
SB3 Clip Fraction: 0.25134
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.04825

Collected Steps per Second: 8,825.44229
Overall Steps per Second: 7,626.97763

Timestep Collection Time: 5.66748
Timestep Consumption Time: 0.89056
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 6.55804

Cumulative Model Updates: 22,576
Cumulative Timesteps: 376,620,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 376620162...
Checkpoint 376620162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.72829
Policy Entropy: 1.01728
Value Function Loss: 1.93191

Mean KL Divergence: 0.06100
SB3 Clip Fraction: 0.35067
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.05614

Collected Steps per Second: 8,710.15658
Overall Steps per Second: 7,597.73733

Timestep Collection Time: 5.74272
Timestep Consumption Time: 0.84082
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.58354

Cumulative Model Updates: 22,579
Cumulative Timesteps: 376,670,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.26905
Policy Entropy: 1.04751
Value Function Loss: 1.87039

Mean KL Divergence: 0.04230
SB3 Clip Fraction: 0.27172
Policy Update Magnitude: 0.03580
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 8,969.12293
Overall Steps per Second: 7,742.77028

Timestep Collection Time: 5.57803
Timestep Consumption Time: 0.88349
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 6.46151

Cumulative Model Updates: 22,582
Cumulative Timesteps: 376,720,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 376720212...
Checkpoint 376720212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.65286
Policy Entropy: 1.02852
Value Function Loss: 1.80851

Mean KL Divergence: 0.05080
SB3 Clip Fraction: 0.30040
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 8,516.59810
Overall Steps per Second: 7,546.95913

Timestep Collection Time: 5.87253
Timestep Consumption Time: 0.75451
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 6.62704

Cumulative Model Updates: 22,585
Cumulative Timesteps: 376,770,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.20359
Policy Entropy: 1.06051
Value Function Loss: 1.82207

Mean KL Divergence: 0.04293
SB3 Clip Fraction: 0.26033
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 8,800.52206
Overall Steps per Second: 7,634.76689

Timestep Collection Time: 5.68330
Timestep Consumption Time: 0.86778
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 6.55108

Cumulative Model Updates: 22,588
Cumulative Timesteps: 376,820,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 376820242...
Checkpoint 376820242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.96656
Policy Entropy: 1.04298
Value Function Loss: 1.79718

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.17530
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.04822

Collected Steps per Second: 8,470.59724
Overall Steps per Second: 7,456.78980

Timestep Collection Time: 5.90277
Timestep Consumption Time: 0.80253
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 6.70530

Cumulative Model Updates: 22,591
Cumulative Timesteps: 376,870,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.78693
Policy Entropy: 1.03858
Value Function Loss: 1.85427

Mean KL Divergence: 0.02997
SB3 Clip Fraction: 0.21341
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 9,036.66012
Overall Steps per Second: 7,815.98239

Timestep Collection Time: 5.53457
Timestep Consumption Time: 0.86437
PPO Batch Consumption Time: 0.04575
Total Iteration Time: 6.39894

Cumulative Model Updates: 22,594
Cumulative Timesteps: 376,920,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 376920256...
Checkpoint 376920256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.54069
Policy Entropy: 1.04771
Value Function Loss: 1.91465

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.04175

Collected Steps per Second: 8,605.22104
Overall Steps per Second: 7,516.36918

Timestep Collection Time: 5.81321
Timestep Consumption Time: 0.84213
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.65534

Cumulative Model Updates: 22,597
Cumulative Timesteps: 376,970,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.96370
Policy Entropy: 1.06341
Value Function Loss: 2.02806

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.17873
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.05146

Collected Steps per Second: 8,482.27440
Overall Steps per Second: 7,461.16604

Timestep Collection Time: 5.89677
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.70378

Cumulative Model Updates: 22,600
Cumulative Timesteps: 377,020,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 377020298...
Checkpoint 377020298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.80260
Policy Entropy: 1.03996
Value Function Loss: 2.08659

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 8,797.36571
Overall Steps per Second: 7,658.07807

Timestep Collection Time: 5.68602
Timestep Consumption Time: 0.84591
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 6.53193

Cumulative Model Updates: 22,603
Cumulative Timesteps: 377,070,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.24915
Policy Entropy: 1.03784
Value Function Loss: 1.98449

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.05565

Collected Steps per Second: 8,605.01807
Overall Steps per Second: 7,532.46317

Timestep Collection Time: 5.81219
Timestep Consumption Time: 0.82760
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.63979

Cumulative Model Updates: 22,606
Cumulative Timesteps: 377,120,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 377120334...
Checkpoint 377120334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.67293
Policy Entropy: 1.05403
Value Function Loss: 1.91884

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.05093

Collected Steps per Second: 8,856.22612
Overall Steps per Second: 7,741.64701

Timestep Collection Time: 5.64846
Timestep Consumption Time: 0.81322
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.46167

Cumulative Model Updates: 22,609
Cumulative Timesteps: 377,170,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.32971
Policy Entropy: 1.06194
Value Function Loss: 1.78791

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.16235
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 8,607.11345
Overall Steps per Second: 7,393.69360

Timestep Collection Time: 5.81240
Timestep Consumption Time: 0.95391
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 6.76631

Cumulative Model Updates: 22,612
Cumulative Timesteps: 377,220,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 377220386...
Checkpoint 377220386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.71676
Policy Entropy: 1.04819
Value Function Loss: 1.79603

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 8,771.67063
Overall Steps per Second: 7,703.21084

Timestep Collection Time: 5.70245
Timestep Consumption Time: 0.79095
PPO Batch Consumption Time: 0.04774
Total Iteration Time: 6.49340

Cumulative Model Updates: 22,615
Cumulative Timesteps: 377,270,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.95864
Policy Entropy: 1.04438
Value Function Loss: 1.94190

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.18038
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 8,677.45596
Overall Steps per Second: 7,526.29641

Timestep Collection Time: 5.76436
Timestep Consumption Time: 0.88167
PPO Batch Consumption Time: 0.04761
Total Iteration Time: 6.64603

Cumulative Model Updates: 22,618
Cumulative Timesteps: 377,320,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 377320426...
Checkpoint 377320426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.61592
Policy Entropy: 1.05789
Value Function Loss: 1.94348

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.04072

Collected Steps per Second: 8,765.48766
Overall Steps per Second: 7,647.43241

Timestep Collection Time: 5.70487
Timestep Consumption Time: 0.83405
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 6.53893

Cumulative Model Updates: 22,621
Cumulative Timesteps: 377,370,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.26890
Policy Entropy: 1.06258
Value Function Loss: 1.99961

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.18712
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.03958

Collected Steps per Second: 8,952.98557
Overall Steps per Second: 7,731.82686

Timestep Collection Time: 5.58696
Timestep Consumption Time: 0.88240
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.46936

Cumulative Model Updates: 22,624
Cumulative Timesteps: 377,420,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 377420452...
Checkpoint 377420452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.68432
Policy Entropy: 1.03898
Value Function Loss: 2.09115

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.22140
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.03726

Collected Steps per Second: 8,647.47744
Overall Steps per Second: 7,491.41098

Timestep Collection Time: 5.78458
Timestep Consumption Time: 0.89267
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 6.67725

Cumulative Model Updates: 22,627
Cumulative Timesteps: 377,470,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.51694
Policy Entropy: 1.05379
Value Function Loss: 2.35232

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.20727
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.03975

Collected Steps per Second: 8,828.08013
Overall Steps per Second: 7,727.61612

Timestep Collection Time: 5.66556
Timestep Consumption Time: 0.80681
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 6.47237

Cumulative Model Updates: 22,630
Cumulative Timesteps: 377,520,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 377520490...
Checkpoint 377520490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.72605
Policy Entropy: 1.04430
Value Function Loss: 2.33861

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.19489
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.04583

Collected Steps per Second: 8,946.43404
Overall Steps per Second: 7,731.26813

Timestep Collection Time: 5.58949
Timestep Consumption Time: 0.87853
PPO Batch Consumption Time: 0.05108
Total Iteration Time: 6.46802

Cumulative Model Updates: 22,633
Cumulative Timesteps: 377,570,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.89743
Policy Entropy: 1.03730
Value Function Loss: 2.24330

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.20880
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 8,637.58843
Overall Steps per Second: 7,548.40590

Timestep Collection Time: 5.79143
Timestep Consumption Time: 0.83566
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 6.62709

Cumulative Model Updates: 22,636
Cumulative Timesteps: 377,620,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 377620520...
Checkpoint 377620520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.37170
Policy Entropy: 1.02897
Value Function Loss: 2.26005

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.23641
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.04675

Collected Steps per Second: 8,823.41695
Overall Steps per Second: 7,504.42644

Timestep Collection Time: 5.66969
Timestep Consumption Time: 0.99651
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.66620

Cumulative Model Updates: 22,639
Cumulative Timesteps: 377,670,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.55812
Policy Entropy: 1.04812
Value Function Loss: 2.43844

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.18492
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.04632

Collected Steps per Second: 8,678.52768
Overall Steps per Second: 7,542.49731

Timestep Collection Time: 5.76342
Timestep Consumption Time: 0.86807
PPO Batch Consumption Time: 0.04752
Total Iteration Time: 6.63149

Cumulative Model Updates: 22,642
Cumulative Timesteps: 377,720,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 377720564...
Checkpoint 377720564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.54940
Policy Entropy: 1.04308
Value Function Loss: 2.35540

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.17329
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.04228

Collected Steps per Second: 8,673.43389
Overall Steps per Second: 7,614.29577

Timestep Collection Time: 5.76634
Timestep Consumption Time: 0.80209
PPO Batch Consumption Time: 0.04801
Total Iteration Time: 6.56843

Cumulative Model Updates: 22,645
Cumulative Timesteps: 377,770,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.63975
Policy Entropy: 1.03701
Value Function Loss: 2.22133

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.04053

Collected Steps per Second: 8,887.31565
Overall Steps per Second: 7,663.14742

Timestep Collection Time: 5.62802
Timestep Consumption Time: 0.89906
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.52708

Cumulative Model Updates: 22,648
Cumulative Timesteps: 377,820,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 377820596...
Checkpoint 377820596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.87884
Policy Entropy: 1.04294
Value Function Loss: 2.12225

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.18457
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.03891

Collected Steps per Second: 8,702.34393
Overall Steps per Second: 7,525.16141

Timestep Collection Time: 5.74880
Timestep Consumption Time: 0.89930
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 6.64810

Cumulative Model Updates: 22,651
Cumulative Timesteps: 377,870,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.46581
Policy Entropy: 1.05886
Value Function Loss: 2.33289

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.03851

Collected Steps per Second: 8,760.10663
Overall Steps per Second: 7,606.71643

Timestep Collection Time: 5.71112
Timestep Consumption Time: 0.86596
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.57708

Cumulative Model Updates: 22,654
Cumulative Timesteps: 377,920,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 377920654...
Checkpoint 377920654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.56725
Policy Entropy: 1.06932
Value Function Loss: 2.50756

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 8,723.05544
Overall Steps per Second: 7,462.89207

Timestep Collection Time: 5.73515
Timestep Consumption Time: 0.96842
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 6.70357

Cumulative Model Updates: 22,657
Cumulative Timesteps: 377,970,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.17123
Policy Entropy: 1.07300
Value Function Loss: 2.43098

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 8,767.23599
Overall Steps per Second: 7,727.20796

Timestep Collection Time: 5.70419
Timestep Consumption Time: 0.76774
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.47194

Cumulative Model Updates: 22,660
Cumulative Timesteps: 378,020,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 378020692...
Checkpoint 378020692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.46558
Policy Entropy: 1.07018
Value Function Loss: 2.38501

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16535
Policy Update Magnitude: 0.07729
Value Function Update Magnitude: 0.05401

Collected Steps per Second: 8,616.70199
Overall Steps per Second: 7,496.30367

Timestep Collection Time: 5.80454
Timestep Consumption Time: 0.86755
PPO Batch Consumption Time: 0.04743
Total Iteration Time: 6.67209

Cumulative Model Updates: 22,663
Cumulative Timesteps: 378,070,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.76382
Policy Entropy: 1.06680
Value Function Loss: 2.28403

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.20405
Policy Update Magnitude: 0.08189
Value Function Update Magnitude: 0.05340

Collected Steps per Second: 9,251.09558
Overall Steps per Second: 8,071.69874

Timestep Collection Time: 5.40606
Timestep Consumption Time: 0.78991
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.19597

Cumulative Model Updates: 22,666
Cumulative Timesteps: 378,120,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 378120720...
Checkpoint 378120720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.87573
Policy Entropy: 1.06943
Value Function Loss: 2.39185

Mean KL Divergence: 0.03263
SB3 Clip Fraction: 0.20761
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.05096

Collected Steps per Second: 9,085.34266
Overall Steps per Second: 7,768.93950

Timestep Collection Time: 5.50557
Timestep Consumption Time: 0.93289
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 6.43846

Cumulative Model Updates: 22,669
Cumulative Timesteps: 378,170,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.67923
Policy Entropy: 1.08461
Value Function Loss: 2.41722

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.05829

Collected Steps per Second: 8,938.75725
Overall Steps per Second: 7,762.51136

Timestep Collection Time: 5.59496
Timestep Consumption Time: 0.84780
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.44276

Cumulative Model Updates: 22,672
Cumulative Timesteps: 378,220,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 378220752...
Checkpoint 378220752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.20789
Policy Entropy: 1.09704
Value Function Loss: 2.36593

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.07335
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 9,221.27182
Overall Steps per Second: 7,926.36862

Timestep Collection Time: 5.42528
Timestep Consumption Time: 0.88631
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 6.31159

Cumulative Model Updates: 22,675
Cumulative Timesteps: 378,270,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.98651
Policy Entropy: 1.09528
Value Function Loss: 2.24517

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.15561
Policy Update Magnitude: 0.07807
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 8,909.08170
Overall Steps per Second: 7,724.19109

Timestep Collection Time: 5.61450
Timestep Consumption Time: 0.86126
PPO Batch Consumption Time: 0.04884
Total Iteration Time: 6.47576

Cumulative Model Updates: 22,678
Cumulative Timesteps: 378,320,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 378320800...
Checkpoint 378320800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.62527
Policy Entropy: 1.11738
Value Function Loss: 2.25597

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 8,789.78930
Overall Steps per Second: 7,753.17053

Timestep Collection Time: 5.68910
Timestep Consumption Time: 0.76065
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 6.44975

Cumulative Model Updates: 22,681
Cumulative Timesteps: 378,370,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.36056
Policy Entropy: 1.10777
Value Function Loss: 2.10334

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 8,655.43773
Overall Steps per Second: 7,576.08393

Timestep Collection Time: 5.77856
Timestep Consumption Time: 0.82326
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 6.60183

Cumulative Model Updates: 22,684
Cumulative Timesteps: 378,420,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 378420822...
Checkpoint 378420822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.15031
Policy Entropy: 1.10075
Value Function Loss: 2.05249

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.06661
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 8,838.72709
Overall Steps per Second: 7,676.75964

Timestep Collection Time: 5.65851
Timestep Consumption Time: 0.85648
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.51499

Cumulative Model Updates: 22,687
Cumulative Timesteps: 378,470,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.44577
Policy Entropy: 1.08071
Value Function Loss: 1.97825

Mean KL Divergence: 0.04119
SB3 Clip Fraction: 0.23998
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.06783

Collected Steps per Second: 9,044.67554
Overall Steps per Second: 7,830.05760

Timestep Collection Time: 5.53010
Timestep Consumption Time: 0.85784
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 6.38795

Cumulative Model Updates: 22,690
Cumulative Timesteps: 378,520,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 378520854...
Checkpoint 378520854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.75158
Policy Entropy: 1.10071
Value Function Loss: 1.87772

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.18907
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.06717

Collected Steps per Second: 8,946.12363
Overall Steps per Second: 7,718.92889

Timestep Collection Time: 5.59102
Timestep Consumption Time: 0.88889
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.47991

Cumulative Model Updates: 22,693
Cumulative Timesteps: 378,570,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.36326
Policy Entropy: 1.08039
Value Function Loss: 1.93513

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.22337
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 8,421.01265
Overall Steps per Second: 7,456.12294

Timestep Collection Time: 5.93943
Timestep Consumption Time: 0.76862
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.70804

Cumulative Model Updates: 22,696
Cumulative Timesteps: 378,620,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 378620888...
Checkpoint 378620888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.93272
Policy Entropy: 1.08280
Value Function Loss: 1.94631

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.21037
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 8,856.47881
Overall Steps per Second: 7,687.88928

Timestep Collection Time: 5.64694
Timestep Consumption Time: 0.85836
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.50530

Cumulative Model Updates: 22,699
Cumulative Timesteps: 378,670,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.80152
Policy Entropy: 1.08579
Value Function Loss: 1.99699

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.19479
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.07428

Collected Steps per Second: 8,931.36789
Overall Steps per Second: 7,753.84616

Timestep Collection Time: 5.59892
Timestep Consumption Time: 0.85027
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.44919

Cumulative Model Updates: 22,702
Cumulative Timesteps: 378,720,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 378720906...
Checkpoint 378720906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.84381
Policy Entropy: 1.07161
Value Function Loss: 1.87101

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.20023
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 8,818.00331
Overall Steps per Second: 7,615.88733

Timestep Collection Time: 5.67339
Timestep Consumption Time: 0.89551
PPO Batch Consumption Time: 0.04479
Total Iteration Time: 6.56890

Cumulative Model Updates: 22,705
Cumulative Timesteps: 378,770,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.95893
Policy Entropy: 1.07411
Value Function Loss: 1.86647

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06938

Collected Steps per Second: 8,499.53191
Overall Steps per Second: 7,424.65119

Timestep Collection Time: 5.88268
Timestep Consumption Time: 0.85165
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 6.73432

Cumulative Model Updates: 22,708
Cumulative Timesteps: 378,820,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 378820934...
Checkpoint 378820934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.21800
Policy Entropy: 1.06311
Value Function Loss: 1.86313

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 8,730.54685
Overall Steps per Second: 7,706.73020

Timestep Collection Time: 5.72725
Timestep Consumption Time: 0.76085
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.48810

Cumulative Model Updates: 22,711
Cumulative Timesteps: 378,870,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.53262
Policy Entropy: 1.06897
Value Function Loss: 2.13336

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 8,833.11521
Overall Steps per Second: 7,643.22322

Timestep Collection Time: 5.66233
Timestep Consumption Time: 0.88151
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.54384

Cumulative Model Updates: 22,714
Cumulative Timesteps: 378,920,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 378920952...
Checkpoint 378920952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.67960
Policy Entropy: 1.06614
Value Function Loss: 1.99831

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.04557

Collected Steps per Second: 8,730.84309
Overall Steps per Second: 7,634.47568

Timestep Collection Time: 5.72934
Timestep Consumption Time: 0.82278
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.55212

Cumulative Model Updates: 22,717
Cumulative Timesteps: 378,970,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.80722
Policy Entropy: 1.07816
Value Function Loss: 2.03983

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.04068

Collected Steps per Second: 9,068.35618
Overall Steps per Second: 7,964.86151

Timestep Collection Time: 5.51721
Timestep Consumption Time: 0.76438
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.28159

Cumulative Model Updates: 22,720
Cumulative Timesteps: 379,021,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 379021006...
Checkpoint 379021006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.49019
Policy Entropy: 1.07621
Value Function Loss: 2.02952

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.06931
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 8,642.04191
Overall Steps per Second: 7,527.99419

Timestep Collection Time: 5.78914
Timestep Consumption Time: 0.85672
PPO Batch Consumption Time: 0.04983
Total Iteration Time: 6.64586

Cumulative Model Updates: 22,723
Cumulative Timesteps: 379,071,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.40295
Policy Entropy: 1.08367
Value Function Loss: 2.12982

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.03979

Collected Steps per Second: 8,907.48808
Overall Steps per Second: 7,734.32223

Timestep Collection Time: 5.61640
Timestep Consumption Time: 0.85191
PPO Batch Consumption Time: 0.04882
Total Iteration Time: 6.46831

Cumulative Model Updates: 22,726
Cumulative Timesteps: 379,121,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 379121064...
Checkpoint 379121064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.99637
Policy Entropy: 1.07569
Value Function Loss: 2.12464

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.03719

Collected Steps per Second: 8,801.76682
Overall Steps per Second: 7,687.65148

Timestep Collection Time: 5.68113
Timestep Consumption Time: 0.82333
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.50446

Cumulative Model Updates: 22,729
Cumulative Timesteps: 379,171,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.98726
Policy Entropy: 1.07930
Value Function Loss: 2.16222

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 8,921.45632
Overall Steps per Second: 7,759.65977

Timestep Collection Time: 5.60716
Timestep Consumption Time: 0.83952
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.44667

Cumulative Model Updates: 22,732
Cumulative Timesteps: 379,221,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 379221092...
Checkpoint 379221092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.03931
Policy Entropy: 1.05736
Value Function Loss: 2.15745

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.20287
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 8,680.81448
Overall Steps per Second: 7,593.52718

Timestep Collection Time: 5.76305
Timestep Consumption Time: 0.82519
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.58824

Cumulative Model Updates: 22,735
Cumulative Timesteps: 379,271,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.19521
Policy Entropy: 1.08216
Value Function Loss: 2.19117

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.15967
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.04252

Collected Steps per Second: 8,770.99898
Overall Steps per Second: 7,627.50957

Timestep Collection Time: 5.70129
Timestep Consumption Time: 0.85472
PPO Batch Consumption Time: 0.04851
Total Iteration Time: 6.55601

Cumulative Model Updates: 22,738
Cumulative Timesteps: 379,321,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 379321126...
Checkpoint 379321126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.35194
Policy Entropy: 1.07767
Value Function Loss: 2.05445

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.03648

Collected Steps per Second: 8,885.30105
Overall Steps per Second: 7,721.86089

Timestep Collection Time: 5.63087
Timestep Consumption Time: 0.84839
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.47927

Cumulative Model Updates: 22,741
Cumulative Timesteps: 379,371,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.00787
Policy Entropy: 1.07332
Value Function Loss: 1.95393

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.03407

Collected Steps per Second: 8,892.21917
Overall Steps per Second: 7,871.50184

Timestep Collection Time: 5.62514
Timestep Consumption Time: 0.72943
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 6.35457

Cumulative Model Updates: 22,744
Cumulative Timesteps: 379,421,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 379421178...
Checkpoint 379421178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.76554
Policy Entropy: 1.06618
Value Function Loss: 2.07860

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.18883
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.03903

Collected Steps per Second: 8,636.50966
Overall Steps per Second: 7,515.67025

Timestep Collection Time: 5.78938
Timestep Consumption Time: 0.86339
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.65277

Cumulative Model Updates: 22,747
Cumulative Timesteps: 379,471,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.07791
Policy Entropy: 1.07433
Value Function Loss: 2.14003

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 8,448.58074
Overall Steps per Second: 7,385.76263

Timestep Collection Time: 5.91839
Timestep Consumption Time: 0.85166
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.77005

Cumulative Model Updates: 22,750
Cumulative Timesteps: 379,521,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 379521180...
Checkpoint 379521180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.89913
Policy Entropy: 1.07608
Value Function Loss: 2.25049

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.17561
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.04060

Collected Steps per Second: 8,726.95017
Overall Steps per Second: 7,567.54688

Timestep Collection Time: 5.73144
Timestep Consumption Time: 0.87810
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 6.60954

Cumulative Model Updates: 22,753
Cumulative Timesteps: 379,571,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.51312
Policy Entropy: 1.04364
Value Function Loss: 2.18190

Mean KL Divergence: 0.04249
SB3 Clip Fraction: 0.23607
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.04960

Collected Steps per Second: 8,759.79289
Overall Steps per Second: 7,613.20997

Timestep Collection Time: 5.71064
Timestep Consumption Time: 0.86005
PPO Batch Consumption Time: 0.05081
Total Iteration Time: 6.57068

Cumulative Model Updates: 22,756
Cumulative Timesteps: 379,621,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 379621222...
Checkpoint 379621222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.10845
Policy Entropy: 1.06569
Value Function Loss: 2.10416

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.05120

Collected Steps per Second: 8,832.26223
Overall Steps per Second: 7,747.12845

Timestep Collection Time: 5.66423
Timestep Consumption Time: 0.79338
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.45762

Cumulative Model Updates: 22,759
Cumulative Timesteps: 379,671,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.47578
Policy Entropy: 1.06526
Value Function Loss: 1.96117

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.16229
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 8,674.84584
Overall Steps per Second: 7,504.54405

Timestep Collection Time: 5.76564
Timestep Consumption Time: 0.89913
PPO Batch Consumption Time: 0.04826
Total Iteration Time: 6.66476

Cumulative Model Updates: 22,762
Cumulative Timesteps: 379,721,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 379721266...
Checkpoint 379721266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.02828
Policy Entropy: 1.05317
Value Function Loss: 1.94426

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.17709
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 8,544.32431
Overall Steps per Second: 7,452.22765

Timestep Collection Time: 5.85277
Timestep Consumption Time: 0.85770
PPO Batch Consumption Time: 0.04807
Total Iteration Time: 6.71048

Cumulative Model Updates: 22,765
Cumulative Timesteps: 379,771,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.51306
Policy Entropy: 1.03002
Value Function Loss: 1.86192

Mean KL Divergence: 0.03986
SB3 Clip Fraction: 0.27144
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 8,844.98501
Overall Steps per Second: 7,676.70475

Timestep Collection Time: 5.65383
Timestep Consumption Time: 0.86043
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.51425

Cumulative Model Updates: 22,768
Cumulative Timesteps: 379,821,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 379821282...
Checkpoint 379821282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.30536
Policy Entropy: 1.08415
Value Function Loss: 1.86289

Mean KL Divergence: 0.04041
SB3 Clip Fraction: 0.28957
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 9,047.95776
Overall Steps per Second: 7,807.78874

Timestep Collection Time: 5.52655
Timestep Consumption Time: 0.87782
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.40437

Cumulative Model Updates: 22,771
Cumulative Timesteps: 379,871,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.03435
Policy Entropy: 1.05365
Value Function Loss: 1.91631

Mean KL Divergence: 0.04560
SB3 Clip Fraction: 0.28092
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.05401

Collected Steps per Second: 8,900.16438
Overall Steps per Second: 7,792.96958

Timestep Collection Time: 5.61832
Timestep Consumption Time: 0.79823
PPO Batch Consumption Time: 0.04849
Total Iteration Time: 6.41655

Cumulative Model Updates: 22,774
Cumulative Timesteps: 379,921,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 379921290...
Checkpoint 379921290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.98430
Policy Entropy: 1.08400
Value Function Loss: 1.86379

Mean KL Divergence: 0.04318
SB3 Clip Fraction: 0.28917
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 8,809.58120
Overall Steps per Second: 7,579.16797

Timestep Collection Time: 5.67564
Timestep Consumption Time: 0.92139
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.59703

Cumulative Model Updates: 22,777
Cumulative Timesteps: 379,971,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.72962
Policy Entropy: 1.04739
Value Function Loss: 1.94420

Mean KL Divergence: 0.04571
SB3 Clip Fraction: 0.28114
Policy Update Magnitude: 0.03627
Value Function Update Magnitude: 0.05618

Collected Steps per Second: 9,169.72625
Overall Steps per Second: 7,898.56802

Timestep Collection Time: 5.45556
Timestep Consumption Time: 0.87799
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.33355

Cumulative Model Updates: 22,780
Cumulative Timesteps: 380,021,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 380021316...
Checkpoint 380021316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.46246
Policy Entropy: 1.07163
Value Function Loss: 1.92010

Mean KL Divergence: 0.02670
SB3 Clip Fraction: 0.20906
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.06015

Collected Steps per Second: 9,161.46194
Overall Steps per Second: 7,867.73448

Timestep Collection Time: 5.45983
Timestep Consumption Time: 0.89778
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 6.35761

Cumulative Model Updates: 22,783
Cumulative Timesteps: 380,071,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.27383
Policy Entropy: 1.05632
Value Function Loss: 2.21218

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.21657
Policy Update Magnitude: 0.03952
Value Function Update Magnitude: 0.05943

Collected Steps per Second: 9,157.18984
Overall Steps per Second: 7,867.23922

Timestep Collection Time: 5.46325
Timestep Consumption Time: 0.89578
PPO Batch Consumption Time: 0.05229
Total Iteration Time: 6.35903

Cumulative Model Updates: 22,786
Cumulative Timesteps: 380,121,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380121364...
Checkpoint 380121364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.04857
Policy Entropy: 1.06304
Value Function Loss: 2.15198

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.05518

Collected Steps per Second: 8,653.53467
Overall Steps per Second: 7,611.99849

Timestep Collection Time: 5.78099
Timestep Consumption Time: 0.79100
PPO Batch Consumption Time: 0.04717
Total Iteration Time: 6.57199

Cumulative Model Updates: 22,789
Cumulative Timesteps: 380,171,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.39267
Policy Entropy: 1.05955
Value Function Loss: 2.16037

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 8,718.23503
Overall Steps per Second: 7,528.94895

Timestep Collection Time: 5.73671
Timestep Consumption Time: 0.90618
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 6.64289

Cumulative Model Updates: 22,792
Cumulative Timesteps: 380,221,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 380221404...
Checkpoint 380221404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.66635
Policy Entropy: 1.06879
Value Function Loss: 1.94078

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 8,613.90145
Overall Steps per Second: 7,559.39895

Timestep Collection Time: 5.80596
Timestep Consumption Time: 0.80991
PPO Batch Consumption Time: 0.04021
Total Iteration Time: 6.61587

Cumulative Model Updates: 22,795
Cumulative Timesteps: 380,271,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.19135
Policy Entropy: 1.04052
Value Function Loss: 1.92282

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.21578
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.04909

Collected Steps per Second: 8,993.61699
Overall Steps per Second: 7,739.67537

Timestep Collection Time: 5.56261
Timestep Consumption Time: 0.90123
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.46384

Cumulative Model Updates: 22,798
Cumulative Timesteps: 380,321,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380321444...
Checkpoint 380321444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.83016
Policy Entropy: 1.05688
Value Function Loss: 1.96156

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.17484
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.04654

Collected Steps per Second: 8,797.24671
Overall Steps per Second: 7,638.71507

Timestep Collection Time: 5.68655
Timestep Consumption Time: 0.86246
PPO Batch Consumption Time: 0.05130
Total Iteration Time: 6.54901

Cumulative Model Updates: 22,801
Cumulative Timesteps: 380,371,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.12288
Policy Entropy: 1.06378
Value Function Loss: 2.08407

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.20422
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.04321

Collected Steps per Second: 8,938.07795
Overall Steps per Second: 7,582.27304

Timestep Collection Time: 5.59494
Timestep Consumption Time: 1.00044
PPO Batch Consumption Time: 0.04864
Total Iteration Time: 6.59538

Cumulative Model Updates: 22,804
Cumulative Timesteps: 380,421,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 380421478...
Checkpoint 380421478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.61892
Policy Entropy: 1.04853
Value Function Loss: 2.13199

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.05179

Collected Steps per Second: 8,648.98741
Overall Steps per Second: 7,550.39247

Timestep Collection Time: 5.78125
Timestep Consumption Time: 0.84118
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.62244

Cumulative Model Updates: 22,807
Cumulative Timesteps: 380,471,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.91770
Policy Entropy: 1.03542
Value Function Loss: 2.11427

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.20751
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 8,892.61944
Overall Steps per Second: 7,767.62089

Timestep Collection Time: 5.62466
Timestep Consumption Time: 0.81463
PPO Batch Consumption Time: 0.04758
Total Iteration Time: 6.43929

Cumulative Model Updates: 22,810
Cumulative Timesteps: 380,521,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 380521498...
Checkpoint 380521498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.54988
Policy Entropy: 1.04974
Value Function Loss: 2.01124

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 8,981.24479
Overall Steps per Second: 7,753.50507

Timestep Collection Time: 5.56916
Timestep Consumption Time: 0.88186
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 6.45102

Cumulative Model Updates: 22,813
Cumulative Timesteps: 380,571,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.32184
Policy Entropy: 1.05399
Value Function Loss: 1.94893

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.04237

Collected Steps per Second: 8,569.13001
Overall Steps per Second: 7,482.93760

Timestep Collection Time: 5.83793
Timestep Consumption Time: 0.84741
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 6.68534

Cumulative Model Updates: 22,816
Cumulative Timesteps: 380,621,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 380621542...
Checkpoint 380621542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.64836
Policy Entropy: 1.04834
Value Function Loss: 1.87739

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.04873

Collected Steps per Second: 8,948.50583
Overall Steps per Second: 7,715.07801

Timestep Collection Time: 5.58909
Timestep Consumption Time: 0.89354
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.48263

Cumulative Model Updates: 22,819
Cumulative Timesteps: 380,671,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.38740
Policy Entropy: 1.04721
Value Function Loss: 1.84460

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.16160
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.04711

Collected Steps per Second: 8,592.28470
Overall Steps per Second: 7,505.15469

Timestep Collection Time: 5.82011
Timestep Consumption Time: 0.84305
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.66315

Cumulative Model Updates: 22,822
Cumulative Timesteps: 380,721,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 380721564...
Checkpoint 380721564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.74820
Policy Entropy: 1.05284
Value Function Loss: 2.11626

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.04484

Collected Steps per Second: 8,821.83174
Overall Steps per Second: 7,844.64074

Timestep Collection Time: 5.67093
Timestep Consumption Time: 0.70642
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.37735

Cumulative Model Updates: 22,825
Cumulative Timesteps: 380,771,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.09059
Policy Entropy: 1.05246
Value Function Loss: 2.18198

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.04677

Collected Steps per Second: 8,754.35996
Overall Steps per Second: 7,589.76871

Timestep Collection Time: 5.71258
Timestep Consumption Time: 0.87655
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.58913

Cumulative Model Updates: 22,828
Cumulative Timesteps: 380,821,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 380821602...
Checkpoint 380821602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.40847
Policy Entropy: 1.05661
Value Function Loss: 2.20770

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.05013

Collected Steps per Second: 8,846.93278
Overall Steps per Second: 7,692.79638

Timestep Collection Time: 5.65281
Timestep Consumption Time: 0.84808
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 6.50089

Cumulative Model Updates: 22,831
Cumulative Timesteps: 380,871,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.20625
Policy Entropy: 1.05766
Value Function Loss: 2.04913

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.04826

Collected Steps per Second: 8,677.19052
Overall Steps per Second: 7,687.88396

Timestep Collection Time: 5.76316
Timestep Consumption Time: 0.74163
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.50478

Cumulative Model Updates: 22,834
Cumulative Timesteps: 380,921,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 380921620...
Checkpoint 380921620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.34503
Policy Entropy: 1.05624
Value Function Loss: 1.99195

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 8,854.22137
Overall Steps per Second: 7,684.41824

Timestep Collection Time: 5.64861
Timestep Consumption Time: 0.85989
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 6.50850

Cumulative Model Updates: 22,837
Cumulative Timesteps: 380,971,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.96045
Policy Entropy: 1.06603
Value Function Loss: 2.07744

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 8,912.20301
Overall Steps per Second: 7,895.78884

Timestep Collection Time: 5.61365
Timestep Consumption Time: 0.72264
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 6.33629

Cumulative Model Updates: 22,840
Cumulative Timesteps: 381,021,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 381021664...
Checkpoint 381021664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.34485
Policy Entropy: 1.06460
Value Function Loss: 2.12131

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.04901

Collected Steps per Second: 8,953.73919
Overall Steps per Second: 7,747.51786

Timestep Collection Time: 5.58538
Timestep Consumption Time: 0.86959
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.45497

Cumulative Model Updates: 22,843
Cumulative Timesteps: 381,071,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.32202
Policy Entropy: 1.07058
Value Function Loss: 2.03605

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.04848

Collected Steps per Second: 8,465.03330
Overall Steps per Second: 7,435.31131

Timestep Collection Time: 5.91020
Timestep Consumption Time: 0.81851
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 6.72870

Cumulative Model Updates: 22,846
Cumulative Timesteps: 381,121,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 381121704...
Checkpoint 381121704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.14959
Policy Entropy: 1.07747
Value Function Loss: 2.07001

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.04380

Collected Steps per Second: 8,801.64155
Overall Steps per Second: 7,748.57957

Timestep Collection Time: 5.68303
Timestep Consumption Time: 0.77235
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.45538

Cumulative Model Updates: 22,849
Cumulative Timesteps: 381,171,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.98399
Policy Entropy: 1.06548
Value Function Loss: 2.02617

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.03634

Collected Steps per Second: 8,883.65450
Overall Steps per Second: 7,667.86999

Timestep Collection Time: 5.63012
Timestep Consumption Time: 0.89269
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.52280

Cumulative Model Updates: 22,852
Cumulative Timesteps: 381,221,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 381221740...
Checkpoint 381221740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.68571
Policy Entropy: 1.07025
Value Function Loss: 2.21765

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.03326

Collected Steps per Second: 8,904.32923
Overall Steps per Second: 7,749.92849

Timestep Collection Time: 5.61749
Timestep Consumption Time: 0.83676
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.45425

Cumulative Model Updates: 22,855
Cumulative Timesteps: 381,271,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.59974
Policy Entropy: 1.06711
Value Function Loss: 2.11918

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.03788

Collected Steps per Second: 9,211.27831
Overall Steps per Second: 7,983.31669

Timestep Collection Time: 5.43030
Timestep Consumption Time: 0.83527
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.26557

Cumulative Model Updates: 22,858
Cumulative Timesteps: 381,321,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 381321780...
Checkpoint 381321780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.75744
Policy Entropy: 1.07093
Value Function Loss: 2.24743

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 7,853.53587
Overall Steps per Second: 6,875.35804

Timestep Collection Time: 6.36834
Timestep Consumption Time: 0.90604
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 7.27438

Cumulative Model Updates: 22,861
Cumulative Timesteps: 381,371,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.68630
Policy Entropy: 1.07690
Value Function Loss: 2.11394

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.04581

Collected Steps per Second: 8,874.50340
Overall Steps per Second: 7,844.62165

Timestep Collection Time: 5.63457
Timestep Consumption Time: 0.73973
PPO Batch Consumption Time: 0.04771
Total Iteration Time: 6.37430

Cumulative Model Updates: 22,864
Cumulative Timesteps: 381,421,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 381421798...
Checkpoint 381421798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.18765
Policy Entropy: 1.07845
Value Function Loss: 2.08318

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.04571

Collected Steps per Second: 8,887.03864
Overall Steps per Second: 7,774.64960

Timestep Collection Time: 5.62662
Timestep Consumption Time: 0.80505
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 6.43167

Cumulative Model Updates: 22,867
Cumulative Timesteps: 381,471,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.63856
Policy Entropy: 1.06107
Value Function Loss: 1.87295

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.04565

Collected Steps per Second: 8,849.83294
Overall Steps per Second: 7,639.67797

Timestep Collection Time: 5.65186
Timestep Consumption Time: 0.89528
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.54713

Cumulative Model Updates: 22,870
Cumulative Timesteps: 381,521,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 381521820...
Checkpoint 381521820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.82326
Policy Entropy: 1.06111
Value Function Loss: 1.91089

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.18449
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.04962

Collected Steps per Second: 8,749.66589
Overall Steps per Second: 7,500.87722

Timestep Collection Time: 5.71702
Timestep Consumption Time: 0.95180
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.66882

Cumulative Model Updates: 22,873
Cumulative Timesteps: 381,571,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.92360
Policy Entropy: 1.07876
Value Function Loss: 2.18131

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.04410
Value Function Update Magnitude: 0.04584

Collected Steps per Second: 8,821.11284
Overall Steps per Second: 7,644.08588

Timestep Collection Time: 5.67003
Timestep Consumption Time: 0.87306
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.54310

Cumulative Model Updates: 22,876
Cumulative Timesteps: 381,621,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 381621858...
Checkpoint 381621858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.24778
Policy Entropy: 1.08775
Value Function Loss: 2.19156

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.17123
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.04485

Collected Steps per Second: 8,625.05715
Overall Steps per Second: 7,607.05532

Timestep Collection Time: 5.79892
Timestep Consumption Time: 0.77603
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.57495

Cumulative Model Updates: 22,879
Cumulative Timesteps: 381,671,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.03914
Policy Entropy: 1.04239
Value Function Loss: 2.12804

Mean KL Divergence: 0.04966
SB3 Clip Fraction: 0.24515
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.04536

Collected Steps per Second: 8,660.34426
Overall Steps per Second: 7,469.00454

Timestep Collection Time: 5.77621
Timestep Consumption Time: 0.92133
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.69755

Cumulative Model Updates: 22,882
Cumulative Timesteps: 381,721,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 381721898...
Checkpoint 381721898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.42881
Policy Entropy: 1.08208
Value Function Loss: 2.01992

Mean KL Divergence: 0.03965
SB3 Clip Fraction: 0.25377
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.04239

Collected Steps per Second: 9,198.93345
Overall Steps per Second: 7,970.88882

Timestep Collection Time: 5.43759
Timestep Consumption Time: 0.83775
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.27534

Cumulative Model Updates: 22,885
Cumulative Timesteps: 381,771,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.91885
Policy Entropy: 1.04742
Value Function Loss: 2.02111

Mean KL Divergence: 0.04876
SB3 Clip Fraction: 0.28345
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.04476

Collected Steps per Second: 8,914.35923
Overall Steps per Second: 7,737.90715

Timestep Collection Time: 5.61050
Timestep Consumption Time: 0.85301
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.46350

Cumulative Model Updates: 22,888
Cumulative Timesteps: 381,821,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381821932...
Checkpoint 381821932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.21487
Policy Entropy: 1.08522
Value Function Loss: 1.99389

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.22341
Policy Update Magnitude: 0.04187
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 8,880.66346
Overall Steps per Second: 7,676.25844

Timestep Collection Time: 5.63089
Timestep Consumption Time: 0.88349
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 6.51437

Cumulative Model Updates: 22,891
Cumulative Timesteps: 381,871,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.04994
Policy Entropy: 1.06724
Value Function Loss: 1.86476

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.17204
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.03997

Collected Steps per Second: 8,931.52371
Overall Steps per Second: 7,858.59914

Timestep Collection Time: 5.60039
Timestep Consumption Time: 0.76461
PPO Batch Consumption Time: 0.04896
Total Iteration Time: 6.36500

Cumulative Model Updates: 22,894
Cumulative Timesteps: 381,921,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 381921958...
Checkpoint 381921958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.19470
Policy Entropy: 1.06373
Value Function Loss: 1.91645

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.03894

Collected Steps per Second: 9,038.34304
Overall Steps per Second: 7,804.57623

Timestep Collection Time: 5.53332
Timestep Consumption Time: 0.87472
PPO Batch Consumption Time: 0.05240
Total Iteration Time: 6.40804

Cumulative Model Updates: 22,897
Cumulative Timesteps: 381,971,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.49721
Policy Entropy: 1.08275
Value Function Loss: 2.04669

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.04220

Collected Steps per Second: 8,678.92936
Overall Steps per Second: 7,541.73238

Timestep Collection Time: 5.76338
Timestep Consumption Time: 0.86904
PPO Batch Consumption Time: 0.04779
Total Iteration Time: 6.63243

Cumulative Model Updates: 22,900
Cumulative Timesteps: 382,021,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 382021990...
Checkpoint 382021990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.05498
Policy Entropy: 1.09472
Value Function Loss: 2.01132

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.17356
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.04513

Collected Steps per Second: 8,732.05980
Overall Steps per Second: 7,579.35134

Timestep Collection Time: 5.72694
Timestep Consumption Time: 0.87098
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 6.59793

Cumulative Model Updates: 22,903
Cumulative Timesteps: 382,071,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.18182
Policy Entropy: 1.07622
Value Function Loss: 1.97412

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.04729

Collected Steps per Second: 8,610.61310
Overall Steps per Second: 7,543.76731

Timestep Collection Time: 5.80795
Timestep Consumption Time: 0.82136
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.62931

Cumulative Model Updates: 22,906
Cumulative Timesteps: 382,122,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382122008...
Checkpoint 382122008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.76480
Policy Entropy: 1.08671
Value Function Loss: 1.76687

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.04401

Collected Steps per Second: 8,983.59516
Overall Steps per Second: 7,823.71721

Timestep Collection Time: 5.56815
Timestep Consumption Time: 0.82549
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.39364

Cumulative Model Updates: 22,909
Cumulative Timesteps: 382,172,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.11198
Policy Entropy: 1.08932
Value Function Loss: 1.91750

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.05001

Collected Steps per Second: 8,740.44230
Overall Steps per Second: 7,627.71215

Timestep Collection Time: 5.72374
Timestep Consumption Time: 0.83498
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.55872

Cumulative Model Updates: 22,912
Cumulative Timesteps: 382,222,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 382222058...
Checkpoint 382222058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.26110
Policy Entropy: 1.09044
Value Function Loss: 1.94390

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 8,372.48563
Overall Steps per Second: 7,358.96030

Timestep Collection Time: 5.97266
Timestep Consumption Time: 0.82259
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.79525

Cumulative Model Updates: 22,915
Cumulative Timesteps: 382,272,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.64772
Policy Entropy: 1.08269
Value Function Loss: 2.16935

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.05365

Collected Steps per Second: 9,006.30582
Overall Steps per Second: 7,797.36030

Timestep Collection Time: 5.55366
Timestep Consumption Time: 0.86107
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 6.41474

Cumulative Model Updates: 22,918
Cumulative Timesteps: 382,322,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 382322082...
Checkpoint 382322082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.68120
Policy Entropy: 1.08467
Value Function Loss: 2.04223

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.05695

Collected Steps per Second: 8,705.35037
Overall Steps per Second: 7,636.55041

Timestep Collection Time: 5.74405
Timestep Consumption Time: 0.80393
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 6.54798

Cumulative Model Updates: 22,921
Cumulative Timesteps: 382,372,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.74600
Policy Entropy: 1.09623
Value Function Loss: 2.06750

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 8,770.28349
Overall Steps per Second: 7,772.12037

Timestep Collection Time: 5.70221
Timestep Consumption Time: 0.73233
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.43454

Cumulative Model Updates: 22,924
Cumulative Timesteps: 382,422,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382422096...
Checkpoint 382422096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.55254
Policy Entropy: 1.09618
Value Function Loss: 1.96219

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.04199
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 8,628.11564
Overall Steps per Second: 7,496.32322

Timestep Collection Time: 5.79640
Timestep Consumption Time: 0.87514
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.67154

Cumulative Model Updates: 22,927
Cumulative Timesteps: 382,472,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.80007
Policy Entropy: 1.07887
Value Function Loss: 1.96930

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.05893

Collected Steps per Second: 8,564.20203
Overall Steps per Second: 7,516.39336

Timestep Collection Time: 5.83942
Timestep Consumption Time: 0.81403
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.65346

Cumulative Model Updates: 22,930
Cumulative Timesteps: 382,522,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382522118...
Checkpoint 382522118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.56566
Policy Entropy: 1.07536
Value Function Loss: 2.07325

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.17076
Policy Update Magnitude: 0.04016
Value Function Update Magnitude: 0.05546

Collected Steps per Second: 8,909.20052
Overall Steps per Second: 7,721.85116

Timestep Collection Time: 5.61307
Timestep Consumption Time: 0.86309
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.47617

Cumulative Model Updates: 22,933
Cumulative Timesteps: 382,572,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.53747
Policy Entropy: 1.08457
Value Function Loss: 2.08756

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.05992

Collected Steps per Second: 8,855.49885
Overall Steps per Second: 7,677.31274

Timestep Collection Time: 5.64666
Timestep Consumption Time: 0.86656
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 6.51322

Cumulative Model Updates: 22,936
Cumulative Timesteps: 382,622,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 382622130...
Checkpoint 382622130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.11382
Policy Entropy: 1.10036
Value Function Loss: 2.03473

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.04864

Collected Steps per Second: 8,691.83638
Overall Steps per Second: 7,661.62400

Timestep Collection Time: 5.75275
Timestep Consumption Time: 0.77354
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.52629

Cumulative Model Updates: 22,939
Cumulative Timesteps: 382,672,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.14263
Policy Entropy: 1.06004
Value Function Loss: 1.97608

Mean KL Divergence: 0.04470
SB3 Clip Fraction: 0.28923
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.04231

Collected Steps per Second: 8,546.35704
Overall Steps per Second: 7,417.09323

Timestep Collection Time: 5.85232
Timestep Consumption Time: 0.89102
PPO Batch Consumption Time: 0.04097
Total Iteration Time: 6.74334

Cumulative Model Updates: 22,942
Cumulative Timesteps: 382,722,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 382722148...
Checkpoint 382722148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.34567
Policy Entropy: 1.08064
Value Function Loss: 2.08146

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.04214

Collected Steps per Second: 8,874.63168
Overall Steps per Second: 7,692.05380

Timestep Collection Time: 5.63539
Timestep Consumption Time: 0.86639
PPO Batch Consumption Time: 0.04512
Total Iteration Time: 6.50177

Cumulative Model Updates: 22,945
Cumulative Timesteps: 382,772,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.93744
Policy Entropy: 1.06628
Value Function Loss: 2.02876

Mean KL Divergence: 0.02779
SB3 Clip Fraction: 0.17464
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.04490

Collected Steps per Second: 9,117.80082
Overall Steps per Second: 7,877.61647

Timestep Collection Time: 5.48553
Timestep Consumption Time: 0.86360
PPO Batch Consumption Time: 0.04696
Total Iteration Time: 6.34913

Cumulative Model Updates: 22,948
Cumulative Timesteps: 382,822,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 382822176...
Checkpoint 382822176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.80747
Policy Entropy: 1.05466
Value Function Loss: 1.87993

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.18862
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.04401

Collected Steps per Second: 8,831.94897
Overall Steps per Second: 7,586.18789

Timestep Collection Time: 5.66308
Timestep Consumption Time: 0.92996
PPO Batch Consumption Time: 0.04791
Total Iteration Time: 6.59303

Cumulative Model Updates: 22,951
Cumulative Timesteps: 382,872,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.74557
Policy Entropy: 1.06098
Value Function Loss: 2.00362

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.18515
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.05361

Collected Steps per Second: 8,772.79908
Overall Steps per Second: 7,753.24327

Timestep Collection Time: 5.70058
Timestep Consumption Time: 0.74963
PPO Batch Consumption Time: 0.04838
Total Iteration Time: 6.45020

Cumulative Model Updates: 22,954
Cumulative Timesteps: 382,922,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382922202...
Checkpoint 382922202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.74195
Policy Entropy: 1.06773
Value Function Loss: 1.97034

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.20337
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 8,515.78102
Overall Steps per Second: 7,461.87737

Timestep Collection Time: 5.87404
Timestep Consumption Time: 0.82964
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.70367

Cumulative Model Updates: 22,957
Cumulative Timesteps: 382,972,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.20083
Policy Entropy: 1.06460
Value Function Loss: 2.01784

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.04362

Collected Steps per Second: 8,655.73721
Overall Steps per Second: 7,555.45186

Timestep Collection Time: 5.77698
Timestep Consumption Time: 0.84129
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.61827

Cumulative Model Updates: 22,960
Cumulative Timesteps: 383,022,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 383022228...
Checkpoint 383022228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.16592
Policy Entropy: 1.05719
Value Function Loss: 1.85526

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.21641
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.04075

Collected Steps per Second: 8,925.44036
Overall Steps per Second: 7,756.97917

Timestep Collection Time: 5.60398
Timestep Consumption Time: 0.84415
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.44813

Cumulative Model Updates: 22,963
Cumulative Timesteps: 383,072,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.70935
Policy Entropy: 1.06606
Value Function Loss: 2.04666

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 9,131.85254
Overall Steps per Second: 7,948.52039

Timestep Collection Time: 5.47731
Timestep Consumption Time: 0.81543
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.29274

Cumulative Model Updates: 22,966
Cumulative Timesteps: 383,122,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 383122264...
Checkpoint 383122264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.70509
Policy Entropy: 1.06097
Value Function Loss: 2.16875

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 8,657.87199
Overall Steps per Second: 7,625.31478

Timestep Collection Time: 5.77740
Timestep Consumption Time: 0.78233
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.55973

Cumulative Model Updates: 22,969
Cumulative Timesteps: 383,172,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.59163
Policy Entropy: 1.06202
Value Function Loss: 2.05983

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.05029

Collected Steps per Second: 8,792.22269
Overall Steps per Second: 7,534.58474

Timestep Collection Time: 5.68798
Timestep Consumption Time: 0.94941
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.63739

Cumulative Model Updates: 22,972
Cumulative Timesteps: 383,222,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 383222294...
Checkpoint 383222294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.86877
Policy Entropy: 1.06522
Value Function Loss: 2.00315

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.04294

Collected Steps per Second: 8,814.26893
Overall Steps per Second: 7,696.87134

Timestep Collection Time: 5.67262
Timestep Consumption Time: 0.82353
PPO Batch Consumption Time: 0.04954
Total Iteration Time: 6.49615

Cumulative Model Updates: 22,975
Cumulative Timesteps: 383,272,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.30793
Policy Entropy: 1.06411
Value Function Loss: 1.86902

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.04453

Collected Steps per Second: 8,773.02344
Overall Steps per Second: 7,664.98326

Timestep Collection Time: 5.70134
Timestep Consumption Time: 0.82418
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 6.52552

Cumulative Model Updates: 22,978
Cumulative Timesteps: 383,322,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 383322312...
Checkpoint 383322312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.02491
Policy Entropy: 1.03975
Value Function Loss: 2.01109

Mean KL Divergence: 0.04610
SB3 Clip Fraction: 0.24033
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.04181

Collected Steps per Second: 8,791.79401
Overall Steps per Second: 7,616.81159

Timestep Collection Time: 5.68735
Timestep Consumption Time: 0.87734
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.56469

Cumulative Model Updates: 22,981
Cumulative Timesteps: 383,372,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.05804
Policy Entropy: 1.06431
Value Function Loss: 2.16244

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.22025
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.04185

Collected Steps per Second: 8,658.48821
Overall Steps per Second: 7,626.93959

Timestep Collection Time: 5.77745
Timestep Consumption Time: 0.78140
PPO Batch Consumption Time: 0.04705
Total Iteration Time: 6.55886

Cumulative Model Updates: 22,984
Cumulative Timesteps: 383,422,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 383422338...
Checkpoint 383422338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.02024
Policy Entropy: 1.03843
Value Function Loss: 2.03901

Mean KL Divergence: 0.02970
SB3 Clip Fraction: 0.23057
Policy Update Magnitude: 0.04110
Value Function Update Magnitude: 0.03471

Collected Steps per Second: 8,845.98971
Overall Steps per Second: 7,601.72043

Timestep Collection Time: 5.65454
Timestep Consumption Time: 0.92555
PPO Batch Consumption Time: 0.04860
Total Iteration Time: 6.58009

Cumulative Model Updates: 22,987
Cumulative Timesteps: 383,472,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.51730
Policy Entropy: 1.04967
Value Function Loss: 2.22939

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.21713
Policy Update Magnitude: 0.04023
Value Function Update Magnitude: 0.04145

Collected Steps per Second: 8,685.09306
Overall Steps per Second: 7,565.73246

Timestep Collection Time: 5.75814
Timestep Consumption Time: 0.85193
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 6.61007

Cumulative Model Updates: 22,990
Cumulative Timesteps: 383,522,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 383522368...
Checkpoint 383522368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.15746
Policy Entropy: 1.05908
Value Function Loss: 2.21284

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.22662
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 9,049.05196
Overall Steps per Second: 7,858.22196

Timestep Collection Time: 5.52544
Timestep Consumption Time: 0.83732
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 6.36276

Cumulative Model Updates: 22,993
Cumulative Timesteps: 383,572,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.25589
Policy Entropy: 1.05027
Value Function Loss: 2.30042

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.20333
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.04367

Collected Steps per Second: 9,091.93908
Overall Steps per Second: 7,736.89243

Timestep Collection Time: 5.49960
Timestep Consumption Time: 0.96320
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.46280

Cumulative Model Updates: 22,996
Cumulative Timesteps: 383,622,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 383622370...
Checkpoint 383622370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.28569
Policy Entropy: 1.04508
Value Function Loss: 2.00078

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.19307
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.04633

Collected Steps per Second: 9,067.84376
Overall Steps per Second: 7,844.11941

Timestep Collection Time: 5.51465
Timestep Consumption Time: 0.86032
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.37497

Cumulative Model Updates: 22,999
Cumulative Timesteps: 383,672,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.58154
Policy Entropy: 1.04905
Value Function Loss: 1.95038

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.04359

Collected Steps per Second: 9,306.74468
Overall Steps per Second: 7,979.44277

Timestep Collection Time: 5.37288
Timestep Consumption Time: 0.89373
PPO Batch Consumption Time: 0.04835
Total Iteration Time: 6.26660

Cumulative Model Updates: 23,002
Cumulative Timesteps: 383,722,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 383722380...
Checkpoint 383722380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.61862
Policy Entropy: 1.05769
Value Function Loss: 1.88237

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.17073
Policy Update Magnitude: 0.03874
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 8,920.02680
Overall Steps per Second: 7,684.89066

Timestep Collection Time: 5.60649
Timestep Consumption Time: 0.90109
PPO Batch Consumption Time: 0.04916
Total Iteration Time: 6.50757

Cumulative Model Updates: 23,005
Cumulative Timesteps: 383,772,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.68029
Policy Entropy: 1.02611
Value Function Loss: 1.94692

Mean KL Divergence: 0.05233
SB3 Clip Fraction: 0.25594
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 8,927.52972
Overall Steps per Second: 7,848.88083

Timestep Collection Time: 5.60289
Timestep Consumption Time: 0.76999
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.37288

Cumulative Model Updates: 23,008
Cumulative Timesteps: 383,822,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 383822410...
Checkpoint 383822410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.50650
Policy Entropy: 1.05082
Value Function Loss: 1.88165

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.19045
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 8,506.15164
Overall Steps per Second: 7,339.15789

Timestep Collection Time: 5.87974
Timestep Consumption Time: 0.93493
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.81468

Cumulative Model Updates: 23,011
Cumulative Timesteps: 383,872,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.20928
Policy Entropy: 1.03178
Value Function Loss: 1.94972

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.22348
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.05124

Collected Steps per Second: 8,898.79961
Overall Steps per Second: 7,751.68411

Timestep Collection Time: 5.62031
Timestep Consumption Time: 0.83171
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.45202

Cumulative Model Updates: 23,014
Cumulative Timesteps: 383,922,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 383922438...
Checkpoint 383922438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.82383
Policy Entropy: 1.01975
Value Function Loss: 1.92990

Mean KL Divergence: 0.02965
SB3 Clip Fraction: 0.25260
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.06389

Collected Steps per Second: 8,841.17082
Overall Steps per Second: 7,675.96813

Timestep Collection Time: 5.65740
Timestep Consumption Time: 0.85879
PPO Batch Consumption Time: 0.04999
Total Iteration Time: 6.51618

Cumulative Model Updates: 23,017
Cumulative Timesteps: 383,972,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.04036
Policy Entropy: 1.02234
Value Function Loss: 1.88003

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.19684
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.05949

Collected Steps per Second: 8,861.41326
Overall Steps per Second: 7,699.13007

Timestep Collection Time: 5.64537
Timestep Consumption Time: 0.85224
PPO Batch Consumption Time: 0.05289
Total Iteration Time: 6.49762

Cumulative Model Updates: 23,020
Cumulative Timesteps: 384,022,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 384022482...
Checkpoint 384022482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.85599
Policy Entropy: 1.03144
Value Function Loss: 1.82224

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17908
Policy Update Magnitude: 0.03916
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 8,791.75484
Overall Steps per Second: 7,788.72713

Timestep Collection Time: 5.68806
Timestep Consumption Time: 0.73250
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.42056

Cumulative Model Updates: 23,023
Cumulative Timesteps: 384,072,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.82815
Policy Entropy: 1.02346
Value Function Loss: 1.77630

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.17759
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.05318

Collected Steps per Second: 8,646.04068
Overall Steps per Second: 7,540.09957

Timestep Collection Time: 5.78600
Timestep Consumption Time: 0.84866
PPO Batch Consumption Time: 0.05063
Total Iteration Time: 6.63466

Cumulative Model Updates: 23,026
Cumulative Timesteps: 384,122,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 384122516...
Checkpoint 384122516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.47216
Policy Entropy: 1.00500
Value Function Loss: 2.04726

Mean KL Divergence: 0.04641
SB3 Clip Fraction: 0.23410
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.05682

Collected Steps per Second: 8,619.50566
Overall Steps per Second: 7,554.78789

Timestep Collection Time: 5.80149
Timestep Consumption Time: 0.81762
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.61911

Cumulative Model Updates: 23,029
Cumulative Timesteps: 384,172,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.21541
Policy Entropy: 1.03942
Value Function Loss: 2.13523

Mean KL Divergence: 0.03356
SB3 Clip Fraction: 0.19957
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.04763

Collected Steps per Second: 9,014.44625
Overall Steps per Second: 7,814.92732

Timestep Collection Time: 5.54931
Timestep Consumption Time: 0.85177
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.40108

Cumulative Model Updates: 23,032
Cumulative Timesteps: 384,222,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 384222546...
Checkpoint 384222546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.04658
Policy Entropy: 1.00265
Value Function Loss: 2.10628

Mean KL Divergence: 0.03034
SB3 Clip Fraction: 0.22572
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.03719

Collected Steps per Second: 8,809.33738
Overall Steps per Second: 7,698.01049

Timestep Collection Time: 5.67875
Timestep Consumption Time: 0.81981
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.49856

Cumulative Model Updates: 23,035
Cumulative Timesteps: 384,272,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.35764
Policy Entropy: 1.03739
Value Function Loss: 2.04530

Mean KL Divergence: 0.02989
SB3 Clip Fraction: 0.21875
Policy Update Magnitude: 0.03990
Value Function Update Magnitude: 0.04363

Collected Steps per Second: 8,713.18629
Overall Steps per Second: 7,622.98764

Timestep Collection Time: 5.73843
Timestep Consumption Time: 0.82068
PPO Batch Consumption Time: 0.04639
Total Iteration Time: 6.55911

Cumulative Model Updates: 23,038
Cumulative Timesteps: 384,322,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 384322572...
Checkpoint 384322572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.94569
Policy Entropy: 1.03403
Value Function Loss: 1.97540

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.20106
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 8,601.95520
Overall Steps per Second: 7,523.29439

Timestep Collection Time: 5.81286
Timestep Consumption Time: 0.83343
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 6.64629

Cumulative Model Updates: 23,041
Cumulative Timesteps: 384,372,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.36643
Policy Entropy: 1.03214
Value Function Loss: 2.10876

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.16319
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.04226

Collected Steps per Second: 8,526.45780
Overall Steps per Second: 7,416.81498

Timestep Collection Time: 5.86645
Timestep Consumption Time: 0.87769
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.74413

Cumulative Model Updates: 23,044
Cumulative Timesteps: 384,422,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 384422594...
Checkpoint 384422594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.25553
Policy Entropy: 1.01264
Value Function Loss: 2.29820

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.20321
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.03534

Collected Steps per Second: 9,006.84027
Overall Steps per Second: 7,807.44313

Timestep Collection Time: 5.55311
Timestep Consumption Time: 0.85308
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.40619

Cumulative Model Updates: 23,047
Cumulative Timesteps: 384,472,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.61218
Policy Entropy: 1.02945
Value Function Loss: 2.26259

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.03125

Collected Steps per Second: 8,833.46195
Overall Steps per Second: 7,622.31472

Timestep Collection Time: 5.66143
Timestep Consumption Time: 0.89957
PPO Batch Consumption Time: 0.04425
Total Iteration Time: 6.56100

Cumulative Model Updates: 23,050
Cumulative Timesteps: 384,522,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 384522620...
Checkpoint 384522620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.76070
Policy Entropy: 1.03595
Value Function Loss: 2.29625

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 8,593.34381
Overall Steps per Second: 7,633.76232

Timestep Collection Time: 5.82009
Timestep Consumption Time: 0.73160
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.55168

Cumulative Model Updates: 23,053
Cumulative Timesteps: 384,572,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.62147
Policy Entropy: 1.02688
Value Function Loss: 2.00946

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.03283

Collected Steps per Second: 8,938.19783
Overall Steps per Second: 7,741.43214

Timestep Collection Time: 5.59464
Timestep Consumption Time: 0.86489
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.45953

Cumulative Model Updates: 23,056
Cumulative Timesteps: 384,622,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 384622640...
Checkpoint 384622640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.15871
Policy Entropy: 1.02443
Value Function Loss: 2.05519

Mean KL Divergence: 0.02624
SB3 Clip Fraction: 0.23501
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.03751

Collected Steps per Second: 8,494.06941
Overall Steps per Second: 7,366.59900

Timestep Collection Time: 5.88999
Timestep Consumption Time: 0.90147
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 6.79147

Cumulative Model Updates: 23,059
Cumulative Timesteps: 384,672,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.41802
Policy Entropy: 1.04887
Value Function Loss: 2.13328

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.17047
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.03884

Collected Steps per Second: 8,668.37161
Overall Steps per Second: 7,441.72658

Timestep Collection Time: 5.77156
Timestep Consumption Time: 0.95135
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.72290

Cumulative Model Updates: 23,062
Cumulative Timesteps: 384,722,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 384722700...
Checkpoint 384722700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.95732
Policy Entropy: 1.04943
Value Function Loss: 2.21466

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 8,732.12124
Overall Steps per Second: 7,554.75981

Timestep Collection Time: 5.72805
Timestep Consumption Time: 0.89268
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.62073

Cumulative Model Updates: 23,065
Cumulative Timesteps: 384,772,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.35687
Policy Entropy: 1.04012
Value Function Loss: 2.10314

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.04996

Collected Steps per Second: 8,992.19681
Overall Steps per Second: 7,925.03472

Timestep Collection Time: 5.56305
Timestep Consumption Time: 0.74910
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.31215

Cumulative Model Updates: 23,068
Cumulative Timesteps: 384,822,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 384822742...
Checkpoint 384822742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.59639
Policy Entropy: 1.01901
Value Function Loss: 2.09530

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.20079
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.04915

Collected Steps per Second: 9,052.20890
Overall Steps per Second: 7,755.24783

Timestep Collection Time: 5.52616
Timestep Consumption Time: 0.92418
PPO Batch Consumption Time: 0.05070
Total Iteration Time: 6.45034

Cumulative Model Updates: 23,071
Cumulative Timesteps: 384,872,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.18141
Policy Entropy: 1.03208
Value Function Loss: 2.12280

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.05478

Collected Steps per Second: 8,895.00368
Overall Steps per Second: 7,689.16503

Timestep Collection Time: 5.62338
Timestep Consumption Time: 0.88188
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 6.50526

Cumulative Model Updates: 23,074
Cumulative Timesteps: 384,922,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 384922786...
Checkpoint 384922786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.49558
Policy Entropy: 1.05154
Value Function Loss: 2.22596

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.04849

Collected Steps per Second: 8,774.62979
Overall Steps per Second: 7,622.47645

Timestep Collection Time: 5.70053
Timestep Consumption Time: 0.86165
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.56217

Cumulative Model Updates: 23,077
Cumulative Timesteps: 384,972,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.33540
Policy Entropy: 1.01962
Value Function Loss: 2.05333

Mean KL Divergence: 0.03907
SB3 Clip Fraction: 0.19119
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 8,634.35351
Overall Steps per Second: 7,511.87399

Timestep Collection Time: 5.79291
Timestep Consumption Time: 0.86562
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 6.65852

Cumulative Model Updates: 23,080
Cumulative Timesteps: 385,022,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 385022824...
Checkpoint 385022824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.06062
Policy Entropy: 1.03944
Value Function Loss: 2.06883

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.19361
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 8,842.73789
Overall Steps per Second: 7,855.37305

Timestep Collection Time: 5.65571
Timestep Consumption Time: 0.71088
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.36660

Cumulative Model Updates: 23,083
Cumulative Timesteps: 385,072,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.44872
Policy Entropy: 1.04555
Value Function Loss: 2.08635

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.19922
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 8,729.73187
Overall Steps per Second: 7,567.52817

Timestep Collection Time: 5.73030
Timestep Consumption Time: 0.88005
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.61035

Cumulative Model Updates: 23,086
Cumulative Timesteps: 385,122,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385122860...
Checkpoint 385122860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.20398
Policy Entropy: 1.04136
Value Function Loss: 2.06051

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.17345
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 8,742.63676
Overall Steps per Second: 7,637.81420

Timestep Collection Time: 5.71978
Timestep Consumption Time: 0.82738
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.54716

Cumulative Model Updates: 23,089
Cumulative Timesteps: 385,172,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.98082
Policy Entropy: 1.03329
Value Function Loss: 1.92536

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.20209
Policy Update Magnitude: 0.04296
Value Function Update Magnitude: 0.04773

Collected Steps per Second: 9,048.42138
Overall Steps per Second: 7,774.23275

Timestep Collection Time: 5.52605
Timestep Consumption Time: 0.90571
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.43176

Cumulative Model Updates: 23,092
Cumulative Timesteps: 385,222,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 385222868...
Checkpoint 385222868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.88778
Policy Entropy: 1.03782
Value Function Loss: 1.87526

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.04113
Value Function Update Magnitude: 0.04739

Collected Steps per Second: 8,549.87080
Overall Steps per Second: 7,469.43155

Timestep Collection Time: 5.85038
Timestep Consumption Time: 0.84625
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.69663

Cumulative Model Updates: 23,095
Cumulative Timesteps: 385,272,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.48083
Policy Entropy: 1.03351
Value Function Loss: 1.98011

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.03725
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 8,850.84083
Overall Steps per Second: 7,738.22715

Timestep Collection Time: 5.65189
Timestep Consumption Time: 0.81264
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.46453

Cumulative Model Updates: 23,098
Cumulative Timesteps: 385,322,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385322912...
Checkpoint 385322912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.28899
Policy Entropy: 1.02853
Value Function Loss: 1.91179

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 8,793.31344
Overall Steps per Second: 7,576.32431

Timestep Collection Time: 5.68955
Timestep Consumption Time: 0.91392
PPO Batch Consumption Time: 0.04522
Total Iteration Time: 6.60347

Cumulative Model Updates: 23,101
Cumulative Timesteps: 385,372,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.21592
Policy Entropy: 1.00290
Value Function Loss: 1.96059

Mean KL Divergence: 0.03498
SB3 Clip Fraction: 0.24105
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.06120

Collected Steps per Second: 9,157.61744
Overall Steps per Second: 7,953.06790

Timestep Collection Time: 5.46321
Timestep Consumption Time: 0.82744
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.29065

Cumulative Model Updates: 23,104
Cumulative Timesteps: 385,422,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 385422972...
Checkpoint 385422972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.97705
Policy Entropy: 1.01428
Value Function Loss: 1.94847

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 8,822.91690
Overall Steps per Second: 7,675.03058

Timestep Collection Time: 5.67046
Timestep Consumption Time: 0.84808
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.51854

Cumulative Model Updates: 23,107
Cumulative Timesteps: 385,473,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.77991
Policy Entropy: 1.01665
Value Function Loss: 1.97759

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.04637

Collected Steps per Second: 9,077.77546
Overall Steps per Second: 7,937.54864

Timestep Collection Time: 5.50862
Timestep Consumption Time: 0.79131
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.29993

Cumulative Model Updates: 23,110
Cumulative Timesteps: 385,523,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 385523008...
Checkpoint 385523008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.23812
Policy Entropy: 1.01224
Value Function Loss: 1.96966

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.04055

Collected Steps per Second: 9,126.42256
Overall Steps per Second: 7,850.56122

Timestep Collection Time: 5.48079
Timestep Consumption Time: 0.89073
PPO Batch Consumption Time: 0.04719
Total Iteration Time: 6.37152

Cumulative Model Updates: 23,113
Cumulative Timesteps: 385,573,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.76491
Policy Entropy: 1.00654
Value Function Loss: 1.88098

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.04506

Collected Steps per Second: 9,132.42026
Overall Steps per Second: 7,881.59419

Timestep Collection Time: 5.47719
Timestep Consumption Time: 0.86924
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.34643

Cumulative Model Updates: 23,116
Cumulative Timesteps: 385,623,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 385623048...
Checkpoint 385623048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.44854
Policy Entropy: 1.01315
Value Function Loss: 1.91448

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 8,658.22753
Overall Steps per Second: 7,680.87722

Timestep Collection Time: 5.77532
Timestep Consumption Time: 0.73488
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.51019

Cumulative Model Updates: 23,119
Cumulative Timesteps: 385,673,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.25458
Policy Entropy: 1.01316
Value Function Loss: 1.90624

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.16253
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 8,634.74220
Overall Steps per Second: 7,553.01885

Timestep Collection Time: 5.79126
Timestep Consumption Time: 0.82941
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.62066

Cumulative Model Updates: 23,122
Cumulative Timesteps: 385,723,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 385723058...
Checkpoint 385723058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.92598
Policy Entropy: 1.01286
Value Function Loss: 1.90477

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.18386
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.06398

Collected Steps per Second: 8,697.10862
Overall Steps per Second: 7,609.32398

Timestep Collection Time: 5.75134
Timestep Consumption Time: 0.82218
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 6.57351

Cumulative Model Updates: 23,125
Cumulative Timesteps: 385,773,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.94232
Policy Entropy: 1.02699
Value Function Loss: 1.93641

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.18422
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.06394

Collected Steps per Second: 8,584.27956
Overall Steps per Second: 7,600.47304

Timestep Collection Time: 5.82623
Timestep Consumption Time: 0.75415
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.58038

Cumulative Model Updates: 23,128
Cumulative Timesteps: 385,823,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 385823092...
Checkpoint 385823092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.34067
Policy Entropy: 1.00560
Value Function Loss: 1.78756

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.21312
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 8,929.96980
Overall Steps per Second: 7,755.02446

Timestep Collection Time: 5.60091
Timestep Consumption Time: 0.84858
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.44950

Cumulative Model Updates: 23,131
Cumulative Timesteps: 385,873,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.76631
Policy Entropy: 1.00197
Value Function Loss: 1.75007

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.20880
Policy Update Magnitude: 0.03878
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 8,481.21608
Overall Steps per Second: 7,496.36195

Timestep Collection Time: 5.89868
Timestep Consumption Time: 0.77495
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.67364

Cumulative Model Updates: 23,134
Cumulative Timesteps: 385,923,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 385923136...
Checkpoint 385923136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.34339
Policy Entropy: 0.99752
Value Function Loss: 1.78601

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.17760
Policy Update Magnitude: 0.03889
Value Function Update Magnitude: 0.05964

Collected Steps per Second: 8,625.93004
Overall Steps per Second: 7,474.52862

Timestep Collection Time: 5.79879
Timestep Consumption Time: 0.89327
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.69206

Cumulative Model Updates: 23,137
Cumulative Timesteps: 385,973,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.28901
Policy Entropy: 0.99975
Value Function Loss: 2.00107

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.18769
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.05864

Collected Steps per Second: 8,715.29198
Overall Steps per Second: 7,600.60545

Timestep Collection Time: 5.73888
Timestep Consumption Time: 0.84165
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.58053

Cumulative Model Updates: 23,140
Cumulative Timesteps: 386,023,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 386023172...
Checkpoint 386023172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.59090
Policy Entropy: 0.97823
Value Function Loss: 2.04016

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.20424
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.05684

Collected Steps per Second: 8,707.76875
Overall Steps per Second: 7,598.82702

Timestep Collection Time: 5.74498
Timestep Consumption Time: 0.83840
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.58338

Cumulative Model Updates: 23,143
Cumulative Timesteps: 386,073,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.77678
Policy Entropy: 0.99664
Value Function Loss: 1.97545

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.21576
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.06117

Collected Steps per Second: 8,791.32672
Overall Steps per Second: 7,645.44462

Timestep Collection Time: 5.68811
Timestep Consumption Time: 0.85252
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.54063

Cumulative Model Updates: 23,146
Cumulative Timesteps: 386,123,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 386123204...
Checkpoint 386123204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.54917
Policy Entropy: 0.99193
Value Function Loss: 1.87302

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.19674
Policy Update Magnitude: 0.03728
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 8,380.66801
Overall Steps per Second: 7,409.52608

Timestep Collection Time: 5.96707
Timestep Consumption Time: 0.78208
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.74915

Cumulative Model Updates: 23,149
Cumulative Timesteps: 386,173,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.28397
Policy Entropy: 0.96746
Value Function Loss: 1.84777

Mean KL Divergence: 0.02670
SB3 Clip Fraction: 0.20593
Policy Update Magnitude: 0.04050
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 8,521.73738
Overall Steps per Second: 7,447.75766

Timestep Collection Time: 5.86899
Timestep Consumption Time: 0.84632
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.71531

Cumulative Model Updates: 23,152
Cumulative Timesteps: 386,223,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 386223226...
Checkpoint 386223226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.53763
Policy Entropy: 0.94307
Value Function Loss: 1.76728

Mean KL Divergence: 0.04246
SB3 Clip Fraction: 0.30168
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.04378

Collected Steps per Second: 8,846.91854
Overall Steps per Second: 7,738.50363

Timestep Collection Time: 5.65282
Timestep Consumption Time: 0.80967
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.46249

Cumulative Model Updates: 23,155
Cumulative Timesteps: 386,273,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.20608
Policy Entropy: 0.98695
Value Function Loss: 1.72197

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.26061
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.04551

Collected Steps per Second: 8,848.94723
Overall Steps per Second: 7,705.43569

Timestep Collection Time: 5.65378
Timestep Consumption Time: 0.83904
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.49282

Cumulative Model Updates: 23,158
Cumulative Timesteps: 386,323,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 386323266...
Checkpoint 386323266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.28128
Policy Entropy: 0.96510
Value Function Loss: 1.80242

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.22351
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.03958

Collected Steps per Second: 8,691.08552
Overall Steps per Second: 7,454.58496

Timestep Collection Time: 5.75647
Timestep Consumption Time: 0.95483
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.71131

Cumulative Model Updates: 23,161
Cumulative Timesteps: 386,373,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.71593
Policy Entropy: 0.99333
Value Function Loss: 1.83759

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.22907
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.04297

Collected Steps per Second: 8,768.17486
Overall Steps per Second: 7,649.48943

Timestep Collection Time: 5.70427
Timestep Consumption Time: 0.83421
PPO Batch Consumption Time: 0.04698
Total Iteration Time: 6.53848

Cumulative Model Updates: 23,164
Cumulative Timesteps: 386,423,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 386423312...
Checkpoint 386423312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.74736
Policy Entropy: 0.98435
Value Function Loss: 1.85842

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.19879
Policy Update Magnitude: 0.03944
Value Function Update Magnitude: 0.04106

Collected Steps per Second: 8,835.50846
Overall Steps per Second: 7,688.18443

Timestep Collection Time: 5.66057
Timestep Consumption Time: 0.84474
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.50531

Cumulative Model Updates: 23,167
Cumulative Timesteps: 386,473,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.41666
Policy Entropy: 0.96981
Value Function Loss: 1.68321

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.19517
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 8,849.68781
Overall Steps per Second: 7,745.27528

Timestep Collection Time: 5.65127
Timestep Consumption Time: 0.80582
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.45710

Cumulative Model Updates: 23,170
Cumulative Timesteps: 386,523,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 386523338...
Checkpoint 386523338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.05587
Policy Entropy: 0.96445
Value Function Loss: 1.75270

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.22319
Policy Update Magnitude: 0.03405
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 8,921.00053
Overall Steps per Second: 7,758.52312

Timestep Collection Time: 5.60699
Timestep Consumption Time: 0.84011
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.44710

Cumulative Model Updates: 23,173
Cumulative Timesteps: 386,573,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.50575
Policy Entropy: 0.96584
Value Function Loss: 1.70951

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.18282
Policy Update Magnitude: 0.03932
Value Function Update Magnitude: 0.04108

Collected Steps per Second: 8,674.63757
Overall Steps per Second: 7,554.55908

Timestep Collection Time: 5.76647
Timestep Consumption Time: 0.85497
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 6.62143

Cumulative Model Updates: 23,176
Cumulative Timesteps: 386,623,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 386623380...
Checkpoint 386623380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.21953
Policy Entropy: 0.96595
Value Function Loss: 1.76776

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.21121
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.03919

Collected Steps per Second: 8,831.85019
Overall Steps per Second: 7,837.17083

Timestep Collection Time: 5.66427
Timestep Consumption Time: 0.71890
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 6.38317

Cumulative Model Updates: 23,179
Cumulative Timesteps: 386,673,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.68178
Policy Entropy: 0.95733
Value Function Loss: 1.73492

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.04335

Collected Steps per Second: 8,738.14780
Overall Steps per Second: 7,639.79859

Timestep Collection Time: 5.72478
Timestep Consumption Time: 0.82303
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.54782

Cumulative Model Updates: 23,182
Cumulative Timesteps: 386,723,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 386723430...
Checkpoint 386723430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.26680
Policy Entropy: 0.92603
Value Function Loss: 1.80196

Mean KL Divergence: 0.04069
SB3 Clip Fraction: 0.25896
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.04291

Collected Steps per Second: 8,704.93807
Overall Steps per Second: 7,612.61465

Timestep Collection Time: 5.74616
Timestep Consumption Time: 0.82451
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.57067

Cumulative Model Updates: 23,185
Cumulative Timesteps: 386,773,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.20538
Policy Entropy: 0.95589
Value Function Loss: 1.89908

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.21621
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.04522

Collected Steps per Second: 9,097.70367
Overall Steps per Second: 7,841.64991

Timestep Collection Time: 5.49743
Timestep Consumption Time: 0.88056
PPO Batch Consumption Time: 0.04801
Total Iteration Time: 6.37799

Cumulative Model Updates: 23,188
Cumulative Timesteps: 386,823,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 386823464...
Checkpoint 386823464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.16291
Policy Entropy: 0.94753
Value Function Loss: 1.86436

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.18375
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.04006

Collected Steps per Second: 8,649.57536
Overall Steps per Second: 7,485.41452

Timestep Collection Time: 5.78063
Timestep Consumption Time: 0.89903
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.67966

Cumulative Model Updates: 23,191
Cumulative Timesteps: 386,873,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.44000
Policy Entropy: 0.94099
Value Function Loss: 1.82135

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.18064
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.03590

Collected Steps per Second: 8,520.66095
Overall Steps per Second: 7,595.32592

Timestep Collection Time: 5.86832
Timestep Consumption Time: 0.71494
PPO Batch Consumption Time: 0.03976
Total Iteration Time: 6.58326

Cumulative Model Updates: 23,194
Cumulative Timesteps: 386,923,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 386923466...
Checkpoint 386923466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.55493
Policy Entropy: 0.94603
Value Function Loss: 1.78847

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.20930
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.03523

Collected Steps per Second: 8,629.34847
Overall Steps per Second: 7,522.73055

Timestep Collection Time: 5.79766
Timestep Consumption Time: 0.85285
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.65051

Cumulative Model Updates: 23,197
Cumulative Timesteps: 386,973,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.88583
Policy Entropy: 0.94279
Value Function Loss: 2.02438

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.21533
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.03715

Collected Steps per Second: 8,735.44520
Overall Steps per Second: 7,643.68596

Timestep Collection Time: 5.72633
Timestep Consumption Time: 0.81790
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.54422

Cumulative Model Updates: 23,200
Cumulative Timesteps: 387,023,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 387023518...
Checkpoint 387023518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.72952
Policy Entropy: 0.94834
Value Function Loss: 2.03334

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.21533
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.04154

Collected Steps per Second: 8,693.76207
Overall Steps per Second: 7,562.53497

Timestep Collection Time: 5.75171
Timestep Consumption Time: 0.86036
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 6.61207

Cumulative Model Updates: 23,203
Cumulative Timesteps: 387,073,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.19448
Policy Entropy: 0.96563
Value Function Loss: 2.27277

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.22267
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 8,673.69672
Overall Steps per Second: 7,513.62334

Timestep Collection Time: 5.76709
Timestep Consumption Time: 0.89042
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 6.65751

Cumulative Model Updates: 23,206
Cumulative Timesteps: 387,123,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 387123544...
Checkpoint 387123544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.49870
Policy Entropy: 0.98564
Value Function Loss: 2.33282

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.25396
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.05169

Collected Steps per Second: 8,644.42254
Overall Steps per Second: 7,600.48704

Timestep Collection Time: 5.78755
Timestep Consumption Time: 0.79493
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.58247

Cumulative Model Updates: 23,209
Cumulative Timesteps: 387,173,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.70257
Policy Entropy: 0.97223
Value Function Loss: 2.37235

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.24187
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 8,722.63624
Overall Steps per Second: 7,554.90302

Timestep Collection Time: 5.73588
Timestep Consumption Time: 0.88657
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.62245

Cumulative Model Updates: 23,212
Cumulative Timesteps: 387,223,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 387223606...
Checkpoint 387223606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.05629
Policy Entropy: 0.97741
Value Function Loss: 2.32478

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.24603
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.05094

Collected Steps per Second: 9,202.87339
Overall Steps per Second: 7,945.96591

Timestep Collection Time: 5.43569
Timestep Consumption Time: 0.85983
PPO Batch Consumption Time: 0.05078
Total Iteration Time: 6.29552

Cumulative Model Updates: 23,215
Cumulative Timesteps: 387,273,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.53030
Policy Entropy: 0.99596
Value Function Loss: 2.19028

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.19003
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.05552

Collected Steps per Second: 8,793.32754
Overall Steps per Second: 7,742.90567

Timestep Collection Time: 5.68613
Timestep Consumption Time: 0.77139
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.45752

Cumulative Model Updates: 23,218
Cumulative Timesteps: 387,323,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 387323630...
Checkpoint 387323630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.77962
Policy Entropy: 0.99836
Value Function Loss: 2.10715

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.20400
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 8,970.87511
Overall Steps per Second: 7,748.05763

Timestep Collection Time: 5.57538
Timestep Consumption Time: 0.87992
PPO Batch Consumption Time: 0.04728
Total Iteration Time: 6.45530

Cumulative Model Updates: 23,221
Cumulative Timesteps: 387,373,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.13616
Policy Entropy: 0.98721
Value Function Loss: 2.01460

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.17105
Policy Update Magnitude: 0.04127
Value Function Update Magnitude: 0.06179

Collected Steps per Second: 9,045.03876
Overall Steps per Second: 7,781.05268

Timestep Collection Time: 5.52944
Timestep Consumption Time: 0.89822
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.42766

Cumulative Model Updates: 23,224
Cumulative Timesteps: 387,423,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 387423660...
Checkpoint 387423660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.54669
Policy Entropy: 0.96575
Value Function Loss: 1.96410

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.26519
Policy Update Magnitude: 0.03948
Value Function Update Magnitude: 0.06886

Collected Steps per Second: 8,794.18183
Overall Steps per Second: 7,631.90862

Timestep Collection Time: 5.68626
Timestep Consumption Time: 0.86597
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 6.55223

Cumulative Model Updates: 23,227
Cumulative Timesteps: 387,473,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.75745
Policy Entropy: 0.98767
Value Function Loss: 1.93592

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.16623
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.06530

Collected Steps per Second: 8,657.34796
Overall Steps per Second: 7,444.07957

Timestep Collection Time: 5.77636
Timestep Consumption Time: 0.94146
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.71782

Cumulative Model Updates: 23,230
Cumulative Timesteps: 387,523,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 387523674...
Checkpoint 387523674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.99576
Policy Entropy: 0.98453
Value Function Loss: 1.75179

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 8,801.85602
Overall Steps per Second: 7,769.27579

Timestep Collection Time: 5.68085
Timestep Consumption Time: 0.75502
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.43586

Cumulative Model Updates: 23,233
Cumulative Timesteps: 387,573,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.81106
Policy Entropy: 0.96838
Value Function Loss: 1.72467

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.05792

Collected Steps per Second: 8,972.99358
Overall Steps per Second: 7,764.32264

Timestep Collection Time: 5.57384
Timestep Consumption Time: 0.86768
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.44151

Cumulative Model Updates: 23,236
Cumulative Timesteps: 387,623,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 387623690...
Checkpoint 387623690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.38733
Policy Entropy: 0.95990
Value Function Loss: 1.73334

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.21300
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.05853

Collected Steps per Second: 8,872.71470
Overall Steps per Second: 7,765.93278

Timestep Collection Time: 5.63773
Timestep Consumption Time: 0.80348
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.44121

Cumulative Model Updates: 23,239
Cumulative Timesteps: 387,673,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.86438
Policy Entropy: 0.97169
Value Function Loss: 1.90744

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.04138
Value Function Update Magnitude: 0.06218

Collected Steps per Second: 8,891.39702
Overall Steps per Second: 7,669.69013

Timestep Collection Time: 5.62544
Timestep Consumption Time: 0.89608
PPO Batch Consumption Time: 0.05140
Total Iteration Time: 6.52152

Cumulative Model Updates: 23,242
Cumulative Timesteps: 387,723,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 387723730...
Checkpoint 387723730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.00579
Policy Entropy: 0.97798
Value Function Loss: 2.00975

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 8,479.57642
Overall Steps per Second: 7,454.66412

Timestep Collection Time: 5.89864
Timestep Consumption Time: 0.81098
PPO Batch Consumption Time: 0.04819
Total Iteration Time: 6.70962

Cumulative Model Updates: 23,245
Cumulative Timesteps: 387,773,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.48016
Policy Entropy: 0.97636
Value Function Loss: 2.01449

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 8,586.93896
Overall Steps per Second: 7,585.76168

Timestep Collection Time: 5.82629
Timestep Consumption Time: 0.76896
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.59525

Cumulative Model Updates: 23,248
Cumulative Timesteps: 387,823,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 387823778...
Checkpoint 387823778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.94553
Policy Entropy: 0.95609
Value Function Loss: 1.82467

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16613
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.05663

Collected Steps per Second: 8,677.48269
Overall Steps per Second: 7,587.83057

Timestep Collection Time: 5.76365
Timestep Consumption Time: 0.82769
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 6.59134

Cumulative Model Updates: 23,251
Cumulative Timesteps: 387,873,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.05702
Policy Entropy: 0.94175
Value Function Loss: 1.75532

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.23324
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.04583

Collected Steps per Second: 8,889.82601
Overall Steps per Second: 7,862.06283

Timestep Collection Time: 5.62576
Timestep Consumption Time: 0.73542
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 6.36118

Cumulative Model Updates: 23,254
Cumulative Timesteps: 387,923,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 387923804...
Checkpoint 387923804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.78930
Policy Entropy: 0.94383
Value Function Loss: 1.75298

Mean KL Divergence: 0.03664
SB3 Clip Fraction: 0.25309
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.04310

Collected Steps per Second: 8,829.61287
Overall Steps per Second: 7,530.73638

Timestep Collection Time: 5.66435
Timestep Consumption Time: 0.97697
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.64132

Cumulative Model Updates: 23,257
Cumulative Timesteps: 387,973,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.53137
Policy Entropy: 0.95074
Value Function Loss: 1.79078

Mean KL Divergence: 0.04303
SB3 Clip Fraction: 0.29215
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 8,756.01184
Overall Steps per Second: 7,695.19923

Timestep Collection Time: 5.71333
Timestep Consumption Time: 0.78760
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.50094

Cumulative Model Updates: 23,260
Cumulative Timesteps: 388,023,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 388023844...
Checkpoint 388023844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.80583
Policy Entropy: 0.94841
Value Function Loss: 1.83657

Mean KL Divergence: 0.05207
SB3 Clip Fraction: 0.31140
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.04104

Collected Steps per Second: 8,808.30709
Overall Steps per Second: 7,783.37755

Timestep Collection Time: 5.67850
Timestep Consumption Time: 0.74776
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.42626

Cumulative Model Updates: 23,263
Cumulative Timesteps: 388,073,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.53051
Policy Entropy: 0.97532
Value Function Loss: 1.96653

Mean KL Divergence: 0.03443
SB3 Clip Fraction: 0.24725
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.04701

Collected Steps per Second: 8,866.65031
Overall Steps per Second: 7,727.77646

Timestep Collection Time: 5.64069
Timestep Consumption Time: 0.83129
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.47198

Cumulative Model Updates: 23,266
Cumulative Timesteps: 388,123,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 388123876...
Checkpoint 388123876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.43690
Policy Entropy: 0.97513
Value Function Loss: 2.02903

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.18942
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 8,889.92591
Overall Steps per Second: 7,735.01878

Timestep Collection Time: 5.62637
Timestep Consumption Time: 0.84007
PPO Batch Consumption Time: 0.04323
Total Iteration Time: 6.46644

Cumulative Model Updates: 23,269
Cumulative Timesteps: 388,173,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.91376
Policy Entropy: 0.97039
Value Function Loss: 1.93515

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.16927
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.04225

Collected Steps per Second: 8,912.68441
Overall Steps per Second: 7,712.00641

Timestep Collection Time: 5.60998
Timestep Consumption Time: 0.87341
PPO Batch Consumption Time: 0.04741
Total Iteration Time: 6.48340

Cumulative Model Updates: 23,272
Cumulative Timesteps: 388,223,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 388223894...
Checkpoint 388223894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.59193
Policy Entropy: 0.94299
Value Function Loss: 1.79376

Mean KL Divergence: 0.03978
SB3 Clip Fraction: 0.23644
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.03926

Collected Steps per Second: 8,203.29891
Overall Steps per Second: 7,084.96039

Timestep Collection Time: 6.09657
Timestep Consumption Time: 0.96232
PPO Batch Consumption Time: 0.05095
Total Iteration Time: 7.05890

Cumulative Model Updates: 23,275
Cumulative Timesteps: 388,273,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.95033
Policy Entropy: 0.95950
Value Function Loss: 1.70560

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.19450
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.03885

Collected Steps per Second: 8,913.32519
Overall Steps per Second: 7,843.35170

Timestep Collection Time: 5.60958
Timestep Consumption Time: 0.76525
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.37483

Cumulative Model Updates: 23,278
Cumulative Timesteps: 388,323,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 388323906...
Checkpoint 388323906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.01166
Policy Entropy: 0.96314
Value Function Loss: 1.71898

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.20644
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 8,876.23981
Overall Steps per Second: 7,547.34559

Timestep Collection Time: 5.63302
Timestep Consumption Time: 0.99183
PPO Batch Consumption Time: 0.05064
Total Iteration Time: 6.62485

Cumulative Model Updates: 23,281
Cumulative Timesteps: 388,373,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.93580
Policy Entropy: 0.95610
Value Function Loss: 1.84901

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.20379
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.04484

Collected Steps per Second: 8,534.98331
Overall Steps per Second: 7,363.67211

Timestep Collection Time: 5.85848
Timestep Consumption Time: 0.93189
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.79036

Cumulative Model Updates: 23,284
Cumulative Timesteps: 388,423,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 388423908...
Checkpoint 388423908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.32404
Policy Entropy: 0.94808
Value Function Loss: 1.81829

Mean KL Divergence: 0.03820
SB3 Clip Fraction: 0.25587
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.04320

Collected Steps per Second: 8,867.17920
Overall Steps per Second: 7,712.30791

Timestep Collection Time: 5.64013
Timestep Consumption Time: 0.84457
PPO Batch Consumption Time: 0.05038
Total Iteration Time: 6.48470

Cumulative Model Updates: 23,287
Cumulative Timesteps: 388,473,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.95907
Policy Entropy: 0.96391
Value Function Loss: 1.89881

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.18931
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 8,783.07405
Overall Steps per Second: 7,664.53719

Timestep Collection Time: 5.69550
Timestep Consumption Time: 0.83118
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.52668

Cumulative Model Updates: 23,290
Cumulative Timesteps: 388,523,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 388523944...
Checkpoint 388523944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.24677
Policy Entropy: 0.96533
Value Function Loss: 1.76562

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.04043

Collected Steps per Second: 8,841.59685
Overall Steps per Second: 7,750.15712

Timestep Collection Time: 5.65735
Timestep Consumption Time: 0.79671
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 6.45406

Cumulative Model Updates: 23,293
Cumulative Timesteps: 388,573,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.60462
Policy Entropy: 0.96373
Value Function Loss: 1.82078

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.18782
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.03824

Collected Steps per Second: 8,796.84929
Overall Steps per Second: 7,624.07143

Timestep Collection Time: 5.68385
Timestep Consumption Time: 0.87432
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 6.55818

Cumulative Model Updates: 23,296
Cumulative Timesteps: 388,623,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 388623964...
Checkpoint 388623964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.92191
Policy Entropy: 0.95793
Value Function Loss: 1.69676

Mean KL Divergence: 0.02697
SB3 Clip Fraction: 0.23018
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 8,504.81997
Overall Steps per Second: 7,401.79089

Timestep Collection Time: 5.88208
Timestep Consumption Time: 0.87656
PPO Batch Consumption Time: 0.04652
Total Iteration Time: 6.75863

Cumulative Model Updates: 23,299
Cumulative Timesteps: 388,673,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.59917
Policy Entropy: 0.96832
Value Function Loss: 1.88239

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.25471
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05623

Collected Steps per Second: 8,813.01462
Overall Steps per Second: 7,643.64106

Timestep Collection Time: 5.67615
Timestep Consumption Time: 0.86837
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.54452

Cumulative Model Updates: 23,302
Cumulative Timesteps: 388,724,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 388724014...
Checkpoint 388724014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.86852
Policy Entropy: 0.95656
Value Function Loss: 1.90566

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.24359
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 8,937.86725
Overall Steps per Second: 7,736.22324

Timestep Collection Time: 5.59776
Timestep Consumption Time: 0.86948
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.46724

Cumulative Model Updates: 23,305
Cumulative Timesteps: 388,774,046

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.60405
Policy Entropy: 0.99147
Value Function Loss: 2.11007

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.22787
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.04880

Collected Steps per Second: 8,633.60052
Overall Steps per Second: 7,446.23362

Timestep Collection Time: 5.79411
Timestep Consumption Time: 0.92392
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 6.71803

Cumulative Model Updates: 23,308
Cumulative Timesteps: 388,824,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 388824070...
Checkpoint 388824070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.48102
Policy Entropy: 1.00202
Value Function Loss: 2.01780

Mean KL Divergence: 0.03405
SB3 Clip Fraction: 0.23028
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.04622

Collected Steps per Second: 8,890.19753
Overall Steps per Second: 7,687.88278

Timestep Collection Time: 5.62687
Timestep Consumption Time: 0.87999
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.50686

Cumulative Model Updates: 23,311
Cumulative Timesteps: 388,874,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.79099
Policy Entropy: 0.97679
Value Function Loss: 2.04319

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.21429
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.04215

Collected Steps per Second: 8,575.03826
Overall Steps per Second: 7,448.68699

Timestep Collection Time: 5.83438
Timestep Consumption Time: 0.88224
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.71662

Cumulative Model Updates: 23,314
Cumulative Timesteps: 388,924,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 388924124...
Checkpoint 388924124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.51564
Policy Entropy: 0.98532
Value Function Loss: 1.96706

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.19635
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.03428

Collected Steps per Second: 8,834.13226
Overall Steps per Second: 7,770.48697

Timestep Collection Time: 5.66213
Timestep Consumption Time: 0.77505
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.43718

Cumulative Model Updates: 23,317
Cumulative Timesteps: 388,974,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.91499
Policy Entropy: 0.99835
Value Function Loss: 1.90220

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.18503
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.03590

Collected Steps per Second: 8,774.05083
Overall Steps per Second: 7,608.07664

Timestep Collection Time: 5.70113
Timestep Consumption Time: 0.87373
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.57485

Cumulative Model Updates: 23,320
Cumulative Timesteps: 389,024,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 389024166...
Checkpoint 389024166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.55304
Policy Entropy: 1.01390
Value Function Loss: 1.83557

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.20301
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.03719

Collected Steps per Second: 8,934.77938
Overall Steps per Second: 7,750.92660

Timestep Collection Time: 5.59924
Timestep Consumption Time: 0.85521
PPO Batch Consumption Time: 0.04765
Total Iteration Time: 6.45445

Cumulative Model Updates: 23,323
Cumulative Timesteps: 389,074,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.94318
Policy Entropy: 0.99754
Value Function Loss: 1.85086

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.04837

Collected Steps per Second: 9,109.15084
Overall Steps per Second: 7,874.31825

Timestep Collection Time: 5.49030
Timestep Consumption Time: 0.86098
PPO Batch Consumption Time: 0.04208
Total Iteration Time: 6.35128

Cumulative Model Updates: 23,326
Cumulative Timesteps: 389,124,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 389124206...
Checkpoint 389124206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.32703
Policy Entropy: 1.00399
Value Function Loss: 1.92870

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.17273
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.04809

Collected Steps per Second: 9,272.76462
Overall Steps per Second: 8,032.58487

Timestep Collection Time: 5.39429
Timestep Consumption Time: 0.83284
PPO Batch Consumption Time: 0.04693
Total Iteration Time: 6.22714

Cumulative Model Updates: 23,329
Cumulative Timesteps: 389,174,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.61933
Policy Entropy: 1.01373
Value Function Loss: 1.98227

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.16347
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.05573

Collected Steps per Second: 9,098.21482
Overall Steps per Second: 7,996.77085

Timestep Collection Time: 5.49668
Timestep Consumption Time: 0.75709
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.25377

Cumulative Model Updates: 23,332
Cumulative Timesteps: 389,224,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 389224236...
Checkpoint 389224236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.06271
Policy Entropy: 1.01776
Value Function Loss: 1.96357

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.05220

Collected Steps per Second: 9,159.73954
Overall Steps per Second: 7,838.36071

Timestep Collection Time: 5.45867
Timestep Consumption Time: 0.92021
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 6.37888

Cumulative Model Updates: 23,335
Cumulative Timesteps: 389,274,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.32700
Policy Entropy: 1.00820
Value Function Loss: 1.98840

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.06430

Collected Steps per Second: 8,793.21431
Overall Steps per Second: 7,725.68618

Timestep Collection Time: 5.68848
Timestep Consumption Time: 0.78603
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.47451

Cumulative Model Updates: 23,338
Cumulative Timesteps: 389,324,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 389324256...
Checkpoint 389324256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.60052
Policy Entropy: 1.00047
Value Function Loss: 1.81765

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.20739
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.05692

Collected Steps per Second: 8,562.25832
Overall Steps per Second: 7,437.62757

Timestep Collection Time: 5.84215
Timestep Consumption Time: 0.88338
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.72553

Cumulative Model Updates: 23,341
Cumulative Timesteps: 389,374,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.20384
Policy Entropy: 1.02129
Value Function Loss: 1.81878

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15437
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.04922

Collected Steps per Second: 8,894.51430
Overall Steps per Second: 7,693.99094

Timestep Collection Time: 5.62369
Timestep Consumption Time: 0.87749
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.50118

Cumulative Model Updates: 23,344
Cumulative Timesteps: 389,424,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 389424298...
Checkpoint 389424298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.96086
Policy Entropy: 1.03481
Value Function Loss: 1.69027

Mean KL Divergence: 0.02750
SB3 Clip Fraction: 0.21734
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 8,708.67139
Overall Steps per Second: 7,679.87515

Timestep Collection Time: 5.74462
Timestep Consumption Time: 0.76955
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.51417

Cumulative Model Updates: 23,347
Cumulative Timesteps: 389,474,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.27349
Policy Entropy: 1.02391
Value Function Loss: 1.83318

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06254

Collected Steps per Second: 8,963.47182
Overall Steps per Second: 7,820.11185

Timestep Collection Time: 5.57976
Timestep Consumption Time: 0.81580
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 6.39556

Cumulative Model Updates: 23,350
Cumulative Timesteps: 389,524,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 389524340...
Checkpoint 389524340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.54431
Policy Entropy: 0.99724
Value Function Loss: 1.71724

Mean KL Divergence: 0.03636
SB3 Clip Fraction: 0.25013
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 8,828.47437
Overall Steps per Second: 7,523.89487

Timestep Collection Time: 5.66417
Timestep Consumption Time: 0.98212
PPO Batch Consumption Time: 0.04834
Total Iteration Time: 6.64629

Cumulative Model Updates: 23,353
Cumulative Timesteps: 389,574,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.13816
Policy Entropy: 1.02732
Value Function Loss: 1.83037

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.20719
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.05844

Collected Steps per Second: 9,050.85652
Overall Steps per Second: 7,785.49781

Timestep Collection Time: 5.52633
Timestep Consumption Time: 0.89818
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.42451

Cumulative Model Updates: 23,356
Cumulative Timesteps: 389,624,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 389624364...
Checkpoint 389624364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.32286
Policy Entropy: 0.99691
Value Function Loss: 1.68642

Mean KL Divergence: 0.03638
SB3 Clip Fraction: 0.27130
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 8,698.22527
Overall Steps per Second: 7,550.19154

Timestep Collection Time: 5.75014
Timestep Consumption Time: 0.87433
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.62447

Cumulative Model Updates: 23,359
Cumulative Timesteps: 389,674,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.77258
Policy Entropy: 1.02510
Value Function Loss: 1.87922

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.18331
Policy Update Magnitude: 0.03876
Value Function Update Magnitude: 0.06737

Collected Steps per Second: 8,583.26676
Overall Steps per Second: 7,593.15580

Timestep Collection Time: 5.82529
Timestep Consumption Time: 0.75959
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.58488

Cumulative Model Updates: 23,362
Cumulative Timesteps: 389,724,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 389724380...
Checkpoint 389724380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.82739
Policy Entropy: 1.02216
Value Function Loss: 1.75429

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.19543
Policy Update Magnitude: 0.04394
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 8,673.07036
Overall Steps per Second: 7,555.39830

Timestep Collection Time: 5.76497
Timestep Consumption Time: 0.85281
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 6.61778

Cumulative Model Updates: 23,365
Cumulative Timesteps: 389,774,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.60810
Policy Entropy: 1.01291
Value Function Loss: 1.83207

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.05659

Collected Steps per Second: 8,694.44596
Overall Steps per Second: 7,601.16887

Timestep Collection Time: 5.75356
Timestep Consumption Time: 0.82753
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 6.58109

Cumulative Model Updates: 23,368
Cumulative Timesteps: 389,824,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 389824404...
Checkpoint 389824404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.66148
Policy Entropy: 1.00251
Value Function Loss: 1.65966

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.05200

Collected Steps per Second: 8,939.13243
Overall Steps per Second: 7,895.33553

Timestep Collection Time: 5.59361
Timestep Consumption Time: 0.73950
PPO Batch Consumption Time: 0.04503
Total Iteration Time: 6.33311

Cumulative Model Updates: 23,371
Cumulative Timesteps: 389,874,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.79443
Policy Entropy: 1.01661
Value Function Loss: 1.76227

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 8,763.66252
Overall Steps per Second: 7,628.73451

Timestep Collection Time: 5.70743
Timestep Consumption Time: 0.84910
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.55653

Cumulative Model Updates: 23,374
Cumulative Timesteps: 389,924,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 389924424...
Checkpoint 389924424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.78424
Policy Entropy: 1.01555
Value Function Loss: 1.83618

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 8,731.66010
Overall Steps per Second: 7,730.18797

Timestep Collection Time: 5.72698
Timestep Consumption Time: 0.74195
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.46892

Cumulative Model Updates: 23,377
Cumulative Timesteps: 389,974,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.27045
Policy Entropy: 1.03277
Value Function Loss: 1.84436

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.21076
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 8,889.69608
Overall Steps per Second: 7,732.77052

Timestep Collection Time: 5.62606
Timestep Consumption Time: 0.84173
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.46780

Cumulative Model Updates: 23,380
Cumulative Timesteps: 390,024,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 390024444...
Checkpoint 390024444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.39730
Policy Entropy: 1.01805
Value Function Loss: 1.75004

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.17107
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.05445

Collected Steps per Second: 8,722.83876
Overall Steps per Second: 7,647.27651

Timestep Collection Time: 5.73345
Timestep Consumption Time: 0.80639
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.53984

Cumulative Model Updates: 23,383
Cumulative Timesteps: 390,074,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.65956
Policy Entropy: 1.00990
Value Function Loss: 1.90466

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.20190
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.04565

Collected Steps per Second: 8,821.01838
Overall Steps per Second: 7,756.72881

Timestep Collection Time: 5.66851
Timestep Consumption Time: 0.77777
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 6.44627

Cumulative Model Updates: 23,386
Cumulative Timesteps: 390,124,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 390124458...
Checkpoint 390124458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.52014
Policy Entropy: 1.02229
Value Function Loss: 2.08398

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 8,961.54007
Overall Steps per Second: 7,688.15739

Timestep Collection Time: 5.58163
Timestep Consumption Time: 0.92448
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 6.50611

Cumulative Model Updates: 23,389
Cumulative Timesteps: 390,174,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.72150
Policy Entropy: 1.03071
Value Function Loss: 2.28565

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.18096
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.04062

Collected Steps per Second: 8,699.02914
Overall Steps per Second: 7,575.49568

Timestep Collection Time: 5.75099
Timestep Consumption Time: 0.85294
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.60392

Cumulative Model Updates: 23,392
Cumulative Timesteps: 390,224,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 390224506...
Checkpoint 390224506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.37346
Policy Entropy: 1.01373
Value Function Loss: 2.11479

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.05764

Collected Steps per Second: 8,901.43347
Overall Steps per Second: 7,708.33738

Timestep Collection Time: 5.61865
Timestep Consumption Time: 0.86965
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 6.48830

Cumulative Model Updates: 23,395
Cumulative Timesteps: 390,274,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.29039
Policy Entropy: 1.00465
Value Function Loss: 1.93500

Mean KL Divergence: 0.02858
SB3 Clip Fraction: 0.17486
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.04981

Collected Steps per Second: 8,833.22081
Overall Steps per Second: 7,650.11898

Timestep Collection Time: 5.66339
Timestep Consumption Time: 0.87585
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 6.53924

Cumulative Model Updates: 23,398
Cumulative Timesteps: 390,324,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 390324546...
Checkpoint 390324546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.42098
Policy Entropy: 1.02397
Value Function Loss: 1.91828

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 8,884.18338
Overall Steps per Second: 7,862.62350

Timestep Collection Time: 5.62933
Timestep Consumption Time: 0.73140
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.36073

Cumulative Model Updates: 23,401
Cumulative Timesteps: 390,374,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.60001
Policy Entropy: 1.03768
Value Function Loss: 1.93568

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.17787
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.04310

Collected Steps per Second: 8,761.42359
Overall Steps per Second: 7,647.79964

Timestep Collection Time: 5.70889
Timestep Consumption Time: 0.83129
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.54018

Cumulative Model Updates: 23,404
Cumulative Timesteps: 390,424,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 390424576...
Checkpoint 390424576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.46713
Policy Entropy: 1.02415
Value Function Loss: 2.00727

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.20406
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.05032

Collected Steps per Second: 8,829.22758
Overall Steps per Second: 7,666.41517

Timestep Collection Time: 5.66482
Timestep Consumption Time: 0.85922
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.52404

Cumulative Model Updates: 23,407
Cumulative Timesteps: 390,474,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.35626
Policy Entropy: 1.02542
Value Function Loss: 1.88370

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.03670

Collected Steps per Second: 8,796.14598
Overall Steps per Second: 7,657.19298

Timestep Collection Time: 5.68726
Timestep Consumption Time: 0.84594
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.53320

Cumulative Model Updates: 23,410
Cumulative Timesteps: 390,524,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 390524618...
Checkpoint 390524618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.02414
Policy Entropy: 1.02573
Value Function Loss: 1.81556

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.03177

Collected Steps per Second: 8,887.23342
Overall Steps per Second: 7,632.51404

Timestep Collection Time: 5.62875
Timestep Consumption Time: 0.92532
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.55407

Cumulative Model Updates: 23,413
Cumulative Timesteps: 390,574,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.10856
Policy Entropy: 1.03821
Value Function Loss: 1.89955

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 8,799.09877
Overall Steps per Second: 7,810.49144

Timestep Collection Time: 5.68399
Timestep Consumption Time: 0.71945
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 6.40344

Cumulative Model Updates: 23,416
Cumulative Timesteps: 390,624,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 390624656...
Checkpoint 390624656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.26360
Policy Entropy: 1.01000
Value Function Loss: 1.87847

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.20035
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.04518

Collected Steps per Second: 8,761.00853
Overall Steps per Second: 7,568.46159

Timestep Collection Time: 5.71007
Timestep Consumption Time: 0.89972
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.60980

Cumulative Model Updates: 23,419
Cumulative Timesteps: 390,674,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.00858
Policy Entropy: 1.03417
Value Function Loss: 2.01445

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.18149
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.04079

Collected Steps per Second: 8,624.49109
Overall Steps per Second: 7,390.85577

Timestep Collection Time: 5.79976
Timestep Consumption Time: 0.96806
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.76782

Cumulative Model Updates: 23,422
Cumulative Timesteps: 390,724,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 390724702...
Checkpoint 390724702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.00249
Policy Entropy: 1.05068
Value Function Loss: 2.01460

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.24294
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.04076

Collected Steps per Second: 8,582.81004
Overall Steps per Second: 7,571.80256

Timestep Collection Time: 5.82676
Timestep Consumption Time: 0.77801
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.60477

Cumulative Model Updates: 23,425
Cumulative Timesteps: 390,774,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.87080
Policy Entropy: 1.06996
Value Function Loss: 2.08886

Mean KL Divergence: 0.03102
SB3 Clip Fraction: 0.25564
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 8,905.84503
Overall Steps per Second: 7,711.95874

Timestep Collection Time: 5.61564
Timestep Consumption Time: 0.86936
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.48499

Cumulative Model Updates: 23,428
Cumulative Timesteps: 390,824,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 390824724...
Checkpoint 390824724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.54711
Policy Entropy: 1.04765
Value Function Loss: 2.15891

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.18847
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 8,540.63059
Overall Steps per Second: 7,464.92156

Timestep Collection Time: 5.85765
Timestep Consumption Time: 0.84410
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.70174

Cumulative Model Updates: 23,431
Cumulative Timesteps: 390,874,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.25425
Policy Entropy: 1.07204
Value Function Loss: 2.26256

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.22531
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.05478

Collected Steps per Second: 9,121.19294
Overall Steps per Second: 7,847.43740

Timestep Collection Time: 5.48174
Timestep Consumption Time: 0.88977
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.37151

Cumulative Model Updates: 23,434
Cumulative Timesteps: 390,924,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 390924752...
Checkpoint 390924752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.01525
Policy Entropy: 1.08051
Value Function Loss: 2.31564

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.20203
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.06749

Collected Steps per Second: 8,813.32764
Overall Steps per Second: 7,670.47281

Timestep Collection Time: 5.67436
Timestep Consumption Time: 0.84545
PPO Batch Consumption Time: 0.03975
Total Iteration Time: 6.51981

Cumulative Model Updates: 23,437
Cumulative Timesteps: 390,974,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.41345
Policy Entropy: 1.06747
Value Function Loss: 2.28926

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.17060
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.06622

Collected Steps per Second: 8,687.22005
Overall Steps per Second: 7,580.52236

Timestep Collection Time: 5.75604
Timestep Consumption Time: 0.84034
PPO Batch Consumption Time: 0.04719
Total Iteration Time: 6.59638

Cumulative Model Updates: 23,440
Cumulative Timesteps: 391,024,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 391024766...
Checkpoint 391024766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.89315
Policy Entropy: 1.06843
Value Function Loss: 2.28084

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.19056
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 8,475.70827
Overall Steps per Second: 7,334.30394

Timestep Collection Time: 5.90228
Timestep Consumption Time: 0.91854
PPO Batch Consumption Time: 0.04847
Total Iteration Time: 6.82082

Cumulative Model Updates: 23,443
Cumulative Timesteps: 391,074,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.51994
Policy Entropy: 1.08350
Value Function Loss: 2.26988

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.16635
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 8,389.75409
Overall Steps per Second: 7,274.76530

Timestep Collection Time: 5.96203
Timestep Consumption Time: 0.91379
PPO Batch Consumption Time: 0.04845
Total Iteration Time: 6.87582

Cumulative Model Updates: 23,446
Cumulative Timesteps: 391,124,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 391124812...
Checkpoint 391124812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.09195
Policy Entropy: 1.09916
Value Function Loss: 2.29146

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.20654
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 8,226.22676
Overall Steps per Second: 6,909.31098

Timestep Collection Time: 6.07812
Timestep Consumption Time: 1.15849
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 7.23661

Cumulative Model Updates: 23,449
Cumulative Timesteps: 391,174,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.81438
Policy Entropy: 1.07778
Value Function Loss: 2.18209

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.18961
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.07033

Collected Steps per Second: 8,146.36213
Overall Steps per Second: 6,979.99654

Timestep Collection Time: 6.13820
Timestep Consumption Time: 1.02570
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 7.16390

Cumulative Model Updates: 23,452
Cumulative Timesteps: 391,224,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 391224816...
Checkpoint 391224816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.09850
Policy Entropy: 1.10100
Value Function Loss: 2.27682

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.19561
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 8,338.91045
Overall Steps per Second: 7,343.04606

Timestep Collection Time: 5.99623
Timestep Consumption Time: 0.81321
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 6.80944

Cumulative Model Updates: 23,455
Cumulative Timesteps: 391,274,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.79478
Policy Entropy: 1.11242
Value Function Loss: 2.25630

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.17701
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.07214

Collected Steps per Second: 8,680.99557
Overall Steps per Second: 7,514.13188

Timestep Collection Time: 5.76247
Timestep Consumption Time: 0.89485
PPO Batch Consumption Time: 0.04323
Total Iteration Time: 6.65732

Cumulative Model Updates: 23,458
Cumulative Timesteps: 391,324,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 391324842...
Checkpoint 391324842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.72272
Policy Entropy: 1.10786
Value Function Loss: 2.40677

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.17745
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 8,748.88787
Overall Steps per Second: 7,525.34083

Timestep Collection Time: 5.71821
Timestep Consumption Time: 0.92973
PPO Batch Consumption Time: 0.05245
Total Iteration Time: 6.64794

Cumulative Model Updates: 23,461
Cumulative Timesteps: 391,374,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.94009
Policy Entropy: 1.10890
Value Function Loss: 2.50049

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.18251
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.09942

Collected Steps per Second: 8,575.24684
Overall Steps per Second: 7,515.17427

Timestep Collection Time: 5.83353
Timestep Consumption Time: 0.82286
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.65640

Cumulative Model Updates: 23,464
Cumulative Timesteps: 391,424,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 391424894...
Checkpoint 391424894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.74537
Policy Entropy: 1.11995
Value Function Loss: 2.48573

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.09698

Collected Steps per Second: 8,806.76567
Overall Steps per Second: 7,604.52053

Timestep Collection Time: 5.67836
Timestep Consumption Time: 0.89773
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 6.57609

Cumulative Model Updates: 23,467
Cumulative Timesteps: 391,474,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.42194
Policy Entropy: 1.12405
Value Function Loss: 2.47226

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.15945
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.10040

Collected Steps per Second: 8,760.86478
Overall Steps per Second: 7,685.78469

Timestep Collection Time: 5.70811
Timestep Consumption Time: 0.79845
PPO Batch Consumption Time: 0.04677
Total Iteration Time: 6.50656

Cumulative Model Updates: 23,470
Cumulative Timesteps: 391,524,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 391524910...
Checkpoint 391524910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.21937
Policy Entropy: 1.10898
Value Function Loss: 2.34977

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 8,683.51870
Overall Steps per Second: 7,479.48704

Timestep Collection Time: 5.75942
Timestep Consumption Time: 0.92714
PPO Batch Consumption Time: 0.05003
Total Iteration Time: 6.68655

Cumulative Model Updates: 23,473
Cumulative Timesteps: 391,574,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.22032
Policy Entropy: 1.08287
Value Function Loss: 2.30939

Mean KL Divergence: 0.03674
SB3 Clip Fraction: 0.21303
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 8,669.42026
Overall Steps per Second: 7,618.49708

Timestep Collection Time: 5.76947
Timestep Consumption Time: 0.79586
PPO Batch Consumption Time: 0.04067
Total Iteration Time: 6.56534

Cumulative Model Updates: 23,476
Cumulative Timesteps: 391,624,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 391624940...
Checkpoint 391624940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.45494
Policy Entropy: 1.11503
Value Function Loss: 2.30995

Mean KL Divergence: 0.04041
SB3 Clip Fraction: 0.20720
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.09811

Collected Steps per Second: 8,684.02233
Overall Steps per Second: 7,578.18251

Timestep Collection Time: 5.75954
Timestep Consumption Time: 0.84046
PPO Batch Consumption Time: 0.04733
Total Iteration Time: 6.60000

Cumulative Model Updates: 23,479
Cumulative Timesteps: 391,674,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.32128
Policy Entropy: 1.07841
Value Function Loss: 2.20303

Mean KL Divergence: 0.06246
SB3 Clip Fraction: 0.30555
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 9,187.56022
Overall Steps per Second: 7,978.28332

Timestep Collection Time: 5.44366
Timestep Consumption Time: 0.82510
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.26877

Cumulative Model Updates: 23,482
Cumulative Timesteps: 391,724,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 391724970...
Checkpoint 391724970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.58781
Policy Entropy: 1.10012
Value Function Loss: 2.10022

Mean KL Divergence: 0.03830
SB3 Clip Fraction: 0.22241
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 9,086.14748
Overall Steps per Second: 7,943.34497

Timestep Collection Time: 5.50596
Timestep Consumption Time: 0.79214
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.29810

Cumulative Model Updates: 23,485
Cumulative Timesteps: 391,774,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.46447
Policy Entropy: 1.07020
Value Function Loss: 1.96156

Mean KL Divergence: 0.05856
SB3 Clip Fraction: 0.31955
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.06661

Collected Steps per Second: 9,143.80795
Overall Steps per Second: 7,893.18961

Timestep Collection Time: 5.46949
Timestep Consumption Time: 0.86660
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.33610

Cumulative Model Updates: 23,488
Cumulative Timesteps: 391,825,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 391825010...
Checkpoint 391825010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.84236
Policy Entropy: 1.09803
Value Function Loss: 2.07113

Mean KL Divergence: 0.03220
SB3 Clip Fraction: 0.23614
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 8,725.46019
Overall Steps per Second: 7,722.47308

Timestep Collection Time: 5.73059
Timestep Consumption Time: 0.74428
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.47487

Cumulative Model Updates: 23,491
Cumulative Timesteps: 391,875,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.96233
Policy Entropy: 1.06739
Value Function Loss: 1.98839

Mean KL Divergence: 0.03729
SB3 Clip Fraction: 0.25595
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 9,255.51504
Overall Steps per Second: 8,032.89011

Timestep Collection Time: 5.40413
Timestep Consumption Time: 0.82252
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.22665

Cumulative Model Updates: 23,494
Cumulative Timesteps: 391,925,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 391925030...
Checkpoint 391925030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.24932
Policy Entropy: 1.08625
Value Function Loss: 1.86327

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 9,078.28572
Overall Steps per Second: 7,866.34975

Timestep Collection Time: 5.50919
Timestep Consumption Time: 0.84878
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 6.35797

Cumulative Model Updates: 23,497
Cumulative Timesteps: 391,975,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.86185
Policy Entropy: 1.07837
Value Function Loss: 1.86424

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.17873
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.06614

Collected Steps per Second: 9,391.30064
Overall Steps per Second: 8,079.43048

Timestep Collection Time: 5.32450
Timestep Consumption Time: 0.86455
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.18905

Cumulative Model Updates: 23,500
Cumulative Timesteps: 392,025,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 392025048...
Checkpoint 392025048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.27018
Policy Entropy: 1.06195
Value Function Loss: 1.78934

Mean KL Divergence: 0.03182
SB3 Clip Fraction: 0.24297
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.05501

Collected Steps per Second: 9,035.42022
Overall Steps per Second: 7,881.94074

Timestep Collection Time: 5.53665
Timestep Consumption Time: 0.81026
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.34691

Cumulative Model Updates: 23,503
Cumulative Timesteps: 392,075,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.85520
Policy Entropy: 1.07492
Value Function Loss: 1.92906

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.20617
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.05874

Collected Steps per Second: 8,900.18751
Overall Steps per Second: 7,877.86674

Timestep Collection Time: 5.62145
Timestep Consumption Time: 0.72950
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 6.35096

Cumulative Model Updates: 23,506
Cumulative Timesteps: 392,125,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 392125106...
Checkpoint 392125106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.13771
Policy Entropy: 1.06440
Value Function Loss: 1.92118

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.20001
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 9,116.49865
Overall Steps per Second: 7,906.62717

Timestep Collection Time: 5.48544
Timestep Consumption Time: 0.83938
PPO Batch Consumption Time: 0.04686
Total Iteration Time: 6.32482

Cumulative Model Updates: 23,509
Cumulative Timesteps: 392,175,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.39289
Policy Entropy: 1.05539
Value Function Loss: 2.05027

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.19589
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 9,083.73214
Overall Steps per Second: 7,911.77412

Timestep Collection Time: 5.50589
Timestep Consumption Time: 0.81558
PPO Batch Consumption Time: 0.03827
Total Iteration Time: 6.32146

Cumulative Model Updates: 23,512
Cumulative Timesteps: 392,225,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 392225128...
Checkpoint 392225128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.48385
Policy Entropy: 1.05901
Value Function Loss: 1.89515

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.18430
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.05244

Collected Steps per Second: 9,273.94489
Overall Steps per Second: 8,052.98861

Timestep Collection Time: 5.39404
Timestep Consumption Time: 0.81782
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.21186

Cumulative Model Updates: 23,515
Cumulative Timesteps: 392,275,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.16057
Policy Entropy: 1.05572
Value Function Loss: 1.76770

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.17575
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 9,013.65298
Overall Steps per Second: 7,746.13580

Timestep Collection Time: 5.54803
Timestep Consumption Time: 0.90784
PPO Batch Consumption Time: 0.04465
Total Iteration Time: 6.45586

Cumulative Model Updates: 23,518
Cumulative Timesteps: 392,325,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 392325160...
Checkpoint 392325160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.09937
Policy Entropy: 1.04918
Value Function Loss: 1.58702

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.17935
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 9,074.93703
Overall Steps per Second: 8,006.58251

Timestep Collection Time: 5.51144
Timestep Consumption Time: 0.73542
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.24686

Cumulative Model Updates: 23,521
Cumulative Timesteps: 392,375,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.72045
Policy Entropy: 1.03150
Value Function Loss: 1.67374

Mean KL Divergence: 0.03221
SB3 Clip Fraction: 0.22492
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 8,782.90949
Overall Steps per Second: 7,600.18961

Timestep Collection Time: 5.69538
Timestep Consumption Time: 0.88630
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.58168

Cumulative Model Updates: 23,524
Cumulative Timesteps: 392,425,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 392425198...
Checkpoint 392425198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.91013
Policy Entropy: 1.04565
Value Function Loss: 1.84140

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.06086

Collected Steps per Second: 8,723.15651
Overall Steps per Second: 7,576.57972

Timestep Collection Time: 5.73370
Timestep Consumption Time: 0.86769
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.60140

Cumulative Model Updates: 23,527
Cumulative Timesteps: 392,475,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.87967
Policy Entropy: 1.04900
Value Function Loss: 1.94777

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.15636
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.04991

Collected Steps per Second: 8,789.40650
Overall Steps per Second: 7,679.53791

Timestep Collection Time: 5.69140
Timestep Consumption Time: 0.82254
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 6.51393

Cumulative Model Updates: 23,530
Cumulative Timesteps: 392,525,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 392525238...
Checkpoint 392525238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.63715
Policy Entropy: 1.02953
Value Function Loss: 1.90879

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.04500

Collected Steps per Second: 8,487.25981
Overall Steps per Second: 7,387.22128

Timestep Collection Time: 5.89260
Timestep Consumption Time: 0.87747
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.77007

Cumulative Model Updates: 23,533
Cumulative Timesteps: 392,575,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.37235
Policy Entropy: 1.00845
Value Function Loss: 1.78335

Mean KL Divergence: 0.04161
SB3 Clip Fraction: 0.23997
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.04124

Collected Steps per Second: 8,801.84905
Overall Steps per Second: 7,723.54424

Timestep Collection Time: 5.68267
Timestep Consumption Time: 0.79337
PPO Batch Consumption Time: 0.04707
Total Iteration Time: 6.47604

Cumulative Model Updates: 23,536
Cumulative Timesteps: 392,625,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 392625268...
Checkpoint 392625268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.79959
Policy Entropy: 1.01877
Value Function Loss: 1.81469

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.03916

Collected Steps per Second: 8,775.95790
Overall Steps per Second: 7,610.66118

Timestep Collection Time: 5.70035
Timestep Consumption Time: 0.87280
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.57315

Cumulative Model Updates: 23,539
Cumulative Timesteps: 392,675,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.46899
Policy Entropy: 1.02100
Value Function Loss: 1.73198

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.03506

Collected Steps per Second: 8,743.94645
Overall Steps per Second: 7,612.64111

Timestep Collection Time: 5.71984
Timestep Consumption Time: 0.85002
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.56986

Cumulative Model Updates: 23,542
Cumulative Timesteps: 392,725,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 392725308...
Checkpoint 392725308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.78450
Policy Entropy: 1.00511
Value Function Loss: 1.81705

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.21996
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 9,032.69905
Overall Steps per Second: 7,917.75992

Timestep Collection Time: 5.53633
Timestep Consumption Time: 0.77960
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.31593

Cumulative Model Updates: 23,545
Cumulative Timesteps: 392,775,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.02751
Policy Entropy: 1.02074
Value Function Loss: 1.64761

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.03823

Collected Steps per Second: 8,954.86052
Overall Steps per Second: 7,747.19957

Timestep Collection Time: 5.58468
Timestep Consumption Time: 0.87056
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.45524

Cumulative Model Updates: 23,548
Cumulative Timesteps: 392,825,326

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 392825326...
Checkpoint 392825326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.07302
Policy Entropy: 1.01568
Value Function Loss: 1.63594

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.19549
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.03439

Collected Steps per Second: 9,348.78999
Overall Steps per Second: 8,081.80745

Timestep Collection Time: 5.35021
Timestep Consumption Time: 0.83875
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.18896

Cumulative Model Updates: 23,551
Cumulative Timesteps: 392,875,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.29549
Policy Entropy: 1.00575
Value Function Loss: 1.57738

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.04561

Collected Steps per Second: 9,179.90073
Overall Steps per Second: 7,954.13186

Timestep Collection Time: 5.44864
Timestep Consumption Time: 0.83966
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.28830

Cumulative Model Updates: 23,554
Cumulative Timesteps: 392,925,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 392925362...
Checkpoint 392925362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.35612
Policy Entropy: 0.99162
Value Function Loss: 1.60050

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.19810
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.04483

Collected Steps per Second: 8,635.51805
Overall Steps per Second: 7,527.40932

Timestep Collection Time: 5.79212
Timestep Consumption Time: 0.85266
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.64478

Cumulative Model Updates: 23,557
Cumulative Timesteps: 392,975,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.22432
Policy Entropy: 1.00235
Value Function Loss: 1.66250

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 8,555.83740
Overall Steps per Second: 7,591.92552

Timestep Collection Time: 5.84466
Timestep Consumption Time: 0.74207
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.58673

Cumulative Model Updates: 23,560
Cumulative Timesteps: 393,025,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 393025386...
Checkpoint 393025386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.43167
Policy Entropy: 1.00962
Value Function Loss: 1.81120

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.15736
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.03877

Collected Steps per Second: 8,765.47784
Overall Steps per Second: 7,618.07112

Timestep Collection Time: 5.70693
Timestep Consumption Time: 0.85956
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.56649

Cumulative Model Updates: 23,563
Cumulative Timesteps: 393,075,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.74210
Policy Entropy: 0.99078
Value Function Loss: 1.76760

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.17934
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 9,039.34419
Overall Steps per Second: 7,891.13372

Timestep Collection Time: 5.53248
Timestep Consumption Time: 0.80501
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 6.33749

Cumulative Model Updates: 23,566
Cumulative Timesteps: 393,125,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 393125420...
Checkpoint 393125420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.43309
Policy Entropy: 0.99987
Value Function Loss: 1.84050

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.19297
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 8,610.90536
Overall Steps per Second: 7,345.75699

Timestep Collection Time: 5.80822
Timestep Consumption Time: 1.00034
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 6.80856

Cumulative Model Updates: 23,569
Cumulative Timesteps: 393,175,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.56371
Policy Entropy: 1.01324
Value Function Loss: 1.74507

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.21901
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.04728

Collected Steps per Second: 8,734.47091
Overall Steps per Second: 7,615.23150

Timestep Collection Time: 5.72536
Timestep Consumption Time: 0.84148
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.56684

Cumulative Model Updates: 23,572
Cumulative Timesteps: 393,225,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 393225442...
Checkpoint 393225442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.22420
Policy Entropy: 0.99918
Value Function Loss: 1.67749

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.04403

Collected Steps per Second: 8,520.15956
Overall Steps per Second: 7,547.23507

Timestep Collection Time: 5.87031
Timestep Consumption Time: 0.75675
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 6.62706

Cumulative Model Updates: 23,575
Cumulative Timesteps: 393,275,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.66916
Policy Entropy: 0.98809
Value Function Loss: 1.64271

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.20349
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.05031

Collected Steps per Second: 8,658.75429
Overall Steps per Second: 7,561.24213

Timestep Collection Time: 5.77681
Timestep Consumption Time: 0.83850
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.61532

Cumulative Model Updates: 23,578
Cumulative Timesteps: 393,325,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 393325478...
Checkpoint 393325478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.46900
Policy Entropy: 1.00310
Value Function Loss: 1.58222

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 8,573.56910
Overall Steps per Second: 7,471.91007

Timestep Collection Time: 5.83234
Timestep Consumption Time: 0.85992
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.69226

Cumulative Model Updates: 23,581
Cumulative Timesteps: 393,375,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.44333
Policy Entropy: 0.99813
Value Function Loss: 1.73202

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.17555
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 8,931.10259
Overall Steps per Second: 7,726.08173

Timestep Collection Time: 5.60020
Timestep Consumption Time: 0.87345
PPO Batch Consumption Time: 0.04661
Total Iteration Time: 6.47366

Cumulative Model Updates: 23,584
Cumulative Timesteps: 393,425,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 393425498...
Checkpoint 393425498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.58751
Policy Entropy: 0.97640
Value Function Loss: 1.65241

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.18861
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 8,712.40736
Overall Steps per Second: 7,524.02480

Timestep Collection Time: 5.74078
Timestep Consumption Time: 0.90673
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.64751

Cumulative Model Updates: 23,587
Cumulative Timesteps: 393,475,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.07722
Policy Entropy: 0.98193
Value Function Loss: 1.76592

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.17753
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.04727

Collected Steps per Second: 8,716.34833
Overall Steps per Second: 7,706.54025

Timestep Collection Time: 5.73864
Timestep Consumption Time: 0.75195
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.49059

Cumulative Model Updates: 23,590
Cumulative Timesteps: 393,525,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 393525534...
Checkpoint 393525534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.34460
Policy Entropy: 0.98903
Value Function Loss: 1.67543

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 8,748.94663
Overall Steps per Second: 7,555.85335

Timestep Collection Time: 5.71726
Timestep Consumption Time: 0.90277
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.62003

Cumulative Model Updates: 23,593
Cumulative Timesteps: 393,575,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.45789
Policy Entropy: 0.99514
Value Function Loss: 1.63228

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 8,725.66318
Overall Steps per Second: 7,635.73730

Timestep Collection Time: 5.73343
Timestep Consumption Time: 0.81839
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.55182

Cumulative Model Updates: 23,596
Cumulative Timesteps: 393,625,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 393625582...
Checkpoint 393625582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.09740
Policy Entropy: 0.98712
Value Function Loss: 1.54691

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17191
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.05210

Collected Steps per Second: 9,000.61866
Overall Steps per Second: 7,893.21401

Timestep Collection Time: 5.55540
Timestep Consumption Time: 0.77941
PPO Batch Consumption Time: 0.05111
Total Iteration Time: 6.33481

Cumulative Model Updates: 23,599
Cumulative Timesteps: 393,675,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.87254
Policy Entropy: 0.97998
Value Function Loss: 1.58964

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 8,696.28201
Overall Steps per Second: 7,610.94032

Timestep Collection Time: 5.75165
Timestep Consumption Time: 0.82020
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.57186

Cumulative Model Updates: 23,602
Cumulative Timesteps: 393,725,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 393725602...
Checkpoint 393725602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.20419
Policy Entropy: 1.00526
Value Function Loss: 1.75956

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.20479
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 8,959.25607
Overall Steps per Second: 7,848.97011

Timestep Collection Time: 5.58283
Timestep Consumption Time: 0.78973
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.37256

Cumulative Model Updates: 23,605
Cumulative Timesteps: 393,775,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.15688
Policy Entropy: 1.00245
Value Function Loss: 1.84291

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.04681

Collected Steps per Second: 8,938.77216
Overall Steps per Second: 7,747.42136

Timestep Collection Time: 5.59562
Timestep Consumption Time: 0.86046
PPO Batch Consumption Time: 0.04996
Total Iteration Time: 6.45608

Cumulative Model Updates: 23,608
Cumulative Timesteps: 393,825,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 393825638...
Checkpoint 393825638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.00220
Policy Entropy: 0.99868
Value Function Loss: 2.00214

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.04658

Collected Steps per Second: 8,823.88371
Overall Steps per Second: 7,747.89649

Timestep Collection Time: 5.66984
Timestep Consumption Time: 0.78740
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.45724

Cumulative Model Updates: 23,611
Cumulative Timesteps: 393,875,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.70814
Policy Entropy: 0.97676
Value Function Loss: 1.78795

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.18705
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.04158

Collected Steps per Second: 9,019.40237
Overall Steps per Second: 7,673.23695

Timestep Collection Time: 5.54538
Timestep Consumption Time: 0.97286
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.51824

Cumulative Model Updates: 23,614
Cumulative Timesteps: 393,925,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 393925684...
Checkpoint 393925684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.76016
Policy Entropy: 0.99232
Value Function Loss: 1.82614

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.03696

Collected Steps per Second: 8,571.32057
Overall Steps per Second: 7,453.78641

Timestep Collection Time: 5.83574
Timestep Consumption Time: 0.87494
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.71068

Cumulative Model Updates: 23,617
Cumulative Timesteps: 393,975,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.64150
Policy Entropy: 1.00000
Value Function Loss: 1.80793

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.17205
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.03594

Collected Steps per Second: 8,765.76156
Overall Steps per Second: 7,738.90197

Timestep Collection Time: 5.70606
Timestep Consumption Time: 0.75713
PPO Batch Consumption Time: 0.04730
Total Iteration Time: 6.46319

Cumulative Model Updates: 23,620
Cumulative Timesteps: 394,025,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 394025722...
Checkpoint 394025722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.34939
Policy Entropy: 0.98093
Value Function Loss: 1.79604

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.19927
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.03242

Collected Steps per Second: 8,827.15938
Overall Steps per Second: 7,642.43643

Timestep Collection Time: 5.66502
Timestep Consumption Time: 0.87819
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.54320

Cumulative Model Updates: 23,623
Cumulative Timesteps: 394,075,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.63377
Policy Entropy: 0.98065
Value Function Loss: 1.81698

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.20114
Policy Update Magnitude: 0.04376
Value Function Update Magnitude: 0.02665

Collected Steps per Second: 8,740.50925
Overall Steps per Second: 7,641.38265

Timestep Collection Time: 5.72301
Timestep Consumption Time: 0.82319
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.54620

Cumulative Model Updates: 23,626
Cumulative Timesteps: 394,125,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 394125750...
Checkpoint 394125750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.78457
Policy Entropy: 0.99021
Value Function Loss: 1.85433

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.03555

Collected Steps per Second: 8,718.16922
Overall Steps per Second: 7,586.18451

Timestep Collection Time: 5.73675
Timestep Consumption Time: 0.85602
PPO Batch Consumption Time: 0.04447
Total Iteration Time: 6.59277

Cumulative Model Updates: 23,629
Cumulative Timesteps: 394,175,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.42901
Policy Entropy: 0.99793
Value Function Loss: 1.77502

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.19059
Policy Update Magnitude: 0.03595
Value Function Update Magnitude: 0.03396

Collected Steps per Second: 8,965.40223
Overall Steps per Second: 7,799.29644

Timestep Collection Time: 5.57722
Timestep Consumption Time: 0.83387
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.41109

Cumulative Model Updates: 23,632
Cumulative Timesteps: 394,225,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 394225766...
Checkpoint 394225766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.80317
Policy Entropy: 0.98534
Value Function Loss: 1.71936

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.03845

Collected Steps per Second: 8,737.65740
Overall Steps per Second: 7,732.50916

Timestep Collection Time: 5.72533
Timestep Consumption Time: 0.74424
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.46957

Cumulative Model Updates: 23,635
Cumulative Timesteps: 394,275,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.49413
Policy Entropy: 0.96042
Value Function Loss: 1.59011

Mean KL Divergence: 0.03718
SB3 Clip Fraction: 0.29176
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 8,956.32726
Overall Steps per Second: 7,730.60668

Timestep Collection Time: 5.58287
Timestep Consumption Time: 0.88519
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 6.46806

Cumulative Model Updates: 23,638
Cumulative Timesteps: 394,325,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 394325794...
Checkpoint 394325794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.12736
Policy Entropy: 1.00824
Value Function Loss: 1.53230

Mean KL Divergence: 0.04766
SB3 Clip Fraction: 0.31595
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.04530

Collected Steps per Second: 8,756.18461
Overall Steps per Second: 7,608.79592

Timestep Collection Time: 5.71162
Timestep Consumption Time: 0.86130
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.57292

Cumulative Model Updates: 23,641
Cumulative Timesteps: 394,375,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.42552
Policy Entropy: 0.97653
Value Function Loss: 1.58453

Mean KL Divergence: 0.04680
SB3 Clip Fraction: 0.31656
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.04095

Collected Steps per Second: 8,652.72819
Overall Steps per Second: 7,512.46533

Timestep Collection Time: 5.78084
Timestep Consumption Time: 0.87743
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.65827

Cumulative Model Updates: 23,644
Cumulative Timesteps: 394,425,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 394425826...
Checkpoint 394425826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.75496
Policy Entropy: 1.00737
Value Function Loss: 1.57940

Mean KL Divergence: 0.04307
SB3 Clip Fraction: 0.29857
Policy Update Magnitude: 0.03680
Value Function Update Magnitude: 0.04616

Collected Steps per Second: 8,747.93662
Overall Steps per Second: 7,541.15676

Timestep Collection Time: 5.71883
Timestep Consumption Time: 0.91516
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.63400

Cumulative Model Updates: 23,647
Cumulative Timesteps: 394,475,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.10014
Policy Entropy: 0.96861
Value Function Loss: 1.84753

Mean KL Divergence: 0.05286
SB3 Clip Fraction: 0.30989
Policy Update Magnitude: 0.03818
Value Function Update Magnitude: 0.05392

Collected Steps per Second: 8,608.08374
Overall Steps per Second: 7,574.70489

Timestep Collection Time: 5.81151
Timestep Consumption Time: 0.79284
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.60435

Cumulative Model Updates: 23,650
Cumulative Timesteps: 394,525,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 394525880...
Checkpoint 394525880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.96426
Policy Entropy: 1.00875
Value Function Loss: 1.68041

Mean KL Divergence: 0.03409
SB3 Clip Fraction: 0.25937
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.04648

Collected Steps per Second: 9,107.61172
Overall Steps per Second: 7,861.37182

Timestep Collection Time: 5.49255
Timestep Consumption Time: 0.87072
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.36327

Cumulative Model Updates: 23,653
Cumulative Timesteps: 394,575,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.65229
Policy Entropy: 0.98964
Value Function Loss: 1.69113

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.20105
Policy Update Magnitude: 0.03925
Value Function Update Magnitude: 0.04417

Collected Steps per Second: 8,884.98248
Overall Steps per Second: 7,713.45392

Timestep Collection Time: 5.62972
Timestep Consumption Time: 0.85505
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.48477

Cumulative Model Updates: 23,656
Cumulative Timesteps: 394,625,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 394625924...
Checkpoint 394625924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.39774
Policy Entropy: 1.01492
Value Function Loss: 1.55032

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.23208
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.05748

Collected Steps per Second: 9,065.12939
Overall Steps per Second: 7,945.44583

Timestep Collection Time: 5.51586
Timestep Consumption Time: 0.77730
PPO Batch Consumption Time: 0.04639
Total Iteration Time: 6.29316

Cumulative Model Updates: 23,659
Cumulative Timesteps: 394,675,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.85345
Policy Entropy: 1.00848
Value Function Loss: 1.62142

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.06499

Collected Steps per Second: 9,280.97078
Overall Steps per Second: 7,987.96134

Timestep Collection Time: 5.38995
Timestep Consumption Time: 0.87247
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 6.26242

Cumulative Model Updates: 23,662
Cumulative Timesteps: 394,725,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 394725950...
Checkpoint 394725950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.64050
Policy Entropy: 1.00216
Value Function Loss: 1.71073

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 9,011.20195
Overall Steps per Second: 7,817.35623

Timestep Collection Time: 5.55220
Timestep Consumption Time: 0.84792
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.40012

Cumulative Model Updates: 23,665
Cumulative Timesteps: 394,775,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.91021
Policy Entropy: 1.00052
Value Function Loss: 1.73804

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.20589
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 8,804.14190
Overall Steps per Second: 7,606.51840

Timestep Collection Time: 5.68096
Timestep Consumption Time: 0.89445
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.57541

Cumulative Model Updates: 23,668
Cumulative Timesteps: 394,825,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 394825998...
Checkpoint 394825998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.27429
Policy Entropy: 1.00911
Value Function Loss: 1.89585

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.05540

Collected Steps per Second: 8,685.62537
Overall Steps per Second: 7,521.43159

Timestep Collection Time: 5.75848
Timestep Consumption Time: 0.89132
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 6.64980

Cumulative Model Updates: 23,671
Cumulative Timesteps: 394,876,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.90600
Policy Entropy: 1.01600
Value Function Loss: 1.91636

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.04703

Collected Steps per Second: 8,727.40771
Overall Steps per Second: 7,733.54079

Timestep Collection Time: 5.73068
Timestep Consumption Time: 0.73647
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.46715

Cumulative Model Updates: 23,674
Cumulative Timesteps: 394,926,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394926028...
Checkpoint 394926028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.78603
Policy Entropy: 0.99027
Value Function Loss: 1.99263

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.20236
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.04296

Collected Steps per Second: 8,904.59964
Overall Steps per Second: 7,743.32550

Timestep Collection Time: 5.61665
Timestep Consumption Time: 0.84233
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.45898

Cumulative Model Updates: 23,677
Cumulative Timesteps: 394,976,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.15144
Policy Entropy: 0.99976
Value Function Loss: 1.92459

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 8,747.47010
Overall Steps per Second: 7,616.72805

Timestep Collection Time: 5.71731
Timestep Consumption Time: 0.84876
PPO Batch Consumption Time: 0.04020
Total Iteration Time: 6.56607

Cumulative Model Updates: 23,680
Cumulative Timesteps: 395,026,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395026054...
Checkpoint 395026054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.08712
Policy Entropy: 0.99762
Value Function Loss: 1.78745

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.22931
Policy Update Magnitude: 0.04219
Value Function Update Magnitude: 0.05085

Collected Steps per Second: 8,711.20747
Overall Steps per Second: 7,545.67392

Timestep Collection Time: 5.74249
Timestep Consumption Time: 0.88701
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.62949

Cumulative Model Updates: 23,683
Cumulative Timesteps: 395,076,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.20482
Policy Entropy: 0.98818
Value Function Loss: 1.70865

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.17827
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.05430

Collected Steps per Second: 8,697.04005
Overall Steps per Second: 7,599.26113

Timestep Collection Time: 5.75230
Timestep Consumption Time: 0.83097
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.58327

Cumulative Model Updates: 23,686
Cumulative Timesteps: 395,126,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 395126106...
Checkpoint 395126106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.28333
Policy Entropy: 0.98311
Value Function Loss: 1.72019

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.19935
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 8,503.86994
Overall Steps per Second: 7,368.41040

Timestep Collection Time: 5.87968
Timestep Consumption Time: 0.90605
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.78572

Cumulative Model Updates: 23,689
Cumulative Timesteps: 395,176,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.14867
Policy Entropy: 1.00395
Value Function Loss: 1.76849

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 8,787.89027
Overall Steps per Second: 7,625.04522

Timestep Collection Time: 5.69192
Timestep Consumption Time: 0.86804
PPO Batch Consumption Time: 0.05190
Total Iteration Time: 6.55996

Cumulative Model Updates: 23,692
Cumulative Timesteps: 395,226,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 395226126...
Checkpoint 395226126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.27085
Policy Entropy: 0.99806
Value Function Loss: 1.69774

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 8,728.70948
Overall Steps per Second: 7,538.66857

Timestep Collection Time: 5.73029
Timestep Consumption Time: 0.90457
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 6.63486

Cumulative Model Updates: 23,695
Cumulative Timesteps: 395,276,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.17288
Policy Entropy: 0.98289
Value Function Loss: 1.63302

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.05786

Collected Steps per Second: 8,550.79165
Overall Steps per Second: 7,554.15361

Timestep Collection Time: 5.84741
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.04878
Total Iteration Time: 6.61888

Cumulative Model Updates: 23,698
Cumulative Timesteps: 395,326,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 395326144...
Checkpoint 395326144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.54237
Policy Entropy: 0.99915
Value Function Loss: 1.80468

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.04611

Collected Steps per Second: 8,627.05381
Overall Steps per Second: 7,504.90323

Timestep Collection Time: 5.79850
Timestep Consumption Time: 0.86701
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.66551

Cumulative Model Updates: 23,701
Cumulative Timesteps: 395,376,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.37959
Policy Entropy: 1.00750
Value Function Loss: 1.88149

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.04423

Collected Steps per Second: 8,873.58852
Overall Steps per Second: 7,723.17270

Timestep Collection Time: 5.63583
Timestep Consumption Time: 0.83949
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.47532

Cumulative Model Updates: 23,704
Cumulative Timesteps: 395,426,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 395426178...
Checkpoint 395426178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.51584
Policy Entropy: 1.00656
Value Function Loss: 1.89108

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.04088

Collected Steps per Second: 8,837.70906
Overall Steps per Second: 7,840.15872

Timestep Collection Time: 5.65803
Timestep Consumption Time: 0.71990
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.37793

Cumulative Model Updates: 23,707
Cumulative Timesteps: 395,476,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.88028
Policy Entropy: 1.00519
Value Function Loss: 1.72490

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.03952

Collected Steps per Second: 8,985.93276
Overall Steps per Second: 7,680.04032

Timestep Collection Time: 5.56448
Timestep Consumption Time: 0.94617
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.51064

Cumulative Model Updates: 23,710
Cumulative Timesteps: 395,526,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 395526184...
Checkpoint 395526184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.85964
Policy Entropy: 1.00404
Value Function Loss: 1.60850

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 8,825.04279
Overall Steps per Second: 7,666.79737

Timestep Collection Time: 5.66728
Timestep Consumption Time: 0.85617
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.52345

Cumulative Model Updates: 23,713
Cumulative Timesteps: 395,576,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.40686
Policy Entropy: 0.99014
Value Function Loss: 1.60049

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.18377
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.03826

Collected Steps per Second: 9,021.56782
Overall Steps per Second: 7,699.99006

Timestep Collection Time: 5.54516
Timestep Consumption Time: 0.95174
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.49689

Cumulative Model Updates: 23,716
Cumulative Timesteps: 395,626,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 395626224...
Checkpoint 395626224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.14540
Policy Entropy: 0.99033
Value Function Loss: 1.64572

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.19143
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.04251

Collected Steps per Second: 8,894.78168
Overall Steps per Second: 7,721.07305

Timestep Collection Time: 5.62465
Timestep Consumption Time: 0.85502
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.47967

Cumulative Model Updates: 23,719
Cumulative Timesteps: 395,676,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.40120
Policy Entropy: 0.99285
Value Function Loss: 1.85659

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.17655
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.04050

Collected Steps per Second: 8,811.63392
Overall Steps per Second: 7,756.40257

Timestep Collection Time: 5.67704
Timestep Consumption Time: 0.77234
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 6.44938

Cumulative Model Updates: 23,722
Cumulative Timesteps: 395,726,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 395726278...
Checkpoint 395726278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.93087
Policy Entropy: 1.01389
Value Function Loss: 1.76350

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.19887
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.05096

Collected Steps per Second: 8,465.10052
Overall Steps per Second: 7,413.57517

Timestep Collection Time: 5.90660
Timestep Consumption Time: 0.83778
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.74438

Cumulative Model Updates: 23,725
Cumulative Timesteps: 395,776,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.17700
Policy Entropy: 0.99400
Value Function Loss: 1.55134

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.04885

Collected Steps per Second: 9,042.08123
Overall Steps per Second: 7,775.00832

Timestep Collection Time: 5.53302
Timestep Consumption Time: 0.90170
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.43472

Cumulative Model Updates: 23,728
Cumulative Timesteps: 395,826,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 395826308...
Checkpoint 395826308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.19221
Policy Entropy: 0.98584
Value Function Loss: 1.36880

Mean KL Divergence: 0.03255
SB3 Clip Fraction: 0.21939
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.05553

Collected Steps per Second: 9,043.86477
Overall Steps per Second: 7,819.65143

Timestep Collection Time: 5.52927
Timestep Consumption Time: 0.86564
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.39491

Cumulative Model Updates: 23,731
Cumulative Timesteps: 395,876,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.91218
Policy Entropy: 1.01118
Value Function Loss: 1.46561

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15730
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.04883

Collected Steps per Second: 8,655.63599
Overall Steps per Second: 7,504.47188

Timestep Collection Time: 5.77866
Timestep Consumption Time: 0.88643
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.66509

Cumulative Model Updates: 23,734
Cumulative Timesteps: 395,926,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 395926332...
Checkpoint 395926332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.64098
Policy Entropy: 0.99506
Value Function Loss: 1.43244

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.18205
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 8,678.05534
Overall Steps per Second: 7,717.54912

Timestep Collection Time: 5.76373
Timestep Consumption Time: 0.71734
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 6.48107

Cumulative Model Updates: 23,737
Cumulative Timesteps: 395,976,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.26137
Policy Entropy: 0.98935
Value Function Loss: 1.64436

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.21548
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.05403

Collected Steps per Second: 8,577.45205
Overall Steps per Second: 7,471.86615

Timestep Collection Time: 5.82924
Timestep Consumption Time: 0.86253
PPO Batch Consumption Time: 0.04892
Total Iteration Time: 6.69177

Cumulative Model Updates: 23,740
Cumulative Timesteps: 396,026,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 396026350...
Checkpoint 396026350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.73960
Policy Entropy: 0.99397
Value Function Loss: 1.75163

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.18684
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 8,722.38843
Overall Steps per Second: 7,642.84282

Timestep Collection Time: 5.73421
Timestep Consumption Time: 0.80995
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.54416

Cumulative Model Updates: 23,743
Cumulative Timesteps: 396,076,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.81965
Policy Entropy: 0.99474
Value Function Loss: 1.83428

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.18924
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.05514

Collected Steps per Second: 8,969.19152
Overall Steps per Second: 7,768.27995

Timestep Collection Time: 5.57709
Timestep Consumption Time: 0.86217
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.43926

Cumulative Model Updates: 23,746
Cumulative Timesteps: 396,126,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 396126388...
Checkpoint 396126388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.05583
Policy Entropy: 0.98300
Value Function Loss: 1.73620

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.06184
Value Function Update Magnitude: 0.04289

Collected Steps per Second: 8,636.80201
Overall Steps per Second: 7,455.03706

Timestep Collection Time: 5.79080
Timestep Consumption Time: 0.91795
PPO Batch Consumption Time: 0.04721
Total Iteration Time: 6.70875

Cumulative Model Updates: 23,749
Cumulative Timesteps: 396,176,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.62799
Policy Entropy: 0.96705
Value Function Loss: 1.75262

Mean KL Divergence: 0.02971
SB3 Clip Fraction: 0.25695
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.03928

Collected Steps per Second: 8,642.33265
Overall Steps per Second: 7,615.29417

Timestep Collection Time: 5.78594
Timestep Consumption Time: 0.78032
PPO Batch Consumption Time: 0.04479
Total Iteration Time: 6.56626

Cumulative Model Updates: 23,752
Cumulative Timesteps: 396,226,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 396226406...
Checkpoint 396226406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.99805
Policy Entropy: 0.98300
Value Function Loss: 1.70501

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.17365
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.04490

Collected Steps per Second: 8,713.53542
Overall Steps per Second: 7,559.32723

Timestep Collection Time: 5.73843
Timestep Consumption Time: 0.87618
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 6.61461

Cumulative Model Updates: 23,755
Cumulative Timesteps: 396,276,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.56019
Policy Entropy: 0.98224
Value Function Loss: 1.64832

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.17205
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 8,626.10036
Overall Steps per Second: 7,522.27287

Timestep Collection Time: 5.79822
Timestep Consumption Time: 0.85084
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.64905

Cumulative Model Updates: 23,758
Cumulative Timesteps: 396,326,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 396326424...
Checkpoint 396326424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.59386
Policy Entropy: 0.96381
Value Function Loss: 1.55825

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.05325

Collected Steps per Second: 8,568.48601
Overall Steps per Second: 7,589.65492

Timestep Collection Time: 5.83534
Timestep Consumption Time: 0.75258
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 6.58791

Cumulative Model Updates: 23,761
Cumulative Timesteps: 396,376,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.70764
Policy Entropy: 0.94341
Value Function Loss: 1.45641

Mean KL Divergence: 0.03267
SB3 Clip Fraction: 0.26663
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 9,158.73170
Overall Steps per Second: 7,871.11536

Timestep Collection Time: 5.46211
Timestep Consumption Time: 0.89353
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.35564

Cumulative Model Updates: 23,764
Cumulative Timesteps: 396,426,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 396426450...
Checkpoint 396426450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.45615
Policy Entropy: 0.95652
Value Function Loss: 1.48979

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.17715
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.04904

Collected Steps per Second: 8,950.75460
Overall Steps per Second: 7,731.11677

Timestep Collection Time: 5.58813
Timestep Consumption Time: 0.88157
PPO Batch Consumption Time: 0.04965
Total Iteration Time: 6.46970

Cumulative Model Updates: 23,767
Cumulative Timesteps: 396,476,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.19986
Policy Entropy: 0.97291
Value Function Loss: 1.54124

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.22226
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.05602

Collected Steps per Second: 9,082.10976
Overall Steps per Second: 7,850.02685

Timestep Collection Time: 5.50775
Timestep Consumption Time: 0.86446
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 6.37221

Cumulative Model Updates: 23,770
Cumulative Timesteps: 396,526,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 396526490...
Checkpoint 396526490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.09211
Policy Entropy: 0.95741
Value Function Loss: 1.61685

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.16398
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.05960

Collected Steps per Second: 9,278.73874
Overall Steps per Second: 7,961.01155

Timestep Collection Time: 5.38953
Timestep Consumption Time: 0.89209
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 6.28161

Cumulative Model Updates: 23,773
Cumulative Timesteps: 396,576,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.20020
Policy Entropy: 0.97114
Value Function Loss: 1.59437

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.21311
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.05690

Collected Steps per Second: 8,913.47553
Overall Steps per Second: 7,813.73254

Timestep Collection Time: 5.61150
Timestep Consumption Time: 0.78979
PPO Batch Consumption Time: 0.04859
Total Iteration Time: 6.40129

Cumulative Model Updates: 23,776
Cumulative Timesteps: 396,626,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 396626516...
Checkpoint 396626516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.13279
Policy Entropy: 0.97863
Value Function Loss: 1.57665

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.21631
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.04865

Collected Steps per Second: 8,596.24407
Overall Steps per Second: 7,384.63199

Timestep Collection Time: 5.81859
Timestep Consumption Time: 0.95467
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.77326

Cumulative Model Updates: 23,779
Cumulative Timesteps: 396,676,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.99794
Policy Entropy: 0.95901
Value Function Loss: 1.57073

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.05242

Collected Steps per Second: 8,702.21052
Overall Steps per Second: 7,703.59473

Timestep Collection Time: 5.74774
Timestep Consumption Time: 0.74508
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.49281

Cumulative Model Updates: 23,782
Cumulative Timesteps: 396,726,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 396726552...
Checkpoint 396726552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.33895
Policy Entropy: 0.94005
Value Function Loss: 1.51411

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.25423
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.04986

Collected Steps per Second: 8,839.65064
Overall Steps per Second: 7,681.48531

Timestep Collection Time: 5.65701
Timestep Consumption Time: 0.85293
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.50994

Cumulative Model Updates: 23,785
Cumulative Timesteps: 396,776,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.59096
Policy Entropy: 0.96231
Value Function Loss: 1.51220

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 8,789.78079
Overall Steps per Second: 7,636.16438

Timestep Collection Time: 5.68842
Timestep Consumption Time: 0.85937
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.54779

Cumulative Model Updates: 23,788
Cumulative Timesteps: 396,826,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 396826558...
Checkpoint 396826558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.22848
Policy Entropy: 0.96526
Value Function Loss: 1.57274

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 8,678.49146
Overall Steps per Second: 7,659.63988

Timestep Collection Time: 5.76321
Timestep Consumption Time: 0.76660
PPO Batch Consumption Time: 0.04876
Total Iteration Time: 6.52981

Cumulative Model Updates: 23,791
Cumulative Timesteps: 396,876,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.41728
Policy Entropy: 0.97183
Value Function Loss: 1.54304

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.18123
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 8,571.85671
Overall Steps per Second: 7,527.81964

Timestep Collection Time: 5.83654
Timestep Consumption Time: 0.80947
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 6.64601

Cumulative Model Updates: 23,794
Cumulative Timesteps: 396,926,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 396926604...
Checkpoint 396926604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.16110
Policy Entropy: 0.97568
Value Function Loss: 1.49805

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.16230
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 8,823.02298
Overall Steps per Second: 7,695.60877

Timestep Collection Time: 5.67062
Timestep Consumption Time: 0.83075
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.50137

Cumulative Model Updates: 23,797
Cumulative Timesteps: 396,976,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.05165
Policy Entropy: 0.95588
Value Function Loss: 1.48205

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.06789
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 8,816.54283
Overall Steps per Second: 7,618.52009

Timestep Collection Time: 5.67479
Timestep Consumption Time: 0.89237
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.56715

Cumulative Model Updates: 23,800
Cumulative Timesteps: 397,026,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 397026668...
Checkpoint 397026668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.16519
Policy Entropy: 0.97341
Value Function Loss: 1.61425

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 8,888.46261
Overall Steps per Second: 7,791.72306

Timestep Collection Time: 5.62594
Timestep Consumption Time: 0.79189
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 6.41784

Cumulative Model Updates: 23,803
Cumulative Timesteps: 397,076,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.44968
Policy Entropy: 0.97062
Value Function Loss: 1.89561

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.05260

Collected Steps per Second: 8,591.72545
Overall Steps per Second: 7,567.15693

Timestep Collection Time: 5.82235
Timestep Consumption Time: 0.78833
PPO Batch Consumption Time: 0.05116
Total Iteration Time: 6.61067

Cumulative Model Updates: 23,806
Cumulative Timesteps: 397,126,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 397126698...
Checkpoint 397126698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.52441
Policy Entropy: 0.97943
Value Function Loss: 2.05508

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.06311
Value Function Update Magnitude: 0.05913

Collected Steps per Second: 8,616.13173
Overall Steps per Second: 7,489.19257

Timestep Collection Time: 5.80516
Timestep Consumption Time: 0.87353
PPO Batch Consumption Time: 0.05028
Total Iteration Time: 6.67869

Cumulative Model Updates: 23,809
Cumulative Timesteps: 397,176,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.69812
Policy Entropy: 0.97351
Value Function Loss: 2.13954

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 8,701.98343
Overall Steps per Second: 7,589.43923

Timestep Collection Time: 5.74651
Timestep Consumption Time: 0.84239
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 6.58889

Cumulative Model Updates: 23,812
Cumulative Timesteps: 397,226,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 397226722...
Checkpoint 397226722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.78725
Policy Entropy: 0.98203
Value Function Loss: 2.13810

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.17227
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 9,090.22889
Overall Steps per Second: 7,842.71347

Timestep Collection Time: 5.50239
Timestep Consumption Time: 0.87525
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.37764

Cumulative Model Updates: 23,815
Cumulative Timesteps: 397,276,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.80072
Policy Entropy: 0.99670
Value Function Loss: 2.15944

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.16057
Policy Update Magnitude: 0.06760
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 8,876.40913
Overall Steps per Second: 7,772.99595

Timestep Collection Time: 5.63494
Timestep Consumption Time: 0.79991
PPO Batch Consumption Time: 0.04043
Total Iteration Time: 6.43484

Cumulative Model Updates: 23,818
Cumulative Timesteps: 397,326,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 397326758...
Checkpoint 397326758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.72027
Policy Entropy: 1.00971
Value Function Loss: 2.06030

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.16249
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.04787

Collected Steps per Second: 8,790.96985
Overall Steps per Second: 7,698.82677

Timestep Collection Time: 5.68811
Timestep Consumption Time: 0.80691
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.49502

Cumulative Model Updates: 23,821
Cumulative Timesteps: 397,376,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.19112
Policy Entropy: 1.02203
Value Function Loss: 2.00166

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.17333
Policy Update Magnitude: 0.07328
Value Function Update Magnitude: 0.04508

Collected Steps per Second: 8,918.73011
Overall Steps per Second: 7,757.19956

Timestep Collection Time: 5.60909
Timestep Consumption Time: 0.83988
PPO Batch Consumption Time: 0.04682
Total Iteration Time: 6.44898

Cumulative Model Updates: 23,824
Cumulative Timesteps: 397,426,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 397426788...
Checkpoint 397426788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.24271
Policy Entropy: 1.01752
Value Function Loss: 1.96832

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.17351
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 8,908.57981
Overall Steps per Second: 7,729.09793

Timestep Collection Time: 5.61391
Timestep Consumption Time: 0.85670
PPO Batch Consumption Time: 0.04858
Total Iteration Time: 6.47061

Cumulative Model Updates: 23,827
Cumulative Timesteps: 397,476,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.89192
Policy Entropy: 1.01446
Value Function Loss: 1.88093

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.04646

Collected Steps per Second: 8,901.31938
Overall Steps per Second: 7,832.22220

Timestep Collection Time: 5.61894
Timestep Consumption Time: 0.76698
PPO Batch Consumption Time: 0.04727
Total Iteration Time: 6.38593

Cumulative Model Updates: 23,830
Cumulative Timesteps: 397,526,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 397526816...
Checkpoint 397526816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.23036
Policy Entropy: 1.00822
Value Function Loss: 1.80863

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.06966
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 8,800.23699
Overall Steps per Second: 7,657.37628

Timestep Collection Time: 5.68485
Timestep Consumption Time: 0.84846
PPO Batch Consumption Time: 0.04918
Total Iteration Time: 6.53331

Cumulative Model Updates: 23,833
Cumulative Timesteps: 397,576,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.84329
Policy Entropy: 0.99529
Value Function Loss: 1.78923

Mean KL Divergence: 0.02932
SB3 Clip Fraction: 0.22757
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.04149

Collected Steps per Second: 8,418.19594
Overall Steps per Second: 7,372.51022

Timestep Collection Time: 5.94047
Timestep Consumption Time: 0.84257
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 6.78304

Cumulative Model Updates: 23,836
Cumulative Timesteps: 397,626,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 397626852...
Checkpoint 397626852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.15782
Policy Entropy: 1.01573
Value Function Loss: 1.88874

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.19105
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.03954

Collected Steps per Second: 9,052.04659
Overall Steps per Second: 7,722.24958

Timestep Collection Time: 5.52383
Timestep Consumption Time: 0.95122
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.47506

Cumulative Model Updates: 23,839
Cumulative Timesteps: 397,676,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.61028
Policy Entropy: 1.02935
Value Function Loss: 1.86169

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.22225
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.04083

Collected Steps per Second: 8,947.27105
Overall Steps per Second: 7,794.36771

Timestep Collection Time: 5.58964
Timestep Consumption Time: 0.82679
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.41643

Cumulative Model Updates: 23,842
Cumulative Timesteps: 397,726,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 397726866...
Checkpoint 397726866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.92646
Policy Entropy: 1.01459
Value Function Loss: 1.86007

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.19111
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.05345

Collected Steps per Second: 8,769.10284
Overall Steps per Second: 7,731.75479

Timestep Collection Time: 5.70412
Timestep Consumption Time: 0.76531
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 6.46942

Cumulative Model Updates: 23,845
Cumulative Timesteps: 397,776,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.78763
Policy Entropy: 1.03036
Value Function Loss: 1.92817

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.20383
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.05113

Collected Steps per Second: 8,557.50332
Overall Steps per Second: 7,405.11188

Timestep Collection Time: 5.84353
Timestep Consumption Time: 0.90938
PPO Batch Consumption Time: 0.04590
Total Iteration Time: 6.75290

Cumulative Model Updates: 23,848
Cumulative Timesteps: 397,826,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 397826892...
Checkpoint 397826892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.74720
Policy Entropy: 1.03177
Value Function Loss: 1.94801

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.21770
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 8,636.72006
Overall Steps per Second: 7,532.56701

Timestep Collection Time: 5.78970
Timestep Consumption Time: 0.84868
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 6.63837

Cumulative Model Updates: 23,851
Cumulative Timesteps: 397,876,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.66678
Policy Entropy: 1.02339
Value Function Loss: 2.01522

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.17299
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.05412

Collected Steps per Second: 8,961.45710
Overall Steps per Second: 7,767.21198

Timestep Collection Time: 5.58146
Timestep Consumption Time: 0.85818
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.43963

Cumulative Model Updates: 23,854
Cumulative Timesteps: 397,926,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 397926914...
Checkpoint 397926914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.17833
Policy Entropy: 1.01771
Value Function Loss: 1.89493

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.17481
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.05599

Collected Steps per Second: 8,686.91316
Overall Steps per Second: 7,458.08777

Timestep Collection Time: 5.75809
Timestep Consumption Time: 0.94873
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.70681

Cumulative Model Updates: 23,857
Cumulative Timesteps: 397,976,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.02799
Policy Entropy: 1.01893
Value Function Loss: 1.84529

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.05610

Collected Steps per Second: 8,704.43513
Overall Steps per Second: 7,657.06492

Timestep Collection Time: 5.74512
Timestep Consumption Time: 0.78584
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.53096

Cumulative Model Updates: 23,860
Cumulative Timesteps: 398,026,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398026942...
Checkpoint 398026942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.34263
Policy Entropy: 1.02566
Value Function Loss: 1.73467

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.19189
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.05691

Collected Steps per Second: 8,553.61689
Overall Steps per Second: 7,377.08882

Timestep Collection Time: 5.84899
Timestep Consumption Time: 0.93282
PPO Batch Consumption Time: 0.04755
Total Iteration Time: 6.78181

Cumulative Model Updates: 23,863
Cumulative Timesteps: 398,076,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.62605
Policy Entropy: 1.00409
Value Function Loss: 1.62439

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.05258

Collected Steps per Second: 8,759.86030
Overall Steps per Second: 7,666.42769

Timestep Collection Time: 5.70808
Timestep Consumption Time: 0.81412
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 6.52220

Cumulative Model Updates: 23,866
Cumulative Timesteps: 398,126,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 398126974...
Checkpoint 398126974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.30308
Policy Entropy: 1.00256
Value Function Loss: 1.67553

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.17893
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.05441

Collected Steps per Second: 9,009.29951
Overall Steps per Second: 7,769.99171

Timestep Collection Time: 5.55115
Timestep Consumption Time: 0.88540
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.43656

Cumulative Model Updates: 23,869
Cumulative Timesteps: 398,176,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.56643
Policy Entropy: 1.03035
Value Function Loss: 1.82033

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.18833
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.05261

Collected Steps per Second: 8,815.92314
Overall Steps per Second: 7,593.67370

Timestep Collection Time: 5.67156
Timestep Consumption Time: 0.91287
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 6.58443

Cumulative Model Updates: 23,872
Cumulative Timesteps: 398,226,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 398226986...
Checkpoint 398226986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.61604
Policy Entropy: 1.03786
Value Function Loss: 1.97645

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.19312
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.04813

Collected Steps per Second: 8,775.93203
Overall Steps per Second: 7,494.61627

Timestep Collection Time: 5.70036
Timestep Consumption Time: 0.97456
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 6.67492

Cumulative Model Updates: 23,875
Cumulative Timesteps: 398,277,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.75462
Policy Entropy: 1.03304
Value Function Loss: 1.98487

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 9,317.57622
Overall Steps per Second: 8,027.50061

Timestep Collection Time: 5.36792
Timestep Consumption Time: 0.86266
PPO Batch Consumption Time: 0.04861
Total Iteration Time: 6.23058

Cumulative Model Updates: 23,878
Cumulative Timesteps: 398,327,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 398327028...
Checkpoint 398327028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.46243
Policy Entropy: 1.02039
Value Function Loss: 1.84344

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.19085
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.05071

Collected Steps per Second: 9,326.95272
Overall Steps per Second: 8,035.86988

Timestep Collection Time: 5.36145
Timestep Consumption Time: 0.86140
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 6.22285

Cumulative Model Updates: 23,881
Cumulative Timesteps: 398,377,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.57721
Policy Entropy: 1.02556
Value Function Loss: 1.87330

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.15283
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.06673

Collected Steps per Second: 9,222.18127
Overall Steps per Second: 8,059.89715

Timestep Collection Time: 5.42323
Timestep Consumption Time: 0.78206
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.20529

Cumulative Model Updates: 23,884
Cumulative Timesteps: 398,427,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 398427048...
Checkpoint 398427048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.07560
Policy Entropy: 1.01955
Value Function Loss: 1.80407

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.17845
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.06356

Collected Steps per Second: 8,888.80629
Overall Steps per Second: 7,663.37111

Timestep Collection Time: 5.62798
Timestep Consumption Time: 0.89996
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.52794

Cumulative Model Updates: 23,887
Cumulative Timesteps: 398,477,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.63970
Policy Entropy: 0.99574
Value Function Loss: 1.96174

Mean KL Divergence: 0.03524
SB3 Clip Fraction: 0.22488
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.05781

Collected Steps per Second: 8,569.25073
Overall Steps per Second: 7,412.63509

Timestep Collection Time: 5.83645
Timestep Consumption Time: 0.91068
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.74713

Cumulative Model Updates: 23,890
Cumulative Timesteps: 398,527,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 398527088...
Checkpoint 398527088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.44532
Policy Entropy: 1.01460
Value Function Loss: 1.80669

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.20680
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.04526

Collected Steps per Second: 8,961.82010
Overall Steps per Second: 7,723.40151

Timestep Collection Time: 5.57922
Timestep Consumption Time: 0.89461
PPO Batch Consumption Time: 0.04782
Total Iteration Time: 6.47383

Cumulative Model Updates: 23,893
Cumulative Timesteps: 398,577,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.69476
Policy Entropy: 1.01549
Value Function Loss: 1.81087

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.21029
Policy Update Magnitude: 0.04164
Value Function Update Magnitude: 0.04496

Collected Steps per Second: 8,714.49505
Overall Steps per Second: 7,580.41254

Timestep Collection Time: 5.73826
Timestep Consumption Time: 0.85848
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.59674

Cumulative Model Updates: 23,896
Cumulative Timesteps: 398,627,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 398627094...
Checkpoint 398627094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.45587
Policy Entropy: 0.99820
Value Function Loss: 1.74503

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.17769
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.04792

Collected Steps per Second: 8,590.80260
Overall Steps per Second: 7,596.77041

Timestep Collection Time: 5.82134
Timestep Consumption Time: 0.76172
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.58306

Cumulative Model Updates: 23,899
Cumulative Timesteps: 398,677,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.74513
Policy Entropy: 0.99283
Value Function Loss: 1.74139

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.23457
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.06075

Collected Steps per Second: 8,769.49044
Overall Steps per Second: 7,582.78841

Timestep Collection Time: 5.70318
Timestep Consumption Time: 0.89254
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.59573

Cumulative Model Updates: 23,902
Cumulative Timesteps: 398,727,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 398727118...
Checkpoint 398727118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.16979
Policy Entropy: 1.01704
Value Function Loss: 1.87119

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.06049

Collected Steps per Second: 8,138.73818
Overall Steps per Second: 7,175.98234

Timestep Collection Time: 6.14493
Timestep Consumption Time: 0.82443
PPO Batch Consumption Time: 0.03983
Total Iteration Time: 6.96936

Cumulative Model Updates: 23,905
Cumulative Timesteps: 398,777,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.98876
Policy Entropy: 1.01974
Value Function Loss: 1.82467

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.04894

Collected Steps per Second: 8,850.72120
Overall Steps per Second: 7,743.18384

Timestep Collection Time: 5.65265
Timestep Consumption Time: 0.80852
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 6.46117

Cumulative Model Updates: 23,908
Cumulative Timesteps: 398,827,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 398827160...
Checkpoint 398827160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.29428
Policy Entropy: 1.00546
Value Function Loss: 1.76147

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.20213
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 8,773.91442
Overall Steps per Second: 7,655.61023

Timestep Collection Time: 5.69871
Timestep Consumption Time: 0.83245
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.53116

Cumulative Model Updates: 23,911
Cumulative Timesteps: 398,877,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.49352
Policy Entropy: 1.00100
Value Function Loss: 1.71305

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.23459
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 8,733.03293
Overall Steps per Second: 7,713.49986

Timestep Collection Time: 5.72722
Timestep Consumption Time: 0.75700
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.48422

Cumulative Model Updates: 23,914
Cumulative Timesteps: 398,927,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 398927176...
Checkpoint 398927176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.36737
Policy Entropy: 1.00675
Value Function Loss: 1.73669

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.18572
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 8,411.79087
Overall Steps per Second: 7,355.72098

Timestep Collection Time: 5.94499
Timestep Consumption Time: 0.85353
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 6.79852

Cumulative Model Updates: 23,917
Cumulative Timesteps: 398,977,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.86115
Policy Entropy: 1.01532
Value Function Loss: 1.79872

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 8,967.15137
Overall Steps per Second: 7,698.87030

Timestep Collection Time: 5.57613
Timestep Consumption Time: 0.91859
PPO Batch Consumption Time: 0.05188
Total Iteration Time: 6.49472

Cumulative Model Updates: 23,920
Cumulative Timesteps: 399,027,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 399027186...
Checkpoint 399027186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.99831
Policy Entropy: 1.00747
Value Function Loss: 1.81561

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.07150

Collected Steps per Second: 8,678.90232
Overall Steps per Second: 7,555.67884

Timestep Collection Time: 5.76363
Timestep Consumption Time: 0.85682
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.62045

Cumulative Model Updates: 23,923
Cumulative Timesteps: 399,077,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.01573
Policy Entropy: 0.99341
Value Function Loss: 1.85394

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.24687
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.07413

Collected Steps per Second: 8,913.51259
Overall Steps per Second: 7,710.50762

Timestep Collection Time: 5.61215
Timestep Consumption Time: 0.87562
PPO Batch Consumption Time: 0.05013
Total Iteration Time: 6.48777

Cumulative Model Updates: 23,926
Cumulative Timesteps: 399,127,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 399127232...
Checkpoint 399127232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.50354
Policy Entropy: 1.00686
Value Function Loss: 1.73681

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 8,555.08998
Overall Steps per Second: 7,593.36635

Timestep Collection Time: 5.84658
Timestep Consumption Time: 0.74049
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.58707

Cumulative Model Updates: 23,929
Cumulative Timesteps: 399,177,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.30315
Policy Entropy: 1.01648
Value Function Loss: 1.51136

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.17127
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 8,523.30583
Overall Steps per Second: 7,422.96151

Timestep Collection Time: 5.86885
Timestep Consumption Time: 0.86997
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.73882

Cumulative Model Updates: 23,932
Cumulative Timesteps: 399,227,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 399227272...
Checkpoint 399227272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.47985
Policy Entropy: 0.99647
Value Function Loss: 1.40776

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.06000

Collected Steps per Second: 8,784.88502
Overall Steps per Second: 7,679.55689

Timestep Collection Time: 5.69364
Timestep Consumption Time: 0.81949
PPO Batch Consumption Time: 0.04710
Total Iteration Time: 6.51314

Cumulative Model Updates: 23,935
Cumulative Timesteps: 399,277,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.62819
Policy Entropy: 0.98718
Value Function Loss: 1.45716

Mean KL Divergence: 0.02817
SB3 Clip Fraction: 0.21046
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06653

Collected Steps per Second: 8,737.77077
Overall Steps per Second: 7,747.77667

Timestep Collection Time: 5.72297
Timestep Consumption Time: 0.73127
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 6.45424

Cumulative Model Updates: 23,938
Cumulative Timesteps: 399,327,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 399327296...
Checkpoint 399327296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.57585
Policy Entropy: 0.99775
Value Function Loss: 1.59609

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.06235

Collected Steps per Second: 8,717.56663
Overall Steps per Second: 7,579.70788

Timestep Collection Time: 5.73669
Timestep Consumption Time: 0.86119
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.59788

Cumulative Model Updates: 23,941
Cumulative Timesteps: 399,377,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.80477
Policy Entropy: 1.00632
Value Function Loss: 1.63421

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.17468
Policy Update Magnitude: 0.04296
Value Function Update Magnitude: 0.06181

Collected Steps per Second: 8,561.05601
Overall Steps per Second: 7,451.15961

Timestep Collection Time: 5.84344
Timestep Consumption Time: 0.87042
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.71385

Cumulative Model Updates: 23,944
Cumulative Timesteps: 399,427,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 399427332...
Checkpoint 399427332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.82266
Policy Entropy: 0.98326
Value Function Loss: 1.60397

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.06346

Collected Steps per Second: 8,858.63411
Overall Steps per Second: 7,617.66360

Timestep Collection Time: 5.64557
Timestep Consumption Time: 0.91970
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.56527

Cumulative Model Updates: 23,947
Cumulative Timesteps: 399,477,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.03514
Policy Entropy: 0.96528
Value Function Loss: 1.58568

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.20354
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.06007

Collected Steps per Second: 8,490.61957
Overall Steps per Second: 7,447.02263

Timestep Collection Time: 5.89121
Timestep Consumption Time: 0.82557
PPO Batch Consumption Time: 0.04156
Total Iteration Time: 6.71678

Cumulative Model Updates: 23,950
Cumulative Timesteps: 399,527,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 399527364...
Checkpoint 399527364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.23759
Policy Entropy: 0.97313
Value Function Loss: 1.44473

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 9,168.71486
Overall Steps per Second: 8,033.96913

Timestep Collection Time: 5.45420
Timestep Consumption Time: 0.77037
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 6.22457

Cumulative Model Updates: 23,953
Cumulative Timesteps: 399,577,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.35684
Policy Entropy: 0.98344
Value Function Loss: 1.38933

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.20074
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.05467

Collected Steps per Second: 8,639.47034
Overall Steps per Second: 7,503.44711

Timestep Collection Time: 5.78855
Timestep Consumption Time: 0.87639
PPO Batch Consumption Time: 0.04699
Total Iteration Time: 6.66494

Cumulative Model Updates: 23,956
Cumulative Timesteps: 399,627,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 399627382...
Checkpoint 399627382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.96071
Policy Entropy: 0.96762
Value Function Loss: 1.37368

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.17695
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 8,397.91527
Overall Steps per Second: 7,382.73020

Timestep Collection Time: 5.95695
Timestep Consumption Time: 0.81913
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.77608

Cumulative Model Updates: 23,959
Cumulative Timesteps: 399,677,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.43243
Policy Entropy: 0.97372
Value Function Loss: 1.59027

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.19440
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.04609

Collected Steps per Second: 8,936.89798
Overall Steps per Second: 7,795.08970

Timestep Collection Time: 5.59613
Timestep Consumption Time: 0.81971
PPO Batch Consumption Time: 0.03922
Total Iteration Time: 6.41583

Cumulative Model Updates: 23,962
Cumulative Timesteps: 399,727,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399727420...
Checkpoint 399727420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.74373
Policy Entropy: 0.99237
Value Function Loss: 1.62969

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.04506

Collected Steps per Second: 8,644.46157
Overall Steps per Second: 7,506.55897

Timestep Collection Time: 5.78428
Timestep Consumption Time: 0.87683
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 6.66111

Cumulative Model Updates: 23,965
Cumulative Timesteps: 399,777,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.19185
Policy Entropy: 0.99013
Value Function Loss: 1.60168

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 8,838.48150
Overall Steps per Second: 7,757.86779

Timestep Collection Time: 5.65912
Timestep Consumption Time: 0.78827
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.44739

Cumulative Model Updates: 23,968
Cumulative Timesteps: 399,827,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 399827440...
Checkpoint 399827440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.31787
Policy Entropy: 0.98200
Value Function Loss: 1.46806

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 8,379.11115
Overall Steps per Second: 7,262.72723

Timestep Collection Time: 5.96817
Timestep Consumption Time: 0.91739
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 6.88557

Cumulative Model Updates: 23,971
Cumulative Timesteps: 399,877,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.77155
Policy Entropy: 0.98177
Value Function Loss: 1.47964

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.17191
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 8,784.70712
Overall Steps per Second: 7,655.56872

Timestep Collection Time: 5.69308
Timestep Consumption Time: 0.83969
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.53276

Cumulative Model Updates: 23,974
Cumulative Timesteps: 399,927,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 399927460...
Checkpoint 399927460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.80741
Policy Entropy: 0.99856
Value Function Loss: 1.63918

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.04674

Collected Steps per Second: 8,989.33071
Overall Steps per Second: 7,710.37725

Timestep Collection Time: 5.56460
Timestep Consumption Time: 0.92302
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.48762

Cumulative Model Updates: 23,977
Cumulative Timesteps: 399,977,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.47620
Policy Entropy: 1.00379
Value Function Loss: 1.64147

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.05368

Collected Steps per Second: 8,743.19096
Overall Steps per Second: 7,600.25943

Timestep Collection Time: 5.71874
Timestep Consumption Time: 0.85999
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.57872

Cumulative Model Updates: 23,980
Cumulative Timesteps: 400,027,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 400027482...
Checkpoint 400027482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.17274
Policy Entropy: 0.99787
Value Function Loss: 1.58435

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.05130

Collected Steps per Second: 8,914.31392
Overall Steps per Second: 7,819.91179

Timestep Collection Time: 5.61008
Timestep Consumption Time: 0.78513
PPO Batch Consumption Time: 0.05076
Total Iteration Time: 6.39521

Cumulative Model Updates: 23,983
Cumulative Timesteps: 400,077,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.47645
Policy Entropy: 0.99540
Value Function Loss: 1.44816

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.05522

Collected Steps per Second: 8,887.07947
Overall Steps per Second: 7,669.42493

Timestep Collection Time: 5.62637
Timestep Consumption Time: 0.89328
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.51965

Cumulative Model Updates: 23,986
Cumulative Timesteps: 400,127,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 400127494...
Checkpoint 400127494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.82753
Policy Entropy: 0.99608
Value Function Loss: 1.55701

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.18339
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 8,753.70208
Overall Steps per Second: 7,607.92038

Timestep Collection Time: 5.71507
Timestep Consumption Time: 0.86071
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.57578

Cumulative Model Updates: 23,989
Cumulative Timesteps: 400,177,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.64199
Policy Entropy: 1.01224
Value Function Loss: 1.81507

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.16989
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.05702

Collected Steps per Second: 9,003.70708
Overall Steps per Second: 7,763.34659

Timestep Collection Time: 5.55416
Timestep Consumption Time: 0.88740
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.44155

Cumulative Model Updates: 23,992
Cumulative Timesteps: 400,227,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 400227530...
Checkpoint 400227530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.35012
Policy Entropy: 1.02524
Value Function Loss: 1.83025

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.20978
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.05777

Collected Steps per Second: 9,130.39096
Overall Steps per Second: 7,869.98950

Timestep Collection Time: 5.47819
Timestep Consumption Time: 0.87735
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 6.35554

Cumulative Model Updates: 23,995
Cumulative Timesteps: 400,277,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.65632
Policy Entropy: 0.97980
Value Function Loss: 1.94855

Mean KL Divergence: 0.05549
SB3 Clip Fraction: 0.31114
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.05327

Collected Steps per Second: 8,678.32958
Overall Steps per Second: 7,542.71413

Timestep Collection Time: 5.76447
Timestep Consumption Time: 0.86789
PPO Batch Consumption Time: 0.05093
Total Iteration Time: 6.63236

Cumulative Model Updates: 23,998
Cumulative Timesteps: 400,327,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 400327574...
Checkpoint 400327574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.78419
Policy Entropy: 1.01613
Value Function Loss: 1.81227

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.23541
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 8,653.43980
Overall Steps per Second: 7,496.69491

Timestep Collection Time: 5.78128
Timestep Consumption Time: 0.89206
PPO Batch Consumption Time: 0.04885
Total Iteration Time: 6.67334

Cumulative Model Updates: 24,001
Cumulative Timesteps: 400,377,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.14477
Policy Entropy: 0.97813
Value Function Loss: 1.95517

Mean KL Divergence: 0.03457
SB3 Clip Fraction: 0.26412
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.06074

Collected Steps per Second: 8,869.55544
Overall Steps per Second: 7,709.66200

Timestep Collection Time: 5.63997
Timestep Consumption Time: 0.84851
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.48848

Cumulative Model Updates: 24,004
Cumulative Timesteps: 400,427,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 400427626...
Checkpoint 400427626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.30597
Policy Entropy: 1.00447
Value Function Loss: 1.97766

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.18710
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.04989

Collected Steps per Second: 8,796.07967
Overall Steps per Second: 7,762.30793

Timestep Collection Time: 5.68799
Timestep Consumption Time: 0.75752
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.44551

Cumulative Model Updates: 24,007
Cumulative Timesteps: 400,477,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.61907
Policy Entropy: 1.01256
Value Function Loss: 2.01745

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.23086
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 8,900.94139
Overall Steps per Second: 7,755.14889

Timestep Collection Time: 5.61986
Timestep Consumption Time: 0.83031
PPO Batch Consumption Time: 0.04523
Total Iteration Time: 6.45017

Cumulative Model Updates: 24,010
Cumulative Timesteps: 400,527,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 400527680...
Checkpoint 400527680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.82689
Policy Entropy: 0.99669
Value Function Loss: 1.85466

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.17557
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 8,494.88539
Overall Steps per Second: 7,541.17163

Timestep Collection Time: 5.88660
Timestep Consumption Time: 0.74446
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.63107

Cumulative Model Updates: 24,013
Cumulative Timesteps: 400,577,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.13643
Policy Entropy: 1.02369
Value Function Loss: 1.82684

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.22669
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.05018

Collected Steps per Second: 8,694.23309
Overall Steps per Second: 7,601.32084

Timestep Collection Time: 5.75324
Timestep Consumption Time: 0.82720
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.58044

Cumulative Model Updates: 24,016
Cumulative Timesteps: 400,627,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 400627706...
Checkpoint 400627706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.47271
Policy Entropy: 1.00936
Value Function Loss: 1.84933

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.19222
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.05096

Collected Steps per Second: 9,052.33835
Overall Steps per Second: 7,906.40536

Timestep Collection Time: 5.52564
Timestep Consumption Time: 0.80087
PPO Batch Consumption Time: 0.04068
Total Iteration Time: 6.32652

Cumulative Model Updates: 24,019
Cumulative Timesteps: 400,677,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.48145
Policy Entropy: 1.00957
Value Function Loss: 1.92037

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.19095
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.05663

Collected Steps per Second: 8,783.78645
Overall Steps per Second: 7,645.89993

Timestep Collection Time: 5.69413
Timestep Consumption Time: 0.84742
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.54155

Cumulative Model Updates: 24,022
Cumulative Timesteps: 400,727,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 400727742...
Checkpoint 400727742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.76705
Policy Entropy: 1.00128
Value Function Loss: 1.79578

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.19978
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.05740

Collected Steps per Second: 8,931.56406
Overall Steps per Second: 7,781.94777

Timestep Collection Time: 5.60036
Timestep Consumption Time: 0.82733
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.42770

Cumulative Model Updates: 24,025
Cumulative Timesteps: 400,777,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.12855
Policy Entropy: 1.01724
Value Function Loss: 1.62199

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.06185

Collected Steps per Second: 8,422.00873
Overall Steps per Second: 7,466.49740

Timestep Collection Time: 5.93991
Timestep Consumption Time: 0.76015
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.70006

Cumulative Model Updates: 24,028
Cumulative Timesteps: 400,827,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 400827788...
Checkpoint 400827788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.58371
Policy Entropy: 1.01856
Value Function Loss: 1.63646

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 8,644.76017
Overall Steps per Second: 7,517.08697

Timestep Collection Time: 5.78663
Timestep Consumption Time: 0.86808
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.65471

Cumulative Model Updates: 24,031
Cumulative Timesteps: 400,877,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.63206
Policy Entropy: 1.01713
Value Function Loss: 1.67439

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 8,908.88635
Overall Steps per Second: 7,797.77986

Timestep Collection Time: 5.61507
Timestep Consumption Time: 0.80009
PPO Batch Consumption Time: 0.04029
Total Iteration Time: 6.41516

Cumulative Model Updates: 24,034
Cumulative Timesteps: 400,927,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 400927836...
Checkpoint 400927836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.99027
Policy Entropy: 1.03892
Value Function Loss: 1.81010

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.17524
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.06274

Collected Steps per Second: 8,944.47617
Overall Steps per Second: 7,842.87530

Timestep Collection Time: 5.59205
Timestep Consumption Time: 0.78545
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.37751

Cumulative Model Updates: 24,037
Cumulative Timesteps: 400,977,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.42297
Policy Entropy: 1.04233
Value Function Loss: 1.77433

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 8,790.44450
Overall Steps per Second: 7,634.51050

Timestep Collection Time: 5.68913
Timestep Consumption Time: 0.86139
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 6.55052

Cumulative Model Updates: 24,040
Cumulative Timesteps: 401,027,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401027864...
Checkpoint 401027864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.71982
Policy Entropy: 1.02545
Value Function Loss: 1.65878

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.16231
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.06595

Collected Steps per Second: 8,837.14052
Overall Steps per Second: 7,639.65781

Timestep Collection Time: 5.65952
Timestep Consumption Time: 0.88711
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 6.54663

Cumulative Model Updates: 24,043
Cumulative Timesteps: 401,077,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.99668
Policy Entropy: 1.01169
Value Function Loss: 1.68610

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.06387

Collected Steps per Second: 9,054.64086
Overall Steps per Second: 7,824.51144

Timestep Collection Time: 5.52402
Timestep Consumption Time: 0.86846
PPO Batch Consumption Time: 0.04958
Total Iteration Time: 6.39248

Cumulative Model Updates: 24,046
Cumulative Timesteps: 401,127,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 401127896...
Checkpoint 401127896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.37337
Policy Entropy: 1.02324
Value Function Loss: 1.63233

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.04975

Collected Steps per Second: 9,067.88702
Overall Steps per Second: 7,879.09282

Timestep Collection Time: 5.51617
Timestep Consumption Time: 0.83228
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 6.34845

Cumulative Model Updates: 24,049
Cumulative Timesteps: 401,177,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.30423
Policy Entropy: 1.02967
Value Function Loss: 1.77318

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.04214

Collected Steps per Second: 8,803.59487
Overall Steps per Second: 7,768.57439

Timestep Collection Time: 5.68132
Timestep Consumption Time: 0.75693
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.43825

Cumulative Model Updates: 24,052
Cumulative Timesteps: 401,227,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 401227932...
Checkpoint 401227932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.54317
Policy Entropy: 1.01448
Value Function Loss: 1.66733

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.04067

Collected Steps per Second: 8,406.87047
Overall Steps per Second: 7,310.27023

Timestep Collection Time: 5.94823
Timestep Consumption Time: 0.89228
PPO Batch Consumption Time: 0.04824
Total Iteration Time: 6.84051

Cumulative Model Updates: 24,055
Cumulative Timesteps: 401,277,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.86252
Policy Entropy: 0.98971
Value Function Loss: 1.50653

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.20715
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.04110

Collected Steps per Second: 8,791.15874
Overall Steps per Second: 7,644.44023

Timestep Collection Time: 5.69094
Timestep Consumption Time: 0.85368
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 6.54463

Cumulative Model Updates: 24,058
Cumulative Timesteps: 401,327,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 401327968...
Checkpoint 401327968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.96758
Policy Entropy: 1.00652
Value Function Loss: 1.47924

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.04312

Collected Steps per Second: 8,807.85113
Overall Steps per Second: 7,747.80896

Timestep Collection Time: 5.67925
Timestep Consumption Time: 0.77703
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.45628

Cumulative Model Updates: 24,061
Cumulative Timesteps: 401,377,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.58653
Policy Entropy: 1.01834
Value Function Loss: 1.55073

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.04751

Collected Steps per Second: 8,883.41651
Overall Steps per Second: 7,675.50758

Timestep Collection Time: 5.63184
Timestep Consumption Time: 0.88629
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.51814

Cumulative Model Updates: 24,064
Cumulative Timesteps: 401,428,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 401428020...
Checkpoint 401428020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.68390
Policy Entropy: 1.00941
Value Function Loss: 1.75872

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16593
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 8,609.44604
Overall Steps per Second: 7,444.86694

Timestep Collection Time: 5.80897
Timestep Consumption Time: 0.90868
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.71765

Cumulative Model Updates: 24,067
Cumulative Timesteps: 401,478,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.52208
Policy Entropy: 1.01488
Value Function Loss: 1.74246

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.04612

Collected Steps per Second: 8,822.04554
Overall Steps per Second: 7,673.01902

Timestep Collection Time: 5.66762
Timestep Consumption Time: 0.84872
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.51634

Cumulative Model Updates: 24,070
Cumulative Timesteps: 401,528,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 401528032...
Checkpoint 401528032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.42912
Policy Entropy: 1.01871
Value Function Loss: 1.80168

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 8,836.49818
Overall Steps per Second: 7,665.49329

Timestep Collection Time: 5.65993
Timestep Consumption Time: 0.86463
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.52456

Cumulative Model Updates: 24,073
Cumulative Timesteps: 401,578,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.89671
Policy Entropy: 1.02660
Value Function Loss: 1.80235

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.04331

Collected Steps per Second: 8,502.12868
Overall Steps per Second: 7,434.36778

Timestep Collection Time: 5.88370
Timestep Consumption Time: 0.84505
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.72875

Cumulative Model Updates: 24,076
Cumulative Timesteps: 401,628,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 401628070...
Checkpoint 401628070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.02074
Policy Entropy: 1.03750
Value Function Loss: 1.75655

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.04415

Collected Steps per Second: 8,749.13903
Overall Steps per Second: 7,523.57937

Timestep Collection Time: 5.71622
Timestep Consumption Time: 0.93115
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.64737

Cumulative Model Updates: 24,079
Cumulative Timesteps: 401,678,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.08364
Policy Entropy: 1.03615
Value Function Loss: 1.79299

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.07102
Value Function Update Magnitude: 0.05201

Collected Steps per Second: 8,547.01892
Overall Steps per Second: 7,420.83579

Timestep Collection Time: 5.85140
Timestep Consumption Time: 0.88801
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.73940

Cumulative Model Updates: 24,082
Cumulative Timesteps: 401,728,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 401728094...
Checkpoint 401728094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.15759
Policy Entropy: 1.03248
Value Function Loss: 1.75534

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.07070
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 8,973.61204
Overall Steps per Second: 7,703.56210

Timestep Collection Time: 5.57390
Timestep Consumption Time: 0.91894
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.49284

Cumulative Model Updates: 24,085
Cumulative Timesteps: 401,778,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.93715
Policy Entropy: 1.03191
Value Function Loss: 1.88358

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 8,685.68863
Overall Steps per Second: 7,514.22093

Timestep Collection Time: 5.75821
Timestep Consumption Time: 0.89771
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.65591

Cumulative Model Updates: 24,088
Cumulative Timesteps: 401,828,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 401828126...
Checkpoint 401828126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.79858
Policy Entropy: 1.02280
Value Function Loss: 1.90598

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.18468
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.06071

Collected Steps per Second: 8,879.53003
Overall Steps per Second: 7,733.28678

Timestep Collection Time: 5.63431
Timestep Consumption Time: 0.83513
PPO Batch Consumption Time: 0.04731
Total Iteration Time: 6.46944

Cumulative Model Updates: 24,091
Cumulative Timesteps: 401,878,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.91038
Policy Entropy: 1.05138
Value Function Loss: 1.90890

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.05727

Collected Steps per Second: 9,129.52110
Overall Steps per Second: 7,717.02588

Timestep Collection Time: 5.47696
Timestep Consumption Time: 1.00248
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.47944

Cumulative Model Updates: 24,094
Cumulative Timesteps: 401,928,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 401928158...
Checkpoint 401928158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.03567
Policy Entropy: 1.04499
Value Function Loss: 1.87017

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 9,147.11415
Overall Steps per Second: 7,890.43963

Timestep Collection Time: 5.46948
Timestep Consumption Time: 0.87110
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.34058

Cumulative Model Updates: 24,097
Cumulative Timesteps: 401,978,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.14534
Policy Entropy: 1.05933
Value Function Loss: 1.83831

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 9,361.74844
Overall Steps per Second: 8,072.14572

Timestep Collection Time: 5.34409
Timestep Consumption Time: 0.85377
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.19786

Cumulative Model Updates: 24,100
Cumulative Timesteps: 402,028,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 402028218...
Checkpoint 402028218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.02764
Policy Entropy: 1.05344
Value Function Loss: 1.73432

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 8,664.98767
Overall Steps per Second: 7,457.48187

Timestep Collection Time: 5.77104
Timestep Consumption Time: 0.93444
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.70548

Cumulative Model Updates: 24,103
Cumulative Timesteps: 402,078,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.15005
Policy Entropy: 1.05750
Value Function Loss: 1.69245

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 8,696.12796
Overall Steps per Second: 7,632.41953

Timestep Collection Time: 5.75153
Timestep Consumption Time: 0.80157
PPO Batch Consumption Time: 0.04761
Total Iteration Time: 6.55310

Cumulative Model Updates: 24,106
Cumulative Timesteps: 402,128,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 402128240...
Checkpoint 402128240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.95488
Policy Entropy: 1.05034
Value Function Loss: 1.64142

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.19386
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 8,490.61537
Overall Steps per Second: 7,375.47152

Timestep Collection Time: 5.89027
Timestep Consumption Time: 0.89059
PPO Batch Consumption Time: 0.04909
Total Iteration Time: 6.78085

Cumulative Model Updates: 24,109
Cumulative Timesteps: 402,178,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.61960
Policy Entropy: 1.06432
Value Function Loss: 1.78459

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.16217
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 8,794.66157
Overall Steps per Second: 7,680.75113

Timestep Collection Time: 5.68754
Timestep Consumption Time: 0.82484
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.51238

Cumulative Model Updates: 24,112
Cumulative Timesteps: 402,228,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 402228272...
Checkpoint 402228272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.69171
Policy Entropy: 1.07972
Value Function Loss: 1.84941

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.17680
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.05688

Collected Steps per Second: 8,506.30620
Overall Steps per Second: 7,560.22027

Timestep Collection Time: 5.88011
Timestep Consumption Time: 0.73584
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.61594

Cumulative Model Updates: 24,115
Cumulative Timesteps: 402,278,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.80964
Policy Entropy: 1.06802
Value Function Loss: 1.94691

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.06285

Collected Steps per Second: 8,956.37652
Overall Steps per Second: 7,755.13031

Timestep Collection Time: 5.58328
Timestep Consumption Time: 0.86483
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.44812

Cumulative Model Updates: 24,118
Cumulative Timesteps: 402,328,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 402328296...
Checkpoint 402328296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.16242
Policy Entropy: 1.05292
Value Function Loss: 1.90458

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.19136
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 8,722.75610
Overall Steps per Second: 7,628.84514

Timestep Collection Time: 5.73557
Timestep Consumption Time: 0.82243
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 6.55800

Cumulative Model Updates: 24,121
Cumulative Timesteps: 402,378,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.85286
Policy Entropy: 1.07630
Value Function Loss: 1.88123

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 8,867.42880
Overall Steps per Second: 7,714.58669

Timestep Collection Time: 5.64177
Timestep Consumption Time: 0.84309
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.48486

Cumulative Model Updates: 24,124
Cumulative Timesteps: 402,428,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 402428354...
Checkpoint 402428354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.19142
Policy Entropy: 1.07073
Value Function Loss: 1.85364

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.06720

Collected Steps per Second: 8,652.74651
Overall Steps per Second: 7,566.05483

Timestep Collection Time: 5.78105
Timestep Consumption Time: 0.83032
PPO Batch Consumption Time: 0.04706
Total Iteration Time: 6.61137

Cumulative Model Updates: 24,127
Cumulative Timesteps: 402,478,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.23262
Policy Entropy: 1.07003
Value Function Loss: 1.92004

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.05985

Collected Steps per Second: 8,704.08565
Overall Steps per Second: 7,725.01719

Timestep Collection Time: 5.74512
Timestep Consumption Time: 0.72814
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.47325

Cumulative Model Updates: 24,130
Cumulative Timesteps: 402,528,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 402528382...
Checkpoint 402528382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.21672
Policy Entropy: 1.06304
Value Function Loss: 1.90771

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 8,664.71877
Overall Steps per Second: 7,562.42913

Timestep Collection Time: 5.77122
Timestep Consumption Time: 0.84121
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.61243

Cumulative Model Updates: 24,133
Cumulative Timesteps: 402,578,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.88910
Policy Entropy: 1.07440
Value Function Loss: 1.97258

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 8,579.06430
Overall Steps per Second: 7,530.13658

Timestep Collection Time: 5.82977
Timestep Consumption Time: 0.81207
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 6.64184

Cumulative Model Updates: 24,136
Cumulative Timesteps: 402,628,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 402628402...
Checkpoint 402628402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.50483
Policy Entropy: 1.07484
Value Function Loss: 1.89195

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 8,760.02862
Overall Steps per Second: 7,775.59198

Timestep Collection Time: 5.70980
Timestep Consumption Time: 0.72289
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.43269

Cumulative Model Updates: 24,139
Cumulative Timesteps: 402,678,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.82262
Policy Entropy: 1.07586
Value Function Loss: 2.05674

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 8,957.86349
Overall Steps per Second: 7,745.57849

Timestep Collection Time: 5.58236
Timestep Consumption Time: 0.87371
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 6.45607

Cumulative Model Updates: 24,142
Cumulative Timesteps: 402,728,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 402728426...
Checkpoint 402728426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.63012
Policy Entropy: 1.08171
Value Function Loss: 2.06610

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.06231

Collected Steps per Second: 8,583.37864
Overall Steps per Second: 7,484.59939

Timestep Collection Time: 5.82871
Timestep Consumption Time: 0.85569
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.68439

Cumulative Model Updates: 24,145
Cumulative Timesteps: 402,778,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.22899
Policy Entropy: 1.09650
Value Function Loss: 2.16717

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.06746
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 9,129.48614
Overall Steps per Second: 7,905.31577

Timestep Collection Time: 5.47829
Timestep Consumption Time: 0.84834
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 6.32663

Cumulative Model Updates: 24,148
Cumulative Timesteps: 402,828,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 402828470...
Checkpoint 402828470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.87645
Policy Entropy: 1.08386
Value Function Loss: 2.05641

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 8,747.79609
Overall Steps per Second: 7,590.55408

Timestep Collection Time: 5.71755
Timestep Consumption Time: 0.87169
PPO Batch Consumption Time: 0.04737
Total Iteration Time: 6.58924

Cumulative Model Updates: 24,151
Cumulative Timesteps: 402,878,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.10083
Policy Entropy: 1.06902
Value Function Loss: 1.95052

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.19149
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 8,946.68507
Overall Steps per Second: 7,741.79731

Timestep Collection Time: 5.59045
Timestep Consumption Time: 0.87006
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 6.46052

Cumulative Model Updates: 24,154
Cumulative Timesteps: 402,928,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 402928502...
Checkpoint 402928502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.39213
Policy Entropy: 1.09498
Value Function Loss: 1.90937

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16129
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 8,990.49798
Overall Steps per Second: 7,763.10410

Timestep Collection Time: 5.56454
Timestep Consumption Time: 0.87979
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.44433

Cumulative Model Updates: 24,157
Cumulative Timesteps: 402,978,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.66600
Policy Entropy: 1.10211
Value Function Loss: 1.97698

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 8,786.84693
Overall Steps per Second: 7,734.93102

Timestep Collection Time: 5.69351
Timestep Consumption Time: 0.77429
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.46780

Cumulative Model Updates: 24,160
Cumulative Timesteps: 403,028,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 403028558...
Checkpoint 403028558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.07759
Policy Entropy: 1.09144
Value Function Loss: 2.08938

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 8,867.78396
Overall Steps per Second: 7,617.25664

Timestep Collection Time: 5.64064
Timestep Consumption Time: 0.92603
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.56667

Cumulative Model Updates: 24,163
Cumulative Timesteps: 403,078,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.76984
Policy Entropy: 1.08508
Value Function Loss: 2.18876

Mean KL Divergence: 0.02893
SB3 Clip Fraction: 0.20815
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 8,829.01662
Overall Steps per Second: 7,777.52266

Timestep Collection Time: 5.66360
Timestep Consumption Time: 0.76570
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.42930

Cumulative Model Updates: 24,166
Cumulative Timesteps: 403,128,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 403128582...
Checkpoint 403128582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.75354
Policy Entropy: 1.09532
Value Function Loss: 2.06461

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 8,722.61304
Overall Steps per Second: 7,565.83287

Timestep Collection Time: 5.73498
Timestep Consumption Time: 0.87685
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.61183

Cumulative Model Updates: 24,169
Cumulative Timesteps: 403,178,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.01209
Policy Entropy: 1.10551
Value Function Loss: 2.00015

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14918
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 8,624.87004
Overall Steps per Second: 7,529.84566

Timestep Collection Time: 5.80090
Timestep Consumption Time: 0.84359
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.64449

Cumulative Model Updates: 24,172
Cumulative Timesteps: 403,228,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 403228638...
Checkpoint 403228638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.04690
Policy Entropy: 1.07990
Value Function Loss: 1.92008

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.17264
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 8,976.08722
Overall Steps per Second: 7,772.22779

Timestep Collection Time: 5.57258
Timestep Consumption Time: 0.86315
PPO Batch Consumption Time: 0.04891
Total Iteration Time: 6.43574

Cumulative Model Updates: 24,175
Cumulative Timesteps: 403,278,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.68510
Policy Entropy: 1.10120
Value Function Loss: 1.99034

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.06813

Collected Steps per Second: 8,596.58617
Overall Steps per Second: 7,508.62123

Timestep Collection Time: 5.81952
Timestep Consumption Time: 0.84322
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.66274

Cumulative Model Updates: 24,178
Cumulative Timesteps: 403,328,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 403328686...
Checkpoint 403328686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.46194
Policy Entropy: 1.08723
Value Function Loss: 1.98124

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 8,732.97918
Overall Steps per Second: 7,675.65954

Timestep Collection Time: 5.72794
Timestep Consumption Time: 0.78902
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.51696

Cumulative Model Updates: 24,181
Cumulative Timesteps: 403,378,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.50615
Policy Entropy: 1.08622
Value Function Loss: 1.92113

Mean KL Divergence: 0.02539
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.07173

Collected Steps per Second: 8,906.01837
Overall Steps per Second: 7,689.05600

Timestep Collection Time: 5.61553
Timestep Consumption Time: 0.88878
PPO Batch Consumption Time: 0.05148
Total Iteration Time: 6.50431

Cumulative Model Updates: 24,184
Cumulative Timesteps: 403,428,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 403428720...
Checkpoint 403428720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.80399
Policy Entropy: 1.07494
Value Function Loss: 1.88387

Mean KL Divergence: 0.02970
SB3 Clip Fraction: 0.21524
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.08044

Collected Steps per Second: 8,549.91781
Overall Steps per Second: 7,482.73355

Timestep Collection Time: 5.85105
Timestep Consumption Time: 0.83447
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.68552

Cumulative Model Updates: 24,187
Cumulative Timesteps: 403,478,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.42986
Policy Entropy: 1.08373
Value Function Loss: 1.92959

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.08772

Collected Steps per Second: 8,912.35626
Overall Steps per Second: 7,511.99186

Timestep Collection Time: 5.61154
Timestep Consumption Time: 1.04609
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 6.65762

Cumulative Model Updates: 24,190
Cumulative Timesteps: 403,528,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 403528758...
Checkpoint 403528758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.19139
Policy Entropy: 1.10317
Value Function Loss: 1.92311

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.18119
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.09975

Collected Steps per Second: 8,803.64521
Overall Steps per Second: 7,662.94128

Timestep Collection Time: 5.68037
Timestep Consumption Time: 0.84558
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.52595

Cumulative Model Updates: 24,193
Cumulative Timesteps: 403,578,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.04304
Policy Entropy: 1.05164
Value Function Loss: 1.93667

Mean KL Divergence: 0.06674
SB3 Clip Fraction: 0.30381
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 8,739.18919
Overall Steps per Second: 7,711.80282

Timestep Collection Time: 5.72319
Timestep Consumption Time: 0.76246
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.48564

Cumulative Model Updates: 24,196
Cumulative Timesteps: 403,628,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 403628782...
Checkpoint 403628782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.92269
Policy Entropy: 1.08689
Value Function Loss: 1.87934

Mean KL Divergence: 0.04634
SB3 Clip Fraction: 0.28035
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.08199

Collected Steps per Second: 8,849.93908
Overall Steps per Second: 7,675.86378

Timestep Collection Time: 5.65224
Timestep Consumption Time: 0.86455
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 6.51679

Cumulative Model Updates: 24,199
Cumulative Timesteps: 403,678,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.36658
Policy Entropy: 1.06840
Value Function Loss: 1.90165

Mean KL Divergence: 0.04740
SB3 Clip Fraction: 0.29002
Policy Update Magnitude: 0.03841
Value Function Update Magnitude: 0.07603

Collected Steps per Second: 9,329.10772
Overall Steps per Second: 7,975.97271

Timestep Collection Time: 5.36171
Timestep Consumption Time: 0.90962
PPO Batch Consumption Time: 0.04810
Total Iteration Time: 6.27134

Cumulative Model Updates: 24,202
Cumulative Timesteps: 403,728,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 403728824...
Checkpoint 403728824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.06486
Policy Entropy: 1.10680
Value Function Loss: 1.85187

Mean KL Divergence: 0.05202
SB3 Clip Fraction: 0.29639
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 8,707.88295
Overall Steps per Second: 7,669.41759

Timestep Collection Time: 5.74353
Timestep Consumption Time: 0.77769
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.52123

Cumulative Model Updates: 24,205
Cumulative Timesteps: 403,778,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.57833
Policy Entropy: 1.08446
Value Function Loss: 1.88912

Mean KL Divergence: 0.05309
SB3 Clip Fraction: 0.30701
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 9,441.42270
Overall Steps per Second: 8,058.92591

Timestep Collection Time: 5.29687
Timestep Consumption Time: 0.90867
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 6.20554

Cumulative Model Updates: 24,208
Cumulative Timesteps: 403,828,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 403828848...
Checkpoint 403828848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.37564
Policy Entropy: 1.10947
Value Function Loss: 1.81978

Mean KL Divergence: 0.04053
SB3 Clip Fraction: 0.25600
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.07192

Collected Steps per Second: 9,246.21857
Overall Steps per Second: 8,084.77447

Timestep Collection Time: 5.40978
Timestep Consumption Time: 0.77716
PPO Batch Consumption Time: 0.04541
Total Iteration Time: 6.18694

Cumulative Model Updates: 24,211
Cumulative Timesteps: 403,878,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.89218
Policy Entropy: 1.08113
Value Function Loss: 1.76566

Mean KL Divergence: 0.04149
SB3 Clip Fraction: 0.25245
Policy Update Magnitude: 0.04213
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 9,254.38640
Overall Steps per Second: 7,913.73457

Timestep Collection Time: 5.40522
Timestep Consumption Time: 0.91569
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 6.32091

Cumulative Model Updates: 24,214
Cumulative Timesteps: 403,928,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 403928890...
Checkpoint 403928890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.34423
Policy Entropy: 1.09910
Value Function Loss: 1.69593

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.20470
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 8,575.22741
Overall Steps per Second: 7,520.47437

Timestep Collection Time: 5.83261
Timestep Consumption Time: 0.81803
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 6.65064

Cumulative Model Updates: 24,217
Cumulative Timesteps: 403,978,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.97308
Policy Entropy: 1.10289
Value Function Loss: 1.72332

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.18419
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 8,521.52685
Overall Steps per Second: 7,514.06383

Timestep Collection Time: 5.87101
Timestep Consumption Time: 0.78717
PPO Batch Consumption Time: 0.04716
Total Iteration Time: 6.65818

Cumulative Model Updates: 24,220
Cumulative Timesteps: 404,028,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 404028936...
Checkpoint 404028936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.60781
Policy Entropy: 1.08195
Value Function Loss: 1.76645

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.22439
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.06987

Collected Steps per Second: 8,605.42903
Overall Steps per Second: 7,422.30715

Timestep Collection Time: 5.81122
Timestep Consumption Time: 0.92631
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.73753

Cumulative Model Updates: 24,223
Cumulative Timesteps: 404,078,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.53882
Policy Entropy: 1.08849
Value Function Loss: 1.76607

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.19112
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.07627

Collected Steps per Second: 8,760.82767
Overall Steps per Second: 7,563.63336

Timestep Collection Time: 5.70973
Timestep Consumption Time: 0.90375
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.61349

Cumulative Model Updates: 24,226
Cumulative Timesteps: 404,128,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 404128966...
Checkpoint 404128966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.90992
Policy Entropy: 1.07706
Value Function Loss: 1.77666

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.18768
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.07628

Collected Steps per Second: 8,903.45589
Overall Steps per Second: 7,766.67239

Timestep Collection Time: 5.61580
Timestep Consumption Time: 0.82197
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.43776

Cumulative Model Updates: 24,229
Cumulative Timesteps: 404,178,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.53877
Policy Entropy: 1.07455
Value Function Loss: 1.71580

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.18499
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 8,618.71674
Overall Steps per Second: 7,452.91725

Timestep Collection Time: 5.80272
Timestep Consumption Time: 0.90767
PPO Batch Consumption Time: 0.04108
Total Iteration Time: 6.71039

Cumulative Model Updates: 24,232
Cumulative Timesteps: 404,228,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 404228978...
Checkpoint 404228978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.29713
Policy Entropy: 1.05546
Value Function Loss: 1.64882

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.20893
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.08745

Collected Steps per Second: 8,870.76351
Overall Steps per Second: 7,861.25089

Timestep Collection Time: 5.63762
Timestep Consumption Time: 0.72396
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 6.36158

Cumulative Model Updates: 24,235
Cumulative Timesteps: 404,278,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.09515
Policy Entropy: 1.06679
Value Function Loss: 1.54573

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.16541
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 8,592.98007
Overall Steps per Second: 7,497.43877

Timestep Collection Time: 5.82196
Timestep Consumption Time: 0.85072
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 6.67268

Cumulative Model Updates: 24,238
Cumulative Timesteps: 404,329,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 404329016...
Checkpoint 404329016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.93199
Policy Entropy: 1.07234
Value Function Loss: 1.59500

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 8,669.23919
Overall Steps per Second: 7,604.32807

Timestep Collection Time: 5.76752
Timestep Consumption Time: 0.80768
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.57520

Cumulative Model Updates: 24,241
Cumulative Timesteps: 404,379,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.20129
Policy Entropy: 1.04287
Value Function Loss: 1.58732

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 8,756.12956
Overall Steps per Second: 7,613.93890

Timestep Collection Time: 5.71348
Timestep Consumption Time: 0.85710
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 6.57058

Cumulative Model Updates: 24,244
Cumulative Timesteps: 404,429,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 404429044...
Checkpoint 404429044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.59156
Policy Entropy: 1.04690
Value Function Loss: 1.67316

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 8,599.62651
Overall Steps per Second: 7,540.09606

Timestep Collection Time: 5.81490
Timestep Consumption Time: 0.81711
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.63201

Cumulative Model Updates: 24,247
Cumulative Timesteps: 404,479,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.89499
Policy Entropy: 1.05627
Value Function Loss: 1.78093

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.07156

Collected Steps per Second: 8,656.74800
Overall Steps per Second: 7,644.83161

Timestep Collection Time: 5.77861
Timestep Consumption Time: 0.76489
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 6.54351

Cumulative Model Updates: 24,250
Cumulative Timesteps: 404,529,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 404529074...
Checkpoint 404529074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.51992
Policy Entropy: 1.06498
Value Function Loss: 1.87306

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 8,758.12274
Overall Steps per Second: 7,615.02406

Timestep Collection Time: 5.71173
Timestep Consumption Time: 0.85739
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 6.56912

Cumulative Model Updates: 24,253
Cumulative Timesteps: 404,579,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.20818
Policy Entropy: 1.05735
Value Function Loss: 1.81115

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 8,784.95565
Overall Steps per Second: 7,651.19062

Timestep Collection Time: 5.69496
Timestep Consumption Time: 0.84389
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 6.53885

Cumulative Model Updates: 24,256
Cumulative Timesteps: 404,629,128

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 404629128...
Checkpoint 404629128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.30274
Policy Entropy: 1.03924
Value Function Loss: 1.67206

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.19127
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 9,052.27134
Overall Steps per Second: 7,694.07556

Timestep Collection Time: 5.52679
Timestep Consumption Time: 0.97562
PPO Batch Consumption Time: 0.05411
Total Iteration Time: 6.50241

Cumulative Model Updates: 24,259
Cumulative Timesteps: 404,679,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.41055
Policy Entropy: 1.05723
Value Function Loss: 1.75076

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.15883
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.07563

Collected Steps per Second: 8,609.90523
Overall Steps per Second: 7,481.59022

Timestep Collection Time: 5.80843
Timestep Consumption Time: 0.87598
PPO Batch Consumption Time: 0.05081
Total Iteration Time: 6.68441

Cumulative Model Updates: 24,262
Cumulative Timesteps: 404,729,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 404729168...
Checkpoint 404729168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.67914
Policy Entropy: 1.05687
Value Function Loss: 1.83088

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.18701
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.07514

Collected Steps per Second: 8,653.57531
Overall Steps per Second: 7,652.22559

Timestep Collection Time: 5.78027
Timestep Consumption Time: 0.75639
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.53666

Cumulative Model Updates: 24,265
Cumulative Timesteps: 404,779,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.71686
Policy Entropy: 1.04463
Value Function Loss: 1.79978

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.07035

Collected Steps per Second: 8,923.72571
Overall Steps per Second: 7,722.03288

Timestep Collection Time: 5.60528
Timestep Consumption Time: 0.87229
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 6.47757

Cumulative Model Updates: 24,268
Cumulative Timesteps: 404,829,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 404829208...
Checkpoint 404829208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.99309
Policy Entropy: 1.03916
Value Function Loss: 1.69605

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.22929
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 8,670.93976
Overall Steps per Second: 7,616.29236

Timestep Collection Time: 5.76823
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.56697

Cumulative Model Updates: 24,271
Cumulative Timesteps: 404,879,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.90992
Policy Entropy: 1.04201
Value Function Loss: 1.76136

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 8,668.20210
Overall Steps per Second: 7,663.81211

Timestep Collection Time: 5.77029
Timestep Consumption Time: 0.75623
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.52652

Cumulative Model Updates: 24,274
Cumulative Timesteps: 404,929,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 404929242...
Checkpoint 404929242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.39786
Policy Entropy: 1.04876
Value Function Loss: 1.69675

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15682
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 8,730.25802
Overall Steps per Second: 7,489.92665

Timestep Collection Time: 5.72904
Timestep Consumption Time: 0.94873
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.67777

Cumulative Model Updates: 24,277
Cumulative Timesteps: 404,979,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.98062
Policy Entropy: 1.03331
Value Function Loss: 1.62289

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.08248

Collected Steps per Second: 8,784.66418
Overall Steps per Second: 7,582.77830

Timestep Collection Time: 5.69333
Timestep Consumption Time: 0.90240
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.59574

Cumulative Model Updates: 24,280
Cumulative Timesteps: 405,029,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 405029272...
Checkpoint 405029272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.12695
Policy Entropy: 1.02734
Value Function Loss: 1.49323

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 9,019.01883
Overall Steps per Second: 7,835.17760

Timestep Collection Time: 5.54428
Timestep Consumption Time: 0.83770
PPO Batch Consumption Time: 0.04729
Total Iteration Time: 6.38199

Cumulative Model Updates: 24,283
Cumulative Timesteps: 405,079,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.43787
Policy Entropy: 1.03752
Value Function Loss: 1.55127

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.19353
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 8,670.58104
Overall Steps per Second: 7,562.81048

Timestep Collection Time: 5.77009
Timestep Consumption Time: 0.84518
PPO Batch Consumption Time: 0.04732
Total Iteration Time: 6.61527

Cumulative Model Updates: 24,286
Cumulative Timesteps: 405,129,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 405129306...
Checkpoint 405129306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.08250
Policy Entropy: 1.05380
Value Function Loss: 1.63826

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.18140
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,906.05950
Overall Steps per Second: 7,830.94980

Timestep Collection Time: 5.61663
Timestep Consumption Time: 0.77111
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.38773

Cumulative Model Updates: 24,289
Cumulative Timesteps: 405,179,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.01911
Policy Entropy: 1.05356
Value Function Loss: 1.76345

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.17177
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.06927

Collected Steps per Second: 8,974.79442
Overall Steps per Second: 7,775.34143

Timestep Collection Time: 5.57428
Timestep Consumption Time: 0.85991
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.43419

Cumulative Model Updates: 24,292
Cumulative Timesteps: 405,229,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 405229356...
Checkpoint 405229356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.16226
Policy Entropy: 1.04860
Value Function Loss: 1.72908

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.08638

Collected Steps per Second: 8,928.42082
Overall Steps per Second: 7,703.94405

Timestep Collection Time: 5.60233
Timestep Consumption Time: 0.89044
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 6.49278

Cumulative Model Updates: 24,295
Cumulative Timesteps: 405,279,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.74317
Policy Entropy: 1.06357
Value Function Loss: 1.84065

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.07440

Collected Steps per Second: 8,869.66610
Overall Steps per Second: 7,807.04989

Timestep Collection Time: 5.63877
Timestep Consumption Time: 0.76749
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.40626

Cumulative Model Updates: 24,298
Cumulative Timesteps: 405,329,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 405329390...
Checkpoint 405329390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.29217
Policy Entropy: 1.06376
Value Function Loss: 1.87171

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 8,374.25610
Overall Steps per Second: 7,173.92136

Timestep Collection Time: 5.97426
Timestep Consumption Time: 0.99961
PPO Batch Consumption Time: 0.04852
Total Iteration Time: 6.97387

Cumulative Model Updates: 24,301
Cumulative Timesteps: 405,379,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.67185
Policy Entropy: 1.08759
Value Function Loss: 2.04076

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 8,892.02522
Overall Steps per Second: 7,696.96275

Timestep Collection Time: 5.62639
Timestep Consumption Time: 0.87358
PPO Batch Consumption Time: 0.04732
Total Iteration Time: 6.49997

Cumulative Model Updates: 24,304
Cumulative Timesteps: 405,429,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 405429450...
Checkpoint 405429450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.06017
Policy Entropy: 1.07739
Value Function Loss: 1.92748

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.17581
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.05285

Collected Steps per Second: 8,892.28848
Overall Steps per Second: 7,678.97153

Timestep Collection Time: 5.62577
Timestep Consumption Time: 0.88890
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.51467

Cumulative Model Updates: 24,307
Cumulative Timesteps: 405,479,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.32089
Policy Entropy: 1.09384
Value Function Loss: 1.96156

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.04617

Collected Steps per Second: 8,759.55034
Overall Steps per Second: 7,599.71179

Timestep Collection Time: 5.70851
Timestep Consumption Time: 0.87121
PPO Batch Consumption Time: 0.05173
Total Iteration Time: 6.57972

Cumulative Model Updates: 24,310
Cumulative Timesteps: 405,529,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 405529480...
Checkpoint 405529480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.62318
Policy Entropy: 1.09088
Value Function Loss: 1.76737

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.04951

Collected Steps per Second: 9,076.88764
Overall Steps per Second: 7,899.42386

Timestep Collection Time: 5.51026
Timestep Consumption Time: 0.82134
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 6.33160

Cumulative Model Updates: 24,313
Cumulative Timesteps: 405,579,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.66475
Policy Entropy: 1.08198
Value Function Loss: 1.76062

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.17493
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.05408

Collected Steps per Second: 8,583.11306
Overall Steps per Second: 7,491.65575

Timestep Collection Time: 5.82819
Timestep Consumption Time: 0.84911
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.67730

Cumulative Model Updates: 24,316
Cumulative Timesteps: 405,629,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 405629520...
Checkpoint 405629520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.64492
Policy Entropy: 1.09587
Value Function Loss: 1.85578

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 9,197.47161
Overall Steps per Second: 7,941.50748

Timestep Collection Time: 5.43910
Timestep Consumption Time: 0.86020
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.29931

Cumulative Model Updates: 24,319
Cumulative Timesteps: 405,679,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.27389
Policy Entropy: 1.09694
Value Function Loss: 1.98094

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.16432
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 9,219.46412
Overall Steps per Second: 7,867.35358

Timestep Collection Time: 5.42396
Timestep Consumption Time: 0.93218
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 6.35614

Cumulative Model Updates: 24,322
Cumulative Timesteps: 405,729,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 405729552...
Checkpoint 405729552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.60678
Policy Entropy: 1.08471
Value Function Loss: 2.08412

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.06074

Collected Steps per Second: 8,768.77461
Overall Steps per Second: 7,612.25056

Timestep Collection Time: 5.70456
Timestep Consumption Time: 0.86669
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.57125

Cumulative Model Updates: 24,325
Cumulative Timesteps: 405,779,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.77994
Policy Entropy: 1.07978
Value Function Loss: 1.99156

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.05918

Collected Steps per Second: 8,948.98570
Overall Steps per Second: 7,729.27240

Timestep Collection Time: 5.58879
Timestep Consumption Time: 0.88194
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.47073

Cumulative Model Updates: 24,328
Cumulative Timesteps: 405,829,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 405829588...
Checkpoint 405829588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.86667
Policy Entropy: 1.09185
Value Function Loss: 2.07813

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.06991

Collected Steps per Second: 8,770.82042
Overall Steps per Second: 7,591.08379

Timestep Collection Time: 5.70323
Timestep Consumption Time: 0.88634
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.58957

Cumulative Model Updates: 24,331
Cumulative Timesteps: 405,879,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.58414
Policy Entropy: 1.09938
Value Function Loss: 2.02999

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.09114

Collected Steps per Second: 8,722.57686
Overall Steps per Second: 7,624.63226

Timestep Collection Time: 5.73477
Timestep Consumption Time: 0.82581
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.56058

Cumulative Model Updates: 24,334
Cumulative Timesteps: 405,929,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 405929632...
Checkpoint 405929632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.30808
Policy Entropy: 1.08888
Value Function Loss: 1.99744

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 8,774.79996
Overall Steps per Second: 7,547.31781

Timestep Collection Time: 5.70178
Timestep Consumption Time: 0.92733
PPO Batch Consumption Time: 0.05395
Total Iteration Time: 6.62911

Cumulative Model Updates: 24,337
Cumulative Timesteps: 405,979,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.49417
Policy Entropy: 1.07635
Value Function Loss: 1.93913

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 8,810.92613
Overall Steps per Second: 7,667.82466

Timestep Collection Time: 5.67613
Timestep Consumption Time: 0.84618
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.52232

Cumulative Model Updates: 24,340
Cumulative Timesteps: 406,029,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 406029676...
Checkpoint 406029676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.98662
Policy Entropy: 1.08661
Value Function Loss: 1.96374

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07136

Collected Steps per Second: 8,461.33287
Overall Steps per Second: 7,509.97373

Timestep Collection Time: 5.91302
Timestep Consumption Time: 0.74906
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.66207

Cumulative Model Updates: 24,343
Cumulative Timesteps: 406,079,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.57866
Policy Entropy: 1.08259
Value Function Loss: 1.87989

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 8,828.26963
Overall Steps per Second: 7,575.64994

Timestep Collection Time: 5.66498
Timestep Consumption Time: 0.93669
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.60168

Cumulative Model Updates: 24,346
Cumulative Timesteps: 406,129,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 406129720...
Checkpoint 406129720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.98288
Policy Entropy: 1.05765
Value Function Loss: 1.70710

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.23617
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.08804

Collected Steps per Second: 8,947.90318
Overall Steps per Second: 7,803.17066

Timestep Collection Time: 5.59036
Timestep Consumption Time: 0.82011
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.41047

Cumulative Model Updates: 24,349
Cumulative Timesteps: 406,179,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.46644
Policy Entropy: 1.07236
Value Function Loss: 1.57238

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.09207

Collected Steps per Second: 8,964.28138
Overall Steps per Second: 7,728.04405

Timestep Collection Time: 5.57948
Timestep Consumption Time: 0.89254
PPO Batch Consumption Time: 0.04794
Total Iteration Time: 6.47201

Cumulative Model Updates: 24,352
Cumulative Timesteps: 406,229,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 406229758...
Checkpoint 406229758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.62227
Policy Entropy: 1.07006
Value Function Loss: 1.58424

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 8,690.59612
Overall Steps per Second: 7,461.42139

Timestep Collection Time: 5.75703
Timestep Consumption Time: 0.94840
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 6.70542

Cumulative Model Updates: 24,355
Cumulative Timesteps: 406,279,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.20569
Policy Entropy: 1.05849
Value Function Loss: 1.61838

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.09086

Collected Steps per Second: 8,853.87067
Overall Steps per Second: 7,817.08295

Timestep Collection Time: 5.64747
Timestep Consumption Time: 0.74903
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.39650

Cumulative Model Updates: 24,358
Cumulative Timesteps: 406,329,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 406329792...
Checkpoint 406329792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.51870
Policy Entropy: 1.02762
Value Function Loss: 1.66713

Mean KL Divergence: 0.05308
SB3 Clip Fraction: 0.31598
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 8,845.31206
Overall Steps per Second: 7,674.56564

Timestep Collection Time: 5.65497
Timestep Consumption Time: 0.86266
PPO Batch Consumption Time: 0.04460
Total Iteration Time: 6.51763

Cumulative Model Updates: 24,361
Cumulative Timesteps: 406,379,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.91163
Policy Entropy: 1.06195
Value Function Loss: 1.66263

Mean KL Divergence: 0.02818
SB3 Clip Fraction: 0.24527
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.08076

Collected Steps per Second: 8,578.38415
Overall Steps per Second: 7,519.73898

Timestep Collection Time: 5.83117
Timestep Consumption Time: 0.82092
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.65209

Cumulative Model Updates: 24,364
Cumulative Timesteps: 406,429,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 406429834...
Checkpoint 406429834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.55285
Policy Entropy: 1.01831
Value Function Loss: 1.71017

Mean KL Divergence: 0.07253
SB3 Clip Fraction: 0.35195
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.07426

Collected Steps per Second: 9,172.24748
Overall Steps per Second: 7,790.87909

Timestep Collection Time: 5.45319
Timestep Consumption Time: 0.96688
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 6.42007

Cumulative Model Updates: 24,367
Cumulative Timesteps: 406,479,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.40148
Policy Entropy: 1.04481
Value Function Loss: 1.55282

Mean KL Divergence: 0.03569
SB3 Clip Fraction: 0.25787
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.06664

Collected Steps per Second: 8,677.66329
Overall Steps per Second: 7,614.34263

Timestep Collection Time: 5.76399
Timestep Consumption Time: 0.80492
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 6.56892

Cumulative Model Updates: 24,370
Cumulative Timesteps: 406,529,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 406529870...
Checkpoint 406529870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.53099
Policy Entropy: 1.01837
Value Function Loss: 1.53734

Mean KL Divergence: 0.04897
SB3 Clip Fraction: 0.29851
Policy Update Magnitude: 0.03866
Value Function Update Magnitude: 0.05801

Collected Steps per Second: 8,908.17731
Overall Steps per Second: 7,831.74963

Timestep Collection Time: 5.61327
Timestep Consumption Time: 0.77151
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.38478

Cumulative Model Updates: 24,373
Cumulative Timesteps: 406,579,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.94536
Policy Entropy: 1.03680
Value Function Loss: 1.46308

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.20167
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.06722

Collected Steps per Second: 8,926.12567
Overall Steps per Second: 7,746.85017

Timestep Collection Time: 5.60445
Timestep Consumption Time: 0.85315
PPO Batch Consumption Time: 0.04781
Total Iteration Time: 6.45759

Cumulative Model Updates: 24,376
Cumulative Timesteps: 406,629,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 406629900...
Checkpoint 406629900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.09241
Policy Entropy: 1.04040
Value Function Loss: 1.62330

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.19710
Policy Update Magnitude: 0.03612
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 8,831.14807
Overall Steps per Second: 7,721.02189

Timestep Collection Time: 5.66427
Timestep Consumption Time: 0.81441
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.47868

Cumulative Model Updates: 24,379
Cumulative Timesteps: 406,679,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.45792
Policy Entropy: 0.98036
Value Function Loss: 1.58698

Mean KL Divergence: 0.07265
SB3 Clip Fraction: 0.36619
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 8,788.33147
Overall Steps per Second: 7,628.09371

Timestep Collection Time: 5.69118
Timestep Consumption Time: 0.86563
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.55682

Cumulative Model Updates: 24,382
Cumulative Timesteps: 406,729,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 406729938...
Checkpoint 406729938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.50517
Policy Entropy: 1.01919
Value Function Loss: 1.47122

Mean KL Divergence: 0.04550
SB3 Clip Fraction: 0.31195
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 8,433.69782
Overall Steps per Second: 7,362.12764

Timestep Collection Time: 5.92955
Timestep Consumption Time: 0.86306
PPO Batch Consumption Time: 0.05021
Total Iteration Time: 6.79260

Cumulative Model Updates: 24,385
Cumulative Timesteps: 406,779,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.75326
Policy Entropy: 0.97886
Value Function Loss: 1.39496

Mean KL Divergence: 0.06579
SB3 Clip Fraction: 0.36658
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.04958

Collected Steps per Second: 8,728.20325
Overall Steps per Second: 7,708.60457

Timestep Collection Time: 5.72924
Timestep Consumption Time: 0.75779
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 6.48704

Cumulative Model Updates: 24,388
Cumulative Timesteps: 406,829,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406829952...
Checkpoint 406829952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.08238
Policy Entropy: 1.02489
Value Function Loss: 1.36201

Mean KL Divergence: 0.05198
SB3 Clip Fraction: 0.33821
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 8,652.00227
Overall Steps per Second: 7,536.87959

Timestep Collection Time: 5.77970
Timestep Consumption Time: 0.85514
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 6.63484

Cumulative Model Updates: 24,391
Cumulative Timesteps: 406,879,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.63260
Policy Entropy: 0.98882
Value Function Loss: 1.51106

Mean KL Divergence: 0.05492
SB3 Clip Fraction: 0.33607
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.05074

Collected Steps per Second: 8,793.05833
Overall Steps per Second: 7,703.08314

Timestep Collection Time: 5.68767
Timestep Consumption Time: 0.80480
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 6.49247

Cumulative Model Updates: 24,394
Cumulative Timesteps: 406,929,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 406929970...
Checkpoint 406929970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.07565
Policy Entropy: 1.02593
Value Function Loss: 1.55376

Mean KL Divergence: 0.04240
SB3 Clip Fraction: 0.30202
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.05011

Collected Steps per Second: 8,592.65269
Overall Steps per Second: 7,481.87697

Timestep Collection Time: 5.82172
Timestep Consumption Time: 0.86430
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.68602

Cumulative Model Updates: 24,397
Cumulative Timesteps: 406,979,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.36345
Policy Entropy: 0.99164
Value Function Loss: 1.65235

Mean KL Divergence: 0.05566
SB3 Clip Fraction: 0.31907
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 8,695.46355
Overall Steps per Second: 7,552.51548

Timestep Collection Time: 5.75334
Timestep Consumption Time: 0.87067
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 6.62402

Cumulative Model Updates: 24,400
Cumulative Timesteps: 407,030,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 407030022...
Checkpoint 407030022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.04907
Policy Entropy: 1.02305
Value Function Loss: 1.58991

Mean KL Divergence: 0.03975
SB3 Clip Fraction: 0.26807
Policy Update Magnitude: 0.03341
Value Function Update Magnitude: 0.04138

Collected Steps per Second: 8,703.66459
Overall Steps per Second: 7,695.97342

Timestep Collection Time: 5.74792
Timestep Consumption Time: 0.75262
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.50054

Cumulative Model Updates: 24,403
Cumulative Timesteps: 407,080,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.47811
Policy Entropy: 0.98814
Value Function Loss: 1.55481

Mean KL Divergence: 0.05695
SB3 Clip Fraction: 0.32887
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.04188

Collected Steps per Second: 8,767.97319
Overall Steps per Second: 7,559.09250

Timestep Collection Time: 5.70417
Timestep Consumption Time: 0.91223
PPO Batch Consumption Time: 0.04858
Total Iteration Time: 6.61640

Cumulative Model Updates: 24,406
Cumulative Timesteps: 407,130,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 407130064...
Checkpoint 407130064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.36156
Policy Entropy: 1.01679
Value Function Loss: 1.41939

Mean KL Divergence: 0.03326
SB3 Clip Fraction: 0.24016
Policy Update Magnitude: 0.03453
Value Function Update Magnitude: 0.04849

Collected Steps per Second: 8,597.79738
Overall Steps per Second: 7,521.57105

Timestep Collection Time: 5.81637
Timestep Consumption Time: 0.83224
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.64861

Cumulative Model Updates: 24,409
Cumulative Timesteps: 407,180,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.71091
Policy Entropy: 0.97205
Value Function Loss: 1.52119

Mean KL Divergence: 0.05990
SB3 Clip Fraction: 0.34501
Policy Update Magnitude: 0.03477
Value Function Update Magnitude: 0.05058

Collected Steps per Second: 8,805.58577
Overall Steps per Second: 7,571.22356

Timestep Collection Time: 5.68094
Timestep Consumption Time: 0.92618
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.60712

Cumulative Model Updates: 24,412
Cumulative Timesteps: 407,230,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 407230096...
Checkpoint 407230096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.75311
Policy Entropy: 1.00772
Value Function Loss: 1.44587

Mean KL Divergence: 0.03063
SB3 Clip Fraction: 0.24087
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.04837

Collected Steps per Second: 8,813.02570
Overall Steps per Second: 7,671.23397

Timestep Collection Time: 5.67637
Timestep Consumption Time: 0.84487
PPO Batch Consumption Time: 0.04353
Total Iteration Time: 6.52125

Cumulative Model Updates: 24,415
Cumulative Timesteps: 407,280,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.12695
Policy Entropy: 0.98467
Value Function Loss: 1.50696

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.21025
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 8,504.75404
Overall Steps per Second: 7,443.26331

Timestep Collection Time: 5.88212
Timestep Consumption Time: 0.83885
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.72098

Cumulative Model Updates: 24,418
Cumulative Timesteps: 407,330,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 407330148...
Checkpoint 407330148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.78958
Policy Entropy: 1.00438
Value Function Loss: 1.52690

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.20205
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 8,942.07823
Overall Steps per Second: 7,765.72359

Timestep Collection Time: 5.59288
Timestep Consumption Time: 0.84721
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.44010

Cumulative Model Updates: 24,421
Cumulative Timesteps: 407,380,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.71059
Policy Entropy: 1.00352
Value Function Loss: 1.53309

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.17009
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 8,978.25956
Overall Steps per Second: 7,780.83432

Timestep Collection Time: 5.57168
Timestep Consumption Time: 0.85745
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.42913

Cumulative Model Updates: 24,424
Cumulative Timesteps: 407,430,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 407430184...
Checkpoint 407430184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.35210
Policy Entropy: 0.99076
Value Function Loss: 1.55386

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.19049
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 9,425.54512
Overall Steps per Second: 8,112.09898

Timestep Collection Time: 5.30622
Timestep Consumption Time: 0.85914
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.16536

Cumulative Model Updates: 24,427
Cumulative Timesteps: 407,480,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.87903
Policy Entropy: 0.99023
Value Function Loss: 1.52426

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.18509
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 9,161.25729
Overall Steps per Second: 7,894.04988

Timestep Collection Time: 5.45864
Timestep Consumption Time: 0.87626
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 6.33490

Cumulative Model Updates: 24,430
Cumulative Timesteps: 407,530,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407530206...
Checkpoint 407530206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.79530
Policy Entropy: 1.00469
Value Function Loss: 1.71853

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 9,060.49014
Overall Steps per Second: 7,967.60708

Timestep Collection Time: 5.52045
Timestep Consumption Time: 0.75722
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 6.27767

Cumulative Model Updates: 24,433
Cumulative Timesteps: 407,580,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.70609
Policy Entropy: 1.01095
Value Function Loss: 1.81832

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.19403
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.07777

Collected Steps per Second: 8,840.17936
Overall Steps per Second: 7,689.03547

Timestep Collection Time: 5.65803
Timestep Consumption Time: 0.84708
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 6.50511

Cumulative Model Updates: 24,436
Cumulative Timesteps: 407,630,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 407630242...
Checkpoint 407630242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.62427
Policy Entropy: 0.99336
Value Function Loss: 1.69713

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 8,568.84658
Overall Steps per Second: 7,494.63592

Timestep Collection Time: 5.83813
Timestep Consumption Time: 0.83678
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.67491

Cumulative Model Updates: 24,439
Cumulative Timesteps: 407,680,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.35556
Policy Entropy: 0.98601
Value Function Loss: 1.59190

Mean KL Divergence: 0.03152
SB3 Clip Fraction: 0.21179
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.06812

Collected Steps per Second: 9,012.40891
Overall Steps per Second: 7,775.96040

Timestep Collection Time: 5.54813
Timestep Consumption Time: 0.88220
PPO Batch Consumption Time: 0.05330
Total Iteration Time: 6.43033

Cumulative Model Updates: 24,442
Cumulative Timesteps: 407,730,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 407730270...
Checkpoint 407730270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.46833
Policy Entropy: 0.99886
Value Function Loss: 1.50874

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.17203
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 8,606.86468
Overall Steps per Second: 7,477.53797

Timestep Collection Time: 5.81001
Timestep Consumption Time: 0.87748
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 6.68750

Cumulative Model Updates: 24,445
Cumulative Timesteps: 407,780,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.86963
Policy Entropy: 1.01037
Value Function Loss: 1.64468

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.19715
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 8,784.47601
Overall Steps per Second: 7,752.14115

Timestep Collection Time: 5.69391
Timestep Consumption Time: 0.75824
PPO Batch Consumption Time: 0.04875
Total Iteration Time: 6.45215

Cumulative Model Updates: 24,448
Cumulative Timesteps: 407,830,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 407830294...
Checkpoint 407830294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.70752
Policy Entropy: 1.00011
Value Function Loss: 1.70545

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.20685
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 8,886.96195
Overall Steps per Second: 7,663.51561

Timestep Collection Time: 5.62734
Timestep Consumption Time: 0.89838
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 6.52573

Cumulative Model Updates: 24,451
Cumulative Timesteps: 407,880,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.18916
Policy Entropy: 0.99425
Value Function Loss: 1.73901

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.19721
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.05573

Collected Steps per Second: 8,834.44761
Overall Steps per Second: 7,735.84315

Timestep Collection Time: 5.66170
Timestep Consumption Time: 0.80405
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.46575

Cumulative Model Updates: 24,454
Cumulative Timesteps: 407,930,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 407930322...
Checkpoint 407930322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.34567
Policy Entropy: 1.00873
Value Function Loss: 1.60869

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.18496
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 8,960.93444
Overall Steps per Second: 7,818.77320

Timestep Collection Time: 5.58044
Timestep Consumption Time: 0.81519
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.39563

Cumulative Model Updates: 24,457
Cumulative Timesteps: 407,980,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.20950
Policy Entropy: 1.00282
Value Function Loss: 1.54151

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.17806
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 8,736.04611
Overall Steps per Second: 7,573.24720

Timestep Collection Time: 5.72456
Timestep Consumption Time: 0.87895
PPO Batch Consumption Time: 0.04647
Total Iteration Time: 6.60351

Cumulative Model Updates: 24,460
Cumulative Timesteps: 408,030,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 408030338...
Checkpoint 408030338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.72024
Policy Entropy: 0.99565
Value Function Loss: 1.43841

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.05113

Collected Steps per Second: 8,992.73123
Overall Steps per Second: 7,926.61258

Timestep Collection Time: 5.56249
Timestep Consumption Time: 0.74815
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 6.31064

Cumulative Model Updates: 24,463
Cumulative Timesteps: 408,080,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.83009
Policy Entropy: 0.98909
Value Function Loss: 1.49677

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.05682

Collected Steps per Second: 8,621.42976
Overall Steps per Second: 7,537.42557

Timestep Collection Time: 5.80182
Timestep Consumption Time: 0.83440
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 6.63622

Cumulative Model Updates: 24,466
Cumulative Timesteps: 408,130,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 408130380...
Checkpoint 408130380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.69368
Policy Entropy: 0.99287
Value Function Loss: 1.61457

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.05030

Collected Steps per Second: 8,840.33704
Overall Steps per Second: 7,648.24228

Timestep Collection Time: 5.65680
Timestep Consumption Time: 0.88170
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.53850

Cumulative Model Updates: 24,469
Cumulative Timesteps: 408,180,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.21048
Policy Entropy: 0.99689
Value Function Loss: 1.72962

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.06928
Value Function Update Magnitude: 0.04761

Collected Steps per Second: 8,888.66910
Overall Steps per Second: 7,636.20161

Timestep Collection Time: 5.62559
Timestep Consumption Time: 0.92269
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 6.54828

Cumulative Model Updates: 24,472
Cumulative Timesteps: 408,230,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 408230392...
Checkpoint 408230392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.36228
Policy Entropy: 1.00522
Value Function Loss: 1.79216

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.16464
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 8,525.00871
Overall Steps per Second: 7,517.20361

Timestep Collection Time: 5.86815
Timestep Consumption Time: 0.78672
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.65487

Cumulative Model Updates: 24,475
Cumulative Timesteps: 408,280,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.83379
Policy Entropy: 1.00155
Value Function Loss: 1.72205

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.05236

Collected Steps per Second: 8,984.86925
Overall Steps per Second: 7,787.31281

Timestep Collection Time: 5.56825
Timestep Consumption Time: 0.85630
PPO Batch Consumption Time: 0.04323
Total Iteration Time: 6.42455

Cumulative Model Updates: 24,478
Cumulative Timesteps: 408,330,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 408330448...
Checkpoint 408330448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.82017
Policy Entropy: 0.99485
Value Function Loss: 1.60315

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.17732
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.06207

Collected Steps per Second: 8,765.94363
Overall Steps per Second: 7,648.11828

Timestep Collection Time: 5.70435
Timestep Consumption Time: 0.83373
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.53808

Cumulative Model Updates: 24,481
Cumulative Timesteps: 408,380,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.28358
Policy Entropy: 1.00586
Value Function Loss: 1.59446

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 8,951.12155
Overall Steps per Second: 7,727.50439

Timestep Collection Time: 5.58656
Timestep Consumption Time: 0.88461
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 6.47117

Cumulative Model Updates: 24,484
Cumulative Timesteps: 408,430,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 408430458...
Checkpoint 408430458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.72500
Policy Entropy: 1.00815
Value Function Loss: 1.55960

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.05839

Collected Steps per Second: 8,961.12278
Overall Steps per Second: 7,819.60664

Timestep Collection Time: 5.58055
Timestep Consumption Time: 0.81466
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 6.39521

Cumulative Model Updates: 24,487
Cumulative Timesteps: 408,480,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.57384
Policy Entropy: 1.01501
Value Function Loss: 1.66927

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.07216
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 8,888.25294
Overall Steps per Second: 7,678.38812

Timestep Collection Time: 5.62585
Timestep Consumption Time: 0.88645
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.51230

Cumulative Model Updates: 24,490
Cumulative Timesteps: 408,530,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 408530470...
Checkpoint 408530470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.72645
Policy Entropy: 1.00804
Value Function Loss: 1.68694

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.07031
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 8,739.99933
Overall Steps per Second: 7,720.17310

Timestep Collection Time: 5.72334
Timestep Consumption Time: 0.75605
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 6.47939

Cumulative Model Updates: 24,493
Cumulative Timesteps: 408,580,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.69394
Policy Entropy: 1.01174
Value Function Loss: 1.61007

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.06887

Collected Steps per Second: 8,907.91124
Overall Steps per Second: 7,740.00406

Timestep Collection Time: 5.61613
Timestep Consumption Time: 0.84743
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.46356

Cumulative Model Updates: 24,496
Cumulative Timesteps: 408,630,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 408630520...
Checkpoint 408630520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.54328
Policy Entropy: 1.02815
Value Function Loss: 1.68356

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.16880
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.06528

Collected Steps per Second: 9,070.04936
Overall Steps per Second: 7,857.46238

Timestep Collection Time: 5.51397
Timestep Consumption Time: 0.85093
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.36490

Cumulative Model Updates: 24,499
Cumulative Timesteps: 408,680,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.56634
Policy Entropy: 1.00848
Value Function Loss: 1.65743

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.06985

Collected Steps per Second: 9,005.71683
Overall Steps per Second: 7,774.80086

Timestep Collection Time: 5.55425
Timestep Consumption Time: 0.87936
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.43361

Cumulative Model Updates: 24,502
Cumulative Timesteps: 408,730,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 408730552...
Checkpoint 408730552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.13331
Policy Entropy: 1.00714
Value Function Loss: 1.73113

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.17623
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 8,976.05606
Overall Steps per Second: 7,710.15229

Timestep Collection Time: 5.57193
Timestep Consumption Time: 0.91484
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.48677

Cumulative Model Updates: 24,505
Cumulative Timesteps: 408,780,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.03568
Policy Entropy: 1.03340
Value Function Loss: 1.74025

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.17909
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 8,396.30943
Overall Steps per Second: 7,411.15883

Timestep Collection Time: 5.95595
Timestep Consumption Time: 0.79171
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 6.74766

Cumulative Model Updates: 24,508
Cumulative Timesteps: 408,830,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 408830574...
Checkpoint 408830574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.76117
Policy Entropy: 1.03787
Value Function Loss: 1.60961

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 8,940.12402
Overall Steps per Second: 7,731.13044

Timestep Collection Time: 5.59321
Timestep Consumption Time: 0.87467
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.46788

Cumulative Model Updates: 24,511
Cumulative Timesteps: 408,880,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.24757
Policy Entropy: 1.02457
Value Function Loss: 1.53931

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.07868

Collected Steps per Second: 8,794.56810
Overall Steps per Second: 7,619.60532

Timestep Collection Time: 5.68851
Timestep Consumption Time: 0.87718
PPO Batch Consumption Time: 0.04957
Total Iteration Time: 6.56569

Cumulative Model Updates: 24,514
Cumulative Timesteps: 408,930,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 408930606...
Checkpoint 408930606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.08308
Policy Entropy: 1.01101
Value Function Loss: 1.48201

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.19995
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.07847

Collected Steps per Second: 8,644.25071
Overall Steps per Second: 7,576.45430

Timestep Collection Time: 5.78581
Timestep Consumption Time: 0.81543
PPO Batch Consumption Time: 0.04921
Total Iteration Time: 6.60124

Cumulative Model Updates: 24,517
Cumulative Timesteps: 408,980,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.27724
Policy Entropy: 1.02151
Value Function Loss: 1.58535

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 8,718.34566
Overall Steps per Second: 7,370.43341

Timestep Collection Time: 5.73641
Timestep Consumption Time: 1.04908
PPO Batch Consumption Time: 0.05066
Total Iteration Time: 6.78549

Cumulative Model Updates: 24,520
Cumulative Timesteps: 409,030,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 409030632...
Checkpoint 409030632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.74152
Policy Entropy: 1.02910
Value Function Loss: 1.55986

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.16543
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.06309

Collected Steps per Second: 8,809.08848
Overall Steps per Second: 7,606.27564

Timestep Collection Time: 5.67800
Timestep Consumption Time: 0.89789
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.57589

Cumulative Model Updates: 24,523
Cumulative Timesteps: 409,080,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.35102
Policy Entropy: 1.01594
Value Function Loss: 1.54728

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.06170

Collected Steps per Second: 9,141.77807
Overall Steps per Second: 7,864.99085

Timestep Collection Time: 5.47136
Timestep Consumption Time: 0.88821
PPO Batch Consumption Time: 0.05241
Total Iteration Time: 6.35958

Cumulative Model Updates: 24,526
Cumulative Timesteps: 409,130,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 409130668...
Checkpoint 409130668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.19361
Policy Entropy: 0.99509
Value Function Loss: 1.55977

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.19503
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.06757

Collected Steps per Second: 8,626.35322
Overall Steps per Second: 7,467.14793

Timestep Collection Time: 5.79689
Timestep Consumption Time: 0.89991
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.69680

Cumulative Model Updates: 24,529
Cumulative Timesteps: 409,180,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.47489
Policy Entropy: 1.01844
Value Function Loss: 1.78372

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 8,991.04825
Overall Steps per Second: 7,903.17379

Timestep Collection Time: 5.56198
Timestep Consumption Time: 0.76561
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 6.32758

Cumulative Model Updates: 24,532
Cumulative Timesteps: 409,230,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409230682...
Checkpoint 409230682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.48630
Policy Entropy: 1.01250
Value Function Loss: 1.76418

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 8,762.62207
Overall Steps per Second: 7,540.19506

Timestep Collection Time: 5.70765
Timestep Consumption Time: 0.92533
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.63298

Cumulative Model Updates: 24,535
Cumulative Timesteps: 409,280,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.49327
Policy Entropy: 1.01359
Value Function Loss: 1.66009

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.16981
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 8,900.49842
Overall Steps per Second: 7,702.49918

Timestep Collection Time: 5.62013
Timestep Consumption Time: 0.87412
PPO Batch Consumption Time: 0.05225
Total Iteration Time: 6.49426

Cumulative Model Updates: 24,538
Cumulative Timesteps: 409,330,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 409330718...
Checkpoint 409330718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.82431
Policy Entropy: 1.00873
Value Function Loss: 1.71697

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.20709
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 8,937.71954
Overall Steps per Second: 7,726.48610

Timestep Collection Time: 5.59561
Timestep Consumption Time: 0.87719
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.47280

Cumulative Model Updates: 24,541
Cumulative Timesteps: 409,380,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.81931
Policy Entropy: 1.01836
Value Function Loss: 1.74198

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.17555
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 8,996.65707
Overall Steps per Second: 7,808.95306

Timestep Collection Time: 5.55940
Timestep Consumption Time: 0.84556
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.40496

Cumulative Model Updates: 24,544
Cumulative Timesteps: 409,430,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 409430746...
Checkpoint 409430746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.37902
Policy Entropy: 1.02142
Value Function Loss: 1.90187

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.06173

Collected Steps per Second: 8,750.30952
Overall Steps per Second: 7,591.26953

Timestep Collection Time: 5.71523
Timestep Consumption Time: 0.87260
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 6.58783

Cumulative Model Updates: 24,547
Cumulative Timesteps: 409,480,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.39655
Policy Entropy: 1.01307
Value Function Loss: 1.67205

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.05532

Collected Steps per Second: 8,890.88992
Overall Steps per Second: 7,655.06457

Timestep Collection Time: 5.62598
Timestep Consumption Time: 0.90825
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.53424

Cumulative Model Updates: 24,550
Cumulative Timesteps: 409,530,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 409530776...
Checkpoint 409530776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.26499
Policy Entropy: 1.01622
Value Function Loss: 1.63269

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 8,705.08858
Overall Steps per Second: 7,532.83736

Timestep Collection Time: 5.74675
Timestep Consumption Time: 0.89430
PPO Batch Consumption Time: 0.04743
Total Iteration Time: 6.64106

Cumulative Model Updates: 24,553
Cumulative Timesteps: 409,580,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.48333
Policy Entropy: 1.03310
Value Function Loss: 1.83609

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 8,756.12047
Overall Steps per Second: 7,742.03453

Timestep Collection Time: 5.71098
Timestep Consumption Time: 0.74805
PPO Batch Consumption Time: 0.04479
Total Iteration Time: 6.45903

Cumulative Model Updates: 24,556
Cumulative Timesteps: 409,630,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 409630808...
Checkpoint 409630808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.37315
Policy Entropy: 1.03780
Value Function Loss: 1.96537

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 8,806.10069
Overall Steps per Second: 7,679.49354

Timestep Collection Time: 5.68038
Timestep Consumption Time: 0.83333
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.51371

Cumulative Model Updates: 24,559
Cumulative Timesteps: 409,680,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.64602
Policy Entropy: 1.05257
Value Function Loss: 2.17178

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 8,503.77113
Overall Steps per Second: 7,448.78524

Timestep Collection Time: 5.88021
Timestep Consumption Time: 0.83283
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.71304

Cumulative Model Updates: 24,562
Cumulative Timesteps: 409,730,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 409730834...
Checkpoint 409730834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.12263
Policy Entropy: 1.04960
Value Function Loss: 2.01190

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 8,911.09450
Overall Steps per Second: 7,758.81441

Timestep Collection Time: 5.61368
Timestep Consumption Time: 0.83370
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.44738

Cumulative Model Updates: 24,565
Cumulative Timesteps: 409,780,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.22083
Policy Entropy: 1.06296
Value Function Loss: 1.99792

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 8,860.66867
Overall Steps per Second: 7,634.30276

Timestep Collection Time: 5.64450
Timestep Consumption Time: 0.90673
PPO Batch Consumption Time: 0.04945
Total Iteration Time: 6.55122

Cumulative Model Updates: 24,568
Cumulative Timesteps: 409,830,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 409830872...
Checkpoint 409830872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.98825
Policy Entropy: 1.05477
Value Function Loss: 1.83825

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 8,848.85465
Overall Steps per Second: 7,847.78214

Timestep Collection Time: 5.65316
Timestep Consumption Time: 0.72112
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 6.37428

Cumulative Model Updates: 24,571
Cumulative Timesteps: 409,880,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.84680
Policy Entropy: 1.04822
Value Function Loss: 1.82068

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.17802
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.06643

Collected Steps per Second: 8,735.55733
Overall Steps per Second: 7,598.50093

Timestep Collection Time: 5.72625
Timestep Consumption Time: 0.85689
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.58314

Cumulative Model Updates: 24,574
Cumulative Timesteps: 409,930,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 409930918...
Checkpoint 409930918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.96370
Policy Entropy: 1.06030
Value Function Loss: 1.76053

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 8,584.23353
Overall Steps per Second: 7,505.42497

Timestep Collection Time: 5.82696
Timestep Consumption Time: 0.83755
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.66451

Cumulative Model Updates: 24,577
Cumulative Timesteps: 409,980,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.49439
Policy Entropy: 1.07079
Value Function Loss: 1.84358

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.17299
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 9,203.25345
Overall Steps per Second: 7,956.13849

Timestep Collection Time: 5.43503
Timestep Consumption Time: 0.85194
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.28697

Cumulative Model Updates: 24,580
Cumulative Timesteps: 410,030,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 410030958...
Checkpoint 410030958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.06203
Policy Entropy: 1.05752
Value Function Loss: 1.80934

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 8,774.52231
Overall Steps per Second: 7,559.59230

Timestep Collection Time: 5.69900
Timestep Consumption Time: 0.91591
PPO Batch Consumption Time: 0.04976
Total Iteration Time: 6.61491

Cumulative Model Updates: 24,583
Cumulative Timesteps: 410,080,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.47244
Policy Entropy: 1.05239
Value Function Loss: 1.97314

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.19817
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.05709

Collected Steps per Second: 8,825.62168
Overall Steps per Second: 7,816.83397

Timestep Collection Time: 5.66736
Timestep Consumption Time: 0.73139
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 6.39875

Cumulative Model Updates: 24,586
Cumulative Timesteps: 410,130,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 410130982...
Checkpoint 410130982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.31536
Policy Entropy: 1.07001
Value Function Loss: 1.97904

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 8,862.91451
Overall Steps per Second: 7,493.82472

Timestep Collection Time: 5.64194
Timestep Consumption Time: 1.03076
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.67269

Cumulative Model Updates: 24,589
Cumulative Timesteps: 410,180,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.62064
Policy Entropy: 1.07701
Value Function Loss: 1.95006

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.06192
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 8,846.31248
Overall Steps per Second: 7,729.13693

Timestep Collection Time: 5.65546
Timestep Consumption Time: 0.81745
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.47291

Cumulative Model Updates: 24,592
Cumulative Timesteps: 410,231,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 410231016...
Checkpoint 410231016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.00978
Policy Entropy: 1.08094
Value Function Loss: 1.93223

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 9,013.65263
Overall Steps per Second: 7,868.99873

Timestep Collection Time: 5.54980
Timestep Consumption Time: 0.80730
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 6.35710

Cumulative Model Updates: 24,595
Cumulative Timesteps: 410,281,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.91453
Policy Entropy: 1.07232
Value Function Loss: 1.93881

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.09764

Collected Steps per Second: 8,952.51126
Overall Steps per Second: 7,817.59418

Timestep Collection Time: 5.58793
Timestep Consumption Time: 0.81123
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.39916

Cumulative Model Updates: 24,598
Cumulative Timesteps: 410,331,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 410331066...
Checkpoint 410331066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.47952
Policy Entropy: 1.06614
Value Function Loss: 1.97811

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 8,985.96682
Overall Steps per Second: 7,794.14131

Timestep Collection Time: 5.56668
Timestep Consumption Time: 0.85122
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 6.41790

Cumulative Model Updates: 24,601
Cumulative Timesteps: 410,381,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.52759
Policy Entropy: 1.07821
Value Function Loss: 1.97358

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.16220
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.13389

Collected Steps per Second: 8,819.22762
Overall Steps per Second: 7,696.31032

Timestep Collection Time: 5.66966
Timestep Consumption Time: 0.82722
PPO Batch Consumption Time: 0.04135
Total Iteration Time: 6.49688

Cumulative Model Updates: 24,604
Cumulative Timesteps: 410,431,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 410431090...
Checkpoint 410431090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.64897
Policy Entropy: 1.08728
Value Function Loss: 1.94086

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 8,957.85155
Overall Steps per Second: 7,795.31798

Timestep Collection Time: 5.58192
Timestep Consumption Time: 0.83244
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.41436

Cumulative Model Updates: 24,607
Cumulative Timesteps: 410,481,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.38582
Policy Entropy: 1.07552
Value Function Loss: 1.87441

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.16899
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 8,837.52167
Overall Steps per Second: 7,759.23762

Timestep Collection Time: 5.65905
Timestep Consumption Time: 0.78643
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.44548

Cumulative Model Updates: 24,610
Cumulative Timesteps: 410,531,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 410531104...
Checkpoint 410531104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.31182
Policy Entropy: 1.07689
Value Function Loss: 1.90025

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.16253
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 8,774.65974
Overall Steps per Second: 7,622.62097

Timestep Collection Time: 5.69937
Timestep Consumption Time: 0.86137
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 6.56074

Cumulative Model Updates: 24,613
Cumulative Timesteps: 410,581,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.50195
Policy Entropy: 1.08812
Value Function Loss: 2.00667

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 8,873.97390
Overall Steps per Second: 7,732.86616

Timestep Collection Time: 5.63603
Timestep Consumption Time: 0.83169
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.46772

Cumulative Model Updates: 24,616
Cumulative Timesteps: 410,631,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 410631128...
Checkpoint 410631128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.74833
Policy Entropy: 1.09136
Value Function Loss: 2.03961

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 8,611.81544
Overall Steps per Second: 7,520.16415

Timestep Collection Time: 5.80760
Timestep Consumption Time: 0.84305
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.65065

Cumulative Model Updates: 24,619
Cumulative Timesteps: 410,681,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.76281
Policy Entropy: 1.05222
Value Function Loss: 1.99015

Mean KL Divergence: 0.05774
SB3 Clip Fraction: 0.23706
Policy Update Magnitude: 0.07181
Value Function Update Magnitude: 0.10211

Collected Steps per Second: 8,893.75537
Overall Steps per Second: 7,739.86681

Timestep Collection Time: 5.62305
Timestep Consumption Time: 0.83831
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 6.46135

Cumulative Model Updates: 24,622
Cumulative Timesteps: 410,731,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 410731152...
Checkpoint 410731152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.80099
Policy Entropy: 1.08326
Value Function Loss: 1.91885

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.20000
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 8,925.39258
Overall Steps per Second: 7,844.27491

Timestep Collection Time: 5.60401
Timestep Consumption Time: 0.77236
PPO Batch Consumption Time: 0.04785
Total Iteration Time: 6.37637

Cumulative Model Updates: 24,625
Cumulative Timesteps: 410,781,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.10586
Policy Entropy: 1.04957
Value Function Loss: 1.84589

Mean KL Divergence: 0.04439
SB3 Clip Fraction: 0.24405
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 8,863.43288
Overall Steps per Second: 7,658.82055

Timestep Collection Time: 5.64386
Timestep Consumption Time: 0.88769
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 6.53155

Cumulative Model Updates: 24,628
Cumulative Timesteps: 410,831,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 410831194...
Checkpoint 410831194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.73111
Policy Entropy: 1.07121
Value Function Loss: 1.73443

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.07768

Collected Steps per Second: 8,668.84200
Overall Steps per Second: 7,487.20133

Timestep Collection Time: 5.76871
Timestep Consumption Time: 0.91043
PPO Batch Consumption Time: 0.04843
Total Iteration Time: 6.67913

Cumulative Model Updates: 24,631
Cumulative Timesteps: 410,881,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.49324
Policy Entropy: 1.06123
Value Function Loss: 1.61387

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.19204
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.08498

Collected Steps per Second: 8,974.17249
Overall Steps per Second: 7,737.26813

Timestep Collection Time: 5.57355
Timestep Consumption Time: 0.89101
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.46456

Cumulative Model Updates: 24,634
Cumulative Timesteps: 410,931,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 410931220...
Checkpoint 410931220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.63805
Policy Entropy: 1.05632
Value Function Loss: 1.60690

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.09590

Collected Steps per Second: 8,940.34691
Overall Steps per Second: 7,720.50685

Timestep Collection Time: 5.59508
Timestep Consumption Time: 0.88402
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.47911

Cumulative Model Updates: 24,637
Cumulative Timesteps: 410,981,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.63864
Policy Entropy: 1.04959
Value Function Loss: 1.64576

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.09412

Collected Steps per Second: 8,787.87471
Overall Steps per Second: 7,677.36794

Timestep Collection Time: 5.69148
Timestep Consumption Time: 0.82325
PPO Batch Consumption Time: 0.05198
Total Iteration Time: 6.51473

Cumulative Model Updates: 24,640
Cumulative Timesteps: 411,031,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411031258...
Checkpoint 411031258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.07744
Policy Entropy: 1.05965
Value Function Loss: 1.79569

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15878
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.09478

Collected Steps per Second: 9,022.91473
Overall Steps per Second: 7,729.13168

Timestep Collection Time: 5.54189
Timestep Consumption Time: 0.92766
PPO Batch Consumption Time: 0.04842
Total Iteration Time: 6.46955

Cumulative Model Updates: 24,643
Cumulative Timesteps: 411,081,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.74736
Policy Entropy: 1.05646
Value Function Loss: 1.89566

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 8,671.47791
Overall Steps per Second: 7,594.59346

Timestep Collection Time: 5.76718
Timestep Consumption Time: 0.81776
PPO Batch Consumption Time: 0.04136
Total Iteration Time: 6.58495

Cumulative Model Updates: 24,646
Cumulative Timesteps: 411,131,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 411131272...
Checkpoint 411131272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.75510
Policy Entropy: 1.06005
Value Function Loss: 1.82371

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.08869

Collected Steps per Second: 9,279.65633
Overall Steps per Second: 7,955.47441

Timestep Collection Time: 5.39007
Timestep Consumption Time: 0.89717
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.28724

Cumulative Model Updates: 24,649
Cumulative Timesteps: 411,181,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.53865
Policy Entropy: 1.04694
Value Function Loss: 1.77570

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.21159
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 9,022.09064
Overall Steps per Second: 7,921.03223

Timestep Collection Time: 5.54240
Timestep Consumption Time: 0.77042
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.31281

Cumulative Model Updates: 24,652
Cumulative Timesteps: 411,231,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 411231294...
Checkpoint 411231294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.17143
Policy Entropy: 1.06410
Value Function Loss: 1.78256

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.06474

Collected Steps per Second: 8,967.27456
Overall Steps per Second: 7,772.67864

Timestep Collection Time: 5.57806
Timestep Consumption Time: 0.85730
PPO Batch Consumption Time: 0.04924
Total Iteration Time: 6.43536

Cumulative Model Updates: 24,655
Cumulative Timesteps: 411,281,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.48037
Policy Entropy: 1.05656
Value Function Loss: 1.77100

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 8,781.19040
Overall Steps per Second: 7,497.70918

Timestep Collection Time: 5.69695
Timestep Consumption Time: 0.97522
PPO Batch Consumption Time: 0.05270
Total Iteration Time: 6.67217

Cumulative Model Updates: 24,658
Cumulative Timesteps: 411,331,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 411331340...
Checkpoint 411331340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.82856
Policy Entropy: 1.05189
Value Function Loss: 1.78376

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 8,834.31341
Overall Steps per Second: 7,782.75090

Timestep Collection Time: 5.66201
Timestep Consumption Time: 0.76502
PPO Batch Consumption Time: 0.04939
Total Iteration Time: 6.42703

Cumulative Model Updates: 24,661
Cumulative Timesteps: 411,381,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.65153
Policy Entropy: 1.03641
Value Function Loss: 1.63539

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.21390
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.07500

Collected Steps per Second: 8,762.29431
Overall Steps per Second: 7,652.09741

Timestep Collection Time: 5.70787
Timestep Consumption Time: 0.82812
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.53599

Cumulative Model Updates: 24,664
Cumulative Timesteps: 411,431,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411431374...
Checkpoint 411431374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.61106
Policy Entropy: 1.05460
Value Function Loss: 1.71313

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.18373
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.08096

Collected Steps per Second: 8,842.78981
Overall Steps per Second: 7,704.48203

Timestep Collection Time: 5.65726
Timestep Consumption Time: 0.83584
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.49310

Cumulative Model Updates: 24,667
Cumulative Timesteps: 411,481,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.60838
Policy Entropy: 1.05943
Value Function Loss: 1.62393

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.18746
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 8,914.76472
Overall Steps per Second: 7,763.61194

Timestep Collection Time: 5.61069
Timestep Consumption Time: 0.83193
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.44262

Cumulative Model Updates: 24,670
Cumulative Timesteps: 411,531,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411531418...
Checkpoint 411531418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.16648
Policy Entropy: 1.04222
Value Function Loss: 1.71404

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 8,722.90119
Overall Steps per Second: 7,637.32785

Timestep Collection Time: 5.73295
Timestep Consumption Time: 0.81488
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.54784

Cumulative Model Updates: 24,673
Cumulative Timesteps: 411,581,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.96877
Policy Entropy: 1.04694
Value Function Loss: 1.71607

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 8,933.06600
Overall Steps per Second: 7,860.52631

Timestep Collection Time: 5.59763
Timestep Consumption Time: 0.76378
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.36141

Cumulative Model Updates: 24,676
Cumulative Timesteps: 411,631,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 411631430...
Checkpoint 411631430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.60627
Policy Entropy: 1.05329
Value Function Loss: 1.92756

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.07626

Collected Steps per Second: 8,955.36269
Overall Steps per Second: 7,712.43543

Timestep Collection Time: 5.58481
Timestep Consumption Time: 0.90004
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.48485

Cumulative Model Updates: 24,679
Cumulative Timesteps: 411,681,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.01217
Policy Entropy: 1.06753
Value Function Loss: 2.01381

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.10171

Collected Steps per Second: 8,776.00551
Overall Steps per Second: 7,652.53138

Timestep Collection Time: 5.69918
Timestep Consumption Time: 0.83670
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.53588

Cumulative Model Updates: 24,682
Cumulative Timesteps: 411,731,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411731460...
Checkpoint 411731460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.07984
Policy Entropy: 1.03758
Value Function Loss: 2.01620

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 8,741.66182
Overall Steps per Second: 7,597.49484

Timestep Collection Time: 5.72294
Timestep Consumption Time: 0.86186
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.58480

Cumulative Model Updates: 24,685
Cumulative Timesteps: 411,781,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.97313
Policy Entropy: 1.05568
Value Function Loss: 1.95923

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.18040
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.11089

Collected Steps per Second: 8,384.66995
Overall Steps per Second: 7,348.77936

Timestep Collection Time: 5.96446
Timestep Consumption Time: 0.84076
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 6.80521

Cumulative Model Updates: 24,688
Cumulative Timesteps: 411,831,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 411831498...
Checkpoint 411831498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.22533
Policy Entropy: 1.05132
Value Function Loss: 1.91069

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.18362
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.09259

Collected Steps per Second: 8,800.13144
Overall Steps per Second: 7,745.50249

Timestep Collection Time: 5.68332
Timestep Consumption Time: 0.77384
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.45717

Cumulative Model Updates: 24,691
Cumulative Timesteps: 411,881,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.33667
Policy Entropy: 1.03921
Value Function Loss: 1.75250

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.18315
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.08152

Collected Steps per Second: 8,852.43052
Overall Steps per Second: 7,656.60421

Timestep Collection Time: 5.65133
Timestep Consumption Time: 0.88264
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 6.53397

Cumulative Model Updates: 24,694
Cumulative Timesteps: 411,931,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 411931540...
Checkpoint 411931540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.17862
Policy Entropy: 1.03590
Value Function Loss: 1.57202

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.18390
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.07090

Collected Steps per Second: 8,539.96659
Overall Steps per Second: 7,489.84729

Timestep Collection Time: 5.85623
Timestep Consumption Time: 0.82108
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 6.67731

Cumulative Model Updates: 24,697
Cumulative Timesteps: 411,981,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.93550
Policy Entropy: 1.03223
Value Function Loss: 1.45939

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.16518
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.06864

Collected Steps per Second: 8,984.47041
Overall Steps per Second: 7,814.23457

Timestep Collection Time: 5.56538
Timestep Consumption Time: 0.83345
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.39884

Cumulative Model Updates: 24,700
Cumulative Timesteps: 412,031,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 412031554...
Checkpoint 412031554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.19110
Policy Entropy: 1.04101
Value Function Loss: 1.50759

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.18269
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.06835

Collected Steps per Second: 8,756.43129
Overall Steps per Second: 7,702.10096

Timestep Collection Time: 5.71169
Timestep Consumption Time: 0.78187
PPO Batch Consumption Time: 0.04015
Total Iteration Time: 6.49355

Cumulative Model Updates: 24,703
Cumulative Timesteps: 412,081,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.40163
Policy Entropy: 1.01985
Value Function Loss: 1.64457

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.07596

Collected Steps per Second: 8,718.20268
Overall Steps per Second: 7,694.02621

Timestep Collection Time: 5.73742
Timestep Consumption Time: 0.76373
PPO Batch Consumption Time: 0.04702
Total Iteration Time: 6.50115

Cumulative Model Updates: 24,706
Cumulative Timesteps: 412,131,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 412131588...
Checkpoint 412131588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.66835
Policy Entropy: 1.03859
Value Function Loss: 1.82702

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.20358
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 8,968.59330
Overall Steps per Second: 7,761.56083

Timestep Collection Time: 5.57657
Timestep Consumption Time: 0.86724
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.44381

Cumulative Model Updates: 24,709
Cumulative Timesteps: 412,181,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.30174
Policy Entropy: 1.04368
Value Function Loss: 1.74852

Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.21236
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 8,800.15134
Overall Steps per Second: 7,693.62807

Timestep Collection Time: 5.68513
Timestep Consumption Time: 0.81765
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.50278

Cumulative Model Updates: 24,712
Cumulative Timesteps: 412,231,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 412231632...
Checkpoint 412231632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.17516
Policy Entropy: 1.02482
Value Function Loss: 1.67722

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 8,657.41050
Overall Steps per Second: 7,524.35395

Timestep Collection Time: 5.77679
Timestep Consumption Time: 0.86990
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.64668

Cumulative Model Updates: 24,715
Cumulative Timesteps: 412,281,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.44109
Policy Entropy: 1.03438
Value Function Loss: 1.53526

Mean KL Divergence: 0.03424
SB3 Clip Fraction: 0.24093
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 8,761.94594
Overall Steps per Second: 7,567.04109

Timestep Collection Time: 5.70946
Timestep Consumption Time: 0.90158
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.61104

Cumulative Model Updates: 24,718
Cumulative Timesteps: 412,331,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 412331670...
Checkpoint 412331670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.48124
Policy Entropy: 1.03642
Value Function Loss: 1.63329

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.20265
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 8,618.69337
Overall Steps per Second: 7,584.60871

Timestep Collection Time: 5.80390
Timestep Consumption Time: 0.79130
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.59520

Cumulative Model Updates: 24,721
Cumulative Timesteps: 412,381,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.96927
Policy Entropy: 1.03276
Value Function Loss: 1.59393

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.17281
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 8,726.64519
Overall Steps per Second: 7,573.98842

Timestep Collection Time: 5.73164
Timestep Consumption Time: 0.87228
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.60392

Cumulative Model Updates: 24,724
Cumulative Timesteps: 412,431,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 412431710...
Checkpoint 412431710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.02940
Policy Entropy: 1.01210
Value Function Loss: 1.65461

Mean KL Divergence: 0.03826
SB3 Clip Fraction: 0.23965
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.06361

Collected Steps per Second: 8,703.04213
Overall Steps per Second: 7,547.46747

Timestep Collection Time: 5.74788
Timestep Consumption Time: 0.88004
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.62792

Cumulative Model Updates: 24,727
Cumulative Timesteps: 412,481,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.55606
Policy Entropy: 1.04630
Value Function Loss: 1.57469

Mean KL Divergence: 0.04073
SB3 Clip Fraction: 0.23080
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 8,828.97763
Overall Steps per Second: 7,686.37134

Timestep Collection Time: 5.66521
Timestep Consumption Time: 0.84215
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.50736

Cumulative Model Updates: 24,730
Cumulative Timesteps: 412,531,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 412531752...
Checkpoint 412531752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.33934
Policy Entropy: 1.01782
Value Function Loss: 1.51217

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.20769
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 8,791.99618
Overall Steps per Second: 7,686.13173

Timestep Collection Time: 5.68745
Timestep Consumption Time: 0.81830
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 6.50574

Cumulative Model Updates: 24,733
Cumulative Timesteps: 412,581,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.16204
Policy Entropy: 1.04656
Value Function Loss: 1.47664

Mean KL Divergence: 0.02782
SB3 Clip Fraction: 0.20113
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 8,868.83879
Overall Steps per Second: 7,814.70545

Timestep Collection Time: 5.63930
Timestep Consumption Time: 0.76069
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.39999

Cumulative Model Updates: 24,736
Cumulative Timesteps: 412,631,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 412631770...
Checkpoint 412631770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.84980
Policy Entropy: 1.03609
Value Function Loss: 1.51591

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.18700
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.06043

Collected Steps per Second: 8,737.63513
Overall Steps per Second: 7,565.34692

Timestep Collection Time: 5.72512
Timestep Consumption Time: 0.88714
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 6.61225

Cumulative Model Updates: 24,739
Cumulative Timesteps: 412,681,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.24301
Policy Entropy: 1.02507
Value Function Loss: 1.52614

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.17565
Policy Update Magnitude: 0.04342
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 8,636.95535
Overall Steps per Second: 7,522.62138

Timestep Collection Time: 5.79000
Timestep Consumption Time: 0.85768
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.64768

Cumulative Model Updates: 24,742
Cumulative Timesteps: 412,731,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 412731802...
Checkpoint 412731802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.42631
Policy Entropy: 1.01620
Value Function Loss: 1.58796

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.19974
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.06302

Collected Steps per Second: 8,875.98024
Overall Steps per Second: 7,670.36603

Timestep Collection Time: 5.63453
Timestep Consumption Time: 0.88563
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.52016

Cumulative Model Updates: 24,745
Cumulative Timesteps: 412,781,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.70433
Policy Entropy: 1.03239
Value Function Loss: 1.72395

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 8,758.72436
Overall Steps per Second: 7,590.17775

Timestep Collection Time: 5.71042
Timestep Consumption Time: 0.87915
PPO Batch Consumption Time: 0.05086
Total Iteration Time: 6.58957

Cumulative Model Updates: 24,748
Cumulative Timesteps: 412,831,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412831830...
Checkpoint 412831830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.12799
Policy Entropy: 1.04111
Value Function Loss: 1.84453

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 8,994.56172
Overall Steps per Second: 7,883.14461

Timestep Collection Time: 5.56069
Timestep Consumption Time: 0.78398
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.34468

Cumulative Model Updates: 24,751
Cumulative Timesteps: 412,881,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.38233
Policy Entropy: 1.01453
Value Function Loss: 1.84352

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.18208
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 9,253.08362
Overall Steps per Second: 7,920.01651

Timestep Collection Time: 5.40490
Timestep Consumption Time: 0.90973
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 6.31463

Cumulative Model Updates: 24,754
Cumulative Timesteps: 412,931,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 412931858...
Checkpoint 412931858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.62966
Policy Entropy: 1.03948
Value Function Loss: 1.74597

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.18737
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 8,636.53106
Overall Steps per Second: 7,545.85333

Timestep Collection Time: 5.79075
Timestep Consumption Time: 0.83700
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.62775

Cumulative Model Updates: 24,757
Cumulative Timesteps: 412,981,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.39401
Policy Entropy: 1.02972
Value Function Loss: 1.67108

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.18223
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 8,863.65840
Overall Steps per Second: 7,707.03834

Timestep Collection Time: 5.64146
Timestep Consumption Time: 0.84663
PPO Batch Consumption Time: 0.03941
Total Iteration Time: 6.48810

Cumulative Model Updates: 24,760
Cumulative Timesteps: 413,031,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 413031874...
Checkpoint 413031874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.43185
Policy Entropy: 1.02875
Value Function Loss: 1.50334

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.05378

Collected Steps per Second: 8,955.16354
Overall Steps per Second: 7,692.72589

Timestep Collection Time: 5.58560
Timestep Consumption Time: 0.91664
PPO Batch Consumption Time: 0.04931
Total Iteration Time: 6.50225

Cumulative Model Updates: 24,763
Cumulative Timesteps: 413,081,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.35219
Policy Entropy: 1.01173
Value Function Loss: 1.56049

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.05052

Collected Steps per Second: 8,852.21969
Overall Steps per Second: 7,820.89045

Timestep Collection Time: 5.65079
Timestep Consumption Time: 0.74516
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.39595

Cumulative Model Updates: 24,766
Cumulative Timesteps: 413,131,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 413131916...
Checkpoint 413131916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.20454
Policy Entropy: 1.03132
Value Function Loss: 1.71000

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 8,548.09606
Overall Steps per Second: 7,475.45935

Timestep Collection Time: 5.85043
Timestep Consumption Time: 0.83946
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.68989

Cumulative Model Updates: 24,769
Cumulative Timesteps: 413,181,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.08148
Policy Entropy: 1.03548
Value Function Loss: 1.82743

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.07696

Collected Steps per Second: 8,897.02229
Overall Steps per Second: 7,701.34163

Timestep Collection Time: 5.62323
Timestep Consumption Time: 0.87304
PPO Batch Consumption Time: 0.05170
Total Iteration Time: 6.49627

Cumulative Model Updates: 24,772
Cumulative Timesteps: 413,231,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 413231956...
Checkpoint 413231956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.06892
Policy Entropy: 1.04401
Value Function Loss: 1.67835

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.18223
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.08197

Collected Steps per Second: 8,817.95892
Overall Steps per Second: 7,677.67330

Timestep Collection Time: 5.67206
Timestep Consumption Time: 0.84241
PPO Batch Consumption Time: 0.04413
Total Iteration Time: 6.51447

Cumulative Model Updates: 24,775
Cumulative Timesteps: 413,281,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.96411
Policy Entropy: 1.02898
Value Function Loss: 1.53375

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.18235
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 8,836.72887
Overall Steps per Second: 7,681.07012

Timestep Collection Time: 5.65865
Timestep Consumption Time: 0.85138
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 6.51003

Cumulative Model Updates: 24,778
Cumulative Timesteps: 413,331,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 413331976...
Checkpoint 413331976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.35132
Policy Entropy: 1.02127
Value Function Loss: 1.64730

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17749
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06191

Collected Steps per Second: 8,758.02269
Overall Steps per Second: 7,754.86165

Timestep Collection Time: 5.71088
Timestep Consumption Time: 0.73875
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.44963

Cumulative Model Updates: 24,781
Cumulative Timesteps: 413,381,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.89365
Policy Entropy: 1.03651
Value Function Loss: 1.80687

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.05552

Collected Steps per Second: 8,769.71160
Overall Steps per Second: 7,625.47273

Timestep Collection Time: 5.70395
Timestep Consumption Time: 0.85591
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 6.55986

Cumulative Model Updates: 24,784
Cumulative Timesteps: 413,432,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 413432014...
Checkpoint 413432014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.18673
Policy Entropy: 1.04490
Value Function Loss: 1.79889

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.04691

Collected Steps per Second: 8,810.46422
Overall Steps per Second: 7,740.53427

Timestep Collection Time: 5.67779
Timestep Consumption Time: 0.78481
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.46260

Cumulative Model Updates: 24,787
Cumulative Timesteps: 413,482,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.39172
Policy Entropy: 1.02939
Value Function Loss: 1.68610

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.04421

Collected Steps per Second: 9,076.74495
Overall Steps per Second: 7,836.27499

Timestep Collection Time: 5.51123
Timestep Consumption Time: 0.87242
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 6.38365

Cumulative Model Updates: 24,790
Cumulative Timesteps: 413,532,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 413532062...
Checkpoint 413532062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.19798
Policy Entropy: 1.01998
Value Function Loss: 1.60994

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.20576
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.06210

Collected Steps per Second: 8,880.70156
Overall Steps per Second: 7,711.29059

Timestep Collection Time: 5.63266
Timestep Consumption Time: 0.85419
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 6.48685

Cumulative Model Updates: 24,793
Cumulative Timesteps: 413,582,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.60085
Policy Entropy: 1.03553
Value Function Loss: 1.60974

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.08539

Collected Steps per Second: 8,406.54552
Overall Steps per Second: 7,432.84575

Timestep Collection Time: 5.95013
Timestep Consumption Time: 0.77946
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 6.72959

Cumulative Model Updates: 24,796
Cumulative Timesteps: 413,632,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 413632104...
Checkpoint 413632104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.41583
Policy Entropy: 1.04089
Value Function Loss: 1.65041

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.08310

Collected Steps per Second: 8,887.96111
Overall Steps per Second: 7,738.94180

Timestep Collection Time: 5.62874
Timestep Consumption Time: 0.83571
PPO Batch Consumption Time: 0.03971
Total Iteration Time: 6.46445

Cumulative Model Updates: 24,799
Cumulative Timesteps: 413,682,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.62990
Policy Entropy: 1.03018
Value Function Loss: 1.73915

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07431

Collected Steps per Second: 8,840.04695
Overall Steps per Second: 7,678.02700

Timestep Collection Time: 5.65789
Timestep Consumption Time: 0.85629
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 6.51417

Cumulative Model Updates: 24,802
Cumulative Timesteps: 413,732,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 413732148...
Checkpoint 413732148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.99749
Policy Entropy: 1.03853
Value Function Loss: 1.75400

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.17014
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.06233

Collected Steps per Second: 8,750.50934
Overall Steps per Second: 7,708.72699

Timestep Collection Time: 5.71670
Timestep Consumption Time: 0.77257
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 6.48927

Cumulative Model Updates: 24,805
Cumulative Timesteps: 413,782,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.77685
Policy Entropy: 1.04071
Value Function Loss: 1.75177

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 8,771.73870
Overall Steps per Second: 7,576.31659

Timestep Collection Time: 5.70035
Timestep Consumption Time: 0.89942
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.59978

Cumulative Model Updates: 24,808
Cumulative Timesteps: 413,832,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 413832174...
Checkpoint 413832174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.68569
Policy Entropy: 1.05907
Value Function Loss: 1.72362

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.20414
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.05876

Collected Steps per Second: 8,813.09356
Overall Steps per Second: 7,686.59713

Timestep Collection Time: 5.67701
Timestep Consumption Time: 0.83198
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 6.50899

Cumulative Model Updates: 24,811
Cumulative Timesteps: 413,882,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.47092
Policy Entropy: 1.00515
Value Function Loss: 1.69135

Mean KL Divergence: 0.10192
SB3 Clip Fraction: 0.34285
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 8,848.18191
Overall Steps per Second: 7,675.36818

Timestep Collection Time: 5.65156
Timestep Consumption Time: 0.86357
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 6.51513

Cumulative Model Updates: 24,814
Cumulative Timesteps: 413,932,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413932212...
Checkpoint 413932212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.40794
Policy Entropy: 1.03418
Value Function Loss: 1.53615

Mean KL Divergence: 0.05798
SB3 Clip Fraction: 0.26145
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.06595

Collected Steps per Second: 8,886.23656
Overall Steps per Second: 7,784.19715

Timestep Collection Time: 5.62960
Timestep Consumption Time: 0.79701
PPO Batch Consumption Time: 0.04179
Total Iteration Time: 6.42661

Cumulative Model Updates: 24,817
Cumulative Timesteps: 413,982,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.22824
Policy Entropy: 1.04467
Value Function Loss: 1.55927

Mean KL Divergence: 0.05995
SB3 Clip Fraction: 0.28123
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 8,814.44515
Overall Steps per Second: 7,758.22764

Timestep Collection Time: 5.67591
Timestep Consumption Time: 0.77273
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 6.44864

Cumulative Model Updates: 24,820
Cumulative Timesteps: 414,032,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 414032268...
Checkpoint 414032268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.09050
Policy Entropy: 1.05981
Value Function Loss: 1.67363

Mean KL Divergence: 0.05004
SB3 Clip Fraction: 0.21477
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.08445

Collected Steps per Second: 8,864.84059
Overall Steps per Second: 7,484.87714

Timestep Collection Time: 5.64139
Timestep Consumption Time: 1.04009
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.68147

Cumulative Model Updates: 24,823
Cumulative Timesteps: 414,082,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.29829
Policy Entropy: 1.05840
Value Function Loss: 1.73508

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.15015
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07881

Collected Steps per Second: 8,847.79884
Overall Steps per Second: 7,730.25387

Timestep Collection Time: 5.65135
Timestep Consumption Time: 0.81700
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.46835

Cumulative Model Updates: 24,826
Cumulative Timesteps: 414,132,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 414132280...
Checkpoint 414132280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.41976
Policy Entropy: 1.03825
Value Function Loss: 1.78044

Mean KL Divergence: 0.02899
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 9,078.07892
Overall Steps per Second: 7,869.35492

Timestep Collection Time: 5.50932
Timestep Consumption Time: 0.84622
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.35554

Cumulative Model Updates: 24,829
Cumulative Timesteps: 414,182,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.67517
Policy Entropy: 1.05843
Value Function Loss: 1.84869

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.16047
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 8,760.06776
Overall Steps per Second: 7,580.67458

Timestep Collection Time: 5.71023
Timestep Consumption Time: 0.88839
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.59862

Cumulative Model Updates: 24,832
Cumulative Timesteps: 414,232,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 414232316...
Checkpoint 414232316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.13161
Policy Entropy: 1.06092
Value Function Loss: 1.89972

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.07790

Collected Steps per Second: 8,762.76271
Overall Steps per Second: 7,678.44625

Timestep Collection Time: 5.70642
Timestep Consumption Time: 0.80584
PPO Batch Consumption Time: 0.04306
Total Iteration Time: 6.51225

Cumulative Model Updates: 24,835
Cumulative Timesteps: 414,282,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.74565
Policy Entropy: 1.05370
Value Function Loss: 1.81524

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.08194

Collected Steps per Second: 8,637.01782
Overall Steps per Second: 7,496.07756

Timestep Collection Time: 5.79251
Timestep Consumption Time: 0.88165
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.67416

Cumulative Model Updates: 24,838
Cumulative Timesteps: 414,332,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 414332350...
Checkpoint 414332350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.24365
Policy Entropy: 1.04353
Value Function Loss: 1.77278

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 8,406.49115
Overall Steps per Second: 7,285.85936

Timestep Collection Time: 5.95064
Timestep Consumption Time: 0.91526
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.86590

Cumulative Model Updates: 24,841
Cumulative Timesteps: 414,382,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.18441
Policy Entropy: 1.04525
Value Function Loss: 1.72235

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 9,063.01354
Overall Steps per Second: 7,724.25184

Timestep Collection Time: 5.51936
Timestep Consumption Time: 0.95661
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.47597

Cumulative Model Updates: 24,844
Cumulative Timesteps: 414,432,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 414432396...
Checkpoint 414432396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.10829
Policy Entropy: 1.06676
Value Function Loss: 1.86777

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 8,715.75326
Overall Steps per Second: 7,547.69817

Timestep Collection Time: 5.73835
Timestep Consumption Time: 0.88805
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.62639

Cumulative Model Updates: 24,847
Cumulative Timesteps: 414,482,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.74217
Policy Entropy: 1.08219
Value Function Loss: 1.80743

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 8,766.84756
Overall Steps per Second: 7,645.83235

Timestep Collection Time: 5.70422
Timestep Consumption Time: 0.83634
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 6.54056

Cumulative Model Updates: 24,850
Cumulative Timesteps: 414,532,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 414532418...
Checkpoint 414532418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.28179
Policy Entropy: 1.07174
Value Function Loss: 1.83595

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 8,543.58907
Overall Steps per Second: 7,427.64990

Timestep Collection Time: 5.85234
Timestep Consumption Time: 0.87926
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 6.73160

Cumulative Model Updates: 24,853
Cumulative Timesteps: 414,582,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.84426
Policy Entropy: 1.06637
Value Function Loss: 1.74405

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 8,888.03393
Overall Steps per Second: 7,697.90041

Timestep Collection Time: 5.62577
Timestep Consumption Time: 0.86977
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.49554

Cumulative Model Updates: 24,856
Cumulative Timesteps: 414,632,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 414632420...
Checkpoint 414632420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.69615
Policy Entropy: 1.07895
Value Function Loss: 1.82018

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 9,163.13541
Overall Steps per Second: 7,891.41188

Timestep Collection Time: 5.45927
Timestep Consumption Time: 0.87978
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.33904

Cumulative Model Updates: 24,859
Cumulative Timesteps: 414,682,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.92415
Policy Entropy: 1.08751
Value Function Loss: 1.83415

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.16178
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 9,003.13709
Overall Steps per Second: 7,765.68462

Timestep Collection Time: 5.55384
Timestep Consumption Time: 0.88500
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 6.43884

Cumulative Model Updates: 24,862
Cumulative Timesteps: 414,732,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 414732446...
Checkpoint 414732446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.10698
Policy Entropy: 1.05545
Value Function Loss: 1.78604

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.21693
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.10278

Collected Steps per Second: 8,876.94601
Overall Steps per Second: 7,839.80075

Timestep Collection Time: 5.63505
Timestep Consumption Time: 0.74547
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 6.38052

Cumulative Model Updates: 24,865
Cumulative Timesteps: 414,782,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.15134
Policy Entropy: 1.07417
Value Function Loss: 1.68426

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.10640

Collected Steps per Second: 9,498.85225
Overall Steps per Second: 8,136.05483

Timestep Collection Time: 5.26443
Timestep Consumption Time: 0.88180
PPO Batch Consumption Time: 0.04598
Total Iteration Time: 6.14622

Cumulative Model Updates: 24,868
Cumulative Timesteps: 414,832,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 414832474...
Checkpoint 414832474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.63605
Policy Entropy: 1.06891
Value Function Loss: 1.70526

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.10324

Collected Steps per Second: 8,966.00136
Overall Steps per Second: 7,798.97784

Timestep Collection Time: 5.57885
Timestep Consumption Time: 0.83481
PPO Batch Consumption Time: 0.03879
Total Iteration Time: 6.41366

Cumulative Model Updates: 24,871
Cumulative Timesteps: 414,882,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.92985
Policy Entropy: 1.06073
Value Function Loss: 1.73587

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.09442

Collected Steps per Second: 9,302.57883
Overall Steps per Second: 8,028.92055

Timestep Collection Time: 5.37765
Timestep Consumption Time: 0.85308
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.23073

Cumulative Model Updates: 24,874
Cumulative Timesteps: 414,932,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 414932520...
Checkpoint 414932520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.56968
Policy Entropy: 1.04037
Value Function Loss: 1.69086

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.21661
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.08366

Collected Steps per Second: 8,768.43868
Overall Steps per Second: 7,542.54320

Timestep Collection Time: 5.70341
Timestep Consumption Time: 0.92698
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 6.63039

Cumulative Model Updates: 24,877
Cumulative Timesteps: 414,982,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.61004
Policy Entropy: 1.06039
Value Function Loss: 1.63745

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.07703

Collected Steps per Second: 8,571.01839
Overall Steps per Second: 7,577.13903

Timestep Collection Time: 5.83361
Timestep Consumption Time: 0.76518
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.59880

Cumulative Model Updates: 24,880
Cumulative Timesteps: 415,032,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 415032530...
Checkpoint 415032530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.36089
Policy Entropy: 1.06178
Value Function Loss: 1.66655

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.06930

Collected Steps per Second: 8,969.68269
Overall Steps per Second: 7,727.11000

Timestep Collection Time: 5.57433
Timestep Consumption Time: 0.89639
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.47072

Cumulative Model Updates: 24,883
Cumulative Timesteps: 415,082,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.28643
Policy Entropy: 1.06094
Value Function Loss: 1.65459

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 8,901.56402
Overall Steps per Second: 7,762.30820

Timestep Collection Time: 5.61744
Timestep Consumption Time: 0.82446
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.44190

Cumulative Model Updates: 24,886
Cumulative Timesteps: 415,132,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 415132534...
Checkpoint 415132534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.64253
Policy Entropy: 1.03964
Value Function Loss: 1.70108

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 8,960.33482
Overall Steps per Second: 7,726.67746

Timestep Collection Time: 5.58305
Timestep Consumption Time: 0.89140
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.47445

Cumulative Model Updates: 24,889
Cumulative Timesteps: 415,182,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.75573
Policy Entropy: 1.04062
Value Function Loss: 1.61432

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 9,064.32918
Overall Steps per Second: 7,660.77347

Timestep Collection Time: 5.51613
Timestep Consumption Time: 1.01063
PPO Batch Consumption Time: 0.04896
Total Iteration Time: 6.52676

Cumulative Model Updates: 24,892
Cumulative Timesteps: 415,232,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 415232560...
Checkpoint 415232560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.85604
Policy Entropy: 1.04965
Value Function Loss: 1.71775

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 8,895.34964
Overall Steps per Second: 7,866.13624

Timestep Collection Time: 5.62136
Timestep Consumption Time: 0.73551
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.35687

Cumulative Model Updates: 24,895
Cumulative Timesteps: 415,282,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.24742
Policy Entropy: 1.05174
Value Function Loss: 1.67804

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.07520

Collected Steps per Second: 8,956.90532
Overall Steps per Second: 7,796.66011

Timestep Collection Time: 5.58229
Timestep Consumption Time: 0.83072
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.41300

Cumulative Model Updates: 24,898
Cumulative Timesteps: 415,332,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 415332564...
Checkpoint 415332564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.21688
Policy Entropy: 1.05955
Value Function Loss: 1.73545

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.06837

Collected Steps per Second: 8,972.73759
Overall Steps per Second: 7,833.68326

Timestep Collection Time: 5.57533
Timestep Consumption Time: 0.81068
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.38601

Cumulative Model Updates: 24,901
Cumulative Timesteps: 415,382,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.47588
Policy Entropy: 1.05904
Value Function Loss: 1.85742

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.06822

Collected Steps per Second: 9,102.97720
Overall Steps per Second: 7,846.37019

Timestep Collection Time: 5.49337
Timestep Consumption Time: 0.87977
PPO Batch Consumption Time: 0.04838
Total Iteration Time: 6.37314

Cumulative Model Updates: 24,904
Cumulative Timesteps: 415,432,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 415432596...
Checkpoint 415432596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.53219
Policy Entropy: 1.07165
Value Function Loss: 1.96090

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 8,420.41119
Overall Steps per Second: 7,327.99215

Timestep Collection Time: 5.94056
Timestep Consumption Time: 0.88559
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.82615

Cumulative Model Updates: 24,907
Cumulative Timesteps: 415,482,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.43311
Policy Entropy: 1.07486
Value Function Loss: 2.12289

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 9,114.48123
Overall Steps per Second: 8,057.98306

Timestep Collection Time: 5.48621
Timestep Consumption Time: 0.71931
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.20552

Cumulative Model Updates: 24,910
Cumulative Timesteps: 415,532,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 415532622...
Checkpoint 415532622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.49092
Policy Entropy: 1.07774
Value Function Loss: 2.17460

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 8,779.70571
Overall Steps per Second: 7,682.70045

Timestep Collection Time: 5.69518
Timestep Consumption Time: 0.81321
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 6.50839

Cumulative Model Updates: 24,913
Cumulative Timesteps: 415,582,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.15714
Policy Entropy: 1.07341
Value Function Loss: 2.25677

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.07949
Value Function Update Magnitude: 0.07763

Collected Steps per Second: 8,901.83729
Overall Steps per Second: 7,784.82827

Timestep Collection Time: 5.61772
Timestep Consumption Time: 0.80606
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 6.42378

Cumulative Model Updates: 24,916
Cumulative Timesteps: 415,632,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415632632...
Checkpoint 415632632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.10427
Policy Entropy: 1.07048
Value Function Loss: 2.03690

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 8,707.31199
Overall Steps per Second: 7,718.09775

Timestep Collection Time: 5.74437
Timestep Consumption Time: 0.73624
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.48061

Cumulative Model Updates: 24,919
Cumulative Timesteps: 415,682,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.13228
Policy Entropy: 1.07459
Value Function Loss: 1.99685

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.06648

Collected Steps per Second: 9,022.21709
Overall Steps per Second: 7,850.31078

Timestep Collection Time: 5.54520
Timestep Consumption Time: 0.82780
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.37300

Cumulative Model Updates: 24,922
Cumulative Timesteps: 415,732,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 415732680...
Checkpoint 415732680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.53178
Policy Entropy: 1.07164
Value Function Loss: 2.06337

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.06887

Collected Steps per Second: 8,933.73616
Overall Steps per Second: 7,896.92511

Timestep Collection Time: 5.59945
Timestep Consumption Time: 0.73517
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.33462

Cumulative Model Updates: 24,925
Cumulative Timesteps: 415,782,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.75067
Policy Entropy: 1.08576
Value Function Loss: 2.25729

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 9,147.76533
Overall Steps per Second: 7,897.24161

Timestep Collection Time: 5.46669
Timestep Consumption Time: 0.86565
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 6.33234

Cumulative Model Updates: 24,928
Cumulative Timesteps: 415,832,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415832712...
Checkpoint 415832712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.06287
Policy Entropy: 1.07364
Value Function Loss: 2.10632

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.06593
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 8,924.34705
Overall Steps per Second: 7,813.71513

Timestep Collection Time: 5.60332
Timestep Consumption Time: 0.79645
PPO Batch Consumption Time: 0.04930
Total Iteration Time: 6.39977

Cumulative Model Updates: 24,931
Cumulative Timesteps: 415,882,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.86517
Policy Entropy: 1.08897
Value Function Loss: 2.09997

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.08949

Collected Steps per Second: 8,447.62390
Overall Steps per Second: 7,267.16104

Timestep Collection Time: 5.92190
Timestep Consumption Time: 0.96194
PPO Batch Consumption Time: 0.04988
Total Iteration Time: 6.88384

Cumulative Model Updates: 24,934
Cumulative Timesteps: 415,932,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 415932744...
Checkpoint 415932744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.94209
Policy Entropy: 1.09513
Value Function Loss: 1.97011

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 8,769.44008
Overall Steps per Second: 7,606.47329

Timestep Collection Time: 5.70481
Timestep Consumption Time: 0.87222
PPO Batch Consumption Time: 0.05214
Total Iteration Time: 6.57703

Cumulative Model Updates: 24,937
Cumulative Timesteps: 415,982,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.98565
Policy Entropy: 1.09640
Value Function Loss: 1.97452

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.08316

Collected Steps per Second: 8,855.83102
Overall Steps per Second: 7,834.12126

Timestep Collection Time: 5.64758
Timestep Consumption Time: 0.73655
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.38412

Cumulative Model Updates: 24,940
Cumulative Timesteps: 416,032,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 416032786...
Checkpoint 416032786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.37249
Policy Entropy: 1.07160
Value Function Loss: 1.86732

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.22351
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 8,902.19790
Overall Steps per Second: 7,747.33807

Timestep Collection Time: 5.61771
Timestep Consumption Time: 0.83741
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.45512

Cumulative Model Updates: 24,943
Cumulative Timesteps: 416,082,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.78466
Policy Entropy: 1.08154
Value Function Loss: 1.85820

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 8,806.71774
Overall Steps per Second: 7,720.49732

Timestep Collection Time: 5.68044
Timestep Consumption Time: 0.79920
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 6.47963

Cumulative Model Updates: 24,946
Cumulative Timesteps: 416,132,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 416132822...
Checkpoint 416132822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.93475
Policy Entropy: 1.07069
Value Function Loss: 1.80442

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16613
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 8,710.29320
Overall Steps per Second: 7,545.79834

Timestep Collection Time: 5.74217
Timestep Consumption Time: 0.88615
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.62832

Cumulative Model Updates: 24,949
Cumulative Timesteps: 416,182,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.00174
Policy Entropy: 1.05319
Value Function Loss: 1.80847

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.18301
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 8,679.28667
Overall Steps per Second: 7,604.17433

Timestep Collection Time: 5.76361
Timestep Consumption Time: 0.81488
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.57849

Cumulative Model Updates: 24,952
Cumulative Timesteps: 416,232,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416232862...
Checkpoint 416232862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.72816
Policy Entropy: 1.07334
Value Function Loss: 1.81916

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.18931
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.06079

Collected Steps per Second: 9,016.53252
Overall Steps per Second: 7,810.12397

Timestep Collection Time: 5.54670
Timestep Consumption Time: 0.85678
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.40348

Cumulative Model Updates: 24,955
Cumulative Timesteps: 416,282,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.39219
Policy Entropy: 1.06577
Value Function Loss: 1.80907

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.20093
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 8,634.78703
Overall Steps per Second: 7,487.23086

Timestep Collection Time: 5.79192
Timestep Consumption Time: 0.88772
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 6.67964

Cumulative Model Updates: 24,958
Cumulative Timesteps: 416,332,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 416332886...
Checkpoint 416332886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.61310
Policy Entropy: 1.05643
Value Function Loss: 1.86686

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.16230
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 8,923.42940
Overall Steps per Second: 7,796.24260

Timestep Collection Time: 5.60368
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.41386

Cumulative Model Updates: 24,961
Cumulative Timesteps: 416,382,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.68487
Policy Entropy: 1.05867
Value Function Loss: 1.91382

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.07821

Collected Steps per Second: 8,437.55996
Overall Steps per Second: 7,366.51820

Timestep Collection Time: 5.92849
Timestep Consumption Time: 0.86196
PPO Batch Consumption Time: 0.04618
Total Iteration Time: 6.79045

Cumulative Model Updates: 24,964
Cumulative Timesteps: 416,432,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 416432912...
Checkpoint 416432912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.64083
Policy Entropy: 1.06417
Value Function Loss: 2.04888

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 8,781.78305
Overall Steps per Second: 7,634.33787

Timestep Collection Time: 5.69588
Timestep Consumption Time: 0.85609
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.55198

Cumulative Model Updates: 24,967
Cumulative Timesteps: 416,482,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.95801
Policy Entropy: 1.05935
Value Function Loss: 1.93755

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.18551
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.08772

Collected Steps per Second: 8,941.32490
Overall Steps per Second: 7,795.23138

Timestep Collection Time: 5.59470
Timestep Consumption Time: 0.82256
PPO Batch Consumption Time: 0.04795
Total Iteration Time: 6.41726

Cumulative Model Updates: 24,970
Cumulative Timesteps: 416,532,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416532956...
Checkpoint 416532956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.71050
Policy Entropy: 1.07797
Value Function Loss: 1.90051

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.09341

Collected Steps per Second: 9,010.23219
Overall Steps per Second: 7,767.76422

Timestep Collection Time: 5.55191
Timestep Consumption Time: 0.88804
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 6.43995

Cumulative Model Updates: 24,973
Cumulative Timesteps: 416,582,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.70967
Policy Entropy: 1.09095
Value Function Loss: 1.82219

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.07853

Collected Steps per Second: 8,833.87671
Overall Steps per Second: 7,787.57670

Timestep Collection Time: 5.66229
Timestep Consumption Time: 0.76076
PPO Batch Consumption Time: 0.04880
Total Iteration Time: 6.42305

Cumulative Model Updates: 24,976
Cumulative Timesteps: 416,633,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 416633000...
Checkpoint 416633000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.82115
Policy Entropy: 1.07217
Value Function Loss: 1.90116

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.15748
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.06895

Collected Steps per Second: 9,237.19873
Overall Steps per Second: 7,929.19075

Timestep Collection Time: 5.41528
Timestep Consumption Time: 0.89331
PPO Batch Consumption Time: 0.04930
Total Iteration Time: 6.30859

Cumulative Model Updates: 24,979
Cumulative Timesteps: 416,683,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.03610
Policy Entropy: 1.09071
Value Function Loss: 1.99235

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.18517
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.06594

Collected Steps per Second: 9,193.72965
Overall Steps per Second: 7,989.11531

Timestep Collection Time: 5.44088
Timestep Consumption Time: 0.82039
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 6.26127

Cumulative Model Updates: 24,982
Cumulative Timesteps: 416,733,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 416733044...
Checkpoint 416733044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.94768
Policy Entropy: 1.08168
Value Function Loss: 2.06180

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.16671
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.06828

Collected Steps per Second: 9,005.92521
Overall Steps per Second: 7,844.31909

Timestep Collection Time: 5.55212
Timestep Consumption Time: 0.82217
PPO Batch Consumption Time: 0.05135
Total Iteration Time: 6.37429

Cumulative Model Updates: 24,985
Cumulative Timesteps: 416,783,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.41531
Policy Entropy: 1.07694
Value Function Loss: 1.95308

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.07514

Collected Steps per Second: 8,963.90614
Overall Steps per Second: 7,787.97841

Timestep Collection Time: 5.58016
Timestep Consumption Time: 0.84256
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 6.42272

Cumulative Model Updates: 24,988
Cumulative Timesteps: 416,833,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 416833066...
Checkpoint 416833066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.41732
Policy Entropy: 1.06417
Value Function Loss: 1.82143

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.21194
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 8,429.20129
Overall Steps per Second: 7,426.02023

Timestep Collection Time: 5.93508
Timestep Consumption Time: 0.80177
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.73685

Cumulative Model Updates: 24,991
Cumulative Timesteps: 416,883,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.24391
Policy Entropy: 1.06637
Value Function Loss: 1.74592

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 8,957.40721
Overall Steps per Second: 7,725.63773

Timestep Collection Time: 5.58220
Timestep Consumption Time: 0.89002
PPO Batch Consumption Time: 0.04959
Total Iteration Time: 6.47222

Cumulative Model Updates: 24,994
Cumulative Timesteps: 416,933,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 416933096...
Checkpoint 416933096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.53711
Policy Entropy: 1.08343
Value Function Loss: 1.68505

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.15952
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 8,911.51860
Overall Steps per Second: 7,778.51135

Timestep Collection Time: 5.61229
Timestep Consumption Time: 0.81748
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.42977

Cumulative Model Updates: 24,997
Cumulative Timesteps: 416,983,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.04508
Policy Entropy: 1.05513
Value Function Loss: 1.77241

Mean KL Divergence: 0.03422
SB3 Clip Fraction: 0.20525
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 8,693.20450
Overall Steps per Second: 7,709.63602

Timestep Collection Time: 5.75346
Timestep Consumption Time: 0.73401
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.48747

Cumulative Model Updates: 25,000
Cumulative Timesteps: 417,033,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417033126...
Checkpoint 417033126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.22070
Policy Entropy: 1.07475
Value Function Loss: 1.70156

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.07618

Collected Steps per Second: 8,812.66563
Overall Steps per Second: 7,596.95758

Timestep Collection Time: 5.67547
Timestep Consumption Time: 0.90822
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.58369

Cumulative Model Updates: 25,003
Cumulative Timesteps: 417,083,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.97755
Policy Entropy: 1.07632
Value Function Loss: 1.72601

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 8,798.06255
Overall Steps per Second: 7,791.10214

Timestep Collection Time: 5.68512
Timestep Consumption Time: 0.73477
PPO Batch Consumption Time: 0.04454
Total Iteration Time: 6.41989

Cumulative Model Updates: 25,006
Cumulative Timesteps: 417,133,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417133160...
Checkpoint 417133160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.23062
Policy Entropy: 1.07267
Value Function Loss: 1.68708

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.06705

Collected Steps per Second: 8,735.20085
Overall Steps per Second: 7,642.78315

Timestep Collection Time: 5.72420
Timestep Consumption Time: 0.81819
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.54238

Cumulative Model Updates: 25,009
Cumulative Timesteps: 417,183,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.68065
Policy Entropy: 1.04817
Value Function Loss: 1.78333

Mean KL Divergence: 0.03354
SB3 Clip Fraction: 0.21693
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.06846

Collected Steps per Second: 8,740.52343
Overall Steps per Second: 7,639.38334

Timestep Collection Time: 5.72163
Timestep Consumption Time: 0.82471
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.54634

Cumulative Model Updates: 25,012
Cumulative Timesteps: 417,233,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 417233172...
Checkpoint 417233172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.05559
Policy Entropy: 1.07189
Value Function Loss: 1.76096

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.17919
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 9,034.31077
Overall Steps per Second: 7,837.30133

Timestep Collection Time: 5.53756
Timestep Consumption Time: 0.84576
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.38332

Cumulative Model Updates: 25,015
Cumulative Timesteps: 417,283,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.15438
Policy Entropy: 1.05747
Value Function Loss: 1.65301

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.07131

Collected Steps per Second: 8,665.34188
Overall Steps per Second: 7,586.00550

Timestep Collection Time: 5.77081
Timestep Consumption Time: 0.82107
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 6.59188

Cumulative Model Updates: 25,018
Cumulative Timesteps: 417,333,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 417333206...
Checkpoint 417333206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.26619
Policy Entropy: 1.04478
Value Function Loss: 1.58752

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.15246
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 8,841.67235
Overall Steps per Second: 7,729.30576

Timestep Collection Time: 5.65798
Timestep Consumption Time: 0.81427
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.47225

Cumulative Model Updates: 25,021
Cumulative Timesteps: 417,383,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.48155
Policy Entropy: 1.03245
Value Function Loss: 1.61634

Mean KL Divergence: 0.03380
SB3 Clip Fraction: 0.20110
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 8,721.94778
Overall Steps per Second: 7,603.11919

Timestep Collection Time: 5.73427
Timestep Consumption Time: 0.84382
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 6.57809

Cumulative Model Updates: 25,024
Cumulative Timesteps: 417,433,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 417433246...
Checkpoint 417433246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.82927
Policy Entropy: 1.04810
Value Function Loss: 1.70558

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 8,856.78443
Overall Steps per Second: 7,719.85978

Timestep Collection Time: 5.64765
Timestep Consumption Time: 0.83174
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 6.47939

Cumulative Model Updates: 25,027
Cumulative Timesteps: 417,483,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.46290
Policy Entropy: 1.05202
Value Function Loss: 1.68316

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 8,818.95865
Overall Steps per Second: 7,824.21497

Timestep Collection Time: 5.67006
Timestep Consumption Time: 0.72087
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.39093

Cumulative Model Updates: 25,030
Cumulative Timesteps: 417,533,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 417533270...
Checkpoint 417533270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.07115
Policy Entropy: 1.04849
Value Function Loss: 1.58655

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.06671
Value Function Update Magnitude: 0.09197

Collected Steps per Second: 8,817.36532
Overall Steps per Second: 7,659.58201

Timestep Collection Time: 5.67380
Timestep Consumption Time: 0.85762
PPO Batch Consumption Time: 0.04807
Total Iteration Time: 6.53143

Cumulative Model Updates: 25,033
Cumulative Timesteps: 417,583,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.51421
Policy Entropy: 1.05067
Value Function Loss: 1.62299

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.09243

Collected Steps per Second: 8,803.90407
Overall Steps per Second: 7,673.32684

Timestep Collection Time: 5.68248
Timestep Consumption Time: 0.83725
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.51973

Cumulative Model Updates: 25,036
Cumulative Timesteps: 417,633,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 417633326...
Checkpoint 417633326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.64086
Policy Entropy: 1.07420
Value Function Loss: 1.84538

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.18895
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 8,950.59170
Overall Steps per Second: 7,683.78787

Timestep Collection Time: 5.58868
Timestep Consumption Time: 0.92139
PPO Batch Consumption Time: 0.04711
Total Iteration Time: 6.51007

Cumulative Model Updates: 25,039
Cumulative Timesteps: 417,683,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.37973
Policy Entropy: 1.08411
Value Function Loss: 1.90907

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.09850

Collected Steps per Second: 8,708.51710
Overall Steps per Second: 7,602.43210

Timestep Collection Time: 5.74403
Timestep Consumption Time: 0.83570
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.57974

Cumulative Model Updates: 25,042
Cumulative Timesteps: 417,733,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 417733370...
Checkpoint 417733370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.74590
Policy Entropy: 1.06176
Value Function Loss: 1.77168

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.18225
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.09285

Collected Steps per Second: 8,323.54471
Overall Steps per Second: 7,401.93951

Timestep Collection Time: 6.00970
Timestep Consumption Time: 0.74826
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 6.75796

Cumulative Model Updates: 25,045
Cumulative Timesteps: 417,783,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.80573
Policy Entropy: 1.05486
Value Function Loss: 1.76797

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.18645
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 8,848.03523
Overall Steps per Second: 7,646.25106

Timestep Collection Time: 5.65346
Timestep Consumption Time: 0.88857
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.54203

Cumulative Model Updates: 25,048
Cumulative Timesteps: 417,833,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 417833414...
Checkpoint 417833414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.42372
Policy Entropy: 1.07243
Value Function Loss: 1.79876

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.09188

Collected Steps per Second: 8,735.60118
Overall Steps per Second: 7,592.93559

Timestep Collection Time: 5.72645
Timestep Consumption Time: 0.86178
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.58823

Cumulative Model Updates: 25,051
Cumulative Timesteps: 417,883,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.45074
Policy Entropy: 1.07764
Value Function Loss: 1.95729

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 9,080.33517
Overall Steps per Second: 7,901.37612

Timestep Collection Time: 5.50927
Timestep Consumption Time: 0.82203
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 6.33130

Cumulative Model Updates: 25,054
Cumulative Timesteps: 417,933,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 417933464...
Checkpoint 417933464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.83075
Policy Entropy: 1.06355
Value Function Loss: 1.81436

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.08099

Collected Steps per Second: 8,725.53506
Overall Steps per Second: 7,635.31839

Timestep Collection Time: 5.73375
Timestep Consumption Time: 0.81870
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 6.55244

Cumulative Model Updates: 25,057
Cumulative Timesteps: 417,983,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.66667
Policy Entropy: 1.04082
Value Function Loss: 1.93541

Mean KL Divergence: 0.04046
SB3 Clip Fraction: 0.21089
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 8,788.73925
Overall Steps per Second: 7,722.43048

Timestep Collection Time: 5.69115
Timestep Consumption Time: 0.78583
PPO Batch Consumption Time: 0.04707
Total Iteration Time: 6.47698

Cumulative Model Updates: 25,060
Cumulative Timesteps: 418,033,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 418033512...
Checkpoint 418033512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.34782
Policy Entropy: 1.08195
Value Function Loss: 1.93822

Mean KL Divergence: 0.03631
SB3 Clip Fraction: 0.20501
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 8,592.12467
Overall Steps per Second: 7,450.92595

Timestep Collection Time: 5.82184
Timestep Consumption Time: 0.89169
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.71353

Cumulative Model Updates: 25,063
Cumulative Timesteps: 418,083,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.56857
Policy Entropy: 1.05510
Value Function Loss: 1.88721

Mean KL Divergence: 0.03983
SB3 Clip Fraction: 0.22151
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.09761

Collected Steps per Second: 8,950.35664
Overall Steps per Second: 7,786.49194

Timestep Collection Time: 5.58771
Timestep Consumption Time: 0.83521
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.42292

Cumulative Model Updates: 25,066
Cumulative Timesteps: 418,133,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 418133546...
Checkpoint 418133546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.62663
Policy Entropy: 1.08126
Value Function Loss: 1.92491

Mean KL Divergence: 0.02789
SB3 Clip Fraction: 0.17644
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.11429

Collected Steps per Second: 8,706.28173
Overall Steps per Second: 7,640.22918

Timestep Collection Time: 5.74551
Timestep Consumption Time: 0.80168
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 6.54719

Cumulative Model Updates: 25,069
Cumulative Timesteps: 418,183,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.80049
Policy Entropy: 1.07661
Value Function Loss: 1.94805

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 8,652.99458
Overall Steps per Second: 7,450.39398

Timestep Collection Time: 5.78112
Timestep Consumption Time: 0.93316
PPO Batch Consumption Time: 0.04740
Total Iteration Time: 6.71428

Cumulative Model Updates: 25,072
Cumulative Timesteps: 418,233,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 418233592...
Checkpoint 418233592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.23415
Policy Entropy: 1.08175
Value Function Loss: 2.01872

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 8,716.45814
Overall Steps per Second: 7,562.07259

Timestep Collection Time: 5.73765
Timestep Consumption Time: 0.87588
PPO Batch Consumption Time: 0.05050
Total Iteration Time: 6.61353

Cumulative Model Updates: 25,075
Cumulative Timesteps: 418,283,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.14537
Policy Entropy: 1.07159
Value Function Loss: 2.02752

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 8,836.88624
Overall Steps per Second: 7,663.09447

Timestep Collection Time: 5.66014
Timestep Consumption Time: 0.86699
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.52713

Cumulative Model Updates: 25,078
Cumulative Timesteps: 418,333,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 418333622...
Checkpoint 418333622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.30486
Policy Entropy: 1.08682
Value Function Loss: 2.02327

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.11009

Collected Steps per Second: 8,866.25774
Overall Steps per Second: 7,715.54512

Timestep Collection Time: 5.64049
Timestep Consumption Time: 0.84123
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.48172

Cumulative Model Updates: 25,081
Cumulative Timesteps: 418,383,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.37920
Policy Entropy: 1.08325
Value Function Loss: 2.17319

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 9,176.79783
Overall Steps per Second: 8,014.49755

Timestep Collection Time: 5.45092
Timestep Consumption Time: 0.79052
PPO Batch Consumption Time: 0.04960
Total Iteration Time: 6.24144

Cumulative Model Updates: 25,084
Cumulative Timesteps: 418,433,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418433654...
Checkpoint 418433654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.56043
Policy Entropy: 1.07773
Value Function Loss: 2.07957

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.08647

Collected Steps per Second: 8,649.34092
Overall Steps per Second: 7,512.31584

Timestep Collection Time: 5.78310
Timestep Consumption Time: 0.87530
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.65840

Cumulative Model Updates: 25,087
Cumulative Timesteps: 418,483,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.75197
Policy Entropy: 1.06803
Value Function Loss: 2.03132

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 9,029.64516
Overall Steps per Second: 7,744.44706

Timestep Collection Time: 5.53887
Timestep Consumption Time: 0.91918
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 6.45805

Cumulative Model Updates: 25,090
Cumulative Timesteps: 418,533,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 418533688...
Checkpoint 418533688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.43543
Policy Entropy: 1.09252
Value Function Loss: 2.01161

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.17355
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.09113

Collected Steps per Second: 9,210.50996
Overall Steps per Second: 7,911.07609

Timestep Collection Time: 5.43075
Timestep Consumption Time: 0.89203
PPO Batch Consumption Time: 0.05203
Total Iteration Time: 6.32278

Cumulative Model Updates: 25,093
Cumulative Timesteps: 418,583,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.87652
Policy Entropy: 1.09590
Value Function Loss: 2.01594

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.09942

Collected Steps per Second: 8,828.56863
Overall Steps per Second: 7,686.68713

Timestep Collection Time: 5.66456
Timestep Consumption Time: 0.84149
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.50605

Cumulative Model Updates: 25,096
Cumulative Timesteps: 418,633,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 418633718...
Checkpoint 418633718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.13942
Policy Entropy: 1.08643
Value Function Loss: 1.97945

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.15692
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.09900

Collected Steps per Second: 8,871.07390
Overall Steps per Second: 7,674.25250

Timestep Collection Time: 5.63765
Timestep Consumption Time: 0.87921
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.51686

Cumulative Model Updates: 25,099
Cumulative Timesteps: 418,683,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.90524
Policy Entropy: 1.08245
Value Function Loss: 1.93083

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.17975
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.09060

Collected Steps per Second: 8,817.64215
Overall Steps per Second: 7,650.78396

Timestep Collection Time: 5.67272
Timestep Consumption Time: 0.86517
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.53789

Cumulative Model Updates: 25,102
Cumulative Timesteps: 418,733,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 418733750...
Checkpoint 418733750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.94693
Policy Entropy: 1.09350
Value Function Loss: 1.92939

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.08296

Collected Steps per Second: 8,722.87397
Overall Steps per Second: 7,708.44455

Timestep Collection Time: 5.73412
Timestep Consumption Time: 0.75461
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 6.48873

Cumulative Model Updates: 25,105
Cumulative Timesteps: 418,783,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.59425
Policy Entropy: 1.10238
Value Function Loss: 1.97057

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 8,801.39924
Overall Steps per Second: 7,617.68538

Timestep Collection Time: 5.68410
Timestep Consumption Time: 0.88325
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.56735

Cumulative Model Updates: 25,108
Cumulative Timesteps: 418,833,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 418833796...
Checkpoint 418833796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.44233
Policy Entropy: 1.03699
Value Function Loss: 1.93635

Mean KL Divergence: 0.12464
SB3 Clip Fraction: 0.35647
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.07552

Collected Steps per Second: 8,836.03339
Overall Steps per Second: 7,677.22891

Timestep Collection Time: 5.65865
Timestep Consumption Time: 0.85412
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.51277

Cumulative Model Updates: 25,111
Cumulative Timesteps: 418,883,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.24814
Policy Entropy: 1.05728
Value Function Loss: 1.92048

Mean KL Divergence: 0.06000
SB3 Clip Fraction: 0.28465
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.07190

Collected Steps per Second: 8,384.18803
Overall Steps per Second: 7,472.90545

Timestep Collection Time: 5.96408
Timestep Consumption Time: 0.72729
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 6.69137

Cumulative Model Updates: 25,114
Cumulative Timesteps: 418,933,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 418933800...
Checkpoint 418933800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.09897
Policy Entropy: 1.05406
Value Function Loss: 1.87187

Mean KL Divergence: 0.05031
SB3 Clip Fraction: 0.29627
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 8,850.67674
Overall Steps per Second: 7,670.67866

Timestep Collection Time: 5.64951
Timestep Consumption Time: 0.86908
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 6.51859

Cumulative Model Updates: 25,117
Cumulative Timesteps: 418,983,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.69447
Policy Entropy: 1.06195
Value Function Loss: 1.85976

Mean KL Divergence: 0.03627
SB3 Clip Fraction: 0.22755
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.10353

Collected Steps per Second: 8,969.08477
Overall Steps per Second: 7,820.58873

Timestep Collection Time: 5.57493
Timestep Consumption Time: 0.81871
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.39364

Cumulative Model Updates: 25,120
Cumulative Timesteps: 419,033,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 419033804...
Checkpoint 419033804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.48422
Policy Entropy: 1.06839
Value Function Loss: 1.93733

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17823
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.09149

Collected Steps per Second: 8,863.54988
Overall Steps per Second: 7,710.76933

Timestep Collection Time: 5.64379
Timestep Consumption Time: 0.84376
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.48755

Cumulative Model Updates: 25,123
Cumulative Timesteps: 419,083,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.32853
Policy Entropy: 1.05124
Value Function Loss: 1.99769

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.08047

Collected Steps per Second: 9,007.10076
Overall Steps per Second: 7,786.56844

Timestep Collection Time: 5.55295
Timestep Consumption Time: 0.87042
PPO Batch Consumption Time: 0.04994
Total Iteration Time: 6.42337

Cumulative Model Updates: 25,126
Cumulative Timesteps: 419,133,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419133844...
Checkpoint 419133844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.38306
Policy Entropy: 1.04511
Value Function Loss: 1.92490

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.17979
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 8,157.31094
Overall Steps per Second: 7,214.13944

Timestep Collection Time: 6.12947
Timestep Consumption Time: 0.80136
PPO Batch Consumption Time: 0.04845
Total Iteration Time: 6.93083

Cumulative Model Updates: 25,129
Cumulative Timesteps: 419,183,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.54399
Policy Entropy: 1.05782
Value Function Loss: 1.80473

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.07891

Collected Steps per Second: 8,793.09049
Overall Steps per Second: 7,619.19190

Timestep Collection Time: 5.68765
Timestep Consumption Time: 0.87630
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 6.56395

Cumulative Model Updates: 25,132
Cumulative Timesteps: 419,233,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 419233856...
Checkpoint 419233856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.42572
Policy Entropy: 1.05694
Value Function Loss: 1.76849

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 8,774.05315
Overall Steps per Second: 7,683.00503

Timestep Collection Time: 5.70067
Timestep Consumption Time: 0.80954
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.51021

Cumulative Model Updates: 25,135
Cumulative Timesteps: 419,283,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.82046
Policy Entropy: 1.06277
Value Function Loss: 1.81427

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.07453

Collected Steps per Second: 9,010.56983
Overall Steps per Second: 7,981.76770

Timestep Collection Time: 5.55148
Timestep Consumption Time: 0.71555
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.26703

Cumulative Model Updates: 25,138
Cumulative Timesteps: 419,333,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 419333896...
Checkpoint 419333896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.14361
Policy Entropy: 1.02942
Value Function Loss: 1.86886

Mean KL Divergence: 0.03391
SB3 Clip Fraction: 0.25839
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07082

Collected Steps per Second: 8,731.18201
Overall Steps per Second: 7,584.51773

Timestep Collection Time: 5.72981
Timestep Consumption Time: 0.86626
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.59607

Cumulative Model Updates: 25,141
Cumulative Timesteps: 419,383,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.85566
Policy Entropy: 1.04425
Value Function Loss: 1.78444

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.07151

Collected Steps per Second: 8,891.10329
Overall Steps per Second: 7,826.08259

Timestep Collection Time: 5.62540
Timestep Consumption Time: 0.76554
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 6.39094

Cumulative Model Updates: 25,144
Cumulative Timesteps: 419,433,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419433940...
Checkpoint 419433940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.04631
Policy Entropy: 1.03335
Value Function Loss: 1.79270

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 8,834.05845
Overall Steps per Second: 7,595.28362

Timestep Collection Time: 5.66263
Timestep Consumption Time: 0.92356
PPO Batch Consumption Time: 0.05799
Total Iteration Time: 6.58619

Cumulative Model Updates: 25,147
Cumulative Timesteps: 419,483,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.98325
Policy Entropy: 1.02835
Value Function Loss: 1.78800

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.07838

Collected Steps per Second: 8,910.92256
Overall Steps per Second: 7,724.89143

Timestep Collection Time: 5.61266
Timestep Consumption Time: 0.86173
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.47440

Cumulative Model Updates: 25,150
Cumulative Timesteps: 419,533,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 419533978...
Checkpoint 419533978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.84414
Policy Entropy: 1.02757
Value Function Loss: 1.78400

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.18187
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.08191

Collected Steps per Second: 8,888.14846
Overall Steps per Second: 7,747.27822

Timestep Collection Time: 5.62794
Timestep Consumption Time: 0.82878
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 6.45672

Cumulative Model Updates: 25,153
Cumulative Timesteps: 419,584,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.77859
Policy Entropy: 1.03423
Value Function Loss: 1.79529

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 8,621.30784
Overall Steps per Second: 7,508.33249

Timestep Collection Time: 5.79982
Timestep Consumption Time: 0.85972
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.65953

Cumulative Model Updates: 25,156
Cumulative Timesteps: 419,634,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 419634002...
Checkpoint 419634002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.38810
Policy Entropy: 1.03325
Value Function Loss: 1.85295

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 8,837.98083
Overall Steps per Second: 7,784.86912

Timestep Collection Time: 5.65853
Timestep Consumption Time: 0.76547
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 6.42400

Cumulative Model Updates: 25,159
Cumulative Timesteps: 419,684,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.66408
Policy Entropy: 1.02451
Value Function Loss: 1.89725

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 8,888.52595
Overall Steps per Second: 7,728.83145

Timestep Collection Time: 5.62815
Timestep Consumption Time: 0.84449
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.47265

Cumulative Model Updates: 25,162
Cumulative Timesteps: 419,734,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 419734038...
Checkpoint 419734038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.18416
Policy Entropy: 1.02521
Value Function Loss: 1.72021

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 8,754.03335
Overall Steps per Second: 7,680.17675

Timestep Collection Time: 5.71302
Timestep Consumption Time: 0.79881
PPO Batch Consumption Time: 0.04348
Total Iteration Time: 6.51183

Cumulative Model Updates: 25,165
Cumulative Timesteps: 419,784,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.43979
Policy Entropy: 1.02677
Value Function Loss: 1.66048

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.10946

Collected Steps per Second: 8,625.97868
Overall Steps per Second: 7,514.67413

Timestep Collection Time: 5.79714
Timestep Consumption Time: 0.85731
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.65445

Cumulative Model Updates: 25,168
Cumulative Timesteps: 419,834,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 419834056...
Checkpoint 419834056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.94084
Policy Entropy: 1.02737
Value Function Loss: 1.68194

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.09984

Collected Steps per Second: 8,968.66472
Overall Steps per Second: 7,741.50261

Timestep Collection Time: 5.57563
Timestep Consumption Time: 0.88383
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.45947

Cumulative Model Updates: 25,171
Cumulative Timesteps: 419,884,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.47207
Policy Entropy: 1.03691
Value Function Loss: 1.88491

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.08369

Collected Steps per Second: 8,808.26015
Overall Steps per Second: 7,692.14065

Timestep Collection Time: 5.67831
Timestep Consumption Time: 0.82391
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.50222

Cumulative Model Updates: 25,174
Cumulative Timesteps: 419,934,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419934078...
Checkpoint 419934078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.47705
Policy Entropy: 1.04159
Value Function Loss: 1.99831

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 9,044.82234
Overall Steps per Second: 7,779.33098

Timestep Collection Time: 5.52847
Timestep Consumption Time: 0.89934
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.42780

Cumulative Model Updates: 25,177
Cumulative Timesteps: 419,984,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.49306
Policy Entropy: 1.02967
Value Function Loss: 2.05841

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.16947
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 8,952.59187
Overall Steps per Second: 7,732.28841

Timestep Collection Time: 5.58587
Timestep Consumption Time: 0.88156
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.46743

Cumulative Model Updates: 25,180
Cumulative Timesteps: 420,034,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 420034090...
Checkpoint 420034090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.96751
Policy Entropy: 1.05146
Value Function Loss: 2.06289

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.18467
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 8,447.17891
Overall Steps per Second: 7,467.56027

Timestep Collection Time: 5.92056
Timestep Consumption Time: 0.77668
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 6.69723

Cumulative Model Updates: 25,183
Cumulative Timesteps: 420,084,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.99535
Policy Entropy: 1.05450
Value Function Loss: 1.99147

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 8,701.90362
Overall Steps per Second: 7,532.10503

Timestep Collection Time: 5.74587
Timestep Consumption Time: 0.89238
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.63825

Cumulative Model Updates: 25,186
Cumulative Timesteps: 420,134,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 420134102...
Checkpoint 420134102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.99410
Policy Entropy: 1.03662
Value Function Loss: 2.00958

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.19315
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 8,727.14964
Overall Steps per Second: 7,657.47155

Timestep Collection Time: 5.73131
Timestep Consumption Time: 0.80061
PPO Batch Consumption Time: 0.04696
Total Iteration Time: 6.53192

Cumulative Model Updates: 25,189
Cumulative Timesteps: 420,184,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.32297
Policy Entropy: 1.03751
Value Function Loss: 2.00679

Mean KL Divergence: 0.03984
SB3 Clip Fraction: 0.24191
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 9,077.47839
Overall Steps per Second: 7,872.64548

Timestep Collection Time: 5.50990
Timestep Consumption Time: 0.84324
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.35314

Cumulative Model Updates: 25,192
Cumulative Timesteps: 420,234,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 420234136...
Checkpoint 420234136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.01601
Policy Entropy: 1.05602
Value Function Loss: 1.94395

Mean KL Divergence: 0.03649
SB3 Clip Fraction: 0.22460
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.08303

Collected Steps per Second: 9,263.65242
Overall Steps per Second: 7,920.66440

Timestep Collection Time: 5.39960
Timestep Consumption Time: 0.91553
PPO Batch Consumption Time: 0.05217
Total Iteration Time: 6.31513

Cumulative Model Updates: 25,195
Cumulative Timesteps: 420,284,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.22180
Policy Entropy: 1.03837
Value Function Loss: 1.93775

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.21589
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.08856

Collected Steps per Second: 8,567.90627
Overall Steps per Second: 7,579.30900

Timestep Collection Time: 5.83620
Timestep Consumption Time: 0.76124
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.59744

Cumulative Model Updates: 25,198
Cumulative Timesteps: 420,334,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 420334160...
Checkpoint 420334160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.51792
Policy Entropy: 1.05732
Value Function Loss: 1.93673

Mean KL Divergence: 0.03008
SB3 Clip Fraction: 0.19962
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.09283

Collected Steps per Second: 9,069.63795
Overall Steps per Second: 7,835.10613

Timestep Collection Time: 5.51400
Timestep Consumption Time: 0.86881
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 6.38281

Cumulative Model Updates: 25,201
Cumulative Timesteps: 420,384,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.25325
Policy Entropy: 1.05661
Value Function Loss: 2.03812

Mean KL Divergence: 0.02978
SB3 Clip Fraction: 0.21592
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.09219

Collected Steps per Second: 9,010.56752
Overall Steps per Second: 7,787.82974

Timestep Collection Time: 5.55104
Timestep Consumption Time: 0.87155
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.42259

Cumulative Model Updates: 25,204
Cumulative Timesteps: 420,434,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 420434188...
Checkpoint 420434188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.67764
Policy Entropy: 1.04806
Value Function Loss: 1.96864

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.17596
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.09675

Collected Steps per Second: 8,988.67553
Overall Steps per Second: 7,797.54893

Timestep Collection Time: 5.56500
Timestep Consumption Time: 0.85009
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.41509

Cumulative Model Updates: 25,207
Cumulative Timesteps: 420,484,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.87172
Policy Entropy: 1.05196
Value Function Loss: 1.86925

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 8,582.40494
Overall Steps per Second: 7,501.25742

Timestep Collection Time: 5.82750
Timestep Consumption Time: 0.83991
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.66742

Cumulative Model Updates: 25,210
Cumulative Timesteps: 420,534,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 420534224...
Checkpoint 420534224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.54625
Policy Entropy: 1.07276
Value Function Loss: 1.86593

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 8,697.44534
Overall Steps per Second: 7,618.02019

Timestep Collection Time: 5.75226
Timestep Consumption Time: 0.81506
PPO Batch Consumption Time: 0.05029
Total Iteration Time: 6.56732

Cumulative Model Updates: 25,213
Cumulative Timesteps: 420,584,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.98737
Policy Entropy: 1.05836
Value Function Loss: 1.94639

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17943
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.08763

Collected Steps per Second: 8,867.93102
Overall Steps per Second: 7,695.49663

Timestep Collection Time: 5.64010
Timestep Consumption Time: 0.85929
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 6.49939

Cumulative Model Updates: 25,216
Cumulative Timesteps: 420,634,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 420634270...
Checkpoint 420634270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.41704
Policy Entropy: 1.05065
Value Function Loss: 2.07063

Mean KL Divergence: 0.03728
SB3 Clip Fraction: 0.21095
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 8,816.49859
Overall Steps per Second: 7,696.17273

Timestep Collection Time: 5.67255
Timestep Consumption Time: 0.82575
PPO Batch Consumption Time: 0.04697
Total Iteration Time: 6.49829

Cumulative Model Updates: 25,219
Cumulative Timesteps: 420,684,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.83635
Policy Entropy: 1.06444
Value Function Loss: 2.02207

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.17491
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 9,105.81504
Overall Steps per Second: 7,873.28454

Timestep Collection Time: 5.49341
Timestep Consumption Time: 0.85997
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 6.35338

Cumulative Model Updates: 25,222
Cumulative Timesteps: 420,734,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 420734304...
Checkpoint 420734304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.78939
Policy Entropy: 1.07162
Value Function Loss: 2.06029

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.07898

Collected Steps per Second: 8,532.38711
Overall Steps per Second: 7,447.84931

Timestep Collection Time: 5.86260
Timestep Consumption Time: 0.85370
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.71630

Cumulative Model Updates: 25,225
Cumulative Timesteps: 420,784,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.36295
Policy Entropy: 1.07110
Value Function Loss: 1.99903

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.07430

Collected Steps per Second: 8,506.18258
Overall Steps per Second: 7,541.18594

Timestep Collection Time: 5.88066
Timestep Consumption Time: 0.75251
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 6.63317

Cumulative Model Updates: 25,228
Cumulative Timesteps: 420,834,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 420834348...
Checkpoint 420834348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.59634
Policy Entropy: 1.06334
Value Function Loss: 2.02871

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.07599
Value Function Update Magnitude: 0.07499

Collected Steps per Second: 8,937.98577
Overall Steps per Second: 7,743.46871

Timestep Collection Time: 5.59500
Timestep Consumption Time: 0.86309
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.45809

Cumulative Model Updates: 25,231
Cumulative Timesteps: 420,884,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.61256
Policy Entropy: 1.06648
Value Function Loss: 2.07821

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 8,644.24097
Overall Steps per Second: 7,552.77157

Timestep Collection Time: 5.78744
Timestep Consumption Time: 0.83636
PPO Batch Consumption Time: 0.04137
Total Iteration Time: 6.62379

Cumulative Model Updates: 25,234
Cumulative Timesteps: 420,934,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 420934384...
Checkpoint 420934384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.44116
Policy Entropy: 1.06939
Value Function Loss: 2.06011

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.08079

Collected Steps per Second: 8,709.06942
Overall Steps per Second: 7,465.47186

Timestep Collection Time: 5.74206
Timestep Consumption Time: 0.95651
PPO Batch Consumption Time: 0.04939
Total Iteration Time: 6.69857

Cumulative Model Updates: 25,237
Cumulative Timesteps: 420,984,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.80008
Policy Entropy: 1.07607
Value Function Loss: 2.00371

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.09698

Collected Steps per Second: 8,546.73827
Overall Steps per Second: 7,443.63409

Timestep Collection Time: 5.85018
Timestep Consumption Time: 0.86696
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 6.71715

Cumulative Model Updates: 25,240
Cumulative Timesteps: 421,034,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 421034392...
Checkpoint 421034392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.98999
Policy Entropy: 1.09017
Value Function Loss: 1.98908

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.17246
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.09722

Collected Steps per Second: 8,817.56294
Overall Steps per Second: 7,774.76711

Timestep Collection Time: 5.67209
Timestep Consumption Time: 0.76077
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.43286

Cumulative Model Updates: 25,243
Cumulative Timesteps: 421,084,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.36549
Policy Entropy: 1.06658
Value Function Loss: 1.97010

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.20262
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.09402

Collected Steps per Second: 8,735.44960
Overall Steps per Second: 7,620.11680

Timestep Collection Time: 5.72449
Timestep Consumption Time: 0.83788
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.56237

Cumulative Model Updates: 25,246
Cumulative Timesteps: 421,134,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 421134412...
Checkpoint 421134412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.23447
Policy Entropy: 1.08466
Value Function Loss: 2.07222

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.17742
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.10019

Collected Steps per Second: 8,864.50632
Overall Steps per Second: 7,725.34153

Timestep Collection Time: 5.64363
Timestep Consumption Time: 0.83220
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.47583

Cumulative Model Updates: 25,249
Cumulative Timesteps: 421,184,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.67852
Policy Entropy: 1.08931
Value Function Loss: 1.99612

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.18330
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.09718

Collected Steps per Second: 8,570.06860
Overall Steps per Second: 7,492.69347

Timestep Collection Time: 5.83519
Timestep Consumption Time: 0.83904
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.67424

Cumulative Model Updates: 25,252
Cumulative Timesteps: 421,234,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 421234448...
Checkpoint 421234448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.53894
Policy Entropy: 1.07403
Value Function Loss: 2.02742

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 8,868.67291
Overall Steps per Second: 7,689.95655

Timestep Collection Time: 5.63805
Timestep Consumption Time: 0.86420
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.50225

Cumulative Model Updates: 25,255
Cumulative Timesteps: 421,284,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.24669
Policy Entropy: 1.06837
Value Function Loss: 1.93384

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.17995
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.09048

Collected Steps per Second: 8,644.65120
Overall Steps per Second: 7,678.80439

Timestep Collection Time: 5.78693
Timestep Consumption Time: 0.72789
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.51482

Cumulative Model Updates: 25,258
Cumulative Timesteps: 421,334,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421334476...
Checkpoint 421334476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.58155
Policy Entropy: 1.08200
Value Function Loss: 1.89170

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.09133

Collected Steps per Second: 8,694.82290
Overall Steps per Second: 7,520.52033

Timestep Collection Time: 5.75147
Timestep Consumption Time: 0.89807
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.64954

Cumulative Model Updates: 25,261
Cumulative Timesteps: 421,384,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.98253
Policy Entropy: 1.09093
Value Function Loss: 1.93504

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 8,827.43996
Overall Steps per Second: 7,523.05719

Timestep Collection Time: 5.66642
Timestep Consumption Time: 0.98247
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.64889

Cumulative Model Updates: 25,264
Cumulative Timesteps: 421,434,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 421434504...
Checkpoint 421434504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.27006
Policy Entropy: 1.07165
Value Function Loss: 1.84500

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.10610

Collected Steps per Second: 8,734.74526
Overall Steps per Second: 7,551.58535

Timestep Collection Time: 5.72656
Timestep Consumption Time: 0.89722
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.62377

Cumulative Model Updates: 25,267
Cumulative Timesteps: 421,484,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.31780
Policy Entropy: 1.06393
Value Function Loss: 2.04521

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 8,877.06589
Overall Steps per Second: 7,693.17218

Timestep Collection Time: 5.63474
Timestep Consumption Time: 0.86712
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 6.50187

Cumulative Model Updates: 25,270
Cumulative Timesteps: 421,534,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 421534544...
Checkpoint 421534544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.68655
Policy Entropy: 1.06617
Value Function Loss: 1.96510

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.08537

Collected Steps per Second: 8,604.94709
Overall Steps per Second: 7,648.17619

Timestep Collection Time: 5.81084
Timestep Consumption Time: 0.72692
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.53777

Cumulative Model Updates: 25,273
Cumulative Timesteps: 421,584,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.39468
Policy Entropy: 1.08002
Value Function Loss: 2.13321

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.08677

Collected Steps per Second: 8,565.71495
Overall Steps per Second: 7,432.28451

Timestep Collection Time: 5.83863
Timestep Consumption Time: 0.89040
PPO Batch Consumption Time: 0.05226
Total Iteration Time: 6.72902

Cumulative Model Updates: 25,276
Cumulative Timesteps: 421,634,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 421634558...
Checkpoint 421634558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.73778
Policy Entropy: 1.06106
Value Function Loss: 1.95529

Mean KL Divergence: 0.03335
SB3 Clip Fraction: 0.21090
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.08225

Collected Steps per Second: 8,392.36595
Overall Steps per Second: 7,344.59449

Timestep Collection Time: 5.95803
Timestep Consumption Time: 0.84997
PPO Batch Consumption Time: 0.04699
Total Iteration Time: 6.80800

Cumulative Model Updates: 25,279
Cumulative Timesteps: 421,684,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.26124
Policy Entropy: 1.08045
Value Function Loss: 1.95291

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.08327

Collected Steps per Second: 9,064.67407
Overall Steps per Second: 7,779.60161

Timestep Collection Time: 5.51879
Timestep Consumption Time: 0.91162
PPO Batch Consumption Time: 0.05251
Total Iteration Time: 6.43041

Cumulative Model Updates: 25,282
Cumulative Timesteps: 421,734,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421734586...
Checkpoint 421734586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.62140
Policy Entropy: 1.08087
Value Function Loss: 1.81137

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.16934
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.07552

Collected Steps per Second: 8,512.09971
Overall Steps per Second: 7,430.06214

Timestep Collection Time: 5.87423
Timestep Consumption Time: 0.85546
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.72969

Cumulative Model Updates: 25,285
Cumulative Timesteps: 421,784,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.72423
Policy Entropy: 1.06154
Value Function Loss: 1.87934

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 8,743.77457
Overall Steps per Second: 7,674.34244

Timestep Collection Time: 5.71904
Timestep Consumption Time: 0.79696
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.51600

Cumulative Model Updates: 25,288
Cumulative Timesteps: 421,834,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 421834594...
Checkpoint 421834594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.96733
Policy Entropy: 1.06029
Value Function Loss: 1.88099

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 8,641.97260
Overall Steps per Second: 7,432.02127

Timestep Collection Time: 5.78572
Timestep Consumption Time: 0.94193
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.72764

Cumulative Model Updates: 25,291
Cumulative Timesteps: 421,884,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.16791
Policy Entropy: 1.06318
Value Function Loss: 1.91534

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.05320

Collected Steps per Second: 8,694.24948
Overall Steps per Second: 7,504.39009

Timestep Collection Time: 5.75415
Timestep Consumption Time: 0.91235
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.66650

Cumulative Model Updates: 25,294
Cumulative Timesteps: 421,934,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 421934622...
Checkpoint 421934622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.57753
Policy Entropy: 1.06849
Value Function Loss: 1.96645

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.04840

Collected Steps per Second: 8,879.10124
Overall Steps per Second: 7,671.05418

Timestep Collection Time: 5.63368
Timestep Consumption Time: 0.88720
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.52088

Cumulative Model Updates: 25,297
Cumulative Timesteps: 421,984,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.18554
Policy Entropy: 1.06914
Value Function Loss: 1.96328

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 8,705.18041
Overall Steps per Second: 7,574.69636

Timestep Collection Time: 5.74394
Timestep Consumption Time: 0.85725
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.60119

Cumulative Model Updates: 25,300
Cumulative Timesteps: 422,034,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 422034646...
Checkpoint 422034646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.35003
Policy Entropy: 1.07027
Value Function Loss: 2.03765

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.06855
Value Function Update Magnitude: 0.05714

Collected Steps per Second: 9,244.32682
Overall Steps per Second: 8,054.77634

Timestep Collection Time: 5.41154
Timestep Consumption Time: 0.79919
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 6.21072

Cumulative Model Updates: 25,303
Cumulative Timesteps: 422,084,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.33517
Policy Entropy: 1.06647
Value Function Loss: 1.90789

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15589
Policy Update Magnitude: 0.07050
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 8,743.43982
Overall Steps per Second: 7,572.89915

Timestep Collection Time: 5.72109
Timestep Consumption Time: 0.88431
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.60540

Cumulative Model Updates: 25,306
Cumulative Timesteps: 422,134,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 422134694...
Checkpoint 422134694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.16597
Policy Entropy: 1.05481
Value Function Loss: 1.94608

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.17020
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.05301

Collected Steps per Second: 9,260.54694
Overall Steps per Second: 7,925.15329

Timestep Collection Time: 5.40162
Timestep Consumption Time: 0.91018
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 6.31180

Cumulative Model Updates: 25,309
Cumulative Timesteps: 422,184,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.11914
Policy Entropy: 1.07006
Value Function Loss: 1.90858

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 9,242.95100
Overall Steps per Second: 7,964.47962

Timestep Collection Time: 5.41018
Timestep Consumption Time: 0.86845
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.27863

Cumulative Model Updates: 25,312
Cumulative Timesteps: 422,234,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 422234722...
Checkpoint 422234722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.61311
Policy Entropy: 1.08427
Value Function Loss: 1.94252

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.05523

Collected Steps per Second: 8,872.52234
Overall Steps per Second: 7,706.30666

Timestep Collection Time: 5.63898
Timestep Consumption Time: 0.85336
PPO Batch Consumption Time: 0.04431
Total Iteration Time: 6.49234

Cumulative Model Updates: 25,315
Cumulative Timesteps: 422,284,754

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.15260
Policy Entropy: 1.06539
Value Function Loss: 1.86361

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.06026

Collected Steps per Second: 8,690.21444
Overall Steps per Second: 7,621.10933

Timestep Collection Time: 5.75544
Timestep Consumption Time: 0.80738
PPO Batch Consumption Time: 0.05233
Total Iteration Time: 6.56282

Cumulative Model Updates: 25,318
Cumulative Timesteps: 422,334,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 422334770...
Checkpoint 422334770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.04001
Policy Entropy: 1.06036
Value Function Loss: 1.78860

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.19626
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 8,675.48452
Overall Steps per Second: 7,558.19971

Timestep Collection Time: 5.76429
Timestep Consumption Time: 0.85210
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.61639

Cumulative Model Updates: 25,321
Cumulative Timesteps: 422,384,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.83727
Policy Entropy: 1.06306
Value Function Loss: 1.82436

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 8,527.85987
Overall Steps per Second: 7,538.62926

Timestep Collection Time: 5.86642
Timestep Consumption Time: 0.76980
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 6.63622

Cumulative Model Updates: 25,324
Cumulative Timesteps: 422,434,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 422434806...
Checkpoint 422434806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.60120
Policy Entropy: 1.07387
Value Function Loss: 1.88716

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16422
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.07649

Collected Steps per Second: 8,822.86041
Overall Steps per Second: 7,659.36893

Timestep Collection Time: 5.66778
Timestep Consumption Time: 0.86096
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 6.52874

Cumulative Model Updates: 25,327
Cumulative Timesteps: 422,484,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.71251
Policy Entropy: 1.03334
Value Function Loss: 2.02914

Mean KL Divergence: 0.04650
SB3 Clip Fraction: 0.28929
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 8,614.02527
Overall Steps per Second: 7,554.86345

Timestep Collection Time: 5.80751
Timestep Consumption Time: 0.81419
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 6.62169

Cumulative Model Updates: 25,330
Cumulative Timesteps: 422,534,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 422534838...
Checkpoint 422534838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.39645
Policy Entropy: 1.05704
Value Function Loss: 2.00998

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.10670

Collected Steps per Second: 8,673.40110
Overall Steps per Second: 7,559.40235

Timestep Collection Time: 5.76637
Timestep Consumption Time: 0.84977
PPO Batch Consumption Time: 0.04810
Total Iteration Time: 6.61613

Cumulative Model Updates: 25,333
Cumulative Timesteps: 422,584,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.46366
Policy Entropy: 1.05139
Value Function Loss: 1.90353

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.18809
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 8,905.64335
Overall Steps per Second: 7,785.10519

Timestep Collection Time: 5.61554
Timestep Consumption Time: 0.80826
PPO Batch Consumption Time: 0.04039
Total Iteration Time: 6.42381

Cumulative Model Updates: 25,336
Cumulative Timesteps: 422,634,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 422634862...
Checkpoint 422634862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.18083
Policy Entropy: 1.05196
Value Function Loss: 1.82595

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.19557
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 8,908.01343
Overall Steps per Second: 7,857.21772

Timestep Collection Time: 5.61382
Timestep Consumption Time: 0.75077
PPO Batch Consumption Time: 0.04581
Total Iteration Time: 6.36459

Cumulative Model Updates: 25,339
Cumulative Timesteps: 422,684,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.96334
Policy Entropy: 1.07008
Value Function Loss: 1.74840

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.18225
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.10475

Collected Steps per Second: 8,761.51047
Overall Steps per Second: 7,644.60123

Timestep Collection Time: 5.70952
Timestep Consumption Time: 0.83419
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.54370

Cumulative Model Updates: 25,342
Cumulative Timesteps: 422,734,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 422734894...
Checkpoint 422734894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.65180
Policy Entropy: 1.06326
Value Function Loss: 1.76524

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.03981
Value Function Update Magnitude: 0.09277

Collected Steps per Second: 8,698.46265
Overall Steps per Second: 7,694.39385

Timestep Collection Time: 5.74837
Timestep Consumption Time: 0.75013
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.49850

Cumulative Model Updates: 25,345
Cumulative Timesteps: 422,784,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.73347
Policy Entropy: 1.04910
Value Function Loss: 1.66070

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.17553
Policy Update Magnitude: 0.04332
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 8,566.93061
Overall Steps per Second: 7,308.13238

Timestep Collection Time: 5.83826
Timestep Consumption Time: 1.00562
PPO Batch Consumption Time: 0.04772
Total Iteration Time: 6.84388

Cumulative Model Updates: 25,348
Cumulative Timesteps: 422,834,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 422834912...
Checkpoint 422834912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.63653
Policy Entropy: 1.03609
Value Function Loss: 1.74558

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.20439
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 8,614.94696
Overall Steps per Second: 7,392.07316

Timestep Collection Time: 5.80572
Timestep Consumption Time: 0.96044
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.76617

Cumulative Model Updates: 25,351
Cumulative Timesteps: 422,884,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.56446
Policy Entropy: 1.03870
Value Function Loss: 1.78312

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.17077
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.09334

Collected Steps per Second: 8,835.22117
Overall Steps per Second: 7,811.31778

Timestep Collection Time: 5.66256
Timestep Consumption Time: 0.74225
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 6.40481

Cumulative Model Updates: 25,354
Cumulative Timesteps: 422,934,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 422934958...
Checkpoint 422934958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.13063
Policy Entropy: 1.03134
Value Function Loss: 1.84329

Mean KL Divergence: 0.02510
SB3 Clip Fraction: 0.20840
Policy Update Magnitude: 0.03818
Value Function Update Magnitude: 0.10222

Collected Steps per Second: 9,056.95018
Overall Steps per Second: 7,863.55294

Timestep Collection Time: 5.52261
Timestep Consumption Time: 0.83813
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.36074

Cumulative Model Updates: 25,357
Cumulative Timesteps: 422,984,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.74270
Policy Entropy: 1.01535
Value Function Loss: 1.76718

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.21028
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.08794

Collected Steps per Second: 8,881.23563
Overall Steps per Second: 7,719.72604

Timestep Collection Time: 5.63165
Timestep Consumption Time: 0.84734
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.47899

Cumulative Model Updates: 25,360
Cumulative Timesteps: 423,034,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423034992...
Checkpoint 423034992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.69057
Policy Entropy: 1.03237
Value Function Loss: 1.73091

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.19785
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.07993

Collected Steps per Second: 8,541.60182
Overall Steps per Second: 7,445.05352

Timestep Collection Time: 5.85675
Timestep Consumption Time: 0.86261
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.71936

Cumulative Model Updates: 25,363
Cumulative Timesteps: 423,085,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.82923
Policy Entropy: 1.02388
Value Function Loss: 1.59382

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.20602
Policy Update Magnitude: 0.04254
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 8,856.86984
Overall Steps per Second: 7,641.58168

Timestep Collection Time: 5.64692
Timestep Consumption Time: 0.89806
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.54498

Cumulative Model Updates: 25,366
Cumulative Timesteps: 423,135,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 423135032...
Checkpoint 423135032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.31449
Policy Entropy: 1.00522
Value Function Loss: 1.58950

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.20735
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07618

Collected Steps per Second: 8,895.80623
Overall Steps per Second: 7,829.55203

Timestep Collection Time: 5.62220
Timestep Consumption Time: 0.76565
PPO Batch Consumption Time: 0.04881
Total Iteration Time: 6.38785

Cumulative Model Updates: 25,369
Cumulative Timesteps: 423,185,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.65100
Policy Entropy: 0.99798
Value Function Loss: 1.66226

Mean KL Divergence: 0.03093
SB3 Clip Fraction: 0.24735
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.07412

Collected Steps per Second: 8,583.56665
Overall Steps per Second: 7,486.80532

Timestep Collection Time: 5.82672
Timestep Consumption Time: 0.85357
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.68029

Cumulative Model Updates: 25,372
Cumulative Timesteps: 423,235,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 423235060...
Checkpoint 423235060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.51962
Policy Entropy: 1.00544
Value Function Loss: 1.84784

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 8,445.20227
Overall Steps per Second: 7,308.52944

Timestep Collection Time: 5.92384
Timestep Consumption Time: 0.92132
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 6.84515

Cumulative Model Updates: 25,375
Cumulative Timesteps: 423,285,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.65232
Policy Entropy: 1.02537
Value Function Loss: 1.88150

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.19826
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 9,010.62073
Overall Steps per Second: 7,816.97246

Timestep Collection Time: 5.55167
Timestep Consumption Time: 0.84774
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.39941

Cumulative Model Updates: 25,378
Cumulative Timesteps: 423,335,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 423335112...
Checkpoint 423335112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.88499
Policy Entropy: 0.97354
Value Function Loss: 1.83329

Mean KL Divergence: 0.06444
SB3 Clip Fraction: 0.32647
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 8,901.86252
Overall Steps per Second: 7,639.48228

Timestep Collection Time: 5.61995
Timestep Consumption Time: 0.92866
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.54861

Cumulative Model Updates: 25,381
Cumulative Timesteps: 423,385,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.83598
Policy Entropy: 1.01686
Value Function Loss: 1.76209

Mean KL Divergence: 0.03787
SB3 Clip Fraction: 0.27795
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.09319

Collected Steps per Second: 8,577.90110
Overall Steps per Second: 7,631.85958

Timestep Collection Time: 5.83080
Timestep Consumption Time: 0.72278
PPO Batch Consumption Time: 0.04234
Total Iteration Time: 6.55358

Cumulative Model Updates: 25,384
Cumulative Timesteps: 423,435,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423435156...
Checkpoint 423435156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.89165
Policy Entropy: 0.95811
Value Function Loss: 1.73433

Mean KL Divergence: 0.07925
SB3 Clip Fraction: 0.39341
Policy Update Magnitude: 0.03580
Value Function Update Magnitude: 0.08517

Collected Steps per Second: 8,817.98675
Overall Steps per Second: 7,475.36229

Timestep Collection Time: 5.67204
Timestep Consumption Time: 1.01874
PPO Batch Consumption Time: 0.04697
Total Iteration Time: 6.69078

Cumulative Model Updates: 25,387
Cumulative Timesteps: 423,485,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.65315
Policy Entropy: 0.99928
Value Function Loss: 1.70994

Mean KL Divergence: 0.04394
SB3 Clip Fraction: 0.30707
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 8,833.81057
Overall Steps per Second: 7,734.55880

Timestep Collection Time: 5.66279
Timestep Consumption Time: 0.80481
PPO Batch Consumption Time: 0.03998
Total Iteration Time: 6.46760

Cumulative Model Updates: 25,390
Cumulative Timesteps: 423,535,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 423535196...
Checkpoint 423535196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.02752
Policy Entropy: 0.95640
Value Function Loss: 1.74664

Mean KL Divergence: 0.07561
SB3 Clip Fraction: 0.36731
Policy Update Magnitude: 0.03086
Value Function Update Magnitude: 0.08861

Collected Steps per Second: 9,088.14354
Overall Steps per Second: 7,893.10908

Timestep Collection Time: 5.50211
Timestep Consumption Time: 0.83303
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.33515

Cumulative Model Updates: 25,393
Cumulative Timesteps: 423,585,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.20119
Policy Entropy: 0.98600
Value Function Loss: 1.73372

Mean KL Divergence: 0.04135
SB3 Clip Fraction: 0.28993
Policy Update Magnitude: 0.02858
Value Function Update Magnitude: 0.08893

Collected Steps per Second: 8,989.94040
Overall Steps per Second: 7,854.64028

Timestep Collection Time: 5.56355
Timestep Consumption Time: 0.80415
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.36770

Cumulative Model Updates: 25,396
Cumulative Timesteps: 423,635,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423635216...
Checkpoint 423635216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.87994
Policy Entropy: 0.94770
Value Function Loss: 1.73221

Mean KL Divergence: 0.08103
SB3 Clip Fraction: 0.37645
Policy Update Magnitude: 0.03350
Value Function Update Magnitude: 0.08351

Collected Steps per Second: 8,735.57418
Overall Steps per Second: 7,639.11109

Timestep Collection Time: 5.72693
Timestep Consumption Time: 0.82200
PPO Batch Consumption Time: 0.05048
Total Iteration Time: 6.54893

Cumulative Model Updates: 25,399
Cumulative Timesteps: 423,685,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.25052
Policy Entropy: 0.97764
Value Function Loss: 1.68382

Mean KL Divergence: 0.03705
SB3 Clip Fraction: 0.25402
Policy Update Magnitude: 0.03444
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 8,878.72975
Overall Steps per Second: 7,693.67656

Timestep Collection Time: 5.63346
Timestep Consumption Time: 0.86772
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.50118

Cumulative Model Updates: 25,402
Cumulative Timesteps: 423,735,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 423735262...
Checkpoint 423735262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.02628
Policy Entropy: 0.95735
Value Function Loss: 1.57345

Mean KL Divergence: 0.03418
SB3 Clip Fraction: 0.26151
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 8,737.46970
Overall Steps per Second: 7,667.06226

Timestep Collection Time: 5.72317
Timestep Consumption Time: 0.79902
PPO Batch Consumption Time: 0.04991
Total Iteration Time: 6.52219

Cumulative Model Updates: 25,405
Cumulative Timesteps: 423,785,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.63197
Policy Entropy: 0.97268
Value Function Loss: 1.60528

Mean KL Divergence: 0.03353
SB3 Clip Fraction: 0.26093
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.05395

Collected Steps per Second: 8,998.57386
Overall Steps per Second: 7,824.99849

Timestep Collection Time: 5.55866
Timestep Consumption Time: 0.83367
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.39233

Cumulative Model Updates: 25,408
Cumulative Timesteps: 423,835,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 423835288...
Checkpoint 423835288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.58474
Policy Entropy: 0.96271
Value Function Loss: 1.49342

Mean KL Divergence: 0.02851
SB3 Clip Fraction: 0.24716
Policy Update Magnitude: 0.03455
Value Function Update Magnitude: 0.05639

Collected Steps per Second: 9,043.44683
Overall Steps per Second: 7,835.25485

Timestep Collection Time: 5.53019
Timestep Consumption Time: 0.85275
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 6.38294

Cumulative Model Updates: 25,411
Cumulative Timesteps: 423,885,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.86820
Policy Entropy: 0.95365
Value Function Loss: 1.55160

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.23173
Policy Update Magnitude: 0.04042
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 9,602.59317
Overall Steps per Second: 8,175.93407

Timestep Collection Time: 5.20901
Timestep Consumption Time: 0.90895
PPO Batch Consumption Time: 0.05193
Total Iteration Time: 6.11796

Cumulative Model Updates: 25,414
Cumulative Timesteps: 423,935,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 423935320...
Checkpoint 423935320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.12172
Policy Entropy: 0.94362
Value Function Loss: 1.47990

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.23487
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.05667

Collected Steps per Second: 8,594.29899
Overall Steps per Second: 7,462.53159

Timestep Collection Time: 5.82037
Timestep Consumption Time: 0.88272
PPO Batch Consumption Time: 0.05040
Total Iteration Time: 6.70309

Cumulative Model Updates: 25,417
Cumulative Timesteps: 423,985,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.56653
Policy Entropy: 0.95287
Value Function Loss: 1.63569

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.17635
Policy Update Magnitude: 0.03869
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 8,935.10614
Overall Steps per Second: 7,841.48053

Timestep Collection Time: 5.59635
Timestep Consumption Time: 0.78050
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 6.37686

Cumulative Model Updates: 25,420
Cumulative Timesteps: 424,035,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 424035346...
Checkpoint 424035346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.23552
Policy Entropy: 0.95531
Value Function Loss: 1.55843

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.18459
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.04398

Collected Steps per Second: 9,360.48301
Overall Steps per Second: 8,110.72194

Timestep Collection Time: 5.34396
Timestep Consumption Time: 0.82344
PPO Batch Consumption Time: 0.04727
Total Iteration Time: 6.16739

Cumulative Model Updates: 25,423
Cumulative Timesteps: 424,085,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.57477
Policy Entropy: 0.94608
Value Function Loss: 1.54445

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.18753
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.04198

Collected Steps per Second: 9,102.83457
Overall Steps per Second: 7,947.35745

Timestep Collection Time: 5.49587
Timestep Consumption Time: 0.79905
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.29492

Cumulative Model Updates: 25,426
Cumulative Timesteps: 424,135,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 424135396...
Checkpoint 424135396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.67637
Policy Entropy: 0.91807
Value Function Loss: 1.53145

Mean KL Divergence: 0.03837
SB3 Clip Fraction: 0.32669
Policy Update Magnitude: 0.03772
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 8,556.33090
Overall Steps per Second: 7,480.38496

Timestep Collection Time: 5.84690
Timestep Consumption Time: 0.84099
PPO Batch Consumption Time: 0.05211
Total Iteration Time: 6.68789

Cumulative Model Updates: 25,429
Cumulative Timesteps: 424,185,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.55926
Policy Entropy: 0.94595
Value Function Loss: 1.50105

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.16224
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.04903

Collected Steps per Second: 8,863.72740
Overall Steps per Second: 7,723.77042

Timestep Collection Time: 5.64210
Timestep Consumption Time: 0.83272
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.47482

Cumulative Model Updates: 25,432
Cumulative Timesteps: 424,235,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424235434...
Checkpoint 424235434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.23715
Policy Entropy: 0.91931
Value Function Loss: 1.55823

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.21045
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.05386

Collected Steps per Second: 8,895.66925
Overall Steps per Second: 7,855.19281

Timestep Collection Time: 5.62251
Timestep Consumption Time: 0.74474
PPO Batch Consumption Time: 0.04805
Total Iteration Time: 6.36725

Cumulative Model Updates: 25,435
Cumulative Timesteps: 424,285,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.78023
Policy Entropy: 0.92366
Value Function Loss: 1.43587

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.23848
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.05559

Collected Steps per Second: 8,962.04357
Overall Steps per Second: 7,829.89148

Timestep Collection Time: 5.58020
Timestep Consumption Time: 0.80686
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 6.38706

Cumulative Model Updates: 25,438
Cumulative Timesteps: 424,335,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424335460...
Checkpoint 424335460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.87622
Policy Entropy: 0.92183
Value Function Loss: 1.50564

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.19721
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 8,904.55069
Overall Steps per Second: 7,805.81022

Timestep Collection Time: 5.61780
Timestep Consumption Time: 0.79076
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.40856

Cumulative Model Updates: 25,441
Cumulative Timesteps: 424,385,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.95599
Policy Entropy: 0.92135
Value Function Loss: 1.44066

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.20585
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.04711

Collected Steps per Second: 9,013.29418
Overall Steps per Second: 7,848.62896

Timestep Collection Time: 5.55047
Timestep Consumption Time: 0.82364
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 6.37411

Cumulative Model Updates: 25,444
Cumulative Timesteps: 424,435,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 424435512...
Checkpoint 424435512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.03440
Policy Entropy: 0.93005
Value Function Loss: 1.58861

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.22797
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.04878

Collected Steps per Second: 8,752.64241
Overall Steps per Second: 7,563.77295

Timestep Collection Time: 5.71439
Timestep Consumption Time: 0.89818
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.61257

Cumulative Model Updates: 25,447
Cumulative Timesteps: 424,485,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.50776
Policy Entropy: 0.90936
Value Function Loss: 1.60508

Mean KL Divergence: 0.02889
SB3 Clip Fraction: 0.24318
Policy Update Magnitude: 0.04315
Value Function Update Magnitude: 0.05701

Collected Steps per Second: 8,850.88129
Overall Steps per Second: 7,829.66936

Timestep Collection Time: 5.65028
Timestep Consumption Time: 0.73696
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 6.38724

Cumulative Model Updates: 25,450
Cumulative Timesteps: 424,535,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424535538...
Checkpoint 424535538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.46737
Policy Entropy: 0.90539
Value Function Loss: 1.65682

Mean KL Divergence: 0.03255
SB3 Clip Fraction: 0.27541
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 8,743.41512
Overall Steps per Second: 7,633.83202

Timestep Collection Time: 5.71973
Timestep Consumption Time: 0.83137
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.55110

Cumulative Model Updates: 25,453
Cumulative Timesteps: 424,585,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.37684
Policy Entropy: 0.93909
Value Function Loss: 1.66438

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.23808
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.05003

Collected Steps per Second: 8,801.36350
Overall Steps per Second: 7,680.98845

Timestep Collection Time: 5.68298
Timestep Consumption Time: 0.82894
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.51192

Cumulative Model Updates: 25,456
Cumulative Timesteps: 424,635,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 424635566...
Checkpoint 424635566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.20455
Policy Entropy: 0.93049
Value Function Loss: 1.59305

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.20267
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 8,837.40089
Overall Steps per Second: 7,709.00014

Timestep Collection Time: 5.65822
Timestep Consumption Time: 0.82822
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.48644

Cumulative Model Updates: 25,459
Cumulative Timesteps: 424,685,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.58146
Policy Entropy: 0.90579
Value Function Loss: 1.58482

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.24894
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.04822

Collected Steps per Second: 8,697.60465
Overall Steps per Second: 7,618.50128

Timestep Collection Time: 5.75101
Timestep Consumption Time: 0.81459
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.56560

Cumulative Model Updates: 25,462
Cumulative Timesteps: 424,735,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424735590...
Checkpoint 424735590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.63019
Policy Entropy: 0.93153
Value Function Loss: 1.39051

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.19137
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 8,790.22198
Overall Steps per Second: 7,711.81432

Timestep Collection Time: 5.69087
Timestep Consumption Time: 0.79580
PPO Batch Consumption Time: 0.04477
Total Iteration Time: 6.48667

Cumulative Model Updates: 25,465
Cumulative Timesteps: 424,785,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.38836
Policy Entropy: 0.94519
Value Function Loss: 1.37879

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.23762
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05025

Collected Steps per Second: 8,920.84333
Overall Steps per Second: 7,791.41476

Timestep Collection Time: 5.60709
Timestep Consumption Time: 0.81279
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.41989

Cumulative Model Updates: 25,468
Cumulative Timesteps: 424,835,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424835634...
Checkpoint 424835634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.21486
Policy Entropy: 0.91002
Value Function Loss: 1.43277

Mean KL Divergence: 0.03396
SB3 Clip Fraction: 0.29729
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.05980

Collected Steps per Second: 8,628.41951
Overall Steps per Second: 7,530.33663

Timestep Collection Time: 5.79805
Timestep Consumption Time: 0.84548
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 6.64353

Cumulative Model Updates: 25,471
Cumulative Timesteps: 424,885,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.36674
Policy Entropy: 0.93770
Value Function Loss: 1.62474

Mean KL Divergence: 0.03036
SB3 Clip Fraction: 0.23539
Policy Update Magnitude: 0.04034
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 8,891.56035
Overall Steps per Second: 7,758.18846

Timestep Collection Time: 5.62556
Timestep Consumption Time: 0.82182
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.44738

Cumulative Model Updates: 25,474
Cumulative Timesteps: 424,935,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424935682...
Checkpoint 424935682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.54801
Policy Entropy: 0.93728
Value Function Loss: 1.62692

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.25087
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.07992

Collected Steps per Second: 8,875.19508
Overall Steps per Second: 7,715.59549

Timestep Collection Time: 5.63661
Timestep Consumption Time: 0.84714
PPO Batch Consumption Time: 0.04579
Total Iteration Time: 6.48375

Cumulative Model Updates: 25,477
Cumulative Timesteps: 424,985,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.23550
Policy Entropy: 0.91552
Value Function Loss: 1.58854

Mean KL Divergence: 0.02882
SB3 Clip Fraction: 0.24943
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.08036

Collected Steps per Second: 9,017.93706
Overall Steps per Second: 7,937.10271

Timestep Collection Time: 5.54694
Timestep Consumption Time: 0.75535
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 6.30230

Cumulative Model Updates: 25,480
Cumulative Timesteps: 425,035,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 425035730...
Checkpoint 425035730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.06323
Policy Entropy: 0.90881
Value Function Loss: 1.54065

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.28081
Policy Update Magnitude: 0.03762
Value Function Update Magnitude: 0.08061

Collected Steps per Second: 8,739.71951
Overall Steps per Second: 7,508.08831

Timestep Collection Time: 5.72101
Timestep Consumption Time: 0.93848
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 6.65948

Cumulative Model Updates: 25,483
Cumulative Timesteps: 425,085,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.64524
Policy Entropy: 0.92982
Value Function Loss: 1.47311

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.21331
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.08332

Collected Steps per Second: 8,582.92055
Overall Steps per Second: 7,449.99205

Timestep Collection Time: 5.82692
Timestep Consumption Time: 0.88611
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 6.71303

Cumulative Model Updates: 25,486
Cumulative Timesteps: 425,135,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 425135742...
Checkpoint 425135742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.29211
Policy Entropy: 0.93456
Value Function Loss: 1.55340

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.24036
Policy Update Magnitude: 0.03450
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 8,838.26646
Overall Steps per Second: 7,656.27665

Timestep Collection Time: 5.65903
Timestep Consumption Time: 0.87365
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.53268

Cumulative Model Updates: 25,489
Cumulative Timesteps: 425,185,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.80176
Policy Entropy: 0.93069
Value Function Loss: 1.67700

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.19113
Policy Update Magnitude: 0.03894
Value Function Update Magnitude: 0.08103

Collected Steps per Second: 8,946.60617
Overall Steps per Second: 7,729.85337

Timestep Collection Time: 5.59050
Timestep Consumption Time: 0.88000
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.47050

Cumulative Model Updates: 25,492
Cumulative Timesteps: 425,235,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 425235774...
Checkpoint 425235774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.30638
Policy Entropy: 0.90421
Value Function Loss: 1.84064

Mean KL Divergence: 0.03397
SB3 Clip Fraction: 0.30531
Policy Update Magnitude: 0.03692
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 8,786.88826
Overall Steps per Second: 7,742.26854

Timestep Collection Time: 5.69121
Timestep Consumption Time: 0.76788
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.45909

Cumulative Model Updates: 25,495
Cumulative Timesteps: 425,285,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.11012
Policy Entropy: 0.94011
Value Function Loss: 1.83704

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.17833
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 8,753.11482
Overall Steps per Second: 7,496.53244

Timestep Collection Time: 5.71385
Timestep Consumption Time: 0.95777
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 6.67162

Cumulative Model Updates: 25,498
Cumulative Timesteps: 425,335,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 425335796...
Checkpoint 425335796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.47953
Policy Entropy: 0.91504
Value Function Loss: 1.70005

Mean KL Divergence: 0.03032
SB3 Clip Fraction: 0.25453
Policy Update Magnitude: 0.03821
Value Function Update Magnitude: 0.06040

Collected Steps per Second: 8,707.22178
Overall Steps per Second: 7,488.63355

Timestep Collection Time: 5.74489
Timestep Consumption Time: 0.93484
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 6.67972

Cumulative Model Updates: 25,501
Cumulative Timesteps: 425,385,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.52635
Policy Entropy: 0.91449
Value Function Loss: 1.63642

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.25482
Policy Update Magnitude: 0.03549
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 9,182.02888
Overall Steps per Second: 7,951.97784

Timestep Collection Time: 5.44803
Timestep Consumption Time: 0.84273
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.29076

Cumulative Model Updates: 25,504
Cumulative Timesteps: 425,435,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 425435842...
Checkpoint 425435842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.52536
Policy Entropy: 0.92368
Value Function Loss: 1.56582

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.21844
Policy Update Magnitude: 0.03707
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 8,969.46579
Overall Steps per Second: 7,707.38999

Timestep Collection Time: 5.57447
Timestep Consumption Time: 0.91281
PPO Batch Consumption Time: 0.04836
Total Iteration Time: 6.48728

Cumulative Model Updates: 25,507
Cumulative Timesteps: 425,485,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.76124
Policy Entropy: 0.92611
Value Function Loss: 1.47484

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.23159
Policy Update Magnitude: 0.03621
Value Function Update Magnitude: 0.06148

Collected Steps per Second: 8,713.06415
Overall Steps per Second: 7,530.13477

Timestep Collection Time: 5.73943
Timestep Consumption Time: 0.90162
PPO Batch Consumption Time: 0.04710
Total Iteration Time: 6.64105

Cumulative Model Updates: 25,510
Cumulative Timesteps: 425,535,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 425535850...
Checkpoint 425535850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.72804
Policy Entropy: 0.91863
Value Function Loss: 1.33155

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.19232
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 8,833.78576
Overall Steps per Second: 7,563.18999

Timestep Collection Time: 5.66258
Timestep Consumption Time: 0.95130
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.61388

Cumulative Model Updates: 25,513
Cumulative Timesteps: 425,585,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.14586
Policy Entropy: 0.91255
Value Function Loss: 1.37672

Mean KL Divergence: 0.03124
SB3 Clip Fraction: 0.27243
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.05731

Collected Steps per Second: 8,581.65890
Overall Steps per Second: 7,481.00376

Timestep Collection Time: 5.82964
Timestep Consumption Time: 0.85770
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.68734

Cumulative Model Updates: 25,516
Cumulative Timesteps: 425,635,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 425635900...
Checkpoint 425635900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.72223
Policy Entropy: 0.91650
Value Function Loss: 1.43846

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.19746
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 8,941.83181
Overall Steps per Second: 7,827.33053

Timestep Collection Time: 5.59393
Timestep Consumption Time: 0.79650
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.39043

Cumulative Model Updates: 25,519
Cumulative Timesteps: 425,685,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.86890
Policy Entropy: 0.93762
Value Function Loss: 1.60480

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.23494
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.08460

Collected Steps per Second: 8,820.70662
Overall Steps per Second: 7,659.63880

Timestep Collection Time: 5.66961
Timestep Consumption Time: 0.85941
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 6.52903

Cumulative Model Updates: 25,522
Cumulative Timesteps: 425,735,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 425735930...
Checkpoint 425735930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.19555
Policy Entropy: 0.90930
Value Function Loss: 1.57870

Mean KL Divergence: 0.03228
SB3 Clip Fraction: 0.24405
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 9,044.32108
Overall Steps per Second: 7,775.03655

Timestep Collection Time: 5.52877
Timestep Consumption Time: 0.90258
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.43135

Cumulative Model Updates: 25,525
Cumulative Timesteps: 425,785,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.53599
Policy Entropy: 0.93076
Value Function Loss: 1.65793

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.24096
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 8,896.87611
Overall Steps per Second: 7,816.66848

Timestep Collection Time: 5.62242
Timestep Consumption Time: 0.77698
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.39940

Cumulative Model Updates: 25,528
Cumulative Timesteps: 425,835,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 425835956...
Checkpoint 425835956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.61732
Policy Entropy: 0.93501
Value Function Loss: 1.55658

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.27553
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 8,963.60033
Overall Steps per Second: 7,726.80501

Timestep Collection Time: 5.58146
Timestep Consumption Time: 0.89340
PPO Batch Consumption Time: 0.04702
Total Iteration Time: 6.47486

Cumulative Model Updates: 25,531
Cumulative Timesteps: 425,885,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.07587
Policy Entropy: 0.91798
Value Function Loss: 1.58117

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.21033
Policy Update Magnitude: 0.04029
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 9,007.02290
Overall Steps per Second: 7,779.87948

Timestep Collection Time: 5.55433
Timestep Consumption Time: 0.87610
PPO Batch Consumption Time: 0.05307
Total Iteration Time: 6.43043

Cumulative Model Updates: 25,534
Cumulative Timesteps: 425,936,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 425936014...
Checkpoint 425936014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.40153
Policy Entropy: 0.92411
Value Function Loss: 1.58621

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.21981
Policy Update Magnitude: 0.03807
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 9,088.96524
Overall Steps per Second: 7,857.19415

Timestep Collection Time: 5.50360
Timestep Consumption Time: 0.86280
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 6.36639

Cumulative Model Updates: 25,537
Cumulative Timesteps: 425,986,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.61720
Policy Entropy: 0.93360
Value Function Loss: 1.64029

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.07554

Collected Steps per Second: 8,331.76403
Overall Steps per Second: 7,186.06182

Timestep Collection Time: 6.00425
Timestep Consumption Time: 0.95728
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.96153

Cumulative Model Updates: 25,540
Cumulative Timesteps: 426,036,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 426036062...
Checkpoint 426036062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.14894
Policy Entropy: 0.95816
Value Function Loss: 1.69319

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.25351
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 8,814.52003
Overall Steps per Second: 7,734.66791

Timestep Collection Time: 5.67291
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.46492

Cumulative Model Updates: 25,543
Cumulative Timesteps: 426,086,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.27506
Policy Entropy: 0.93490
Value Function Loss: 1.67465

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.17401
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 8,963.23878
Overall Steps per Second: 7,766.21464

Timestep Collection Time: 5.57879
Timestep Consumption Time: 0.85987
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 6.43866

Cumulative Model Updates: 25,546
Cumulative Timesteps: 426,136,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 426136070...
Checkpoint 426136070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.81590
Policy Entropy: 0.92365
Value Function Loss: 1.57766

Mean KL Divergence: 0.03600
SB3 Clip Fraction: 0.24596
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 8,569.06015
Overall Steps per Second: 7,521.58022

Timestep Collection Time: 5.83728
Timestep Consumption Time: 0.81292
PPO Batch Consumption Time: 0.04069
Total Iteration Time: 6.65020

Cumulative Model Updates: 25,549
Cumulative Timesteps: 426,186,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.79231
Policy Entropy: 0.95548
Value Function Loss: 1.59721

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.21159
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.07243

Collected Steps per Second: 8,935.79095
Overall Steps per Second: 7,737.87057

Timestep Collection Time: 5.59816
Timestep Consumption Time: 0.86667
PPO Batch Consumption Time: 0.04952
Total Iteration Time: 6.46483

Cumulative Model Updates: 25,552
Cumulative Timesteps: 426,236,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426236114...
Checkpoint 426236114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.92267
Policy Entropy: 0.96547
Value Function Loss: 1.48613

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.22395
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 8,477.48591
Overall Steps per Second: 7,452.89031

Timestep Collection Time: 5.89915
Timestep Consumption Time: 0.81099
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.71015

Cumulative Model Updates: 25,555
Cumulative Timesteps: 426,286,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.85502
Policy Entropy: 0.95635
Value Function Loss: 1.60920

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.15808
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 8,713.62737
Overall Steps per Second: 7,645.47381

Timestep Collection Time: 5.73975
Timestep Consumption Time: 0.80190
PPO Batch Consumption Time: 0.05043
Total Iteration Time: 6.54165

Cumulative Model Updates: 25,558
Cumulative Timesteps: 426,336,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 426336138...
Checkpoint 426336138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.73321
Policy Entropy: 0.95412
Value Function Loss: 1.68344

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.18911
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.05718

Collected Steps per Second: 8,688.74424
Overall Steps per Second: 7,571.38558

Timestep Collection Time: 5.75595
Timestep Consumption Time: 0.84944
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.60540

Cumulative Model Updates: 25,561
Cumulative Timesteps: 426,386,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.85981
Policy Entropy: 0.93168
Value Function Loss: 1.74562

Mean KL Divergence: 0.03447
SB3 Clip Fraction: 0.25645
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.04856

Collected Steps per Second: 8,879.66183
Overall Steps per Second: 7,725.95359

Timestep Collection Time: 5.63107
Timestep Consumption Time: 0.84088
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 6.47195

Cumulative Model Updates: 25,564
Cumulative Timesteps: 426,436,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 426436152...
Checkpoint 426436152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.18215
Policy Entropy: 0.95962
Value Function Loss: 1.86612

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.18941
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 8,741.42726
Overall Steps per Second: 7,616.00138

Timestep Collection Time: 5.72149
Timestep Consumption Time: 0.84547
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.56696

Cumulative Model Updates: 25,567
Cumulative Timesteps: 426,486,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.46332
Policy Entropy: 0.95584
Value Function Loss: 1.78600

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.18143
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.04300

Collected Steps per Second: 8,868.18495
Overall Steps per Second: 7,722.28981

Timestep Collection Time: 5.63994
Timestep Consumption Time: 0.83690
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.47684

Cumulative Model Updates: 25,570
Cumulative Timesteps: 426,536,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 426536182...
Checkpoint 426536182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.71292
Policy Entropy: 0.96954
Value Function Loss: 1.94000

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.23875
Policy Update Magnitude: 0.06038
Value Function Update Magnitude: 0.04703

Collected Steps per Second: 8,771.78073
Overall Steps per Second: 7,712.20131

Timestep Collection Time: 5.70124
Timestep Consumption Time: 0.78329
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 6.48453

Cumulative Model Updates: 25,573
Cumulative Timesteps: 426,586,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.25213
Policy Entropy: 0.95232
Value Function Loss: 1.89062

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.21503
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.05061

Collected Steps per Second: 8,986.24959
Overall Steps per Second: 7,721.67111

Timestep Collection Time: 5.56673
Timestep Consumption Time: 0.91166
PPO Batch Consumption Time: 0.04904
Total Iteration Time: 6.47839

Cumulative Model Updates: 25,576
Cumulative Timesteps: 426,636,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426636216...
Checkpoint 426636216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.73140
Policy Entropy: 0.93506
Value Function Loss: 1.95019

Mean KL Divergence: 0.03814
SB3 Clip Fraction: 0.28043
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.04776

Collected Steps per Second: 8,895.81513
Overall Steps per Second: 7,786.36985

Timestep Collection Time: 5.62422
Timestep Consumption Time: 0.80137
PPO Batch Consumption Time: 0.04444
Total Iteration Time: 6.42559

Cumulative Model Updates: 25,579
Cumulative Timesteps: 426,686,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.95810
Policy Entropy: 0.97125
Value Function Loss: 1.87848

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.23136
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.04103

Collected Steps per Second: 8,715.11422
Overall Steps per Second: 7,593.21877

Timestep Collection Time: 5.73991
Timestep Consumption Time: 0.84807
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.58798

Cumulative Model Updates: 25,582
Cumulative Timesteps: 426,736,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426736272...
Checkpoint 426736272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.65675
Policy Entropy: 0.96898
Value Function Loss: 1.80771

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.19466
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.04052

Collected Steps per Second: 8,771.89676
Overall Steps per Second: 7,643.24554

Timestep Collection Time: 5.70321
Timestep Consumption Time: 0.84217
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.54539

Cumulative Model Updates: 25,585
Cumulative Timesteps: 426,786,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.34908
Policy Entropy: 0.96563
Value Function Loss: 1.75583

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.04641

Collected Steps per Second: 8,838.43820
Overall Steps per Second: 7,806.10880

Timestep Collection Time: 5.65801
Timestep Consumption Time: 0.74825
PPO Batch Consumption Time: 0.04818
Total Iteration Time: 6.40626

Cumulative Model Updates: 25,588
Cumulative Timesteps: 426,836,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 426836308...
Checkpoint 426836308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.40685
Policy Entropy: 0.96330
Value Function Loss: 1.86477

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.16496
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.05022

Collected Steps per Second: 8,741.27356
Overall Steps per Second: 7,591.61779

Timestep Collection Time: 5.72022
Timestep Consumption Time: 0.86626
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 6.58647

Cumulative Model Updates: 25,591
Cumulative Timesteps: 426,886,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.60769
Policy Entropy: 0.95195
Value Function Loss: 1.92521

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.18222
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 8,812.71646
Overall Steps per Second: 7,543.63548

Timestep Collection Time: 5.67612
Timestep Consumption Time: 0.95490
PPO Batch Consumption Time: 0.05066
Total Iteration Time: 6.63102

Cumulative Model Updates: 25,594
Cumulative Timesteps: 426,936,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 426936332...
Checkpoint 426936332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.95732
Policy Entropy: 0.94120
Value Function Loss: 1.98347

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.19411
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.06252

Collected Steps per Second: 9,014.75293
Overall Steps per Second: 7,797.05388

Timestep Collection Time: 5.54868
Timestep Consumption Time: 0.86656
PPO Batch Consumption Time: 0.04923
Total Iteration Time: 6.41524

Cumulative Model Updates: 25,597
Cumulative Timesteps: 426,986,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.67852
Policy Entropy: 0.94585
Value Function Loss: 1.81358

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.18919
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.07716

Collected Steps per Second: 8,718.24978
Overall Steps per Second: 7,519.76992

Timestep Collection Time: 5.73716
Timestep Consumption Time: 0.91437
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 6.65153

Cumulative Model Updates: 25,600
Cumulative Timesteps: 427,036,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 427036370...
Checkpoint 427036370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.63387
Policy Entropy: 0.95448
Value Function Loss: 1.77461

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 8,937.48651
Overall Steps per Second: 7,864.58769

Timestep Collection Time: 5.59576
Timestep Consumption Time: 0.76338
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 6.35914

Cumulative Model Updates: 25,603
Cumulative Timesteps: 427,086,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.52024
Policy Entropy: 0.96248
Value Function Loss: 1.78268

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15831
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 8,795.01860
Overall Steps per Second: 7,622.30372

Timestep Collection Time: 5.68549
Timestep Consumption Time: 0.87473
PPO Batch Consumption Time: 0.04978
Total Iteration Time: 6.56022

Cumulative Model Updates: 25,606
Cumulative Timesteps: 427,136,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 427136386...
Checkpoint 427136386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.08987
Policy Entropy: 0.96603
Value Function Loss: 1.89577

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.19399
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 8,515.46977
Overall Steps per Second: 7,470.95235

Timestep Collection Time: 5.87214
Timestep Consumption Time: 0.82099
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.69312

Cumulative Model Updates: 25,609
Cumulative Timesteps: 427,186,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.89104
Policy Entropy: 0.95263
Value Function Loss: 1.87810

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.24417
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 8,828.28770
Overall Steps per Second: 7,684.71170

Timestep Collection Time: 5.66497
Timestep Consumption Time: 0.84301
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.50799

Cumulative Model Updates: 25,612
Cumulative Timesteps: 427,236,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 427236402...
Checkpoint 427236402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.13702
Policy Entropy: 0.96940
Value Function Loss: 1.91012

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.18182
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.06423

Collected Steps per Second: 8,767.57609
Overall Steps per Second: 7,634.30661

Timestep Collection Time: 5.70351
Timestep Consumption Time: 0.84665
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 6.55017

Cumulative Model Updates: 25,615
Cumulative Timesteps: 427,286,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.71843
Policy Entropy: 0.97944
Value Function Loss: 1.87129

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.21008
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 8,748.97142
Overall Steps per Second: 7,664.15314

Timestep Collection Time: 5.71747
Timestep Consumption Time: 0.80928
PPO Batch Consumption Time: 0.04810
Total Iteration Time: 6.52675

Cumulative Model Updates: 25,618
Cumulative Timesteps: 427,336,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 427336430...
Checkpoint 427336430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.32163
Policy Entropy: 0.96192
Value Function Loss: 1.90255

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 8,677.48557
Overall Steps per Second: 7,504.88732

Timestep Collection Time: 5.76227
Timestep Consumption Time: 0.90032
PPO Batch Consumption Time: 0.04752
Total Iteration Time: 6.66259

Cumulative Model Updates: 25,621
Cumulative Timesteps: 427,386,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.32387
Policy Entropy: 0.94533
Value Function Loss: 1.84728

Mean KL Divergence: 0.03075
SB3 Clip Fraction: 0.25383
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.07599

Collected Steps per Second: 8,565.88198
Overall Steps per Second: 7,431.59730

Timestep Collection Time: 5.83921
Timestep Consumption Time: 0.89124
PPO Batch Consumption Time: 0.04312
Total Iteration Time: 6.73045

Cumulative Model Updates: 25,624
Cumulative Timesteps: 427,436,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 427436450...
Checkpoint 427436450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.37545
Policy Entropy: 0.96240
Value Function Loss: 1.82940

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 8,874.62654
Overall Steps per Second: 7,785.15911

Timestep Collection Time: 5.63697
Timestep Consumption Time: 0.78885
PPO Batch Consumption Time: 0.04466
Total Iteration Time: 6.42582

Cumulative Model Updates: 25,627
Cumulative Timesteps: 427,486,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.74905
Policy Entropy: 0.96524
Value Function Loss: 1.86435

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 8,832.53850
Overall Steps per Second: 7,571.78596

Timestep Collection Time: 5.66451
Timestep Consumption Time: 0.94318
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.60769

Cumulative Model Updates: 25,630
Cumulative Timesteps: 427,536,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 427536508...
Checkpoint 427536508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.22833
Policy Entropy: 0.97890
Value Function Loss: 1.96072

Mean KL Divergence: 0.03861
SB3 Clip Fraction: 0.24247
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 9,015.54012
Overall Steps per Second: 7,774.40784

Timestep Collection Time: 5.54642
Timestep Consumption Time: 0.88545
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.43187

Cumulative Model Updates: 25,633
Cumulative Timesteps: 427,586,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.34923
Policy Entropy: 0.95111
Value Function Loss: 1.91367

Mean KL Divergence: 0.04562
SB3 Clip Fraction: 0.26351
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 8,753.00491
Overall Steps per Second: 7,556.47155

Timestep Collection Time: 5.71552
Timestep Consumption Time: 0.90503
PPO Batch Consumption Time: 0.04944
Total Iteration Time: 6.62055

Cumulative Model Updates: 25,636
Cumulative Timesteps: 427,636,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 427636540...
Checkpoint 427636540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.94499
Policy Entropy: 0.97164
Value Function Loss: 1.82680

Mean KL Divergence: 0.03344
SB3 Clip Fraction: 0.22775
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 8,877.28464
Overall Steps per Second: 7,739.91220

Timestep Collection Time: 5.63280
Timestep Consumption Time: 0.82773
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.46054

Cumulative Model Updates: 25,639
Cumulative Timesteps: 427,686,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.00488
Policy Entropy: 0.97672
Value Function Loss: 1.64726

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.23217
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 8,210.88667
Overall Steps per Second: 7,245.02410

Timestep Collection Time: 6.09094
Timestep Consumption Time: 0.81201
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 6.90294

Cumulative Model Updates: 25,642
Cumulative Timesteps: 427,736,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 427736556...
Checkpoint 427736556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.16628
Policy Entropy: 0.97094
Value Function Loss: 1.61430

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.18743
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 8,956.84995
Overall Steps per Second: 7,774.20381

Timestep Collection Time: 5.58567
Timestep Consumption Time: 0.84972
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.43539

Cumulative Model Updates: 25,645
Cumulative Timesteps: 427,786,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.97624
Policy Entropy: 0.96488
Value Function Loss: 1.68642

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.19261
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 8,807.99144
Overall Steps per Second: 7,641.14882

Timestep Collection Time: 5.67734
Timestep Consumption Time: 0.86696
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 6.54430

Cumulative Model Updates: 25,648
Cumulative Timesteps: 427,836,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 427836592...
Checkpoint 427836592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.65327
Policy Entropy: 0.97513
Value Function Loss: 1.69737

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 8,727.47843
Overall Steps per Second: 7,622.33724

Timestep Collection Time: 5.73041
Timestep Consumption Time: 0.83084
PPO Batch Consumption Time: 0.04003
Total Iteration Time: 6.56124

Cumulative Model Updates: 25,651
Cumulative Timesteps: 427,886,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.63390
Policy Entropy: 0.98112
Value Function Loss: 1.79533

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 8,633.87700
Overall Steps per Second: 7,512.61128

Timestep Collection Time: 5.79160
Timestep Consumption Time: 0.86440
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 6.65601

Cumulative Model Updates: 25,654
Cumulative Timesteps: 427,936,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 427936608...
Checkpoint 427936608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.45039
Policy Entropy: 0.97551
Value Function Loss: 1.72637

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.16415
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.08053

Collected Steps per Second: 8,924.53085
Overall Steps per Second: 7,866.16724

Timestep Collection Time: 5.60276
Timestep Consumption Time: 0.75383
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 6.35659

Cumulative Model Updates: 25,657
Cumulative Timesteps: 427,986,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.58518
Policy Entropy: 0.97680
Value Function Loss: 1.76402

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.20805
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.08215

Collected Steps per Second: 8,823.75837
Overall Steps per Second: 7,681.91674

Timestep Collection Time: 5.66901
Timestep Consumption Time: 0.84264
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.51166

Cumulative Model Updates: 25,660
Cumulative Timesteps: 428,036,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 428036632...
Checkpoint 428036632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.75304
Policy Entropy: 0.99011
Value Function Loss: 1.72531

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 8,412.34620
Overall Steps per Second: 7,399.75200

Timestep Collection Time: 5.94483
Timestep Consumption Time: 0.81350
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.75833

Cumulative Model Updates: 25,663
Cumulative Timesteps: 428,086,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.75050
Policy Entropy: 1.00247
Value Function Loss: 1.84857

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.18219
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.08703

Collected Steps per Second: 8,841.02841
Overall Steps per Second: 7,708.89941

Timestep Collection Time: 5.65839
Timestep Consumption Time: 0.83099
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.48938

Cumulative Model Updates: 25,666
Cumulative Timesteps: 428,136,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 428136668...
Checkpoint 428136668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.29151
Policy Entropy: 1.01186
Value Function Loss: 1.94378

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16841
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 8,553.49504
Overall Steps per Second: 7,475.38393

Timestep Collection Time: 5.84884
Timestep Consumption Time: 0.84353
PPO Batch Consumption Time: 0.05041
Total Iteration Time: 6.69237

Cumulative Model Updates: 25,669
Cumulative Timesteps: 428,186,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.42945
Policy Entropy: 1.01775
Value Function Loss: 2.01494

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 8,617.28987
Overall Steps per Second: 7,583.29082

Timestep Collection Time: 5.80438
Timestep Consumption Time: 0.79144
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.59582

Cumulative Model Updates: 25,672
Cumulative Timesteps: 428,236,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 428236714...
Checkpoint 428236714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.65864
Policy Entropy: 1.01665
Value Function Loss: 1.99583

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 8,734.03285
Overall Steps per Second: 7,595.75449

Timestep Collection Time: 5.72702
Timestep Consumption Time: 0.85824
PPO Batch Consumption Time: 0.04602
Total Iteration Time: 6.58526

Cumulative Model Updates: 25,675
Cumulative Timesteps: 428,286,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.28341
Policy Entropy: 1.02273
Value Function Loss: 1.95724

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 8,520.75093
Overall Steps per Second: 7,559.82731

Timestep Collection Time: 5.87014
Timestep Consumption Time: 0.74615
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.61629

Cumulative Model Updates: 25,678
Cumulative Timesteps: 428,336,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 428336752...
Checkpoint 428336752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.88305
Policy Entropy: 1.01499
Value Function Loss: 1.92916

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 8,820.68929
Overall Steps per Second: 7,624.50160

Timestep Collection Time: 5.67053
Timestep Consumption Time: 0.88963
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.56017

Cumulative Model Updates: 25,681
Cumulative Timesteps: 428,386,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.94570
Policy Entropy: 1.02293
Value Function Loss: 1.91652

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 8,700.34244
Overall Steps per Second: 7,619.34294

Timestep Collection Time: 5.75012
Timestep Consumption Time: 0.81580
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.56592

Cumulative Model Updates: 25,684
Cumulative Timesteps: 428,436,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 428436798...
Checkpoint 428436798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.76118
Policy Entropy: 1.01173
Value Function Loss: 1.81336

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.07338
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 8,597.74324
Overall Steps per Second: 7,545.27429

Timestep Collection Time: 5.81850
Timestep Consumption Time: 0.81161
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.63011

Cumulative Model Updates: 25,687
Cumulative Timesteps: 428,486,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.99810
Policy Entropy: 1.01029
Value Function Loss: 1.67098

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.18185
Policy Update Magnitude: 0.07133
Value Function Update Magnitude: 0.08357

Collected Steps per Second: 8,831.17919
Overall Steps per Second: 7,658.43133

Timestep Collection Time: 5.66380
Timestep Consumption Time: 0.86731
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.53110

Cumulative Model Updates: 25,690
Cumulative Timesteps: 428,536,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 428536842...
Checkpoint 428536842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.52928
Policy Entropy: 1.01619
Value Function Loss: 1.69718

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.19497
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 8,995.85633
Overall Steps per Second: 7,831.53660

Timestep Collection Time: 5.56034
Timestep Consumption Time: 0.82666
PPO Batch Consumption Time: 0.04689
Total Iteration Time: 6.38700

Cumulative Model Updates: 25,693
Cumulative Timesteps: 428,586,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.27802
Policy Entropy: 1.02883
Value Function Loss: 1.87182

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.06090

Collected Steps per Second: 9,314.87521
Overall Steps per Second: 8,101.25591

Timestep Collection Time: 5.36905
Timestep Consumption Time: 0.80432
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.17336

Cumulative Model Updates: 25,696
Cumulative Timesteps: 428,636,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 428636874...
Checkpoint 428636874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.49582
Policy Entropy: 1.02561
Value Function Loss: 1.89236

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.06076

Collected Steps per Second: 8,968.85037
Overall Steps per Second: 7,755.76389

Timestep Collection Time: 5.57507
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.04952
Total Iteration Time: 6.44708

Cumulative Model Updates: 25,699
Cumulative Timesteps: 428,686,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.38272
Policy Entropy: 1.03439
Value Function Loss: 1.84494

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.06274

Collected Steps per Second: 8,746.40908
Overall Steps per Second: 7,713.21465

Timestep Collection Time: 5.71709
Timestep Consumption Time: 0.76581
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.48290

Cumulative Model Updates: 25,702
Cumulative Timesteps: 428,736,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 428736880...
Checkpoint 428736880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.69349
Policy Entropy: 1.02637
Value Function Loss: 1.73615

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.07857

Collected Steps per Second: 8,602.34403
Overall Steps per Second: 7,419.29984

Timestep Collection Time: 5.81516
Timestep Consumption Time: 0.92726
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.74242

Cumulative Model Updates: 25,705
Cumulative Timesteps: 428,786,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.75584
Policy Entropy: 1.03735
Value Function Loss: 1.81301

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.06704
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 8,995.15665
Overall Steps per Second: 7,778.54276

Timestep Collection Time: 5.55966
Timestep Consumption Time: 0.86957
PPO Batch Consumption Time: 0.04815
Total Iteration Time: 6.42922

Cumulative Model Updates: 25,708
Cumulative Timesteps: 428,836,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 428836914...
Checkpoint 428836914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.05117
Policy Entropy: 1.02668
Value Function Loss: 1.84585

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.17463
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.10265

Collected Steps per Second: 8,943.19963
Overall Steps per Second: 7,890.40412

Timestep Collection Time: 5.59285
Timestep Consumption Time: 0.74624
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.33909

Cumulative Model Updates: 25,711
Cumulative Timesteps: 428,886,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.47007
Policy Entropy: 1.04035
Value Function Loss: 1.97985

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.17244
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 8,900.21818
Overall Steps per Second: 7,652.86513

Timestep Collection Time: 5.62099
Timestep Consumption Time: 0.91617
PPO Batch Consumption Time: 0.04967
Total Iteration Time: 6.53716

Cumulative Model Updates: 25,714
Cumulative Timesteps: 428,936,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 428936960...
Checkpoint 428936960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.78274
Policy Entropy: 1.04241
Value Function Loss: 2.03008

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.20031
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.09930

Collected Steps per Second: 8,865.36768
Overall Steps per Second: 7,855.02063

Timestep Collection Time: 5.64060
Timestep Consumption Time: 0.72552
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.36612

Cumulative Model Updates: 25,717
Cumulative Timesteps: 428,986,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.18248
Policy Entropy: 1.03014
Value Function Loss: 1.98240

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 8,832.39160
Overall Steps per Second: 7,660.83304

Timestep Collection Time: 5.66279
Timestep Consumption Time: 0.86600
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.52879

Cumulative Model Updates: 25,720
Cumulative Timesteps: 429,036,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 429036982...
Checkpoint 429036982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.37903
Policy Entropy: 1.00729
Value Function Loss: 1.95727

Mean KL Divergence: 0.04608
SB3 Clip Fraction: 0.25363
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.09492

Collected Steps per Second: 8,824.31259
Overall Steps per Second: 7,790.42419

Timestep Collection Time: 5.66843
Timestep Consumption Time: 0.75227
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.42070

Cumulative Model Updates: 25,723
Cumulative Timesteps: 429,087,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.28715
Policy Entropy: 1.05643
Value Function Loss: 1.89071

Mean KL Divergence: 0.03948
SB3 Clip Fraction: 0.24546
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.08491

Collected Steps per Second: 8,563.26133
Overall Steps per Second: 7,363.14987

Timestep Collection Time: 5.84100
Timestep Consumption Time: 0.95202
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.79302

Cumulative Model Updates: 25,726
Cumulative Timesteps: 429,137,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 429137020...
Checkpoint 429137020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.04492
Policy Entropy: 1.00413
Value Function Loss: 1.91702

Mean KL Divergence: 0.09860
SB3 Clip Fraction: 0.38873
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.08286

Collected Steps per Second: 9,085.95497
Overall Steps per Second: 7,788.23466

Timestep Collection Time: 5.50322
Timestep Consumption Time: 0.91698
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.42020

Cumulative Model Updates: 25,729
Cumulative Timesteps: 429,187,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.41511
Policy Entropy: 1.03034
Value Function Loss: 1.67068

Mean KL Divergence: 0.05892
SB3 Clip Fraction: 0.31935
Policy Update Magnitude: 0.04382
Value Function Update Magnitude: 0.07000

Collected Steps per Second: 8,721.62075
Overall Steps per Second: 7,581.50298

Timestep Collection Time: 5.73426
Timestep Consumption Time: 0.86233
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.59658

Cumulative Model Updates: 25,732
Cumulative Timesteps: 429,237,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 429237034...
Checkpoint 429237034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.92616
Policy Entropy: 1.01177
Value Function Loss: 1.73268

Mean KL Divergence: 0.06699
SB3 Clip Fraction: 0.32055
Policy Update Magnitude: 0.03753
Value Function Update Magnitude: 0.06582

Collected Steps per Second: 8,843.08864
Overall Steps per Second: 7,650.49916

Timestep Collection Time: 5.65662
Timestep Consumption Time: 0.88178
PPO Batch Consumption Time: 0.04406
Total Iteration Time: 6.53840

Cumulative Model Updates: 25,735
Cumulative Timesteps: 429,287,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.99624
Policy Entropy: 1.04475
Value Function Loss: 1.70599

Mean KL Divergence: 0.05120
SB3 Clip Fraction: 0.29277
Policy Update Magnitude: 0.04003
Value Function Update Magnitude: 0.07620

Collected Steps per Second: 8,834.65375
Overall Steps per Second: 7,762.25842

Timestep Collection Time: 5.66270
Timestep Consumption Time: 0.78233
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.44503

Cumulative Model Updates: 25,738
Cumulative Timesteps: 429,337,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 429337084...
Checkpoint 429337084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.65399
Policy Entropy: 1.02413
Value Function Loss: 1.77416

Mean KL Divergence: 0.03607
SB3 Clip Fraction: 0.21979
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.07237

Collected Steps per Second: 8,976.52792
Overall Steps per Second: 7,788.27903

Timestep Collection Time: 5.57164
Timestep Consumption Time: 0.85006
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 6.42170

Cumulative Model Updates: 25,741
Cumulative Timesteps: 429,387,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.17792
Policy Entropy: 1.04383
Value Function Loss: 1.65845

Mean KL Divergence: 0.03432
SB3 Clip Fraction: 0.23036
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 9,388.42488
Overall Steps per Second: 8,151.91779

Timestep Collection Time: 5.32656
Timestep Consumption Time: 0.80795
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 6.13451

Cumulative Model Updates: 25,744
Cumulative Timesteps: 429,437,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 429437106...
Checkpoint 429437106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.91910
Policy Entropy: 1.04265
Value Function Loss: 1.72374

Mean KL Divergence: 0.02467
SB3 Clip Fraction: 0.20716
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.05833

Collected Steps per Second: 9,088.98268
Overall Steps per Second: 7,937.42083

Timestep Collection Time: 5.50293
Timestep Consumption Time: 0.79837
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.30129

Cumulative Model Updates: 25,747
Cumulative Timesteps: 429,487,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.25239
Policy Entropy: 1.02745
Value Function Loss: 1.64897

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.06116

Collected Steps per Second: 9,100.02502
Overall Steps per Second: 7,867.37878

Timestep Collection Time: 5.49757
Timestep Consumption Time: 0.86135
PPO Batch Consumption Time: 0.04763
Total Iteration Time: 6.35892

Cumulative Model Updates: 25,750
Cumulative Timesteps: 429,537,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 429537150...
Checkpoint 429537150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.73608
Policy Entropy: 1.00804
Value Function Loss: 1.72598

Mean KL Divergence: 0.03576
SB3 Clip Fraction: 0.21611
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.07923

Collected Steps per Second: 9,129.42115
Overall Steps per Second: 7,911.12268

Timestep Collection Time: 5.47987
Timestep Consumption Time: 0.84389
PPO Batch Consumption Time: 0.03948
Total Iteration Time: 6.32375

Cumulative Model Updates: 25,753
Cumulative Timesteps: 429,587,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.23229
Policy Entropy: 1.01653
Value Function Loss: 1.70949

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.08420

Collected Steps per Second: 9,313.37573
Overall Steps per Second: 8,048.14213

Timestep Collection Time: 5.37120
Timestep Consumption Time: 0.84440
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.21560

Cumulative Model Updates: 25,756
Cumulative Timesteps: 429,637,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 429637202...
Checkpoint 429637202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.51320
Policy Entropy: 1.02601
Value Function Loss: 1.77123

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 8,944.84828
Overall Steps per Second: 7,710.41548

Timestep Collection Time: 5.59093
Timestep Consumption Time: 0.89510
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.48603

Cumulative Model Updates: 25,759
Cumulative Timesteps: 429,687,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.18008
Policy Entropy: 1.00600
Value Function Loss: 1.80525

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 8,921.44602
Overall Steps per Second: 7,799.88854

Timestep Collection Time: 5.60582
Timestep Consumption Time: 0.80607
PPO Batch Consumption Time: 0.05196
Total Iteration Time: 6.41189

Cumulative Model Updates: 25,762
Cumulative Timesteps: 429,737,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 429737224...
Checkpoint 429737224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.97269
Policy Entropy: 0.98092
Value Function Loss: 1.82913

Mean KL Divergence: 0.04435
SB3 Clip Fraction: 0.29199
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 8,339.52221
Overall Steps per Second: 7,251.48540

Timestep Collection Time: 5.99867
Timestep Consumption Time: 0.90006
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.89872

Cumulative Model Updates: 25,765
Cumulative Timesteps: 429,787,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.39763
Policy Entropy: 0.99549
Value Function Loss: 1.73501

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.16237
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.08208

Collected Steps per Second: 9,016.35971
Overall Steps per Second: 7,795.85331

Timestep Collection Time: 5.54792
Timestep Consumption Time: 0.86857
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.41649

Cumulative Model Updates: 25,768
Cumulative Timesteps: 429,837,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 429837272...
Checkpoint 429837272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.07403
Policy Entropy: 1.01831
Value Function Loss: 1.67017

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.21470
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.08224

Collected Steps per Second: 8,818.69814
Overall Steps per Second: 7,814.48155

Timestep Collection Time: 5.67022
Timestep Consumption Time: 0.72866
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.39889

Cumulative Model Updates: 25,771
Cumulative Timesteps: 429,887,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.51304
Policy Entropy: 1.00308
Value Function Loss: 1.56421

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.18139
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 8,807.19124
Overall Steps per Second: 7,702.35155

Timestep Collection Time: 5.68013
Timestep Consumption Time: 0.81477
PPO Batch Consumption Time: 0.04054
Total Iteration Time: 6.49490

Cumulative Model Updates: 25,774
Cumulative Timesteps: 429,937,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 429937302...
Checkpoint 429937302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.34619
Policy Entropy: 0.99821
Value Function Loss: 1.59864

Mean KL Divergence: 0.03386
SB3 Clip Fraction: 0.21449
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 8,729.41543
Overall Steps per Second: 7,672.80401

Timestep Collection Time: 5.72776
Timestep Consumption Time: 0.78876
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.51652

Cumulative Model Updates: 25,777
Cumulative Timesteps: 429,987,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.89013
Policy Entropy: 1.02543
Value Function Loss: 1.77133

Mean KL Divergence: 0.02819
SB3 Clip Fraction: 0.22465
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 8,848.27522
Overall Steps per Second: 7,658.90486

Timestep Collection Time: 5.65285
Timestep Consumption Time: 0.87785
PPO Batch Consumption Time: 0.04049
Total Iteration Time: 6.53070

Cumulative Model Updates: 25,780
Cumulative Timesteps: 430,037,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 430037320...
Checkpoint 430037320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.88921
Policy Entropy: 1.02205
Value Function Loss: 1.75868

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.20956
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.08508

Collected Steps per Second: 8,586.60828
Overall Steps per Second: 7,510.64820

Timestep Collection Time: 5.82349
Timestep Consumption Time: 0.83426
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.65775

Cumulative Model Updates: 25,783
Cumulative Timesteps: 430,087,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.63876
Policy Entropy: 1.00332
Value Function Loss: 1.82546

Mean KL Divergence: 0.03966
SB3 Clip Fraction: 0.20542
Policy Update Magnitude: 0.06583
Value Function Update Magnitude: 0.08854

Collected Steps per Second: 8,737.71598
Overall Steps per Second: 7,705.97232

Timestep Collection Time: 5.72255
Timestep Consumption Time: 0.76619
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.48873

Cumulative Model Updates: 25,786
Cumulative Timesteps: 430,137,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 430137326...
Checkpoint 430137326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.93722
Policy Entropy: 1.01983
Value Function Loss: 1.63815

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.19855
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.08911

Collected Steps per Second: 8,709.26093
Overall Steps per Second: 7,622.85097

Timestep Collection Time: 5.74400
Timestep Consumption Time: 0.81864
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.56264

Cumulative Model Updates: 25,789
Cumulative Timesteps: 430,187,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.34010
Policy Entropy: 1.01855
Value Function Loss: 1.69917

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.18546
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.07663

Collected Steps per Second: 8,927.50643
Overall Steps per Second: 7,758.97559

Timestep Collection Time: 5.60112
Timestep Consumption Time: 0.84355
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 6.44467

Cumulative Model Updates: 25,792
Cumulative Timesteps: 430,237,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 430237356...
Checkpoint 430237356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.06152
Policy Entropy: 1.00700
Value Function Loss: 1.67402

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.07562

Collected Steps per Second: 9,058.57315
Overall Steps per Second: 7,877.35228

Timestep Collection Time: 5.52228
Timestep Consumption Time: 0.82807
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 6.35036

Cumulative Model Updates: 25,795
Cumulative Timesteps: 430,287,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.70049
Policy Entropy: 1.00258
Value Function Loss: 1.75482

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 9,009.71110
Overall Steps per Second: 7,804.00125

Timestep Collection Time: 5.55223
Timestep Consumption Time: 0.85781
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 6.41005

Cumulative Model Updates: 25,798
Cumulative Timesteps: 430,337,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 430337404...
Checkpoint 430337404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.95747
Policy Entropy: 0.99832
Value Function Loss: 1.81669

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.19710
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.07359

Collected Steps per Second: 8,688.60168
Overall Steps per Second: 7,614.55546

Timestep Collection Time: 5.75674
Timestep Consumption Time: 0.81200
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.56874

Cumulative Model Updates: 25,801
Cumulative Timesteps: 430,387,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.99714
Policy Entropy: 1.01148
Value Function Loss: 1.78200

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.18376
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 8,918.32796
Overall Steps per Second: 7,723.30083

Timestep Collection Time: 5.60845
Timestep Consumption Time: 0.86780
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.47625

Cumulative Model Updates: 25,804
Cumulative Timesteps: 430,437,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 430437440...
Checkpoint 430437440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.38342
Policy Entropy: 1.00724
Value Function Loss: 1.72504

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.08313

Collected Steps per Second: 8,934.75540
Overall Steps per Second: 7,794.67695

Timestep Collection Time: 5.59814
Timestep Consumption Time: 0.81880
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.41694

Cumulative Model Updates: 25,807
Cumulative Timesteps: 430,487,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.55839
Policy Entropy: 1.00460
Value Function Loss: 1.75634

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.08554

Collected Steps per Second: 9,119.40724
Overall Steps per Second: 7,919.69387

Timestep Collection Time: 5.48632
Timestep Consumption Time: 0.83109
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.31742

Cumulative Model Updates: 25,810
Cumulative Timesteps: 430,537,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 430537490...
Checkpoint 430537490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.73059
Policy Entropy: 1.00116
Value Function Loss: 1.69464

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 8,818.82645
Overall Steps per Second: 7,678.80548

Timestep Collection Time: 5.67196
Timestep Consumption Time: 0.84208
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 6.51403

Cumulative Model Updates: 25,813
Cumulative Timesteps: 430,587,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.34106
Policy Entropy: 0.99571
Value Function Loss: 1.72406

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 8,538.13015
Overall Steps per Second: 7,566.22164

Timestep Collection Time: 5.85913
Timestep Consumption Time: 0.75263
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.61175

Cumulative Model Updates: 25,816
Cumulative Timesteps: 430,637,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 430637536...
Checkpoint 430637536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.59374
Policy Entropy: 0.99665
Value Function Loss: 1.68616

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.09693

Collected Steps per Second: 8,771.40074
Overall Steps per Second: 7,644.88689

Timestep Collection Time: 5.70331
Timestep Consumption Time: 0.84041
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 6.54372

Cumulative Model Updates: 25,819
Cumulative Timesteps: 430,687,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.38744
Policy Entropy: 0.99265
Value Function Loss: 1.79907

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 8,723.43357
Overall Steps per Second: 7,593.72010

Timestep Collection Time: 5.73421
Timestep Consumption Time: 0.85308
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.58729

Cumulative Model Updates: 25,822
Cumulative Timesteps: 430,737,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 430737584...
Checkpoint 430737584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.12693
Policy Entropy: 1.00174
Value Function Loss: 1.88661

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.18242
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 8,719.15468
Overall Steps per Second: 7,688.38763

Timestep Collection Time: 5.73634
Timestep Consumption Time: 0.76906
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.50540

Cumulative Model Updates: 25,825
Cumulative Timesteps: 430,787,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.32502
Policy Entropy: 1.02092
Value Function Loss: 1.75337

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.22476
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.11347

Collected Steps per Second: 8,914.11787
Overall Steps per Second: 7,640.11075

Timestep Collection Time: 5.60953
Timestep Consumption Time: 0.93540
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.54493

Cumulative Model Updates: 25,828
Cumulative Timesteps: 430,837,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 430837604...
Checkpoint 430837604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.16901
Policy Entropy: 1.00180
Value Function Loss: 1.72644

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 8,557.70518
Overall Steps per Second: 7,514.59976

Timestep Collection Time: 5.84456
Timestep Consumption Time: 0.81129
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.65584

Cumulative Model Updates: 25,831
Cumulative Timesteps: 430,887,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.90251
Policy Entropy: 1.01560
Value Function Loss: 1.76214

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.17001
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 8,998.78188
Overall Steps per Second: 7,833.44147

Timestep Collection Time: 5.55764
Timestep Consumption Time: 0.82678
PPO Batch Consumption Time: 0.04707
Total Iteration Time: 6.38442

Cumulative Model Updates: 25,834
Cumulative Timesteps: 430,937,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 430937632...
Checkpoint 430937632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.13780
Policy Entropy: 1.02697
Value Function Loss: 1.81079

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.19679
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 8,346.09209
Overall Steps per Second: 7,354.00682

Timestep Collection Time: 5.99346
Timestep Consumption Time: 0.80854
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.80201

Cumulative Model Updates: 25,837
Cumulative Timesteps: 430,987,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.02524
Policy Entropy: 1.01773
Value Function Loss: 1.84905

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16785
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 9,008.68807
Overall Steps per Second: 7,919.12926

Timestep Collection Time: 5.55242
Timestep Consumption Time: 0.76393
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.31635

Cumulative Model Updates: 25,840
Cumulative Timesteps: 431,037,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 431037674...
Checkpoint 431037674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.33424
Policy Entropy: 1.00910
Value Function Loss: 1.75911

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.17403
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 8,532.49875
Overall Steps per Second: 7,433.90873

Timestep Collection Time: 5.86206
Timestep Consumption Time: 0.86630
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.72836

Cumulative Model Updates: 25,843
Cumulative Timesteps: 431,087,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.39451
Policy Entropy: 0.99272
Value Function Loss: 1.76801

Mean KL Divergence: 0.03309
SB3 Clip Fraction: 0.24243
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08817

Collected Steps per Second: 8,788.01047
Overall Steps per Second: 7,626.87652

Timestep Collection Time: 5.68980
Timestep Consumption Time: 0.86623
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 6.55603

Cumulative Model Updates: 25,846
Cumulative Timesteps: 431,137,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 431137694...
Checkpoint 431137694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.30415
Policy Entropy: 1.02822
Value Function Loss: 1.57474

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16391
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.08536

Collected Steps per Second: 8,843.42866
Overall Steps per Second: 7,631.96912

Timestep Collection Time: 5.65437
Timestep Consumption Time: 0.89755
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.55191

Cumulative Model Updates: 25,849
Cumulative Timesteps: 431,187,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.11092
Policy Entropy: 1.02076
Value Function Loss: 1.53135

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.17048
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.07853

Collected Steps per Second: 8,771.26929
Overall Steps per Second: 7,572.58493

Timestep Collection Time: 5.70111
Timestep Consumption Time: 0.90244
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 6.60356

Cumulative Model Updates: 25,852
Cumulative Timesteps: 431,237,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 431237704...
Checkpoint 431237704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.20067
Policy Entropy: 1.00753
Value Function Loss: 1.64438

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.21049
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.07704

Collected Steps per Second: 9,054.00755
Overall Steps per Second: 7,912.17661

Timestep Collection Time: 5.52418
Timestep Consumption Time: 0.79721
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.32140

Cumulative Model Updates: 25,855
Cumulative Timesteps: 431,287,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.48795
Policy Entropy: 0.99334
Value Function Loss: 1.86525

Mean KL Divergence: 0.03667
SB3 Clip Fraction: 0.24969
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 8,875.99097
Overall Steps per Second: 7,667.00200

Timestep Collection Time: 5.63633
Timestep Consumption Time: 0.88878
PPO Batch Consumption Time: 0.04881
Total Iteration Time: 6.52511

Cumulative Model Updates: 25,858
Cumulative Timesteps: 431,337,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 431337748...
Checkpoint 431337748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.03132
Policy Entropy: 1.01614
Value Function Loss: 1.91061

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.16800
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.07895

Collected Steps per Second: 9,063.38771
Overall Steps per Second: 7,887.20592

Timestep Collection Time: 5.51736
Timestep Consumption Time: 0.82278
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.34014

Cumulative Model Updates: 25,861
Cumulative Timesteps: 431,387,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.56017
Policy Entropy: 1.01499
Value Function Loss: 1.74449

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.18167
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.07958

Collected Steps per Second: 9,089.56372
Overall Steps per Second: 7,911.08218

Timestep Collection Time: 5.50235
Timestep Consumption Time: 0.81966
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 6.32202

Cumulative Model Updates: 25,864
Cumulative Timesteps: 431,437,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 431437768...
Checkpoint 431437768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.12122
Policy Entropy: 0.98760
Value Function Loss: 1.61076

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.20489
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 8,867.45036
Overall Steps per Second: 7,674.84279

Timestep Collection Time: 5.63928
Timestep Consumption Time: 0.87630
PPO Batch Consumption Time: 0.04876
Total Iteration Time: 6.51557

Cumulative Model Updates: 25,867
Cumulative Timesteps: 431,487,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.73825
Policy Entropy: 1.00899
Value Function Loss: 1.63684

Mean KL Divergence: 0.03413
SB3 Clip Fraction: 0.23089
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 8,504.37908
Overall Steps per Second: 7,396.46972

Timestep Collection Time: 5.88191
Timestep Consumption Time: 0.88105
PPO Batch Consumption Time: 0.04877
Total Iteration Time: 6.76296

Cumulative Model Updates: 25,870
Cumulative Timesteps: 431,537,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 431537796...
Checkpoint 431537796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.67823
Policy Entropy: 1.01163
Value Function Loss: 1.66102

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.22303
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 9,048.89018
Overall Steps per Second: 7,839.55205

Timestep Collection Time: 5.52775
Timestep Consumption Time: 0.85272
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.38047

Cumulative Model Updates: 25,873
Cumulative Timesteps: 431,587,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.55006
Policy Entropy: 1.00083
Value Function Loss: 1.62794

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.06918

Collected Steps per Second: 8,672.47403
Overall Steps per Second: 7,498.63401

Timestep Collection Time: 5.76837
Timestep Consumption Time: 0.90298
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.67135

Cumulative Model Updates: 25,876
Cumulative Timesteps: 431,637,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 431637842...
Checkpoint 431637842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.23124
Policy Entropy: 0.98228
Value Function Loss: 1.65465

Mean KL Divergence: 0.03899
SB3 Clip Fraction: 0.25373
Policy Update Magnitude: 0.03924
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 9,004.89923
Overall Steps per Second: 7,876.52350

Timestep Collection Time: 5.55520
Timestep Consumption Time: 0.79583
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.35103

Cumulative Model Updates: 25,879
Cumulative Timesteps: 431,687,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.17617
Policy Entropy: 0.99782
Value Function Loss: 1.67307

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.07962

Collected Steps per Second: 8,575.96108
Overall Steps per Second: 7,453.90326

Timestep Collection Time: 5.83398
Timestep Consumption Time: 0.87821
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 6.71219

Cumulative Model Updates: 25,882
Cumulative Timesteps: 431,737,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 431737898...
Checkpoint 431737898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.31770
Policy Entropy: 1.00243
Value Function Loss: 1.75116

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.09719

Collected Steps per Second: 8,530.42306
Overall Steps per Second: 7,473.47862

Timestep Collection Time: 5.86348
Timestep Consumption Time: 0.82925
PPO Batch Consumption Time: 0.04337
Total Iteration Time: 6.69273

Cumulative Model Updates: 25,885
Cumulative Timesteps: 431,787,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.74248
Policy Entropy: 0.99386
Value Function Loss: 1.66092

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 8,787.56171
Overall Steps per Second: 7,643.76790

Timestep Collection Time: 5.69259
Timestep Consumption Time: 0.85182
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 6.54442

Cumulative Model Updates: 25,888
Cumulative Timesteps: 431,837,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 431837940...
Checkpoint 431837940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.43734
Policy Entropy: 0.99886
Value Function Loss: 1.54163

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.10392

Collected Steps per Second: 8,740.68827
Overall Steps per Second: 7,635.44318

Timestep Collection Time: 5.72312
Timestep Consumption Time: 0.82843
PPO Batch Consumption Time: 0.04666
Total Iteration Time: 6.55155

Cumulative Model Updates: 25,891
Cumulative Timesteps: 431,887,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.19622
Policy Entropy: 0.99862
Value Function Loss: 1.50152

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.08865

Collected Steps per Second: 8,794.71622
Overall Steps per Second: 7,805.44318

Timestep Collection Time: 5.68614
Timestep Consumption Time: 0.72067
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.40681

Cumulative Model Updates: 25,894
Cumulative Timesteps: 431,937,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 431937972...
Checkpoint 431937972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.95855
Policy Entropy: 1.00118
Value Function Loss: 1.57178

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 8,603.76259
Overall Steps per Second: 7,453.40556

Timestep Collection Time: 5.81374
Timestep Consumption Time: 0.89729
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.71103

Cumulative Model Updates: 25,897
Cumulative Timesteps: 431,987,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.30995
Policy Entropy: 0.97021
Value Function Loss: 1.59166

Mean KL Divergence: 0.04448
SB3 Clip Fraction: 0.27053
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 8,957.03640
Overall Steps per Second: 7,793.82092

Timestep Collection Time: 5.58421
Timestep Consumption Time: 0.83343
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 6.41765

Cumulative Model Updates: 25,900
Cumulative Timesteps: 432,038,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432038010...
Checkpoint 432038010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.05303
Policy Entropy: 0.99918
Value Function Loss: 1.58715

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.20589
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 8,969.65890
Overall Steps per Second: 7,816.45573

Timestep Collection Time: 5.57591
Timestep Consumption Time: 0.82264
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.39855

Cumulative Model Updates: 25,903
Cumulative Timesteps: 432,088,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.56377
Policy Entropy: 0.98199
Value Function Loss: 1.56221

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.19489
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 9,026.49038
Overall Steps per Second: 7,878.90093

Timestep Collection Time: 5.54191
Timestep Consumption Time: 0.80720
PPO Batch Consumption Time: 0.04458
Total Iteration Time: 6.34911

Cumulative Model Updates: 25,906
Cumulative Timesteps: 432,138,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 432138048...
Checkpoint 432138048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.26534
Policy Entropy: 0.98556
Value Function Loss: 1.58544

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.18384
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.06594

Collected Steps per Second: 8,960.79073
Overall Steps per Second: 7,902.23667

Timestep Collection Time: 5.58031
Timestep Consumption Time: 0.74752
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.32783

Cumulative Model Updates: 25,909
Cumulative Timesteps: 432,188,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.72806
Policy Entropy: 0.98711
Value Function Loss: 1.67958

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16321
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 8,889.95820
Overall Steps per Second: 7,728.42684

Timestep Collection Time: 5.62522
Timestep Consumption Time: 0.84543
PPO Batch Consumption Time: 0.04400
Total Iteration Time: 6.47066

Cumulative Model Updates: 25,912
Cumulative Timesteps: 432,238,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 432238060...
Checkpoint 432238060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.25458
Policy Entropy: 1.00102
Value Function Loss: 1.67205

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.05691

Collected Steps per Second: 8,821.54282
Overall Steps per Second: 7,746.47076

Timestep Collection Time: 5.67066
Timestep Consumption Time: 0.78699
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.45765

Cumulative Model Updates: 25,915
Cumulative Timesteps: 432,288,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.23188
Policy Entropy: 1.00690
Value Function Loss: 1.78900

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 9,265.08805
Overall Steps per Second: 7,981.57688

Timestep Collection Time: 5.39833
Timestep Consumption Time: 0.86810
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.26643

Cumulative Model Updates: 25,918
Cumulative Timesteps: 432,338,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 432338100...
Checkpoint 432338100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.43541
Policy Entropy: 1.02242
Value Function Loss: 1.80375

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16807
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 8,915.64811
Overall Steps per Second: 7,733.82324

Timestep Collection Time: 5.60946
Timestep Consumption Time: 0.85720
PPO Batch Consumption Time: 0.04597
Total Iteration Time: 6.46666

Cumulative Model Updates: 25,921
Cumulative Timesteps: 432,388,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.36848
Policy Entropy: 1.02000
Value Function Loss: 1.85073

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15248
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.07179

Collected Steps per Second: 8,857.31199
Overall Steps per Second: 7,807.42196

Timestep Collection Time: 5.64596
Timestep Consumption Time: 0.75923
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 6.40519

Cumulative Model Updates: 25,924
Cumulative Timesteps: 432,438,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 432438120...
Checkpoint 432438120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.81724
Policy Entropy: 1.02238
Value Function Loss: 1.78588

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 8,684.15801
Overall Steps per Second: 7,541.80158

Timestep Collection Time: 5.75876
Timestep Consumption Time: 0.87228
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 6.63104

Cumulative Model Updates: 25,927
Cumulative Timesteps: 432,488,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.25783
Policy Entropy: 1.01216
Value Function Loss: 1.71981

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 8,925.34800
Overall Steps per Second: 7,771.42842

Timestep Collection Time: 5.60516
Timestep Consumption Time: 0.83227
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.43743

Cumulative Model Updates: 25,930
Cumulative Timesteps: 432,538,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 432538158...
Checkpoint 432538158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.40327
Policy Entropy: 1.01457
Value Function Loss: 1.76866

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.06813
Value Function Update Magnitude: 0.05444

Collected Steps per Second: 8,767.75412
Overall Steps per Second: 7,654.65411

Timestep Collection Time: 5.70363
Timestep Consumption Time: 0.82939
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 6.53302

Cumulative Model Updates: 25,933
Cumulative Timesteps: 432,588,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.30110
Policy Entropy: 1.02150
Value Function Loss: 1.79447

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.17995
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.08339

Collected Steps per Second: 9,024.80363
Overall Steps per Second: 7,870.71276

Timestep Collection Time: 5.54317
Timestep Consumption Time: 0.81280
PPO Batch Consumption Time: 0.03991
Total Iteration Time: 6.35597

Cumulative Model Updates: 25,936
Cumulative Timesteps: 432,638,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432638192...
Checkpoint 432638192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.54426
Policy Entropy: 1.02658
Value Function Loss: 1.79523

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.06909
Value Function Update Magnitude: 0.09493

Collected Steps per Second: 8,836.70237
Overall Steps per Second: 7,811.94237

Timestep Collection Time: 5.65890
Timestep Consumption Time: 0.74233
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 6.40122

Cumulative Model Updates: 25,939
Cumulative Timesteps: 432,688,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.05913
Policy Entropy: 1.04800
Value Function Loss: 1.85119

Mean KL Divergence: 0.02983
SB3 Clip Fraction: 0.22227
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.08207

Collected Steps per Second: 8,954.39836
Overall Steps per Second: 7,730.08824

Timestep Collection Time: 5.58563
Timestep Consumption Time: 0.88467
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.47030

Cumulative Model Updates: 25,942
Cumulative Timesteps: 432,738,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 432738214...
Checkpoint 432738214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.59626
Policy Entropy: 1.03206
Value Function Loss: 1.82786

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.17995
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.07615

Collected Steps per Second: 9,192.97101
Overall Steps per Second: 8,026.46735

Timestep Collection Time: 5.44133
Timestep Consumption Time: 0.79080
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.23213

Cumulative Model Updates: 25,945
Cumulative Timesteps: 432,788,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.20304
Policy Entropy: 1.02987
Value Function Loss: 1.81947

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.19711
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 8,860.41021
Overall Steps per Second: 7,587.63370

Timestep Collection Time: 5.64511
Timestep Consumption Time: 0.94693
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 6.59204

Cumulative Model Updates: 25,948
Cumulative Timesteps: 432,838,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432838254...
Checkpoint 432838254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.19103
Policy Entropy: 1.04750
Value Function Loss: 1.64977

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.17693
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 9,027.39223
Overall Steps per Second: 7,800.47571

Timestep Collection Time: 5.54202
Timestep Consumption Time: 0.87169
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.41371

Cumulative Model Updates: 25,951
Cumulative Timesteps: 432,888,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.10723
Policy Entropy: 1.05865
Value Function Loss: 1.66077

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.18648
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 8,558.54898
Overall Steps per Second: 7,528.82255

Timestep Collection Time: 5.84515
Timestep Consumption Time: 0.79945
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 6.64460

Cumulative Model Updates: 25,954
Cumulative Timesteps: 432,938,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432938310...
Checkpoint 432938310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.19080
Policy Entropy: 1.03916
Value Function Loss: 1.60713

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 8,851.66111
Overall Steps per Second: 7,663.08766

Timestep Collection Time: 5.65069
Timestep Consumption Time: 0.87644
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.52713

Cumulative Model Updates: 25,957
Cumulative Timesteps: 432,988,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.53240
Policy Entropy: 1.03186
Value Function Loss: 1.73344

Mean KL Divergence: 0.03190
SB3 Clip Fraction: 0.22452
Policy Update Magnitude: 0.04116
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 8,852.76963
Overall Steps per Second: 7,682.29857

Timestep Collection Time: 5.64953
Timestep Consumption Time: 0.86076
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.51029

Cumulative Model Updates: 25,960
Cumulative Timesteps: 433,038,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 433038342...
Checkpoint 433038342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.91752
Policy Entropy: 1.05213
Value Function Loss: 1.69149

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.04203
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 9,319.39052
Overall Steps per Second: 8,007.70427

Timestep Collection Time: 5.36795
Timestep Consumption Time: 0.87929
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.24723

Cumulative Model Updates: 25,963
Cumulative Timesteps: 433,088,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.53137
Policy Entropy: 1.05383
Value Function Loss: 1.84482

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 9,404.10837
Overall Steps per Second: 8,092.70814

Timestep Collection Time: 5.31810
Timestep Consumption Time: 0.86178
PPO Batch Consumption Time: 0.04934
Total Iteration Time: 6.17988

Cumulative Model Updates: 25,966
Cumulative Timesteps: 433,138,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 433138380...
Checkpoint 433138380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.88322
Policy Entropy: 1.04156
Value Function Loss: 1.76153

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.17956
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 8,961.21389
Overall Steps per Second: 7,853.85352

Timestep Collection Time: 5.58273
Timestep Consumption Time: 0.78714
PPO Batch Consumption Time: 0.05085
Total Iteration Time: 6.36987

Cumulative Model Updates: 25,969
Cumulative Timesteps: 433,188,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.67790
Policy Entropy: 1.02655
Value Function Loss: 1.81847

Mean KL Divergence: 0.03155
SB3 Clip Fraction: 0.20917
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 9,011.75317
Overall Steps per Second: 7,777.17187

Timestep Collection Time: 5.55053
Timestep Consumption Time: 0.88111
PPO Batch Consumption Time: 0.05012
Total Iteration Time: 6.43164

Cumulative Model Updates: 25,972
Cumulative Timesteps: 433,238,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 433238428...
Checkpoint 433238428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.33294
Policy Entropy: 1.04735
Value Function Loss: 1.82386

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.11294

Collected Steps per Second: 8,908.43385
Overall Steps per Second: 7,724.76200

Timestep Collection Time: 5.61468
Timestep Consumption Time: 0.86034
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.47502

Cumulative Model Updates: 25,975
Cumulative Timesteps: 433,288,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.18336
Policy Entropy: 1.05016
Value Function Loss: 1.82710

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 9,103.94240
Overall Steps per Second: 7,857.73136

Timestep Collection Time: 5.49410
Timestep Consumption Time: 0.87135
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.36545

Cumulative Model Updates: 25,978
Cumulative Timesteps: 433,338,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 433338464...
Checkpoint 433338464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.16019
Policy Entropy: 1.04406
Value Function Loss: 1.81201

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.09484

Collected Steps per Second: 8,618.37874
Overall Steps per Second: 7,476.79673

Timestep Collection Time: 5.80156
Timestep Consumption Time: 0.88580
PPO Batch Consumption Time: 0.04841
Total Iteration Time: 6.68736

Cumulative Model Updates: 25,981
Cumulative Timesteps: 433,388,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.11495
Policy Entropy: 1.02591
Value Function Loss: 1.67800

Mean KL Divergence: 0.03504
SB3 Clip Fraction: 0.21848
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.10422

Collected Steps per Second: 8,959.56805
Overall Steps per Second: 7,832.66385

Timestep Collection Time: 5.58174
Timestep Consumption Time: 0.80306
PPO Batch Consumption Time: 0.04047
Total Iteration Time: 6.38480

Cumulative Model Updates: 25,984
Cumulative Timesteps: 433,438,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 433438474...
Checkpoint 433438474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.82428
Policy Entropy: 1.04498
Value Function Loss: 1.62735

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 8,998.24067
Overall Steps per Second: 7,816.20870

Timestep Collection Time: 5.55842
Timestep Consumption Time: 0.84059
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.39901

Cumulative Model Updates: 25,987
Cumulative Timesteps: 433,488,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.95462
Policy Entropy: 1.04054
Value Function Loss: 1.53155

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 8,877.78205
Overall Steps per Second: 7,769.66106

Timestep Collection Time: 5.63497
Timestep Consumption Time: 0.80367
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.43863

Cumulative Model Updates: 25,990
Cumulative Timesteps: 433,538,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 433538516...
Checkpoint 433538516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.92257
Policy Entropy: 1.01706
Value Function Loss: 1.55344

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.19811
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.11356

Collected Steps per Second: 8,982.95585
Overall Steps per Second: 7,839.00355

Timestep Collection Time: 5.56610
Timestep Consumption Time: 0.81227
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 6.37836

Cumulative Model Updates: 25,993
Cumulative Timesteps: 433,588,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.07052
Policy Entropy: 1.03067
Value Function Loss: 1.58465

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.10452

Collected Steps per Second: 8,894.65579
Overall Steps per Second: 7,718.88507

Timestep Collection Time: 5.62428
Timestep Consumption Time: 0.85671
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.48099

Cumulative Model Updates: 25,996
Cumulative Timesteps: 433,638,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 433638542...
Checkpoint 433638542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.69393
Policy Entropy: 1.03222
Value Function Loss: 1.74378

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.08668

Collected Steps per Second: 8,880.04270
Overall Steps per Second: 7,874.95503

Timestep Collection Time: 5.63286
Timestep Consumption Time: 0.71893
PPO Batch Consumption Time: 0.04013
Total Iteration Time: 6.35178

Cumulative Model Updates: 25,999
Cumulative Timesteps: 433,688,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.10811
Policy Entropy: 1.03653
Value Function Loss: 1.78196

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.08016

Collected Steps per Second: 8,870.32084
Overall Steps per Second: 7,682.80739

Timestep Collection Time: 5.63903
Timestep Consumption Time: 0.87161
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.51064

Cumulative Model Updates: 26,002
Cumulative Timesteps: 433,738,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 433738582...
Checkpoint 433738582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.36682
Policy Entropy: 1.02774
Value Function Loss: 1.85776

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.17937
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 8,522.16354
Overall Steps per Second: 7,472.87542

Timestep Collection Time: 5.86893
Timestep Consumption Time: 0.82407
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.69301

Cumulative Model Updates: 26,005
Cumulative Timesteps: 433,788,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.20839
Policy Entropy: 1.01440
Value Function Loss: 1.81657

Mean KL Divergence: 0.04452
SB3 Clip Fraction: 0.24891
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 8,990.25423
Overall Steps per Second: 7,629.72955

Timestep Collection Time: 5.56269
Timestep Consumption Time: 0.99193
PPO Batch Consumption Time: 0.04825
Total Iteration Time: 6.55462

Cumulative Model Updates: 26,008
Cumulative Timesteps: 433,838,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 433838608...
Checkpoint 433838608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.63486
Policy Entropy: 1.04345
Value Function Loss: 1.77794

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.20806
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 8,825.30028
Overall Steps per Second: 7,719.71848

Timestep Collection Time: 5.66870
Timestep Consumption Time: 0.81184
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 6.48055

Cumulative Model Updates: 26,011
Cumulative Timesteps: 433,888,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.42247
Policy Entropy: 1.04001
Value Function Loss: 1.78852

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.21113
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 8,689.11759
Overall Steps per Second: 7,697.76984

Timestep Collection Time: 5.75640
Timestep Consumption Time: 0.74133
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.49773

Cumulative Model Updates: 26,014
Cumulative Timesteps: 433,938,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 433938654...
Checkpoint 433938654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.98534
Policy Entropy: 1.03675
Value Function Loss: 1.72437

Mean KL Divergence: 0.02858
SB3 Clip Fraction: 0.20683
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 8,719.55626
Overall Steps per Second: 7,586.34749

Timestep Collection Time: 5.73538
Timestep Consumption Time: 0.85672
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.59211

Cumulative Model Updates: 26,017
Cumulative Timesteps: 433,988,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.41187
Policy Entropy: 1.04994
Value Function Loss: 1.83233

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.19277
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 8,992.53514
Overall Steps per Second: 7,834.69458

Timestep Collection Time: 5.56284
Timestep Consumption Time: 0.82210
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.38493

Cumulative Model Updates: 26,020
Cumulative Timesteps: 434,038,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 434038688...
Checkpoint 434038688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.70151
Policy Entropy: 1.04390
Value Function Loss: 1.72987

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.05232

Collected Steps per Second: 8,898.74602
Overall Steps per Second: 7,756.77101

Timestep Collection Time: 5.62057
Timestep Consumption Time: 0.82748
PPO Batch Consumption Time: 0.04567
Total Iteration Time: 6.44804

Cumulative Model Updates: 26,023
Cumulative Timesteps: 434,088,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.25929
Policy Entropy: 1.04070
Value Function Loss: 1.78181

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 9,027.89117
Overall Steps per Second: 7,868.11662

Timestep Collection Time: 5.54105
Timestep Consumption Time: 0.81676
PPO Batch Consumption Time: 0.04016
Total Iteration Time: 6.35781

Cumulative Model Updates: 26,026
Cumulative Timesteps: 434,138,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 434138728...
Checkpoint 434138728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.12966
Policy Entropy: 1.04549
Value Function Loss: 1.81405

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.06364

Collected Steps per Second: 8,868.86240
Overall Steps per Second: 7,812.94591

Timestep Collection Time: 5.63973
Timestep Consumption Time: 0.76221
PPO Batch Consumption Time: 0.04482
Total Iteration Time: 6.40194

Cumulative Model Updates: 26,029
Cumulative Timesteps: 434,188,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.81372
Policy Entropy: 1.04759
Value Function Loss: 1.86958

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.17691
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 8,688.43849
Overall Steps per Second: 7,582.79321

Timestep Collection Time: 5.75754
Timestep Consumption Time: 0.83950
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.59704

Cumulative Model Updates: 26,032
Cumulative Timesteps: 434,238,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 434238770...
Checkpoint 434238770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.33065
Policy Entropy: 1.06967
Value Function Loss: 1.85227

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.06553
Value Function Update Magnitude: 0.09796

Collected Steps per Second: 8,640.90117
Overall Steps per Second: 7,556.54985

Timestep Collection Time: 5.78967
Timestep Consumption Time: 0.83081
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.62048

Cumulative Model Updates: 26,035
Cumulative Timesteps: 434,288,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.84470
Policy Entropy: 1.06496
Value Function Loss: 1.90816

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.06957
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 8,597.07451
Overall Steps per Second: 7,476.66378

Timestep Collection Time: 5.81896
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.04811
Total Iteration Time: 6.69095

Cumulative Model Updates: 26,038
Cumulative Timesteps: 434,338,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434338824...
Checkpoint 434338824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.21302
Policy Entropy: 1.07058
Value Function Loss: 2.03764

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.07564
Value Function Update Magnitude: 0.09684

Collected Steps per Second: 8,788.35701
Overall Steps per Second: 7,652.91477

Timestep Collection Time: 5.69253
Timestep Consumption Time: 0.84459
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.53712

Cumulative Model Updates: 26,041
Cumulative Timesteps: 434,388,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.94534
Policy Entropy: 1.07132
Value Function Loss: 2.05679

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.07597
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 8,991.95293
Overall Steps per Second: 7,949.43722

Timestep Collection Time: 5.56342
Timestep Consumption Time: 0.72961
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.29302

Cumulative Model Updates: 26,044
Cumulative Timesteps: 434,438,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434438878...
Checkpoint 434438878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.24808
Policy Entropy: 1.06346
Value Function Loss: 1.93095

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.07354
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 8,762.91198
Overall Steps per Second: 7,621.80265

Timestep Collection Time: 5.70701
Timestep Consumption Time: 0.85443
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 6.56144

Cumulative Model Updates: 26,047
Cumulative Timesteps: 434,488,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.38753
Policy Entropy: 1.06836
Value Function Loss: 1.79038

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.09080

Collected Steps per Second: 8,602.28574
Overall Steps per Second: 7,566.94472

Timestep Collection Time: 5.81543
Timestep Consumption Time: 0.79569
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 6.61112

Cumulative Model Updates: 26,050
Cumulative Timesteps: 434,538,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434538914...
Checkpoint 434538914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.25218
Policy Entropy: 1.06267
Value Function Loss: 1.73241

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.07972

Collected Steps per Second: 8,824.27522
Overall Steps per Second: 7,659.52604

Timestep Collection Time: 5.66891
Timestep Consumption Time: 0.86204
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 6.53095

Cumulative Model Updates: 26,053
Cumulative Timesteps: 434,588,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.56385
Policy Entropy: 1.03736
Value Function Loss: 1.68908

Mean KL Divergence: 0.04383
SB3 Clip Fraction: 0.26661
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.07386

Collected Steps per Second: 8,769.32202
Overall Steps per Second: 7,600.08280

Timestep Collection Time: 5.70420
Timestep Consumption Time: 0.87757
PPO Batch Consumption Time: 0.04704
Total Iteration Time: 6.58177

Cumulative Model Updates: 26,056
Cumulative Timesteps: 434,638,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 434638960...
Checkpoint 434638960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.73074
Policy Entropy: 1.06234
Value Function Loss: 1.73444

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 8,383.02289
Overall Steps per Second: 7,379.10094

Timestep Collection Time: 5.96634
Timestep Consumption Time: 0.81172
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.77806

Cumulative Model Updates: 26,059
Cumulative Timesteps: 434,688,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.85607
Policy Entropy: 1.06085
Value Function Loss: 1.72659

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 8,733.00582
Overall Steps per Second: 7,507.98465

Timestep Collection Time: 5.72747
Timestep Consumption Time: 0.93451
PPO Batch Consumption Time: 0.05307
Total Iteration Time: 6.66197

Cumulative Model Updates: 26,062
Cumulative Timesteps: 434,738,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 434738994...
Checkpoint 434738994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.69594
Policy Entropy: 1.05079
Value Function Loss: 1.70641

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.17867
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.06858

Collected Steps per Second: 8,505.10480
Overall Steps per Second: 7,424.32926

Timestep Collection Time: 5.88047
Timestep Consumption Time: 0.85603
PPO Batch Consumption Time: 0.03940
Total Iteration Time: 6.73650

Cumulative Model Updates: 26,065
Cumulative Timesteps: 434,789,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.24007
Policy Entropy: 1.03388
Value Function Loss: 1.60178

Mean KL Divergence: 0.03633
SB3 Clip Fraction: 0.25021
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.07667

Collected Steps per Second: 8,978.88965
Overall Steps per Second: 7,745.67398

Timestep Collection Time: 5.57174
Timestep Consumption Time: 0.88710
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.45883

Cumulative Model Updates: 26,068
Cumulative Timesteps: 434,839,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 434839036...
Checkpoint 434839036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.77038
Policy Entropy: 1.04781
Value Function Loss: 1.65540

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.07700

Collected Steps per Second: 8,690.01424
Overall Steps per Second: 7,569.58871

Timestep Collection Time: 5.75373
Timestep Consumption Time: 0.85165
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.60538

Cumulative Model Updates: 26,071
Cumulative Timesteps: 434,889,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.05525
Policy Entropy: 1.06418
Value Function Loss: 1.64042

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.18327
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.08283

Collected Steps per Second: 9,196.41929
Overall Steps per Second: 8,042.12093

Timestep Collection Time: 5.43864
Timestep Consumption Time: 0.78062
PPO Batch Consumption Time: 0.05158
Total Iteration Time: 6.21925

Cumulative Model Updates: 26,074
Cumulative Timesteps: 434,939,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434939052...
Checkpoint 434939052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.66189
Policy Entropy: 1.05014
Value Function Loss: 1.71399

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 8,996.66386
Overall Steps per Second: 7,722.10250

Timestep Collection Time: 5.55939
Timestep Consumption Time: 0.91760
PPO Batch Consumption Time: 0.05026
Total Iteration Time: 6.47699

Cumulative Model Updates: 26,077
Cumulative Timesteps: 434,989,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.15408
Policy Entropy: 1.03687
Value Function Loss: 1.69734

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.20595
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.07806

Collected Steps per Second: 9,099.65932
Overall Steps per Second: 7,852.49320

Timestep Collection Time: 5.49669
Timestep Consumption Time: 0.87301
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.36970

Cumulative Model Updates: 26,080
Cumulative Timesteps: 435,039,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 435039086...
Checkpoint 435039086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.50361
Policy Entropy: 1.05537
Value Function Loss: 1.71783

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.08121

Collected Steps per Second: 9,340.32114
Overall Steps per Second: 8,107.65230

Timestep Collection Time: 5.35485
Timestep Consumption Time: 0.81414
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.16899

Cumulative Model Updates: 26,083
Cumulative Timesteps: 435,089,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.59029
Policy Entropy: 1.05232
Value Function Loss: 1.59291

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.18468
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 8,913.98216
Overall Steps per Second: 7,752.79421

Timestep Collection Time: 5.60961
Timestep Consumption Time: 0.84019
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.44980

Cumulative Model Updates: 26,086
Cumulative Timesteps: 435,139,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 435139106...
Checkpoint 435139106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.72329
Policy Entropy: 1.03734
Value Function Loss: 1.56674

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 8,616.92289
Overall Steps per Second: 7,625.75223

Timestep Collection Time: 5.80486
Timestep Consumption Time: 0.75450
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.55935

Cumulative Model Updates: 26,089
Cumulative Timesteps: 435,189,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.29314
Policy Entropy: 1.02565
Value Function Loss: 1.58701

Mean KL Divergence: 0.03415
SB3 Clip Fraction: 0.23261
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.07975

Collected Steps per Second: 8,489.16198
Overall Steps per Second: 7,364.98918

Timestep Collection Time: 5.89316
Timestep Consumption Time: 0.89952
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.79268

Cumulative Model Updates: 26,092
Cumulative Timesteps: 435,239,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 435239154...
Checkpoint 435239154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.97227
Policy Entropy: 1.03966
Value Function Loss: 1.78316

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.16282
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.07237

Collected Steps per Second: 8,833.17576
Overall Steps per Second: 7,799.42853

Timestep Collection Time: 5.66365
Timestep Consumption Time: 0.75067
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.41432

Cumulative Model Updates: 26,095
Cumulative Timesteps: 435,289,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.06539
Policy Entropy: 1.05052
Value Function Loss: 1.83732

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.18999
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.07533

Collected Steps per Second: 8,684.16994
Overall Steps per Second: 7,602.62607

Timestep Collection Time: 5.75968
Timestep Consumption Time: 0.81937
PPO Batch Consumption Time: 0.03988
Total Iteration Time: 6.57904

Cumulative Model Updates: 26,098
Cumulative Timesteps: 435,339,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 435339200...
Checkpoint 435339200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.88116
Policy Entropy: 1.01610
Value Function Loss: 1.84585

Mean KL Divergence: 0.03786
SB3 Clip Fraction: 0.23214
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 8,943.74318
Overall Steps per Second: 7,880.64278

Timestep Collection Time: 5.59251
Timestep Consumption Time: 0.75443
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.34694

Cumulative Model Updates: 26,101
Cumulative Timesteps: 435,389,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.56602
Policy Entropy: 1.04613
Value Function Loss: 1.75333

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.18801
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 8,867.64506
Overall Steps per Second: 7,714.49983

Timestep Collection Time: 5.63983
Timestep Consumption Time: 0.84303
PPO Batch Consumption Time: 0.03958
Total Iteration Time: 6.48286

Cumulative Model Updates: 26,104
Cumulative Timesteps: 435,439,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 435439230...
Checkpoint 435439230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.32256
Policy Entropy: 1.04368
Value Function Loss: 1.70249

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.18868
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.09597

Collected Steps per Second: 8,673.90339
Overall Steps per Second: 7,615.00199

Timestep Collection Time: 5.76580
Timestep Consumption Time: 0.80176
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 6.56756

Cumulative Model Updates: 26,107
Cumulative Timesteps: 435,489,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.35054
Policy Entropy: 1.03634
Value Function Loss: 1.63172

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.17403
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.11317

Collected Steps per Second: 8,625.24234
Overall Steps per Second: 7,620.01381

Timestep Collection Time: 5.79972
Timestep Consumption Time: 0.76510
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.56482

Cumulative Model Updates: 26,110
Cumulative Timesteps: 435,539,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 435539266...
Checkpoint 435539266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.42978
Policy Entropy: 1.01509
Value Function Loss: 1.59313

Mean KL Divergence: 0.03543
SB3 Clip Fraction: 0.24298
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 8,811.60752
Overall Steps per Second: 7,653.63624

Timestep Collection Time: 5.67456
Timestep Consumption Time: 0.85854
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 6.53310

Cumulative Model Updates: 26,113
Cumulative Timesteps: 435,589,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.97882
Policy Entropy: 1.03784
Value Function Loss: 1.70823

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.07800

Collected Steps per Second: 8,712.43969
Overall Steps per Second: 7,576.31697

Timestep Collection Time: 5.74236
Timestep Consumption Time: 0.86111
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.60347

Cumulative Model Updates: 26,116
Cumulative Timesteps: 435,639,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 435639298...
Checkpoint 435639298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.26543
Policy Entropy: 1.05108
Value Function Loss: 1.81220

Mean KL Divergence: 0.02598
SB3 Clip Fraction: 0.19810
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.08578

Collected Steps per Second: 8,802.77477
Overall Steps per Second: 7,687.66137

Timestep Collection Time: 5.68275
Timestep Consumption Time: 0.82430
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 6.50705

Cumulative Model Updates: 26,119
Cumulative Timesteps: 435,689,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.48765
Policy Entropy: 1.03028
Value Function Loss: 1.86872

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.18469
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 8,518.84595
Overall Steps per Second: 7,449.12416

Timestep Collection Time: 5.87122
Timestep Consumption Time: 0.84313
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.71435

Cumulative Model Updates: 26,122
Cumulative Timesteps: 435,739,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 435739338...
Checkpoint 435739338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.85135
Policy Entropy: 1.02180
Value Function Loss: 1.82418

Mean KL Divergence: 0.03334
SB3 Clip Fraction: 0.23621
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.07037

Collected Steps per Second: 8,566.84620
Overall Steps per Second: 7,547.98395

Timestep Collection Time: 5.83902
Timestep Consumption Time: 0.78818
PPO Batch Consumption Time: 0.04951
Total Iteration Time: 6.62720

Cumulative Model Updates: 26,125
Cumulative Timesteps: 435,789,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.22126
Policy Entropy: 1.03417
Value Function Loss: 1.65952

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 8,882.34747
Overall Steps per Second: 7,678.13428

Timestep Collection Time: 5.63072
Timestep Consumption Time: 0.88310
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.51382

Cumulative Model Updates: 26,128
Cumulative Timesteps: 435,839,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 435839374...
Checkpoint 435839374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.10746
Policy Entropy: 1.05560
Value Function Loss: 1.60916

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.18682
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 8,879.93390
Overall Steps per Second: 7,779.22629

Timestep Collection Time: 5.63112
Timestep Consumption Time: 0.79677
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 6.42789

Cumulative Model Updates: 26,131
Cumulative Timesteps: 435,889,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.99678
Policy Entropy: 1.02751
Value Function Loss: 1.58281

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.20422
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 8,695.38528
Overall Steps per Second: 7,571.06733

Timestep Collection Time: 5.75064
Timestep Consumption Time: 0.85398
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.60462

Cumulative Model Updates: 26,134
Cumulative Timesteps: 435,939,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 435939382...
Checkpoint 435939382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.62442
Policy Entropy: 1.05752
Value Function Loss: 1.60043

Mean KL Divergence: 0.03742
SB3 Clip Fraction: 0.22091
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 8,743.16619
Overall Steps per Second: 7,662.66188

Timestep Collection Time: 5.72150
Timestep Consumption Time: 0.80678
PPO Batch Consumption Time: 0.04739
Total Iteration Time: 6.52828

Cumulative Model Updates: 26,137
Cumulative Timesteps: 435,989,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.80623
Policy Entropy: 1.06147
Value Function Loss: 1.71546

Mean KL Divergence: 0.03484
SB3 Clip Fraction: 0.21807
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.07307

Collected Steps per Second: 8,762.17010
Overall Steps per Second: 7,686.97069

Timestep Collection Time: 5.70749
Timestep Consumption Time: 0.79832
PPO Batch Consumption Time: 0.04778
Total Iteration Time: 6.50581

Cumulative Model Updates: 26,140
Cumulative Timesteps: 436,039,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 436039416...
Checkpoint 436039416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.44807
Policy Entropy: 1.04758
Value Function Loss: 1.62796

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.19513
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.07734

Collected Steps per Second: 8,643.43165
Overall Steps per Second: 7,535.85555

Timestep Collection Time: 5.78566
Timestep Consumption Time: 0.85034
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.63601

Cumulative Model Updates: 26,143
Cumulative Timesteps: 436,089,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.72004
Policy Entropy: 1.03905
Value Function Loss: 1.70009

Mean KL Divergence: 0.03521
SB3 Clip Fraction: 0.23660
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.07540

Collected Steps per Second: 8,619.43286
Overall Steps per Second: 7,569.30474

Timestep Collection Time: 5.80363
Timestep Consumption Time: 0.80517
PPO Batch Consumption Time: 0.04078
Total Iteration Time: 6.60880

Cumulative Model Updates: 26,146
Cumulative Timesteps: 436,139,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 436139448...
Checkpoint 436139448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.36784
Policy Entropy: 1.05379
Value Function Loss: 1.53902

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.18043
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 8,760.67902
Overall Steps per Second: 7,634.09379

Timestep Collection Time: 5.70937
Timestep Consumption Time: 0.84255
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.55192

Cumulative Model Updates: 26,149
Cumulative Timesteps: 436,189,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.19873
Policy Entropy: 1.05455
Value Function Loss: 1.58861

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.07011

Collected Steps per Second: 8,972.42270
Overall Steps per Second: 7,795.24121

Timestep Collection Time: 5.57263
Timestep Consumption Time: 0.84154
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.41417

Cumulative Model Updates: 26,152
Cumulative Timesteps: 436,239,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 436239466...
Checkpoint 436239466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.64358
Policy Entropy: 1.04018
Value Function Loss: 1.65530

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.20264
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 8,865.32020
Overall Steps per Second: 7,808.08655

Timestep Collection Time: 5.64176
Timestep Consumption Time: 0.76391
PPO Batch Consumption Time: 0.04831
Total Iteration Time: 6.40567

Cumulative Model Updates: 26,155
Cumulative Timesteps: 436,289,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.08417
Policy Entropy: 1.05604
Value Function Loss: 1.71806

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.17133
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 8,699.68934
Overall Steps per Second: 7,592.05127

Timestep Collection Time: 5.74940
Timestep Consumption Time: 0.83881
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.58821

Cumulative Model Updates: 26,158
Cumulative Timesteps: 436,339,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 436339500...
Checkpoint 436339500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.11465
Policy Entropy: 1.05301
Value Function Loss: 1.71450

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 8,559.22609
Overall Steps per Second: 7,492.14748

Timestep Collection Time: 5.84469
Timestep Consumption Time: 0.83244
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 6.67712

Cumulative Model Updates: 26,161
Cumulative Timesteps: 436,389,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.15642
Policy Entropy: 1.04123
Value Function Loss: 1.62305

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.07761

Collected Steps per Second: 8,774.76945
Overall Steps per Second: 7,651.88819

Timestep Collection Time: 5.70066
Timestep Consumption Time: 0.83655
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.53721

Cumulative Model Updates: 26,164
Cumulative Timesteps: 436,439,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 436439548...
Checkpoint 436439548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.46839
Policy Entropy: 1.02932
Value Function Loss: 1.65299

Mean KL Divergence: 0.03195
SB3 Clip Fraction: 0.18941
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.07107

Collected Steps per Second: 8,873.31751
Overall Steps per Second: 7,637.90964

Timestep Collection Time: 5.63735
Timestep Consumption Time: 0.91182
PPO Batch Consumption Time: 0.05234
Total Iteration Time: 6.54917

Cumulative Model Updates: 26,167
Cumulative Timesteps: 436,489,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.57018
Policy Entropy: 1.04067
Value Function Loss: 1.68470

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.19280
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.07439

Collected Steps per Second: 8,848.60492
Overall Steps per Second: 7,613.67454

Timestep Collection Time: 5.65287
Timestep Consumption Time: 0.91689
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.56976

Cumulative Model Updates: 26,170
Cumulative Timesteps: 436,539,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 436539590...
Checkpoint 436539590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.03899
Policy Entropy: 1.04792
Value Function Loss: 1.68638

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.19505
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 8,456.85199
Overall Steps per Second: 7,251.51488

Timestep Collection Time: 5.91260
Timestep Consumption Time: 0.98278
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.89539

Cumulative Model Updates: 26,173
Cumulative Timesteps: 436,589,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.51066
Policy Entropy: 1.02198
Value Function Loss: 1.54358

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.19511
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.08023

Collected Steps per Second: 8,786.61321
Overall Steps per Second: 7,674.02771

Timestep Collection Time: 5.69070
Timestep Consumption Time: 0.82504
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.51574

Cumulative Model Updates: 26,176
Cumulative Timesteps: 436,639,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 436639594...
Checkpoint 436639594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.50536
Policy Entropy: 1.02638
Value Function Loss: 1.58311

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.20883
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.07769

Collected Steps per Second: 8,786.52093
Overall Steps per Second: 7,479.53736

Timestep Collection Time: 5.69327
Timestep Consumption Time: 0.99485
PPO Batch Consumption Time: 0.05806
Total Iteration Time: 6.68811

Cumulative Model Updates: 26,179
Cumulative Timesteps: 436,689,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.60963
Policy Entropy: 1.03482
Value Function Loss: 1.61180

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.07240

Collected Steps per Second: 8,370.01336
Overall Steps per Second: 7,226.32087

Timestep Collection Time: 5.97562
Timestep Consumption Time: 0.94575
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.92136

Cumulative Model Updates: 26,182
Cumulative Timesteps: 436,739,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 436739634...
Checkpoint 436739634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.60313
Policy Entropy: 1.05530
Value Function Loss: 1.80344

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 8,722.72236
Overall Steps per Second: 7,698.39703

Timestep Collection Time: 5.73537
Timestep Consumption Time: 0.76313
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.49850

Cumulative Model Updates: 26,185
Cumulative Timesteps: 436,789,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.41994
Policy Entropy: 1.04420
Value Function Loss: 1.67063

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 8,898.51023
Overall Steps per Second: 7,706.32668

Timestep Collection Time: 5.62139
Timestep Consumption Time: 0.86964
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 6.49103

Cumulative Model Updates: 26,188
Cumulative Timesteps: 436,839,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 436839684...
Checkpoint 436839684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.90152
Policy Entropy: 1.03939
Value Function Loss: 1.62196

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 9,045.31084
Overall Steps per Second: 7,782.75550

Timestep Collection Time: 5.52994
Timestep Consumption Time: 0.89709
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.42703

Cumulative Model Updates: 26,191
Cumulative Timesteps: 436,889,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.84109
Policy Entropy: 1.02896
Value Function Loss: 1.49922

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16710
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 9,432.99980
Overall Steps per Second: 8,123.03444

Timestep Collection Time: 5.30181
Timestep Consumption Time: 0.85500
PPO Batch Consumption Time: 0.05167
Total Iteration Time: 6.15681

Cumulative Model Updates: 26,194
Cumulative Timesteps: 436,939,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 436939716...
Checkpoint 436939716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.07424
Policy Entropy: 1.01524
Value Function Loss: 1.48094

Mean KL Divergence: 0.03415
SB3 Clip Fraction: 0.24490
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 8,804.49104
Overall Steps per Second: 7,681.97709

Timestep Collection Time: 5.67983
Timestep Consumption Time: 0.82995
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.50978

Cumulative Model Updates: 26,197
Cumulative Timesteps: 436,989,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.95886
Policy Entropy: 1.03226
Value Function Loss: 1.43441

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.17721
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 8,766.83997
Overall Steps per Second: 7,651.58379

Timestep Collection Time: 5.70536
Timestep Consumption Time: 0.83158
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.53695

Cumulative Model Updates: 26,200
Cumulative Timesteps: 437,039,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 437039742...
Checkpoint 437039742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.90510
Policy Entropy: 1.04942
Value Function Loss: 1.52713

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.19908
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.09699

Collected Steps per Second: 8,599.15788
Overall Steps per Second: 7,426.70814

Timestep Collection Time: 5.81638
Timestep Consumption Time: 0.91823
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.73461

Cumulative Model Updates: 26,203
Cumulative Timesteps: 437,089,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.97929
Policy Entropy: 1.01893
Value Function Loss: 1.67006

Mean KL Divergence: 0.03833
SB3 Clip Fraction: 0.22909
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 8,732.42804
Overall Steps per Second: 7,607.54570

Timestep Collection Time: 5.72601
Timestep Consumption Time: 0.84667
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.57268

Cumulative Model Updates: 26,206
Cumulative Timesteps: 437,139,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 437139760...
Checkpoint 437139760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.31994
Policy Entropy: 1.03979
Value Function Loss: 1.72436

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 8,580.79667
Overall Steps per Second: 7,483.91493

Timestep Collection Time: 5.82790
Timestep Consumption Time: 0.85417
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 6.68206

Cumulative Model Updates: 26,209
Cumulative Timesteps: 437,189,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.54359
Policy Entropy: 1.04052
Value Function Loss: 1.69133

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 8,873.11131
Overall Steps per Second: 7,756.33789

Timestep Collection Time: 5.63613
Timestep Consumption Time: 0.81150
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 6.44763

Cumulative Model Updates: 26,212
Cumulative Timesteps: 437,239,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 437239778...
Checkpoint 437239778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.01249
Policy Entropy: 1.05266
Value Function Loss: 1.67537

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.13707

Collected Steps per Second: 8,430.86939
Overall Steps per Second: 7,468.81666

Timestep Collection Time: 5.93082
Timestep Consumption Time: 0.76394
PPO Batch Consumption Time: 0.05101
Total Iteration Time: 6.69477

Cumulative Model Updates: 26,215
Cumulative Timesteps: 437,289,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.78261
Policy Entropy: 1.04533
Value Function Loss: 1.69927

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.12699

Collected Steps per Second: 8,845.42713
Overall Steps per Second: 7,708.16374

Timestep Collection Time: 5.65332
Timestep Consumption Time: 0.83409
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.48741

Cumulative Model Updates: 26,218
Cumulative Timesteps: 437,339,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 437339786...
Checkpoint 437339786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.93389
Policy Entropy: 1.05573
Value Function Loss: 1.64356

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 8,741.14770
Overall Steps per Second: 7,605.99874

Timestep Collection Time: 5.72305
Timestep Consumption Time: 0.85413
PPO Batch Consumption Time: 0.05127
Total Iteration Time: 6.57718

Cumulative Model Updates: 26,221
Cumulative Timesteps: 437,389,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.59792
Policy Entropy: 1.06272
Value Function Loss: 1.51462

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.10119

Collected Steps per Second: 8,997.09446
Overall Steps per Second: 7,807.07130

Timestep Collection Time: 5.56024
Timestep Consumption Time: 0.84754
PPO Batch Consumption Time: 0.04740
Total Iteration Time: 6.40778

Cumulative Model Updates: 26,224
Cumulative Timesteps: 437,439,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 437439838...
Checkpoint 437439838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.31599
Policy Entropy: 1.06215
Value Function Loss: 1.58901

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 8,727.10420
Overall Steps per Second: 7,644.06796

Timestep Collection Time: 5.73088
Timestep Consumption Time: 0.81197
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.54285

Cumulative Model Updates: 26,227
Cumulative Timesteps: 437,489,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.42184
Policy Entropy: 1.05531
Value Function Loss: 1.54558

Mean KL Divergence: 0.02316
SB3 Clip Fraction: 0.16663
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 8,158.40750
Overall Steps per Second: 7,249.63921

Timestep Collection Time: 6.13110
Timestep Consumption Time: 0.76856
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.89965

Cumulative Model Updates: 26,230
Cumulative Timesteps: 437,539,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 437539872...
Checkpoint 437539872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.07735
Policy Entropy: 1.06953
Value Function Loss: 1.64194

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.18047
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 8,952.87604
Overall Steps per Second: 7,816.29652

Timestep Collection Time: 5.58569
Timestep Consumption Time: 0.81222
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 6.39791

Cumulative Model Updates: 26,233
Cumulative Timesteps: 437,589,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.17776
Policy Entropy: 1.06956
Value Function Loss: 1.55490

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.18265
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 8,638.20523
Overall Steps per Second: 7,527.93002

Timestep Collection Time: 5.79125
Timestep Consumption Time: 0.85414
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.64539

Cumulative Model Updates: 26,236
Cumulative Timesteps: 437,639,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 437639906...
Checkpoint 437639906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.70641
Policy Entropy: 1.04966
Value Function Loss: 1.68559

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.09733

Collected Steps per Second: 9,072.65277
Overall Steps per Second: 7,888.14364

Timestep Collection Time: 5.51415
Timestep Consumption Time: 0.82802
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.34218

Cumulative Model Updates: 26,239
Cumulative Timesteps: 437,689,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.56456
Policy Entropy: 1.03994
Value Function Loss: 1.78066

Mean KL Divergence: 0.03438
SB3 Clip Fraction: 0.23151
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 8,568.46018
Overall Steps per Second: 7,469.31122

Timestep Collection Time: 5.83886
Timestep Consumption Time: 0.85922
PPO Batch Consumption Time: 0.04170
Total Iteration Time: 6.69807

Cumulative Model Updates: 26,242
Cumulative Timesteps: 437,739,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 437739964...
Checkpoint 437739964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.36108
Policy Entropy: 1.05137
Value Function Loss: 1.67765

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16461
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 8,823.46274
Overall Steps per Second: 7,792.15410

Timestep Collection Time: 5.66875
Timestep Consumption Time: 0.75027
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.41902

Cumulative Model Updates: 26,245
Cumulative Timesteps: 437,789,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.72298
Policy Entropy: 1.04196
Value Function Loss: 1.60552

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 8,972.79778
Overall Steps per Second: 7,705.10285

Timestep Collection Time: 5.57552
Timestep Consumption Time: 0.91732
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.49284

Cumulative Model Updates: 26,248
Cumulative Timesteps: 437,840,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 437840010...
Checkpoint 437840010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.54994
Policy Entropy: 1.02536
Value Function Loss: 1.56665

Mean KL Divergence: 0.03468
SB3 Clip Fraction: 0.25545
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 8,793.11646
Overall Steps per Second: 7,630.22143

Timestep Collection Time: 5.68809
Timestep Consumption Time: 0.86690
PPO Batch Consumption Time: 0.05169
Total Iteration Time: 6.55499

Cumulative Model Updates: 26,251
Cumulative Timesteps: 437,890,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.48044
Policy Entropy: 1.03257
Value Function Loss: 1.64912

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 8,948.66870
Overall Steps per Second: 7,726.82771

Timestep Collection Time: 5.58742
Timestep Consumption Time: 0.88354
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.47096

Cumulative Model Updates: 26,254
Cumulative Timesteps: 437,940,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 437940026...
Checkpoint 437940026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.33954
Policy Entropy: 1.04252
Value Function Loss: 1.68182

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.07349

Collected Steps per Second: 8,580.60784
Overall Steps per Second: 7,494.29191

Timestep Collection Time: 5.83012
Timestep Consumption Time: 0.84509
PPO Batch Consumption Time: 0.04616
Total Iteration Time: 6.67521

Cumulative Model Updates: 26,257
Cumulative Timesteps: 437,990,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.20952
Policy Entropy: 1.03985
Value Function Loss: 1.57007

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.08510

Collected Steps per Second: 8,724.17063
Overall Steps per Second: 7,648.22332

Timestep Collection Time: 5.73304
Timestep Consumption Time: 0.80652
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.53956

Cumulative Model Updates: 26,260
Cumulative Timesteps: 438,040,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 438040068...
Checkpoint 438040068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.37858
Policy Entropy: 1.03697
Value Function Loss: 1.57934

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.07988

Collected Steps per Second: 8,757.64289
Overall Steps per Second: 7,621.56711

Timestep Collection Time: 5.71090
Timestep Consumption Time: 0.85127
PPO Batch Consumption Time: 0.04041
Total Iteration Time: 6.56217

Cumulative Model Updates: 26,263
Cumulative Timesteps: 438,090,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.89568
Policy Entropy: 1.01813
Value Function Loss: 1.62632

Mean KL Divergence: 0.03587
SB3 Clip Fraction: 0.21982
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 8,687.15700
Overall Steps per Second: 7,648.45825

Timestep Collection Time: 5.75816
Timestep Consumption Time: 0.78199
PPO Batch Consumption Time: 0.05238
Total Iteration Time: 6.54014

Cumulative Model Updates: 26,266
Cumulative Timesteps: 438,140,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 438140104...
Checkpoint 438140104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.17828
Policy Entropy: 1.04766
Value Function Loss: 1.69696

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.17273
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.07671

Collected Steps per Second: 8,505.07645
Overall Steps per Second: 7,395.07205

Timestep Collection Time: 5.88049
Timestep Consumption Time: 0.88266
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 6.76315

Cumulative Model Updates: 26,269
Cumulative Timesteps: 438,190,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.07502
Policy Entropy: 1.06066
Value Function Loss: 1.66897

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.20071
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 8,919.63734
Overall Steps per Second: 7,742.00233

Timestep Collection Time: 5.60583
Timestep Consumption Time: 0.85270
PPO Batch Consumption Time: 0.04038
Total Iteration Time: 6.45854

Cumulative Model Updates: 26,272
Cumulative Timesteps: 438,240,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 438240120...
Checkpoint 438240120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.47910
Policy Entropy: 1.05046
Value Function Loss: 1.52531

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.07324

Collected Steps per Second: 8,782.76099
Overall Steps per Second: 7,802.34476

Timestep Collection Time: 5.69434
Timestep Consumption Time: 0.71553
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 6.40987

Cumulative Model Updates: 26,275
Cumulative Timesteps: 438,290,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.69552
Policy Entropy: 1.03817
Value Function Loss: 1.59888

Mean KL Divergence: 0.03625
SB3 Clip Fraction: 0.22683
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.08055

Collected Steps per Second: 8,924.61829
Overall Steps per Second: 7,745.00592

Timestep Collection Time: 5.60405
Timestep Consumption Time: 0.85353
PPO Batch Consumption Time: 0.04079
Total Iteration Time: 6.45758

Cumulative Model Updates: 26,278
Cumulative Timesteps: 438,340,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 438340146...
Checkpoint 438340146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.71959
Policy Entropy: 1.05561
Value Function Loss: 1.59902

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15625
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.08460

Collected Steps per Second: 8,619.65370
Overall Steps per Second: 7,519.68234

Timestep Collection Time: 5.80255
Timestep Consumption Time: 0.84879
PPO Batch Consumption Time: 0.04085
Total Iteration Time: 6.65134

Cumulative Model Updates: 26,281
Cumulative Timesteps: 438,390,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.89799
Policy Entropy: 1.04314
Value Function Loss: 1.75314

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15917
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.08352

Collected Steps per Second: 8,678.92826
Overall Steps per Second: 7,490.10822

Timestep Collection Time: 5.76269
Timestep Consumption Time: 0.91465
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.67734

Cumulative Model Updates: 26,284
Cumulative Timesteps: 438,440,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 438440176...
Checkpoint 438440176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.96782
Policy Entropy: 1.01391
Value Function Loss: 1.70953

Mean KL Divergence: 0.04638
SB3 Clip Fraction: 0.27969
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 8,782.79418
Overall Steps per Second: 7,632.66490

Timestep Collection Time: 5.69454
Timestep Consumption Time: 0.85808
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.55263

Cumulative Model Updates: 26,287
Cumulative Timesteps: 438,490,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.64615
Policy Entropy: 1.03334
Value Function Loss: 1.74609

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.17817
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 8,876.78689
Overall Steps per Second: 7,781.50926

Timestep Collection Time: 5.63470
Timestep Consumption Time: 0.79311
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.42780

Cumulative Model Updates: 26,290
Cumulative Timesteps: 438,540,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 438540208...
Checkpoint 438540208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.64468
Policy Entropy: 1.02746
Value Function Loss: 1.65027

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.20886
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.08447

Collected Steps per Second: 9,077.76196
Overall Steps per Second: 7,835.65263

Timestep Collection Time: 5.50995
Timestep Consumption Time: 0.87344
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.38339

Cumulative Model Updates: 26,293
Cumulative Timesteps: 438,590,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.78955
Policy Entropy: 1.01262
Value Function Loss: 1.63795

Mean KL Divergence: 0.03173
SB3 Clip Fraction: 0.21261
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.07552

Collected Steps per Second: 8,938.53231
Overall Steps per Second: 7,719.79514

Timestep Collection Time: 5.59644
Timestep Consumption Time: 0.88352
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 6.47996

Cumulative Model Updates: 26,296
Cumulative Timesteps: 438,640,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 438640250...
Checkpoint 438640250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.85676
Policy Entropy: 1.03080
Value Function Loss: 1.63772

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.17255
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 9,120.64224
Overall Steps per Second: 7,877.93413

Timestep Collection Time: 5.48448
Timestep Consumption Time: 0.86515
PPO Batch Consumption Time: 0.04656
Total Iteration Time: 6.34963

Cumulative Model Updates: 26,299
Cumulative Timesteps: 438,690,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.20628
Policy Entropy: 1.04520
Value Function Loss: 1.59130

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.18685
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 9,129.14193
Overall Steps per Second: 7,883.06966

Timestep Collection Time: 5.47806
Timestep Consumption Time: 0.86591
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.34398

Cumulative Model Updates: 26,302
Cumulative Timesteps: 438,740,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 438740282...
Checkpoint 438740282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.02551
Policy Entropy: 1.02827
Value Function Loss: 1.45646

Mean KL Divergence: 0.02650
SB3 Clip Fraction: 0.19353
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.06277

Collected Steps per Second: 9,296.10596
Overall Steps per Second: 8,053.55069

Timestep Collection Time: 5.37967
Timestep Consumption Time: 0.83001
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.20968

Cumulative Model Updates: 26,305
Cumulative Timesteps: 438,790,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.95886
Policy Entropy: 1.04439
Value Function Loss: 1.46503

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.19431
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.08315

Collected Steps per Second: 8,701.79403
Overall Steps per Second: 7,523.52565

Timestep Collection Time: 5.74617
Timestep Consumption Time: 0.89991
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.64609

Cumulative Model Updates: 26,308
Cumulative Timesteps: 438,840,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 438840294...
Checkpoint 438840294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.63491
Policy Entropy: 1.05380
Value Function Loss: 1.46529

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.08784

Collected Steps per Second: 8,654.53417
Overall Steps per Second: 7,569.80949

Timestep Collection Time: 5.77917
Timestep Consumption Time: 0.82813
PPO Batch Consumption Time: 0.05148
Total Iteration Time: 6.60730

Cumulative Model Updates: 26,311
Cumulative Timesteps: 438,890,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.30492
Policy Entropy: 1.05889
Value Function Loss: 1.65247

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.08260

Collected Steps per Second: 8,775.13242
Overall Steps per Second: 7,639.31977

Timestep Collection Time: 5.70043
Timestep Consumption Time: 0.84754
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.54797

Cumulative Model Updates: 26,314
Cumulative Timesteps: 438,940,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 438940332...
Checkpoint 438940332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.97818
Policy Entropy: 1.06106
Value Function Loss: 1.79192

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.16385
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 8,791.00792
Overall Steps per Second: 7,658.74966

Timestep Collection Time: 5.68945
Timestep Consumption Time: 0.84112
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 6.53057

Cumulative Model Updates: 26,317
Cumulative Timesteps: 438,990,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.41877
Policy Entropy: 1.04748
Value Function Loss: 1.89320

Mean KL Divergence: 0.02993
SB3 Clip Fraction: 0.19911
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.07919

Collected Steps per Second: 9,142.98030
Overall Steps per Second: 7,896.52708

Timestep Collection Time: 5.47130
Timestep Consumption Time: 0.86364
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.33494

Cumulative Model Updates: 26,320
Cumulative Timesteps: 439,040,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 439040372...
Checkpoint 439040372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.37404
Policy Entropy: 1.06807
Value Function Loss: 1.85113

Mean KL Divergence: 0.03013
SB3 Clip Fraction: 0.20816
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 8,585.37978
Overall Steps per Second: 7,486.21033

Timestep Collection Time: 5.82735
Timestep Consumption Time: 0.85561
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.68295

Cumulative Model Updates: 26,323
Cumulative Timesteps: 439,090,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.87704
Policy Entropy: 1.05940
Value Function Loss: 1.72352

Mean KL Divergence: 0.02973
SB3 Clip Fraction: 0.22856
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 8,649.27307
Overall Steps per Second: 7,628.46724

Timestep Collection Time: 5.78407
Timestep Consumption Time: 0.77400
PPO Batch Consumption Time: 0.04907
Total Iteration Time: 6.55807

Cumulative Model Updates: 26,326
Cumulative Timesteps: 439,140,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 439140430...
Checkpoint 439140430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.02367
Policy Entropy: 1.06375
Value Function Loss: 1.61678

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.17286
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.06628

Collected Steps per Second: 8,843.96201
Overall Steps per Second: 7,587.43531

Timestep Collection Time: 5.65403
Timestep Consumption Time: 0.93634
PPO Batch Consumption Time: 0.05204
Total Iteration Time: 6.59037

Cumulative Model Updates: 26,329
Cumulative Timesteps: 439,190,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.84867
Policy Entropy: 1.03749
Value Function Loss: 1.56510

Mean KL Divergence: 0.04442
SB3 Clip Fraction: 0.26176
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.06550

Collected Steps per Second: 8,641.10087
Overall Steps per Second: 7,583.96814

Timestep Collection Time: 5.78954
Timestep Consumption Time: 0.80701
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.59655

Cumulative Model Updates: 26,332
Cumulative Timesteps: 439,240,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 439240462...
Checkpoint 439240462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.24597
Policy Entropy: 1.08950
Value Function Loss: 1.55032

Mean KL Divergence: 0.06216
SB3 Clip Fraction: 0.33111
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 8,978.90593
Overall Steps per Second: 7,755.56386

Timestep Collection Time: 5.56972
Timestep Consumption Time: 0.87855
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.44827

Cumulative Model Updates: 26,335
Cumulative Timesteps: 439,290,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.11047
Policy Entropy: 1.06898
Value Function Loss: 1.55311

Mean KL Divergence: 0.05997
SB3 Clip Fraction: 0.31219
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 8,533.85012
Overall Steps per Second: 7,477.26761

Timestep Collection Time: 5.86183
Timestep Consumption Time: 0.82831
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.69014

Cumulative Model Updates: 26,338
Cumulative Timesteps: 439,340,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 439340496...
Checkpoint 439340496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.30004
Policy Entropy: 1.08999
Value Function Loss: 1.58732

Mean KL Divergence: 0.04894
SB3 Clip Fraction: 0.28421
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.07279

Collected Steps per Second: 8,510.23193
Overall Steps per Second: 7,509.86302

Timestep Collection Time: 5.87881
Timestep Consumption Time: 0.78310
PPO Batch Consumption Time: 0.05028
Total Iteration Time: 6.66191

Cumulative Model Updates: 26,341
Cumulative Timesteps: 439,390,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.53064
Policy Entropy: 1.07566
Value Function Loss: 1.62131

Mean KL Divergence: 0.04040
SB3 Clip Fraction: 0.22578
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 8,947.03882
Overall Steps per Second: 7,717.97961

Timestep Collection Time: 5.59045
Timestep Consumption Time: 0.89026
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.48071

Cumulative Model Updates: 26,344
Cumulative Timesteps: 439,440,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 439440544...
Checkpoint 439440544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.82888
Policy Entropy: 1.09145
Value Function Loss: 1.64647

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.18692
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 8,519.72569
Overall Steps per Second: 7,494.14304

Timestep Collection Time: 5.86897
Timestep Consumption Time: 0.80318
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.67214

Cumulative Model Updates: 26,347
Cumulative Timesteps: 439,490,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.66833
Policy Entropy: 1.07932
Value Function Loss: 1.57885

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.07804

Collected Steps per Second: 8,967.47949
Overall Steps per Second: 7,704.93865

Timestep Collection Time: 5.57771
Timestep Consumption Time: 0.91397
PPO Batch Consumption Time: 0.05187
Total Iteration Time: 6.49168

Cumulative Model Updates: 26,350
Cumulative Timesteps: 439,540,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 439540564...
Checkpoint 439540564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.54470
Policy Entropy: 1.06393
Value Function Loss: 1.49263

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.17841
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.09022

Collected Steps per Second: 8,522.21999
Overall Steps per Second: 7,418.64326

Timestep Collection Time: 5.86795
Timestep Consumption Time: 0.87290
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.74086

Cumulative Model Updates: 26,353
Cumulative Timesteps: 439,590,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.37818
Policy Entropy: 1.08769
Value Function Loss: 1.56905

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.09148

Collected Steps per Second: 8,946.37962
Overall Steps per Second: 7,838.34703

Timestep Collection Time: 5.58952
Timestep Consumption Time: 0.79014
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.37966

Cumulative Model Updates: 26,356
Cumulative Timesteps: 439,640,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 439640578...
Checkpoint 439640578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.07119
Policy Entropy: 1.07910
Value Function Loss: 1.56062

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.08420

Collected Steps per Second: 8,916.68133
Overall Steps per Second: 7,685.13358

Timestep Collection Time: 5.61016
Timestep Consumption Time: 0.89903
PPO Batch Consumption Time: 0.04899
Total Iteration Time: 6.50919

Cumulative Model Updates: 26,359
Cumulative Timesteps: 439,690,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.94085
Policy Entropy: 1.07080
Value Function Loss: 1.66594

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.07692

Collected Steps per Second: 8,637.62073
Overall Steps per Second: 7,512.20136

Timestep Collection Time: 5.79118
Timestep Consumption Time: 0.86759
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.65877

Cumulative Model Updates: 26,362
Cumulative Timesteps: 439,740,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 439740624...
Checkpoint 439740624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.20593
Policy Entropy: 1.03892
Value Function Loss: 1.53668

Mean KL Divergence: 0.05889
SB3 Clip Fraction: 0.27967
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 8,837.04636
Overall Steps per Second: 7,616.45492

Timestep Collection Time: 5.66071
Timestep Consumption Time: 0.90717
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.56789

Cumulative Model Updates: 26,365
Cumulative Timesteps: 439,790,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.97701
Policy Entropy: 1.08528
Value Function Loss: 1.57644

Mean KL Divergence: 0.04651
SB3 Clip Fraction: 0.26249
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.07215

Collected Steps per Second: 8,784.72066
Overall Steps per Second: 7,662.47053

Timestep Collection Time: 5.69398
Timestep Consumption Time: 0.83394
PPO Batch Consumption Time: 0.04820
Total Iteration Time: 6.52792

Cumulative Model Updates: 26,368
Cumulative Timesteps: 439,840,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 439840668...
Checkpoint 439840668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.33748
Policy Entropy: 1.05417
Value Function Loss: 1.45739

Mean KL Divergence: 0.06086
SB3 Clip Fraction: 0.32817
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 8,870.07192
Overall Steps per Second: 7,802.71497

Timestep Collection Time: 5.63964
Timestep Consumption Time: 0.77146
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.41110

Cumulative Model Updates: 26,371
Cumulative Timesteps: 439,890,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.79274
Policy Entropy: 1.08797
Value Function Loss: 1.53314

Mean KL Divergence: 0.04717
SB3 Clip Fraction: 0.29087
Policy Update Magnitude: 0.03910
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 8,732.56047
Overall Steps per Second: 7,613.87404

Timestep Collection Time: 5.72867
Timestep Consumption Time: 0.84170
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.57037

Cumulative Model Updates: 26,374
Cumulative Timesteps: 439,940,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 439940718...
Checkpoint 439940718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.01519
Policy Entropy: 1.05152
Value Function Loss: 1.48100

Mean KL Divergence: 0.05087
SB3 Clip Fraction: 0.28491
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.07888

Collected Steps per Second: 8,703.77680
Overall Steps per Second: 7,710.77576

Timestep Collection Time: 5.74624
Timestep Consumption Time: 0.74001
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.48625

Cumulative Model Updates: 26,377
Cumulative Timesteps: 439,990,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.85814
Policy Entropy: 1.07371
Value Function Loss: 1.50027

Mean KL Divergence: 0.03238
SB3 Clip Fraction: 0.23681
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.07699

Collected Steps per Second: 8,687.06403
Overall Steps per Second: 7,596.81281

Timestep Collection Time: 5.75799
Timestep Consumption Time: 0.82635
PPO Batch Consumption Time: 0.04374
Total Iteration Time: 6.58434

Cumulative Model Updates: 26,380
Cumulative Timesteps: 440,040,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 440040752...
Checkpoint 440040752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.85742
Policy Entropy: 1.05225
Value Function Loss: 1.42704

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.17561
Policy Update Magnitude: 0.04225
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 9,078.13740
Overall Steps per Second: 7,681.15414

Timestep Collection Time: 5.50906
Timestep Consumption Time: 1.00194
PPO Batch Consumption Time: 0.04458
Total Iteration Time: 6.51100

Cumulative Model Updates: 26,383
Cumulative Timesteps: 440,090,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.79644
Policy Entropy: 1.06378
Value Function Loss: 1.43705

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 8,852.83933
Overall Steps per Second: 7,731.12345

Timestep Collection Time: 5.65062
Timestep Consumption Time: 0.81985
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 6.47047

Cumulative Model Updates: 26,386
Cumulative Timesteps: 440,140,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 440140788...
Checkpoint 440140788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.40116
Policy Entropy: 1.06687
Value Function Loss: 1.47851

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.06194

Collected Steps per Second: 8,820.18363
Overall Steps per Second: 7,671.68818

Timestep Collection Time: 5.67176
Timestep Consumption Time: 0.84910
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 6.52086

Cumulative Model Updates: 26,389
Cumulative Timesteps: 440,190,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.01834
Policy Entropy: 1.07964
Value Function Loss: 1.62514

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.06312

Collected Steps per Second: 8,668.94275
Overall Steps per Second: 7,524.81151

Timestep Collection Time: 5.76979
Timestep Consumption Time: 0.87728
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.64708

Cumulative Model Updates: 26,392
Cumulative Timesteps: 440,240,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440240832...
Checkpoint 440240832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.20798
Policy Entropy: 1.05135
Value Function Loss: 1.69292

Mean KL Divergence: 0.04110
SB3 Clip Fraction: 0.23238
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 8,749.60222
Overall Steps per Second: 7,532.45770

Timestep Collection Time: 5.71455
Timestep Consumption Time: 0.92339
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 6.63794

Cumulative Model Updates: 26,395
Cumulative Timesteps: 440,290,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.00989
Policy Entropy: 1.07914
Value Function Loss: 1.74473

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 8,833.65785
Overall Steps per Second: 7,705.06792

Timestep Collection Time: 5.66289
Timestep Consumption Time: 0.82946
PPO Batch Consumption Time: 0.03953
Total Iteration Time: 6.49235

Cumulative Model Updates: 26,398
Cumulative Timesteps: 440,340,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 440340856...
Checkpoint 440340856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.81590
Policy Entropy: 1.06880
Value Function Loss: 1.67853

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15336
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.08837

Collected Steps per Second: 8,960.87406
Overall Steps per Second: 7,741.48691

Timestep Collection Time: 5.58048
Timestep Consumption Time: 0.87900
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.45948

Cumulative Model Updates: 26,401
Cumulative Timesteps: 440,390,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.06784
Policy Entropy: 1.06025
Value Function Loss: 1.61246

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.18063
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 9,117.77415
Overall Steps per Second: 7,871.11104

Timestep Collection Time: 5.48621
Timestep Consumption Time: 0.86893
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.35514

Cumulative Model Updates: 26,404
Cumulative Timesteps: 440,440,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 440440884...
Checkpoint 440440884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.89400
Policy Entropy: 1.05746
Value Function Loss: 1.54629

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.20366
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.07741

Collected Steps per Second: 8,745.65505
Overall Steps per Second: 7,700.51012

Timestep Collection Time: 5.71781
Timestep Consumption Time: 0.77604
PPO Batch Consumption Time: 0.04764
Total Iteration Time: 6.49386

Cumulative Model Updates: 26,407
Cumulative Timesteps: 440,490,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.16360
Policy Entropy: 1.06424
Value Function Loss: 1.58905

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.06656

Collected Steps per Second: 9,252.07384
Overall Steps per Second: 7,957.51149

Timestep Collection Time: 5.40614
Timestep Consumption Time: 0.87949
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 6.28563

Cumulative Model Updates: 26,410
Cumulative Timesteps: 440,540,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440540908...
Checkpoint 440540908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.57713
Policy Entropy: 1.06544
Value Function Loss: 1.55239

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.18019
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.05142

Collected Steps per Second: 9,030.27835
Overall Steps per Second: 7,834.91685

Timestep Collection Time: 5.53870
Timestep Consumption Time: 0.84503
PPO Batch Consumption Time: 0.04761
Total Iteration Time: 6.38373

Cumulative Model Updates: 26,413
Cumulative Timesteps: 440,590,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.21188
Policy Entropy: 1.01598
Value Function Loss: 1.61688

Mean KL Divergence: 0.07510
SB3 Clip Fraction: 0.35293
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 8,818.45440
Overall Steps per Second: 7,764.70735

Timestep Collection Time: 5.67197
Timestep Consumption Time: 0.76974
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.44171

Cumulative Model Updates: 26,416
Cumulative Timesteps: 440,640,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440640942...
Checkpoint 440640942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.10618
Policy Entropy: 1.06385
Value Function Loss: 1.52338

Mean KL Divergence: 0.04821
SB3 Clip Fraction: 0.30647
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.04952

Collected Steps per Second: 8,750.81357
Overall Steps per Second: 7,577.98220

Timestep Collection Time: 5.71398
Timestep Consumption Time: 0.88434
PPO Batch Consumption Time: 0.04622
Total Iteration Time: 6.59833

Cumulative Model Updates: 26,419
Cumulative Timesteps: 440,690,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.08647
Policy Entropy: 1.03276
Value Function Loss: 1.52098

Mean KL Divergence: 0.05554
SB3 Clip Fraction: 0.32386
Policy Update Magnitude: 0.04145
Value Function Update Magnitude: 0.04789

Collected Steps per Second: 8,532.46701
Overall Steps per Second: 7,474.42848

Timestep Collection Time: 5.86302
Timestep Consumption Time: 0.82994
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.69295

Cumulative Model Updates: 26,422
Cumulative Timesteps: 440,740,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 440740970...
Checkpoint 440740970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.28789
Policy Entropy: 1.07299
Value Function Loss: 1.47102

Mean KL Divergence: 0.04508
SB3 Clip Fraction: 0.30565
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.04765

Collected Steps per Second: 8,921.58755
Overall Steps per Second: 7,759.62083

Timestep Collection Time: 5.60730
Timestep Consumption Time: 0.83967
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.44696

Cumulative Model Updates: 26,425
Cumulative Timesteps: 440,790,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.45946
Policy Entropy: 1.03822
Value Function Loss: 1.36421

Mean KL Divergence: 0.06566
SB3 Clip Fraction: 0.32253
Policy Update Magnitude: 0.04025
Value Function Update Magnitude: 0.05426

Collected Steps per Second: 8,587.47594
Overall Steps per Second: 7,445.54768

Timestep Collection Time: 5.82360
Timestep Consumption Time: 0.89317
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.71677

Cumulative Model Updates: 26,428
Cumulative Timesteps: 440,841,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 440841006...
Checkpoint 440841006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.63557
Policy Entropy: 1.06868
Value Function Loss: 1.29724

Mean KL Divergence: 0.04022
SB3 Clip Fraction: 0.27383
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 8,644.38632
Overall Steps per Second: 7,669.87565

Timestep Collection Time: 5.78595
Timestep Consumption Time: 0.73515
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.52110

Cumulative Model Updates: 26,431
Cumulative Timesteps: 440,891,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.22984
Policy Entropy: 1.05323
Value Function Loss: 1.29807

Mean KL Divergence: 0.02797
SB3 Clip Fraction: 0.22407
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 8,636.95665
Overall Steps per Second: 7,495.85234

Timestep Collection Time: 5.79209
Timestep Consumption Time: 0.88174
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.67382

Cumulative Model Updates: 26,434
Cumulative Timesteps: 440,941,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 440941048...
Checkpoint 440941048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.95723
Policy Entropy: 1.07084
Value Function Loss: 1.37337

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.21611
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 8,802.33668
Overall Steps per Second: 7,698.64221

Timestep Collection Time: 5.68258
Timestep Consumption Time: 0.81467
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 6.49725

Cumulative Model Updates: 26,437
Cumulative Timesteps: 440,991,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.03568
Policy Entropy: 1.06416
Value Function Loss: 1.45383

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.16353
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 8,950.39077
Overall Steps per Second: 7,753.08964

Timestep Collection Time: 5.58814
Timestep Consumption Time: 0.86297
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.45111

Cumulative Model Updates: 26,440
Cumulative Timesteps: 441,041,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 441041084...
Checkpoint 441041084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.78022
Policy Entropy: 1.04167
Value Function Loss: 1.41257

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.18643
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 8,744.51566
Overall Steps per Second: 7,619.78568

Timestep Collection Time: 5.71833
Timestep Consumption Time: 0.84406
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 6.56239

Cumulative Model Updates: 26,443
Cumulative Timesteps: 441,091,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.64576
Policy Entropy: 1.03675
Value Function Loss: 1.45317

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.20483
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.07732

Collected Steps per Second: 8,561.01716
Overall Steps per Second: 7,546.82015

Timestep Collection Time: 5.84323
Timestep Consumption Time: 0.78526
PPO Batch Consumption Time: 0.04766
Total Iteration Time: 6.62849

Cumulative Model Updates: 26,446
Cumulative Timesteps: 441,141,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 441141112...
Checkpoint 441141112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.34467
Policy Entropy: 1.04974
Value Function Loss: 1.45731

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 8,408.86020
Overall Steps per Second: 7,317.71973

Timestep Collection Time: 5.94944
Timestep Consumption Time: 0.88712
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.83656

Cumulative Model Updates: 26,449
Cumulative Timesteps: 441,191,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.82230
Policy Entropy: 1.06349
Value Function Loss: 1.55852

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.18430
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 8,685.53104
Overall Steps per Second: 7,583.73049

Timestep Collection Time: 5.75670
Timestep Consumption Time: 0.83636
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.59306

Cumulative Model Updates: 26,452
Cumulative Timesteps: 441,241,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 441241140...
Checkpoint 441241140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.06586
Policy Entropy: 1.02729
Value Function Loss: 1.51373

Mean KL Divergence: 0.05246
SB3 Clip Fraction: 0.25070
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 8,989.09754
Overall Steps per Second: 7,795.35102

Timestep Collection Time: 5.56318
Timestep Consumption Time: 0.85192
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.41511

Cumulative Model Updates: 26,455
Cumulative Timesteps: 441,291,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.55796
Policy Entropy: 1.06345
Value Function Loss: 1.52069

Mean KL Divergence: 0.03393
SB3 Clip Fraction: 0.23167
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.06223

Collected Steps per Second: 8,727.07662
Overall Steps per Second: 7,564.58296

Timestep Collection Time: 5.73182
Timestep Consumption Time: 0.88084
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 6.61266

Cumulative Model Updates: 26,458
Cumulative Timesteps: 441,341,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 441341170...
Checkpoint 441341170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.47036
Policy Entropy: 1.01249
Value Function Loss: 1.48576

Mean KL Divergence: 0.06636
SB3 Clip Fraction: 0.34853
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 8,778.99478
Overall Steps per Second: 7,676.56770

Timestep Collection Time: 5.69701
Timestep Consumption Time: 0.81814
PPO Batch Consumption Time: 0.04344
Total Iteration Time: 6.51515

Cumulative Model Updates: 26,461
Cumulative Timesteps: 441,391,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.97480
Policy Entropy: 1.05262
Value Function Loss: 1.46661

Mean KL Divergence: 0.04433
SB3 Clip Fraction: 0.29358
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 8,940.07706
Overall Steps per Second: 7,735.06242

Timestep Collection Time: 5.59369
Timestep Consumption Time: 0.87142
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 6.46511

Cumulative Model Updates: 26,464
Cumulative Timesteps: 441,441,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 441441192...
Checkpoint 441441192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.47833
Policy Entropy: 1.01537
Value Function Loss: 1.46981

Mean KL Divergence: 0.06691
SB3 Clip Fraction: 0.33203
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.09646

Collected Steps per Second: 8,729.07785
Overall Steps per Second: 7,647.98932

Timestep Collection Time: 5.73027
Timestep Consumption Time: 0.81001
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.54028

Cumulative Model Updates: 26,467
Cumulative Timesteps: 441,491,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.28379
Policy Entropy: 1.05251
Value Function Loss: 1.44455

Mean KL Divergence: 0.04429
SB3 Clip Fraction: 0.28717
Policy Update Magnitude: 0.03943
Value Function Update Magnitude: 0.07913

Collected Steps per Second: 9,135.79460
Overall Steps per Second: 7,884.35348

Timestep Collection Time: 5.47539
Timestep Consumption Time: 0.86908
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 6.34446

Cumulative Model Updates: 26,470
Cumulative Timesteps: 441,541,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 441541234...
Checkpoint 441541234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.90642
Policy Entropy: 1.03176
Value Function Loss: 1.50635

Mean KL Divergence: 0.04110
SB3 Clip Fraction: 0.26143
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.08193

Collected Steps per Second: 8,757.15489
Overall Steps per Second: 7,504.11781

Timestep Collection Time: 5.71190
Timestep Consumption Time: 0.95377
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.66567

Cumulative Model Updates: 26,473
Cumulative Timesteps: 441,591,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.49848
Policy Entropy: 1.05206
Value Function Loss: 1.56622

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.20037
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.08839

Collected Steps per Second: 8,509.66760
Overall Steps per Second: 7,428.38918

Timestep Collection Time: 5.87779
Timestep Consumption Time: 0.85557
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 6.73336

Cumulative Model Updates: 26,476
Cumulative Timesteps: 441,641,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 441641272...
Checkpoint 441641272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.31886
Policy Entropy: 1.04361
Value Function Loss: 1.47356

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.18996
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 8,626.95574
Overall Steps per Second: 7,480.06576

Timestep Collection Time: 5.79695
Timestep Consumption Time: 0.88882
PPO Batch Consumption Time: 0.04746
Total Iteration Time: 6.68577

Cumulative Model Updates: 26,479
Cumulative Timesteps: 441,691,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.67684
Policy Entropy: 1.03631
Value Function Loss: 1.38991

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 8,934.88015
Overall Steps per Second: 7,838.07505

Timestep Collection Time: 5.59784
Timestep Consumption Time: 0.78332
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.38116

Cumulative Model Updates: 26,482
Cumulative Timesteps: 441,741,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 441741298...
Checkpoint 441741298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.53459
Policy Entropy: 1.04813
Value Function Loss: 1.35175

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.20127
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 8,783.53748
Overall Steps per Second: 7,666.21823

Timestep Collection Time: 5.69429
Timestep Consumption Time: 0.82992
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.52421

Cumulative Model Updates: 26,485
Cumulative Timesteps: 441,791,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.39796
Policy Entropy: 1.04669
Value Function Loss: 1.48042

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.17306
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 8,722.04226
Overall Steps per Second: 7,566.73867

Timestep Collection Time: 5.73512
Timestep Consumption Time: 0.87565
PPO Batch Consumption Time: 0.04731
Total Iteration Time: 6.61077

Cumulative Model Updates: 26,488
Cumulative Timesteps: 441,841,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 441841336...
Checkpoint 441841336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.93922
Policy Entropy: 1.03758
Value Function Loss: 1.57643

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.18176
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.07245

Collected Steps per Second: 8,775.97257
Overall Steps per Second: 7,632.87003

Timestep Collection Time: 5.69897
Timestep Consumption Time: 0.85348
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.55245

Cumulative Model Updates: 26,491
Cumulative Timesteps: 441,891,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.93788
Policy Entropy: 1.02591
Value Function Loss: 1.54200

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.24290
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 8,660.52373
Overall Steps per Second: 7,569.35925

Timestep Collection Time: 5.77402
Timestep Consumption Time: 0.83236
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.60637

Cumulative Model Updates: 26,494
Cumulative Timesteps: 441,941,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 441941356...
Checkpoint 441941356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.07697
Policy Entropy: 1.04028
Value Function Loss: 1.52725

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.09928

Collected Steps per Second: 8,871.52626
Overall Steps per Second: 7,697.85132

Timestep Collection Time: 5.63939
Timestep Consumption Time: 0.85983
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.49922

Cumulative Model Updates: 26,497
Cumulative Timesteps: 441,991,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.00352
Policy Entropy: 1.05062
Value Function Loss: 1.43357

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.09767

Collected Steps per Second: 8,705.97395
Overall Steps per Second: 7,531.69887

Timestep Collection Time: 5.74640
Timestep Consumption Time: 0.89593
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.64233

Cumulative Model Updates: 26,500
Cumulative Timesteps: 442,041,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 442041414...
Checkpoint 442041414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.89910
Policy Entropy: 1.03880
Value Function Loss: 1.50612

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.18714
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.08637

Collected Steps per Second: 8,481.28386
Overall Steps per Second: 7,486.64605

Timestep Collection Time: 5.89581
Timestep Consumption Time: 0.78329
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.67909

Cumulative Model Updates: 26,503
Cumulative Timesteps: 442,091,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.13309
Policy Entropy: 1.04245
Value Function Loss: 1.50716

Mean KL Divergence: 0.02800
SB3 Clip Fraction: 0.21543
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.08408

Collected Steps per Second: 8,734.17426
Overall Steps per Second: 7,551.20559

Timestep Collection Time: 5.72647
Timestep Consumption Time: 0.89711
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.62358

Cumulative Model Updates: 26,506
Cumulative Timesteps: 442,141,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442141434...
Checkpoint 442141434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.29272
Policy Entropy: 1.06129
Value Function Loss: 1.61647

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.16377
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 8,605.86901
Overall Steps per Second: 7,543.97361

Timestep Collection Time: 5.81092
Timestep Consumption Time: 0.81795
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 6.62887

Cumulative Model Updates: 26,509
Cumulative Timesteps: 442,191,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.86783
Policy Entropy: 1.06759
Value Function Loss: 1.57390

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.17839
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.09155

Collected Steps per Second: 8,812.98957
Overall Steps per Second: 7,602.69197

Timestep Collection Time: 5.67594
Timestep Consumption Time: 0.90357
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.57951

Cumulative Model Updates: 26,512
Cumulative Timesteps: 442,241,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 442241464...
Checkpoint 442241464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.72020
Policy Entropy: 1.05024
Value Function Loss: 1.55104

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 8,906.71308
Overall Steps per Second: 7,576.84362

Timestep Collection Time: 5.61419
Timestep Consumption Time: 0.98539
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 6.59958

Cumulative Model Updates: 26,515
Cumulative Timesteps: 442,291,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.16422
Policy Entropy: 1.03285
Value Function Loss: 1.48522

Mean KL Divergence: 0.03374
SB3 Clip Fraction: 0.22285
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 8,655.50253
Overall Steps per Second: 7,587.17432

Timestep Collection Time: 5.77667
Timestep Consumption Time: 0.81340
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 6.59007

Cumulative Model Updates: 26,518
Cumulative Timesteps: 442,341,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 442341468...
Checkpoint 442341468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.65475
Policy Entropy: 1.06493
Value Function Loss: 1.52680

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.21344
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 9,213.19808
Overall Steps per Second: 7,880.49496

Timestep Collection Time: 5.42787
Timestep Consumption Time: 0.91793
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.34579

Cumulative Model Updates: 26,521
Cumulative Timesteps: 442,391,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.78534
Policy Entropy: 1.03858
Value Function Loss: 1.45328

Mean KL Divergence: 0.03722
SB3 Clip Fraction: 0.23773
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.10249

Collected Steps per Second: 9,216.86932
Overall Steps per Second: 7,960.94659

Timestep Collection Time: 5.42527
Timestep Consumption Time: 0.85589
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.28116

Cumulative Model Updates: 26,524
Cumulative Timesteps: 442,441,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 442441480...
Checkpoint 442441480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.24073
Policy Entropy: 1.05936
Value Function Loss: 1.45667

Mean KL Divergence: 0.03327
SB3 Clip Fraction: 0.20768
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 9,102.80196
Overall Steps per Second: 7,850.73378

Timestep Collection Time: 5.49435
Timestep Consumption Time: 0.87626
PPO Batch Consumption Time: 0.05228
Total Iteration Time: 6.37061

Cumulative Model Updates: 26,527
Cumulative Timesteps: 442,491,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.75928
Policy Entropy: 1.04853
Value Function Loss: 1.44781

Mean KL Divergence: 0.02948
SB3 Clip Fraction: 0.19201
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 8,572.77575
Overall Steps per Second: 7,507.37615

Timestep Collection Time: 5.83568
Timestep Consumption Time: 0.82816
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.66385

Cumulative Model Updates: 26,530
Cumulative Timesteps: 442,541,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 442541522...
Checkpoint 442541522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.13276
Policy Entropy: 1.03384
Value Function Loss: 1.57826

Mean KL Divergence: 0.03335
SB3 Clip Fraction: 0.21478
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 8,813.32103
Overall Steps per Second: 7,729.13617

Timestep Collection Time: 5.67391
Timestep Consumption Time: 0.79589
PPO Batch Consumption Time: 0.05256
Total Iteration Time: 6.46980

Cumulative Model Updates: 26,533
Cumulative Timesteps: 442,591,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.45921
Policy Entropy: 1.05720
Value Function Loss: 1.56400

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.18033
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 8,873.03370
Overall Steps per Second: 7,686.07942

Timestep Collection Time: 5.63595
Timestep Consumption Time: 0.87036
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 6.50631

Cumulative Model Updates: 26,536
Cumulative Timesteps: 442,641,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 442641536...
Checkpoint 442641536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.84474
Policy Entropy: 1.04674
Value Function Loss: 1.47605

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10922

Collected Steps per Second: 8,718.01049
Overall Steps per Second: 7,570.71336

Timestep Collection Time: 5.73571
Timestep Consumption Time: 0.86921
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.60493

Cumulative Model Updates: 26,539
Cumulative Timesteps: 442,691,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.21066
Policy Entropy: 1.02990
Value Function Loss: 1.41230

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.18665
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 8,696.68501
Overall Steps per Second: 7,695.59586

Timestep Collection Time: 5.75116
Timestep Consumption Time: 0.74814
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 6.49930

Cumulative Model Updates: 26,542
Cumulative Timesteps: 442,741,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442741556...
Checkpoint 442741556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.51735
Policy Entropy: 0.99965
Value Function Loss: 1.51379

Mean KL Divergence: 0.03954
SB3 Clip Fraction: 0.24504
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.08409

Collected Steps per Second: 8,503.11631
Overall Steps per Second: 7,348.69733

Timestep Collection Time: 5.88278
Timestep Consumption Time: 0.92414
PPO Batch Consumption Time: 0.04897
Total Iteration Time: 6.80692

Cumulative Model Updates: 26,545
Cumulative Timesteps: 442,791,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.06121
Policy Entropy: 1.04155
Value Function Loss: 1.57819

Mean KL Divergence: 0.03683
SB3 Clip Fraction: 0.19190
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 8,833.23828
Overall Steps per Second: 7,644.47264

Timestep Collection Time: 5.66338
Timestep Consumption Time: 0.88069
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.54407

Cumulative Model Updates: 26,548
Cumulative Timesteps: 442,841,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 442841604...
Checkpoint 442841604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.27769
Policy Entropy: 1.02428
Value Function Loss: 1.62987

Mean KL Divergence: 0.03637
SB3 Clip Fraction: 0.24323
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.08086

Collected Steps per Second: 8,944.60029
Overall Steps per Second: 7,776.60054

Timestep Collection Time: 5.59242
Timestep Consumption Time: 0.83995
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.43237

Cumulative Model Updates: 26,551
Cumulative Timesteps: 442,891,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.76690
Policy Entropy: 1.04963
Value Function Loss: 1.58361

Mean KL Divergence: 0.03449
SB3 Clip Fraction: 0.24351
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 8,802.74176
Overall Steps per Second: 7,701.02768

Timestep Collection Time: 5.68209
Timestep Consumption Time: 0.81288
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.49498

Cumulative Model Updates: 26,554
Cumulative Timesteps: 442,941,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 442941644...
Checkpoint 442941644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.08325
Policy Entropy: 1.05266
Value Function Loss: 1.61155

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.23335
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.09421

Collected Steps per Second: 8,593.32174
Overall Steps per Second: 7,566.32560

Timestep Collection Time: 5.82103
Timestep Consumption Time: 0.79010
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.61113

Cumulative Model Updates: 26,557
Cumulative Timesteps: 442,991,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.66496
Policy Entropy: 1.04321
Value Function Loss: 1.62618

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.18281
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.08543

Collected Steps per Second: 8,716.31892
Overall Steps per Second: 7,623.36742

Timestep Collection Time: 5.73797
Timestep Consumption Time: 0.82265
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.56062

Cumulative Model Updates: 26,560
Cumulative Timesteps: 443,041,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 443041680...
Checkpoint 443041680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.82548
Policy Entropy: 1.02456
Value Function Loss: 1.53979

Mean KL Divergence: 0.03168
SB3 Clip Fraction: 0.25232
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.06886

Collected Steps per Second: 8,664.18894
Overall Steps per Second: 7,583.28033

Timestep Collection Time: 5.77342
Timestep Consumption Time: 0.82293
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.59635

Cumulative Model Updates: 26,563
Cumulative Timesteps: 443,091,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.53561
Policy Entropy: 1.06595
Value Function Loss: 1.50828

Mean KL Divergence: 0.03655
SB3 Clip Fraction: 0.26184
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 8,918.26438
Overall Steps per Second: 7,734.29895

Timestep Collection Time: 5.60894
Timestep Consumption Time: 0.85862
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 6.46755

Cumulative Model Updates: 26,566
Cumulative Timesteps: 443,141,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 443141724...
Checkpoint 443141724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.45472
Policy Entropy: 1.03256
Value Function Loss: 1.45582

Mean KL Divergence: 0.03191
SB3 Clip Fraction: 0.25205
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 8,620.95274
Overall Steps per Second: 7,437.75010

Timestep Collection Time: 5.80307
Timestep Consumption Time: 0.92316
PPO Batch Consumption Time: 0.05218
Total Iteration Time: 6.72623

Cumulative Model Updates: 26,569
Cumulative Timesteps: 443,191,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.78205
Policy Entropy: 1.05308
Value Function Loss: 1.51705

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.20361
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 8,673.91556
Overall Steps per Second: 7,660.31221

Timestep Collection Time: 5.76787
Timestep Consumption Time: 0.76320
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 6.53107

Cumulative Model Updates: 26,572
Cumulative Timesteps: 443,241,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 443241782...
Checkpoint 443241782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.83374
Policy Entropy: 1.06018
Value Function Loss: 1.46477

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.21355
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 8,948.02855
Overall Steps per Second: 7,758.81907

Timestep Collection Time: 5.59073
Timestep Consumption Time: 0.85690
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.44763

Cumulative Model Updates: 26,575
Cumulative Timesteps: 443,291,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.84597
Policy Entropy: 1.04374
Value Function Loss: 1.47954

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.17377
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.05693

Collected Steps per Second: 9,057.00979
Overall Steps per Second: 8,010.42345

Timestep Collection Time: 5.52301
Timestep Consumption Time: 0.72160
PPO Batch Consumption Time: 0.04177
Total Iteration Time: 6.24461

Cumulative Model Updates: 26,578
Cumulative Timesteps: 443,341,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 443341830...
Checkpoint 443341830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.95005
Policy Entropy: 1.04532
Value Function Loss: 1.47268

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.19088
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.05953

Collected Steps per Second: 8,796.61755
Overall Steps per Second: 7,579.57029

Timestep Collection Time: 5.68423
Timestep Consumption Time: 0.91271
PPO Batch Consumption Time: 0.03984
Total Iteration Time: 6.59694

Cumulative Model Updates: 26,581
Cumulative Timesteps: 443,391,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.89834
Policy Entropy: 1.05464
Value Function Loss: 1.47397

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 8,600.48318
Overall Steps per Second: 7,368.03732

Timestep Collection Time: 5.81642
Timestep Consumption Time: 0.97291
PPO Batch Consumption Time: 0.04981
Total Iteration Time: 6.78933

Cumulative Model Updates: 26,584
Cumulative Timesteps: 443,441,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 443441856...
Checkpoint 443441856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.10856
Policy Entropy: 1.05733
Value Function Loss: 1.44835

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 8,985.94838
Overall Steps per Second: 7,814.87541

Timestep Collection Time: 5.56469
Timestep Consumption Time: 0.83388
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.39857

Cumulative Model Updates: 26,587
Cumulative Timesteps: 443,491,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.14755
Policy Entropy: 1.06065
Value Function Loss: 1.46531

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.06234

Collected Steps per Second: 8,865.16449
Overall Steps per Second: 7,656.40414

Timestep Collection Time: 5.64276
Timestep Consumption Time: 0.89085
PPO Batch Consumption Time: 0.04570
Total Iteration Time: 6.53362

Cumulative Model Updates: 26,590
Cumulative Timesteps: 443,541,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 443541884...
Checkpoint 443541884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.59463
Policy Entropy: 1.06510
Value Function Loss: 1.51596

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.07412
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 8,812.99094
Overall Steps per Second: 7,686.23373

Timestep Collection Time: 5.67526
Timestep Consumption Time: 0.83196
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 6.50722

Cumulative Model Updates: 26,593
Cumulative Timesteps: 443,591,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.17724
Policy Entropy: 1.07170
Value Function Loss: 1.49014

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.07884
Value Function Update Magnitude: 0.07620

Collected Steps per Second: 8,325.81489
Overall Steps per Second: 7,187.61802

Timestep Collection Time: 6.00878
Timestep Consumption Time: 0.95152
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 6.96030

Cumulative Model Updates: 26,596
Cumulative Timesteps: 443,641,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443641928...
Checkpoint 443641928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.50970
Policy Entropy: 1.07307
Value Function Loss: 1.47571

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.07839
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 8,526.23297
Overall Steps per Second: 7,423.34490

Timestep Collection Time: 5.86496
Timestep Consumption Time: 0.87136
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 6.73632

Cumulative Model Updates: 26,599
Cumulative Timesteps: 443,691,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.78030
Policy Entropy: 1.07519
Value Function Loss: 1.53368

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.07340
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 8,741.81617
Overall Steps per Second: 7,650.94710

Timestep Collection Time: 5.72215
Timestep Consumption Time: 0.81586
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.53801

Cumulative Model Updates: 26,602
Cumulative Timesteps: 443,741,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 443741956...
Checkpoint 443741956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.69092
Policy Entropy: 1.06468
Value Function Loss: 1.56318

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.07268
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 8,728.20090
Overall Steps per Second: 7,607.25086

Timestep Collection Time: 5.73062
Timestep Consumption Time: 0.84442
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 6.57504

Cumulative Model Updates: 26,605
Cumulative Timesteps: 443,791,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.96337
Policy Entropy: 1.07882
Value Function Loss: 1.63629

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.17058
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.05003

Collected Steps per Second: 8,876.77299
Overall Steps per Second: 7,826.34111

Timestep Collection Time: 5.63403
Timestep Consumption Time: 0.75619
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 6.39021

Cumulative Model Updates: 26,608
Cumulative Timesteps: 443,841,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 443841986...
Checkpoint 443841986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.55753
Policy Entropy: 1.08224
Value Function Loss: 1.60783

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.04907

Collected Steps per Second: 8,556.68665
Overall Steps per Second: 7,266.49393

Timestep Collection Time: 5.84525
Timestep Consumption Time: 1.03785
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 6.88310

Cumulative Model Updates: 26,611
Cumulative Timesteps: 443,892,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.74709
Policy Entropy: 1.08956
Value Function Loss: 1.71248

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.06118

Collected Steps per Second: 8,740.65977
Overall Steps per Second: 7,709.72384

Timestep Collection Time: 5.72222
Timestep Consumption Time: 0.76517
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.48739

Cumulative Model Updates: 26,614
Cumulative Timesteps: 443,942,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 443942018...
Checkpoint 443942018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.97974
Policy Entropy: 1.09499
Value Function Loss: 1.64193

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 8,781.80862
Overall Steps per Second: 7,587.51058

Timestep Collection Time: 5.69473
Timestep Consumption Time: 0.89637
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.59109

Cumulative Model Updates: 26,617
Cumulative Timesteps: 443,992,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.49459
Policy Entropy: 1.09321
Value Function Loss: 1.63244

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.06327

Collected Steps per Second: 8,695.20276
Overall Steps per Second: 7,557.82645

Timestep Collection Time: 5.75237
Timestep Consumption Time: 0.86567
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.61804

Cumulative Model Updates: 26,620
Cumulative Timesteps: 444,042,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 444042046...
Checkpoint 444042046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.81809
Policy Entropy: 1.08088
Value Function Loss: 1.50886

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.06582

Collected Steps per Second: 9,206.67652
Overall Steps per Second: 8,066.93452

Timestep Collection Time: 5.43084
Timestep Consumption Time: 0.76730
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.19814

Cumulative Model Updates: 26,623
Cumulative Timesteps: 444,092,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.26756
Policy Entropy: 1.08883
Value Function Loss: 1.57193

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 8,761.77290
Overall Steps per Second: 7,559.56886

Timestep Collection Time: 5.70866
Timestep Consumption Time: 0.90785
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.61651

Cumulative Model Updates: 26,626
Cumulative Timesteps: 444,142,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 444142064...
Checkpoint 444142064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.30156
Policy Entropy: 1.09349
Value Function Loss: 1.55014

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.09638

Collected Steps per Second: 9,016.90218
Overall Steps per Second: 7,827.50576

Timestep Collection Time: 5.54647
Timestep Consumption Time: 0.84279
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.38926

Cumulative Model Updates: 26,629
Cumulative Timesteps: 444,192,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.39100
Policy Entropy: 1.10182
Value Function Loss: 1.71148

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 9,391.68220
Overall Steps per Second: 8,085.08866

Timestep Collection Time: 5.32514
Timestep Consumption Time: 0.86057
PPO Batch Consumption Time: 0.04987
Total Iteration Time: 6.18571

Cumulative Model Updates: 26,632
Cumulative Timesteps: 444,242,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 444242088...
Checkpoint 444242088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.37481
Policy Entropy: 1.11150
Value Function Loss: 1.64450

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 9,177.11098
Overall Steps per Second: 7,984.27878

Timestep Collection Time: 5.45073
Timestep Consumption Time: 0.81433
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.26506

Cumulative Model Updates: 26,635
Cumulative Timesteps: 444,292,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.56096
Policy Entropy: 1.10761
Value Function Loss: 1.67200

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.07473
Value Function Update Magnitude: 0.07800

Collected Steps per Second: 8,703.44715
Overall Steps per Second: 7,691.56442

Timestep Collection Time: 5.74830
Timestep Consumption Time: 0.75623
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.50453

Cumulative Model Updates: 26,638
Cumulative Timesteps: 444,342,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 444342140...
Checkpoint 444342140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.08203
Policy Entropy: 1.09921
Value Function Loss: 1.56673

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.07538
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 8,435.10561
Overall Steps per Second: 7,410.78200

Timestep Collection Time: 5.92974
Timestep Consumption Time: 0.81961
PPO Batch Consumption Time: 0.04467
Total Iteration Time: 6.74936

Cumulative Model Updates: 26,641
Cumulative Timesteps: 444,392,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.85045
Policy Entropy: 1.11449
Value Function Loss: 1.67729

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 8,818.38523
Overall Steps per Second: 7,684.76581

Timestep Collection Time: 5.67020
Timestep Consumption Time: 0.83644
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.50664

Cumulative Model Updates: 26,644
Cumulative Timesteps: 444,442,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 444442160...
Checkpoint 444442160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.53783
Policy Entropy: 1.12028
Value Function Loss: 1.69911

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 8,936.28592
Overall Steps per Second: 7,690.37128

Timestep Collection Time: 5.59696
Timestep Consumption Time: 0.90676
PPO Batch Consumption Time: 0.05001
Total Iteration Time: 6.50372

Cumulative Model Updates: 26,647
Cumulative Timesteps: 444,492,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.78256
Policy Entropy: 1.10179
Value Function Loss: 1.68903

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 8,705.74428
Overall Steps per Second: 7,570.13832

Timestep Collection Time: 5.74517
Timestep Consumption Time: 0.86184
PPO Batch Consumption Time: 0.04836
Total Iteration Time: 6.60701

Cumulative Model Updates: 26,650
Cumulative Timesteps: 444,542,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444542192...
Checkpoint 444542192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.05786
Policy Entropy: 1.09129
Value Function Loss: 1.53728

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.19360
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.07662

Collected Steps per Second: 8,711.85212
Overall Steps per Second: 7,656.14279

Timestep Collection Time: 5.74183
Timestep Consumption Time: 0.79174
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.53358

Cumulative Model Updates: 26,653
Cumulative Timesteps: 444,592,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.27803
Policy Entropy: 1.09242
Value Function Loss: 1.51441

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 8,621.39895
Overall Steps per Second: 7,550.29100

Timestep Collection Time: 5.80231
Timestep Consumption Time: 0.82313
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.62544

Cumulative Model Updates: 26,656
Cumulative Timesteps: 444,642,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 444642238...
Checkpoint 444642238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.18109
Policy Entropy: 1.10806
Value Function Loss: 1.50620

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.07772

Collected Steps per Second: 8,834.47543
Overall Steps per Second: 7,735.55519

Timestep Collection Time: 5.66123
Timestep Consumption Time: 0.80424
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.46547

Cumulative Model Updates: 26,659
Cumulative Timesteps: 444,692,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.79428
Policy Entropy: 1.07303
Value Function Loss: 1.57205

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 8,751.65198
Overall Steps per Second: 7,630.44970

Timestep Collection Time: 5.71504
Timestep Consumption Time: 0.83976
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.55479

Cumulative Model Updates: 26,662
Cumulative Timesteps: 444,742,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444742268...
Checkpoint 444742268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.35732
Policy Entropy: 1.07103
Value Function Loss: 1.50105

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.06531

Collected Steps per Second: 8,722.61525
Overall Steps per Second: 7,611.26456

Timestep Collection Time: 5.73383
Timestep Consumption Time: 0.83722
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.57105

Cumulative Model Updates: 26,665
Cumulative Timesteps: 444,792,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.04483
Policy Entropy: 1.08825
Value Function Loss: 1.46950

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.18199
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.07736

Collected Steps per Second: 8,521.13235
Overall Steps per Second: 7,527.13630

Timestep Collection Time: 5.86894
Timestep Consumption Time: 0.77502
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.64396

Cumulative Model Updates: 26,668
Cumulative Timesteps: 444,842,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 444842292...
Checkpoint 444842292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.28022
Policy Entropy: 1.08745
Value Function Loss: 1.43922

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.17389
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.08309

Collected Steps per Second: 8,935.03015
Overall Steps per Second: 7,738.19265

Timestep Collection Time: 5.59819
Timestep Consumption Time: 0.86585
PPO Batch Consumption Time: 0.04819
Total Iteration Time: 6.46404

Cumulative Model Updates: 26,671
Cumulative Timesteps: 444,892,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.63487
Policy Entropy: 1.07959
Value Function Loss: 1.53643

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 8,891.88874
Overall Steps per Second: 7,762.67370

Timestep Collection Time: 5.62310
Timestep Consumption Time: 0.81798
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 6.44108

Cumulative Model Updates: 26,674
Cumulative Timesteps: 444,942,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 444942312...
Checkpoint 444942312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.23460
Policy Entropy: 1.06222
Value Function Loss: 1.53940

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 8,869.85549
Overall Steps per Second: 7,797.89136

Timestep Collection Time: 5.63730
Timestep Consumption Time: 0.77495
PPO Batch Consumption Time: 0.04637
Total Iteration Time: 6.41225

Cumulative Model Updates: 26,677
Cumulative Timesteps: 444,992,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.09103
Policy Entropy: 1.08106
Value Function Loss: 1.58071

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.17700
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 9,134.43997
Overall Steps per Second: 7,758.05548

Timestep Collection Time: 5.47707
Timestep Consumption Time: 0.97171
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.44878

Cumulative Model Updates: 26,680
Cumulative Timesteps: 445,042,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 445042344...
Checkpoint 445042344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.54634
Policy Entropy: 1.08569
Value Function Loss: 1.49486

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 8,818.51277
Overall Steps per Second: 7,667.70262

Timestep Collection Time: 5.66989
Timestep Consumption Time: 0.85097
PPO Batch Consumption Time: 0.05298
Total Iteration Time: 6.52086

Cumulative Model Updates: 26,683
Cumulative Timesteps: 445,092,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.31201
Policy Entropy: 1.07616
Value Function Loss: 1.39121

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.06686

Collected Steps per Second: 9,121.97239
Overall Steps per Second: 7,943.27106

Timestep Collection Time: 5.48127
Timestep Consumption Time: 0.81337
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.29464

Cumulative Model Updates: 26,686
Cumulative Timesteps: 445,142,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 445142344...
Checkpoint 445142344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.04171
Policy Entropy: 1.07736
Value Function Loss: 1.29580

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.15389
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 8,524.84434
Overall Steps per Second: 7,432.86470

Timestep Collection Time: 5.86709
Timestep Consumption Time: 0.86195
PPO Batch Consumption Time: 0.04643
Total Iteration Time: 6.72903

Cumulative Model Updates: 26,689
Cumulative Timesteps: 445,192,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.97386
Policy Entropy: 1.09442
Value Function Loss: 1.38399

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.16003
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 8,921.70399
Overall Steps per Second: 7,719.17821

Timestep Collection Time: 5.60655
Timestep Consumption Time: 0.87341
PPO Batch Consumption Time: 0.04705
Total Iteration Time: 6.47996

Cumulative Model Updates: 26,692
Cumulative Timesteps: 445,242,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 445242380...
Checkpoint 445242380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.59886
Policy Entropy: 1.10270
Value Function Loss: 1.43433

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.16943
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.06207

Collected Steps per Second: 8,551.27493
Overall Steps per Second: 7,400.06615

Timestep Collection Time: 5.84895
Timestep Consumption Time: 0.90991
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.75886

Cumulative Model Updates: 26,695
Cumulative Timesteps: 445,292,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.99356
Policy Entropy: 1.08957
Value Function Loss: 1.61885

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 8,776.62024
Overall Steps per Second: 7,657.10246

Timestep Collection Time: 5.69695
Timestep Consumption Time: 0.83293
PPO Batch Consumption Time: 0.04466
Total Iteration Time: 6.52989

Cumulative Model Updates: 26,698
Cumulative Timesteps: 445,342,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 445342396...
Checkpoint 445342396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.72541
Policy Entropy: 1.06124
Value Function Loss: 1.54505

Mean KL Divergence: 0.03687
SB3 Clip Fraction: 0.24791
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 8,844.73868
Overall Steps per Second: 7,800.19098

Timestep Collection Time: 5.65534
Timestep Consumption Time: 0.75732
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.41266

Cumulative Model Updates: 26,701
Cumulative Timesteps: 445,392,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.78389
Policy Entropy: 1.07747
Value Function Loss: 1.64996

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 8,834.95584
Overall Steps per Second: 7,660.42672

Timestep Collection Time: 5.65979
Timestep Consumption Time: 0.86778
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.52757

Cumulative Model Updates: 26,704
Cumulative Timesteps: 445,442,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 445442420...
Checkpoint 445442420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.30384
Policy Entropy: 1.07463
Value Function Loss: 1.59550

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.06725

Collected Steps per Second: 8,767.87401
Overall Steps per Second: 7,734.55390

Timestep Collection Time: 5.70309
Timestep Consumption Time: 0.76192
PPO Batch Consumption Time: 0.03950
Total Iteration Time: 6.46501

Cumulative Model Updates: 26,707
Cumulative Timesteps: 445,492,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.59527
Policy Entropy: 1.07735
Value Function Loss: 1.51980

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 8,560.99928
Overall Steps per Second: 7,505.13090

Timestep Collection Time: 5.84324
Timestep Consumption Time: 0.82206
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.66531

Cumulative Model Updates: 26,710
Cumulative Timesteps: 445,542,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 445542448...
Checkpoint 445542448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.36607
Policy Entropy: 1.07316
Value Function Loss: 1.44974

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.06197

Collected Steps per Second: 8,687.51888
Overall Steps per Second: 7,581.13490

Timestep Collection Time: 5.75722
Timestep Consumption Time: 0.84020
PPO Batch Consumption Time: 0.03894
Total Iteration Time: 6.59743

Cumulative Model Updates: 26,713
Cumulative Timesteps: 445,592,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.10518
Policy Entropy: 1.05927
Value Function Loss: 1.49035

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.06222

Collected Steps per Second: 8,805.09871
Overall Steps per Second: 7,626.19224

Timestep Collection Time: 5.68103
Timestep Consumption Time: 0.87821
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.55924

Cumulative Model Updates: 26,716
Cumulative Timesteps: 445,642,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445642486...
Checkpoint 445642486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.20125
Policy Entropy: 1.07746
Value Function Loss: 1.56593

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 8,769.86986
Overall Steps per Second: 7,616.61982

Timestep Collection Time: 5.70271
Timestep Consumption Time: 0.86346
PPO Batch Consumption Time: 0.04106
Total Iteration Time: 6.56617

Cumulative Model Updates: 26,719
Cumulative Timesteps: 445,692,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.18427
Policy Entropy: 1.07486
Value Function Loss: 1.58873

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 8,487.03907
Overall Steps per Second: 7,469.58451

Timestep Collection Time: 5.89204
Timestep Consumption Time: 0.80257
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.69462

Cumulative Model Updates: 26,722
Cumulative Timesteps: 445,742,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 445742504...
Checkpoint 445742504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.47256
Policy Entropy: 1.06293
Value Function Loss: 1.49395

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.15710
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.05932

Collected Steps per Second: 8,803.99268
Overall Steps per Second: 7,565.20362

Timestep Collection Time: 5.67947
Timestep Consumption Time: 0.93000
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.60947

Cumulative Model Updates: 26,725
Cumulative Timesteps: 445,792,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.11958
Policy Entropy: 1.05502
Value Function Loss: 1.47285

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.18764
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.05275

Collected Steps per Second: 8,713.22936
Overall Steps per Second: 7,595.82475

Timestep Collection Time: 5.74138
Timestep Consumption Time: 0.84460
PPO Batch Consumption Time: 0.04194
Total Iteration Time: 6.58599

Cumulative Model Updates: 26,728
Cumulative Timesteps: 445,842,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 445842532...
Checkpoint 445842532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.72273
Policy Entropy: 1.05939
Value Function Loss: 1.46615

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.15956
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 8,704.99209
Overall Steps per Second: 7,688.32922

Timestep Collection Time: 5.74682
Timestep Consumption Time: 0.75993
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.50675

Cumulative Model Updates: 26,731
Cumulative Timesteps: 445,892,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.84614
Policy Entropy: 1.06301
Value Function Loss: 1.38512

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.19171
Policy Update Magnitude: 0.04452
Value Function Update Magnitude: 0.06615

Collected Steps per Second: 8,942.42993
Overall Steps per Second: 7,715.65972

Timestep Collection Time: 5.59378
Timestep Consumption Time: 0.88940
PPO Batch Consumption Time: 0.04563
Total Iteration Time: 6.48318

Cumulative Model Updates: 26,734
Cumulative Timesteps: 445,942,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445942580...
Checkpoint 445942580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.15626
Policy Entropy: 1.03882
Value Function Loss: 1.32161

Mean KL Divergence: 0.03269
SB3 Clip Fraction: 0.21878
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.06583

Collected Steps per Second: 8,777.70679
Overall Steps per Second: 7,567.23353

Timestep Collection Time: 5.69716
Timestep Consumption Time: 0.91133
PPO Batch Consumption Time: 0.05112
Total Iteration Time: 6.60849

Cumulative Model Updates: 26,737
Cumulative Timesteps: 445,992,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.83685
Policy Entropy: 1.06819
Value Function Loss: 1.38149

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.19516
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 9,145.19633
Overall Steps per Second: 7,839.67989

Timestep Collection Time: 5.47041
Timestep Consumption Time: 0.91097
PPO Batch Consumption Time: 0.05161
Total Iteration Time: 6.38138

Cumulative Model Updates: 26,740
Cumulative Timesteps: 446,042,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 446042616...
Checkpoint 446042616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.11500
Policy Entropy: 1.06387
Value Function Loss: 1.43936

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.17228
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 8,953.84335
Overall Steps per Second: 7,744.56306

Timestep Collection Time: 5.58687
Timestep Consumption Time: 0.87237
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 6.45924

Cumulative Model Updates: 26,743
Cumulative Timesteps: 446,092,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.26641
Policy Entropy: 1.05159
Value Function Loss: 1.48221

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.06709

Collected Steps per Second: 8,754.36248
Overall Steps per Second: 7,748.45474

Timestep Collection Time: 5.71235
Timestep Consumption Time: 0.74158
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 6.45393

Cumulative Model Updates: 26,746
Cumulative Timesteps: 446,142,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 446142648...
Checkpoint 446142648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.44969
Policy Entropy: 1.01849
Value Function Loss: 1.44056

Mean KL Divergence: 0.05249
SB3 Clip Fraction: 0.29589
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 8,616.83068
Overall Steps per Second: 7,447.32714

Timestep Collection Time: 5.80376
Timestep Consumption Time: 0.91140
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.71516

Cumulative Model Updates: 26,749
Cumulative Timesteps: 446,192,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.99821
Policy Entropy: 1.06057
Value Function Loss: 1.43098

Mean KL Divergence: 0.03199
SB3 Clip Fraction: 0.24934
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 8,581.50248
Overall Steps per Second: 7,518.97106

Timestep Collection Time: 5.82835
Timestep Consumption Time: 0.82362
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.65197

Cumulative Model Updates: 26,752
Cumulative Timesteps: 446,242,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 446242674...
Checkpoint 446242674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.94847
Policy Entropy: 1.01204
Value Function Loss: 1.39622

Mean KL Divergence: 0.05857
SB3 Clip Fraction: 0.32680
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.06113

Collected Steps per Second: 8,284.14371
Overall Steps per Second: 7,243.09168

Timestep Collection Time: 6.03828
Timestep Consumption Time: 0.86788
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 6.90617

Cumulative Model Updates: 26,755
Cumulative Timesteps: 446,292,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.35958
Policy Entropy: 1.04599
Value Function Loss: 1.32992

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.22651
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 8,674.25208
Overall Steps per Second: 7,523.07699

Timestep Collection Time: 5.76649
Timestep Consumption Time: 0.88238
PPO Batch Consumption Time: 0.04829
Total Iteration Time: 6.64888

Cumulative Model Updates: 26,758
Cumulative Timesteps: 446,342,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 446342716...
Checkpoint 446342716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.58797
Policy Entropy: 1.01889
Value Function Loss: 1.28493

Mean KL Divergence: 0.02754
SB3 Clip Fraction: 0.23296
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 8,614.65153
Overall Steps per Second: 7,643.57461

Timestep Collection Time: 5.80407
Timestep Consumption Time: 0.73738
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.54144

Cumulative Model Updates: 26,761
Cumulative Timesteps: 446,392,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.24633
Policy Entropy: 1.03027
Value Function Loss: 1.30946

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.21292
Policy Update Magnitude: 0.04332
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 8,399.57820
Overall Steps per Second: 7,291.37355

Timestep Collection Time: 5.95387
Timestep Consumption Time: 0.90492
PPO Batch Consumption Time: 0.05411
Total Iteration Time: 6.85879

Cumulative Model Updates: 26,764
Cumulative Timesteps: 446,442,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 446442726...
Checkpoint 446442726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.24054
Policy Entropy: 1.01606
Value Function Loss: 1.32348

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 8,796.23080
Overall Steps per Second: 7,793.93017

Timestep Collection Time: 5.68766
Timestep Consumption Time: 0.73143
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.41910

Cumulative Model Updates: 26,767
Cumulative Timesteps: 446,492,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.03240
Policy Entropy: 1.01782
Value Function Loss: 1.45645

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 8,898.99732
Overall Steps per Second: 7,692.47447

Timestep Collection Time: 5.62153
Timestep Consumption Time: 0.88171
PPO Batch Consumption Time: 0.04730
Total Iteration Time: 6.50324

Cumulative Model Updates: 26,770
Cumulative Timesteps: 446,542,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446542782...
Checkpoint 446542782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.81476
Policy Entropy: 1.01193
Value Function Loss: 1.47688

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.17864
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.05201

Collected Steps per Second: 8,944.18187
Overall Steps per Second: 7,739.51879

Timestep Collection Time: 5.59224
Timestep Consumption Time: 0.87044
PPO Batch Consumption Time: 0.04005
Total Iteration Time: 6.46268

Cumulative Model Updates: 26,773
Cumulative Timesteps: 446,592,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.41535
Policy Entropy: 1.02289
Value Function Loss: 1.52594

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.17741
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 8,563.38213
Overall Steps per Second: 7,519.75228

Timestep Collection Time: 5.84092
Timestep Consumption Time: 0.81063
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.65155

Cumulative Model Updates: 26,776
Cumulative Timesteps: 446,642,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 446642818...
Checkpoint 446642818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.66847
Policy Entropy: 1.02799
Value Function Loss: 1.41919

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 8,633.57822
Overall Steps per Second: 7,542.56214

Timestep Collection Time: 5.79343
Timestep Consumption Time: 0.83801
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.63143

Cumulative Model Updates: 26,779
Cumulative Timesteps: 446,692,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.88593
Policy Entropy: 1.02156
Value Function Loss: 1.42970

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.18457
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.06392

Collected Steps per Second: 8,983.47256
Overall Steps per Second: 7,778.74884

Timestep Collection Time: 5.56756
Timestep Consumption Time: 0.86227
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.42983

Cumulative Model Updates: 26,782
Cumulative Timesteps: 446,742,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 446742852...
Checkpoint 446742852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.56401
Policy Entropy: 1.01340
Value Function Loss: 1.44008

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.21211
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.06246

Collected Steps per Second: 8,843.63457
Overall Steps per Second: 7,709.01830

Timestep Collection Time: 5.65537
Timestep Consumption Time: 0.83236
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.48773

Cumulative Model Updates: 26,785
Cumulative Timesteps: 446,792,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.14938
Policy Entropy: 1.01899
Value Function Loss: 1.50001

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.18741
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 8,850.73866
Overall Steps per Second: 7,731.17209

Timestep Collection Time: 5.65151
Timestep Consumption Time: 0.81841
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.46991

Cumulative Model Updates: 26,788
Cumulative Timesteps: 446,842,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 446842886...
Checkpoint 446842886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.65543
Policy Entropy: 1.03103
Value Function Loss: 1.40244

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.19805
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 8,648.11605
Overall Steps per Second: 7,599.49552

Timestep Collection Time: 5.78253
Timestep Consumption Time: 0.79791
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.58044

Cumulative Model Updates: 26,791
Cumulative Timesteps: 446,892,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.60297
Policy Entropy: 1.00855
Value Function Loss: 1.32507

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.18552
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 8,734.63046
Overall Steps per Second: 7,662.08492

Timestep Collection Time: 5.72457
Timestep Consumption Time: 0.80133
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.52590

Cumulative Model Updates: 26,794
Cumulative Timesteps: 446,942,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 446942896...
Checkpoint 446942896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.15554
Policy Entropy: 1.01632
Value Function Loss: 1.41277

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.20100
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.05863

Collected Steps per Second: 8,936.84678
Overall Steps per Second: 7,801.05556

Timestep Collection Time: 5.59795
Timestep Consumption Time: 0.81503
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.41298

Cumulative Model Updates: 26,797
Cumulative Timesteps: 446,992,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.45660
Policy Entropy: 1.02772
Value Function Loss: 1.44433

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 9,076.77854
Overall Steps per Second: 7,811.57026

Timestep Collection Time: 5.51121
Timestep Consumption Time: 0.89263
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.40383

Cumulative Model Updates: 26,800
Cumulative Timesteps: 447,042,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 447042948...
Checkpoint 447042948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.88735
Policy Entropy: 1.03680
Value Function Loss: 1.52634

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.07072

Collected Steps per Second: 8,737.76667
Overall Steps per Second: 7,504.64517

Timestep Collection Time: 5.72526
Timestep Consumption Time: 0.94074
PPO Batch Consumption Time: 0.05199
Total Iteration Time: 6.66600

Cumulative Model Updates: 26,803
Cumulative Timesteps: 447,092,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.45438
Policy Entropy: 1.03210
Value Function Loss: 1.45482

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.06443

Collected Steps per Second: 8,605.71172
Overall Steps per Second: 7,606.96077

Timestep Collection Time: 5.81033
Timestep Consumption Time: 0.76286
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.57319

Cumulative Model Updates: 26,806
Cumulative Timesteps: 447,142,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 447142976...
Checkpoint 447142976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.52780
Policy Entropy: 1.03483
Value Function Loss: 1.55252

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.06412

Collected Steps per Second: 8,681.05015
Overall Steps per Second: 7,529.19614

Timestep Collection Time: 5.76198
Timestep Consumption Time: 0.88150
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.64347

Cumulative Model Updates: 26,809
Cumulative Timesteps: 447,192,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.63038
Policy Entropy: 1.03411
Value Function Loss: 1.56401

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.07471
Value Function Update Magnitude: 0.05855

Collected Steps per Second: 8,645.55745
Overall Steps per Second: 7,538.38536

Timestep Collection Time: 5.78632
Timestep Consumption Time: 0.84984
PPO Batch Consumption Time: 0.04783
Total Iteration Time: 6.63617

Cumulative Model Updates: 26,812
Cumulative Timesteps: 447,243,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 447243022...
Checkpoint 447243022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.72234
Policy Entropy: 1.03228
Value Function Loss: 1.50130

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.06111

Collected Steps per Second: 8,728.61694
Overall Steps per Second: 7,694.20039

Timestep Collection Time: 5.72851
Timestep Consumption Time: 0.77015
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.49866

Cumulative Model Updates: 26,815
Cumulative Timesteps: 447,293,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.65616
Policy Entropy: 1.03418
Value Function Loss: 1.41615

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.07279
Value Function Update Magnitude: 0.06258

Collected Steps per Second: 8,571.65109
Overall Steps per Second: 7,518.37728

Timestep Collection Time: 5.83575
Timestep Consumption Time: 0.81755
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.65330

Cumulative Model Updates: 26,818
Cumulative Timesteps: 447,343,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 447343046...
Checkpoint 447343046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.17864
Policy Entropy: 1.01798
Value Function Loss: 1.35770

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.19983
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 8,904.25907
Overall Steps per Second: 7,803.59634

Timestep Collection Time: 5.61821
Timestep Consumption Time: 0.79242
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.41063

Cumulative Model Updates: 26,821
Cumulative Timesteps: 447,393,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.62253
Policy Entropy: 1.03801
Value Function Loss: 1.45162

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.19419
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.06422

Collected Steps per Second: 8,985.27522
Overall Steps per Second: 7,707.55320

Timestep Collection Time: 5.56666
Timestep Consumption Time: 0.92282
PPO Batch Consumption Time: 0.04124
Total Iteration Time: 6.48948

Cumulative Model Updates: 26,824
Cumulative Timesteps: 447,443,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 447443090...
Checkpoint 447443090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.71155
Policy Entropy: 1.05045
Value Function Loss: 1.45167

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.21347
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.06213

Collected Steps per Second: 8,768.34408
Overall Steps per Second: 7,594.45005

Timestep Collection Time: 5.70461
Timestep Consumption Time: 0.88178
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.58639

Cumulative Model Updates: 26,827
Cumulative Timesteps: 447,493,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.89890
Policy Entropy: 1.04100
Value Function Loss: 1.49380

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.08587

Collected Steps per Second: 8,903.97598
Overall Steps per Second: 7,793.57642

Timestep Collection Time: 5.61816
Timestep Consumption Time: 0.80045
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 6.41862

Cumulative Model Updates: 26,830
Cumulative Timesteps: 447,543,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 447543134...
Checkpoint 447543134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.63102
Policy Entropy: 1.02666
Value Function Loss: 1.37625

Mean KL Divergence: 0.02510
SB3 Clip Fraction: 0.23767
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 8,489.55821
Overall Steps per Second: 7,300.52212

Timestep Collection Time: 5.89218
Timestep Consumption Time: 0.95966
PPO Batch Consumption Time: 0.04946
Total Iteration Time: 6.85184

Cumulative Model Updates: 26,833
Cumulative Timesteps: 447,593,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.05450
Policy Entropy: 1.04645
Value Function Loss: 1.39010

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.07701

Collected Steps per Second: 8,680.22734
Overall Steps per Second: 7,544.33291

Timestep Collection Time: 5.76298
Timestep Consumption Time: 0.86769
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.63067

Cumulative Model Updates: 26,836
Cumulative Timesteps: 447,643,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 447643180...
Checkpoint 447643180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.22455
Policy Entropy: 1.04826
Value Function Loss: 1.37580

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 8,999.69434
Overall Steps per Second: 7,797.83882

Timestep Collection Time: 5.55841
Timestep Consumption Time: 0.85670
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.41511

Cumulative Model Updates: 26,839
Cumulative Timesteps: 447,693,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.40059
Policy Entropy: 1.04759
Value Function Loss: 1.46410

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.07776
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 9,189.05530
Overall Steps per Second: 7,918.26446

Timestep Collection Time: 5.44278
Timestep Consumption Time: 0.87350
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.31628

Cumulative Model Updates: 26,842
Cumulative Timesteps: 447,743,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 447743218...
Checkpoint 447743218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.18845
Policy Entropy: 1.05433
Value Function Loss: 1.40865

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.16142
Policy Update Magnitude: 0.07342
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 8,904.90178
Overall Steps per Second: 7,857.73461

Timestep Collection Time: 5.61803
Timestep Consumption Time: 0.74869
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.36672

Cumulative Model Updates: 26,845
Cumulative Timesteps: 447,793,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.42432
Policy Entropy: 1.04881
Value Function Loss: 1.45122

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.07085
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 9,124.03167
Overall Steps per Second: 7,863.27015

Timestep Collection Time: 5.48223
Timestep Consumption Time: 0.87900
PPO Batch Consumption Time: 0.04292
Total Iteration Time: 6.36122

Cumulative Model Updates: 26,848
Cumulative Timesteps: 447,843,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 447843266...
Checkpoint 447843266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.27148
Policy Entropy: 1.04102
Value Function Loss: 1.50591

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.19234
Policy Update Magnitude: 0.06665
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 9,158.93717
Overall Steps per Second: 7,964.13813

Timestep Collection Time: 5.46046
Timestep Consumption Time: 0.81919
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.27965

Cumulative Model Updates: 26,851
Cumulative Timesteps: 447,893,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.75414
Policy Entropy: 1.06612
Value Function Loss: 1.57485

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.18561
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 9,309.87291
Overall Steps per Second: 8,036.17965

Timestep Collection Time: 5.37150
Timestep Consumption Time: 0.85136
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 6.22286

Cumulative Model Updates: 26,854
Cumulative Timesteps: 447,943,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 447943286...
Checkpoint 447943286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.57714
Policy Entropy: 1.07504
Value Function Loss: 1.55864

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.18849
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 8,711.92595
Overall Steps per Second: 7,559.91392

Timestep Collection Time: 5.74133
Timestep Consumption Time: 0.87489
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.61621

Cumulative Model Updates: 26,857
Cumulative Timesteps: 447,993,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.86758
Policy Entropy: 1.04507
Value Function Loss: 1.47476

Mean KL Divergence: 0.03016
SB3 Clip Fraction: 0.20905
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.06554

Collected Steps per Second: 8,611.16689
Overall Steps per Second: 7,573.50681

Timestep Collection Time: 5.80804
Timestep Consumption Time: 0.79577
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.60381

Cumulative Model Updates: 26,860
Cumulative Timesteps: 448,043,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 448043318...
Checkpoint 448043318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.61824
Policy Entropy: 1.06298
Value Function Loss: 1.46901

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.21595
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 8,970.73135
Overall Steps per Second: 7,672.94059

Timestep Collection Time: 5.57524
Timestep Consumption Time: 0.94299
PPO Batch Consumption Time: 0.05162
Total Iteration Time: 6.51823

Cumulative Model Updates: 26,863
Cumulative Timesteps: 448,093,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.33661
Policy Entropy: 1.06977
Value Function Loss: 1.43756

Mean KL Divergence: 0.03572
SB3 Clip Fraction: 0.25105
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 8,708.53020
Overall Steps per Second: 7,653.47256

Timestep Collection Time: 5.74265
Timestep Consumption Time: 0.79164
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.53429

Cumulative Model Updates: 26,866
Cumulative Timesteps: 448,143,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 448143342...
Checkpoint 448143342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.38410
Policy Entropy: 1.05790
Value Function Loss: 1.49682

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.19258
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 8,952.46061
Overall Steps per Second: 7,888.18618

Timestep Collection Time: 5.58617
Timestep Consumption Time: 0.75369
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.33986

Cumulative Model Updates: 26,869
Cumulative Timesteps: 448,193,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.26195
Policy Entropy: 1.05649
Value Function Loss: 1.53934

Mean KL Divergence: 0.03392
SB3 Clip Fraction: 0.23537
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.05951

Collected Steps per Second: 8,726.26420
Overall Steps per Second: 7,497.06782

Timestep Collection Time: 5.73350
Timestep Consumption Time: 0.94005
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.67354

Cumulative Model Updates: 26,872
Cumulative Timesteps: 448,243,384

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 448243384...
Checkpoint 448243384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.02528
Policy Entropy: 1.06431
Value Function Loss: 1.60205

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.05929

Collected Steps per Second: 8,767.19802
Overall Steps per Second: 7,640.18339

Timestep Collection Time: 5.70422
Timestep Consumption Time: 0.84144
PPO Batch Consumption Time: 0.04859
Total Iteration Time: 6.54565

Cumulative Model Updates: 26,875
Cumulative Timesteps: 448,293,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.70211
Policy Entropy: 1.06891
Value Function Loss: 1.66410

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.06163

Collected Steps per Second: 8,923.99420
Overall Steps per Second: 7,793.52780

Timestep Collection Time: 5.60422
Timestep Consumption Time: 0.81290
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.41712

Cumulative Model Updates: 26,878
Cumulative Timesteps: 448,343,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 448343406...
Checkpoint 448343406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.78491
Policy Entropy: 1.07869
Value Function Loss: 1.66018

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.06426

Collected Steps per Second: 8,829.18547
Overall Steps per Second: 7,686.25746

Timestep Collection Time: 5.66462
Timestep Consumption Time: 0.84232
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.50694

Cumulative Model Updates: 26,881
Cumulative Timesteps: 448,393,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.33294
Policy Entropy: 1.09452
Value Function Loss: 1.61735

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.21514
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.07292

Collected Steps per Second: 8,674.04670
Overall Steps per Second: 7,663.53013

Timestep Collection Time: 5.76778
Timestep Consumption Time: 0.76054
PPO Batch Consumption Time: 0.04560
Total Iteration Time: 6.52832

Cumulative Model Updates: 26,884
Cumulative Timesteps: 448,443,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 448443450...
Checkpoint 448443450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.34432
Policy Entropy: 1.07575
Value Function Loss: 1.55975

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 8,533.78594
Overall Steps per Second: 7,320.24993

Timestep Collection Time: 5.85930
Timestep Consumption Time: 0.97134
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.83064

Cumulative Model Updates: 26,887
Cumulative Timesteps: 448,493,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.90552
Policy Entropy: 1.07578
Value Function Loss: 1.56477

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.16156
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 8,950.41837
Overall Steps per Second: 7,775.20698

Timestep Collection Time: 5.58655
Timestep Consumption Time: 0.84440
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.43095

Cumulative Model Updates: 26,890
Cumulative Timesteps: 448,543,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 448543454...
Checkpoint 448543454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.87729
Policy Entropy: 1.09476
Value Function Loss: 1.54976

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 8,858.30966
Overall Steps per Second: 7,703.36526

Timestep Collection Time: 5.64555
Timestep Consumption Time: 0.84642
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 6.49197

Cumulative Model Updates: 26,893
Cumulative Timesteps: 448,593,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.72320
Policy Entropy: 1.09617
Value Function Loss: 1.58428

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 8,905.87031
Overall Steps per Second: 7,791.63896

Timestep Collection Time: 5.61607
Timestep Consumption Time: 0.80312
PPO Batch Consumption Time: 0.03992
Total Iteration Time: 6.41919

Cumulative Model Updates: 26,896
Cumulative Timesteps: 448,643,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 448643480...
Checkpoint 448643480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.56306
Policy Entropy: 1.09877
Value Function Loss: 1.54367

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 9,007.62764
Overall Steps per Second: 7,929.49518

Timestep Collection Time: 5.55329
Timestep Consumption Time: 0.75505
PPO Batch Consumption Time: 0.04811
Total Iteration Time: 6.30835

Cumulative Model Updates: 26,899
Cumulative Timesteps: 448,693,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.45105
Policy Entropy: 1.09186
Value Function Loss: 1.57311

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 8,745.58831
Overall Steps per Second: 7,639.12461

Timestep Collection Time: 5.72014
Timestep Consumption Time: 0.82851
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.54866

Cumulative Model Updates: 26,902
Cumulative Timesteps: 448,743,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 448743528...
Checkpoint 448743528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.40169
Policy Entropy: 1.07465
Value Function Loss: 1.54698

Mean KL Divergence: 0.03027
SB3 Clip Fraction: 0.21003
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.08374

Collected Steps per Second: 8,905.21248
Overall Steps per Second: 7,574.23675

Timestep Collection Time: 5.61761
Timestep Consumption Time: 0.98715
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.60476

Cumulative Model Updates: 26,905
Cumulative Timesteps: 448,793,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.90621
Policy Entropy: 1.10936
Value Function Loss: 1.56228

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.20152
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 9,089.74428
Overall Steps per Second: 7,914.20533

Timestep Collection Time: 5.50070
Timestep Consumption Time: 0.81705
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.31775

Cumulative Model Updates: 26,908
Cumulative Timesteps: 448,843,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 448843554...
Checkpoint 448843554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.67816
Policy Entropy: 1.09487
Value Function Loss: 1.58370

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.17475
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 8,725.33488
Overall Steps per Second: 7,527.04585

Timestep Collection Time: 5.73067
Timestep Consumption Time: 0.91231
PPO Batch Consumption Time: 0.04432
Total Iteration Time: 6.64298

Cumulative Model Updates: 26,911
Cumulative Timesteps: 448,893,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.36406
Policy Entropy: 1.08563
Value Function Loss: 1.57958

Mean KL Divergence: 0.02918
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.10189

Collected Steps per Second: 8,657.39177
Overall Steps per Second: 7,583.78455

Timestep Collection Time: 5.77541
Timestep Consumption Time: 0.81760
PPO Batch Consumption Time: 0.05042
Total Iteration Time: 6.59301

Cumulative Model Updates: 26,914
Cumulative Timesteps: 448,943,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 448943556...
Checkpoint 448943556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.74003
Policy Entropy: 1.10319
Value Function Loss: 1.58827

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.17873
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 8,819.37181
Overall Steps per Second: 7,654.42252

Timestep Collection Time: 5.66956
Timestep Consumption Time: 0.86287
PPO Batch Consumption Time: 0.04301
Total Iteration Time: 6.53243

Cumulative Model Updates: 26,917
Cumulative Timesteps: 448,993,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.25541
Policy Entropy: 1.09753
Value Function Loss: 1.63510

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 8,630.95989
Overall Steps per Second: 7,570.23307

Timestep Collection Time: 5.79495
Timestep Consumption Time: 0.81198
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 6.60693

Cumulative Model Updates: 26,920
Cumulative Timesteps: 449,043,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449043574...
Checkpoint 449043574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.69879
Policy Entropy: 1.10389
Value Function Loss: 1.67383

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 8,921.33627
Overall Steps per Second: 7,722.78894

Timestep Collection Time: 5.60544
Timestep Consumption Time: 0.86994
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 6.47538

Cumulative Model Updates: 26,923
Cumulative Timesteps: 449,093,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.85345
Policy Entropy: 1.08261
Value Function Loss: 1.73323

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.18627
Policy Update Magnitude: 0.07138
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 8,896.01550
Overall Steps per Second: 7,793.48906

Timestep Collection Time: 5.62274
Timestep Consumption Time: 0.79544
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.41818

Cumulative Model Updates: 26,926
Cumulative Timesteps: 449,143,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 449143602...
Checkpoint 449143602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.43690
Policy Entropy: 1.10653
Value Function Loss: 1.66937

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.08156

Collected Steps per Second: 8,648.78330
Overall Steps per Second: 7,605.99284

Timestep Collection Time: 5.78370
Timestep Consumption Time: 0.79295
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.57666

Cumulative Model Updates: 26,929
Cumulative Timesteps: 449,193,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.55240
Policy Entropy: 1.10817
Value Function Loss: 1.64459

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.16551
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.07015

Collected Steps per Second: 8,695.95829
Overall Steps per Second: 7,616.37340

Timestep Collection Time: 5.75233
Timestep Consumption Time: 0.81537
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 6.56769

Cumulative Model Updates: 26,932
Cumulative Timesteps: 449,243,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449243646...
Checkpoint 449243646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.69270
Policy Entropy: 1.09495
Value Function Loss: 1.60540

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.17371
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.07230

Collected Steps per Second: 8,881.44490
Overall Steps per Second: 7,686.82025

Timestep Collection Time: 5.62971
Timestep Consumption Time: 0.87493
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.50464

Cumulative Model Updates: 26,935
Cumulative Timesteps: 449,293,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.62993
Policy Entropy: 1.09745
Value Function Loss: 1.71713

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.18000
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 8,859.49502
Overall Steps per Second: 7,674.43409

Timestep Collection Time: 5.64502
Timestep Consumption Time: 0.87169
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.51670

Cumulative Model Updates: 26,938
Cumulative Timesteps: 449,343,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 449343658...
Checkpoint 449343658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.51448
Policy Entropy: 1.11154
Value Function Loss: 1.75417

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08935

Collected Steps per Second: 8,729.63237
Overall Steps per Second: 7,502.72866

Timestep Collection Time: 5.72968
Timestep Consumption Time: 0.93696
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.66664

Cumulative Model Updates: 26,941
Cumulative Timesteps: 449,393,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.86711
Policy Entropy: 1.11364
Value Function Loss: 1.78919

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.09535

Collected Steps per Second: 8,620.44467
Overall Steps per Second: 7,633.48201

Timestep Collection Time: 5.80272
Timestep Consumption Time: 0.75026
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.55297

Cumulative Model Updates: 26,944
Cumulative Timesteps: 449,443,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449443698...
Checkpoint 449443698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.47257
Policy Entropy: 1.10904
Value Function Loss: 1.75250

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.07085
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 8,999.50296
Overall Steps per Second: 7,756.19334

Timestep Collection Time: 5.55786
Timestep Consumption Time: 0.89092
PPO Batch Consumption Time: 0.04756
Total Iteration Time: 6.44878

Cumulative Model Updates: 26,947
Cumulative Timesteps: 449,493,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.49515
Policy Entropy: 1.11102
Value Function Loss: 1.85910

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 8,969.82252
Overall Steps per Second: 7,824.06617

Timestep Collection Time: 5.57425
Timestep Consumption Time: 0.81629
PPO Batch Consumption Time: 0.04179
Total Iteration Time: 6.39054

Cumulative Model Updates: 26,950
Cumulative Timesteps: 449,543,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 449543716...
Checkpoint 449543716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.79437
Policy Entropy: 1.10624
Value Function Loss: 1.86411

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.07455
Value Function Update Magnitude: 0.08733

Collected Steps per Second: 9,402.16491
Overall Steps per Second: 8,014.15327

Timestep Collection Time: 5.31835
Timestep Consumption Time: 0.92111
PPO Batch Consumption Time: 0.05418
Total Iteration Time: 6.23946

Cumulative Model Updates: 26,953
Cumulative Timesteps: 449,593,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.84430
Policy Entropy: 1.11380
Value Function Loss: 1.89666

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 8,901.31370
Overall Steps per Second: 7,723.35053

Timestep Collection Time: 5.62029
Timestep Consumption Time: 0.85721
PPO Batch Consumption Time: 0.04209
Total Iteration Time: 6.47750

Cumulative Model Updates: 26,956
Cumulative Timesteps: 449,643,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 449643748...
Checkpoint 449643748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.67914
Policy Entropy: 1.10916
Value Function Loss: 1.77124

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.09417

Collected Steps per Second: 9,404.60410
Overall Steps per Second: 8,156.14411

Timestep Collection Time: 5.31825
Timestep Consumption Time: 0.81406
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 6.13231

Cumulative Model Updates: 26,959
Cumulative Timesteps: 449,693,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.73792
Policy Entropy: 1.13052
Value Function Loss: 1.79661

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 9,340.63826
Overall Steps per Second: 8,034.91009

Timestep Collection Time: 5.35467
Timestep Consumption Time: 0.87017
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.22484

Cumulative Model Updates: 26,962
Cumulative Timesteps: 449,743,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449743780...
Checkpoint 449743780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.86764
Policy Entropy: 1.13082
Value Function Loss: 1.80535

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15077
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.12271

Collected Steps per Second: 8,736.52676
Overall Steps per Second: 7,634.03864

Timestep Collection Time: 5.72562
Timestep Consumption Time: 0.82688
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.55249

Cumulative Model Updates: 26,965
Cumulative Timesteps: 449,793,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.06254
Policy Entropy: 1.12585
Value Function Loss: 1.90584

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.06645
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 9,082.41535
Overall Steps per Second: 7,876.76041

Timestep Collection Time: 5.50823
Timestep Consumption Time: 0.84312
PPO Batch Consumption Time: 0.04316
Total Iteration Time: 6.35134

Cumulative Model Updates: 26,968
Cumulative Timesteps: 449,843,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 449843830...
Checkpoint 449843830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 813.71884
Policy Entropy: 1.10619
Value Function Loss: 1.89718

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.11548

Collected Steps per Second: 8,749.89733
Overall Steps per Second: 7,591.87887

Timestep Collection Time: 5.71755
Timestep Consumption Time: 0.87212
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.58967

Cumulative Model Updates: 26,971
Cumulative Timesteps: 449,893,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.07727
Policy Entropy: 1.11644
Value Function Loss: 1.84048

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 8,763.54457
Overall Steps per Second: 7,731.90282

Timestep Collection Time: 5.70728
Timestep Consumption Time: 0.76150
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.46878

Cumulative Model Updates: 26,974
Cumulative Timesteps: 449,943,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449943874...
Checkpoint 449943874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.03721
Policy Entropy: 1.11472
Value Function Loss: 1.77538

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.08763

Collected Steps per Second: 8,657.38538
Overall Steps per Second: 7,519.26779

Timestep Collection Time: 5.77726
Timestep Consumption Time: 0.87445
PPO Batch Consumption Time: 0.04767
Total Iteration Time: 6.65171

Cumulative Model Updates: 26,977
Cumulative Timesteps: 449,993,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.42351
Policy Entropy: 1.12007
Value Function Loss: 1.64450

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.07502

Collected Steps per Second: 8,750.72878
Overall Steps per Second: 7,689.01014

Timestep Collection Time: 5.71724
Timestep Consumption Time: 0.78945
PPO Batch Consumption Time: 0.04144
Total Iteration Time: 6.50669

Cumulative Model Updates: 26,980
Cumulative Timesteps: 450,043,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 450043920...
Checkpoint 450043920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.78539
Policy Entropy: 1.10423
Value Function Loss: 1.65505

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.19814
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.06507

Collected Steps per Second: 8,651.93099
Overall Steps per Second: 7,505.10881

Timestep Collection Time: 5.78044
Timestep Consumption Time: 0.88328
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.66373

Cumulative Model Updates: 26,983
Cumulative Timesteps: 450,093,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.41005
Policy Entropy: 1.11836
Value Function Loss: 1.59320

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.05907

Collected Steps per Second: 8,794.36400
Overall Steps per Second: 7,699.94970

Timestep Collection Time: 5.68591
Timestep Consumption Time: 0.80815
PPO Batch Consumption Time: 0.04679
Total Iteration Time: 6.49407

Cumulative Model Updates: 26,986
Cumulative Timesteps: 450,143,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 450143936...
Checkpoint 450143936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.71221
Policy Entropy: 1.13208
Value Function Loss: 1.61911

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.06112

Collected Steps per Second: 8,546.91096
Overall Steps per Second: 7,529.40400

Timestep Collection Time: 5.85053
Timestep Consumption Time: 0.79063
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.64116

Cumulative Model Updates: 26,989
Cumulative Timesteps: 450,193,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.78045
Policy Entropy: 1.11650
Value Function Loss: 1.53349

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.05699

Collected Steps per Second: 8,991.83709
Overall Steps per Second: 7,795.19012

Timestep Collection Time: 5.56371
Timestep Consumption Time: 0.85409
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.41780

Cumulative Model Updates: 26,992
Cumulative Timesteps: 450,243,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 450243968...
Checkpoint 450243968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.07381
Policy Entropy: 1.10782
Value Function Loss: 1.45590

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.17949
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.06821

Collected Steps per Second: 8,668.48978
Overall Steps per Second: 7,590.88548

Timestep Collection Time: 5.77009
Timestep Consumption Time: 0.81912
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.58922

Cumulative Model Updates: 26,995
Cumulative Timesteps: 450,293,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.63230
Policy Entropy: 1.11636
Value Function Loss: 1.46887

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 8,785.20104
Overall Steps per Second: 7,655.78951

Timestep Collection Time: 5.69389
Timestep Consumption Time: 0.83999
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.53388

Cumulative Model Updates: 26,998
Cumulative Timesteps: 450,344,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 450344008...
Checkpoint 450344008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.57368
Policy Entropy: 1.11996
Value Function Loss: 1.38002

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.06472

Collected Steps per Second: 8,794.55686
Overall Steps per Second: 7,668.36141

Timestep Collection Time: 5.68738
Timestep Consumption Time: 0.83526
PPO Batch Consumption Time: 0.04674
Total Iteration Time: 6.52265

Cumulative Model Updates: 27,001
Cumulative Timesteps: 450,394,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.06872
Policy Entropy: 1.10065
Value Function Loss: 1.46823

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.07389

Collected Steps per Second: 8,539.88226
Overall Steps per Second: 7,567.92796

Timestep Collection Time: 5.85769
Timestep Consumption Time: 0.75231
PPO Batch Consumption Time: 0.04249
Total Iteration Time: 6.61000

Cumulative Model Updates: 27,004
Cumulative Timesteps: 450,444,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 450444050...
Checkpoint 450444050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.88032
Policy Entropy: 1.10532
Value Function Loss: 1.50142

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.07783

Collected Steps per Second: 8,876.10044
Overall Steps per Second: 7,719.31387

Timestep Collection Time: 5.63355
Timestep Consumption Time: 0.84422
PPO Batch Consumption Time: 0.04277
Total Iteration Time: 6.47778

Cumulative Model Updates: 27,007
Cumulative Timesteps: 450,494,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.73776
Policy Entropy: 1.11354
Value Function Loss: 1.59305

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 8,273.01519
Overall Steps per Second: 7,090.69015

Timestep Collection Time: 6.04665
Timestep Consumption Time: 1.00824
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 7.05488

Cumulative Model Updates: 27,010
Cumulative Timesteps: 450,544,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 450544078...
Checkpoint 450544078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.77178
Policy Entropy: 1.12261
Value Function Loss: 1.58434

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.16386
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 8,926.01264
Overall Steps per Second: 7,616.40192

Timestep Collection Time: 5.60429
Timestep Consumption Time: 0.96364
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 6.56793

Cumulative Model Updates: 27,013
Cumulative Timesteps: 450,594,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.41663
Policy Entropy: 1.09194
Value Function Loss: 1.60094

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.22186
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 8,956.15019
Overall Steps per Second: 7,801.95346

Timestep Collection Time: 5.58566
Timestep Consumption Time: 0.82633
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 6.41198

Cumulative Model Updates: 27,016
Cumulative Timesteps: 450,644,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 450644128...
Checkpoint 450644128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.33755
Policy Entropy: 1.10511
Value Function Loss: 1.66410

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.06628

Collected Steps per Second: 8,914.79588
Overall Steps per Second: 7,830.42114

Timestep Collection Time: 5.61022
Timestep Consumption Time: 0.77692
PPO Batch Consumption Time: 0.04507
Total Iteration Time: 6.38714

Cumulative Model Updates: 27,019
Cumulative Timesteps: 450,694,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.43241
Policy Entropy: 1.10018
Value Function Loss: 1.62153

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.18197
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.07508

Collected Steps per Second: 8,767.41146
Overall Steps per Second: 7,571.63830

Timestep Collection Time: 5.70362
Timestep Consumption Time: 0.90076
PPO Batch Consumption Time: 0.04975
Total Iteration Time: 6.60438

Cumulative Model Updates: 27,022
Cumulative Timesteps: 450,744,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 450744148...
Checkpoint 450744148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.07602
Policy Entropy: 1.09214
Value Function Loss: 1.54547

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.19202
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 8,622.78202
Overall Steps per Second: 7,547.79055

Timestep Collection Time: 5.80230
Timestep Consumption Time: 0.82639
PPO Batch Consumption Time: 0.04030
Total Iteration Time: 6.62869

Cumulative Model Updates: 27,025
Cumulative Timesteps: 450,794,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.05969
Policy Entropy: 1.09127
Value Function Loss: 1.43030

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.21442
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 8,849.25741
Overall Steps per Second: 7,783.38059

Timestep Collection Time: 5.65268
Timestep Consumption Time: 0.77409
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.42677

Cumulative Model Updates: 27,028
Cumulative Timesteps: 450,844,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 450844202...
Checkpoint 450844202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.66431
Policy Entropy: 1.09604
Value Function Loss: 1.44046

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 8,841.14508
Overall Steps per Second: 7,670.04674

Timestep Collection Time: 5.65786
Timestep Consumption Time: 0.86387
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.52173

Cumulative Model Updates: 27,031
Cumulative Timesteps: 450,894,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.87205
Policy Entropy: 1.10882
Value Function Loss: 1.52093

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.04639

Collected Steps per Second: 8,860.16803
Overall Steps per Second: 7,699.84396

Timestep Collection Time: 5.64527
Timestep Consumption Time: 0.85071
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.49598

Cumulative Model Updates: 27,034
Cumulative Timesteps: 450,944,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 450944242...
Checkpoint 450944242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.18648
Policy Entropy: 1.07413
Value Function Loss: 1.49183

Mean KL Divergence: 0.04334
SB3 Clip Fraction: 0.25257
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.04395

Collected Steps per Second: 8,805.11792
Overall Steps per Second: 7,639.09518

Timestep Collection Time: 5.67874
Timestep Consumption Time: 0.86680
PPO Batch Consumption Time: 0.04575
Total Iteration Time: 6.54554

Cumulative Model Updates: 27,037
Cumulative Timesteps: 450,994,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.90473
Policy Entropy: 1.09401
Value Function Loss: 1.49667

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.04791

Collected Steps per Second: 8,916.82779
Overall Steps per Second: 7,719.61060

Timestep Collection Time: 5.60782
Timestep Consumption Time: 0.86970
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.47753

Cumulative Model Updates: 27,040
Cumulative Timesteps: 451,044,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 451044248...
Checkpoint 451044248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.84192
Policy Entropy: 1.09411
Value Function Loss: 1.51009

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 8,680.99320
Overall Steps per Second: 7,556.25372

Timestep Collection Time: 5.75994
Timestep Consumption Time: 0.85736
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.61730

Cumulative Model Updates: 27,043
Cumulative Timesteps: 451,094,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.77236
Policy Entropy: 1.08049
Value Function Loss: 1.50455

Mean KL Divergence: 0.02592
SB3 Clip Fraction: 0.17469
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.07681

Collected Steps per Second: 8,976.70225
Overall Steps per Second: 7,702.57829

Timestep Collection Time: 5.57198
Timestep Consumption Time: 0.92169
PPO Batch Consumption Time: 0.04916
Total Iteration Time: 6.49367

Cumulative Model Updates: 27,046
Cumulative Timesteps: 451,144,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451144268...
Checkpoint 451144268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.08413
Policy Entropy: 1.06858
Value Function Loss: 1.45426

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.20335
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.10013

Collected Steps per Second: 8,635.91758
Overall Steps per Second: 7,474.24361

Timestep Collection Time: 5.79024
Timestep Consumption Time: 0.89994
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.69018

Cumulative Model Updates: 27,049
Cumulative Timesteps: 451,194,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.36290
Policy Entropy: 1.08592
Value Function Loss: 1.45319

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 8,344.50245
Overall Steps per Second: 7,340.10372

Timestep Collection Time: 5.99532
Timestep Consumption Time: 0.82038
PPO Batch Consumption Time: 0.04694
Total Iteration Time: 6.81571

Cumulative Model Updates: 27,052
Cumulative Timesteps: 451,244,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 451244300...
Checkpoint 451244300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.65035
Policy Entropy: 1.08233
Value Function Loss: 1.49347

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 8,727.70739
Overall Steps per Second: 7,563.54556

Timestep Collection Time: 5.73163
Timestep Consumption Time: 0.88220
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.61383

Cumulative Model Updates: 27,055
Cumulative Timesteps: 451,294,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.43864
Policy Entropy: 1.07659
Value Function Loss: 1.51549

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.07073
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 8,832.81296
Overall Steps per Second: 7,626.59056

Timestep Collection Time: 5.66365
Timestep Consumption Time: 0.89576
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 6.55942

Cumulative Model Updates: 27,058
Cumulative Timesteps: 451,344,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 451344350...
Checkpoint 451344350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.06996
Policy Entropy: 1.07030
Value Function Loss: 1.41217

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.17789
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.06282

Collected Steps per Second: 9,025.47677
Overall Steps per Second: 7,762.18266

Timestep Collection Time: 5.54187
Timestep Consumption Time: 0.90194
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 6.44381

Cumulative Model Updates: 27,061
Cumulative Timesteps: 451,394,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.69554
Policy Entropy: 1.07767
Value Function Loss: 1.36871

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 8,997.49581
Overall Steps per Second: 7,834.11158

Timestep Collection Time: 5.55821
Timestep Consumption Time: 0.82541
PPO Batch Consumption Time: 0.05086
Total Iteration Time: 6.38362

Cumulative Model Updates: 27,064
Cumulative Timesteps: 451,444,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 451444378...
Checkpoint 451444378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.78399
Policy Entropy: 1.08126
Value Function Loss: 1.38880

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16950
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 8,532.32391
Overall Steps per Second: 7,585.77689

Timestep Collection Time: 5.86007
Timestep Consumption Time: 0.73121
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.59128

Cumulative Model Updates: 27,067
Cumulative Timesteps: 451,494,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.34057
Policy Entropy: 1.06269
Value Function Loss: 1.47651

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 9,101.30823
Overall Steps per Second: 7,812.51037

Timestep Collection Time: 5.49547
Timestep Consumption Time: 0.90657
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 6.40204

Cumulative Model Updates: 27,070
Cumulative Timesteps: 451,544,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 451544394...
Checkpoint 451544394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.89388
Policy Entropy: 1.05234
Value Function Loss: 1.49190

Mean KL Divergence: 0.03238
SB3 Clip Fraction: 0.23627
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 9,195.02475
Overall Steps per Second: 7,969.49349

Timestep Collection Time: 5.44099
Timestep Consumption Time: 0.83670
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.27769

Cumulative Model Updates: 27,073
Cumulative Timesteps: 451,594,424

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.04434
Policy Entropy: 1.06520
Value Function Loss: 1.40021

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.09868

Collected Steps per Second: 9,005.50299
Overall Steps per Second: 7,782.64909

Timestep Collection Time: 5.55416
Timestep Consumption Time: 0.87270
PPO Batch Consumption Time: 0.04583
Total Iteration Time: 6.42686

Cumulative Model Updates: 27,076
Cumulative Timesteps: 451,644,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451644442...
Checkpoint 451644442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.17075
Policy Entropy: 1.06537
Value Function Loss: 1.34293

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.08721

Collected Steps per Second: 8,609.71312
Overall Steps per Second: 7,453.03214

Timestep Collection Time: 5.80902
Timestep Consumption Time: 0.90154
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.71056

Cumulative Model Updates: 27,079
Cumulative Timesteps: 451,694,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.77269
Policy Entropy: 1.06820
Value Function Loss: 1.41733

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.08094

Collected Steps per Second: 8,692.92947
Overall Steps per Second: 7,691.39925

Timestep Collection Time: 5.75387
Timestep Consumption Time: 0.74924
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 6.50311

Cumulative Model Updates: 27,082
Cumulative Timesteps: 451,744,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451744474...
Checkpoint 451744474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.28495
Policy Entropy: 1.05894
Value Function Loss: 1.46583

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 8,703.06001
Overall Steps per Second: 7,579.17330

Timestep Collection Time: 5.74832
Timestep Consumption Time: 0.85240
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.60072

Cumulative Model Updates: 27,085
Cumulative Timesteps: 451,794,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.68226
Policy Entropy: 1.05739
Value Function Loss: 1.47207

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.16235
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 8,895.66048
Overall Steps per Second: 7,678.17800

Timestep Collection Time: 5.62139
Timestep Consumption Time: 0.89135
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 6.51274

Cumulative Model Updates: 27,088
Cumulative Timesteps: 451,844,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 451844508...
Checkpoint 451844508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.85745
Policy Entropy: 1.05731
Value Function Loss: 1.43665

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.16023
Policy Update Magnitude: 0.06867
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 8,993.57612
Overall Steps per Second: 7,841.42042

Timestep Collection Time: 5.56241
Timestep Consumption Time: 0.81730
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.37971

Cumulative Model Updates: 27,091
Cumulative Timesteps: 451,894,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.66465
Policy Entropy: 1.06433
Value Function Loss: 1.39270

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.06958
Value Function Update Magnitude: 0.07100

Collected Steps per Second: 8,517.81853
Overall Steps per Second: 7,400.89392

Timestep Collection Time: 5.87357
Timestep Consumption Time: 0.88642
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 6.75999

Cumulative Model Updates: 27,094
Cumulative Timesteps: 451,944,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 451944564...
Checkpoint 451944564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.63833
Policy Entropy: 1.05385
Value Function Loss: 1.44676

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.19983
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 8,880.49343
Overall Steps per Second: 7,848.39310

Timestep Collection Time: 5.63077
Timestep Consumption Time: 0.74047
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.37124

Cumulative Model Updates: 27,097
Cumulative Timesteps: 451,994,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.39484
Policy Entropy: 1.06557
Value Function Loss: 1.39039

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 8,558.64148
Overall Steps per Second: 7,484.76930

Timestep Collection Time: 5.84415
Timestep Consumption Time: 0.83849
PPO Batch Consumption Time: 0.04768
Total Iteration Time: 6.68264

Cumulative Model Updates: 27,100
Cumulative Timesteps: 452,044,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 452044586...
Checkpoint 452044586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.18786
Policy Entropy: 1.07334
Value Function Loss: 1.50788

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.07815

Collected Steps per Second: 8,723.04200
Overall Steps per Second: 7,703.77321

Timestep Collection Time: 5.73447
Timestep Consumption Time: 0.75871
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.49318

Cumulative Model Updates: 27,103
Cumulative Timesteps: 452,094,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.39895
Policy Entropy: 1.05058
Value Function Loss: 1.40617

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.18478
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 8,745.90711
Overall Steps per Second: 7,420.85640

Timestep Collection Time: 5.71879
Timestep Consumption Time: 1.02113
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 6.73992

Cumulative Model Updates: 27,106
Cumulative Timesteps: 452,144,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 452144624...
Checkpoint 452144624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.87511
Policy Entropy: 1.05322
Value Function Loss: 1.44615

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 8,766.72321
Overall Steps per Second: 7,698.69902

Timestep Collection Time: 5.70361
Timestep Consumption Time: 0.79125
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.49486

Cumulative Model Updates: 27,109
Cumulative Timesteps: 452,194,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.42817
Policy Entropy: 1.06501
Value Function Loss: 1.39404

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 8,810.80429
Overall Steps per Second: 7,780.10784

Timestep Collection Time: 5.67576
Timestep Consumption Time: 0.75192
PPO Batch Consumption Time: 0.04184
Total Iteration Time: 6.42767

Cumulative Model Updates: 27,112
Cumulative Timesteps: 452,244,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 452244634...
Checkpoint 452244634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.63114
Policy Entropy: 1.06396
Value Function Loss: 1.43855

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.17041
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.05860

Collected Steps per Second: 8,892.17423
Overall Steps per Second: 7,710.02724

Timestep Collection Time: 5.62337
Timestep Consumption Time: 0.86221
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.48558

Cumulative Model Updates: 27,115
Cumulative Timesteps: 452,294,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.34275
Policy Entropy: 1.04157
Value Function Loss: 1.37719

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.18833
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.05193

Collected Steps per Second: 9,012.75819
Overall Steps per Second: 7,834.21270

Timestep Collection Time: 5.55124
Timestep Consumption Time: 0.83511
PPO Batch Consumption Time: 0.05316
Total Iteration Time: 6.38635

Cumulative Model Updates: 27,118
Cumulative Timesteps: 452,344,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 452344670...
Checkpoint 452344670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.71758
Policy Entropy: 1.04110
Value Function Loss: 1.37102

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.22937
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.05055

Collected Steps per Second: 8,797.10782
Overall Steps per Second: 7,613.85720

Timestep Collection Time: 5.68482
Timestep Consumption Time: 0.88346
PPO Batch Consumption Time: 0.05048
Total Iteration Time: 6.56829

Cumulative Model Updates: 27,121
Cumulative Timesteps: 452,394,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.22326
Policy Entropy: 1.05733
Value Function Loss: 1.37992

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.05620

Collected Steps per Second: 9,000.76825
Overall Steps per Second: 7,802.73011

Timestep Collection Time: 5.55708
Timestep Consumption Time: 0.85324
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.41032

Cumulative Model Updates: 27,124
Cumulative Timesteps: 452,444,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 452444698...
Checkpoint 452444698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.40403
Policy Entropy: 1.06986
Value Function Loss: 1.42328

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.18842
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.05641

Collected Steps per Second: 8,818.82765
Overall Steps per Second: 7,804.68328

Timestep Collection Time: 5.67059
Timestep Consumption Time: 0.73684
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.40743

Cumulative Model Updates: 27,127
Cumulative Timesteps: 452,494,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.36497
Policy Entropy: 1.03268
Value Function Loss: 1.41866

Mean KL Divergence: 0.03988
SB3 Clip Fraction: 0.24992
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.05474

Collected Steps per Second: 9,017.97748
Overall Steps per Second: 7,794.90229

Timestep Collection Time: 5.54736
Timestep Consumption Time: 0.87042
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.41778

Cumulative Model Updates: 27,130
Cumulative Timesteps: 452,544,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 452544732...
Checkpoint 452544732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.89605
Policy Entropy: 1.04651
Value Function Loss: 1.40561

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.20288
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 8,743.97220
Overall Steps per Second: 7,521.27194

Timestep Collection Time: 5.72097
Timestep Consumption Time: 0.93003
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.65100

Cumulative Model Updates: 27,133
Cumulative Timesteps: 452,594,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.06998
Policy Entropy: 1.04986
Value Function Loss: 1.35851

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.20555
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.06394

Collected Steps per Second: 8,801.01694
Overall Steps per Second: 7,692.56980

Timestep Collection Time: 5.68184
Timestep Consumption Time: 0.81872
PPO Batch Consumption Time: 0.04363
Total Iteration Time: 6.50056

Cumulative Model Updates: 27,136
Cumulative Timesteps: 452,644,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 452644762...
Checkpoint 452644762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.95044
Policy Entropy: 1.03004
Value Function Loss: 1.36056

Mean KL Divergence: 0.02760
SB3 Clip Fraction: 0.20337
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.06129

Collected Steps per Second: 9,012.06316
Overall Steps per Second: 7,842.01226

Timestep Collection Time: 5.54967
Timestep Consumption Time: 0.82803
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.37770

Cumulative Model Updates: 27,139
Cumulative Timesteps: 452,694,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.48557
Policy Entropy: 1.02575
Value Function Loss: 1.35458

Mean KL Divergence: 0.03655
SB3 Clip Fraction: 0.25408
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.06248

Collected Steps per Second: 8,662.38362
Overall Steps per Second: 7,639.63465

Timestep Collection Time: 5.77508
Timestep Consumption Time: 0.77313
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 6.54822

Cumulative Model Updates: 27,142
Cumulative Timesteps: 452,744,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 452744802...
Checkpoint 452744802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.07914
Policy Entropy: 1.04391
Value Function Loss: 1.39184

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.19753
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 8,789.26009
Overall Steps per Second: 7,593.62890

Timestep Collection Time: 5.68922
Timestep Consumption Time: 0.89578
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.58499

Cumulative Model Updates: 27,145
Cumulative Timesteps: 452,794,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.84717
Policy Entropy: 1.04012
Value Function Loss: 1.33440

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.20287
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 8,459.19384
Overall Steps per Second: 7,403.89113

Timestep Collection Time: 5.91380
Timestep Consumption Time: 0.84292
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.75672

Cumulative Model Updates: 27,148
Cumulative Timesteps: 452,844,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 452844832...
Checkpoint 452844832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.47311
Policy Entropy: 1.00057
Value Function Loss: 1.24819

Mean KL Divergence: 0.06119
SB3 Clip Fraction: 0.30275
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.09016

Collected Steps per Second: 9,132.78642
Overall Steps per Second: 7,879.65545

Timestep Collection Time: 5.47697
Timestep Consumption Time: 0.87102
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.34799

Cumulative Model Updates: 27,151
Cumulative Timesteps: 452,894,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.03873
Policy Entropy: 1.03153
Value Function Loss: 1.18618

Mean KL Divergence: 0.03520
SB3 Clip Fraction: 0.26177
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.11042

Collected Steps per Second: 8,803.66948
Overall Steps per Second: 7,659.98181

Timestep Collection Time: 5.68286
Timestep Consumption Time: 0.84849
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.53135

Cumulative Model Updates: 27,154
Cumulative Timesteps: 452,944,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 452944882...
Checkpoint 452944882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.64636
Policy Entropy: 0.99527
Value Function Loss: 1.27311

Mean KL Divergence: 0.03851
SB3 Clip Fraction: 0.27031
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.10155

Collected Steps per Second: 8,691.05692
Overall Steps per Second: 7,667.61454

Timestep Collection Time: 5.75603
Timestep Consumption Time: 0.76829
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.52432

Cumulative Model Updates: 27,157
Cumulative Timesteps: 452,994,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.97725
Policy Entropy: 1.03149
Value Function Loss: 1.35742

Mean KL Divergence: 0.02823
SB3 Clip Fraction: 0.21353
Policy Update Magnitude: 0.03970
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 8,632.16737
Overall Steps per Second: 7,498.23695

Timestep Collection Time: 5.79391
Timestep Consumption Time: 0.87619
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.67010

Cumulative Model Updates: 27,160
Cumulative Timesteps: 453,044,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 453044922...
Checkpoint 453044922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.82506
Policy Entropy: 1.03325
Value Function Loss: 1.46651

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.23759
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 8,377.20307
Overall Steps per Second: 7,326.10187

Timestep Collection Time: 5.97025
Timestep Consumption Time: 0.85657
PPO Batch Consumption Time: 0.04605
Total Iteration Time: 6.82682

Cumulative Model Updates: 27,163
Cumulative Timesteps: 453,094,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.93003
Policy Entropy: 1.02515
Value Function Loss: 1.37558

Mean KL Divergence: 0.02561
SB3 Clip Fraction: 0.20261
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.07814

Collected Steps per Second: 8,791.85705
Overall Steps per Second: 7,622.13412

Timestep Collection Time: 5.69027
Timestep Consumption Time: 0.87325
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.56352

Cumulative Model Updates: 27,166
Cumulative Timesteps: 453,144,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 453144964...
Checkpoint 453144964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.60103
Policy Entropy: 1.00767
Value Function Loss: 1.47856

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.23349
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 8,766.35179
Overall Steps per Second: 7,561.85809

Timestep Collection Time: 5.70659
Timestep Consumption Time: 0.90898
PPO Batch Consumption Time: 0.05216
Total Iteration Time: 6.61557

Cumulative Model Updates: 27,169
Cumulative Timesteps: 453,194,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.77320
Policy Entropy: 1.01753
Value Function Loss: 1.44479

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.19165
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 8,913.21002
Overall Steps per Second: 7,838.66582

Timestep Collection Time: 5.61257
Timestep Consumption Time: 0.76939
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.38195

Cumulative Model Updates: 27,172
Cumulative Timesteps: 453,245,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 453245016...
Checkpoint 453245016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.17120
Policy Entropy: 1.02634
Value Function Loss: 1.45947

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.20671
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 8,703.75882
Overall Steps per Second: 7,506.82053

Timestep Collection Time: 5.74579
Timestep Consumption Time: 0.91615
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 6.66194

Cumulative Model Updates: 27,175
Cumulative Timesteps: 453,295,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.62086
Policy Entropy: 1.01461
Value Function Loss: 1.42886

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16802
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.05927

Collected Steps per Second: 8,988.80603
Overall Steps per Second: 7,845.85553

Timestep Collection Time: 5.56603
Timestep Consumption Time: 0.81084
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 6.37687

Cumulative Model Updates: 27,178
Cumulative Timesteps: 453,345,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 453345058...
Checkpoint 453345058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.69025
Policy Entropy: 1.00013
Value Function Loss: 1.46787

Mean KL Divergence: 0.02934
SB3 Clip Fraction: 0.23663
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.05583

Collected Steps per Second: 9,227.19222
Overall Steps per Second: 8,063.41518

Timestep Collection Time: 5.42180
Timestep Consumption Time: 0.78252
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.20432

Cumulative Model Updates: 27,181
Cumulative Timesteps: 453,395,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.20591
Policy Entropy: 1.02571
Value Function Loss: 1.50911

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 8,994.74774
Overall Steps per Second: 7,721.49558

Timestep Collection Time: 5.56058
Timestep Consumption Time: 0.91692
PPO Batch Consumption Time: 0.04714
Total Iteration Time: 6.47750

Cumulative Model Updates: 27,184
Cumulative Timesteps: 453,445,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 453445102...
Checkpoint 453445102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.78248
Policy Entropy: 1.01798
Value Function Loss: 1.52636

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.05227

Collected Steps per Second: 8,771.86768
Overall Steps per Second: 7,639.14932

Timestep Collection Time: 5.70255
Timestep Consumption Time: 0.84556
PPO Batch Consumption Time: 0.04959
Total Iteration Time: 6.54811

Cumulative Model Updates: 27,187
Cumulative Timesteps: 453,495,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.14027
Policy Entropy: 1.02160
Value Function Loss: 1.45984

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.05816

Collected Steps per Second: 8,648.38092
Overall Steps per Second: 7,556.53260

Timestep Collection Time: 5.78235
Timestep Consumption Time: 0.83550
PPO Batch Consumption Time: 0.04680
Total Iteration Time: 6.61785

Cumulative Model Updates: 27,190
Cumulative Timesteps: 453,545,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453545132...
Checkpoint 453545132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.07376
Policy Entropy: 1.01525
Value Function Loss: 1.40008

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,651.62326
Overall Steps per Second: 7,566.44652

Timestep Collection Time: 5.78227
Timestep Consumption Time: 0.82929
PPO Batch Consumption Time: 0.03942
Total Iteration Time: 6.61156

Cumulative Model Updates: 27,193
Cumulative Timesteps: 453,595,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.57092
Policy Entropy: 1.03221
Value Function Loss: 1.40089

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.21154
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 8,999.17535
Overall Steps per Second: 7,935.36690

Timestep Collection Time: 5.55740
Timestep Consumption Time: 0.74502
PPO Batch Consumption Time: 0.04827
Total Iteration Time: 6.30242

Cumulative Model Updates: 27,196
Cumulative Timesteps: 453,645,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 453645170...
Checkpoint 453645170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.86403
Policy Entropy: 1.03704
Value Function Loss: 1.43703

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.23761
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 8,654.50943
Overall Steps per Second: 7,562.13363

Timestep Collection Time: 5.77988
Timestep Consumption Time: 0.83492
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.61480

Cumulative Model Updates: 27,199
Cumulative Timesteps: 453,695,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.79534
Policy Entropy: 1.01392
Value Function Loss: 1.50483

Mean KL Divergence: 0.02745
SB3 Clip Fraction: 0.19621
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 8,801.09101
Overall Steps per Second: 7,558.52530

Timestep Collection Time: 5.68293
Timestep Consumption Time: 0.93423
PPO Batch Consumption Time: 0.04871
Total Iteration Time: 6.61716

Cumulative Model Updates: 27,202
Cumulative Timesteps: 453,745,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 453745208...
Checkpoint 453745208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.56468
Policy Entropy: 1.04073
Value Function Loss: 1.49657

Mean KL Divergence: 0.03043
SB3 Clip Fraction: 0.23539
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.06563

Collected Steps per Second: 8,777.69354
Overall Steps per Second: 7,756.21654

Timestep Collection Time: 5.69945
Timestep Consumption Time: 0.75060
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.45005

Cumulative Model Updates: 27,205
Cumulative Timesteps: 453,795,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.19723
Policy Entropy: 1.04277
Value Function Loss: 1.40271

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.21499
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 9,033.96954
Overall Steps per Second: 7,904.58667

Timestep Collection Time: 5.53555
Timestep Consumption Time: 0.79090
PPO Batch Consumption Time: 0.04017
Total Iteration Time: 6.32645

Cumulative Model Updates: 27,208
Cumulative Timesteps: 453,845,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453845244...
Checkpoint 453845244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.45947
Policy Entropy: 1.02833
Value Function Loss: 1.32979

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.19964
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 8,663.29724
Overall Steps per Second: 7,581.45367

Timestep Collection Time: 5.77263
Timestep Consumption Time: 0.82373
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.59636

Cumulative Model Updates: 27,211
Cumulative Timesteps: 453,895,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.78916
Policy Entropy: 1.03074
Value Function Loss: 1.30090

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.23349
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.05916

Collected Steps per Second: 8,378.96153
Overall Steps per Second: 7,241.47758

Timestep Collection Time: 5.96733
Timestep Consumption Time: 0.93734
PPO Batch Consumption Time: 0.04841
Total Iteration Time: 6.90467

Cumulative Model Updates: 27,214
Cumulative Timesteps: 453,945,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 453945254...
Checkpoint 453945254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.04857
Policy Entropy: 1.04349
Value Function Loss: 1.36358

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.05545

Collected Steps per Second: 7,997.69931
Overall Steps per Second: 6,993.62681

Timestep Collection Time: 6.25205
Timestep Consumption Time: 0.89760
PPO Batch Consumption Time: 0.04923
Total Iteration Time: 7.14965

Cumulative Model Updates: 27,217
Cumulative Timesteps: 453,995,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.53638
Policy Entropy: 1.06134
Value Function Loss: 1.42991

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.20361
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 8,390.75931
Overall Steps per Second: 7,256.50580

Timestep Collection Time: 5.95989
Timestep Consumption Time: 0.93158
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.89147

Cumulative Model Updates: 27,220
Cumulative Timesteps: 454,045,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 454045264...
Checkpoint 454045264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.91124
Policy Entropy: 1.03312
Value Function Loss: 1.41995

Mean KL Divergence: 0.03132
SB3 Clip Fraction: 0.22559
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 8,604.03238
Overall Steps per Second: 7,519.21847

Timestep Collection Time: 5.81355
Timestep Consumption Time: 0.83873
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 6.65229

Cumulative Model Updates: 27,223
Cumulative Timesteps: 454,095,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.75700
Policy Entropy: 1.04654
Value Function Loss: 1.42016

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.20043
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.05901

Collected Steps per Second: 8,667.67823
Overall Steps per Second: 7,701.67417

Timestep Collection Time: 5.76925
Timestep Consumption Time: 0.72362
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.49287

Cumulative Model Updates: 27,226
Cumulative Timesteps: 454,145,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 454145290...
Checkpoint 454145290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.73168
Policy Entropy: 1.05398
Value Function Loss: 1.32284

Mean KL Divergence: 0.03075
SB3 Clip Fraction: 0.21972
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.05131

Collected Steps per Second: 8,907.45272
Overall Steps per Second: 7,577.94469

Timestep Collection Time: 5.61575
Timestep Consumption Time: 0.98525
PPO Batch Consumption Time: 0.04609
Total Iteration Time: 6.60100

Cumulative Model Updates: 27,229
Cumulative Timesteps: 454,195,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.00786
Policy Entropy: 1.04714
Value Function Loss: 1.31668

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.18483
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.04869

Collected Steps per Second: 8,868.64597
Overall Steps per Second: 7,554.52386

Timestep Collection Time: 5.64100
Timestep Consumption Time: 0.98126
PPO Batch Consumption Time: 0.04681
Total Iteration Time: 6.62226

Cumulative Model Updates: 27,232
Cumulative Timesteps: 454,245,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 454245340...
Checkpoint 454245340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.29352
Policy Entropy: 1.03471
Value Function Loss: 1.34068

Mean KL Divergence: 0.03143
SB3 Clip Fraction: 0.22373
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.04231

Collected Steps per Second: 8,876.99154
Overall Steps per Second: 7,718.20307

Timestep Collection Time: 5.63479
Timestep Consumption Time: 0.84599
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.48078

Cumulative Model Updates: 27,235
Cumulative Timesteps: 454,295,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.57076
Policy Entropy: 1.04696
Value Function Loss: 1.44115

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 8,881.89513
Overall Steps per Second: 7,657.78296

Timestep Collection Time: 5.62965
Timestep Consumption Time: 0.89991
PPO Batch Consumption Time: 0.05180
Total Iteration Time: 6.52957

Cumulative Model Updates: 27,238
Cumulative Timesteps: 454,345,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 454345362...
Checkpoint 454345362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.70835
Policy Entropy: 1.05301
Value Function Loss: 1.44220

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 8,824.05176
Overall Steps per Second: 7,792.88980

Timestep Collection Time: 5.66837
Timestep Consumption Time: 0.75004
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.41841

Cumulative Model Updates: 27,241
Cumulative Timesteps: 454,395,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.96143
Policy Entropy: 1.03965
Value Function Loss: 1.40614

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16314
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 8,450.18566
Overall Steps per Second: 7,291.04729

Timestep Collection Time: 5.91774
Timestep Consumption Time: 0.94081
PPO Batch Consumption Time: 0.06061
Total Iteration Time: 6.85855

Cumulative Model Updates: 27,244
Cumulative Timesteps: 454,445,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 454445386...
Checkpoint 454445386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.54665
Policy Entropy: 1.02363
Value Function Loss: 1.39551

Mean KL Divergence: 0.03379
SB3 Clip Fraction: 0.22968
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.05499

Collected Steps per Second: 8,649.86055
Overall Steps per Second: 7,576.00116

Timestep Collection Time: 5.78298
Timestep Consumption Time: 0.81971
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.60269

Cumulative Model Updates: 27,247
Cumulative Timesteps: 454,495,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.46996
Policy Entropy: 1.03890
Value Function Loss: 1.42010

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.17491
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 8,922.08275
Overall Steps per Second: 7,704.47795

Timestep Collection Time: 5.60564
Timestep Consumption Time: 0.88591
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.49155

Cumulative Model Updates: 27,250
Cumulative Timesteps: 454,545,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 454545422...
Checkpoint 454545422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.50741
Policy Entropy: 1.04653
Value Function Loss: 1.46379

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.16607
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.07028

Collected Steps per Second: 8,560.05977
Overall Steps per Second: 7,423.94244

Timestep Collection Time: 5.84318
Timestep Consumption Time: 0.89421
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.73739

Cumulative Model Updates: 27,253
Cumulative Timesteps: 454,595,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.84577
Policy Entropy: 1.03000
Value Function Loss: 1.44898

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.17182
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.06662

Collected Steps per Second: 8,925.99523
Overall Steps per Second: 7,722.28928

Timestep Collection Time: 5.60453
Timestep Consumption Time: 0.87360
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 6.47813

Cumulative Model Updates: 27,256
Cumulative Timesteps: 454,645,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 454645466...
Checkpoint 454645466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.79029
Policy Entropy: 1.01132
Value Function Loss: 1.37831

Mean KL Divergence: 0.04797
SB3 Clip Fraction: 0.25222
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.06604

Collected Steps per Second: 8,693.83787
Overall Steps per Second: 7,464.74848

Timestep Collection Time: 5.75189
Timestep Consumption Time: 0.94706
PPO Batch Consumption Time: 0.04472
Total Iteration Time: 6.69895

Cumulative Model Updates: 27,259
Cumulative Timesteps: 454,695,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.07994
Policy Entropy: 1.05152
Value Function Loss: 1.28501

Mean KL Divergence: 0.04100
SB3 Clip Fraction: 0.25037
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 8,808.28747
Overall Steps per Second: 7,719.54419

Timestep Collection Time: 5.67988
Timestep Consumption Time: 0.80107
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.48095

Cumulative Model Updates: 27,262
Cumulative Timesteps: 454,745,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 454745502...
Checkpoint 454745502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.43988
Policy Entropy: 1.02997
Value Function Loss: 1.28848

Mean KL Divergence: 0.02984
SB3 Clip Fraction: 0.20114
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.06171

Collected Steps per Second: 8,785.13851
Overall Steps per Second: 7,598.81133

Timestep Collection Time: 5.69143
Timestep Consumption Time: 0.88855
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.57998

Cumulative Model Updates: 27,265
Cumulative Timesteps: 454,795,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.83298
Policy Entropy: 1.05431
Value Function Loss: 1.42843

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.22732
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 8,692.34459
Overall Steps per Second: 7,547.25500

Timestep Collection Time: 5.75357
Timestep Consumption Time: 0.87295
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 6.62652

Cumulative Model Updates: 27,268
Cumulative Timesteps: 454,845,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 454845514...
Checkpoint 454845514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.52175
Policy Entropy: 1.07767
Value Function Loss: 1.48021

Mean KL Divergence: 0.03359
SB3 Clip Fraction: 0.23739
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.07332

Collected Steps per Second: 8,338.96867
Overall Steps per Second: 7,364.40703

Timestep Collection Time: 5.99786
Timestep Consumption Time: 0.79372
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.79159

Cumulative Model Updates: 27,271
Cumulative Timesteps: 454,895,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.24478
Policy Entropy: 1.05514
Value Function Loss: 1.58722

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.17465
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 8,637.55564
Overall Steps per Second: 7,457.79048

Timestep Collection Time: 5.79053
Timestep Consumption Time: 0.91602
PPO Batch Consumption Time: 0.04559
Total Iteration Time: 6.70654

Cumulative Model Updates: 27,274
Cumulative Timesteps: 454,945,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 454945546...
Checkpoint 454945546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.26767
Policy Entropy: 1.06783
Value Function Loss: 1.56820

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.17453
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 8,711.36964
Overall Steps per Second: 7,567.80827

Timestep Collection Time: 5.74077
Timestep Consumption Time: 0.86748
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.60825

Cumulative Model Updates: 27,277
Cumulative Timesteps: 454,995,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.51616
Policy Entropy: 1.06911
Value Function Loss: 1.66363

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 8,877.58382
Overall Steps per Second: 7,652.44436

Timestep Collection Time: 5.63554
Timestep Consumption Time: 0.90224
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 6.53778

Cumulative Model Updates: 27,280
Cumulative Timesteps: 455,045,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 455045586...
Checkpoint 455045586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.99902
Policy Entropy: 1.08338
Value Function Loss: 1.70351

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.06946
Value Function Update Magnitude: 0.06433

Collected Steps per Second: 8,812.51602
Overall Steps per Second: 7,638.17824

Timestep Collection Time: 5.67625
Timestep Consumption Time: 0.87270
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.54894

Cumulative Model Updates: 27,283
Cumulative Timesteps: 455,095,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.62432
Policy Entropy: 1.08523
Value Function Loss: 1.71414

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.07392
Value Function Update Magnitude: 0.06454

Collected Steps per Second: 8,678.49677
Overall Steps per Second: 7,688.18413

Timestep Collection Time: 5.76206
Timestep Consumption Time: 0.74221
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.50427

Cumulative Model Updates: 27,286
Cumulative Timesteps: 455,145,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 455145614...
Checkpoint 455145614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.96593
Policy Entropy: 1.08489
Value Function Loss: 1.81467

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.07700
Value Function Update Magnitude: 0.06304

Collected Steps per Second: 8,847.15953
Overall Steps per Second: 7,635.48439

Timestep Collection Time: 5.65334
Timestep Consumption Time: 0.89713
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.55047

Cumulative Model Updates: 27,289
Cumulative Timesteps: 455,195,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.39615
Policy Entropy: 1.08264
Value Function Loss: 1.68907

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 9,031.13620
Overall Steps per Second: 7,901.94683

Timestep Collection Time: 5.53662
Timestep Consumption Time: 0.79118
PPO Batch Consumption Time: 0.04522
Total Iteration Time: 6.32781

Cumulative Model Updates: 27,292
Cumulative Timesteps: 455,245,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 455245632...
Checkpoint 455245632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.25904
Policy Entropy: 1.09129
Value Function Loss: 1.70789

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 8,956.02603
Overall Steps per Second: 7,741.88782

Timestep Collection Time: 5.58350
Timestep Consumption Time: 0.87564
PPO Batch Consumption Time: 0.04146
Total Iteration Time: 6.45915

Cumulative Model Updates: 27,295
Cumulative Timesteps: 455,295,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.61329
Policy Entropy: 1.09575
Value Function Loss: 1.60923

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.06611
Value Function Update Magnitude: 0.08013

Collected Steps per Second: 8,449.92987
Overall Steps per Second: 7,384.39470

Timestep Collection Time: 5.92076
Timestep Consumption Time: 0.85434
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.77510

Cumulative Model Updates: 27,298
Cumulative Timesteps: 455,345,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 455345668...
Checkpoint 455345668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.73182
Policy Entropy: 1.10904
Value Function Loss: 1.69807

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 8,745.42800
Overall Steps per Second: 7,663.49204

Timestep Collection Time: 5.71910
Timestep Consumption Time: 0.80743
PPO Batch Consumption Time: 0.04662
Total Iteration Time: 6.52653

Cumulative Model Updates: 27,301
Cumulative Timesteps: 455,395,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.15496
Policy Entropy: 1.11077
Value Function Loss: 1.76609

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 8,701.44794
Overall Steps per Second: 7,563.44337

Timestep Collection Time: 5.74617
Timestep Consumption Time: 0.86458
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 6.61075

Cumulative Model Updates: 27,304
Cumulative Timesteps: 455,445,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 455445684...
Checkpoint 455445684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.57795
Policy Entropy: 1.12259
Value Function Loss: 1.85386

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 8,560.16390
Overall Steps per Second: 7,467.05744

Timestep Collection Time: 5.84358
Timestep Consumption Time: 0.85544
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.69902

Cumulative Model Updates: 27,307
Cumulative Timesteps: 455,495,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.70763
Policy Entropy: 1.12621
Value Function Loss: 1.82540

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 8,846.92276
Overall Steps per Second: 7,664.39918

Timestep Collection Time: 5.65281
Timestep Consumption Time: 0.87216
PPO Batch Consumption Time: 0.05044
Total Iteration Time: 6.52497

Cumulative Model Updates: 27,310
Cumulative Timesteps: 455,545,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 455545716...
Checkpoint 455545716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.57995
Policy Entropy: 1.14319
Value Function Loss: 1.84448

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.10925

Collected Steps per Second: 8,621.10821
Overall Steps per Second: 7,494.15101

Timestep Collection Time: 5.79995
Timestep Consumption Time: 0.87219
PPO Batch Consumption Time: 0.04916
Total Iteration Time: 6.67214

Cumulative Model Updates: 27,313
Cumulative Timesteps: 455,595,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.35296
Policy Entropy: 1.14500
Value Function Loss: 1.83707

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.07279
Value Function Update Magnitude: 0.09952

Collected Steps per Second: 8,881.07712
Overall Steps per Second: 7,808.29938

Timestep Collection Time: 5.63355
Timestep Consumption Time: 0.77399
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.40754

Cumulative Model Updates: 27,316
Cumulative Timesteps: 455,645,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 455645750...
Checkpoint 455645750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.87409
Policy Entropy: 1.14852
Value Function Loss: 1.93794

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.07553
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 8,876.20345
Overall Steps per Second: 7,700.18016

Timestep Collection Time: 5.63326
Timestep Consumption Time: 0.86035
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.49361

Cumulative Model Updates: 27,319
Cumulative Timesteps: 455,695,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.15293
Policy Entropy: 1.16640
Value Function Loss: 1.94523

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.09988

Collected Steps per Second: 8,639.99808
Overall Steps per Second: 7,532.51125

Timestep Collection Time: 5.78982
Timestep Consumption Time: 0.85126
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.64108

Cumulative Model Updates: 27,322
Cumulative Timesteps: 455,745,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 455745776...
Checkpoint 455745776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.40742
Policy Entropy: 1.17486
Value Function Loss: 1.96838

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.07616
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 8,562.83116
Overall Steps per Second: 7,504.00996

Timestep Collection Time: 5.84153
Timestep Consumption Time: 0.82424
PPO Batch Consumption Time: 0.04031
Total Iteration Time: 6.66577

Cumulative Model Updates: 27,325
Cumulative Timesteps: 455,795,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.73392
Policy Entropy: 1.17706
Value Function Loss: 2.03326

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.08128
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 8,861.80387
Overall Steps per Second: 7,690.88829

Timestep Collection Time: 5.64445
Timestep Consumption Time: 0.85935
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 6.50380

Cumulative Model Updates: 27,328
Cumulative Timesteps: 455,845,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 455845816...
Checkpoint 455845816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.65114
Policy Entropy: 1.17336
Value Function Loss: 2.04182

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.07899
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 8,552.78180
Overall Steps per Second: 7,594.78655

Timestep Collection Time: 5.84792
Timestep Consumption Time: 0.73765
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.58557

Cumulative Model Updates: 27,331
Cumulative Timesteps: 455,895,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.76814
Policy Entropy: 1.19122
Value Function Loss: 2.08828

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 8,719.26717
Overall Steps per Second: 7,610.49561

Timestep Collection Time: 5.73718
Timestep Consumption Time: 0.83585
PPO Batch Consumption Time: 0.04536
Total Iteration Time: 6.57303

Cumulative Model Updates: 27,334
Cumulative Timesteps: 455,945,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 455945856...
Checkpoint 455945856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.27033
Policy Entropy: 1.19361
Value Function Loss: 1.96280

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.10594

Collected Steps per Second: 8,853.43158
Overall Steps per Second: 7,630.09257

Timestep Collection Time: 5.64933
Timestep Consumption Time: 0.90576
PPO Batch Consumption Time: 0.04715
Total Iteration Time: 6.55510

Cumulative Model Updates: 27,337
Cumulative Timesteps: 455,995,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.90959
Policy Entropy: 1.17311
Value Function Loss: 2.00569

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.09766

Collected Steps per Second: 8,750.54660
Overall Steps per Second: 7,583.08674

Timestep Collection Time: 5.71644
Timestep Consumption Time: 0.88008
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.59652

Cumulative Model Updates: 27,340
Cumulative Timesteps: 456,045,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 456045894...
Checkpoint 456045894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.44618
Policy Entropy: 1.15982
Value Function Loss: 1.88702

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.10238

Collected Steps per Second: 8,847.20370
Overall Steps per Second: 7,706.78459

Timestep Collection Time: 5.65150
Timestep Consumption Time: 0.83629
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.48779

Cumulative Model Updates: 27,343
Cumulative Timesteps: 456,095,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.67843
Policy Entropy: 1.16953
Value Function Loss: 1.88423

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.10321

Collected Steps per Second: 8,824.42436
Overall Steps per Second: 7,724.84750

Timestep Collection Time: 5.66677
Timestep Consumption Time: 0.80662
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.47340

Cumulative Model Updates: 27,346
Cumulative Timesteps: 456,145,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 456145900...
Checkpoint 456145900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.91239
Policy Entropy: 1.18118
Value Function Loss: 1.77242

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 8,993.31737
Overall Steps per Second: 7,755.52284

Timestep Collection Time: 5.55968
Timestep Consumption Time: 0.88733
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.44702

Cumulative Model Updates: 27,349
Cumulative Timesteps: 456,195,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.61534
Policy Entropy: 1.14992
Value Function Loss: 1.77046

Mean KL Divergence: 0.05238
SB3 Clip Fraction: 0.24597
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.09739

Collected Steps per Second: 8,541.55399
Overall Steps per Second: 7,417.97673

Timestep Collection Time: 5.85631
Timestep Consumption Time: 0.88704
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 6.74335

Cumulative Model Updates: 27,352
Cumulative Timesteps: 456,245,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 456245922...
Checkpoint 456245922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.42326
Policy Entropy: 1.16826
Value Function Loss: 1.73509

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.16823
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.09571

Collected Steps per Second: 8,757.50097
Overall Steps per Second: 7,565.34299

Timestep Collection Time: 5.71236
Timestep Consumption Time: 0.90016
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 6.61252

Cumulative Model Updates: 27,355
Cumulative Timesteps: 456,295,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.89429
Policy Entropy: 1.14282
Value Function Loss: 1.70359

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.09562

Collected Steps per Second: 8,619.52082
Overall Steps per Second: 7,432.27602

Timestep Collection Time: 5.80079
Timestep Consumption Time: 0.92663
PPO Batch Consumption Time: 0.05066
Total Iteration Time: 6.72741

Cumulative Model Updates: 27,358
Cumulative Timesteps: 456,345,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 456345948...
Checkpoint 456345948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.54607
Policy Entropy: 1.14220
Value Function Loss: 1.66539

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.16651
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.08396

Collected Steps per Second: 8,569.18955
Overall Steps per Second: 7,539.97389

Timestep Collection Time: 5.83532
Timestep Consumption Time: 0.79653
PPO Batch Consumption Time: 0.04561
Total Iteration Time: 6.63185

Cumulative Model Updates: 27,361
Cumulative Timesteps: 456,395,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.28895
Policy Entropy: 1.14151
Value Function Loss: 1.60091

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.06645
Value Function Update Magnitude: 0.08138

Collected Steps per Second: 8,618.03653
Overall Steps per Second: 7,501.35891

Timestep Collection Time: 5.80480
Timestep Consumption Time: 0.86412
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.66892

Cumulative Model Updates: 27,364
Cumulative Timesteps: 456,445,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 456445978...
Checkpoint 456445978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.68895
Policy Entropy: 1.14629
Value Function Loss: 1.53973

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 8,478.74040
Overall Steps per Second: 7,412.04571

Timestep Collection Time: 5.89946
Timestep Consumption Time: 0.84901
PPO Batch Consumption Time: 0.04181
Total Iteration Time: 6.74847

Cumulative Model Updates: 27,367
Cumulative Timesteps: 456,495,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.06104
Policy Entropy: 1.12820
Value Function Loss: 1.57034

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.20919
Policy Update Magnitude: 0.07177
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 8,749.13064
Overall Steps per Second: 7,579.68740

Timestep Collection Time: 5.71554
Timestep Consumption Time: 0.88183
PPO Batch Consumption Time: 0.04723
Total Iteration Time: 6.59737

Cumulative Model Updates: 27,370
Cumulative Timesteps: 456,546,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 456546004...
Checkpoint 456546004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.47942
Policy Entropy: 1.14237
Value Function Loss: 1.64017

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.16340
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 8,642.22233
Overall Steps per Second: 7,415.43530

Timestep Collection Time: 5.78856
Timestep Consumption Time: 0.95764
PPO Batch Consumption Time: 0.04201
Total Iteration Time: 6.74620

Cumulative Model Updates: 27,373
Cumulative Timesteps: 456,596,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.72742
Policy Entropy: 1.13507
Value Function Loss: 1.72517

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.17635
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 8,515.41473
Overall Steps per Second: 7,435.72299

Timestep Collection Time: 5.87405
Timestep Consumption Time: 0.85293
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 6.72699

Cumulative Model Updates: 27,376
Cumulative Timesteps: 456,646,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 456646050...
Checkpoint 456646050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.80030
Policy Entropy: 1.12680
Value Function Loss: 1.67840

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.18369
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 8,449.38284
Overall Steps per Second: 7,311.02032

Timestep Collection Time: 5.91996
Timestep Consumption Time: 0.92177
PPO Batch Consumption Time: 0.04905
Total Iteration Time: 6.84173

Cumulative Model Updates: 27,379
Cumulative Timesteps: 456,696,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.25682
Policy Entropy: 1.14406
Value Function Loss: 1.61888

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.16928
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 8,700.79756
Overall Steps per Second: 7,568.92896

Timestep Collection Time: 5.74867
Timestep Consumption Time: 0.85966
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 6.60833

Cumulative Model Updates: 27,382
Cumulative Timesteps: 456,746,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 456746088...
Checkpoint 456746088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.79720
Policy Entropy: 1.13604
Value Function Loss: 1.60406

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.17591
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.10861

Collected Steps per Second: 8,879.25880
Overall Steps per Second: 7,693.20585

Timestep Collection Time: 5.63290
Timestep Consumption Time: 0.86842
PPO Batch Consumption Time: 0.04978
Total Iteration Time: 6.50132

Cumulative Model Updates: 27,385
Cumulative Timesteps: 456,796,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.25875
Policy Entropy: 1.11545
Value Function Loss: 1.58237

Mean KL Divergence: 0.05817
SB3 Clip Fraction: 0.25015
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 8,867.64981
Overall Steps per Second: 7,662.34787

Timestep Collection Time: 5.63937
Timestep Consumption Time: 0.88708
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.52646

Cumulative Model Updates: 27,388
Cumulative Timesteps: 456,846,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 456846112...
Checkpoint 456846112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.69521
Policy Entropy: 1.11778
Value Function Loss: 1.55112

Mean KL Divergence: 0.03230
SB3 Clip Fraction: 0.19455
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 9,128.91469
Overall Steps per Second: 7,917.56327

Timestep Collection Time: 5.48039
Timestep Consumption Time: 0.83847
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.31886

Cumulative Model Updates: 27,391
Cumulative Timesteps: 456,896,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.38023
Policy Entropy: 1.10936
Value Function Loss: 1.47201

Mean KL Divergence: 0.03362
SB3 Clip Fraction: 0.21052
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 8,946.23772
Overall Steps per Second: 7,658.88968

Timestep Collection Time: 5.58939
Timestep Consumption Time: 0.93950
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.52888

Cumulative Model Updates: 27,394
Cumulative Timesteps: 456,946,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 456946146...
Checkpoint 456946146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.44157
Policy Entropy: 1.09993
Value Function Loss: 1.35302

Mean KL Divergence: 0.03475
SB3 Clip Fraction: 0.21921
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 9,089.71622
Overall Steps per Second: 7,837.67708

Timestep Collection Time: 5.50160
Timestep Consumption Time: 0.87886
PPO Batch Consumption Time: 0.05015
Total Iteration Time: 6.38046

Cumulative Model Updates: 27,397
Cumulative Timesteps: 456,996,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.04242
Policy Entropy: 1.10950
Value Function Loss: 1.22841

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.17719
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 9,397.81649
Overall Steps per Second: 8,056.09241

Timestep Collection Time: 5.32315
Timestep Consumption Time: 0.88656
PPO Batch Consumption Time: 0.04762
Total Iteration Time: 6.20971

Cumulative Model Updates: 27,400
Cumulative Timesteps: 457,046,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457046180...
Checkpoint 457046180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.52344
Policy Entropy: 1.10509
Value Function Loss: 1.21066

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.08591

Collected Steps per Second: 8,697.72985
Overall Steps per Second: 7,586.94917

Timestep Collection Time: 5.74932
Timestep Consumption Time: 0.84174
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.59106

Cumulative Model Updates: 27,403
Cumulative Timesteps: 457,096,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.64958
Policy Entropy: 1.10371
Value Function Loss: 1.34398

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 8,755.82990
Overall Steps per Second: 7,669.13510

Timestep Collection Time: 5.71208
Timestep Consumption Time: 0.80939
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 6.52147

Cumulative Model Updates: 27,406
Cumulative Timesteps: 457,146,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 457146200...
Checkpoint 457146200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.12296
Policy Entropy: 1.09994
Value Function Loss: 1.39332

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.16230
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.08561

Collected Steps per Second: 8,434.74252
Overall Steps per Second: 7,384.83563

Timestep Collection Time: 5.93071
Timestep Consumption Time: 0.84317
PPO Batch Consumption Time: 0.04736
Total Iteration Time: 6.77388

Cumulative Model Updates: 27,409
Cumulative Timesteps: 457,196,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.50149
Policy Entropy: 1.11163
Value Function Loss: 1.45801

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.09840

Collected Steps per Second: 8,750.13545
Overall Steps per Second: 7,713.88352

Timestep Collection Time: 5.71603
Timestep Consumption Time: 0.76787
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.48389

Cumulative Model Updates: 27,412
Cumulative Timesteps: 457,246,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 457246240...
Checkpoint 457246240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.04282
Policy Entropy: 1.09796
Value Function Loss: 1.43387

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.18463
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 8,636.65911
Overall Steps per Second: 7,435.85825

Timestep Collection Time: 5.79182
Timestep Consumption Time: 0.93531
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 6.72713

Cumulative Model Updates: 27,415
Cumulative Timesteps: 457,296,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.25743
Policy Entropy: 1.08455
Value Function Loss: 1.44080

Mean KL Divergence: 0.04094
SB3 Clip Fraction: 0.25893
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.08770

Collected Steps per Second: 8,537.05792
Overall Steps per Second: 7,467.78188

Timestep Collection Time: 5.85893
Timestep Consumption Time: 0.83891
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.69784

Cumulative Model Updates: 27,418
Cumulative Timesteps: 457,346,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 457346280...
Checkpoint 457346280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.61064
Policy Entropy: 1.08921
Value Function Loss: 1.37416

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.07551

Collected Steps per Second: 8,276.99382
Overall Steps per Second: 7,312.28094

Timestep Collection Time: 6.04326
Timestep Consumption Time: 0.79729
PPO Batch Consumption Time: 0.04950
Total Iteration Time: 6.84055

Cumulative Model Updates: 27,421
Cumulative Timesteps: 457,396,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.96945
Policy Entropy: 1.09510
Value Function Loss: 1.33550

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.19491
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 8,549.76277
Overall Steps per Second: 7,405.27392

Timestep Collection Time: 5.85022
Timestep Consumption Time: 0.90415
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.75438

Cumulative Model Updates: 27,424
Cumulative Timesteps: 457,446,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 457446318...
Checkpoint 457446318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.40900
Policy Entropy: 1.06335
Value Function Loss: 1.41538

Mean KL Divergence: 0.03026
SB3 Clip Fraction: 0.20722
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 8,717.80981
Overall Steps per Second: 7,554.84679

Timestep Collection Time: 5.73837
Timestep Consumption Time: 0.88334
PPO Batch Consumption Time: 0.04953
Total Iteration Time: 6.62171

Cumulative Model Updates: 27,427
Cumulative Timesteps: 457,496,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.15496
Policy Entropy: 1.08737
Value Function Loss: 1.42554

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.18920
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 8,759.86400
Overall Steps per Second: 7,597.25894

Timestep Collection Time: 5.70991
Timestep Consumption Time: 0.87378
PPO Batch Consumption Time: 0.04961
Total Iteration Time: 6.58369

Cumulative Model Updates: 27,430
Cumulative Timesteps: 457,546,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 457546362...
Checkpoint 457546362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.62226
Policy Entropy: 1.08184
Value Function Loss: 1.43749

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.19411
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 8,733.80406
Overall Steps per Second: 7,574.48165

Timestep Collection Time: 5.72809
Timestep Consumption Time: 0.87672
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 6.60481

Cumulative Model Updates: 27,433
Cumulative Timesteps: 457,596,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.82942
Policy Entropy: 1.07184
Value Function Loss: 1.39408

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.19411
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.09708

Collected Steps per Second: 8,546.84237
Overall Steps per Second: 7,551.25038

Timestep Collection Time: 5.85316
Timestep Consumption Time: 0.77171
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.62486

Cumulative Model Updates: 27,436
Cumulative Timesteps: 457,646,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457646416...
Checkpoint 457646416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.48657
Policy Entropy: 1.06053
Value Function Loss: 1.39154

Mean KL Divergence: 0.03146
SB3 Clip Fraction: 0.22229
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 8,603.56160
Overall Steps per Second: 7,495.75617

Timestep Collection Time: 5.81155
Timestep Consumption Time: 0.85889
PPO Batch Consumption Time: 0.04359
Total Iteration Time: 6.67044

Cumulative Model Updates: 27,439
Cumulative Timesteps: 457,696,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.26370
Policy Entropy: 1.07010
Value Function Loss: 1.37270

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 8,732.38910
Overall Steps per Second: 7,546.85457

Timestep Collection Time: 5.72718
Timestep Consumption Time: 0.89968
PPO Batch Consumption Time: 0.05196
Total Iteration Time: 6.62687

Cumulative Model Updates: 27,442
Cumulative Timesteps: 457,746,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 457746428...
Checkpoint 457746428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.85159
Policy Entropy: 1.07234
Value Function Loss: 1.38493

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 8,806.79775
Overall Steps per Second: 7,691.73007

Timestep Collection Time: 5.67948
Timestep Consumption Time: 0.82335
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.50283

Cumulative Model Updates: 27,445
Cumulative Timesteps: 457,796,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.94075
Policy Entropy: 1.06379
Value Function Loss: 1.33600

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.10247

Collected Steps per Second: 8,636.50145
Overall Steps per Second: 7,479.92974

Timestep Collection Time: 5.79031
Timestep Consumption Time: 0.89532
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.68562

Cumulative Model Updates: 27,448
Cumulative Timesteps: 457,846,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 457846454...
Checkpoint 457846454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.84896
Policy Entropy: 1.06816
Value Function Loss: 1.42553

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.17521
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 8,730.76957
Overall Steps per Second: 7,730.74461

Timestep Collection Time: 5.72710
Timestep Consumption Time: 0.74084
PPO Batch Consumption Time: 0.04421
Total Iteration Time: 6.46794

Cumulative Model Updates: 27,451
Cumulative Timesteps: 457,896,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.13456
Policy Entropy: 1.07208
Value Function Loss: 1.37494

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.09115

Collected Steps per Second: 8,982.24447
Overall Steps per Second: 7,754.68422

Timestep Collection Time: 5.56899
Timestep Consumption Time: 0.88157
PPO Batch Consumption Time: 0.04590
Total Iteration Time: 6.45055

Cumulative Model Updates: 27,454
Cumulative Timesteps: 457,946,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 457946478...
Checkpoint 457946478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.78604
Policy Entropy: 1.04374
Value Function Loss: 1.41245

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.18501
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 8,723.57773
Overall Steps per Second: 7,579.62234

Timestep Collection Time: 5.73182
Timestep Consumption Time: 0.86508
PPO Batch Consumption Time: 0.04204
Total Iteration Time: 6.59690

Cumulative Model Updates: 27,457
Cumulative Timesteps: 457,996,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.97430
Policy Entropy: 1.05604
Value Function Loss: 1.41738

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.20041
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 8,760.67441
Overall Steps per Second: 7,487.84718

Timestep Collection Time: 5.70938
Timestep Consumption Time: 0.97051
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 6.67989

Cumulative Model Updates: 27,460
Cumulative Timesteps: 458,046,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 458046498...
Checkpoint 458046498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.58330
Policy Entropy: 1.05372
Value Function Loss: 1.37225

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.21331
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 8,453.24327
Overall Steps per Second: 7,380.94423

Timestep Collection Time: 5.91584
Timestep Consumption Time: 0.85945
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.77528

Cumulative Model Updates: 27,463
Cumulative Timesteps: 458,096,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.75884
Policy Entropy: 1.04011
Value Function Loss: 1.31353

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.20603
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.07431

Collected Steps per Second: 8,648.59974
Overall Steps per Second: 7,633.67948

Timestep Collection Time: 5.78267
Timestep Consumption Time: 0.76882
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.55149

Cumulative Model Updates: 27,466
Cumulative Timesteps: 458,146,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 458146518...
Checkpoint 458146518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.02734
Policy Entropy: 1.03277
Value Function Loss: 1.20321

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.22069
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.07913

Collected Steps per Second: 8,884.33821
Overall Steps per Second: 7,694.72270

Timestep Collection Time: 5.63081
Timestep Consumption Time: 0.87053
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.50134

Cumulative Model Updates: 27,469
Cumulative Timesteps: 458,196,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.69201
Policy Entropy: 1.04150
Value Function Loss: 1.34229

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.17552
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.07359

Collected Steps per Second: 8,604.62432
Overall Steps per Second: 7,509.66260

Timestep Collection Time: 5.81339
Timestep Consumption Time: 0.84763
PPO Batch Consumption Time: 0.04515
Total Iteration Time: 6.66102

Cumulative Model Updates: 27,472
Cumulative Timesteps: 458,246,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 458246566...
Checkpoint 458246566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.65088
Policy Entropy: 1.05072
Value Function Loss: 1.46965

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.20108
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.07750

Collected Steps per Second: 8,751.30815
Overall Steps per Second: 7,638.86727

Timestep Collection Time: 5.71503
Timestep Consumption Time: 0.83227
PPO Batch Consumption Time: 0.04448
Total Iteration Time: 6.54731

Cumulative Model Updates: 27,475
Cumulative Timesteps: 458,296,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.92891
Policy Entropy: 1.00895
Value Function Loss: 1.44196

Mean KL Divergence: 0.05744
SB3 Clip Fraction: 0.30178
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.08011

Collected Steps per Second: 8,675.72091
Overall Steps per Second: 7,418.44582

Timestep Collection Time: 5.76459
Timestep Consumption Time: 0.97698
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.74157

Cumulative Model Updates: 27,478
Cumulative Timesteps: 458,346,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 458346592...
Checkpoint 458346592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.12521
Policy Entropy: 1.03057
Value Function Loss: 1.37089

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.19360
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 8,714.70291
Overall Steps per Second: 7,692.64101

Timestep Collection Time: 5.74064
Timestep Consumption Time: 0.76271
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 6.50336

Cumulative Model Updates: 27,481
Cumulative Timesteps: 458,396,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.03758
Policy Entropy: 1.01652
Value Function Loss: 1.32805

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.21515
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 8,608.52685
Overall Steps per Second: 7,474.58344

Timestep Collection Time: 5.81075
Timestep Consumption Time: 0.88153
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.69228

Cumulative Model Updates: 27,484
Cumulative Timesteps: 458,446,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 458446642...
Checkpoint 458446642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.09444
Policy Entropy: 1.01043
Value Function Loss: 1.34297

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.22573
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.07973

Collected Steps per Second: 8,751.79149
Overall Steps per Second: 7,589.98606

Timestep Collection Time: 5.71403
Timestep Consumption Time: 0.87465
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.58868

Cumulative Model Updates: 27,487
Cumulative Timesteps: 458,496,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.80460
Policy Entropy: 1.02079
Value Function Loss: 1.30548

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.17416
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 8,626.50289
Overall Steps per Second: 7,482.87243

Timestep Collection Time: 5.79934
Timestep Consumption Time: 0.88633
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.68567

Cumulative Model Updates: 27,490
Cumulative Timesteps: 458,546,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 458546678...
Checkpoint 458546678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.08073
Policy Entropy: 1.03340
Value Function Loss: 1.28719

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.16541
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 8,737.72327
Overall Steps per Second: 7,544.70623

Timestep Collection Time: 5.72346
Timestep Consumption Time: 0.90503
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.62849

Cumulative Model Updates: 27,493
Cumulative Timesteps: 458,596,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.98823
Policy Entropy: 1.00788
Value Function Loss: 1.33673

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.19311
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.06404

Collected Steps per Second: 8,639.28035
Overall Steps per Second: 7,626.54415

Timestep Collection Time: 5.78821
Timestep Consumption Time: 0.76862
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.55684

Cumulative Model Updates: 27,496
Cumulative Timesteps: 458,646,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 458646694...
Checkpoint 458646694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.24920
Policy Entropy: 0.98868
Value Function Loss: 1.40145

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.25729
Policy Update Magnitude: 0.04431
Value Function Update Magnitude: 0.07488

Collected Steps per Second: 9,081.05423
Overall Steps per Second: 7,776.45526

Timestep Collection Time: 5.50619
Timestep Consumption Time: 0.92373
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.42992

Cumulative Model Updates: 27,499
Cumulative Timesteps: 458,696,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.47786
Policy Entropy: 1.00244
Value Function Loss: 1.35956

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 8,843.46378
Overall Steps per Second: 7,679.68369

Timestep Collection Time: 5.65457
Timestep Consumption Time: 0.85689
PPO Batch Consumption Time: 0.04511
Total Iteration Time: 6.51147

Cumulative Model Updates: 27,502
Cumulative Timesteps: 458,746,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 458746702...
Checkpoint 458746702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.33999
Policy Entropy: 1.02589
Value Function Loss: 1.35287

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.23671
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 9,407.89505
Overall Steps per Second: 8,036.48047

Timestep Collection Time: 5.31532
Timestep Consumption Time: 0.90705
PPO Batch Consumption Time: 0.04881
Total Iteration Time: 6.22238

Cumulative Model Updates: 27,505
Cumulative Timesteps: 458,796,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.03595
Policy Entropy: 0.98990
Value Function Loss: 1.30670

Mean KL Divergence: 0.03741
SB3 Clip Fraction: 0.27096
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 9,013.99533
Overall Steps per Second: 7,819.25064

Timestep Collection Time: 5.54959
Timestep Consumption Time: 0.84795
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 6.39754

Cumulative Model Updates: 27,508
Cumulative Timesteps: 458,846,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 458846732...
Checkpoint 458846732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.38575
Policy Entropy: 1.01531
Value Function Loss: 1.32733

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.21505
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.07666

Collected Steps per Second: 8,949.23587
Overall Steps per Second: 7,892.81251

Timestep Collection Time: 5.58953
Timestep Consumption Time: 0.74814
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.33766

Cumulative Model Updates: 27,511
Cumulative Timesteps: 458,896,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.63668
Policy Entropy: 1.00015
Value Function Loss: 1.33554

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.19001
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 8,779.00603
Overall Steps per Second: 7,646.91654

Timestep Collection Time: 5.69700
Timestep Consumption Time: 0.84341
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 6.54041

Cumulative Model Updates: 27,514
Cumulative Timesteps: 458,946,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 458946768...
Checkpoint 458946768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.39450
Policy Entropy: 0.99889
Value Function Loss: 1.32553

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 8,350.97334
Overall Steps per Second: 7,319.75159

Timestep Collection Time: 5.98804
Timestep Consumption Time: 0.84361
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.83165

Cumulative Model Updates: 27,517
Cumulative Timesteps: 458,996,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.32060
Policy Entropy: 0.97525
Value Function Loss: 1.43757

Mean KL Divergence: 0.04128
SB3 Clip Fraction: 0.27791
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.06482

Collected Steps per Second: 8,973.92416
Overall Steps per Second: 7,747.19407

Timestep Collection Time: 5.57326
Timestep Consumption Time: 0.88250
PPO Batch Consumption Time: 0.04794
Total Iteration Time: 6.45576

Cumulative Model Updates: 27,520
Cumulative Timesteps: 459,046,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 459046788...
Checkpoint 459046788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.95440
Policy Entropy: 1.01198
Value Function Loss: 1.40450

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.23990
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 8,597.59018
Overall Steps per Second: 7,471.15929

Timestep Collection Time: 5.81675
Timestep Consumption Time: 0.87699
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 6.69374

Cumulative Model Updates: 27,523
Cumulative Timesteps: 459,096,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.56867
Policy Entropy: 0.98886
Value Function Loss: 1.40976

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.20355
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 8,528.12944
Overall Steps per Second: 7,561.53042

Timestep Collection Time: 5.86412
Timestep Consumption Time: 0.74962
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.61374

Cumulative Model Updates: 27,526
Cumulative Timesteps: 459,146,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 459146808...
Checkpoint 459146808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.84837
Policy Entropy: 0.99037
Value Function Loss: 1.27468

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.19403
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.05755

Collected Steps per Second: 8,777.71804
Overall Steps per Second: 7,610.27143

Timestep Collection Time: 5.69670
Timestep Consumption Time: 0.87390
PPO Batch Consumption Time: 0.05153
Total Iteration Time: 6.57059

Cumulative Model Updates: 27,529
Cumulative Timesteps: 459,196,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.16201
Policy Entropy: 1.01141
Value Function Loss: 1.28496

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.20279
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 8,748.79036
Overall Steps per Second: 7,673.40435

Timestep Collection Time: 5.71576
Timestep Consumption Time: 0.80103
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.51679

Cumulative Model Updates: 27,532
Cumulative Timesteps: 459,246,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 459246818...
Checkpoint 459246818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.86264
Policy Entropy: 1.02497
Value Function Loss: 1.27007

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.24212
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.05698

Collected Steps per Second: 9,023.83160
Overall Steps per Second: 7,795.01428

Timestep Collection Time: 5.54376
Timestep Consumption Time: 0.87393
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.41769

Cumulative Model Updates: 27,535
Cumulative Timesteps: 459,296,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.27917
Policy Entropy: 1.00146
Value Function Loss: 1.29214

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.18974
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 8,712.37761
Overall Steps per Second: 7,570.31586

Timestep Collection Time: 5.74195
Timestep Consumption Time: 0.86623
PPO Batch Consumption Time: 0.04410
Total Iteration Time: 6.60818

Cumulative Model Updates: 27,538
Cumulative Timesteps: 459,346,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 459346870...
Checkpoint 459346870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.07041
Policy Entropy: 1.00320
Value Function Loss: 1.34047

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.20455
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.05558

Collected Steps per Second: 8,614.62977
Overall Steps per Second: 7,609.63842

Timestep Collection Time: 5.80571
Timestep Consumption Time: 0.76675
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.57245

Cumulative Model Updates: 27,541
Cumulative Timesteps: 459,396,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.58024
Policy Entropy: 1.01892
Value Function Loss: 1.48366

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.18899
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.05544

Collected Steps per Second: 8,650.87913
Overall Steps per Second: 7,534.57811

Timestep Collection Time: 5.78230
Timestep Consumption Time: 0.85669
PPO Batch Consumption Time: 0.04191
Total Iteration Time: 6.63899

Cumulative Model Updates: 27,544
Cumulative Timesteps: 459,446,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 459446906...
Checkpoint 459446906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.05529
Policy Entropy: 1.02264
Value Function Loss: 1.53615

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.17883
Policy Update Magnitude: 0.04198
Value Function Update Magnitude: 0.05615

Collected Steps per Second: 8,768.25053
Overall Steps per Second: 7,621.43867

Timestep Collection Time: 5.70285
Timestep Consumption Time: 0.85812
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.56097

Cumulative Model Updates: 27,547
Cumulative Timesteps: 459,496,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.03186
Policy Entropy: 1.01087
Value Function Loss: 1.43110

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.19565
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.05474

Collected Steps per Second: 8,774.26670
Overall Steps per Second: 7,649.25556

Timestep Collection Time: 5.69848
Timestep Consumption Time: 0.83810
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.53658

Cumulative Model Updates: 27,550
Cumulative Timesteps: 459,546,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 459546910...
Checkpoint 459546910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.77069
Policy Entropy: 1.01726
Value Function Loss: 1.30111

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.20492
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 8,936.38668
Overall Steps per Second: 7,713.18558

Timestep Collection Time: 5.59734
Timestep Consumption Time: 0.88766
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 6.48500

Cumulative Model Updates: 27,553
Cumulative Timesteps: 459,596,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.35624
Policy Entropy: 1.02619
Value Function Loss: 1.30969

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.17971
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 8,724.87477
Overall Steps per Second: 7,539.70039

Timestep Collection Time: 5.73166
Timestep Consumption Time: 0.90097
PPO Batch Consumption Time: 0.05059
Total Iteration Time: 6.63262

Cumulative Model Updates: 27,556
Cumulative Timesteps: 459,646,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 459646938...
Checkpoint 459646938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.07769
Policy Entropy: 1.03059
Value Function Loss: 1.33453

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.21117
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 8,703.17384
Overall Steps per Second: 7,555.98012

Timestep Collection Time: 5.74549
Timestep Consumption Time: 0.87231
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 6.61780

Cumulative Model Updates: 27,559
Cumulative Timesteps: 459,696,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.58562
Policy Entropy: 1.01051
Value Function Loss: 1.37667

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 8,770.98836
Overall Steps per Second: 7,761.11083

Timestep Collection Time: 5.70312
Timestep Consumption Time: 0.74209
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.44521

Cumulative Model Updates: 27,562
Cumulative Timesteps: 459,746,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 459746964...
Checkpoint 459746964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.13085
Policy Entropy: 0.98997
Value Function Loss: 1.35439

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.25673
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.07269

Collected Steps per Second: 8,905.30699
Overall Steps per Second: 7,700.73203

Timestep Collection Time: 5.61575
Timestep Consumption Time: 0.87844
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.49419

Cumulative Model Updates: 27,565
Cumulative Timesteps: 459,796,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.79131
Policy Entropy: 1.02984
Value Function Loss: 1.33930

Mean KL Divergence: 0.02951
SB3 Clip Fraction: 0.24515
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 8,703.29396
Overall Steps per Second: 7,530.73407

Timestep Collection Time: 5.74587
Timestep Consumption Time: 0.89465
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 6.64052

Cumulative Model Updates: 27,568
Cumulative Timesteps: 459,846,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 459846982...
Checkpoint 459846982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.47828
Policy Entropy: 0.99554
Value Function Loss: 1.34596

Mean KL Divergence: 0.03112
SB3 Clip Fraction: 0.23900
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 8,579.32801
Overall Steps per Second: 7,547.97720

Timestep Collection Time: 5.83076
Timestep Consumption Time: 0.79671
PPO Batch Consumption Time: 0.04633
Total Iteration Time: 6.62747

Cumulative Model Updates: 27,571
Cumulative Timesteps: 459,897,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.05680
Policy Entropy: 1.02766
Value Function Loss: 1.31897

Mean KL Divergence: 0.02995
SB3 Clip Fraction: 0.22812
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.05787

Collected Steps per Second: 8,641.33154
Overall Steps per Second: 7,485.73739

Timestep Collection Time: 5.78707
Timestep Consumption Time: 0.89337
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.68044

Cumulative Model Updates: 27,574
Cumulative Timesteps: 459,947,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 459947014...
Checkpoint 459947014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.91366
Policy Entropy: 1.02004
Value Function Loss: 1.39506

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.21123
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.05597

Collected Steps per Second: 8,830.48376
Overall Steps per Second: 7,652.19764

Timestep Collection Time: 5.66311
Timestep Consumption Time: 0.87201
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.53512

Cumulative Model Updates: 27,577
Cumulative Timesteps: 459,997,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.75256
Policy Entropy: 1.01540
Value Function Loss: 1.38260

Mean KL Divergence: 0.02760
SB3 Clip Fraction: 0.23164
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.05330

Collected Steps per Second: 8,945.95482
Overall Steps per Second: 7,738.82703

Timestep Collection Time: 5.59180
Timestep Consumption Time: 0.87223
PPO Batch Consumption Time: 0.04945
Total Iteration Time: 6.46403

Cumulative Model Updates: 27,580
Cumulative Timesteps: 460,047,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 460047046...
Checkpoint 460047046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.74785
Policy Entropy: 1.03212
Value Function Loss: 1.47859

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.17027
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 8,667.02945
Overall Steps per Second: 7,541.95281

Timestep Collection Time: 5.77060
Timestep Consumption Time: 0.86083
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 6.63144

Cumulative Model Updates: 27,583
Cumulative Timesteps: 460,097,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.03509
Policy Entropy: 1.05388
Value Function Loss: 1.52281

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.18221
Policy Update Magnitude: 0.06643
Value Function Update Magnitude: 0.07069

Collected Steps per Second: 8,678.67179
Overall Steps per Second: 7,543.85016

Timestep Collection Time: 5.76379
Timestep Consumption Time: 0.86705
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.63083

Cumulative Model Updates: 27,586
Cumulative Timesteps: 460,147,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 460147082...
Checkpoint 460147082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.35818
Policy Entropy: 1.02455
Value Function Loss: 1.51669

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.20580
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.06679

Collected Steps per Second: 8,737.21818
Overall Steps per Second: 7,611.82499

Timestep Collection Time: 5.72516
Timestep Consumption Time: 0.84645
PPO Batch Consumption Time: 0.04815
Total Iteration Time: 6.57162

Cumulative Model Updates: 27,589
Cumulative Timesteps: 460,197,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.60023
Policy Entropy: 1.03970
Value Function Loss: 1.44949

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.20074
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 8,864.11386
Overall Steps per Second: 7,722.25004

Timestep Collection Time: 5.64411
Timestep Consumption Time: 0.83458
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.47868

Cumulative Model Updates: 27,592
Cumulative Timesteps: 460,247,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 460247134...
Checkpoint 460247134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.11492
Policy Entropy: 1.04582
Value Function Loss: 1.42847

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.16983
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.07571

Collected Steps per Second: 8,806.39569
Overall Steps per Second: 7,652.65789

Timestep Collection Time: 5.67974
Timestep Consumption Time: 0.85629
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 6.53603

Cumulative Model Updates: 27,595
Cumulative Timesteps: 460,297,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.53483
Policy Entropy: 1.06217
Value Function Loss: 1.43890

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.18871
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.06175

Collected Steps per Second: 8,630.84196
Overall Steps per Second: 7,429.03782

Timestep Collection Time: 5.79689
Timestep Consumption Time: 0.93777
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.73465

Cumulative Model Updates: 27,598
Cumulative Timesteps: 460,347,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 460347184...
Checkpoint 460347184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.47752
Policy Entropy: 1.04397
Value Function Loss: 1.36575

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.18287
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.06143

Collected Steps per Second: 8,770.54424
Overall Steps per Second: 7,735.71783

Timestep Collection Time: 5.70158
Timestep Consumption Time: 0.76272
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.46430

Cumulative Model Updates: 27,601
Cumulative Timesteps: 460,397,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.62749
Policy Entropy: 1.03872
Value Function Loss: 1.32891

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.21796
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 8,746.38464
Overall Steps per Second: 7,564.58125

Timestep Collection Time: 5.71893
Timestep Consumption Time: 0.89346
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 6.61240

Cumulative Model Updates: 27,604
Cumulative Timesteps: 460,447,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 460447210...
Checkpoint 460447210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.96865
Policy Entropy: 1.05917
Value Function Loss: 1.35962

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.16182
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.06113

Collected Steps per Second: 8,657.91440
Overall Steps per Second: 7,630.67997

Timestep Collection Time: 5.77760
Timestep Consumption Time: 0.77778
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.55538

Cumulative Model Updates: 27,607
Cumulative Timesteps: 460,497,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.78916
Policy Entropy: 1.06358
Value Function Loss: 1.38924

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 8,997.15413
Overall Steps per Second: 7,675.93277

Timestep Collection Time: 5.56087
Timestep Consumption Time: 0.95717
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.51804

Cumulative Model Updates: 27,610
Cumulative Timesteps: 460,547,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 460547264...
Checkpoint 460547264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.97612
Policy Entropy: 1.05786
Value Function Loss: 1.41954

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 8,775.38420
Overall Steps per Second: 7,754.34681

Timestep Collection Time: 5.69935
Timestep Consumption Time: 0.75045
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.44980

Cumulative Model Updates: 27,613
Cumulative Timesteps: 460,597,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.27250
Policy Entropy: 1.03894
Value Function Loss: 1.32831

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.19763
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 9,344.74872
Overall Steps per Second: 8,015.53251

Timestep Collection Time: 5.35274
Timestep Consumption Time: 0.88764
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.24038

Cumulative Model Updates: 27,616
Cumulative Timesteps: 460,647,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 460647298...
Checkpoint 460647298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.65486
Policy Entropy: 1.06213
Value Function Loss: 1.39919

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.17025
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.08718

Collected Steps per Second: 9,061.63674
Overall Steps per Second: 7,789.86470

Timestep Collection Time: 5.52019
Timestep Consumption Time: 0.90123
PPO Batch Consumption Time: 0.04786
Total Iteration Time: 6.42142

Cumulative Model Updates: 27,619
Cumulative Timesteps: 460,697,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.55352
Policy Entropy: 1.07292
Value Function Loss: 1.39703

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17585
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.08751

Collected Steps per Second: 8,528.84530
Overall Steps per Second: 7,498.50365

Timestep Collection Time: 5.86340
Timestep Consumption Time: 0.80567
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.66906

Cumulative Model Updates: 27,622
Cumulative Timesteps: 460,747,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 460747328...
Checkpoint 460747328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.49570
Policy Entropy: 1.05247
Value Function Loss: 1.38456

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 8,664.89438
Overall Steps per Second: 7,536.18191

Timestep Collection Time: 5.77341
Timestep Consumption Time: 0.86470
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.63811

Cumulative Model Updates: 27,625
Cumulative Timesteps: 460,797,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.64773
Policy Entropy: 1.05932
Value Function Loss: 1.29620

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.08336

Collected Steps per Second: 8,694.61973
Overall Steps per Second: 7,555.95323

Timestep Collection Time: 5.75252
Timestep Consumption Time: 0.86689
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 6.61942

Cumulative Model Updates: 27,628
Cumulative Timesteps: 460,847,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 460847370...
Checkpoint 460847370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.72905
Policy Entropy: 1.06836
Value Function Loss: 1.27815

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 8,978.90684
Overall Steps per Second: 7,809.39784

Timestep Collection Time: 5.56905
Timestep Consumption Time: 0.83400
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 6.40305

Cumulative Model Updates: 27,631
Cumulative Timesteps: 460,897,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.02452
Policy Entropy: 1.08821
Value Function Loss: 1.33914

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.17871
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.08027

Collected Steps per Second: 8,799.84791
Overall Steps per Second: 7,670.43327

Timestep Collection Time: 5.68464
Timestep Consumption Time: 0.83702
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.52167

Cumulative Model Updates: 27,634
Cumulative Timesteps: 460,947,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 460947398...
Checkpoint 460947398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.66856
Policy Entropy: 1.06990
Value Function Loss: 1.47571

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 8,847.63555
Overall Steps per Second: 7,788.35888

Timestep Collection Time: 5.65145
Timestep Consumption Time: 0.76864
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 6.42009

Cumulative Model Updates: 27,637
Cumulative Timesteps: 460,997,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.09931
Policy Entropy: 1.08211
Value Function Loss: 1.42554

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07923

Collected Steps per Second: 8,458.84671
Overall Steps per Second: 7,404.87206

Timestep Collection Time: 5.91168
Timestep Consumption Time: 0.84144
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.75312

Cumulative Model Updates: 27,640
Cumulative Timesteps: 461,047,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 461047406...
Checkpoint 461047406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.35376
Policy Entropy: 1.07874
Value Function Loss: 1.35932

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 8,702.12775
Overall Steps per Second: 7,590.66973

Timestep Collection Time: 5.74641
Timestep Consumption Time: 0.84141
PPO Batch Consumption Time: 0.04837
Total Iteration Time: 6.58782

Cumulative Model Updates: 27,643
Cumulative Timesteps: 461,097,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.79234
Policy Entropy: 1.08976
Value Function Loss: 1.32648

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 8,857.89868
Overall Steps per Second: 7,790.69178

Timestep Collection Time: 5.64468
Timestep Consumption Time: 0.77324
PPO Batch Consumption Time: 0.04910
Total Iteration Time: 6.41792

Cumulative Model Updates: 27,646
Cumulative Timesteps: 461,147,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 461147412...
Checkpoint 461147412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.72167
Policy Entropy: 1.07254
Value Function Loss: 1.45721

Mean KL Divergence: 0.03134
SB3 Clip Fraction: 0.18195
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 8,709.47541
Overall Steps per Second: 7,582.94851

Timestep Collection Time: 5.74225
Timestep Consumption Time: 0.85307
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 6.59532

Cumulative Model Updates: 27,649
Cumulative Timesteps: 461,197,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.46806
Policy Entropy: 1.08117
Value Function Loss: 1.59136

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 8,649.10037
Overall Steps per Second: 7,472.94769

Timestep Collection Time: 5.78303
Timestep Consumption Time: 0.91018
PPO Batch Consumption Time: 0.04732
Total Iteration Time: 6.69321

Cumulative Model Updates: 27,652
Cumulative Timesteps: 461,247,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 461247442...
Checkpoint 461247442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.86774
Policy Entropy: 1.08550
Value Function Loss: 1.56220

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.17320
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 8,974.35946
Overall Steps per Second: 7,839.14135

Timestep Collection Time: 5.57232
Timestep Consumption Time: 0.80695
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.37927

Cumulative Model Updates: 27,655
Cumulative Timesteps: 461,297,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.10495
Policy Entropy: 1.08374
Value Function Loss: 1.56781

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.07291

Collected Steps per Second: 8,895.14672
Overall Steps per Second: 7,756.39883

Timestep Collection Time: 5.62239
Timestep Consumption Time: 0.82545
PPO Batch Consumption Time: 0.04787
Total Iteration Time: 6.44784

Cumulative Model Updates: 27,658
Cumulative Timesteps: 461,347,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 461347462...
Checkpoint 461347462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.44217
Policy Entropy: 1.08715
Value Function Loss: 1.51896

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.08058

Collected Steps per Second: 8,846.04054
Overall Steps per Second: 7,857.51871

Timestep Collection Time: 5.65247
Timestep Consumption Time: 0.71111
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.36359

Cumulative Model Updates: 27,661
Cumulative Timesteps: 461,397,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.01228
Policy Entropy: 1.08848
Value Function Loss: 1.46765

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.07531
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 8,993.00056
Overall Steps per Second: 7,751.86159

Timestep Collection Time: 5.56277
Timestep Consumption Time: 0.89065
PPO Batch Consumption Time: 0.05109
Total Iteration Time: 6.45342

Cumulative Model Updates: 27,664
Cumulative Timesteps: 461,447,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 461447490...
Checkpoint 461447490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.56477
Policy Entropy: 1.09459
Value Function Loss: 1.35741

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.07457
Value Function Update Magnitude: 0.09836

Collected Steps per Second: 8,787.54046
Overall Steps per Second: 7,683.16113

Timestep Collection Time: 5.69124
Timestep Consumption Time: 0.81806
PPO Batch Consumption Time: 0.03968
Total Iteration Time: 6.50930

Cumulative Model Updates: 27,667
Cumulative Timesteps: 461,497,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.49467
Policy Entropy: 1.09723
Value Function Loss: 1.28956

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.09798

Collected Steps per Second: 9,146.10738
Overall Steps per Second: 7,911.04018

Timestep Collection Time: 5.46899
Timestep Consumption Time: 0.85382
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.32281

Cumulative Model Updates: 27,670
Cumulative Timesteps: 461,547,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 461547522...
Checkpoint 461547522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.96270
Policy Entropy: 1.08343
Value Function Loss: 1.34036

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.09177

Collected Steps per Second: 8,993.70182
Overall Steps per Second: 7,793.96719

Timestep Collection Time: 5.55989
Timestep Consumption Time: 0.85584
PPO Batch Consumption Time: 0.03996
Total Iteration Time: 6.41573

Cumulative Model Updates: 27,673
Cumulative Timesteps: 461,597,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.19381
Policy Entropy: 1.09805
Value Function Loss: 1.44260

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 8,994.67313
Overall Steps per Second: 7,882.12649

Timestep Collection Time: 5.56218
Timestep Consumption Time: 0.78509
PPO Batch Consumption Time: 0.04710
Total Iteration Time: 6.34727

Cumulative Model Updates: 27,676
Cumulative Timesteps: 461,647,556

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 461647556...
Checkpoint 461647556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.89550
Policy Entropy: 1.09741
Value Function Loss: 1.48559

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.08865

Collected Steps per Second: 8,784.04101
Overall Steps per Second: 7,662.94999

Timestep Collection Time: 5.69214
Timestep Consumption Time: 0.83276
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 6.52490

Cumulative Model Updates: 27,679
Cumulative Timesteps: 461,697,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.15083
Policy Entropy: 1.10290
Value Function Loss: 1.41020

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.07959

Collected Steps per Second: 8,599.02715
Overall Steps per Second: 7,555.55793

Timestep Collection Time: 5.81531
Timestep Consumption Time: 0.80313
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.61844

Cumulative Model Updates: 27,682
Cumulative Timesteps: 461,747,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 461747562...
Checkpoint 461747562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.19451
Policy Entropy: 1.09797
Value Function Loss: 1.39327

Mean KL Divergence: 0.02535
SB3 Clip Fraction: 0.19439
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 8,975.24653
Overall Steps per Second: 7,811.70844

Timestep Collection Time: 5.57333
Timestep Consumption Time: 0.83014
PPO Batch Consumption Time: 0.04759
Total Iteration Time: 6.40346

Cumulative Model Updates: 27,685
Cumulative Timesteps: 461,797,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.81728
Policy Entropy: 1.11799
Value Function Loss: 1.38643

Mean KL Divergence: 0.02665
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.07120

Collected Steps per Second: 8,756.86858
Overall Steps per Second: 7,631.66981

Timestep Collection Time: 5.71072
Timestep Consumption Time: 0.84198
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.55269

Cumulative Model Updates: 27,688
Cumulative Timesteps: 461,847,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 461847592...
Checkpoint 461847592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.83587
Policy Entropy: 1.12016
Value Function Loss: 1.47933

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 9,013.08340
Overall Steps per Second: 7,684.31628

Timestep Collection Time: 5.54949
Timestep Consumption Time: 0.95961
PPO Batch Consumption Time: 0.04760
Total Iteration Time: 6.50910

Cumulative Model Updates: 27,691
Cumulative Timesteps: 461,897,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.53926
Policy Entropy: 1.10242
Value Function Loss: 1.50005

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 8,678.04936
Overall Steps per Second: 7,567.12728

Timestep Collection Time: 5.76420
Timestep Consumption Time: 0.84624
PPO Batch Consumption Time: 0.04460
Total Iteration Time: 6.61043

Cumulative Model Updates: 27,694
Cumulative Timesteps: 461,947,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 461947632...
Checkpoint 461947632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.12596
Policy Entropy: 1.09357
Value Function Loss: 1.58314

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.18651
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07323

Collected Steps per Second: 8,901.81481
Overall Steps per Second: 7,842.26730

Timestep Collection Time: 5.61930
Timestep Consumption Time: 0.75921
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 6.37851

Cumulative Model Updates: 27,697
Cumulative Timesteps: 461,997,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.61891
Policy Entropy: 1.10289
Value Function Loss: 1.53698

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 8,979.00554
Overall Steps per Second: 7,761.67969

Timestep Collection Time: 5.57122
Timestep Consumption Time: 0.87378
PPO Batch Consumption Time: 0.04161
Total Iteration Time: 6.44500

Cumulative Model Updates: 27,700
Cumulative Timesteps: 462,047,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 462047678...
Checkpoint 462047678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.65807
Policy Entropy: 1.11237
Value Function Loss: 1.48638

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 8,721.45822
Overall Steps per Second: 7,574.10316

Timestep Collection Time: 5.73482
Timestep Consumption Time: 0.86873
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.60355

Cumulative Model Updates: 27,703
Cumulative Timesteps: 462,097,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.36055
Policy Entropy: 1.08356
Value Function Loss: 1.36734

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.19619
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 8,898.68090
Overall Steps per Second: 7,670.29888

Timestep Collection Time: 5.62218
Timestep Consumption Time: 0.90038
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.52256

Cumulative Model Updates: 27,706
Cumulative Timesteps: 462,147,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 462147724...
Checkpoint 462147724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.60708
Policy Entropy: 1.10309
Value Function Loss: 1.39073

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.09357

Collected Steps per Second: 8,579.80727
Overall Steps per Second: 7,447.81120

Timestep Collection Time: 5.83043
Timestep Consumption Time: 0.88617
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.71660

Cumulative Model Updates: 27,709
Cumulative Timesteps: 462,197,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.77213
Policy Entropy: 1.10638
Value Function Loss: 1.40016

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.16433
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.08180

Collected Steps per Second: 9,199.33896
Overall Steps per Second: 7,934.48386

Timestep Collection Time: 5.43713
Timestep Consumption Time: 0.86675
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.30388

Cumulative Model Updates: 27,712
Cumulative Timesteps: 462,247,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 462247766...
Checkpoint 462247766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.59066
Policy Entropy: 1.08709
Value Function Loss: 1.46590

Mean KL Divergence: 0.03859
SB3 Clip Fraction: 0.20504
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 8,877.31621
Overall Steps per Second: 7,646.72533

Timestep Collection Time: 5.63504
Timestep Consumption Time: 0.90685
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.54189

Cumulative Model Updates: 27,715
Cumulative Timesteps: 462,297,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.06682
Policy Entropy: 1.09878
Value Function Loss: 1.53859

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 9,125.33874
Overall Steps per Second: 8,004.36495

Timestep Collection Time: 5.48254
Timestep Consumption Time: 0.76780
PPO Batch Consumption Time: 0.04857
Total Iteration Time: 6.25034

Cumulative Model Updates: 27,718
Cumulative Timesteps: 462,347,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 462347820...
Checkpoint 462347820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.22246
Policy Entropy: 1.09121
Value Function Loss: 1.55252

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.09981

Collected Steps per Second: 9,193.35809
Overall Steps per Second: 7,831.29875

Timestep Collection Time: 5.44067
Timestep Consumption Time: 0.94627
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 6.38694

Cumulative Model Updates: 27,721
Cumulative Timesteps: 462,397,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.44664
Policy Entropy: 1.08739
Value Function Loss: 1.46407

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.17630
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.09998

Collected Steps per Second: 8,968.69621
Overall Steps per Second: 7,804.66180

Timestep Collection Time: 5.57807
Timestep Consumption Time: 0.83195
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.41002

Cumulative Model Updates: 27,724
Cumulative Timesteps: 462,447,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 462447866...
Checkpoint 462447866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.02485
Policy Entropy: 1.07459
Value Function Loss: 1.43775

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.20325
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 9,199.90432
Overall Steps per Second: 7,924.83987

Timestep Collection Time: 5.43593
Timestep Consumption Time: 0.87461
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.31054

Cumulative Model Updates: 27,727
Cumulative Timesteps: 462,497,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.43124
Policy Entropy: 1.09757
Value Function Loss: 1.38072

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 9,471.92915
Overall Steps per Second: 8,107.53151

Timestep Collection Time: 5.27918
Timestep Consumption Time: 0.88842
PPO Batch Consumption Time: 0.05009
Total Iteration Time: 6.16760

Cumulative Model Updates: 27,730
Cumulative Timesteps: 462,547,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 462547880...
Checkpoint 462547880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.49558
Policy Entropy: 1.09688
Value Function Loss: 1.37211

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 8,731.90309
Overall Steps per Second: 7,728.65377

Timestep Collection Time: 5.72613
Timestep Consumption Time: 0.74330
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.46943

Cumulative Model Updates: 27,733
Cumulative Timesteps: 462,597,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.63216
Policy Entropy: 1.09214
Value Function Loss: 1.29259

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 8,775.25445
Overall Steps per Second: 7,582.18622

Timestep Collection Time: 5.69989
Timestep Consumption Time: 0.89689
PPO Batch Consumption Time: 0.04769
Total Iteration Time: 6.59678

Cumulative Model Updates: 27,736
Cumulative Timesteps: 462,647,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 462647898...
Checkpoint 462647898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.27004
Policy Entropy: 1.06580
Value Function Loss: 1.33379

Mean KL Divergence: 0.03603
SB3 Clip Fraction: 0.23077
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 8,961.75586
Overall Steps per Second: 7,799.64292

Timestep Collection Time: 5.58150
Timestep Consumption Time: 0.83162
PPO Batch Consumption Time: 0.04426
Total Iteration Time: 6.41311

Cumulative Model Updates: 27,739
Cumulative Timesteps: 462,697,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.32946
Policy Entropy: 1.10270
Value Function Loss: 1.36716

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.20837
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 8,993.78342
Overall Steps per Second: 7,780.51600

Timestep Collection Time: 5.55940
Timestep Consumption Time: 0.86691
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 6.42631

Cumulative Model Updates: 27,742
Cumulative Timesteps: 462,747,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 462747918...
Checkpoint 462747918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.54648
Policy Entropy: 1.07394
Value Function Loss: 1.37202

Mean KL Divergence: 0.03578
SB3 Clip Fraction: 0.24299
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.08085

Collected Steps per Second: 9,134.88125
Overall Steps per Second: 7,962.78044

Timestep Collection Time: 5.47352
Timestep Consumption Time: 0.80569
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.27921

Cumulative Model Updates: 27,745
Cumulative Timesteps: 462,797,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.60936
Policy Entropy: 1.09332
Value Function Loss: 1.37532

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.19234
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.08067

Collected Steps per Second: 8,891.19338
Overall Steps per Second: 7,784.36354

Timestep Collection Time: 5.62534
Timestep Consumption Time: 0.79985
PPO Batch Consumption Time: 0.04679
Total Iteration Time: 6.42519

Cumulative Model Updates: 27,748
Cumulative Timesteps: 462,847,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 462847934...
Checkpoint 462847934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.61277
Policy Entropy: 1.09151
Value Function Loss: 1.40977

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.19535
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.07832

Collected Steps per Second: 8,634.24607
Overall Steps per Second: 7,558.87362

Timestep Collection Time: 5.79437
Timestep Consumption Time: 0.82434
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.61871

Cumulative Model Updates: 27,751
Cumulative Timesteps: 462,897,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.99741
Policy Entropy: 1.07077
Value Function Loss: 1.51531

Mean KL Divergence: 0.03157
SB3 Clip Fraction: 0.21077
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.08548

Collected Steps per Second: 8,816.69114
Overall Steps per Second: 7,736.13183

Timestep Collection Time: 5.67288
Timestep Consumption Time: 0.79237
PPO Batch Consumption Time: 0.05000
Total Iteration Time: 6.46525

Cumulative Model Updates: 27,754
Cumulative Timesteps: 462,947,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 462947980...
Checkpoint 462947980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.37486
Policy Entropy: 1.09563
Value Function Loss: 1.53695

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.19994
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 8,837.92488
Overall Steps per Second: 7,702.51492

Timestep Collection Time: 5.66060
Timestep Consumption Time: 0.83442
PPO Batch Consumption Time: 0.04105
Total Iteration Time: 6.49502

Cumulative Model Updates: 27,757
Cumulative Timesteps: 462,998,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.88573
Policy Entropy: 1.08263
Value Function Loss: 1.52865

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.18903
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 8,753.20857
Overall Steps per Second: 7,645.17767

Timestep Collection Time: 5.71379
Timestep Consumption Time: 0.82811
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.54190

Cumulative Model Updates: 27,760
Cumulative Timesteps: 463,048,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 463048022...
Checkpoint 463048022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.82309
Policy Entropy: 1.08786
Value Function Loss: 1.39569

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 8,688.56838
Overall Steps per Second: 7,533.87987

Timestep Collection Time: 5.75791
Timestep Consumption Time: 0.88249
PPO Batch Consumption Time: 0.04518
Total Iteration Time: 6.64040

Cumulative Model Updates: 27,763
Cumulative Timesteps: 463,098,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.24583
Policy Entropy: 1.08027
Value Function Loss: 1.35876

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 8,858.59475
Overall Steps per Second: 7,716.81391

Timestep Collection Time: 5.64695
Timestep Consumption Time: 0.83552
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.48247

Cumulative Model Updates: 27,766
Cumulative Timesteps: 463,148,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 463148074...
Checkpoint 463148074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.55860
Policy Entropy: 1.07920
Value Function Loss: 1.38489

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.04541

Collected Steps per Second: 8,722.42019
Overall Steps per Second: 7,604.03447

Timestep Collection Time: 5.73511
Timestep Consumption Time: 0.84351
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.57861

Cumulative Model Updates: 27,769
Cumulative Timesteps: 463,198,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.73589
Policy Entropy: 1.08281
Value Function Loss: 1.41761

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.04358

Collected Steps per Second: 8,775.82905
Overall Steps per Second: 7,602.90611

Timestep Collection Time: 5.69883
Timestep Consumption Time: 0.87918
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 6.57801

Cumulative Model Updates: 27,772
Cumulative Timesteps: 463,248,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 463248110...
Checkpoint 463248110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.11031
Policy Entropy: 1.07818
Value Function Loss: 1.34505

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.06089

Collected Steps per Second: 8,975.26450
Overall Steps per Second: 7,852.19087

Timestep Collection Time: 5.57109
Timestep Consumption Time: 0.79682
PPO Batch Consumption Time: 0.04262
Total Iteration Time: 6.36790

Cumulative Model Updates: 27,775
Cumulative Timesteps: 463,298,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.49530
Policy Entropy: 1.08210
Value Function Loss: 1.27598

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.07212

Collected Steps per Second: 8,730.36652
Overall Steps per Second: 7,687.90116

Timestep Collection Time: 5.72737
Timestep Consumption Time: 0.77662
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 6.50399

Cumulative Model Updates: 27,778
Cumulative Timesteps: 463,348,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 463348114...
Checkpoint 463348114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.77989
Policy Entropy: 1.06290
Value Function Loss: 1.31097

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.18731
Policy Update Magnitude: 0.07860
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 9,040.69599
Overall Steps per Second: 7,825.44506

Timestep Collection Time: 5.53099
Timestep Consumption Time: 0.85893
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 6.38992

Cumulative Model Updates: 27,781
Cumulative Timesteps: 463,398,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.58031
Policy Entropy: 1.09204
Value Function Loss: 1.37588

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.19208
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 8,859.05930
Overall Steps per Second: 7,761.82390

Timestep Collection Time: 5.64710
Timestep Consumption Time: 0.79829
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.44539

Cumulative Model Updates: 27,784
Cumulative Timesteps: 463,448,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 463448146...
Checkpoint 463448146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.13204
Policy Entropy: 1.08125
Value Function Loss: 1.40184

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.07411
Value Function Update Magnitude: 0.05479

Collected Steps per Second: 8,923.69074
Overall Steps per Second: 7,750.72705

Timestep Collection Time: 5.60463
Timestep Consumption Time: 0.84818
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.45281

Cumulative Model Updates: 27,787
Cumulative Timesteps: 463,498,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.18488
Policy Entropy: 1.08620
Value Function Loss: 1.41799

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.07767
Value Function Update Magnitude: 0.05020

Collected Steps per Second: 8,928.50196
Overall Steps per Second: 7,715.23572

Timestep Collection Time: 5.60340
Timestep Consumption Time: 0.88117
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 6.48457

Cumulative Model Updates: 27,790
Cumulative Timesteps: 463,548,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 463548190...
Checkpoint 463548190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.28079
Policy Entropy: 1.08955
Value Function Loss: 1.30207

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.16240
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.05765

Collected Steps per Second: 8,618.88984
Overall Steps per Second: 7,614.44711

Timestep Collection Time: 5.80423
Timestep Consumption Time: 0.76565
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.56988

Cumulative Model Updates: 27,793
Cumulative Timesteps: 463,598,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.00522
Policy Entropy: 1.09607
Value Function Loss: 1.37191

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 8,819.53956
Overall Steps per Second: 7,610.63330

Timestep Collection Time: 5.66923
Timestep Consumption Time: 0.90053
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.56976

Cumulative Model Updates: 27,796
Cumulative Timesteps: 463,648,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 463648216...
Checkpoint 463648216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.10298
Policy Entropy: 1.09568
Value Function Loss: 1.43493

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.06556
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 8,761.17240
Overall Steps per Second: 7,669.97811

Timestep Collection Time: 5.70768
Timestep Consumption Time: 0.81202
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.51971

Cumulative Model Updates: 27,799
Cumulative Timesteps: 463,698,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.16579
Policy Entropy: 1.10691
Value Function Loss: 1.54097

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.06100

Collected Steps per Second: 8,927.76280
Overall Steps per Second: 7,738.52713

Timestep Collection Time: 5.60364
Timestep Consumption Time: 0.86115
PPO Batch Consumption Time: 0.03970
Total Iteration Time: 6.46480

Cumulative Model Updates: 27,802
Cumulative Timesteps: 463,748,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 463748250...
Checkpoint 463748250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.00663
Policy Entropy: 1.09335
Value Function Loss: 1.46604

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16635
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 8,522.35122
Overall Steps per Second: 7,433.42001

Timestep Collection Time: 5.86833
Timestep Consumption Time: 0.85966
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 6.72799

Cumulative Model Updates: 27,805
Cumulative Timesteps: 463,798,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.65690
Policy Entropy: 1.08296
Value Function Loss: 1.43571

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.19337
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.06504

Collected Steps per Second: 8,753.79411
Overall Steps per Second: 7,690.39682

Timestep Collection Time: 5.71432
Timestep Consumption Time: 0.79015
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.50448

Cumulative Model Updates: 27,808
Cumulative Timesteps: 463,848,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 463848284...
Checkpoint 463848284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.74376
Policy Entropy: 1.09359
Value Function Loss: 1.42337

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.06373

Collected Steps per Second: 8,946.96831
Overall Steps per Second: 7,772.35833

Timestep Collection Time: 5.58960
Timestep Consumption Time: 0.84474
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 6.43434

Cumulative Model Updates: 27,811
Cumulative Timesteps: 463,898,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.38608
Policy Entropy: 1.09215
Value Function Loss: 1.45832

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 8,831.42304
Overall Steps per Second: 7,556.42638

Timestep Collection Time: 5.66183
Timestep Consumption Time: 0.95532
PPO Batch Consumption Time: 0.04697
Total Iteration Time: 6.61715

Cumulative Model Updates: 27,814
Cumulative Timesteps: 463,948,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 463948296...
Checkpoint 463948296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.06072
Policy Entropy: 1.08171
Value Function Loss: 1.40216

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 9,029.51968
Overall Steps per Second: 7,815.68440

Timestep Collection Time: 5.53761
Timestep Consumption Time: 0.86003
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.39765

Cumulative Model Updates: 27,817
Cumulative Timesteps: 463,998,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.58446
Policy Entropy: 1.07982
Value Function Loss: 1.37736

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.19416
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.07188

Collected Steps per Second: 8,607.13271
Overall Steps per Second: 7,465.68868

Timestep Collection Time: 5.81169
Timestep Consumption Time: 0.88856
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.70025

Cumulative Model Updates: 27,820
Cumulative Timesteps: 464,048,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 464048320...
Checkpoint 464048320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.99066
Policy Entropy: 1.08463
Value Function Loss: 1.32162

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 8,698.49268
Overall Steps per Second: 7,648.96163

Timestep Collection Time: 5.74973
Timestep Consumption Time: 0.78893
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 6.53867

Cumulative Model Updates: 27,823
Cumulative Timesteps: 464,098,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.79379
Policy Entropy: 1.09131
Value Function Loss: 1.30086

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.15577
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.08097

Collected Steps per Second: 8,813.82057
Overall Steps per Second: 7,617.94991

Timestep Collection Time: 5.67336
Timestep Consumption Time: 0.89061
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.56397

Cumulative Model Updates: 27,826
Cumulative Timesteps: 464,148,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464148338...
Checkpoint 464148338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.00845
Policy Entropy: 1.05047
Value Function Loss: 1.36082

Mean KL Divergence: 0.04412
SB3 Clip Fraction: 0.22705
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 9,100.49922
Overall Steps per Second: 7,866.03528

Timestep Collection Time: 5.49618
Timestep Consumption Time: 0.86255
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 6.35873

Cumulative Model Updates: 27,829
Cumulative Timesteps: 464,198,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.77143
Policy Entropy: 1.08270
Value Function Loss: 1.43419

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.06922

Collected Steps per Second: 9,302.92009
Overall Steps per Second: 7,803.07227

Timestep Collection Time: 5.37638
Timestep Consumption Time: 1.03341
PPO Batch Consumption Time: 0.05185
Total Iteration Time: 6.40978

Cumulative Model Updates: 27,832
Cumulative Timesteps: 464,248,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 464248372...
Checkpoint 464248372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.43502
Policy Entropy: 1.07114
Value Function Loss: 1.40816

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.16231
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.06224

Collected Steps per Second: 9,057.94755
Overall Steps per Second: 7,755.20557

Timestep Collection Time: 5.52134
Timestep Consumption Time: 0.92749
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 6.44883

Cumulative Model Updates: 27,835
Cumulative Timesteps: 464,298,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.89518
Policy Entropy: 1.06601
Value Function Loss: 1.30513

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.15478
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 8,527.45630
Overall Steps per Second: 7,553.20330

Timestep Collection Time: 5.86459
Timestep Consumption Time: 0.75645
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.62103

Cumulative Model Updates: 27,838
Cumulative Timesteps: 464,348,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 464348394...
Checkpoint 464348394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.85669
Policy Entropy: 1.05571
Value Function Loss: 1.24167

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.06760

Collected Steps per Second: 9,061.85284
Overall Steps per Second: 7,790.90932

Timestep Collection Time: 5.51764
Timestep Consumption Time: 0.90010
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 6.41774

Cumulative Model Updates: 27,841
Cumulative Timesteps: 464,398,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.53243
Policy Entropy: 1.07267
Value Function Loss: 1.30414

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.17724
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 8,913.88133
Overall Steps per Second: 7,863.96668

Timestep Collection Time: 5.61080
Timestep Consumption Time: 0.74910
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.35989

Cumulative Model Updates: 27,844
Cumulative Timesteps: 464,448,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 464448408...
Checkpoint 464448408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.31411
Policy Entropy: 1.07711
Value Function Loss: 1.31558

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 8,494.06220
Overall Steps per Second: 7,383.53071

Timestep Collection Time: 5.89000
Timestep Consumption Time: 0.88589
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.77589

Cumulative Model Updates: 27,847
Cumulative Timesteps: 464,498,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.66221
Policy Entropy: 1.06508
Value Function Loss: 1.32470

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 8,832.62717
Overall Steps per Second: 7,676.16444

Timestep Collection Time: 5.66355
Timestep Consumption Time: 0.85325
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.51680

Cumulative Model Updates: 27,850
Cumulative Timesteps: 464,548,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 464548462...
Checkpoint 464548462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.75020
Policy Entropy: 1.04293
Value Function Loss: 1.33770

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.19759
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 8,827.49020
Overall Steps per Second: 7,811.04470

Timestep Collection Time: 5.66412
Timestep Consumption Time: 0.73707
PPO Batch Consumption Time: 0.04167
Total Iteration Time: 6.40119

Cumulative Model Updates: 27,853
Cumulative Timesteps: 464,598,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.85912
Policy Entropy: 1.06783
Value Function Loss: 1.33936

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.15773
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.06374

Collected Steps per Second: 8,811.55814
Overall Steps per Second: 7,705.62593

Timestep Collection Time: 5.67732
Timestep Consumption Time: 0.81482
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.49214

Cumulative Model Updates: 27,856
Cumulative Timesteps: 464,648,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 464648488...
Checkpoint 464648488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.24381
Policy Entropy: 1.06950
Value Function Loss: 1.26742

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.05216

Collected Steps per Second: 8,602.40118
Overall Steps per Second: 7,456.85227

Timestep Collection Time: 5.81396
Timestep Consumption Time: 0.89316
PPO Batch Consumption Time: 0.04936
Total Iteration Time: 6.70712

Cumulative Model Updates: 27,859
Cumulative Timesteps: 464,698,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.67021
Policy Entropy: 1.07597
Value Function Loss: 1.24788

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.07766
Value Function Update Magnitude: 0.04845

Collected Steps per Second: 8,858.07749
Overall Steps per Second: 7,735.96603

Timestep Collection Time: 5.64660
Timestep Consumption Time: 0.81905
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.46564

Cumulative Model Updates: 27,862
Cumulative Timesteps: 464,748,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 464748520...
Checkpoint 464748520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.36895
Policy Entropy: 1.07119
Value Function Loss: 1.28073

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.17405
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.04545

Collected Steps per Second: 8,807.64588
Overall Steps per Second: 7,706.68955

Timestep Collection Time: 5.67984
Timestep Consumption Time: 0.81141
PPO Batch Consumption Time: 0.04158
Total Iteration Time: 6.49124

Cumulative Model Updates: 27,865
Cumulative Timesteps: 464,798,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.92108
Policy Entropy: 1.07300
Value Function Loss: 1.37839

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.18085
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.04697

Collected Steps per Second: 8,688.19784
Overall Steps per Second: 7,694.37814

Timestep Collection Time: 5.75539
Timestep Consumption Time: 0.74338
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.49877

Cumulative Model Updates: 27,868
Cumulative Timesteps: 464,848,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464848550...
Checkpoint 464848550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.23620
Policy Entropy: 1.05215
Value Function Loss: 1.43135

Mean KL Divergence: 0.02782
SB3 Clip Fraction: 0.20545
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.04626

Collected Steps per Second: 8,607.85744
Overall Steps per Second: 7,514.79322

Timestep Collection Time: 5.81074
Timestep Consumption Time: 0.84520
PPO Batch Consumption Time: 0.04712
Total Iteration Time: 6.65594

Cumulative Model Updates: 27,871
Cumulative Timesteps: 464,898,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.14748
Policy Entropy: 1.06134
Value Function Loss: 1.44917

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.21065
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 8,651.84996
Overall Steps per Second: 7,567.61086

Timestep Collection Time: 5.78142
Timestep Consumption Time: 0.82833
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.60975

Cumulative Model Updates: 27,874
Cumulative Timesteps: 464,948,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 464948588...
Checkpoint 464948588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.58442
Policy Entropy: 1.05715
Value Function Loss: 1.37910

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.20151
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 8,736.07091
Overall Steps per Second: 7,638.08662

Timestep Collection Time: 5.72614
Timestep Consumption Time: 0.82314
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.54928

Cumulative Model Updates: 27,877
Cumulative Timesteps: 464,998,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.00594
Policy Entropy: 1.04178
Value Function Loss: 1.38264

Mean KL Divergence: 0.02953
SB3 Clip Fraction: 0.20630
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 8,793.59954
Overall Steps per Second: 7,671.30521

Timestep Collection Time: 5.68823
Timestep Consumption Time: 0.83217
PPO Batch Consumption Time: 0.03925
Total Iteration Time: 6.52040

Cumulative Model Updates: 27,880
Cumulative Timesteps: 465,048,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 465048632...
Checkpoint 465048632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.67819
Policy Entropy: 1.03717
Value Function Loss: 1.31598

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.21506
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 8,560.94781
Overall Steps per Second: 7,582.21196

Timestep Collection Time: 5.84164
Timestep Consumption Time: 0.75406
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.59570

Cumulative Model Updates: 27,883
Cumulative Timesteps: 465,098,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.18327
Policy Entropy: 1.05361
Value Function Loss: 1.34684

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.06894

Collected Steps per Second: 8,889.37417
Overall Steps per Second: 7,709.37821

Timestep Collection Time: 5.62514
Timestep Consumption Time: 0.86098
PPO Batch Consumption Time: 0.04927
Total Iteration Time: 6.48613

Cumulative Model Updates: 27,886
Cumulative Timesteps: 465,148,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 465148646...
Checkpoint 465148646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.55383
Policy Entropy: 1.06169
Value Function Loss: 1.27128

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 8,458.45460
Overall Steps per Second: 7,377.75683

Timestep Collection Time: 5.91408
Timestep Consumption Time: 0.86630
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.78038

Cumulative Model Updates: 27,889
Cumulative Timesteps: 465,198,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.76219
Policy Entropy: 1.05040
Value Function Loss: 1.27837

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.17706
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.07000

Collected Steps per Second: 8,981.83993
Overall Steps per Second: 7,691.92021

Timestep Collection Time: 5.56946
Timestep Consumption Time: 0.93399
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.50345

Cumulative Model Updates: 27,892
Cumulative Timesteps: 465,248,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 465248694...
Checkpoint 465248694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.66606
Policy Entropy: 1.06342
Value Function Loss: 1.35479

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.17113
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.06693

Collected Steps per Second: 8,839.75901
Overall Steps per Second: 7,745.37880

Timestep Collection Time: 5.65762
Timestep Consumption Time: 0.79939
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.45701

Cumulative Model Updates: 27,895
Cumulative Timesteps: 465,298,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.97824
Policy Entropy: 1.05906
Value Function Loss: 1.39692

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.06646

Collected Steps per Second: 8,574.23655
Overall Steps per Second: 7,569.39972

Timestep Collection Time: 5.83236
Timestep Consumption Time: 0.77424
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.60660

Cumulative Model Updates: 27,898
Cumulative Timesteps: 465,348,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 465348714...
Checkpoint 465348714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.75769
Policy Entropy: 1.06842
Value Function Loss: 1.44603

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 8,571.83143
Overall Steps per Second: 7,418.54473

Timestep Collection Time: 5.83539
Timestep Consumption Time: 0.90717
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.74256

Cumulative Model Updates: 27,901
Cumulative Timesteps: 465,398,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.13003
Policy Entropy: 1.07401
Value Function Loss: 1.39658

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 8,760.68245
Overall Steps per Second: 7,671.06496

Timestep Collection Time: 5.70823
Timestep Consumption Time: 0.81081
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.51904

Cumulative Model Updates: 27,904
Cumulative Timesteps: 465,448,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 465448742...
Checkpoint 465448742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.11516
Policy Entropy: 1.07214
Value Function Loss: 1.43463

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.07495
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 8,892.10099
Overall Steps per Second: 7,699.25418

Timestep Collection Time: 5.62567
Timestep Consumption Time: 0.87159
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.49725

Cumulative Model Updates: 27,907
Cumulative Timesteps: 465,498,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.79151
Policy Entropy: 1.06272
Value Function Loss: 1.38676

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.07105
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 8,955.22420
Overall Steps per Second: 7,783.94052

Timestep Collection Time: 5.58579
Timestep Consumption Time: 0.84052
PPO Batch Consumption Time: 0.04036
Total Iteration Time: 6.42631

Cumulative Model Updates: 27,910
Cumulative Timesteps: 465,548,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 465548788...
Checkpoint 465548788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.65283
Policy Entropy: 1.04169
Value Function Loss: 1.28860

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.18515
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.07221

Collected Steps per Second: 8,708.37711
Overall Steps per Second: 7,664.28049

Timestep Collection Time: 5.74435
Timestep Consumption Time: 0.78255
PPO Batch Consumption Time: 0.04512
Total Iteration Time: 6.52690

Cumulative Model Updates: 27,913
Cumulative Timesteps: 465,598,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.35038
Policy Entropy: 1.07144
Value Function Loss: 1.22636

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.18972
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 8,462.73496
Overall Steps per Second: 7,407.51810

Timestep Collection Time: 5.91015
Timestep Consumption Time: 0.84191
PPO Batch Consumption Time: 0.04963
Total Iteration Time: 6.75206

Cumulative Model Updates: 27,916
Cumulative Timesteps: 465,648,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 465648828...
Checkpoint 465648828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.15588
Policy Entropy: 1.06515
Value Function Loss: 1.16025

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.17907
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.07121

Collected Steps per Second: 8,750.01222
Overall Steps per Second: 7,653.02059

Timestep Collection Time: 5.71611
Timestep Consumption Time: 0.81935
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 6.53546

Cumulative Model Updates: 27,919
Cumulative Timesteps: 465,698,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.64892
Policy Entropy: 1.05572
Value Function Loss: 1.23469

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 8,939.92455
Overall Steps per Second: 7,753.86988

Timestep Collection Time: 5.59624
Timestep Consumption Time: 0.85602
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.45226

Cumulative Model Updates: 27,922
Cumulative Timesteps: 465,748,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465748874...
Checkpoint 465748874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.50276
Policy Entropy: 1.04161
Value Function Loss: 1.25218

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.21351
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 8,491.43929
Overall Steps per Second: 7,394.94849

Timestep Collection Time: 5.88993
Timestep Consumption Time: 0.87333
PPO Batch Consumption Time: 0.04566
Total Iteration Time: 6.76327

Cumulative Model Updates: 27,925
Cumulative Timesteps: 465,798,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.40781
Policy Entropy: 1.05424
Value Function Loss: 1.38907

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.16429
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 8,601.77466
Overall Steps per Second: 7,595.99595

Timestep Collection Time: 5.81299
Timestep Consumption Time: 0.76969
PPO Batch Consumption Time: 0.04463
Total Iteration Time: 6.58268

Cumulative Model Updates: 27,928
Cumulative Timesteps: 465,848,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 465848890...
Checkpoint 465848890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.95765
Policy Entropy: 1.06333
Value Function Loss: 1.48853

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.19720
Policy Update Magnitude: 0.04231
Value Function Update Magnitude: 0.06248

Collected Steps per Second: 8,637.06252
Overall Steps per Second: 7,479.82685

Timestep Collection Time: 5.79086
Timestep Consumption Time: 0.89593
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 6.68679

Cumulative Model Updates: 27,931
Cumulative Timesteps: 465,898,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.49481
Policy Entropy: 1.04937
Value Function Loss: 1.41027

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 8,780.31069
Overall Steps per Second: 7,533.42192

Timestep Collection Time: 5.69729
Timestep Consumption Time: 0.94298
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 6.64028

Cumulative Model Updates: 27,934
Cumulative Timesteps: 465,948,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 465948930...
Checkpoint 465948930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.23019
Policy Entropy: 1.03300
Value Function Loss: 1.41620

Mean KL Divergence: 0.03447
SB3 Clip Fraction: 0.24512
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.07840

Collected Steps per Second: 8,986.19693
Overall Steps per Second: 7,765.54700

Timestep Collection Time: 5.56565
Timestep Consumption Time: 0.87485
PPO Batch Consumption Time: 0.04417
Total Iteration Time: 6.44050

Cumulative Model Updates: 27,937
Cumulative Timesteps: 465,998,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.74589
Policy Entropy: 1.07758
Value Function Loss: 1.26569

Mean KL Divergence: 0.03894
SB3 Clip Fraction: 0.22575
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 8,876.20110
Overall Steps per Second: 7,707.30274

Timestep Collection Time: 5.63439
Timestep Consumption Time: 0.85452
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.48891

Cumulative Model Updates: 27,940
Cumulative Timesteps: 466,048,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 466048956...
Checkpoint 466048956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.63473
Policy Entropy: 1.03873
Value Function Loss: 1.37588

Mean KL Divergence: 0.05390
SB3 Clip Fraction: 0.31957
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.08008

Collected Steps per Second: 8,669.94276
Overall Steps per Second: 7,623.58784

Timestep Collection Time: 5.76913
Timestep Consumption Time: 0.79183
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 6.56095

Cumulative Model Updates: 27,943
Cumulative Timesteps: 466,098,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.10252
Policy Entropy: 1.07008
Value Function Loss: 1.31554

Mean KL Divergence: 0.03060
SB3 Clip Fraction: 0.19830
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 9,218.67337
Overall Steps per Second: 7,904.93651

Timestep Collection Time: 5.42421
Timestep Consumption Time: 0.90146
PPO Batch Consumption Time: 0.04874
Total Iteration Time: 6.32567

Cumulative Model Updates: 27,946
Cumulative Timesteps: 466,148,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 466148978...
Checkpoint 466148978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.13011
Policy Entropy: 1.04872
Value Function Loss: 1.33608

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.18804
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.06988

Collected Steps per Second: 8,888.78840
Overall Steps per Second: 7,728.41563

Timestep Collection Time: 5.62574
Timestep Consumption Time: 0.84467
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 6.47041

Cumulative Model Updates: 27,949
Cumulative Timesteps: 466,198,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.75397
Policy Entropy: 1.05491
Value Function Loss: 1.31818

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.18747
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 8,915.89732
Overall Steps per Second: 7,878.81897

Timestep Collection Time: 5.60796
Timestep Consumption Time: 0.73817
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 6.34613

Cumulative Model Updates: 27,952
Cumulative Timesteps: 466,248,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 466248984...
Checkpoint 466248984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.56777
Policy Entropy: 1.06555
Value Function Loss: 1.30746

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 8,738.27655
Overall Steps per Second: 7,476.79063

Timestep Collection Time: 5.72424
Timestep Consumption Time: 0.96580
PPO Batch Consumption Time: 0.04897
Total Iteration Time: 6.69004

Cumulative Model Updates: 27,955
Cumulative Timesteps: 466,299,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.17864
Policy Entropy: 1.08036
Value Function Loss: 1.26437

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.07116
Value Function Update Magnitude: 0.08155

Collected Steps per Second: 8,606.20491
Overall Steps per Second: 7,556.72786

Timestep Collection Time: 5.81069
Timestep Consumption Time: 0.80699
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.61768

Cumulative Model Updates: 27,958
Cumulative Timesteps: 466,349,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 466349012...
Checkpoint 466349012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.48757
Policy Entropy: 1.08022
Value Function Loss: 1.22464

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.07818

Collected Steps per Second: 8,850.78957
Overall Steps per Second: 7,691.11229

Timestep Collection Time: 5.65215
Timestep Consumption Time: 0.85224
PPO Batch Consumption Time: 0.04502
Total Iteration Time: 6.50439

Cumulative Model Updates: 27,961
Cumulative Timesteps: 466,399,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.22518
Policy Entropy: 1.07705
Value Function Loss: 1.30162

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.07742

Collected Steps per Second: 8,789.14365
Overall Steps per Second: 7,596.62395

Timestep Collection Time: 5.69111
Timestep Consumption Time: 0.89339
PPO Batch Consumption Time: 0.04724
Total Iteration Time: 6.58450

Cumulative Model Updates: 27,964
Cumulative Timesteps: 466,449,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 466449058...
Checkpoint 466449058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.37597
Policy Entropy: 1.08006
Value Function Loss: 1.42919

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.07775

Collected Steps per Second: 8,977.27998
Overall Steps per Second: 7,900.88081

Timestep Collection Time: 5.57184
Timestep Consumption Time: 0.75910
PPO Batch Consumption Time: 0.04995
Total Iteration Time: 6.33094

Cumulative Model Updates: 27,967
Cumulative Timesteps: 466,499,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.51968
Policy Entropy: 1.06648
Value Function Loss: 1.49387

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.18576
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 8,421.44802
Overall Steps per Second: 7,371.63458

Timestep Collection Time: 5.94007
Timestep Consumption Time: 0.84594
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.78601

Cumulative Model Updates: 27,970
Cumulative Timesteps: 466,549,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 466549102...
Checkpoint 466549102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.86773
Policy Entropy: 1.08883
Value Function Loss: 1.52642

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 8,402.61887
Overall Steps per Second: 7,377.03412

Timestep Collection Time: 5.95219
Timestep Consumption Time: 0.82750
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.77969

Cumulative Model Updates: 27,973
Cumulative Timesteps: 466,599,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.62563
Policy Entropy: 1.08586
Value Function Loss: 1.46449

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 8,702.70661
Overall Steps per Second: 7,568.91481

Timestep Collection Time: 5.74649
Timestep Consumption Time: 0.86080
PPO Batch Consumption Time: 0.04970
Total Iteration Time: 6.60729

Cumulative Model Updates: 27,976
Cumulative Timesteps: 466,649,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466649126...
Checkpoint 466649126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.13891
Policy Entropy: 1.08817
Value Function Loss: 1.48952

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 8,798.24483
Overall Steps per Second: 7,645.09108

Timestep Collection Time: 5.68477
Timestep Consumption Time: 0.85747
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.54224

Cumulative Model Updates: 27,979
Cumulative Timesteps: 466,699,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.08879
Policy Entropy: 1.06715
Value Function Loss: 1.43386

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.07731

Collected Steps per Second: 8,688.65395
Overall Steps per Second: 7,605.76868

Timestep Collection Time: 5.75624
Timestep Consumption Time: 0.81956
PPO Batch Consumption Time: 0.04847
Total Iteration Time: 6.57580

Cumulative Model Updates: 27,982
Cumulative Timesteps: 466,749,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 466749156...
Checkpoint 466749156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.43484
Policy Entropy: 1.06720
Value Function Loss: 1.45753

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.06911

Collected Steps per Second: 8,753.95327
Overall Steps per Second: 7,600.27478

Timestep Collection Time: 5.71353
Timestep Consumption Time: 0.86728
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 6.58081

Cumulative Model Updates: 27,985
Cumulative Timesteps: 466,799,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.11365
Policy Entropy: 1.06853
Value Function Loss: 1.39805

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 8,622.67120
Overall Steps per Second: 7,510.20084

Timestep Collection Time: 5.80006
Timestep Consumption Time: 0.85915
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 6.65921

Cumulative Model Updates: 27,988
Cumulative Timesteps: 466,849,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 466849184...
Checkpoint 466849184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.89325
Policy Entropy: 1.07444
Value Function Loss: 1.34781

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.07808

Collected Steps per Second: 8,658.20259
Overall Steps per Second: 7,658.14147

Timestep Collection Time: 5.77695
Timestep Consumption Time: 0.75440
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.53135

Cumulative Model Updates: 27,991
Cumulative Timesteps: 466,899,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.37776
Policy Entropy: 1.08463
Value Function Loss: 1.41988

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 8,859.09111
Overall Steps per Second: 7,594.23674

Timestep Collection Time: 5.64618
Timestep Consumption Time: 0.94040
PPO Batch Consumption Time: 0.04638
Total Iteration Time: 6.58657

Cumulative Model Updates: 27,994
Cumulative Timesteps: 466,949,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 466949222...
Checkpoint 466949222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.73958
Policy Entropy: 1.09715
Value Function Loss: 1.43422

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.19817
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 8,560.12336
Overall Steps per Second: 7,514.06792

Timestep Collection Time: 5.84431
Timestep Consumption Time: 0.81360
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.65791

Cumulative Model Updates: 27,997
Cumulative Timesteps: 466,999,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.25764
Policy Entropy: 1.05980
Value Function Loss: 1.55343

Mean KL Divergence: 0.03927
SB3 Clip Fraction: 0.22547
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 9,127.47117
Overall Steps per Second: 7,885.83215

Timestep Collection Time: 5.47972
Timestep Consumption Time: 0.86279
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 6.34251

Cumulative Model Updates: 28,000
Cumulative Timesteps: 467,049,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 467049266...
Checkpoint 467049266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.60600
Policy Entropy: 1.08677
Value Function Loss: 1.60704

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 9,052.22348
Overall Steps per Second: 7,735.90875

Timestep Collection Time: 5.52505
Timestep Consumption Time: 0.94012
PPO Batch Consumption Time: 0.05104
Total Iteration Time: 6.46517

Cumulative Model Updates: 28,003
Cumulative Timesteps: 467,099,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.97538
Policy Entropy: 1.08708
Value Function Loss: 1.58357

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 8,874.07897
Overall Steps per Second: 7,770.37731

Timestep Collection Time: 5.63754
Timestep Consumption Time: 0.80075
PPO Batch Consumption Time: 0.04574
Total Iteration Time: 6.43830

Cumulative Model Updates: 28,006
Cumulative Timesteps: 467,149,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 467149308...
Checkpoint 467149308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.72942
Policy Entropy: 1.07601
Value Function Loss: 1.56949

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.07272

Collected Steps per Second: 8,734.03934
Overall Steps per Second: 7,577.61213

Timestep Collection Time: 5.72793
Timestep Consumption Time: 0.87415
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.60208

Cumulative Model Updates: 28,009
Cumulative Timesteps: 467,199,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.90601
Policy Entropy: 1.06640
Value Function Loss: 1.48542

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.18117
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 8,462.65558
Overall Steps per Second: 7,397.18377

Timestep Collection Time: 5.91067
Timestep Consumption Time: 0.85136
PPO Batch Consumption Time: 0.04695
Total Iteration Time: 6.76203

Cumulative Model Updates: 28,012
Cumulative Timesteps: 467,249,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467249356...
Checkpoint 467249356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.94869
Policy Entropy: 1.07944
Value Function Loss: 1.52322

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.09705

Collected Steps per Second: 8,797.90335
Overall Steps per Second: 7,630.84527

Timestep Collection Time: 5.68545
Timestep Consumption Time: 0.86953
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.55497

Cumulative Model Updates: 28,015
Cumulative Timesteps: 467,299,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.44413
Policy Entropy: 1.09718
Value Function Loss: 1.53991

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15854
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 8,696.20227
Overall Steps per Second: 7,512.29808

Timestep Collection Time: 5.75240
Timestep Consumption Time: 0.90655
PPO Batch Consumption Time: 0.04823
Total Iteration Time: 6.65895

Cumulative Model Updates: 28,018
Cumulative Timesteps: 467,349,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 467349400...
Checkpoint 467349400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.78146
Policy Entropy: 1.07745
Value Function Loss: 1.54246

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.11162

Collected Steps per Second: 8,740.23511
Overall Steps per Second: 7,705.67021

Timestep Collection Time: 5.72227
Timestep Consumption Time: 0.76827
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.49055

Cumulative Model Updates: 28,021
Cumulative Timesteps: 467,399,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.24323
Policy Entropy: 1.07153
Value Function Loss: 1.54873

Mean KL Divergence: 0.03179
SB3 Clip Fraction: 0.21702
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11562

Collected Steps per Second: 8,283.84962
Overall Steps per Second: 7,229.84289

Timestep Collection Time: 6.03584
Timestep Consumption Time: 0.87994
PPO Batch Consumption Time: 0.04150
Total Iteration Time: 6.91578

Cumulative Model Updates: 28,024
Cumulative Timesteps: 467,449,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 467449414...
Checkpoint 467449414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.24571
Policy Entropy: 1.10501
Value Function Loss: 1.48859

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.17954
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 8,851.81655
Overall Steps per Second: 7,708.79553

Timestep Collection Time: 5.65127
Timestep Consumption Time: 0.83794
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 6.48921

Cumulative Model Updates: 28,027
Cumulative Timesteps: 467,499,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.86597
Policy Entropy: 1.09237
Value Function Loss: 1.51292

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.10291

Collected Steps per Second: 8,803.99832
Overall Steps per Second: 7,586.08905

Timestep Collection Time: 5.67992
Timestep Consumption Time: 0.91188
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.59180

Cumulative Model Updates: 28,030
Cumulative Timesteps: 467,549,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 467549444...
Checkpoint 467549444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.27508
Policy Entropy: 1.10621
Value Function Loss: 1.51948

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.10232

Collected Steps per Second: 8,757.93508
Overall Steps per Second: 7,601.51096

Timestep Collection Time: 5.71048
Timestep Consumption Time: 0.86874
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.57922

Cumulative Model Updates: 28,033
Cumulative Timesteps: 467,599,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.39534
Policy Entropy: 1.10240
Value Function Loss: 1.48181

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.09345

Collected Steps per Second: 8,724.82634
Overall Steps per Second: 7,685.20314

Timestep Collection Time: 5.73307
Timestep Consumption Time: 0.77555
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 6.50861

Cumulative Model Updates: 28,036
Cumulative Timesteps: 467,649,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467649476...
Checkpoint 467649476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.91664
Policy Entropy: 1.10131
Value Function Loss: 1.44818

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.09942

Collected Steps per Second: 8,619.47877
Overall Steps per Second: 7,475.69182

Timestep Collection Time: 5.80081
Timestep Consumption Time: 0.88753
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.68834

Cumulative Model Updates: 28,039
Cumulative Timesteps: 467,699,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.95574
Policy Entropy: 1.07606
Value Function Loss: 1.38838

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.17608
Policy Update Magnitude: 0.06503
Value Function Update Magnitude: 0.10489

Collected Steps per Second: 8,738.18971
Overall Steps per Second: 7,595.96813

Timestep Collection Time: 5.72292
Timestep Consumption Time: 0.86057
PPO Batch Consumption Time: 0.04310
Total Iteration Time: 6.58349

Cumulative Model Updates: 28,042
Cumulative Timesteps: 467,749,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 467749484...
Checkpoint 467749484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.28552
Policy Entropy: 1.08207
Value Function Loss: 1.44958

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.17618
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.10525

Collected Steps per Second: 8,860.18192
Overall Steps per Second: 7,761.50079

Timestep Collection Time: 5.64413
Timestep Consumption Time: 0.79896
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.44308

Cumulative Model Updates: 28,045
Cumulative Timesteps: 467,799,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.23944
Policy Entropy: 1.09408
Value Function Loss: 1.40318

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.17686
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.10821

Collected Steps per Second: 9,120.88558
Overall Steps per Second: 7,868.60592

Timestep Collection Time: 5.48412
Timestep Consumption Time: 0.87279
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.35691

Cumulative Model Updates: 28,048
Cumulative Timesteps: 467,849,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467849512...
Checkpoint 467849512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.38543
Policy Entropy: 1.07032
Value Function Loss: 1.40609

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.17317
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 8,795.56957
Overall Steps per Second: 7,723.20364

Timestep Collection Time: 5.68786
Timestep Consumption Time: 0.78976
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.47762

Cumulative Model Updates: 28,051
Cumulative Timesteps: 467,899,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.74003
Policy Entropy: 1.06272
Value Function Loss: 1.40236

Mean KL Divergence: 0.02825
SB3 Clip Fraction: 0.20513
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.08055

Collected Steps per Second: 9,109.21485
Overall Steps per Second: 7,850.61303

Timestep Collection Time: 5.49246
Timestep Consumption Time: 0.88055
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.37301

Cumulative Model Updates: 28,054
Cumulative Timesteps: 467,949,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 467949572...
Checkpoint 467949572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.66349
Policy Entropy: 1.06548
Value Function Loss: 1.45935

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 9,150.12372
Overall Steps per Second: 7,934.66819

Timestep Collection Time: 5.46616
Timestep Consumption Time: 0.83732
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.30348

Cumulative Model Updates: 28,057
Cumulative Timesteps: 467,999,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.34097
Policy Entropy: 1.06887
Value Function Loss: 1.41988

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.10664

Collected Steps per Second: 9,144.72048
Overall Steps per Second: 7,846.82858

Timestep Collection Time: 5.46829
Timestep Consumption Time: 0.90447
PPO Batch Consumption Time: 0.05186
Total Iteration Time: 6.37277

Cumulative Model Updates: 28,060
Cumulative Timesteps: 468,049,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 468049594...
Checkpoint 468049594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.37660
Policy Entropy: 1.06231
Value Function Loss: 1.38852

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 8,639.23228
Overall Steps per Second: 7,483.39748

Timestep Collection Time: 5.78755
Timestep Consumption Time: 0.89391
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 6.68146

Cumulative Model Updates: 28,063
Cumulative Timesteps: 468,099,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.61263
Policy Entropy: 1.03568
Value Function Loss: 1.31881

Mean KL Divergence: 0.04529
SB3 Clip Fraction: 0.27025
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.10068

Collected Steps per Second: 8,394.66636
Overall Steps per Second: 7,439.30719

Timestep Collection Time: 5.95688
Timestep Consumption Time: 0.76498
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.72186

Cumulative Model Updates: 28,066
Cumulative Timesteps: 468,149,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 468149600...
Checkpoint 468149600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.96353
Policy Entropy: 1.04988
Value Function Loss: 1.38700

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.16707
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.08818

Collected Steps per Second: 8,715.03985
Overall Steps per Second: 7,545.95657

Timestep Collection Time: 5.73950
Timestep Consumption Time: 0.88921
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 6.62872

Cumulative Model Updates: 28,069
Cumulative Timesteps: 468,199,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.81973
Policy Entropy: 1.01900
Value Function Loss: 1.33602

Mean KL Divergence: 0.03137
SB3 Clip Fraction: 0.23969
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.09029

Collected Steps per Second: 8,639.39912
Overall Steps per Second: 7,543.17513

Timestep Collection Time: 5.79068
Timestep Consumption Time: 0.84154
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.63222

Cumulative Model Updates: 28,072
Cumulative Timesteps: 468,249,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 468249648...
Checkpoint 468249648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.53052
Policy Entropy: 1.01122
Value Function Loss: 1.23687

Mean KL Divergence: 0.03244
SB3 Clip Fraction: 0.21862
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.10844

Collected Steps per Second: 8,819.88870
Overall Steps per Second: 7,698.91362

Timestep Collection Time: 5.67173
Timestep Consumption Time: 0.82581
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 6.49754

Cumulative Model Updates: 28,075
Cumulative Timesteps: 468,299,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.14682
Policy Entropy: 1.02806
Value Function Loss: 1.24755

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.17809
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.10619

Collected Steps per Second: 8,838.15780
Overall Steps per Second: 7,488.10741

Timestep Collection Time: 5.65842
Timestep Consumption Time: 1.02017
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.67859

Cumulative Model Updates: 28,078
Cumulative Timesteps: 468,349,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 468349682...
Checkpoint 468349682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.61492
Policy Entropy: 1.03647
Value Function Loss: 1.28836

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.20486
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.10043

Collected Steps per Second: 8,546.37678
Overall Steps per Second: 7,579.67176

Timestep Collection Time: 5.85254
Timestep Consumption Time: 0.74643
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 6.59897

Cumulative Model Updates: 28,081
Cumulative Timesteps: 468,399,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.72512
Policy Entropy: 1.01273
Value Function Loss: 1.29071

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.17984
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.09672

Collected Steps per Second: 8,590.65911
Overall Steps per Second: 7,499.51987

Timestep Collection Time: 5.82284
Timestep Consumption Time: 0.84719
PPO Batch Consumption Time: 0.04490
Total Iteration Time: 6.67003

Cumulative Model Updates: 28,084
Cumulative Timesteps: 468,449,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 468449722...
Checkpoint 468449722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.95412
Policy Entropy: 1.02465
Value Function Loss: 1.17587

Mean KL Divergence: 0.03072
SB3 Clip Fraction: 0.22927
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.09364

Collected Steps per Second: 8,670.89720
Overall Steps per Second: 7,606.06751

Timestep Collection Time: 5.76780
Timestep Consumption Time: 0.80748
PPO Batch Consumption Time: 0.04052
Total Iteration Time: 6.57528

Cumulative Model Updates: 28,087
Cumulative Timesteps: 468,499,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.74818
Policy Entropy: 1.02065
Value Function Loss: 1.10355

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.22923
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 8,755.17811
Overall Steps per Second: 7,652.94719

Timestep Collection Time: 5.71159
Timestep Consumption Time: 0.82262
PPO Batch Consumption Time: 0.04505
Total Iteration Time: 6.53421

Cumulative Model Updates: 28,090
Cumulative Timesteps: 468,549,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 468549740...
Checkpoint 468549740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.63004
Policy Entropy: 1.01485
Value Function Loss: 1.15013

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.19329
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 8,467.54992
Overall Steps per Second: 7,398.27031

Timestep Collection Time: 5.90513
Timestep Consumption Time: 0.85347
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.75861

Cumulative Model Updates: 28,093
Cumulative Timesteps: 468,599,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.69499
Policy Entropy: 0.98997
Value Function Loss: 1.19566

Mean KL Divergence: 0.03858
SB3 Clip Fraction: 0.27163
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 8,828.03168
Overall Steps per Second: 7,833.83084

Timestep Collection Time: 5.66695
Timestep Consumption Time: 0.71920
PPO Batch Consumption Time: 0.04171
Total Iteration Time: 6.38615

Cumulative Model Updates: 28,096
Cumulative Timesteps: 468,649,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 468649770...
Checkpoint 468649770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.71911
Policy Entropy: 1.03107
Value Function Loss: 1.38302

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.20049
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 8,925.16406
Overall Steps per Second: 7,753.37364

Timestep Collection Time: 5.60393
Timestep Consumption Time: 0.84694
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.45087

Cumulative Model Updates: 28,099
Cumulative Timesteps: 468,699,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.52004
Policy Entropy: 1.00096
Value Function Loss: 1.40198

Mean KL Divergence: 0.03165
SB3 Clip Fraction: 0.22361
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 8,341.73204
Overall Steps per Second: 7,291.47376

Timestep Collection Time: 5.99636
Timestep Consumption Time: 0.86371
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.86007

Cumulative Model Updates: 28,102
Cumulative Timesteps: 468,749,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 468749806...
Checkpoint 468749806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.40608
Policy Entropy: 1.02988
Value Function Loss: 1.41639

Mean KL Divergence: 0.03146
SB3 Clip Fraction: 0.22460
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.07099

Collected Steps per Second: 9,113.70138
Overall Steps per Second: 7,696.24364

Timestep Collection Time: 5.48910
Timestep Consumption Time: 1.01096
PPO Batch Consumption Time: 0.04644
Total Iteration Time: 6.50005

Cumulative Model Updates: 28,105
Cumulative Timesteps: 468,799,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.84714
Policy Entropy: 1.01057
Value Function Loss: 1.24546

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.21099
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.07455

Collected Steps per Second: 8,740.11698
Overall Steps per Second: 7,598.77669

Timestep Collection Time: 5.72281
Timestep Consumption Time: 0.85957
PPO Batch Consumption Time: 0.04588
Total Iteration Time: 6.58238

Cumulative Model Updates: 28,108
Cumulative Timesteps: 468,849,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 468849850...
Checkpoint 468849850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.30827
Policy Entropy: 0.98402
Value Function Loss: 1.26262

Mean KL Divergence: 0.03930
SB3 Clip Fraction: 0.24521
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 8,912.65327
Overall Steps per Second: 7,818.92116

Timestep Collection Time: 5.61225
Timestep Consumption Time: 0.78506
PPO Batch Consumption Time: 0.04504
Total Iteration Time: 6.39730

Cumulative Model Updates: 28,111
Cumulative Timesteps: 468,899,870

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.94442
Policy Entropy: 0.99621
Value Function Loss: 1.31330

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.23621
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.07487

Collected Steps per Second: 8,950.89604
Overall Steps per Second: 7,777.63496

Timestep Collection Time: 5.58804
Timestep Consumption Time: 0.84296
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.43100

Cumulative Model Updates: 28,114
Cumulative Timesteps: 468,949,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 468949888...
Checkpoint 468949888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.57047
Policy Entropy: 1.00067
Value Function Loss: 1.31501

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.20730
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.08220

Collected Steps per Second: 8,834.13239
Overall Steps per Second: 7,813.37074

Timestep Collection Time: 5.66281
Timestep Consumption Time: 0.73981
PPO Batch Consumption Time: 0.04048
Total Iteration Time: 6.40261

Cumulative Model Updates: 28,117
Cumulative Timesteps: 468,999,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.70825
Policy Entropy: 1.03329
Value Function Loss: 1.32585

Mean KL Divergence: 0.03386
SB3 Clip Fraction: 0.25393
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 8,564.87469
Overall Steps per Second: 7,448.69228

Timestep Collection Time: 5.83920
Timestep Consumption Time: 0.87500
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.71420

Cumulative Model Updates: 28,120
Cumulative Timesteps: 469,049,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 469049926...
Checkpoint 469049926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.62629
Policy Entropy: 0.98897
Value Function Loss: 1.26649

Mean KL Divergence: 0.06085
SB3 Clip Fraction: 0.31391
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.07244

Collected Steps per Second: 8,708.28549
Overall Steps per Second: 7,564.12926

Timestep Collection Time: 5.74327
Timestep Consumption Time: 0.86873
PPO Batch Consumption Time: 0.04415
Total Iteration Time: 6.61200

Cumulative Model Updates: 28,123
Cumulative Timesteps: 469,099,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.70564
Policy Entropy: 1.02499
Value Function Loss: 1.28597

Mean KL Divergence: 0.04607
SB3 Clip Fraction: 0.28741
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.06260

Collected Steps per Second: 9,096.20822
Overall Steps per Second: 7,818.67148

Timestep Collection Time: 5.49834
Timestep Consumption Time: 0.89840
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 6.39674

Cumulative Model Updates: 28,126
Cumulative Timesteps: 469,149,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 469149954...
Checkpoint 469149954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.41975
Policy Entropy: 0.97659
Value Function Loss: 1.27621

Mean KL Divergence: 0.06706
SB3 Clip Fraction: 0.32499
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 8,693.14522
Overall Steps per Second: 7,550.35745

Timestep Collection Time: 5.75235
Timestep Consumption Time: 0.87065
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.62300

Cumulative Model Updates: 28,129
Cumulative Timesteps: 469,199,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.16174
Policy Entropy: 1.00512
Value Function Loss: 1.28122

Mean KL Divergence: 0.04851
SB3 Clip Fraction: 0.30107
Policy Update Magnitude: 0.03616
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 8,595.37876
Overall Steps per Second: 7,616.96841

Timestep Collection Time: 5.82010
Timestep Consumption Time: 0.74760
PPO Batch Consumption Time: 0.05070
Total Iteration Time: 6.56770

Cumulative Model Updates: 28,132
Cumulative Timesteps: 469,249,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 469249986...
Checkpoint 469249986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.18382
Policy Entropy: 0.99045
Value Function Loss: 1.28408

Mean KL Divergence: 0.04514
SB3 Clip Fraction: 0.26925
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.06603

Collected Steps per Second: 8,503.83362
Overall Steps per Second: 7,396.94646

Timestep Collection Time: 5.87994
Timestep Consumption Time: 0.87988
PPO Batch Consumption Time: 0.04954
Total Iteration Time: 6.75982

Cumulative Model Updates: 28,135
Cumulative Timesteps: 469,299,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.43791
Policy Entropy: 1.02315
Value Function Loss: 1.25574

Mean KL Divergence: 0.05565
SB3 Clip Fraction: 0.28820
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.06806

Collected Steps per Second: 8,786.47750
Overall Steps per Second: 7,690.02561

Timestep Collection Time: 5.69284
Timestep Consumption Time: 0.81169
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.50453

Cumulative Model Updates: 28,138
Cumulative Timesteps: 469,350,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 469350008...
Checkpoint 469350008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.92845
Policy Entropy: 0.99468
Value Function Loss: 1.22777

Mean KL Divergence: 0.03243
SB3 Clip Fraction: 0.22602
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 8,663.26128
Overall Steps per Second: 7,494.98268

Timestep Collection Time: 5.77358
Timestep Consumption Time: 0.89995
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 6.67353

Cumulative Model Updates: 28,141
Cumulative Timesteps: 469,400,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.46759
Policy Entropy: 1.01928
Value Function Loss: 1.28782

Mean KL Divergence: 0.03185
SB3 Clip Fraction: 0.22549
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 8,706.69711
Overall Steps per Second: 7,547.10878

Timestep Collection Time: 5.74546
Timestep Consumption Time: 0.88277
PPO Batch Consumption Time: 0.04264
Total Iteration Time: 6.62823

Cumulative Model Updates: 28,144
Cumulative Timesteps: 469,450,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 469450050...
Checkpoint 469450050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.29903
Policy Entropy: 1.01704
Value Function Loss: 1.27976

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.20140
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 8,688.06289
Overall Steps per Second: 7,503.29929

Timestep Collection Time: 5.75525
Timestep Consumption Time: 0.90875
PPO Batch Consumption Time: 0.05013
Total Iteration Time: 6.66400

Cumulative Model Updates: 28,147
Cumulative Timesteps: 469,500,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.79287
Policy Entropy: 1.00275
Value Function Loss: 1.30642

Mean KL Divergence: 0.03072
SB3 Clip Fraction: 0.21647
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.09323

Collected Steps per Second: 8,703.47880
Overall Steps per Second: 7,543.83861

Timestep Collection Time: 5.74805
Timestep Consumption Time: 0.88359
PPO Batch Consumption Time: 0.04282
Total Iteration Time: 6.63164

Cumulative Model Updates: 28,150
Cumulative Timesteps: 469,550,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 469550080...
Checkpoint 469550080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.63178
Policy Entropy: 0.99533
Value Function Loss: 1.31286

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.21767
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 8,654.34955
Overall Steps per Second: 7,652.96151

Timestep Collection Time: 5.77767
Timestep Consumption Time: 0.75601
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.53368

Cumulative Model Updates: 28,153
Cumulative Timesteps: 469,600,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.29724
Policy Entropy: 1.00870
Value Function Loss: 1.34325

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.17975
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 9,083.89416
Overall Steps per Second: 7,852.65879

Timestep Collection Time: 5.50579
Timestep Consumption Time: 0.86326
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.36905

Cumulative Model Updates: 28,156
Cumulative Timesteps: 469,650,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 469650096...
Checkpoint 469650096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.24061
Policy Entropy: 1.02534
Value Function Loss: 1.30012

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.17899
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.08437

Collected Steps per Second: 9,180.22873
Overall Steps per Second: 7,956.09655

Timestep Collection Time: 5.44910
Timestep Consumption Time: 0.83840
PPO Batch Consumption Time: 0.04655
Total Iteration Time: 6.28751

Cumulative Model Updates: 28,159
Cumulative Timesteps: 469,700,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.09453
Policy Entropy: 1.01405
Value Function Loss: 1.22593

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15087
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.07621

Collected Steps per Second: 8,495.87098
Overall Steps per Second: 7,473.06676

Timestep Collection Time: 5.88851
Timestep Consumption Time: 0.80593
PPO Batch Consumption Time: 0.04912
Total Iteration Time: 6.69444

Cumulative Model Updates: 28,162
Cumulative Timesteps: 469,750,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 469750148...
Checkpoint 469750148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.08230
Policy Entropy: 0.99870
Value Function Loss: 1.17376

Mean KL Divergence: 0.02936
SB3 Clip Fraction: 0.23109
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.08660

Collected Steps per Second: 9,428.90082
Overall Steps per Second: 8,070.64400

Timestep Collection Time: 5.30518
Timestep Consumption Time: 0.89284
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.19802

Cumulative Model Updates: 28,165
Cumulative Timesteps: 469,800,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.84481
Policy Entropy: 1.02354
Value Function Loss: 1.27157

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08025

Collected Steps per Second: 8,976.60863
Overall Steps per Second: 7,722.45342

Timestep Collection Time: 5.57003
Timestep Consumption Time: 0.90459
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.47463

Cumulative Model Updates: 28,168
Cumulative Timesteps: 469,850,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 469850170...
Checkpoint 469850170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.03216
Policy Entropy: 1.02551
Value Function Loss: 1.35320

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 8,827.37065
Overall Steps per Second: 7,647.53275

Timestep Collection Time: 5.66783
Timestep Consumption Time: 0.87441
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.54224

Cumulative Model Updates: 28,171
Cumulative Timesteps: 469,900,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.55604
Policy Entropy: 1.00560
Value Function Loss: 1.46730

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.06824

Collected Steps per Second: 8,715.63897
Overall Steps per Second: 7,458.43242

Timestep Collection Time: 5.74049
Timestep Consumption Time: 0.96763
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 6.70811

Cumulative Model Updates: 28,174
Cumulative Timesteps: 469,950,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 469950234...
Checkpoint 469950234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.79039
Policy Entropy: 1.00456
Value Function Loss: 1.50986

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.19461
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 8,792.50913
Overall Steps per Second: 7,634.57810

Timestep Collection Time: 5.68848
Timestep Consumption Time: 0.86277
PPO Batch Consumption Time: 0.04757
Total Iteration Time: 6.55125

Cumulative Model Updates: 28,177
Cumulative Timesteps: 470,000,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.49644
Policy Entropy: 1.01972
Value Function Loss: 1.54196

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.19301
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 8,843.47887
Overall Steps per Second: 7,699.32180

Timestep Collection Time: 5.65682
Timestep Consumption Time: 0.84063
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 6.49746

Cumulative Model Updates: 28,180
Cumulative Timesteps: 470,050,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 470050276...
Checkpoint 470050276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.07429
Policy Entropy: 1.02576
Value Function Loss: 1.51236

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.19509
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.07502

Collected Steps per Second: 8,923.67138
Overall Steps per Second: 7,857.76095

Timestep Collection Time: 5.60307
Timestep Consumption Time: 0.76006
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.36314

Cumulative Model Updates: 28,183
Cumulative Timesteps: 470,100,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.47078
Policy Entropy: 1.02372
Value Function Loss: 1.41581

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 8,829.10290
Overall Steps per Second: 7,690.48870

Timestep Collection Time: 5.66490
Timestep Consumption Time: 0.83872
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.50362

Cumulative Model Updates: 28,186
Cumulative Timesteps: 470,150,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 470150292...
Checkpoint 470150292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.72684
Policy Entropy: 1.00426
Value Function Loss: 1.39863

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.25248
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.06863

Collected Steps per Second: 8,385.59398
Overall Steps per Second: 7,252.99751

Timestep Collection Time: 5.96595
Timestep Consumption Time: 0.93162
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 6.89756

Cumulative Model Updates: 28,189
Cumulative Timesteps: 470,200,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.31451
Policy Entropy: 1.04171
Value Function Loss: 1.42519

Mean KL Divergence: 0.03728
SB3 Clip Fraction: 0.26103
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 8,580.25023
Overall Steps per Second: 7,386.61853

Timestep Collection Time: 5.83013
Timestep Consumption Time: 0.94211
PPO Batch Consumption Time: 0.04876
Total Iteration Time: 6.77225

Cumulative Model Updates: 28,192
Cumulative Timesteps: 470,250,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 470250344...
Checkpoint 470250344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.91313
Policy Entropy: 1.02346
Value Function Loss: 1.39490

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.19651
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 8,752.45438
Overall Steps per Second: 7,564.77419

Timestep Collection Time: 5.71565
Timestep Consumption Time: 0.89737
PPO Batch Consumption Time: 0.04214
Total Iteration Time: 6.61302

Cumulative Model Updates: 28,195
Cumulative Timesteps: 470,300,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.73492
Policy Entropy: 1.04153
Value Function Loss: 1.40321

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.16908
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 8,904.31144
Overall Steps per Second: 7,707.97596

Timestep Collection Time: 5.61705
Timestep Consumption Time: 0.87181
PPO Batch Consumption Time: 0.04816
Total Iteration Time: 6.48886

Cumulative Model Updates: 28,198
Cumulative Timesteps: 470,350,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 470350386...
Checkpoint 470350386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.16540
Policy Entropy: 1.04540
Value Function Loss: 1.38024

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.18173
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.09167

Collected Steps per Second: 8,808.06669
Overall Steps per Second: 7,501.24911

Timestep Collection Time: 5.67730
Timestep Consumption Time: 0.98906
PPO Batch Consumption Time: 0.04692
Total Iteration Time: 6.66636

Cumulative Model Updates: 28,201
Cumulative Timesteps: 470,400,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.99874
Policy Entropy: 1.05159
Value Function Loss: 1.53176

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.17835
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 8,693.34220
Overall Steps per Second: 7,597.42254

Timestep Collection Time: 5.75199
Timestep Consumption Time: 0.82972
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.58171

Cumulative Model Updates: 28,204
Cumulative Timesteps: 470,450,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 470450396...
Checkpoint 470450396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.07740
Policy Entropy: 1.04115
Value Function Loss: 1.57181

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16775
Policy Update Magnitude: 0.06980
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 8,555.91087
Overall Steps per Second: 7,602.80119

Timestep Collection Time: 5.84578
Timestep Consumption Time: 0.73284
PPO Batch Consumption Time: 0.04086
Total Iteration Time: 6.57863

Cumulative Model Updates: 28,207
Cumulative Timesteps: 470,500,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.58131
Policy Entropy: 1.04518
Value Function Loss: 1.61282

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 9,020.82184
Overall Steps per Second: 7,817.04923

Timestep Collection Time: 5.54428
Timestep Consumption Time: 0.85378
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.39807

Cumulative Model Updates: 28,210
Cumulative Timesteps: 470,550,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 470550426...
Checkpoint 470550426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.79392
Policy Entropy: 1.04084
Value Function Loss: 1.59202

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.16281
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.08036

Collected Steps per Second: 8,881.53941
Overall Steps per Second: 7,723.36878

Timestep Collection Time: 5.63281
Timestep Consumption Time: 0.84468
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.47748

Cumulative Model Updates: 28,213
Cumulative Timesteps: 470,600,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.43189
Policy Entropy: 1.06669
Value Function Loss: 1.58191

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.16667
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.08003

Collected Steps per Second: 8,823.08529
Overall Steps per Second: 7,663.40619

Timestep Collection Time: 5.67013
Timestep Consumption Time: 0.85804
PPO Batch Consumption Time: 0.04299
Total Iteration Time: 6.52817

Cumulative Model Updates: 28,216
Cumulative Timesteps: 470,650,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 470650482...
Checkpoint 470650482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.97080
Policy Entropy: 1.06655
Value Function Loss: 1.58475

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.18013
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08354

Collected Steps per Second: 8,996.41340
Overall Steps per Second: 7,773.74263

Timestep Collection Time: 5.55999
Timestep Consumption Time: 0.87449
PPO Batch Consumption Time: 0.04574
Total Iteration Time: 6.43448

Cumulative Model Updates: 28,219
Cumulative Timesteps: 470,700,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.33666
Policy Entropy: 1.06245
Value Function Loss: 1.58263

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 9,185.54138
Overall Steps per Second: 8,026.08091

Timestep Collection Time: 5.44334
Timestep Consumption Time: 0.78635
PPO Batch Consumption Time: 0.04568
Total Iteration Time: 6.22969

Cumulative Model Updates: 28,222
Cumulative Timesteps: 470,750,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 470750502...
Checkpoint 470750502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.44251
Policy Entropy: 1.05252
Value Function Loss: 1.61001

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.19500
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.07901

Collected Steps per Second: 8,934.04902
Overall Steps per Second: 7,768.00350

Timestep Collection Time: 5.59813
Timestep Consumption Time: 0.84033
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.43846

Cumulative Model Updates: 28,225
Cumulative Timesteps: 470,800,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.89097
Policy Entropy: 1.06209
Value Function Loss: 1.55573

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.07845

Collected Steps per Second: 8,776.06580
Overall Steps per Second: 7,636.13046

Timestep Collection Time: 5.69754
Timestep Consumption Time: 0.85054
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.54808

Cumulative Model Updates: 28,228
Cumulative Timesteps: 470,850,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 470850518...
Checkpoint 470850518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.30556
Policy Entropy: 1.07414
Value Function Loss: 1.55819

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.19849
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.07405

Collected Steps per Second: 8,836.06366
Overall Steps per Second: 7,721.98745

Timestep Collection Time: 5.65908
Timestep Consumption Time: 0.81645
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.47553

Cumulative Model Updates: 28,231
Cumulative Timesteps: 470,900,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.43246
Policy Entropy: 1.04636
Value Function Loss: 1.49338

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.21379
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.07050

Collected Steps per Second: 8,993.78235
Overall Steps per Second: 7,761.23686

Timestep Collection Time: 5.56273
Timestep Consumption Time: 0.88341
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.44614

Cumulative Model Updates: 28,234
Cumulative Timesteps: 470,950,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 470950552...
Checkpoint 470950552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.12432
Policy Entropy: 1.07721
Value Function Loss: 1.51731

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.17029
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 8,810.00945
Overall Steps per Second: 7,777.92638

Timestep Collection Time: 5.67831
Timestep Consumption Time: 0.75348
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.43179

Cumulative Model Updates: 28,237
Cumulative Timesteps: 471,000,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.83791
Policy Entropy: 1.06474
Value Function Loss: 1.42345

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 9,062.52941
Overall Steps per Second: 7,766.19526

Timestep Collection Time: 5.51877
Timestep Consumption Time: 0.92119
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.43996

Cumulative Model Updates: 28,240
Cumulative Timesteps: 471,050,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 471050592...
Checkpoint 471050592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.10360
Policy Entropy: 1.06196
Value Function Loss: 1.34351

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 8,873.75272
Overall Steps per Second: 7,633.12361

Timestep Collection Time: 5.63730
Timestep Consumption Time: 0.91624
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.55354

Cumulative Model Updates: 28,243
Cumulative Timesteps: 471,100,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.35972
Policy Entropy: 1.05043
Value Function Loss: 1.32212

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.18281
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 8,577.72230
Overall Steps per Second: 7,633.89373

Timestep Collection Time: 5.83115
Timestep Consumption Time: 0.72094
PPO Batch Consumption Time: 0.04175
Total Iteration Time: 6.55210

Cumulative Model Updates: 28,246
Cumulative Timesteps: 471,150,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 471150634...
Checkpoint 471150634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.57453
Policy Entropy: 1.06426
Value Function Loss: 1.40526

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 8,437.34535
Overall Steps per Second: 7,324.17328

Timestep Collection Time: 5.92864
Timestep Consumption Time: 0.90107
PPO Batch Consumption Time: 0.04658
Total Iteration Time: 6.82971

Cumulative Model Updates: 28,249
Cumulative Timesteps: 471,200,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.27696
Policy Entropy: 1.06850
Value Function Loss: 1.37601

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.06967

Collected Steps per Second: 8,596.26227
Overall Steps per Second: 7,418.43537

Timestep Collection Time: 5.81788
Timestep Consumption Time: 0.92371
PPO Batch Consumption Time: 0.05131
Total Iteration Time: 6.74158

Cumulative Model Updates: 28,252
Cumulative Timesteps: 471,250,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 471250668...
Checkpoint 471250668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.85305
Policy Entropy: 1.06244
Value Function Loss: 1.35106

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.06586

Collected Steps per Second: 8,683.98665
Overall Steps per Second: 7,452.54552

Timestep Collection Time: 5.76049
Timestep Consumption Time: 0.95185
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.71234

Cumulative Model Updates: 28,255
Cumulative Timesteps: 471,300,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.16620
Policy Entropy: 1.06258
Value Function Loss: 1.37605

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.07111

Collected Steps per Second: 8,710.46951
Overall Steps per Second: 7,582.23662

Timestep Collection Time: 5.74274
Timestep Consumption Time: 0.85452
PPO Batch Consumption Time: 0.04485
Total Iteration Time: 6.59726

Cumulative Model Updates: 28,258
Cumulative Timesteps: 471,350,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 471350714...
Checkpoint 471350714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.00355
Policy Entropy: 1.06005
Value Function Loss: 1.43466

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.06867

Collected Steps per Second: 8,688.85739
Overall Steps per Second: 7,666.49012

Timestep Collection Time: 5.75749
Timestep Consumption Time: 0.76779
PPO Batch Consumption Time: 0.04065
Total Iteration Time: 6.52528

Cumulative Model Updates: 28,261
Cumulative Timesteps: 471,400,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.39400
Policy Entropy: 1.05408
Value Function Loss: 1.47384

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.18413
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 8,791.65073
Overall Steps per Second: 7,635.45888

Timestep Collection Time: 5.68721
Timestep Consumption Time: 0.86118
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.54839

Cumulative Model Updates: 28,264
Cumulative Timesteps: 471,450,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 471450740...
Checkpoint 471450740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.06601
Policy Entropy: 1.06800
Value Function Loss: 1.50021

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.06126

Collected Steps per Second: 9,223.44248
Overall Steps per Second: 7,983.87700

Timestep Collection Time: 5.42401
Timestep Consumption Time: 0.84212
PPO Batch Consumption Time: 0.04795
Total Iteration Time: 6.26613

Cumulative Model Updates: 28,267
Cumulative Timesteps: 471,500,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.31543
Policy Entropy: 1.07475
Value Function Loss: 1.60148

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 8,990.24919
Overall Steps per Second: 7,852.18392

Timestep Collection Time: 5.56403
Timestep Consumption Time: 0.80643
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.37046

Cumulative Model Updates: 28,270
Cumulative Timesteps: 471,550,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 471550790...
Checkpoint 471550790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.91288
Policy Entropy: 1.07225
Value Function Loss: 1.61536

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.06682

Collected Steps per Second: 9,018.87575
Overall Steps per Second: 7,809.04792

Timestep Collection Time: 5.54570
Timestep Consumption Time: 0.85918
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.40488

Cumulative Model Updates: 28,273
Cumulative Timesteps: 471,600,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.56508
Policy Entropy: 1.07355
Value Function Loss: 1.64836

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.07472
Value Function Update Magnitude: 0.08433

Collected Steps per Second: 9,192.56544
Overall Steps per Second: 7,936.58326

Timestep Collection Time: 5.44005
Timestep Consumption Time: 0.86090
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.30095

Cumulative Model Updates: 28,276
Cumulative Timesteps: 471,650,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471650814...
Checkpoint 471650814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.65614
Policy Entropy: 1.05742
Value Function Loss: 1.59688

Mean KL Divergence: 0.03475
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.09944

Collected Steps per Second: 9,200.23771
Overall Steps per Second: 7,894.13923

Timestep Collection Time: 5.43595
Timestep Consumption Time: 0.89939
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.33533

Cumulative Model Updates: 28,279
Cumulative Timesteps: 471,700,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.62925
Policy Entropy: 1.07928
Value Function Loss: 1.61975

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.09732

Collected Steps per Second: 8,958.19347
Overall Steps per Second: 7,818.34263

Timestep Collection Time: 5.58416
Timestep Consumption Time: 0.81413
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.39829

Cumulative Model Updates: 28,282
Cumulative Timesteps: 471,750,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 471750850...
Checkpoint 471750850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.54051
Policy Entropy: 1.08020
Value Function Loss: 1.50870

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 8,658.59628
Overall Steps per Second: 7,671.77552

Timestep Collection Time: 5.77576
Timestep Consumption Time: 0.74294
PPO Batch Consumption Time: 0.04523
Total Iteration Time: 6.51870

Cumulative Model Updates: 28,285
Cumulative Timesteps: 471,800,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.29625
Policy Entropy: 1.07290
Value Function Loss: 1.48204

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 8,822.33211
Overall Steps per Second: 7,621.27523

Timestep Collection Time: 5.66789
Timestep Consumption Time: 0.89322
PPO Batch Consumption Time: 0.05027
Total Iteration Time: 6.56111

Cumulative Model Updates: 28,288
Cumulative Timesteps: 471,850,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 471850864...
Checkpoint 471850864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.94057
Policy Entropy: 1.07441
Value Function Loss: 1.53342

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.07724

Collected Steps per Second: 8,884.30637
Overall Steps per Second: 7,684.50226

Timestep Collection Time: 5.62970
Timestep Consumption Time: 0.87898
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.50868

Cumulative Model Updates: 28,291
Cumulative Timesteps: 471,900,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.42490
Policy Entropy: 1.08882
Value Function Loss: 1.61303

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.08334

Collected Steps per Second: 8,783.33123
Overall Steps per Second: 7,624.81193

Timestep Collection Time: 5.69351
Timestep Consumption Time: 0.86508
PPO Batch Consumption Time: 0.04884
Total Iteration Time: 6.55859

Cumulative Model Updates: 28,294
Cumulative Timesteps: 471,950,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471950888...
Checkpoint 471950888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.50914
Policy Entropy: 1.09263
Value Function Loss: 1.68487

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 8,888.86251
Overall Steps per Second: 7,747.29588

Timestep Collection Time: 5.62839
Timestep Consumption Time: 0.82935
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.45774

Cumulative Model Updates: 28,297
Cumulative Timesteps: 472,000,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.30359
Policy Entropy: 1.08570
Value Function Loss: 1.56139

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.07675
Value Function Update Magnitude: 0.09860

Collected Steps per Second: 8,675.94961
Overall Steps per Second: 7,672.82083

Timestep Collection Time: 5.76605
Timestep Consumption Time: 0.75384
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 6.51990

Cumulative Model Updates: 28,300
Cumulative Timesteps: 472,050,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 472050944...
Checkpoint 472050944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.40320
Policy Entropy: 1.08136
Value Function Loss: 1.51294

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.17341
Policy Update Magnitude: 0.06928
Value Function Update Magnitude: 0.08851

Collected Steps per Second: 8,910.38359
Overall Steps per Second: 7,740.28548

Timestep Collection Time: 5.61457
Timestep Consumption Time: 0.84875
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.46333

Cumulative Model Updates: 28,303
Cumulative Timesteps: 472,100,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.19978
Policy Entropy: 1.09136
Value Function Loss: 1.52506

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.08739

Collected Steps per Second: 8,576.22271
Overall Steps per Second: 7,492.50356

Timestep Collection Time: 5.83194
Timestep Consumption Time: 0.84353
PPO Batch Consumption Time: 0.05113
Total Iteration Time: 6.67547

Cumulative Model Updates: 28,306
Cumulative Timesteps: 472,150,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 472150988...
Checkpoint 472150988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.61804
Policy Entropy: 1.09935
Value Function Loss: 1.56788

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 8,865.92503
Overall Steps per Second: 7,714.04897

Timestep Collection Time: 5.64160
Timestep Consumption Time: 0.84241
PPO Batch Consumption Time: 0.04064
Total Iteration Time: 6.48401

Cumulative Model Updates: 28,309
Cumulative Timesteps: 472,201,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.10777
Policy Entropy: 1.08741
Value Function Loss: 1.47975

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 8,377.45793
Overall Steps per Second: 7,341.63344

Timestep Collection Time: 5.96959
Timestep Consumption Time: 0.84224
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.81184

Cumulative Model Updates: 28,312
Cumulative Timesteps: 472,251,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 472251016...
Checkpoint 472251016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.61445
Policy Entropy: 1.07813
Value Function Loss: 1.38929

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.07549

Collected Steps per Second: 8,826.81855
Overall Steps per Second: 7,685.07662

Timestep Collection Time: 5.66705
Timestep Consumption Time: 0.84193
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 6.50898

Cumulative Model Updates: 28,315
Cumulative Timesteps: 472,301,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.07148
Policy Entropy: 1.06120
Value Function Loss: 1.33418

Mean KL Divergence: 0.02984
SB3 Clip Fraction: 0.20092
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 8,698.68146
Overall Steps per Second: 7,549.30641

Timestep Collection Time: 5.75168
Timestep Consumption Time: 0.87569
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 6.62736

Cumulative Model Updates: 28,318
Cumulative Timesteps: 472,351,070

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 472351070...
Checkpoint 472351070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.59544
Policy Entropy: 1.07935
Value Function Loss: 1.37885

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.06784

Collected Steps per Second: 8,865.48198
Overall Steps per Second: 7,790.55985

Timestep Collection Time: 5.64324
Timestep Consumption Time: 0.77864
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 6.42187

Cumulative Model Updates: 28,321
Cumulative Timesteps: 472,401,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.43079
Policy Entropy: 1.08034
Value Function Loss: 1.36185

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 9,060.23366
Overall Steps per Second: 7,831.75325

Timestep Collection Time: 5.52171
Timestep Consumption Time: 0.86613
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.38784

Cumulative Model Updates: 28,324
Cumulative Timesteps: 472,451,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 472451128...
Checkpoint 472451128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.34943
Policy Entropy: 1.06791
Value Function Loss: 1.43687

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.06020

Collected Steps per Second: 8,641.81208
Overall Steps per Second: 7,583.38329

Timestep Collection Time: 5.78675
Timestep Consumption Time: 0.80767
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.59442

Cumulative Model Updates: 28,327
Cumulative Timesteps: 472,501,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.62267
Policy Entropy: 1.05786
Value Function Loss: 1.45156

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.18915
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.06286

Collected Steps per Second: 8,807.76409
Overall Steps per Second: 7,760.53325

Timestep Collection Time: 5.67953
Timestep Consumption Time: 0.76641
PPO Batch Consumption Time: 0.04274
Total Iteration Time: 6.44595

Cumulative Model Updates: 28,330
Cumulative Timesteps: 472,551,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 472551160...
Checkpoint 472551160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.28324
Policy Entropy: 1.06550
Value Function Loss: 1.49079

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.06681

Collected Steps per Second: 8,794.98693
Overall Steps per Second: 7,656.98472

Timestep Collection Time: 5.68779
Timestep Consumption Time: 0.84533
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 6.53312

Cumulative Model Updates: 28,333
Cumulative Timesteps: 472,601,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.68919
Policy Entropy: 1.06862
Value Function Loss: 1.51611

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.16781
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 8,845.55311
Overall Steps per Second: 7,716.91743

Timestep Collection Time: 5.65482
Timestep Consumption Time: 0.82704
PPO Batch Consumption Time: 0.04145
Total Iteration Time: 6.48186

Cumulative Model Updates: 28,336
Cumulative Timesteps: 472,651,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 472651204...
Checkpoint 472651204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.54900
Policy Entropy: 1.04836
Value Function Loss: 1.40384

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 8,898.00716
Overall Steps per Second: 7,611.86806

Timestep Collection Time: 5.62261
Timestep Consumption Time: 0.95002
PPO Batch Consumption Time: 0.04229
Total Iteration Time: 6.57263

Cumulative Model Updates: 28,339
Cumulative Timesteps: 472,701,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.63945
Policy Entropy: 1.04511
Value Function Loss: 1.38496

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.19202
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 8,905.63823
Overall Steps per Second: 7,734.08409

Timestep Collection Time: 5.61577
Timestep Consumption Time: 0.85067
PPO Batch Consumption Time: 0.04313
Total Iteration Time: 6.46644

Cumulative Model Updates: 28,342
Cumulative Timesteps: 472,751,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 472751246...
Checkpoint 472751246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.79917
Policy Entropy: 1.05264
Value Function Loss: 1.39532

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 8,540.09021
Overall Steps per Second: 7,578.43708

Timestep Collection Time: 5.85685
Timestep Consumption Time: 0.74319
PPO Batch Consumption Time: 0.03997
Total Iteration Time: 6.60004

Cumulative Model Updates: 28,345
Cumulative Timesteps: 472,801,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.91500
Policy Entropy: 1.06451
Value Function Loss: 1.48109

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.07395

Collected Steps per Second: 8,959.57195
Overall Steps per Second: 7,805.71712

Timestep Collection Time: 5.58196
Timestep Consumption Time: 0.82514
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.40710

Cumulative Model Updates: 28,348
Cumulative Timesteps: 472,851,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 472851276...
Checkpoint 472851276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.00685
Policy Entropy: 1.03352
Value Function Loss: 1.43059

Mean KL Divergence: 0.03499
SB3 Clip Fraction: 0.20709
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.08259

Collected Steps per Second: 8,568.38018
Overall Steps per Second: 7,506.98083

Timestep Collection Time: 5.83728
Timestep Consumption Time: 0.82532
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.66260

Cumulative Model Updates: 28,351
Cumulative Timesteps: 472,901,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.11502
Policy Entropy: 1.05949
Value Function Loss: 1.31634

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.17883
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.07774

Collected Steps per Second: 8,852.15520
Overall Steps per Second: 7,716.28954

Timestep Collection Time: 5.64902
Timestep Consumption Time: 0.83156
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.48058

Cumulative Model Updates: 28,354
Cumulative Timesteps: 472,951,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 472951298...
Checkpoint 472951298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.25864
Policy Entropy: 1.05865
Value Function Loss: 1.35238

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.18902
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.07648

Collected Steps per Second: 8,658.18550
Overall Steps per Second: 7,510.56769

Timestep Collection Time: 5.77719
Timestep Consumption Time: 0.88276
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.65995

Cumulative Model Updates: 28,357
Cumulative Timesteps: 473,001,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.99862
Policy Entropy: 1.05872
Value Function Loss: 1.41533

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.07937

Collected Steps per Second: 8,590.48636
Overall Steps per Second: 7,567.34071

Timestep Collection Time: 5.82156
Timestep Consumption Time: 0.78711
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.60866

Cumulative Model Updates: 28,360
Cumulative Timesteps: 473,051,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 473051328...
Checkpoint 473051328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.88248
Policy Entropy: 1.03338
Value Function Loss: 1.48571

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.21513
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.08964

Collected Steps per Second: 8,825.30678
Overall Steps per Second: 7,595.67281

Timestep Collection Time: 5.66734
Timestep Consumption Time: 0.91746
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.58480

Cumulative Model Updates: 28,363
Cumulative Timesteps: 473,101,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.57882
Policy Entropy: 1.06410
Value Function Loss: 1.47042

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.08290

Collected Steps per Second: 8,664.09691
Overall Steps per Second: 7,463.10609

Timestep Collection Time: 5.77210
Timestep Consumption Time: 0.92887
PPO Batch Consumption Time: 0.04267
Total Iteration Time: 6.70096

Cumulative Model Updates: 28,366
Cumulative Timesteps: 473,151,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 473151354...
Checkpoint 473151354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.31937
Policy Entropy: 1.04645
Value Function Loss: 1.37069

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.08132

Collected Steps per Second: 8,983.00373
Overall Steps per Second: 7,669.45769

Timestep Collection Time: 5.56852
Timestep Consumption Time: 0.95372
PPO Batch Consumption Time: 0.04785
Total Iteration Time: 6.52223

Cumulative Model Updates: 28,369
Cumulative Timesteps: 473,201,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.08931
Policy Entropy: 1.02828
Value Function Loss: 1.38168

Mean KL Divergence: 0.04426
SB3 Clip Fraction: 0.23647
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.08368

Collected Steps per Second: 8,717.93510
Overall Steps per Second: 7,614.44633

Timestep Collection Time: 5.73760
Timestep Consumption Time: 0.83150
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.56909

Cumulative Model Updates: 28,372
Cumulative Timesteps: 473,251,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 473251396...
Checkpoint 473251396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.38171
Policy Entropy: 1.05827
Value Function Loss: 1.33864

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.19342
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 8,882.71856
Overall Steps per Second: 7,770.84752

Timestep Collection Time: 5.62981
Timestep Consumption Time: 0.80553
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 6.43533

Cumulative Model Updates: 28,375
Cumulative Timesteps: 473,301,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.83311
Policy Entropy: 1.03732
Value Function Loss: 1.41002

Mean KL Divergence: 0.03187
SB3 Clip Fraction: 0.20557
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 9,330.30753
Overall Steps per Second: 8,012.18098

Timestep Collection Time: 5.36017
Timestep Consumption Time: 0.88183
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.24200

Cumulative Model Updates: 28,378
Cumulative Timesteps: 473,351,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 473351416...
Checkpoint 473351416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.45381
Policy Entropy: 1.06114
Value Function Loss: 1.39087

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.20197
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.06924

Collected Steps per Second: 8,918.96490
Overall Steps per Second: 7,723.43996

Timestep Collection Time: 5.60872
Timestep Consumption Time: 0.86818
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.47691

Cumulative Model Updates: 28,381
Cumulative Timesteps: 473,401,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.21788
Policy Entropy: 1.06551
Value Function Loss: 1.41658

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 9,050.99503
Overall Steps per Second: 7,803.83457

Timestep Collection Time: 5.52425
Timestep Consumption Time: 0.88285
PPO Batch Consumption Time: 0.04886
Total Iteration Time: 6.40711

Cumulative Model Updates: 28,384
Cumulative Timesteps: 473,451,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 473451440...
Checkpoint 473451440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.89455
Policy Entropy: 1.04523
Value Function Loss: 1.32094

Mean KL Divergence: 0.02640
SB3 Clip Fraction: 0.17969
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 8,991.41107
Overall Steps per Second: 7,765.98390

Timestep Collection Time: 5.56131
Timestep Consumption Time: 0.87754
PPO Batch Consumption Time: 0.04880
Total Iteration Time: 6.43885

Cumulative Model Updates: 28,387
Cumulative Timesteps: 473,501,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.86820
Policy Entropy: 1.04850
Value Function Loss: 1.32621

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.18669
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 8,835.82277
Overall Steps per Second: 7,778.84230

Timestep Collection Time: 5.66195
Timestep Consumption Time: 0.76934
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.43129

Cumulative Model Updates: 28,390
Cumulative Timesteps: 473,551,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 473551472...
Checkpoint 473551472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.55067
Policy Entropy: 1.06261
Value Function Loss: 1.30952

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.16217
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.07212

Collected Steps per Second: 8,740.37940
Overall Steps per Second: 7,558.82251

Timestep Collection Time: 5.72286
Timestep Consumption Time: 0.89457
PPO Batch Consumption Time: 0.04774
Total Iteration Time: 6.61743

Cumulative Model Updates: 28,393
Cumulative Timesteps: 473,601,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.95471
Policy Entropy: 1.08087
Value Function Loss: 1.43214

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.08175

Collected Steps per Second: 8,457.43500
Overall Steps per Second: 7,410.47718

Timestep Collection Time: 5.91456
Timestep Consumption Time: 0.83561
PPO Batch Consumption Time: 0.04679
Total Iteration Time: 6.75017

Cumulative Model Updates: 28,396
Cumulative Timesteps: 473,651,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 473651514...
Checkpoint 473651514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.94677
Policy Entropy: 1.05726
Value Function Loss: 1.57270

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.09044

Collected Steps per Second: 8,930.19081
Overall Steps per Second: 7,744.08490

Timestep Collection Time: 5.60122
Timestep Consumption Time: 0.85790
PPO Batch Consumption Time: 0.04412
Total Iteration Time: 6.45912

Cumulative Model Updates: 28,399
Cumulative Timesteps: 473,701,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.56366
Policy Entropy: 1.06567
Value Function Loss: 1.65829

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 8,785.67454
Overall Steps per Second: 7,644.09934

Timestep Collection Time: 5.69131
Timestep Consumption Time: 0.84994
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.54125

Cumulative Model Updates: 28,402
Cumulative Timesteps: 473,751,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 473751536...
Checkpoint 473751536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.34698
Policy Entropy: 1.07316
Value Function Loss: 1.59689

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.09115

Collected Steps per Second: 8,866.07692
Overall Steps per Second: 7,778.41504

Timestep Collection Time: 5.63992
Timestep Consumption Time: 0.78863
PPO Batch Consumption Time: 0.04731
Total Iteration Time: 6.42856

Cumulative Model Updates: 28,405
Cumulative Timesteps: 473,801,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.29269
Policy Entropy: 1.08048
Value Function Loss: 1.47670

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.08559

Collected Steps per Second: 8,811.57172
Overall Steps per Second: 7,663.69414

Timestep Collection Time: 5.67685
Timestep Consumption Time: 0.85029
PPO Batch Consumption Time: 0.04449
Total Iteration Time: 6.52714

Cumulative Model Updates: 28,408
Cumulative Timesteps: 473,851,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 473851562...
Checkpoint 473851562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.42892
Policy Entropy: 1.06058
Value Function Loss: 1.45418

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 8,382.56671
Overall Steps per Second: 7,366.62963

Timestep Collection Time: 5.96643
Timestep Consumption Time: 0.82283
PPO Batch Consumption Time: 0.04215
Total Iteration Time: 6.78926

Cumulative Model Updates: 28,411
Cumulative Timesteps: 473,901,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.15613
Policy Entropy: 1.05091
Value Function Loss: 1.53375

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.19017
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.07173

Collected Steps per Second: 9,075.00348
Overall Steps per Second: 7,884.73427

Timestep Collection Time: 5.51206
Timestep Consumption Time: 0.83209
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.34416

Cumulative Model Updates: 28,414
Cumulative Timesteps: 473,951,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 473951598...
Checkpoint 473951598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.19067
Policy Entropy: 1.06300
Value Function Loss: 1.48343

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.07169

Collected Steps per Second: 8,462.78350
Overall Steps per Second: 7,454.12385

Timestep Collection Time: 5.91011
Timestep Consumption Time: 0.79973
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.70984

Cumulative Model Updates: 28,417
Cumulative Timesteps: 474,001,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.04127
Policy Entropy: 1.06383
Value Function Loss: 1.47350

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.07816

Collected Steps per Second: 8,745.84322
Overall Steps per Second: 7,744.52085

Timestep Collection Time: 5.71975
Timestep Consumption Time: 0.73953
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 6.45928

Cumulative Model Updates: 28,420
Cumulative Timesteps: 474,051,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 474051638...
Checkpoint 474051638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.52997
Policy Entropy: 1.05423
Value Function Loss: 1.35284

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.07122
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 8,404.94797
Overall Steps per Second: 7,312.37823

Timestep Collection Time: 5.94888
Timestep Consumption Time: 0.88884
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 6.83772

Cumulative Model Updates: 28,423
Cumulative Timesteps: 474,101,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.34182
Policy Entropy: 1.05028
Value Function Loss: 1.32624

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 8,696.88149
Overall Steps per Second: 7,543.91261

Timestep Collection Time: 5.75011
Timestep Consumption Time: 0.87881
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.62892

Cumulative Model Updates: 28,426
Cumulative Timesteps: 474,151,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 474151646...
Checkpoint 474151646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.84013
Policy Entropy: 1.04001
Value Function Loss: 1.36297

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16650
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.07704

Collected Steps per Second: 8,814.03511
Overall Steps per Second: 7,657.69864

Timestep Collection Time: 5.67300
Timestep Consumption Time: 0.85664
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 6.52964

Cumulative Model Updates: 28,429
Cumulative Timesteps: 474,201,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.33470
Policy Entropy: 1.06296
Value Function Loss: 1.48938

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 8,755.36478
Overall Steps per Second: 7,629.22683

Timestep Collection Time: 5.71421
Timestep Consumption Time: 0.84347
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 6.55768

Cumulative Model Updates: 28,432
Cumulative Timesteps: 474,251,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 474251678...
Checkpoint 474251678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.85765
Policy Entropy: 1.06474
Value Function Loss: 1.48813

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.07983

Collected Steps per Second: 8,723.44731
Overall Steps per Second: 7,639.30200

Timestep Collection Time: 5.73260
Timestep Consumption Time: 0.81355
PPO Batch Consumption Time: 0.04276
Total Iteration Time: 6.54615

Cumulative Model Updates: 28,435
Cumulative Timesteps: 474,301,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.34940
Policy Entropy: 1.05003
Value Function Loss: 1.44771

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.15266
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 8,832.09739
Overall Steps per Second: 7,639.24096

Timestep Collection Time: 5.66185
Timestep Consumption Time: 0.88409
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 6.54594

Cumulative Model Updates: 28,438
Cumulative Timesteps: 474,351,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 474351692...
Checkpoint 474351692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.97047
Policy Entropy: 1.04203
Value Function Loss: 1.43390

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.19948
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.07962

Collected Steps per Second: 8,928.21085
Overall Steps per Second: 7,772.59853

Timestep Collection Time: 5.60359
Timestep Consumption Time: 0.83313
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.43671

Cumulative Model Updates: 28,441
Cumulative Timesteps: 474,401,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.94370
Policy Entropy: 1.04975
Value Function Loss: 1.51764

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.06855

Collected Steps per Second: 8,867.49246
Overall Steps per Second: 7,632.41051

Timestep Collection Time: 5.64015
Timestep Consumption Time: 0.91269
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.55284

Cumulative Model Updates: 28,444
Cumulative Timesteps: 474,451,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 474451736...
Checkpoint 474451736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.36450
Policy Entropy: 1.05331
Value Function Loss: 1.48999

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.16223
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.07941

Collected Steps per Second: 8,833.40091
Overall Steps per Second: 7,625.25059

Timestep Collection Time: 5.66282
Timestep Consumption Time: 0.89722
PPO Batch Consumption Time: 0.04761
Total Iteration Time: 6.56005

Cumulative Model Updates: 28,447
Cumulative Timesteps: 474,501,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.62773
Policy Entropy: 1.02959
Value Function Loss: 1.46909

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.16561
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 8,329.73936
Overall Steps per Second: 7,403.36636

Timestep Collection Time: 6.00403
Timestep Consumption Time: 0.75128
PPO Batch Consumption Time: 0.04906
Total Iteration Time: 6.75531

Cumulative Model Updates: 28,450
Cumulative Timesteps: 474,551,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 474551770...
Checkpoint 474551770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.45909
Policy Entropy: 1.01212
Value Function Loss: 1.41760

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.23016
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 8,724.93989
Overall Steps per Second: 7,606.42634

Timestep Collection Time: 5.73391
Timestep Consumption Time: 0.84316
PPO Batch Consumption Time: 0.04122
Total Iteration Time: 6.57707

Cumulative Model Updates: 28,453
Cumulative Timesteps: 474,601,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.85668
Policy Entropy: 1.02245
Value Function Loss: 1.40805

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.18328
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.07788

Collected Steps per Second: 8,710.19350
Overall Steps per Second: 7,618.51175

Timestep Collection Time: 5.74178
Timestep Consumption Time: 0.82276
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.56454

Cumulative Model Updates: 28,456
Cumulative Timesteps: 474,651,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 474651810...
Checkpoint 474651810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.28876
Policy Entropy: 1.02807
Value Function Loss: 1.27995

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.19651
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 9,020.35731
Overall Steps per Second: 7,821.75666

Timestep Collection Time: 5.54435
Timestep Consumption Time: 0.84961
PPO Batch Consumption Time: 0.04763
Total Iteration Time: 6.39396

Cumulative Model Updates: 28,459
Cumulative Timesteps: 474,701,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.17466
Policy Entropy: 1.01114
Value Function Loss: 1.26117

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.18972
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 8,928.71776
Overall Steps per Second: 7,626.96102

Timestep Collection Time: 5.60125
Timestep Consumption Time: 0.95601
PPO Batch Consumption Time: 0.05181
Total Iteration Time: 6.55726

Cumulative Model Updates: 28,462
Cumulative Timesteps: 474,751,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 474751834...
Checkpoint 474751834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.73832
Policy Entropy: 1.02731
Value Function Loss: 1.29316

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.17133
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.05860

Collected Steps per Second: 8,375.50498
Overall Steps per Second: 7,379.96057

Timestep Collection Time: 5.97265
Timestep Consumption Time: 0.80570
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.77836

Cumulative Model Updates: 28,465
Cumulative Timesteps: 474,801,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.50656
Policy Entropy: 1.04242
Value Function Loss: 1.43808

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.19019
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.06169

Collected Steps per Second: 8,662.34129
Overall Steps per Second: 7,517.29616

Timestep Collection Time: 5.77396
Timestep Consumption Time: 0.87950
PPO Batch Consumption Time: 0.04004
Total Iteration Time: 6.65346

Cumulative Model Updates: 28,468
Cumulative Timesteps: 474,851,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 474851874...
Checkpoint 474851874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.79818
Policy Entropy: 1.02731
Value Function Loss: 1.41878

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 8,272.00534
Overall Steps per Second: 7,307.75880

Timestep Collection Time: 6.04593
Timestep Consumption Time: 0.79775
PPO Batch Consumption Time: 0.04322
Total Iteration Time: 6.84369

Cumulative Model Updates: 28,471
Cumulative Timesteps: 474,901,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.99705
Policy Entropy: 1.02193
Value Function Loss: 1.35486

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.18884
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 8,909.70560
Overall Steps per Second: 7,602.01673

Timestep Collection Time: 5.61276
Timestep Consumption Time: 0.96550
PPO Batch Consumption Time: 0.04522
Total Iteration Time: 6.57825

Cumulative Model Updates: 28,474
Cumulative Timesteps: 474,951,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 474951894...
Checkpoint 474951894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.02039
Policy Entropy: 1.03230
Value Function Loss: 1.32964

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 8,285.36197
Overall Steps per Second: 7,262.48102

Timestep Collection Time: 6.03619
Timestep Consumption Time: 0.85016
PPO Batch Consumption Time: 0.04727
Total Iteration Time: 6.88635

Cumulative Model Updates: 28,477
Cumulative Timesteps: 475,001,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.71043
Policy Entropy: 1.03896
Value Function Loss: 1.38911

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.18385
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 8,803.52115
Overall Steps per Second: 7,737.78129

Timestep Collection Time: 5.67977
Timestep Consumption Time: 0.78229
PPO Batch Consumption Time: 0.04678
Total Iteration Time: 6.46206

Cumulative Model Updates: 28,480
Cumulative Timesteps: 475,051,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 475051908...
Checkpoint 475051908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.89765
Policy Entropy: 1.02714
Value Function Loss: 1.37660

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 8,606.93440
Overall Steps per Second: 7,452.09323

Timestep Collection Time: 5.80950
Timestep Consumption Time: 0.90029
PPO Batch Consumption Time: 0.04860
Total Iteration Time: 6.70979

Cumulative Model Updates: 28,483
Cumulative Timesteps: 475,101,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.69761
Policy Entropy: 1.00835
Value Function Loss: 1.22693

Mean KL Divergence: 0.03258
SB3 Clip Fraction: 0.22443
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.07994

Collected Steps per Second: 8,894.26317
Overall Steps per Second: 7,706.56148

Timestep Collection Time: 5.62250
Timestep Consumption Time: 0.86652
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 6.48902

Cumulative Model Updates: 28,486
Cumulative Timesteps: 475,151,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 475151918...
Checkpoint 475151918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.54714
Policy Entropy: 1.04121
Value Function Loss: 1.19060

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.20891
Policy Update Magnitude: 0.06975
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 9,069.00647
Overall Steps per Second: 7,665.17580

Timestep Collection Time: 5.51549
Timestep Consumption Time: 1.01013
PPO Batch Consumption Time: 0.04850
Total Iteration Time: 6.52562

Cumulative Model Updates: 28,489
Cumulative Timesteps: 475,201,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.20127
Policy Entropy: 1.01130
Value Function Loss: 1.20126

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.19403
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 9,047.29944
Overall Steps per Second: 7,786.68457

Timestep Collection Time: 5.52828
Timestep Consumption Time: 0.89499
PPO Batch Consumption Time: 0.04789
Total Iteration Time: 6.42327

Cumulative Model Updates: 28,492
Cumulative Timesteps: 475,251,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 475251954...
Checkpoint 475251954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.58318
Policy Entropy: 1.02049
Value Function Loss: 1.30420

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.17703
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 9,212.93916
Overall Steps per Second: 8,086.63386

Timestep Collection Time: 5.42715
Timestep Consumption Time: 0.75589
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 6.18304

Cumulative Model Updates: 28,495
Cumulative Timesteps: 475,301,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.30473
Policy Entropy: 1.02400
Value Function Loss: 1.37530

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.06431

Collected Steps per Second: 8,763.98755
Overall Steps per Second: 7,594.70961

Timestep Collection Time: 5.70631
Timestep Consumption Time: 0.87854
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.58485

Cumulative Model Updates: 28,498
Cumulative Timesteps: 475,351,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 475351964...
Checkpoint 475351964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.68780
Policy Entropy: 1.04877
Value Function Loss: 1.41807

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.19014
Policy Update Magnitude: 0.06821
Value Function Update Magnitude: 0.06349

Collected Steps per Second: 8,701.86666
Overall Steps per Second: 7,583.00753

Timestep Collection Time: 5.74842
Timestep Consumption Time: 0.84817
PPO Batch Consumption Time: 0.04401
Total Iteration Time: 6.59659

Cumulative Model Updates: 28,501
Cumulative Timesteps: 475,401,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.56492
Policy Entropy: 1.04688
Value Function Loss: 1.41202

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.17536
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 8,646.33144
Overall Steps per Second: 7,558.81850

Timestep Collection Time: 5.78534
Timestep Consumption Time: 0.83236
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.61770

Cumulative Model Updates: 28,504
Cumulative Timesteps: 475,452,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 475452008...
Checkpoint 475452008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.35830
Policy Entropy: 1.04572
Value Function Loss: 1.33533

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.07007
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 8,787.66441
Overall Steps per Second: 7,654.70882

Timestep Collection Time: 5.69184
Timestep Consumption Time: 0.84244
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.53428

Cumulative Model Updates: 28,507
Cumulative Timesteps: 475,502,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.75240
Policy Entropy: 1.03289
Value Function Loss: 1.30385

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16818
Policy Update Magnitude: 0.07542
Value Function Update Magnitude: 0.07039

Collected Steps per Second: 8,810.73420
Overall Steps per Second: 7,743.39367

Timestep Collection Time: 5.67853
Timestep Consumption Time: 0.78272
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.46125

Cumulative Model Updates: 28,510
Cumulative Timesteps: 475,552,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 475552058...
Checkpoint 475552058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.56845
Policy Entropy: 1.04930
Value Function Loss: 1.34815

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.17195
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.06482

Collected Steps per Second: 8,782.34398
Overall Steps per Second: 7,655.23081

Timestep Collection Time: 5.69552
Timestep Consumption Time: 0.83858
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 6.53409

Cumulative Model Updates: 28,513
Cumulative Timesteps: 475,602,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.82534
Policy Entropy: 1.05212
Value Function Loss: 1.35295

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.19327
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.06262

Collected Steps per Second: 8,764.29827
Overall Steps per Second: 7,629.14646

Timestep Collection Time: 5.70542
Timestep Consumption Time: 0.84892
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.55434

Cumulative Model Updates: 28,516
Cumulative Timesteps: 475,652,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 475652082...
Checkpoint 475652082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.92374
Policy Entropy: 1.04280
Value Function Loss: 1.35938

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.06298

Collected Steps per Second: 8,648.66181
Overall Steps per Second: 7,572.40621

Timestep Collection Time: 5.78124
Timestep Consumption Time: 0.82168
PPO Batch Consumption Time: 0.04032
Total Iteration Time: 6.60292

Cumulative Model Updates: 28,519
Cumulative Timesteps: 475,702,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.55944
Policy Entropy: 1.04643
Value Function Loss: 1.37634

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.19574
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 8,531.82801
Overall Steps per Second: 7,465.54049

Timestep Collection Time: 5.86322
Timestep Consumption Time: 0.83743
PPO Batch Consumption Time: 0.04585
Total Iteration Time: 6.70065

Cumulative Model Updates: 28,522
Cumulative Timesteps: 475,752,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 475752106...
Checkpoint 475752106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.06033
Policy Entropy: 1.06138
Value Function Loss: 1.41619

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 8,769.12998
Overall Steps per Second: 7,725.21036

Timestep Collection Time: 5.70364
Timestep Consumption Time: 0.77074
PPO Batch Consumption Time: 0.04723
Total Iteration Time: 6.47439

Cumulative Model Updates: 28,525
Cumulative Timesteps: 475,802,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.49862
Policy Entropy: 1.06354
Value Function Loss: 1.50378

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.07257

Collected Steps per Second: 8,731.14113
Overall Steps per Second: 7,605.81311

Timestep Collection Time: 5.72869
Timestep Consumption Time: 0.84760
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 6.57629

Cumulative Model Updates: 28,528
Cumulative Timesteps: 475,852,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 475852140...
Checkpoint 475852140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.45818
Policy Entropy: 1.06351
Value Function Loss: 1.41045

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14506
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.07108

Collected Steps per Second: 8,455.60665
Overall Steps per Second: 7,399.79489

Timestep Collection Time: 5.91584
Timestep Consumption Time: 0.84408
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 6.75992

Cumulative Model Updates: 28,531
Cumulative Timesteps: 475,902,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.61394
Policy Entropy: 1.06548
Value Function Loss: 1.51159

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.17260
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 8,841.33253
Overall Steps per Second: 7,665.79406

Timestep Collection Time: 5.65684
Timestep Consumption Time: 0.86747
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.52431

Cumulative Model Updates: 28,534
Cumulative Timesteps: 475,952,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 475952176...
Checkpoint 475952176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.10216
Policy Entropy: 1.06862
Value Function Loss: 1.45125

Mean KL Divergence: 0.02216
SB3 Clip Fraction: 0.18325
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.07138

Collected Steps per Second: 8,906.42386
Overall Steps per Second: 7,708.23148

Timestep Collection Time: 5.61393
Timestep Consumption Time: 0.87265
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.48657

Cumulative Model Updates: 28,537
Cumulative Timesteps: 476,002,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.08883
Policy Entropy: 1.05923
Value Function Loss: 1.58296

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 9,009.72335
Overall Steps per Second: 7,996.66042

Timestep Collection Time: 5.55289
Timestep Consumption Time: 0.70347
PPO Batch Consumption Time: 0.04159
Total Iteration Time: 6.25636

Cumulative Model Updates: 28,540
Cumulative Timesteps: 476,052,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 476052206...
Checkpoint 476052206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.57808
Policy Entropy: 1.05869
Value Function Loss: 1.52128

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17287
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 8,978.83833
Overall Steps per Second: 7,756.18821

Timestep Collection Time: 5.57154
Timestep Consumption Time: 0.87827
PPO Batch Consumption Time: 0.04731
Total Iteration Time: 6.44982

Cumulative Model Updates: 28,543
Cumulative Timesteps: 476,102,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.34918
Policy Entropy: 1.07531
Value Function Loss: 1.55540

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.08260

Collected Steps per Second: 8,618.37211
Overall Steps per Second: 7,577.95111

Timestep Collection Time: 5.80504
Timestep Consumption Time: 0.79701
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.60205

Cumulative Model Updates: 28,546
Cumulative Timesteps: 476,152,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 476152262...
Checkpoint 476152262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.14896
Policy Entropy: 1.09655
Value Function Loss: 1.53493

Mean KL Divergence: 0.02802
SB3 Clip Fraction: 0.17221
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 8,580.84347
Overall Steps per Second: 7,554.93588

Timestep Collection Time: 5.82903
Timestep Consumption Time: 0.79154
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.62057

Cumulative Model Updates: 28,549
Cumulative Timesteps: 476,202,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.94761
Policy Entropy: 1.08669
Value Function Loss: 1.52838

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 8,774.08529
Overall Steps per Second: 7,579.03717

Timestep Collection Time: 5.69951
Timestep Consumption Time: 0.89869
PPO Batch Consumption Time: 0.04717
Total Iteration Time: 6.59820

Cumulative Model Updates: 28,552
Cumulative Timesteps: 476,252,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 476252288...
Checkpoint 476252288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.62777
Policy Entropy: 1.06800
Value Function Loss: 1.58734

Mean KL Divergence: 0.04065
SB3 Clip Fraction: 0.20773
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 8,670.63444
Overall Steps per Second: 7,557.74610

Timestep Collection Time: 5.76982
Timestep Consumption Time: 0.84961
PPO Batch Consumption Time: 0.04289
Total Iteration Time: 6.61943

Cumulative Model Updates: 28,555
Cumulative Timesteps: 476,302,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.95795
Policy Entropy: 1.09561
Value Function Loss: 1.77250

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.19673
Policy Update Magnitude: 0.07162
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 8,817.46395
Overall Steps per Second: 7,605.42086

Timestep Collection Time: 5.67238
Timestep Consumption Time: 0.90398
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.57636

Cumulative Model Updates: 28,558
Cumulative Timesteps: 476,352,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 476352332...
Checkpoint 476352332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.86534
Policy Entropy: 1.09237
Value Function Loss: 1.73503

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 8,557.15124
Overall Steps per Second: 7,463.47840

Timestep Collection Time: 5.84447
Timestep Consumption Time: 0.85643
PPO Batch Consumption Time: 0.04454
Total Iteration Time: 6.70090

Cumulative Model Updates: 28,561
Cumulative Timesteps: 476,402,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.70511
Policy Entropy: 1.08029
Value Function Loss: 1.74665

Mean KL Divergence: 0.03131
SB3 Clip Fraction: 0.19071
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 8,850.41079
Overall Steps per Second: 7,770.18711

Timestep Collection Time: 5.65239
Timestep Consumption Time: 0.78580
PPO Batch Consumption Time: 0.05022
Total Iteration Time: 6.43820

Cumulative Model Updates: 28,564
Cumulative Timesteps: 476,452,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 476452370...
Checkpoint 476452370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806.00840
Policy Entropy: 1.10053
Value Function Loss: 1.72313

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 8,709.54215
Overall Steps per Second: 7,600.15600

Timestep Collection Time: 5.74290
Timestep Consumption Time: 0.83828
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.58118

Cumulative Model Updates: 28,567
Cumulative Timesteps: 476,502,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.76794
Policy Entropy: 1.10825
Value Function Loss: 1.74009

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 8,673.87436
Overall Steps per Second: 7,612.59925

Timestep Collection Time: 5.76582
Timestep Consumption Time: 0.80381
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.56964

Cumulative Model Updates: 28,570
Cumulative Timesteps: 476,552,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 476552400...
Checkpoint 476552400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.26887
Policy Entropy: 1.09549
Value Function Loss: 1.74047

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 8,665.44791
Overall Steps per Second: 7,513.59471

Timestep Collection Time: 5.77212
Timestep Consumption Time: 0.88488
PPO Batch Consumption Time: 0.04814
Total Iteration Time: 6.65700

Cumulative Model Updates: 28,573
Cumulative Timesteps: 476,602,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.56729
Policy Entropy: 1.08092
Value Function Loss: 1.58924

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.16726
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 8,720.43950
Overall Steps per Second: 7,614.37237

Timestep Collection Time: 5.73480
Timestep Consumption Time: 0.83304
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.56784

Cumulative Model Updates: 28,576
Cumulative Timesteps: 476,652,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 476652428...
Checkpoint 476652428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.17141
Policy Entropy: 1.08657
Value Function Loss: 1.54030

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.09621

Collected Steps per Second: 8,664.60317
Overall Steps per Second: 7,597.90165

Timestep Collection Time: 5.77130
Timestep Consumption Time: 0.81026
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.58155

Cumulative Model Updates: 28,579
Cumulative Timesteps: 476,702,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.02623
Policy Entropy: 1.08519
Value Function Loss: 1.46050

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.15845
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08881

Collected Steps per Second: 8,722.49775
Overall Steps per Second: 7,563.47134

Timestep Collection Time: 5.73505
Timestep Consumption Time: 0.87884
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.61389

Cumulative Model Updates: 28,582
Cumulative Timesteps: 476,752,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 476752458...
Checkpoint 476752458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.20023
Policy Entropy: 1.07692
Value Function Loss: 1.48171

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 8,750.82575
Overall Steps per Second: 7,489.78337

Timestep Collection Time: 5.71375
Timestep Consumption Time: 0.96201
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.67576

Cumulative Model Updates: 28,585
Cumulative Timesteps: 476,802,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.26853
Policy Entropy: 1.06125
Value Function Loss: 1.42883

Mean KL Divergence: 0.03271
SB3 Clip Fraction: 0.22873
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 8,819.73865
Overall Steps per Second: 7,614.21223

Timestep Collection Time: 5.67114
Timestep Consumption Time: 0.89789
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 6.56903

Cumulative Model Updates: 28,588
Cumulative Timesteps: 476,852,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 476852476...
Checkpoint 476852476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.84076
Policy Entropy: 1.07516
Value Function Loss: 1.42298

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.08122

Collected Steps per Second: 8,677.30508
Overall Steps per Second: 7,524.61610

Timestep Collection Time: 5.76492
Timestep Consumption Time: 0.88312
PPO Batch Consumption Time: 0.04379
Total Iteration Time: 6.64805

Cumulative Model Updates: 28,591
Cumulative Timesteps: 476,902,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.62472
Policy Entropy: 1.05587
Value Function Loss: 1.35266

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.16657
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08279

Collected Steps per Second: 8,825.86096
Overall Steps per Second: 7,751.17417

Timestep Collection Time: 5.66880
Timestep Consumption Time: 0.78597
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 6.45476

Cumulative Model Updates: 28,594
Cumulative Timesteps: 476,952,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 476952532...
Checkpoint 476952532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.80536
Policy Entropy: 1.03490
Value Function Loss: 1.36046

Mean KL Divergence: 0.04525
SB3 Clip Fraction: 0.28343
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.08253

Collected Steps per Second: 8,971.73291
Overall Steps per Second: 7,713.87926

Timestep Collection Time: 5.57551
Timestep Consumption Time: 0.90916
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 6.48467

Cumulative Model Updates: 28,597
Cumulative Timesteps: 477,002,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.97232
Policy Entropy: 1.05259
Value Function Loss: 1.24948

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.15847
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.07389

Collected Steps per Second: 8,794.45221
Overall Steps per Second: 7,656.46386

Timestep Collection Time: 5.68631
Timestep Consumption Time: 0.84516
PPO Batch Consumption Time: 0.04491
Total Iteration Time: 6.53147

Cumulative Model Updates: 28,600
Cumulative Timesteps: 477,052,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 477052562...
Checkpoint 477052562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.77577
Policy Entropy: 1.05411
Value Function Loss: 1.20260

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.07964

Collected Steps per Second: 8,859.12206
Overall Steps per Second: 7,739.06295

Timestep Collection Time: 5.64706
Timestep Consumption Time: 0.81729
PPO Batch Consumption Time: 0.05116
Total Iteration Time: 6.46435

Cumulative Model Updates: 28,603
Cumulative Timesteps: 477,102,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.29389
Policy Entropy: 1.03386
Value Function Loss: 1.14138

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.09586

Collected Steps per Second: 9,148.44519
Overall Steps per Second: 7,831.04906

Timestep Collection Time: 5.46563
Timestep Consumption Time: 0.91947
PPO Batch Consumption Time: 0.04668
Total Iteration Time: 6.38510

Cumulative Model Updates: 28,606
Cumulative Timesteps: 477,152,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477152592...
Checkpoint 477152592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.89823
Policy Entropy: 1.02238
Value Function Loss: 1.18685

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.21221
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.08821

Collected Steps per Second: 8,599.31222
Overall Steps per Second: 7,600.21415

Timestep Collection Time: 5.81535
Timestep Consumption Time: 0.76447
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.57981

Cumulative Model Updates: 28,609
Cumulative Timesteps: 477,202,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.46508
Policy Entropy: 1.03137
Value Function Loss: 1.25203

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 8,709.11573
Overall Steps per Second: 7,504.70642

Timestep Collection Time: 5.74272
Timestep Consumption Time: 0.92163
PPO Batch Consumption Time: 0.05405
Total Iteration Time: 6.66435

Cumulative Model Updates: 28,612
Cumulative Timesteps: 477,252,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 477252614...
Checkpoint 477252614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.27619
Policy Entropy: 1.03390
Value Function Loss: 1.29250

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.19319
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 8,667.44288
Overall Steps per Second: 7,548.19054

Timestep Collection Time: 5.77010
Timestep Consumption Time: 0.85560
PPO Batch Consumption Time: 0.04172
Total Iteration Time: 6.62569

Cumulative Model Updates: 28,615
Cumulative Timesteps: 477,302,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.24037
Policy Entropy: 1.01753
Value Function Loss: 1.34125

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.17449
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.10657

Collected Steps per Second: 9,082.06983
Overall Steps per Second: 7,849.25760

Timestep Collection Time: 5.50756
Timestep Consumption Time: 0.86502
PPO Batch Consumption Time: 0.04237
Total Iteration Time: 6.37258

Cumulative Model Updates: 28,618
Cumulative Timesteps: 477,352,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 477352646...
Checkpoint 477352646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.91942
Policy Entropy: 1.01082
Value Function Loss: 1.27375

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.20967
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.10301

Collected Steps per Second: 8,746.61595
Overall Steps per Second: 7,641.24331

Timestep Collection Time: 5.71855
Timestep Consumption Time: 0.82724
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.54579

Cumulative Model Updates: 28,621
Cumulative Timesteps: 477,402,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.17435
Policy Entropy: 1.02938
Value Function Loss: 1.25199

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16584
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.09770

Collected Steps per Second: 8,717.98671
Overall Steps per Second: 7,689.21406

Timestep Collection Time: 5.73687
Timestep Consumption Time: 0.76756
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.50444

Cumulative Model Updates: 28,624
Cumulative Timesteps: 477,452,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 477452678...
Checkpoint 477452678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.16838
Policy Entropy: 1.03772
Value Function Loss: 1.22843

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 8,505.37484
Overall Steps per Second: 7,438.68709

Timestep Collection Time: 5.88028
Timestep Consumption Time: 0.84322
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.72350

Cumulative Model Updates: 28,627
Cumulative Timesteps: 477,502,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.70316
Policy Entropy: 1.02865
Value Function Loss: 1.27570

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.15581
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.09073

Collected Steps per Second: 8,791.41776
Overall Steps per Second: 7,747.96582

Timestep Collection Time: 5.68782
Timestep Consumption Time: 0.76600
PPO Batch Consumption Time: 0.04094
Total Iteration Time: 6.45382

Cumulative Model Updates: 28,630
Cumulative Timesteps: 477,552,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 477552696...
Checkpoint 477552696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.67805
Policy Entropy: 1.01936
Value Function Loss: 1.35421

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.20528
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08979

Collected Steps per Second: 8,490.38814
Overall Steps per Second: 7,405.88255

Timestep Collection Time: 5.89066
Timestep Consumption Time: 0.86262
PPO Batch Consumption Time: 0.04882
Total Iteration Time: 6.75328

Cumulative Model Updates: 28,633
Cumulative Timesteps: 477,602,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.73725
Policy Entropy: 1.04781
Value Function Loss: 1.39524

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.17386
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.09163

Collected Steps per Second: 8,629.17700
Overall Steps per Second: 7,530.52342

Timestep Collection Time: 5.79453
Timestep Consumption Time: 0.84538
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 6.63991

Cumulative Model Updates: 28,636
Cumulative Timesteps: 477,652,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477652712...
Checkpoint 477652712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.79752
Policy Entropy: 1.04320
Value Function Loss: 1.38454

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17395
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 8,801.67771
Overall Steps per Second: 7,606.53067

Timestep Collection Time: 5.68187
Timestep Consumption Time: 0.89274
PPO Batch Consumption Time: 0.04647
Total Iteration Time: 6.57461

Cumulative Model Updates: 28,639
Cumulative Timesteps: 477,702,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.95502
Policy Entropy: 1.04908
Value Function Loss: 1.30301

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.07571

Collected Steps per Second: 8,401.43660
Overall Steps per Second: 7,333.83238

Timestep Collection Time: 5.95255
Timestep Consumption Time: 0.86653
PPO Batch Consumption Time: 0.04722
Total Iteration Time: 6.81908

Cumulative Model Updates: 28,642
Cumulative Timesteps: 477,752,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 477752732...
Checkpoint 477752732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.35880
Policy Entropy: 1.05953
Value Function Loss: 1.33598

Mean KL Divergence: 0.02510
SB3 Clip Fraction: 0.19324
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 8,609.20483
Overall Steps per Second: 7,643.52116

Timestep Collection Time: 5.81029
Timestep Consumption Time: 0.73407
PPO Batch Consumption Time: 0.04389
Total Iteration Time: 6.54437

Cumulative Model Updates: 28,645
Cumulative Timesteps: 477,802,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.05089
Policy Entropy: 1.06739
Value Function Loss: 1.37063

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.17149
Policy Update Magnitude: 0.07095
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 8,688.55504
Overall Steps per Second: 7,572.80132

Timestep Collection Time: 5.75493
Timestep Consumption Time: 0.84791
PPO Batch Consumption Time: 0.04186
Total Iteration Time: 6.60284

Cumulative Model Updates: 28,648
Cumulative Timesteps: 477,852,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477852756...
Checkpoint 477852756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.25166
Policy Entropy: 1.07721
Value Function Loss: 1.49588

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.19269
Policy Update Magnitude: 0.06673
Value Function Update Magnitude: 0.10582

Collected Steps per Second: 8,868.54759
Overall Steps per Second: 7,735.63414

Timestep Collection Time: 5.63993
Timestep Consumption Time: 0.82599
PPO Batch Consumption Time: 0.04447
Total Iteration Time: 6.46592

Cumulative Model Updates: 28,651
Cumulative Timesteps: 477,902,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.35715
Policy Entropy: 1.07568
Value Function Loss: 1.45507

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17575
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 8,795.66194
Overall Steps per Second: 7,644.23033

Timestep Collection Time: 5.68735
Timestep Consumption Time: 0.85667
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.54402

Cumulative Model Updates: 28,654
Cumulative Timesteps: 477,952,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 477952798...
Checkpoint 477952798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.05206
Policy Entropy: 1.07846
Value Function Loss: 1.46713

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 8,750.38447
Overall Steps per Second: 7,589.38773

Timestep Collection Time: 5.71723
Timestep Consumption Time: 0.87460
PPO Batch Consumption Time: 0.04544
Total Iteration Time: 6.59184

Cumulative Model Updates: 28,657
Cumulative Timesteps: 478,002,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.50995
Policy Entropy: 1.06868
Value Function Loss: 1.37284

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 8,745.95911
Overall Steps per Second: 7,718.32639

Timestep Collection Time: 5.71876
Timestep Consumption Time: 0.76141
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.48016

Cumulative Model Updates: 28,660
Cumulative Timesteps: 478,052,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 478052842...
Checkpoint 478052842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.97717
Policy Entropy: 1.08165
Value Function Loss: 1.34663

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 8,184.12993
Overall Steps per Second: 7,114.48733

Timestep Collection Time: 6.10963
Timestep Consumption Time: 0.91857
PPO Batch Consumption Time: 0.04902
Total Iteration Time: 7.02819

Cumulative Model Updates: 28,663
Cumulative Timesteps: 478,102,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.94790
Policy Entropy: 1.08624
Value Function Loss: 1.48560

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.07623

Collected Steps per Second: 8,525.09426
Overall Steps per Second: 7,413.58974

Timestep Collection Time: 5.86645
Timestep Consumption Time: 0.87954
PPO Batch Consumption Time: 0.05135
Total Iteration Time: 6.74599

Cumulative Model Updates: 28,666
Cumulative Timesteps: 478,152,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 478152856...
Checkpoint 478152856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.37602
Policy Entropy: 1.09368
Value Function Loss: 1.48605

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.07975

Collected Steps per Second: 8,683.69503
Overall Steps per Second: 7,503.23017

Timestep Collection Time: 5.75861
Timestep Consumption Time: 0.90599
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 6.66460

Cumulative Model Updates: 28,669
Cumulative Timesteps: 478,202,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.54572
Policy Entropy: 1.09680
Value Function Loss: 1.59901

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.07912
Value Function Update Magnitude: 0.07685

Collected Steps per Second: 8,771.92029
Overall Steps per Second: 7,668.86015

Timestep Collection Time: 5.70251
Timestep Consumption Time: 0.82023
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.52274

Cumulative Model Updates: 28,672
Cumulative Timesteps: 478,252,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 478252884...
Checkpoint 478252884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.35456
Policy Entropy: 1.11071
Value Function Loss: 1.57185

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.07274
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 8,720.77088
Overall Steps per Second: 7,693.46383

Timestep Collection Time: 5.73527
Timestep Consumption Time: 0.76583
PPO Batch Consumption Time: 0.04154
Total Iteration Time: 6.50110

Cumulative Model Updates: 28,675
Cumulative Timesteps: 478,302,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.65657
Policy Entropy: 1.11292
Value Function Loss: 1.65257

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 8,915.30000
Overall Steps per Second: 7,770.81053

Timestep Collection Time: 5.60946
Timestep Consumption Time: 0.82616
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.43562

Cumulative Model Updates: 28,678
Cumulative Timesteps: 478,352,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478352910...
Checkpoint 478352910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.85685
Policy Entropy: 1.10954
Value Function Loss: 1.68631

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.08982

Collected Steps per Second: 8,232.60158
Overall Steps per Second: 7,241.03253

Timestep Collection Time: 6.07487
Timestep Consumption Time: 0.83188
PPO Batch Consumption Time: 0.04838
Total Iteration Time: 6.90675

Cumulative Model Updates: 28,681
Cumulative Timesteps: 478,402,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.77211
Policy Entropy: 1.09581
Value Function Loss: 1.72289

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.16764
Policy Update Magnitude: 0.07134
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 8,709.21040
Overall Steps per Second: 7,678.98655

Timestep Collection Time: 5.74335
Timestep Consumption Time: 0.77054
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.51388

Cumulative Model Updates: 28,684
Cumulative Timesteps: 478,452,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 478452942...
Checkpoint 478452942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.91248
Policy Entropy: 1.11090
Value Function Loss: 1.76860

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.14363

Collected Steps per Second: 8,618.51936
Overall Steps per Second: 7,511.15393

Timestep Collection Time: 5.80448
Timestep Consumption Time: 0.85575
PPO Batch Consumption Time: 0.04151
Total Iteration Time: 6.66023

Cumulative Model Updates: 28,687
Cumulative Timesteps: 478,502,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.31477
Policy Entropy: 1.11079
Value Function Loss: 1.75012

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.06982
Value Function Update Magnitude: 0.15037

Collected Steps per Second: 8,653.48952
Overall Steps per Second: 7,536.97424

Timestep Collection Time: 5.77917
Timestep Consumption Time: 0.85612
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.63529

Cumulative Model Updates: 28,690
Cumulative Timesteps: 478,552,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478552978...
Checkpoint 478552978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.21642
Policy Entropy: 1.11912
Value Function Loss: 1.75715

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.07884
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 9,006.22096
Overall Steps per Second: 7,782.52587

Timestep Collection Time: 5.55461
Timestep Consumption Time: 0.87339
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.42799

Cumulative Model Updates: 28,693
Cumulative Timesteps: 478,603,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.26080
Policy Entropy: 1.12265
Value Function Loss: 1.77411

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.07531
Value Function Update Magnitude: 0.11035

Collected Steps per Second: 8,669.25888
Overall Steps per Second: 7,480.39734

Timestep Collection Time: 5.77097
Timestep Consumption Time: 0.91718
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.68815

Cumulative Model Updates: 28,696
Cumulative Timesteps: 478,653,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 478653034...
Checkpoint 478653034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.02615
Policy Entropy: 1.12869
Value Function Loss: 1.73743

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.07494
Value Function Update Magnitude: 0.10104

Collected Steps per Second: 8,623.30058
Overall Steps per Second: 7,588.67569

Timestep Collection Time: 5.80056
Timestep Consumption Time: 0.79084
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.59140

Cumulative Model Updates: 28,699
Cumulative Timesteps: 478,703,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.71770
Policy Entropy: 1.13543
Value Function Loss: 1.75368

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.07660
Value Function Update Magnitude: 0.10220

Collected Steps per Second: 8,694.97120
Overall Steps per Second: 7,579.43553

Timestep Collection Time: 5.75390
Timestep Consumption Time: 0.84685
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.60076

Cumulative Model Updates: 28,702
Cumulative Timesteps: 478,753,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 478753084...
Checkpoint 478753084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.36777
Policy Entropy: 1.13492
Value Function Loss: 1.72043

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.07895
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 9,284.87284
Overall Steps per Second: 7,998.42987

Timestep Collection Time: 5.38683
Timestep Consumption Time: 0.86640
PPO Batch Consumption Time: 0.04548
Total Iteration Time: 6.25323

Cumulative Model Updates: 28,705
Cumulative Timesteps: 478,803,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.67155
Policy Entropy: 1.13684
Value Function Loss: 1.76742

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.07540
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 8,966.64209
Overall Steps per Second: 7,833.68473

Timestep Collection Time: 5.57912
Timestep Consumption Time: 0.80689
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.38601

Cumulative Model Updates: 28,708
Cumulative Timesteps: 478,853,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478853126...
Checkpoint 478853126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.36926
Policy Entropy: 1.13742
Value Function Loss: 1.68957

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.07298
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 9,139.21380
Overall Steps per Second: 7,884.63971

Timestep Collection Time: 5.47377
Timestep Consumption Time: 0.87097
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.34474

Cumulative Model Updates: 28,711
Cumulative Timesteps: 478,903,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.43032
Policy Entropy: 1.12812
Value Function Loss: 1.67081

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.07505
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 9,058.82952
Overall Steps per Second: 7,911.93769

Timestep Collection Time: 5.52235
Timestep Consumption Time: 0.80050
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.32285

Cumulative Model Updates: 28,714
Cumulative Timesteps: 478,953,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478953178...
Checkpoint 478953178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.17768
Policy Entropy: 1.13358
Value Function Loss: 1.61286

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.08065
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 8,906.28438
Overall Steps per Second: 7,664.93854

Timestep Collection Time: 5.61469
Timestep Consumption Time: 0.90931
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.52399

Cumulative Model Updates: 28,717
Cumulative Timesteps: 479,003,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.64519
Policy Entropy: 1.13670
Value Function Loss: 1.60885

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.08491
Value Function Update Magnitude: 0.10040

Collected Steps per Second: 8,746.84805
Overall Steps per Second: 7,679.53351

Timestep Collection Time: 5.71817
Timestep Consumption Time: 0.79472
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.51290

Cumulative Model Updates: 28,720
Cumulative Timesteps: 479,053,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 479053200...
Checkpoint 479053200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.85986
Policy Entropy: 1.13673
Value Function Loss: 1.63898

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.08673
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 8,588.53717
Overall Steps per Second: 7,502.96960

Timestep Collection Time: 5.82451
Timestep Consumption Time: 0.84272
PPO Batch Consumption Time: 0.04165
Total Iteration Time: 6.66723

Cumulative Model Updates: 28,723
Cumulative Timesteps: 479,103,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.73443
Policy Entropy: 1.13787
Value Function Loss: 1.68374

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.07801
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 8,818.98735
Overall Steps per Second: 7,695.63663

Timestep Collection Time: 5.67072
Timestep Consumption Time: 0.82777
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 6.49849

Cumulative Model Updates: 28,726
Cumulative Timesteps: 479,153,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 479153234...
Checkpoint 479153234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.31959
Policy Entropy: 1.13183
Value Function Loss: 1.68260

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 8,899.50709
Overall Steps per Second: 7,813.66743

Timestep Collection Time: 5.62054
Timestep Consumption Time: 0.78107
PPO Batch Consumption Time: 0.04290
Total Iteration Time: 6.40160

Cumulative Model Updates: 28,729
Cumulative Timesteps: 479,203,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.96698
Policy Entropy: 1.13534
Value Function Loss: 1.65074

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 8,782.18994
Overall Steps per Second: 7,668.77620

Timestep Collection Time: 5.69630
Timestep Consumption Time: 0.82703
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.52334

Cumulative Model Updates: 28,732
Cumulative Timesteps: 479,253,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 479253280...
Checkpoint 479253280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.91982
Policy Entropy: 1.13537
Value Function Loss: 1.61030

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 8,856.08025
Overall Steps per Second: 7,627.25535

Timestep Collection Time: 5.64900
Timestep Consumption Time: 0.91011
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.55911

Cumulative Model Updates: 28,735
Cumulative Timesteps: 479,303,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.71917
Policy Entropy: 1.13849
Value Function Loss: 1.58946

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 8,979.93178
Overall Steps per Second: 7,778.26656

Timestep Collection Time: 5.56998
Timestep Consumption Time: 0.86051
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.43048

Cumulative Model Updates: 28,738
Cumulative Timesteps: 479,353,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 479353326...
Checkpoint 479353326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.69566
Policy Entropy: 1.14665
Value Function Loss: 1.53272

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.10589

Collected Steps per Second: 8,650.91640
Overall Steps per Second: 7,570.43952

Timestep Collection Time: 5.78205
Timestep Consumption Time: 0.82523
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.60728

Cumulative Model Updates: 28,741
Cumulative Timesteps: 479,403,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.39847
Policy Entropy: 1.14601
Value Function Loss: 1.51474

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 8,916.11574
Overall Steps per Second: 7,729.37426

Timestep Collection Time: 5.61096
Timestep Consumption Time: 0.86149
PPO Batch Consumption Time: 0.04371
Total Iteration Time: 6.47245

Cumulative Model Updates: 28,744
Cumulative Timesteps: 479,453,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 479453374...
Checkpoint 479453374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.82992
Policy Entropy: 1.14365
Value Function Loss: 1.53355

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.09555

Collected Steps per Second: 8,690.29682
Overall Steps per Second: 7,587.62371

Timestep Collection Time: 5.75515
Timestep Consumption Time: 0.83637
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.59152

Cumulative Model Updates: 28,747
Cumulative Timesteps: 479,503,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.57238
Policy Entropy: 1.13465
Value Function Loss: 1.55403

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 8,615.72676
Overall Steps per Second: 7,526.05425

Timestep Collection Time: 5.80706
Timestep Consumption Time: 0.84078
PPO Batch Consumption Time: 0.04791
Total Iteration Time: 6.64784

Cumulative Model Updates: 28,750
Cumulative Timesteps: 479,553,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 479553420...
Checkpoint 479553420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.94559
Policy Entropy: 1.14289
Value Function Loss: 1.56845

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.09084

Collected Steps per Second: 8,987.05582
Overall Steps per Second: 7,804.25529

Timestep Collection Time: 5.56356
Timestep Consumption Time: 0.84320
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.40676

Cumulative Model Updates: 28,753
Cumulative Timesteps: 479,603,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.73427
Policy Entropy: 1.14608
Value Function Loss: 1.64401

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.08456

Collected Steps per Second: 8,858.79985
Overall Steps per Second: 7,689.42779

Timestep Collection Time: 5.64659
Timestep Consumption Time: 0.85871
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.50530

Cumulative Model Updates: 28,756
Cumulative Timesteps: 479,653,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 479653442...
Checkpoint 479653442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.23289
Policy Entropy: 1.14967
Value Function Loss: 1.71611

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.08910

Collected Steps per Second: 8,681.61404
Overall Steps per Second: 7,696.86775

Timestep Collection Time: 5.76114
Timestep Consumption Time: 0.73709
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 6.49823

Cumulative Model Updates: 28,759
Cumulative Timesteps: 479,703,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.33385
Policy Entropy: 1.14723
Value Function Loss: 1.79197

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 9,046.00099
Overall Steps per Second: 7,835.78071

Timestep Collection Time: 5.52952
Timestep Consumption Time: 0.85402
PPO Batch Consumption Time: 0.04550
Total Iteration Time: 6.38354

Cumulative Model Updates: 28,762
Cumulative Timesteps: 479,753,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 479753478...
Checkpoint 479753478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.52594
Policy Entropy: 1.15366
Value Function Loss: 1.75554

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 8,641.56410
Overall Steps per Second: 7,548.87045

Timestep Collection Time: 5.78715
Timestep Consumption Time: 0.83769
PPO Batch Consumption Time: 0.04103
Total Iteration Time: 6.62483

Cumulative Model Updates: 28,765
Cumulative Timesteps: 479,803,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.12412
Policy Entropy: 1.15383
Value Function Loss: 1.66672

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.07711
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 9,069.78153
Overall Steps per Second: 7,853.45229

Timestep Collection Time: 5.51546
Timestep Consumption Time: 0.85422
PPO Batch Consumption Time: 0.04788
Total Iteration Time: 6.36968

Cumulative Model Updates: 28,768
Cumulative Timesteps: 479,853,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 479853512...
Checkpoint 479853512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.51517
Policy Entropy: 1.16287
Value Function Loss: 1.57475

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 8,752.98038
Overall Steps per Second: 7,664.32448

Timestep Collection Time: 5.71257
Timestep Consumption Time: 0.81142
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.52399

Cumulative Model Updates: 28,771
Cumulative Timesteps: 479,903,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.92359
Policy Entropy: 1.16241
Value Function Loss: 1.53775

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 8,705.44731
Overall Steps per Second: 7,570.45448

Timestep Collection Time: 5.74491
Timestep Consumption Time: 0.86130
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 6.60621

Cumulative Model Updates: 28,774
Cumulative Timesteps: 479,953,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479953526...
Checkpoint 479953526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.77726
Policy Entropy: 1.14883
Value Function Loss: 1.52994

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.07723
Value Function Update Magnitude: 0.08887

Collected Steps per Second: 8,474.03452
Overall Steps per Second: 7,349.07859

Timestep Collection Time: 5.90368
Timestep Consumption Time: 0.90370
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.80738

Cumulative Model Updates: 28,777
Cumulative Timesteps: 480,003,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.34069
Policy Entropy: 1.16424
Value Function Loss: 1.52759

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 8,803.82707
Overall Steps per Second: 7,665.92726

Timestep Collection Time: 5.68253
Timestep Consumption Time: 0.84349
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 6.52602

Cumulative Model Updates: 28,780
Cumulative Timesteps: 480,053,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 480053582...
Checkpoint 480053582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.13661
Policy Entropy: 1.15357
Value Function Loss: 1.53003

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 8,926.14903
Overall Steps per Second: 7,750.80209

Timestep Collection Time: 5.60174
Timestep Consumption Time: 0.84946
PPO Batch Consumption Time: 0.03972
Total Iteration Time: 6.45120

Cumulative Model Updates: 28,783
Cumulative Timesteps: 480,103,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.12340
Policy Entropy: 1.15412
Value Function Loss: 1.51473

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 8,709.28622
Overall Steps per Second: 7,542.21131

Timestep Collection Time: 5.74100
Timestep Consumption Time: 0.88836
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 6.62936

Cumulative Model Updates: 28,786
Cumulative Timesteps: 480,153,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 480153584...
Checkpoint 480153584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.75870
Policy Entropy: 1.14322
Value Function Loss: 1.52218

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.16611
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 8,701.44789
Overall Steps per Second: 7,649.51835

Timestep Collection Time: 5.74893
Timestep Consumption Time: 0.79057
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.53950

Cumulative Model Updates: 28,789
Cumulative Timesteps: 480,203,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.46583
Policy Entropy: 1.15328
Value Function Loss: 1.53300

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.10057

Collected Steps per Second: 8,608.14447
Overall Steps per Second: 7,438.70488

Timestep Collection Time: 5.81147
Timestep Consumption Time: 0.91362
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.72510

Cumulative Model Updates: 28,792
Cumulative Timesteps: 480,253,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480253634...
Checkpoint 480253634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.01253
Policy Entropy: 1.15667
Value Function Loss: 1.54340

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.16240
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 8,809.70719
Overall Steps per Second: 7,658.31744

Timestep Collection Time: 5.67624
Timestep Consumption Time: 0.85339
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.52963

Cumulative Model Updates: 28,795
Cumulative Timesteps: 480,303,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.77606
Policy Entropy: 1.13584
Value Function Loss: 1.52173

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.09106

Collected Steps per Second: 8,695.13522
Overall Steps per Second: 7,671.08435

Timestep Collection Time: 5.75103
Timestep Consumption Time: 0.76773
PPO Batch Consumption Time: 0.05107
Total Iteration Time: 6.51877

Cumulative Model Updates: 28,798
Cumulative Timesteps: 480,353,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 480353646...
Checkpoint 480353646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.11670
Policy Entropy: 1.15272
Value Function Loss: 1.52337

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.08408

Collected Steps per Second: 8,914.09147
Overall Steps per Second: 7,724.77962

Timestep Collection Time: 5.61022
Timestep Consumption Time: 0.86375
PPO Batch Consumption Time: 0.04143
Total Iteration Time: 6.47397

Cumulative Model Updates: 28,801
Cumulative Timesteps: 480,403,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.66473
Policy Entropy: 1.14908
Value Function Loss: 1.51785

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.08332

Collected Steps per Second: 8,528.10057
Overall Steps per Second: 7,371.87901

Timestep Collection Time: 5.86602
Timestep Consumption Time: 0.92004
PPO Batch Consumption Time: 0.04955
Total Iteration Time: 6.78606

Cumulative Model Updates: 28,804
Cumulative Timesteps: 480,453,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480453682...
Checkpoint 480453682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.64332
Policy Entropy: 1.13918
Value Function Loss: 1.53621

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 8,711.26612
Overall Steps per Second: 7,546.87827

Timestep Collection Time: 5.74130
Timestep Consumption Time: 0.88581
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.62711

Cumulative Model Updates: 28,807
Cumulative Timesteps: 480,503,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.42448
Policy Entropy: 1.13022
Value Function Loss: 1.49517

Mean KL Divergence: 0.03157
SB3 Clip Fraction: 0.19223
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 8,993.21074
Overall Steps per Second: 7,802.11160

Timestep Collection Time: 5.56242
Timestep Consumption Time: 0.84918
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.41160

Cumulative Model Updates: 28,810
Cumulative Timesteps: 480,553,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 480553720...
Checkpoint 480553720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.72729
Policy Entropy: 1.13878
Value Function Loss: 1.49929

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 8,787.09530
Overall Steps per Second: 7,647.94224

Timestep Collection Time: 5.69085
Timestep Consumption Time: 0.84765
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 6.53849

Cumulative Model Updates: 28,813
Cumulative Timesteps: 480,603,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.51497
Policy Entropy: 1.14409
Value Function Loss: 1.49910

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.12948

Collected Steps per Second: 8,871.41142
Overall Steps per Second: 7,711.91968

Timestep Collection Time: 5.63946
Timestep Consumption Time: 0.84790
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.48736

Cumulative Model Updates: 28,816
Cumulative Timesteps: 480,653,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 480653756...
Checkpoint 480653756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.50467
Policy Entropy: 1.12021
Value Function Loss: 1.53042

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 8,771.71183
Overall Steps per Second: 7,646.28520

Timestep Collection Time: 5.70197
Timestep Consumption Time: 0.83925
PPO Batch Consumption Time: 0.04811
Total Iteration Time: 6.54122

Cumulative Model Updates: 28,819
Cumulative Timesteps: 480,703,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.51092
Policy Entropy: 1.13752
Value Function Loss: 1.57585

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 8,680.68811
Overall Steps per Second: 7,633.14832

Timestep Collection Time: 5.76291
Timestep Consumption Time: 0.79088
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.55378

Cumulative Model Updates: 28,822
Cumulative Timesteps: 480,753,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480753798...
Checkpoint 480753798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.65779
Policy Entropy: 1.13230
Value Function Loss: 1.49212

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 9,128.97189
Overall Steps per Second: 7,851.97308

Timestep Collection Time: 5.47860
Timestep Consumption Time: 0.89101
PPO Batch Consumption Time: 0.04811
Total Iteration Time: 6.36961

Cumulative Model Updates: 28,825
Cumulative Timesteps: 480,803,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.92186
Policy Entropy: 1.12379
Value Function Loss: 1.47633

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 8,918.80375
Overall Steps per Second: 7,722.45473

Timestep Collection Time: 5.60613
Timestep Consumption Time: 0.86849
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.47463

Cumulative Model Updates: 28,828
Cumulative Timesteps: 480,853,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 480853812...
Checkpoint 480853812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.67654
Policy Entropy: 1.10943
Value Function Loss: 1.48247

Mean KL Divergence: 0.03347
SB3 Clip Fraction: 0.19569
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.09539

Collected Steps per Second: 8,837.24870
Overall Steps per Second: 7,514.17366

Timestep Collection Time: 5.65923
Timestep Consumption Time: 0.99646
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.65569

Cumulative Model Updates: 28,831
Cumulative Timesteps: 480,903,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.13102
Policy Entropy: 1.12738
Value Function Loss: 1.49406

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 8,758.49690
Overall Steps per Second: 7,675.78310

Timestep Collection Time: 5.71011
Timestep Consumption Time: 0.80544
PPO Batch Consumption Time: 0.04347
Total Iteration Time: 6.51556

Cumulative Model Updates: 28,834
Cumulative Timesteps: 480,953,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480953836...
Checkpoint 480953836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.59886
Policy Entropy: 1.11502
Value Function Loss: 1.51957

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.18367
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 8,706.86785
Overall Steps per Second: 7,671.97184

Timestep Collection Time: 5.74351
Timestep Consumption Time: 0.77476
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.51827

Cumulative Model Updates: 28,837
Cumulative Timesteps: 481,003,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.60816
Policy Entropy: 1.11092
Value Function Loss: 1.46158

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.10079

Collected Steps per Second: 8,852.51779
Overall Steps per Second: 7,731.74787

Timestep Collection Time: 5.64856
Timestep Consumption Time: 0.81880
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.46736

Cumulative Model Updates: 28,840
Cumulative Timesteps: 481,053,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 481053848...
Checkpoint 481053848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.68421
Policy Entropy: 1.11420
Value Function Loss: 1.45528

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.09301

Collected Steps per Second: 8,696.42305
Overall Steps per Second: 7,624.54352

Timestep Collection Time: 5.75294
Timestep Consumption Time: 0.80876
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.56170

Cumulative Model Updates: 28,843
Cumulative Timesteps: 481,103,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.58317
Policy Entropy: 1.12801
Value Function Loss: 1.42562

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.16213
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 8,691.07289
Overall Steps per Second: 7,599.66120

Timestep Collection Time: 5.75579
Timestep Consumption Time: 0.82661
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 6.58240

Cumulative Model Updates: 28,846
Cumulative Timesteps: 481,153,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 481153902...
Checkpoint 481153902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.00311
Policy Entropy: 1.10941
Value Function Loss: 1.42196

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 8,862.42885
Overall Steps per Second: 7,497.43909

Timestep Collection Time: 5.64450
Timestep Consumption Time: 1.02764
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.67214

Cumulative Model Updates: 28,849
Cumulative Timesteps: 481,203,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.99295
Policy Entropy: 1.11530
Value Function Loss: 1.50860

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.08224

Collected Steps per Second: 8,737.90792
Overall Steps per Second: 7,722.42297

Timestep Collection Time: 5.72425
Timestep Consumption Time: 0.75273
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 6.47698

Cumulative Model Updates: 28,852
Cumulative Timesteps: 481,253,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 481253944...
Checkpoint 481253944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.83296
Policy Entropy: 1.11812
Value Function Loss: 1.52756

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 8,738.76307
Overall Steps per Second: 7,537.66592

Timestep Collection Time: 5.72461
Timestep Consumption Time: 0.91219
PPO Batch Consumption Time: 0.05017
Total Iteration Time: 6.63680

Cumulative Model Updates: 28,855
Cumulative Timesteps: 481,303,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.03816
Policy Entropy: 1.12482
Value Function Loss: 1.57201

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15750
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.07760

Collected Steps per Second: 8,698.24596
Overall Steps per Second: 7,620.41268

Timestep Collection Time: 5.74852
Timestep Consumption Time: 0.81307
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.56159

Cumulative Model Updates: 28,858
Cumulative Timesteps: 481,353,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 481353972...
Checkpoint 481353972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.88503
Policy Entropy: 1.11073
Value Function Loss: 1.41601

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 8,632.01604
Overall Steps per Second: 7,614.20914

Timestep Collection Time: 5.79285
Timestep Consumption Time: 0.77434
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 6.56720

Cumulative Model Updates: 28,861
Cumulative Timesteps: 481,403,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.02095
Policy Entropy: 1.11049
Value Function Loss: 1.42578

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 8,721.41329
Overall Steps per Second: 7,563.87574

Timestep Collection Time: 5.73439
Timestep Consumption Time: 0.87756
PPO Batch Consumption Time: 0.04366
Total Iteration Time: 6.61195

Cumulative Model Updates: 28,864
Cumulative Timesteps: 481,453,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 481453988...
Checkpoint 481453988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.62282
Policy Entropy: 1.12137
Value Function Loss: 1.48390

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.06462

Collected Steps per Second: 8,715.01276
Overall Steps per Second: 7,611.58520

Timestep Collection Time: 5.74044
Timestep Consumption Time: 0.83217
PPO Batch Consumption Time: 0.04072
Total Iteration Time: 6.57261

Cumulative Model Updates: 28,867
Cumulative Timesteps: 481,504,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.20354
Policy Entropy: 1.12055
Value Function Loss: 1.62008

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.06276

Collected Steps per Second: 9,135.40489
Overall Steps per Second: 7,929.41552

Timestep Collection Time: 5.47584
Timestep Consumption Time: 0.83282
PPO Batch Consumption Time: 0.04185
Total Iteration Time: 6.30866

Cumulative Model Updates: 28,870
Cumulative Timesteps: 481,554,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 481554040...
Checkpoint 481554040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.41011
Policy Entropy: 1.12047
Value Function Loss: 1.54110

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.06304

Collected Steps per Second: 8,684.32102
Overall Steps per Second: 7,556.34907

Timestep Collection Time: 5.75773
Timestep Consumption Time: 0.85948
PPO Batch Consumption Time: 0.04614
Total Iteration Time: 6.61722

Cumulative Model Updates: 28,873
Cumulative Timesteps: 481,604,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.18549
Policy Entropy: 1.11364
Value Function Loss: 1.45842

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 8,789.67565
Overall Steps per Second: 7,706.63237

Timestep Collection Time: 5.69054
Timestep Consumption Time: 0.79971
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.49025

Cumulative Model Updates: 28,876
Cumulative Timesteps: 481,654,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 481654060...
Checkpoint 481654060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.21716
Policy Entropy: 1.13252
Value Function Loss: 1.41448

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.07493

Collected Steps per Second: 8,862.47546
Overall Steps per Second: 7,603.57734

Timestep Collection Time: 5.64380
Timestep Consumption Time: 0.93442
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 6.57822

Cumulative Model Updates: 28,879
Cumulative Timesteps: 481,704,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.84010
Policy Entropy: 1.12988
Value Function Loss: 1.40898

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.07032
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 8,817.26726
Overall Steps per Second: 7,741.95178

Timestep Collection Time: 5.67387
Timestep Consumption Time: 0.78807
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.46194

Cumulative Model Updates: 28,882
Cumulative Timesteps: 481,754,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 481754106...
Checkpoint 481754106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.65863
Policy Entropy: 1.12886
Value Function Loss: 1.52523

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.07243
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 8,977.60455
Overall Steps per Second: 7,740.74486

Timestep Collection Time: 5.57031
Timestep Consumption Time: 0.89005
PPO Batch Consumption Time: 0.04734
Total Iteration Time: 6.46036

Cumulative Model Updates: 28,885
Cumulative Timesteps: 481,804,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.26900
Policy Entropy: 1.12175
Value Function Loss: 1.49641

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.08352

Collected Steps per Second: 8,548.76757
Overall Steps per Second: 7,427.96507

Timestep Collection Time: 5.85067
Timestep Consumption Time: 0.88280
PPO Batch Consumption Time: 0.04492
Total Iteration Time: 6.73347

Cumulative Model Updates: 28,888
Cumulative Timesteps: 481,854,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 481854130...
Checkpoint 481854130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.24968
Policy Entropy: 1.13213
Value Function Loss: 1.54336

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 8,779.14137
Overall Steps per Second: 7,771.51286

Timestep Collection Time: 5.69737
Timestep Consumption Time: 0.73870
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.43607

Cumulative Model Updates: 28,891
Cumulative Timesteps: 481,904,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.01195
Policy Entropy: 1.12795
Value Function Loss: 1.51374

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.07437

Collected Steps per Second: 8,960.16775
Overall Steps per Second: 7,756.13698

Timestep Collection Time: 5.58315
Timestep Consumption Time: 0.86671
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.44986

Cumulative Model Updates: 28,894
Cumulative Timesteps: 481,954,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 481954174...
Checkpoint 481954174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.57008
Policy Entropy: 1.11786
Value Function Loss: 1.51871

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.07788

Collected Steps per Second: 8,793.78402
Overall Steps per Second: 7,657.25439

Timestep Collection Time: 5.68902
Timestep Consumption Time: 0.84439
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.53341

Cumulative Model Updates: 28,897
Cumulative Timesteps: 482,004,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.63464
Policy Entropy: 1.10618
Value Function Loss: 1.49727

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.17769
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.07726

Collected Steps per Second: 8,789.73073
Overall Steps per Second: 7,572.06107

Timestep Collection Time: 5.69028
Timestep Consumption Time: 0.91506
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.60534

Cumulative Model Updates: 28,900
Cumulative Timesteps: 482,054,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 482054218...
Checkpoint 482054218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.84341
Policy Entropy: 1.11489
Value Function Loss: 1.33823

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 8,790.88580
Overall Steps per Second: 7,631.36923

Timestep Collection Time: 5.69135
Timestep Consumption Time: 0.86475
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.55610

Cumulative Model Updates: 28,903
Cumulative Timesteps: 482,104,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.98405
Policy Entropy: 1.11034
Value Function Loss: 1.36930

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 8,725.93027
Overall Steps per Second: 7,682.10161

Timestep Collection Time: 5.73257
Timestep Consumption Time: 0.77893
PPO Batch Consumption Time: 0.04188
Total Iteration Time: 6.51150

Cumulative Model Updates: 28,906
Cumulative Timesteps: 482,154,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 482154272...
Checkpoint 482154272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.16252
Policy Entropy: 1.10549
Value Function Loss: 1.28328

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.08372
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 8,691.00198
Overall Steps per Second: 7,517.09406

Timestep Collection Time: 5.75423
Timestep Consumption Time: 0.89861
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.65284

Cumulative Model Updates: 28,909
Cumulative Timesteps: 482,204,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.84712
Policy Entropy: 1.08774
Value Function Loss: 1.33052

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.07196
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 8,670.52795
Overall Steps per Second: 7,641.98575

Timestep Collection Time: 5.76966
Timestep Consumption Time: 0.77654
PPO Batch Consumption Time: 0.04011
Total Iteration Time: 6.54620

Cumulative Model Updates: 28,912
Cumulative Timesteps: 482,254,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 482254308...
Checkpoint 482254308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.85013
Policy Entropy: 1.11058
Value Function Loss: 1.23193

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.06665
Value Function Update Magnitude: 0.08712

Collected Steps per Second: 8,483.85930
Overall Steps per Second: 7,385.23965

Timestep Collection Time: 5.89567
Timestep Consumption Time: 0.87703
PPO Batch Consumption Time: 0.04332
Total Iteration Time: 6.77270

Cumulative Model Updates: 28,915
Cumulative Timesteps: 482,304,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.62803
Policy Entropy: 1.10881
Value Function Loss: 1.30469

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.06346
Value Function Update Magnitude: 0.08493

Collected Steps per Second: 8,464.82034
Overall Steps per Second: 7,354.61783

Timestep Collection Time: 5.90940
Timestep Consumption Time: 0.89204
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.80144

Cumulative Model Updates: 28,918
Cumulative Timesteps: 482,354,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 482354348...
Checkpoint 482354348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.88680
Policy Entropy: 1.09922
Value Function Loss: 1.28073

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.15933
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.09317

Collected Steps per Second: 8,830.90729
Overall Steps per Second: 7,766.55097

Timestep Collection Time: 5.66284
Timestep Consumption Time: 0.77606
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.43889

Cumulative Model Updates: 28,921
Cumulative Timesteps: 482,404,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.67917
Policy Entropy: 1.08266
Value Function Loss: 1.24224

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.20536
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 9,045.44452
Overall Steps per Second: 7,821.61918

Timestep Collection Time: 5.53074
Timestep Consumption Time: 0.86538
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.39612

Cumulative Model Updates: 28,924
Cumulative Timesteps: 482,454,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 482454384...
Checkpoint 482454384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.80886
Policy Entropy: 1.09622
Value Function Loss: 1.20164

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.10923

Collected Steps per Second: 8,705.58928
Overall Steps per Second: 7,403.16157

Timestep Collection Time: 5.74413
Timestep Consumption Time: 1.01056
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.75468

Cumulative Model Updates: 28,927
Cumulative Timesteps: 482,504,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.42862
Policy Entropy: 1.11040
Value Function Loss: 1.24216

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 8,897.30710
Overall Steps per Second: 7,709.54705

Timestep Collection Time: 5.62305
Timestep Consumption Time: 0.86631
PPO Batch Consumption Time: 0.04345
Total Iteration Time: 6.48936

Cumulative Model Updates: 28,930
Cumulative Timesteps: 482,554,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 482554420...
Checkpoint 482554420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.55230
Policy Entropy: 1.06188
Value Function Loss: 1.42086

Mean KL Divergence: 0.09377
SB3 Clip Fraction: 0.31819
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 8,801.15807
Overall Steps per Second: 7,640.70034

Timestep Collection Time: 5.68289
Timestep Consumption Time: 0.86311
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.54600

Cumulative Model Updates: 28,933
Cumulative Timesteps: 482,604,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.42603
Policy Entropy: 1.08440
Value Function Loss: 1.44173

Mean KL Divergence: 0.04268
SB3 Clip Fraction: 0.25090
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 8,964.75133
Overall Steps per Second: 7,895.69812

Timestep Collection Time: 5.57985
Timestep Consumption Time: 0.75549
PPO Batch Consumption Time: 0.04351
Total Iteration Time: 6.33535

Cumulative Model Updates: 28,936
Cumulative Timesteps: 482,654,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 482654458...
Checkpoint 482654458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.05071
Policy Entropy: 1.04989
Value Function Loss: 1.46144

Mean KL Divergence: 0.07958
SB3 Clip Fraction: 0.32435
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.09762

Collected Steps per Second: 8,701.22355
Overall Steps per Second: 7,499.92940

Timestep Collection Time: 5.74724
Timestep Consumption Time: 0.92056
PPO Batch Consumption Time: 0.04543
Total Iteration Time: 6.66780

Cumulative Model Updates: 28,939
Cumulative Timesteps: 482,704,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.48565
Policy Entropy: 1.07450
Value Function Loss: 1.37654

Mean KL Divergence: 0.03630
SB3 Clip Fraction: 0.22794
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.08460

Collected Steps per Second: 8,676.53552
Overall Steps per Second: 7,613.00463

Timestep Collection Time: 5.76474
Timestep Consumption Time: 0.80533
PPO Batch Consumption Time: 0.04035
Total Iteration Time: 6.57007

Cumulative Model Updates: 28,942
Cumulative Timesteps: 482,754,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 482754484...
Checkpoint 482754484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.80779
Policy Entropy: 1.04050
Value Function Loss: 1.29375

Mean KL Divergence: 0.07448
SB3 Clip Fraction: 0.31545
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 8,635.82658
Overall Steps per Second: 7,564.49630

Timestep Collection Time: 5.79076
Timestep Consumption Time: 0.82012
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.61088

Cumulative Model Updates: 28,945
Cumulative Timesteps: 482,804,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.38280
Policy Entropy: 1.06570
Value Function Loss: 1.31387

Mean KL Divergence: 0.03331
SB3 Clip Fraction: 0.19939
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 8,832.28088
Overall Steps per Second: 7,660.47005

Timestep Collection Time: 5.66241
Timestep Consumption Time: 0.86617
PPO Batch Consumption Time: 0.04843
Total Iteration Time: 6.52858

Cumulative Model Updates: 28,948
Cumulative Timesteps: 482,854,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 482854504...
Checkpoint 482854504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.00362
Policy Entropy: 1.05569
Value Function Loss: 1.36010

Mean KL Divergence: 0.03113
SB3 Clip Fraction: 0.20751
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 8,604.20810
Overall Steps per Second: 7,516.40166

Timestep Collection Time: 5.81460
Timestep Consumption Time: 0.84151
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.65611

Cumulative Model Updates: 28,951
Cumulative Timesteps: 482,904,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.10345
Policy Entropy: 1.04355
Value Function Loss: 1.36790

Mean KL Divergence: 0.03777
SB3 Clip Fraction: 0.24914
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 8,721.90675
Overall Steps per Second: 7,540.60920

Timestep Collection Time: 5.73498
Timestep Consumption Time: 0.89843
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.63342

Cumulative Model Updates: 28,954
Cumulative Timesteps: 482,954,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 482954554...
Checkpoint 482954554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.70465
Policy Entropy: 1.05048
Value Function Loss: 1.32489

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 8,531.74882
Overall Steps per Second: 7,448.54567

Timestep Collection Time: 5.86046
Timestep Consumption Time: 0.85226
PPO Batch Consumption Time: 0.04739
Total Iteration Time: 6.71272

Cumulative Model Updates: 28,957
Cumulative Timesteps: 483,004,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.97530
Policy Entropy: 1.06770
Value Function Loss: 1.34642

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16663
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 8,752.68437
Overall Steps per Second: 7,768.80641

Timestep Collection Time: 5.71368
Timestep Consumption Time: 0.72361
PPO Batch Consumption Time: 0.04008
Total Iteration Time: 6.43728

Cumulative Model Updates: 28,960
Cumulative Timesteps: 483,054,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 483054564...
Checkpoint 483054564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.40233
Policy Entropy: 1.04807
Value Function Loss: 1.41702

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.16981
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 8,631.43728
Overall Steps per Second: 7,412.83140

Timestep Collection Time: 5.79278
Timestep Consumption Time: 0.95228
PPO Batch Consumption Time: 0.04799
Total Iteration Time: 6.74506

Cumulative Model Updates: 28,963
Cumulative Timesteps: 483,104,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.95202
Policy Entropy: 1.04420
Value Function Loss: 1.48104

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.10920

Collected Steps per Second: 8,541.29734
Overall Steps per Second: 7,458.90533

Timestep Collection Time: 5.85578
Timestep Consumption Time: 0.84976
PPO Batch Consumption Time: 0.04254
Total Iteration Time: 6.70554

Cumulative Model Updates: 28,966
Cumulative Timesteps: 483,154,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 483154580...
Checkpoint 483154580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.94503
Policy Entropy: 1.05429
Value Function Loss: 1.49796

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.16792
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 8,274.92741
Overall Steps per Second: 7,394.36046

Timestep Collection Time: 6.04549
Timestep Consumption Time: 0.71994
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.76543

Cumulative Model Updates: 28,969
Cumulative Timesteps: 483,204,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.37666
Policy Entropy: 1.05572
Value Function Loss: 1.56337

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.16002
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.08474

Collected Steps per Second: 8,703.44595
Overall Steps per Second: 7,599.88244

Timestep Collection Time: 5.74807
Timestep Consumption Time: 0.83467
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.58273

Cumulative Model Updates: 28,972
Cumulative Timesteps: 483,254,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 483254634...
Checkpoint 483254634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.86076
Policy Entropy: 1.05419
Value Function Loss: 1.46746

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.17734
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 8,588.71881
Overall Steps per Second: 7,593.63351

Timestep Collection Time: 5.82322
Timestep Consumption Time: 0.76309
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.58631

Cumulative Model Updates: 28,975
Cumulative Timesteps: 483,304,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.73091
Policy Entropy: 1.04165
Value Function Loss: 1.42225

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.20975
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.08150

Collected Steps per Second: 9,016.38908
Overall Steps per Second: 7,705.04553

Timestep Collection Time: 5.54634
Timestep Consumption Time: 0.94395
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.49029

Cumulative Model Updates: 28,978
Cumulative Timesteps: 483,354,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 483354656...
Checkpoint 483354656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.39402
Policy Entropy: 1.05327
Value Function Loss: 1.25454

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.17743
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 8,551.21552
Overall Steps per Second: 7,486.14289

Timestep Collection Time: 5.84946
Timestep Consumption Time: 0.83222
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.68168

Cumulative Model Updates: 28,981
Cumulative Timesteps: 483,404,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.70203
Policy Entropy: 1.05252
Value Function Loss: 1.34993

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 8,567.93932
Overall Steps per Second: 7,569.56305

Timestep Collection Time: 5.83874
Timestep Consumption Time: 0.77009
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.60884

Cumulative Model Updates: 28,984
Cumulative Timesteps: 483,454,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 483454702...
Checkpoint 483454702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.07775
Policy Entropy: 1.02789
Value Function Loss: 1.40425

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.22373
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.08534

Collected Steps per Second: 8,817.45314
Overall Steps per Second: 7,600.18701

Timestep Collection Time: 5.67284
Timestep Consumption Time: 0.90858
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.58142

Cumulative Model Updates: 28,987
Cumulative Timesteps: 483,504,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.65318
Policy Entropy: 1.04482
Value Function Loss: 1.45474

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.19885
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 8,794.85621
Overall Steps per Second: 7,634.65584

Timestep Collection Time: 5.68628
Timestep Consumption Time: 0.86412
PPO Batch Consumption Time: 0.04268
Total Iteration Time: 6.55039

Cumulative Model Updates: 28,990
Cumulative Timesteps: 483,554,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 483554732...
Checkpoint 483554732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.00511
Policy Entropy: 1.04399
Value Function Loss: 1.47416

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.19094
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 8,711.15093
Overall Steps per Second: 7,567.11411

Timestep Collection Time: 5.74184
Timestep Consumption Time: 0.86808
PPO Batch Consumption Time: 0.04096
Total Iteration Time: 6.60992

Cumulative Model Updates: 28,993
Cumulative Timesteps: 483,604,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.65579
Policy Entropy: 1.03133
Value Function Loss: 1.38848

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.19290
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 8,299.66698
Overall Steps per Second: 7,275.03453

Timestep Collection Time: 6.02795
Timestep Consumption Time: 0.84899
PPO Batch Consumption Time: 0.04112
Total Iteration Time: 6.87694

Cumulative Model Updates: 28,996
Cumulative Timesteps: 483,654,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 483654780...
Checkpoint 483654780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.82010
Policy Entropy: 1.01314
Value Function Loss: 1.35114

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.23949
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.10627

Collected Steps per Second: 8,631.49645
Overall Steps per Second: 7,620.69815

Timestep Collection Time: 5.79297
Timestep Consumption Time: 0.76837
PPO Batch Consumption Time: 0.04592
Total Iteration Time: 6.56134

Cumulative Model Updates: 28,999
Cumulative Timesteps: 483,704,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.72724
Policy Entropy: 1.02278
Value Function Loss: 1.33170

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.16286
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 8,730.28074
Overall Steps per Second: 7,571.88094

Timestep Collection Time: 5.72880
Timestep Consumption Time: 0.87643
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.60523

Cumulative Model Updates: 29,002
Cumulative Timesteps: 483,754,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 483754796...
Checkpoint 483754796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.05783
Policy Entropy: 1.02943
Value Function Loss: 1.35645

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.17724
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 8,722.13411
Overall Steps per Second: 7,550.17592

Timestep Collection Time: 5.73461
Timestep Consumption Time: 0.89014
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.62475

Cumulative Model Updates: 29,005
Cumulative Timesteps: 483,804,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.14536
Policy Entropy: 1.00893
Value Function Loss: 1.37720

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.19075
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.11092

Collected Steps per Second: 8,916.20546
Overall Steps per Second: 7,738.89363

Timestep Collection Time: 5.61001
Timestep Consumption Time: 0.85345
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.46346

Cumulative Model Updates: 29,008
Cumulative Timesteps: 483,854,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 483854834...
Checkpoint 483854834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.43890
Policy Entropy: 0.99310
Value Function Loss: 1.22119

Mean KL Divergence: 0.03102
SB3 Clip Fraction: 0.22305
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 8,522.57987
Overall Steps per Second: 7,477.66445

Timestep Collection Time: 5.86865
Timestep Consumption Time: 0.82007
PPO Batch Consumption Time: 0.04084
Total Iteration Time: 6.68872

Cumulative Model Updates: 29,011
Cumulative Timesteps: 483,904,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.85619
Policy Entropy: 1.01041
Value Function Loss: 1.24048

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 8,655.53479
Overall Steps per Second: 7,641.66094

Timestep Collection Time: 5.77919
Timestep Consumption Time: 0.76677
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.54596

Cumulative Model Updates: 29,014
Cumulative Timesteps: 483,954,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 483954872...
Checkpoint 483954872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.49288
Policy Entropy: 1.00697
Value Function Loss: 1.22850

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.18249
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 8,710.51657
Overall Steps per Second: 7,453.66321

Timestep Collection Time: 5.74042
Timestep Consumption Time: 0.96796
PPO Batch Consumption Time: 0.05146
Total Iteration Time: 6.70838

Cumulative Model Updates: 29,017
Cumulative Timesteps: 484,004,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.86087
Policy Entropy: 0.99650
Value Function Loss: 1.25369

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 8,568.01983
Overall Steps per Second: 7,341.44890

Timestep Collection Time: 5.83659
Timestep Consumption Time: 0.97515
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 6.81173

Cumulative Model Updates: 29,020
Cumulative Timesteps: 484,054,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 484054882...
Checkpoint 484054882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.69246
Policy Entropy: 0.96958
Value Function Loss: 1.19582

Mean KL Divergence: 0.04114
SB3 Clip Fraction: 0.27553
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.10119

Collected Steps per Second: 8,233.46253
Overall Steps per Second: 7,312.59030

Timestep Collection Time: 6.07278
Timestep Consumption Time: 0.76474
PPO Batch Consumption Time: 0.04160
Total Iteration Time: 6.83752

Cumulative Model Updates: 29,023
Cumulative Timesteps: 484,104,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.31850
Policy Entropy: 1.00746
Value Function Loss: 1.20202

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.19985
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.09266

Collected Steps per Second: 8,560.64128
Overall Steps per Second: 7,434.53828

Timestep Collection Time: 5.84209
Timestep Consumption Time: 0.88490
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.72698

Cumulative Model Updates: 29,026
Cumulative Timesteps: 484,154,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 484154894...
Checkpoint 484154894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.58094
Policy Entropy: 0.98665
Value Function Loss: 1.33329

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.19007
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 8,627.46837
Overall Steps per Second: 7,553.39034

Timestep Collection Time: 5.79591
Timestep Consumption Time: 0.82417
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.62007

Cumulative Model Updates: 29,029
Cumulative Timesteps: 484,204,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.20225
Policy Entropy: 0.97230
Value Function Loss: 1.29762

Mean KL Divergence: 0.03195
SB3 Clip Fraction: 0.24787
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.06905

Collected Steps per Second: 9,040.26045
Overall Steps per Second: 7,830.75780

Timestep Collection Time: 5.53214
Timestep Consumption Time: 0.85447
PPO Batch Consumption Time: 0.04153
Total Iteration Time: 6.38661

Cumulative Model Updates: 29,032
Cumulative Timesteps: 484,254,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 484254910...
Checkpoint 484254910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.21319
Policy Entropy: 0.97910
Value Function Loss: 1.33774

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.20015
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06667

Collected Steps per Second: 8,987.89045
Overall Steps per Second: 7,715.53886

Timestep Collection Time: 5.56349
Timestep Consumption Time: 0.91746
PPO Batch Consumption Time: 0.05004
Total Iteration Time: 6.48095

Cumulative Model Updates: 29,035
Cumulative Timesteps: 484,304,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.89327
Policy Entropy: 0.99200
Value Function Loss: 1.20310

Mean KL Divergence: 0.02538
SB3 Clip Fraction: 0.22852
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.07459

Collected Steps per Second: 8,605.53786
Overall Steps per Second: 7,574.14092

Timestep Collection Time: 5.81091
Timestep Consumption Time: 0.79129
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 6.60220

Cumulative Model Updates: 29,038
Cumulative Timesteps: 484,354,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 484354920...
Checkpoint 484354920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.48310
Policy Entropy: 0.95520
Value Function Loss: 1.26710

Mean KL Divergence: 0.03413
SB3 Clip Fraction: 0.22876
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 9,093.72218
Overall Steps per Second: 7,849.66747

Timestep Collection Time: 5.49962
Timestep Consumption Time: 0.87161
PPO Batch Consumption Time: 0.04884
Total Iteration Time: 6.37123

Cumulative Model Updates: 29,041
Cumulative Timesteps: 484,404,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.50990
Policy Entropy: 0.97219
Value Function Loss: 1.29433

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.23103
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 9,210.69619
Overall Steps per Second: 7,905.36510

Timestep Collection Time: 5.43064
Timestep Consumption Time: 0.89671
PPO Batch Consumption Time: 0.04813
Total Iteration Time: 6.32735

Cumulative Model Updates: 29,044
Cumulative Timesteps: 484,454,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 484454952...
Checkpoint 484454952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.94748
Policy Entropy: 0.96496
Value Function Loss: 1.44282

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.19621
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 8,799.20009
Overall Steps per Second: 7,777.96069

Timestep Collection Time: 5.68574
Timestep Consumption Time: 0.74653
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.43228

Cumulative Model Updates: 29,047
Cumulative Timesteps: 484,504,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.83309
Policy Entropy: 0.95152
Value Function Loss: 1.38974

Mean KL Divergence: 0.02697
SB3 Clip Fraction: 0.21234
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.05304

Collected Steps per Second: 8,327.13743
Overall Steps per Second: 7,299.86187

Timestep Collection Time: 6.00639
Timestep Consumption Time: 0.84525
PPO Batch Consumption Time: 0.04425
Total Iteration Time: 6.85164

Cumulative Model Updates: 29,050
Cumulative Timesteps: 484,554,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 484554998...
Checkpoint 484554998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.79079
Policy Entropy: 0.94243
Value Function Loss: 1.29410

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.23204
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 8,579.83729
Overall Steps per Second: 7,486.22274

Timestep Collection Time: 5.83065
Timestep Consumption Time: 0.85176
PPO Batch Consumption Time: 0.04006
Total Iteration Time: 6.68241

Cumulative Model Updates: 29,053
Cumulative Timesteps: 484,605,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.95966
Policy Entropy: 0.96126
Value Function Loss: 1.25399

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.19445
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 9,045.21646
Overall Steps per Second: 7,834.29314

Timestep Collection Time: 5.52999
Timestep Consumption Time: 0.85475
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 6.38475

Cumulative Model Updates: 29,056
Cumulative Timesteps: 484,655,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 484655044...
Checkpoint 484655044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.68375
Policy Entropy: 0.96562
Value Function Loss: 1.31177

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.21553
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 8,905.39650
Overall Steps per Second: 7,816.21734

Timestep Collection Time: 5.61772
Timestep Consumption Time: 0.78282
PPO Batch Consumption Time: 0.04023
Total Iteration Time: 6.40054

Cumulative Model Updates: 29,059
Cumulative Timesteps: 484,705,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.36571
Policy Entropy: 0.94647
Value Function Loss: 1.29021

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.17851
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 8,614.28835
Overall Steps per Second: 7,617.88633

Timestep Collection Time: 5.80431
Timestep Consumption Time: 0.75919
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.56350

Cumulative Model Updates: 29,062
Cumulative Timesteps: 484,755,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 484755072...
Checkpoint 484755072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.45884
Policy Entropy: 0.93393
Value Function Loss: 1.20161

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.23748
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.08318

Collected Steps per Second: 8,514.15571
Overall Steps per Second: 7,393.53059

Timestep Collection Time: 5.87328
Timestep Consumption Time: 0.89020
PPO Batch Consumption Time: 0.04930
Total Iteration Time: 6.76348

Cumulative Model Updates: 29,065
Cumulative Timesteps: 484,805,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.65857
Policy Entropy: 0.95902
Value Function Loss: 1.17490

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 8,747.97039
Overall Steps per Second: 7,606.71938

Timestep Collection Time: 5.71767
Timestep Consumption Time: 0.85783
PPO Batch Consumption Time: 0.05093
Total Iteration Time: 6.57550

Cumulative Model Updates: 29,068
Cumulative Timesteps: 484,855,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 484855096...
Checkpoint 484855096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.70160
Policy Entropy: 0.96374
Value Function Loss: 1.22373

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.16155
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 8,822.05385
Overall Steps per Second: 7,700.94456

Timestep Collection Time: 5.66943
Timestep Consumption Time: 0.82536
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.49479

Cumulative Model Updates: 29,071
Cumulative Timesteps: 484,905,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.74036
Policy Entropy: 0.94736
Value Function Loss: 1.27519

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.19964
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 8,547.91543
Overall Steps per Second: 7,374.46775

Timestep Collection Time: 5.85172
Timestep Consumption Time: 0.93114
PPO Batch Consumption Time: 0.04991
Total Iteration Time: 6.78286

Cumulative Model Updates: 29,074
Cumulative Timesteps: 484,955,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 484955132...
Checkpoint 484955132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.61743
Policy Entropy: 0.95500
Value Function Loss: 1.27881

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.21521
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 8,299.92993
Overall Steps per Second: 7,345.68374

Timestep Collection Time: 6.02656
Timestep Consumption Time: 0.78288
PPO Batch Consumption Time: 0.03931
Total Iteration Time: 6.80944

Cumulative Model Updates: 29,077
Cumulative Timesteps: 485,005,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.70447
Policy Entropy: 0.95477
Value Function Loss: 1.32869

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.06751

Collected Steps per Second: 8,716.66538
Overall Steps per Second: 7,528.91782

Timestep Collection Time: 5.73958
Timestep Consumption Time: 0.90547
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.64505

Cumulative Model Updates: 29,080
Cumulative Timesteps: 485,055,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 485055182...
Checkpoint 485055182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.08982
Policy Entropy: 0.96859
Value Function Loss: 1.34256

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.08120

Collected Steps per Second: 8,624.53199
Overall Steps per Second: 7,575.86257

Timestep Collection Time: 5.79927
Timestep Consumption Time: 0.80275
PPO Batch Consumption Time: 0.04452
Total Iteration Time: 6.60202

Cumulative Model Updates: 29,083
Cumulative Timesteps: 485,105,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.92650
Policy Entropy: 0.98158
Value Function Loss: 1.34924

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.08740

Collected Steps per Second: 8,669.01220
Overall Steps per Second: 7,638.82306

Timestep Collection Time: 5.77044
Timestep Consumption Time: 0.77821
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 6.54865

Cumulative Model Updates: 29,086
Cumulative Timesteps: 485,155,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 485155222...
Checkpoint 485155222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.25476
Policy Entropy: 0.97576
Value Function Loss: 1.35570

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.16212
Policy Update Magnitude: 0.08046
Value Function Update Magnitude: 0.08794

Collected Steps per Second: 8,991.57788
Overall Steps per Second: 7,816.56612

Timestep Collection Time: 5.56321
Timestep Consumption Time: 0.83628
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.39949

Cumulative Model Updates: 29,089
Cumulative Timesteps: 485,205,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.97830
Policy Entropy: 0.97033
Value Function Loss: 1.37190

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.17389
Policy Update Magnitude: 0.07663
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 8,464.03467
Overall Steps per Second: 7,397.89700

Timestep Collection Time: 5.90735
Timestep Consumption Time: 0.85133
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 6.75868

Cumulative Model Updates: 29,092
Cumulative Timesteps: 485,255,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 485255244...
Checkpoint 485255244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.01541
Policy Entropy: 0.97857
Value Function Loss: 1.43879

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.18297
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 8,947.92027
Overall Steps per Second: 7,784.77100

Timestep Collection Time: 5.59147
Timestep Consumption Time: 0.83544
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.42691

Cumulative Model Updates: 29,095
Cumulative Timesteps: 485,305,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.48299
Policy Entropy: 0.98220
Value Function Loss: 1.47889

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15969
Policy Update Magnitude: 0.07505
Value Function Update Magnitude: 0.09178

Collected Steps per Second: 8,870.14317
Overall Steps per Second: 7,704.81646

Timestep Collection Time: 5.64050
Timestep Consumption Time: 0.85311
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.49360

Cumulative Model Updates: 29,098
Cumulative Timesteps: 485,355,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 485355308...
Checkpoint 485355308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.47584
Policy Entropy: 0.99264
Value Function Loss: 1.49333

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.17865
Policy Update Magnitude: 0.07915
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 8,757.95113
Overall Steps per Second: 7,621.59278

Timestep Collection Time: 5.71070
Timestep Consumption Time: 0.85145
PPO Batch Consumption Time: 0.04583
Total Iteration Time: 6.56215

Cumulative Model Updates: 29,101
Cumulative Timesteps: 485,405,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.14565
Policy Entropy: 0.99031
Value Function Loss: 1.45117

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.20668
Policy Update Magnitude: 0.07462
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 8,608.53595
Overall Steps per Second: 7,441.34379

Timestep Collection Time: 5.81191
Timestep Consumption Time: 0.91161
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.72352

Cumulative Model Updates: 29,104
Cumulative Timesteps: 485,455,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 485455354...
Checkpoint 485455354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.03766
Policy Entropy: 1.01225
Value Function Loss: 1.41081

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.20709
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 8,836.58524
Overall Steps per Second: 7,735.91469

Timestep Collection Time: 5.65965
Timestep Consumption Time: 0.80526
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.46491

Cumulative Model Updates: 29,107
Cumulative Timesteps: 485,505,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.11818
Policy Entropy: 1.03190
Value Function Loss: 1.41040

Mean KL Divergence: 0.02733
SB3 Clip Fraction: 0.20893
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.06868

Collected Steps per Second: 8,759.07423
Overall Steps per Second: 7,655.68953

Timestep Collection Time: 5.71019
Timestep Consumption Time: 0.82299
PPO Batch Consumption Time: 0.05129
Total Iteration Time: 6.53318

Cumulative Model Updates: 29,110
Cumulative Timesteps: 485,555,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 485555382...
Checkpoint 485555382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.81030
Policy Entropy: 1.02793
Value Function Loss: 1.37407

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.19637
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 8,863.20123
Overall Steps per Second: 7,657.75928

Timestep Collection Time: 5.64311
Timestep Consumption Time: 0.88831
PPO Batch Consumption Time: 0.04221
Total Iteration Time: 6.53141

Cumulative Model Updates: 29,113
Cumulative Timesteps: 485,605,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.84900
Policy Entropy: 1.01597
Value Function Loss: 1.34508

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.24108
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 8,642.50677
Overall Steps per Second: 7,560.63619

Timestep Collection Time: 5.78536
Timestep Consumption Time: 0.82784
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.61320

Cumulative Model Updates: 29,116
Cumulative Timesteps: 485,655,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 485655398...
Checkpoint 485655398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.47248
Policy Entropy: 1.03755
Value Function Loss: 1.43658

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.19759
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 8,711.25110
Overall Steps per Second: 7,577.51576

Timestep Collection Time: 5.74131
Timestep Consumption Time: 0.85901
PPO Batch Consumption Time: 0.04340
Total Iteration Time: 6.60032

Cumulative Model Updates: 29,119
Cumulative Timesteps: 485,705,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.82679
Policy Entropy: 1.05859
Value Function Loss: 1.44850

Mean KL Divergence: 0.03513
SB3 Clip Fraction: 0.24801
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 8,787.55248
Overall Steps per Second: 7,665.03423

Timestep Collection Time: 5.69191
Timestep Consumption Time: 0.83356
PPO Batch Consumption Time: 0.04659
Total Iteration Time: 6.52548

Cumulative Model Updates: 29,122
Cumulative Timesteps: 485,755,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 485755430...
Checkpoint 485755430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.03859
Policy Entropy: 1.04959
Value Function Loss: 1.45574

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.18971
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 8,667.31458
Overall Steps per Second: 7,633.21012

Timestep Collection Time: 5.76926
Timestep Consumption Time: 0.78159
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.55085

Cumulative Model Updates: 29,125
Cumulative Timesteps: 485,805,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.71255
Policy Entropy: 1.04554
Value Function Loss: 1.36664

Mean KL Divergence: 0.03506
SB3 Clip Fraction: 0.21766
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.07616

Collected Steps per Second: 8,724.57243
Overall Steps per Second: 7,549.99335

Timestep Collection Time: 5.73415
Timestep Consumption Time: 0.89208
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.62623

Cumulative Model Updates: 29,128
Cumulative Timesteps: 485,855,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 485855462...
Checkpoint 485855462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.83091
Policy Entropy: 1.05973
Value Function Loss: 1.41095

Mean KL Divergence: 0.03136
SB3 Clip Fraction: 0.20583
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.08315

Collected Steps per Second: 8,596.41332
Overall Steps per Second: 7,403.53447

Timestep Collection Time: 5.81661
Timestep Consumption Time: 0.93719
PPO Batch Consumption Time: 0.04916
Total Iteration Time: 6.75380

Cumulative Model Updates: 29,131
Cumulative Timesteps: 485,905,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.61352
Policy Entropy: 1.07859
Value Function Loss: 1.48281

Mean KL Divergence: 0.03198
SB3 Clip Fraction: 0.22436
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.07508

Collected Steps per Second: 9,035.12181
Overall Steps per Second: 7,725.97846

Timestep Collection Time: 5.53396
Timestep Consumption Time: 0.93771
PPO Batch Consumption Time: 0.05035
Total Iteration Time: 6.47167

Cumulative Model Updates: 29,134
Cumulative Timesteps: 485,955,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 485955464...
Checkpoint 485955464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.08822
Policy Entropy: 1.05801
Value Function Loss: 1.48338

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.16467
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 8,651.91414
Overall Steps per Second: 7,530.13046

Timestep Collection Time: 5.78207
Timestep Consumption Time: 0.86137
PPO Batch Consumption Time: 0.04628
Total Iteration Time: 6.64344

Cumulative Model Updates: 29,137
Cumulative Timesteps: 486,005,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.65508
Policy Entropy: 1.05693
Value Function Loss: 1.48820

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.18775
Policy Update Magnitude: 0.06731
Value Function Update Magnitude: 0.10069

Collected Steps per Second: 8,940.56791
Overall Steps per Second: 7,861.76657

Timestep Collection Time: 5.59472
Timestep Consumption Time: 0.76771
PPO Batch Consumption Time: 0.04610
Total Iteration Time: 6.36244

Cumulative Model Updates: 29,140
Cumulative Timesteps: 486,055,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 486055510...
Checkpoint 486055510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.83845
Policy Entropy: 1.07936
Value Function Loss: 1.46265

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.09524

Collected Steps per Second: 9,262.81175
Overall Steps per Second: 7,986.94124

Timestep Collection Time: 5.39944
Timestep Consumption Time: 0.86253
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 6.26197

Cumulative Model Updates: 29,143
Cumulative Timesteps: 486,105,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.98744
Policy Entropy: 1.07550
Value Function Loss: 1.44024

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.06192
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 8,824.43878
Overall Steps per Second: 7,660.47155

Timestep Collection Time: 5.66654
Timestep Consumption Time: 0.86100
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.52754

Cumulative Model Updates: 29,146
Cumulative Timesteps: 486,155,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 486155528...
Checkpoint 486155528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.01839
Policy Entropy: 1.06329
Value Function Loss: 1.42894

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.16849
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 9,001.88771
Overall Steps per Second: 7,892.98195

Timestep Collection Time: 5.55572
Timestep Consumption Time: 0.78054
PPO Batch Consumption Time: 0.04392
Total Iteration Time: 6.33626

Cumulative Model Updates: 29,149
Cumulative Timesteps: 486,205,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.25067
Policy Entropy: 1.06157
Value Function Loss: 1.38577

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.17471
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 9,094.72176
Overall Steps per Second: 7,791.26588

Timestep Collection Time: 5.49769
Timestep Consumption Time: 0.91975
PPO Batch Consumption Time: 0.04998
Total Iteration Time: 6.41744

Cumulative Model Updates: 29,152
Cumulative Timesteps: 486,255,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486255540...
Checkpoint 486255540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.31341
Policy Entropy: 1.07013
Value Function Loss: 1.39956

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.11128

Collected Steps per Second: 8,601.39306
Overall Steps per Second: 7,497.24499

Timestep Collection Time: 5.81673
Timestep Consumption Time: 0.85665
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 6.67338

Cumulative Model Updates: 29,155
Cumulative Timesteps: 486,305,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.25516
Policy Entropy: 1.08459
Value Function Loss: 1.43487

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16327
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 9,020.34127
Overall Steps per Second: 7,786.17546

Timestep Collection Time: 5.54480
Timestep Consumption Time: 0.87889
PPO Batch Consumption Time: 0.04315
Total Iteration Time: 6.42369

Cumulative Model Updates: 29,158
Cumulative Timesteps: 486,355,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 486355588...
Checkpoint 486355588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.27298
Policy Entropy: 1.06458
Value Function Loss: 1.44959

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.16144
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.10427

Collected Steps per Second: 8,442.35025
Overall Steps per Second: 7,366.01475

Timestep Collection Time: 5.92371
Timestep Consumption Time: 0.86558
PPO Batch Consumption Time: 0.04779
Total Iteration Time: 6.78929

Cumulative Model Updates: 29,161
Cumulative Timesteps: 486,405,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.24291
Policy Entropy: 1.07906
Value Function Loss: 1.47140

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.10759

Collected Steps per Second: 8,697.42306
Overall Steps per Second: 7,630.25627

Timestep Collection Time: 5.74952
Timestep Consumption Time: 0.80413
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.55365

Cumulative Model Updates: 29,164
Cumulative Timesteps: 486,455,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 486455604...
Checkpoint 486455604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.34245
Policy Entropy: 1.08483
Value Function Loss: 1.38523

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.11191

Collected Steps per Second: 8,890.45232
Overall Steps per Second: 7,671.98690

Timestep Collection Time: 5.62694
Timestep Consumption Time: 0.89367
PPO Batch Consumption Time: 0.04739
Total Iteration Time: 6.52061

Cumulative Model Updates: 29,167
Cumulative Timesteps: 486,505,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.67818
Policy Entropy: 1.09572
Value Function Loss: 1.44707

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.10143

Collected Steps per Second: 8,812.10654
Overall Steps per Second: 7,700.67821

Timestep Collection Time: 5.67401
Timestep Consumption Time: 0.81892
PPO Batch Consumption Time: 0.04318
Total Iteration Time: 6.49293

Cumulative Model Updates: 29,170
Cumulative Timesteps: 486,555,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486555630...
Checkpoint 486555630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.08627
Policy Entropy: 1.08435
Value Function Loss: 1.46451

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.08713

Collected Steps per Second: 8,649.51098
Overall Steps per Second: 7,539.80598

Timestep Collection Time: 5.78391
Timestep Consumption Time: 0.85127
PPO Batch Consumption Time: 0.04596
Total Iteration Time: 6.63518

Cumulative Model Updates: 29,173
Cumulative Timesteps: 486,605,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.91377
Policy Entropy: 1.07949
Value Function Loss: 1.56940

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.19593
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.08755

Collected Steps per Second: 8,445.71050
Overall Steps per Second: 7,389.13607

Timestep Collection Time: 5.92253
Timestep Consumption Time: 0.84686
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.76940

Cumulative Model Updates: 29,176
Cumulative Timesteps: 486,655,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 486655678...
Checkpoint 486655678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.44584
Policy Entropy: 1.08622
Value Function Loss: 1.53621

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.09511

Collected Steps per Second: 8,881.09857
Overall Steps per Second: 7,819.11518

Timestep Collection Time: 5.63309
Timestep Consumption Time: 0.76508
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.39817

Cumulative Model Updates: 29,179
Cumulative Timesteps: 486,705,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.79963
Policy Entropy: 1.08730
Value Function Loss: 1.48739

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.06702
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 8,769.01802
Overall Steps per Second: 7,630.43761

Timestep Collection Time: 5.70395
Timestep Consumption Time: 0.85112
PPO Batch Consumption Time: 0.04010
Total Iteration Time: 6.55506

Cumulative Model Updates: 29,182
Cumulative Timesteps: 486,755,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 486755724...
Checkpoint 486755724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.33372
Policy Entropy: 1.06792
Value Function Loss: 1.41604

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.17157
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 8,503.85960
Overall Steps per Second: 7,433.67598

Timestep Collection Time: 5.88251
Timestep Consumption Time: 0.84687
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.72938

Cumulative Model Updates: 29,185
Cumulative Timesteps: 486,805,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.12618
Policy Entropy: 1.06859
Value Function Loss: 1.31831

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 8,305.55571
Overall Steps per Second: 7,356.79129

Timestep Collection Time: 6.02223
Timestep Consumption Time: 0.77665
PPO Batch Consumption Time: 0.04861
Total Iteration Time: 6.79889

Cumulative Model Updates: 29,188
Cumulative Timesteps: 486,855,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 486855766...
Checkpoint 486855766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.59904
Policy Entropy: 1.07328
Value Function Loss: 1.28148

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.09396

Collected Steps per Second: 8,580.44265
Overall Steps per Second: 7,481.63674

Timestep Collection Time: 5.82907
Timestep Consumption Time: 0.85610
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.68517

Cumulative Model Updates: 29,191
Cumulative Timesteps: 486,905,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.82691
Policy Entropy: 1.08030
Value Function Loss: 1.27122

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.06812
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 8,719.30984
Overall Steps per Second: 7,667.34260

Timestep Collection Time: 5.73738
Timestep Consumption Time: 0.78717
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.52456

Cumulative Model Updates: 29,194
Cumulative Timesteps: 486,955,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 486955808...
Checkpoint 486955808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.90778
Policy Entropy: 1.08801
Value Function Loss: 1.34346

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 9,152.97165
Overall Steps per Second: 7,924.93402

Timestep Collection Time: 5.46402
Timestep Consumption Time: 0.84670
PPO Batch Consumption Time: 0.04092
Total Iteration Time: 6.31071

Cumulative Model Updates: 29,197
Cumulative Timesteps: 487,005,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.45681
Policy Entropy: 1.08853
Value Function Loss: 1.38583

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.07545
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 8,627.43164
Overall Steps per Second: 7,483.23407

Timestep Collection Time: 5.79871
Timestep Consumption Time: 0.88663
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.68534

Cumulative Model Updates: 29,200
Cumulative Timesteps: 487,055,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 487055848...
Checkpoint 487055848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.17079
Policy Entropy: 1.07918
Value Function Loss: 1.44223

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 8,815.98617
Overall Steps per Second: 7,752.42065

Timestep Collection Time: 5.67469
Timestep Consumption Time: 0.77852
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 6.45321

Cumulative Model Updates: 29,203
Cumulative Timesteps: 487,105,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.02668
Policy Entropy: 1.09047
Value Function Loss: 1.44497

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 8,799.96471
Overall Steps per Second: 7,678.79998

Timestep Collection Time: 5.68502
Timestep Consumption Time: 0.83006
PPO Batch Consumption Time: 0.04125
Total Iteration Time: 6.51508

Cumulative Model Updates: 29,206
Cumulative Timesteps: 487,155,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 487155904...
Checkpoint 487155904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.37663
Policy Entropy: 1.08347
Value Function Loss: 1.38576

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.07888

Collected Steps per Second: 8,678.15550
Overall Steps per Second: 7,543.40096

Timestep Collection Time: 5.76159
Timestep Consumption Time: 0.86672
PPO Batch Consumption Time: 0.05155
Total Iteration Time: 6.62831

Cumulative Model Updates: 29,209
Cumulative Timesteps: 487,205,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.57398
Policy Entropy: 1.07031
Value Function Loss: 1.35695

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.17899
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 8,960.15838
Overall Steps per Second: 7,736.47121

Timestep Collection Time: 5.58227
Timestep Consumption Time: 0.88295
PPO Batch Consumption Time: 0.04082
Total Iteration Time: 6.46522

Cumulative Model Updates: 29,212
Cumulative Timesteps: 487,255,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487255922...
Checkpoint 487255922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.07117
Policy Entropy: 1.06667
Value Function Loss: 1.32726

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.19823
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.07379

Collected Steps per Second: 8,380.17388
Overall Steps per Second: 7,311.95268

Timestep Collection Time: 5.96885
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.04551
Total Iteration Time: 6.84085

Cumulative Model Updates: 29,215
Cumulative Timesteps: 487,305,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.44613
Policy Entropy: 1.06638
Value Function Loss: 1.31782

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.07683

Collected Steps per Second: 8,755.65515
Overall Steps per Second: 7,663.06592

Timestep Collection Time: 5.71311
Timestep Consumption Time: 0.81457
PPO Batch Consumption Time: 0.04754
Total Iteration Time: 6.52767

Cumulative Model Updates: 29,218
Cumulative Timesteps: 487,355,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 487355964...
Checkpoint 487355964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.55909
Policy Entropy: 1.07910
Value Function Loss: 1.31836

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 8,625.56452
Overall Steps per Second: 7,544.80878

Timestep Collection Time: 5.79927
Timestep Consumption Time: 0.83072
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.62999

Cumulative Model Updates: 29,221
Cumulative Timesteps: 487,405,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.58853
Policy Entropy: 1.05870
Value Function Loss: 1.38048

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.07099

Collected Steps per Second: 8,697.59905
Overall Steps per Second: 7,546.21624

Timestep Collection Time: 5.75101
Timestep Consumption Time: 0.87748
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.62849

Cumulative Model Updates: 29,224
Cumulative Timesteps: 487,456,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 487456006...
Checkpoint 487456006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.93772
Policy Entropy: 1.06659
Value Function Loss: 1.44643

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 8,593.22392
Overall Steps per Second: 7,573.06381

Timestep Collection Time: 5.82017
Timestep Consumption Time: 0.78403
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.60420

Cumulative Model Updates: 29,227
Cumulative Timesteps: 487,506,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.54430
Policy Entropy: 1.06706
Value Function Loss: 1.46021

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 8,800.06094
Overall Steps per Second: 7,547.73182

Timestep Collection Time: 5.68519
Timestep Consumption Time: 0.94329
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.62848

Cumulative Model Updates: 29,230
Cumulative Timesteps: 487,556,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 487556050...
Checkpoint 487556050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.31544
Policy Entropy: 1.07104
Value Function Loss: 1.44177

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.05744

Collected Steps per Second: 8,754.07789
Overall Steps per Second: 7,637.07060

Timestep Collection Time: 5.71322
Timestep Consumption Time: 0.83562
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.54885

Cumulative Model Updates: 29,233
Cumulative Timesteps: 487,606,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.43210
Policy Entropy: 1.05875
Value Function Loss: 1.35160

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 8,796.71584
Overall Steps per Second: 7,563.30963

Timestep Collection Time: 5.68462
Timestep Consumption Time: 0.92703
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.61166

Cumulative Model Updates: 29,236
Cumulative Timesteps: 487,656,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 487656070...
Checkpoint 487656070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.44680
Policy Entropy: 1.05672
Value Function Loss: 1.32549

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.07888
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 8,558.05381
Overall Steps per Second: 7,438.92801

Timestep Collection Time: 5.84596
Timestep Consumption Time: 0.87948
PPO Batch Consumption Time: 0.04195
Total Iteration Time: 6.72543

Cumulative Model Updates: 29,239
Cumulative Timesteps: 487,706,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.18821
Policy Entropy: 1.06013
Value Function Loss: 1.27730

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 8,405.33747
Overall Steps per Second: 7,429.90273

Timestep Collection Time: 5.95003
Timestep Consumption Time: 0.78115
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.73118

Cumulative Model Updates: 29,242
Cumulative Timesteps: 487,756,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 487756112...
Checkpoint 487756112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.81784
Policy Entropy: 1.05819
Value Function Loss: 1.25518

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.05709

Collected Steps per Second: 8,713.65944
Overall Steps per Second: 7,541.77634

Timestep Collection Time: 5.73904
Timestep Consumption Time: 0.89176
PPO Batch Consumption Time: 0.04932
Total Iteration Time: 6.63080

Cumulative Model Updates: 29,245
Cumulative Timesteps: 487,806,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.70018
Policy Entropy: 1.06049
Value Function Loss: 1.30689

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17281
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 8,630.54892
Overall Steps per Second: 7,515.43564

Timestep Collection Time: 5.79361
Timestep Consumption Time: 0.85963
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.65324

Cumulative Model Updates: 29,248
Cumulative Timesteps: 487,856,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 487856122...
Checkpoint 487856122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.22558
Policy Entropy: 1.05928
Value Function Loss: 1.32792

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 9,035.05909
Overall Steps per Second: 7,940.25719

Timestep Collection Time: 5.53688
Timestep Consumption Time: 0.76342
PPO Batch Consumption Time: 0.04235
Total Iteration Time: 6.30030

Cumulative Model Updates: 29,251
Cumulative Timesteps: 487,906,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.35040
Policy Entropy: 1.04752
Value Function Loss: 1.34737

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 8,823.58152
Overall Steps per Second: 7,643.23414

Timestep Collection Time: 5.66731
Timestep Consumption Time: 0.87521
PPO Batch Consumption Time: 0.03995
Total Iteration Time: 6.54252

Cumulative Model Updates: 29,254
Cumulative Timesteps: 487,956,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 487956154...
Checkpoint 487956154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.14773
Policy Entropy: 1.03585
Value Function Loss: 1.32366

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 9,110.47758
Overall Steps per Second: 7,867.48084

Timestep Collection Time: 5.48906
Timestep Consumption Time: 0.86723
PPO Batch Consumption Time: 0.04377
Total Iteration Time: 6.35629

Cumulative Model Updates: 29,257
Cumulative Timesteps: 488,006,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.63016
Policy Entropy: 1.02367
Value Function Loss: 1.36070

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.20131
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 9,360.31379
Overall Steps per Second: 8,028.78520

Timestep Collection Time: 5.34213
Timestep Consumption Time: 0.88596
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.22809

Cumulative Model Updates: 29,260
Cumulative Timesteps: 488,056,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 488056166...
Checkpoint 488056166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.27578
Policy Entropy: 1.05314
Value Function Loss: 1.41277

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.06002

Collected Steps per Second: 8,826.69855
Overall Steps per Second: 7,688.35253

Timestep Collection Time: 5.66780
Timestep Consumption Time: 0.83918
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 6.50699

Cumulative Model Updates: 29,263
Cumulative Timesteps: 488,106,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.10537
Policy Entropy: 1.04399
Value Function Loss: 1.40568

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.06759
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 8,776.25263
Overall Steps per Second: 7,713.78650

Timestep Collection Time: 5.69765
Timestep Consumption Time: 0.78477
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.48242

Cumulative Model Updates: 29,266
Cumulative Timesteps: 488,156,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 488156198...
Checkpoint 488156198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.87240
Policy Entropy: 1.04246
Value Function Loss: 1.33644

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.08191
Value Function Update Magnitude: 0.05984

Collected Steps per Second: 8,426.12576
Overall Steps per Second: 7,348.58126

Timestep Collection Time: 5.93725
Timestep Consumption Time: 0.87060
PPO Batch Consumption Time: 0.04855
Total Iteration Time: 6.80784

Cumulative Model Updates: 29,269
Cumulative Timesteps: 488,206,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.61853
Policy Entropy: 1.04183
Value Function Loss: 1.24269

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 8,759.46817
Overall Steps per Second: 7,637.07486

Timestep Collection Time: 5.70902
Timestep Consumption Time: 0.83903
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.54806

Cumulative Model Updates: 29,272
Cumulative Timesteps: 488,256,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 488256234...
Checkpoint 488256234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.15238
Policy Entropy: 1.03802
Value Function Loss: 1.27857

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.20108
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 8,864.38122
Overall Steps per Second: 7,665.66625

Timestep Collection Time: 5.64326
Timestep Consumption Time: 0.88246
PPO Batch Consumption Time: 0.04954
Total Iteration Time: 6.52572

Cumulative Model Updates: 29,275
Cumulative Timesteps: 488,306,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.39653
Policy Entropy: 1.05878
Value Function Loss: 1.33442

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 8,837.87540
Overall Steps per Second: 7,688.96935

Timestep Collection Time: 5.65883
Timestep Consumption Time: 0.84556
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.50438

Cumulative Model Updates: 29,278
Cumulative Timesteps: 488,356,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 488356270...
Checkpoint 488356270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.46207
Policy Entropy: 1.06395
Value Function Loss: 1.33520

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.16912
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.07886

Collected Steps per Second: 8,678.94549
Overall Steps per Second: 7,624.51658

Timestep Collection Time: 5.76291
Timestep Consumption Time: 0.79698
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.55989

Cumulative Model Updates: 29,281
Cumulative Timesteps: 488,406,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.04666
Policy Entropy: 1.04762
Value Function Loss: 1.18735

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.07548

Collected Steps per Second: 8,791.32114
Overall Steps per Second: 7,674.49862

Timestep Collection Time: 5.68856
Timestep Consumption Time: 0.82782
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.51639

Cumulative Model Updates: 29,284
Cumulative Timesteps: 488,456,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 488456296...
Checkpoint 488456296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.14612
Policy Entropy: 1.04908
Value Function Loss: 1.13092

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.18172
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 8,488.02306
Overall Steps per Second: 7,422.25297

Timestep Collection Time: 5.89089
Timestep Consumption Time: 0.84588
PPO Batch Consumption Time: 0.04921
Total Iteration Time: 6.73677

Cumulative Model Updates: 29,287
Cumulative Timesteps: 488,506,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.36972
Policy Entropy: 1.04923
Value Function Loss: 1.25501

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 8,965.87856
Overall Steps per Second: 7,758.36743

Timestep Collection Time: 5.57692
Timestep Consumption Time: 0.86799
PPO Batch Consumption Time: 0.04684
Total Iteration Time: 6.44491

Cumulative Model Updates: 29,290
Cumulative Timesteps: 488,556,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 488556300...
Checkpoint 488556300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.21943
Policy Entropy: 1.05238
Value Function Loss: 1.40358

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 8,769.54343
Overall Steps per Second: 7,666.38293

Timestep Collection Time: 5.70155
Timestep Consumption Time: 0.82043
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.52198

Cumulative Model Updates: 29,293
Cumulative Timesteps: 488,606,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.64945
Policy Entropy: 1.03540
Value Function Loss: 1.50638

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.19207
Policy Update Magnitude: 0.07193
Value Function Update Magnitude: 0.08889

Collected Steps per Second: 8,490.61065
Overall Steps per Second: 7,525.12457

Timestep Collection Time: 5.89168
Timestep Consumption Time: 0.75591
PPO Batch Consumption Time: 0.04791
Total Iteration Time: 6.64760

Cumulative Model Updates: 29,296
Cumulative Timesteps: 488,656,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 488656324...
Checkpoint 488656324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.77911
Policy Entropy: 1.03452
Value Function Loss: 1.41565

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.18742
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.09672

Collected Steps per Second: 8,801.09755
Overall Steps per Second: 7,629.24389

Timestep Collection Time: 5.68202
Timestep Consumption Time: 0.87276
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.55478

Cumulative Model Updates: 29,299
Cumulative Timesteps: 488,706,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.42276
Policy Entropy: 1.04835
Value Function Loss: 1.41573

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.17733
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 8,665.09201
Overall Steps per Second: 7,565.14434

Timestep Collection Time: 5.77282
Timestep Consumption Time: 0.83935
PPO Batch Consumption Time: 0.04851
Total Iteration Time: 6.61217

Cumulative Model Updates: 29,302
Cumulative Timesteps: 488,756,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 488756354...
Checkpoint 488756354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.66870
Policy Entropy: 1.04077
Value Function Loss: 1.36621

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.08260

Collected Steps per Second: 8,896.83213
Overall Steps per Second: 7,716.17724

Timestep Collection Time: 5.62155
Timestep Consumption Time: 0.86016
PPO Batch Consumption Time: 0.04053
Total Iteration Time: 6.48171

Cumulative Model Updates: 29,305
Cumulative Timesteps: 488,806,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.26999
Policy Entropy: 1.04464
Value Function Loss: 1.42084

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15933
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 8,974.99767
Overall Steps per Second: 7,799.68792

Timestep Collection Time: 5.57326
Timestep Consumption Time: 0.83982
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.41308

Cumulative Model Updates: 29,308
Cumulative Timesteps: 488,856,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 488856388...
Checkpoint 488856388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.27726
Policy Entropy: 1.03310
Value Function Loss: 1.34292

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.18637
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 8,550.15640
Overall Steps per Second: 7,538.36834

Timestep Collection Time: 5.84878
Timestep Consumption Time: 0.78501
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.63380

Cumulative Model Updates: 29,311
Cumulative Timesteps: 488,906,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.00386
Policy Entropy: 1.04549
Value Function Loss: 1.29488

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.17661
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 8,736.17842
Overall Steps per Second: 7,665.02951

Timestep Collection Time: 5.72516
Timestep Consumption Time: 0.80006
PPO Batch Consumption Time: 0.03987
Total Iteration Time: 6.52522

Cumulative Model Updates: 29,314
Cumulative Timesteps: 488,956,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 488956412...
Checkpoint 488956412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.69824
Policy Entropy: 1.05902
Value Function Loss: 1.20899

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.18624
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 8,893.85833
Overall Steps per Second: 7,769.25406

Timestep Collection Time: 5.62388
Timestep Consumption Time: 0.81406
PPO Batch Consumption Time: 0.04883
Total Iteration Time: 6.43794

Cumulative Model Updates: 29,317
Cumulative Timesteps: 489,006,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.70230
Policy Entropy: 1.04426
Value Function Loss: 1.32510

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.10184

Collected Steps per Second: 8,827.98765
Overall Steps per Second: 7,687.99062

Timestep Collection Time: 5.66539
Timestep Consumption Time: 0.84008
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.50547

Cumulative Model Updates: 29,320
Cumulative Timesteps: 489,056,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 489056444...
Checkpoint 489056444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.80284
Policy Entropy: 1.03933
Value Function Loss: 1.35652

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.17610
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 8,737.05237
Overall Steps per Second: 7,563.43694

Timestep Collection Time: 5.72413
Timestep Consumption Time: 0.88821
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 6.61234

Cumulative Model Updates: 29,323
Cumulative Timesteps: 489,106,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.19758
Policy Entropy: 1.06012
Value Function Loss: 1.48737

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.16866
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.07787

Collected Steps per Second: 8,701.48900
Overall Steps per Second: 7,633.84398

Timestep Collection Time: 5.74821
Timestep Consumption Time: 0.80393
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.55214

Cumulative Model Updates: 29,326
Cumulative Timesteps: 489,156,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489156474...
Checkpoint 489156474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.05494
Policy Entropy: 1.06436
Value Function Loss: 1.49016

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.19293
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.08488

Collected Steps per Second: 8,883.53113
Overall Steps per Second: 7,709.09487

Timestep Collection Time: 5.63154
Timestep Consumption Time: 0.85793
PPO Batch Consumption Time: 0.04090
Total Iteration Time: 6.48948

Cumulative Model Updates: 29,329
Cumulative Timesteps: 489,206,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.83893
Policy Entropy: 1.05195
Value Function Loss: 1.42687

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 8,702.89128
Overall Steps per Second: 7,623.84836

Timestep Collection Time: 5.74729
Timestep Consumption Time: 0.81344
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.56073

Cumulative Model Updates: 29,332
Cumulative Timesteps: 489,256,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489256520...
Checkpoint 489256520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.32856
Policy Entropy: 1.04645
Value Function Loss: 1.36007

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.19151
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.09161

Collected Steps per Second: 8,897.48258
Overall Steps per Second: 7,724.69299

Timestep Collection Time: 5.62294
Timestep Consumption Time: 0.85369
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 6.47663

Cumulative Model Updates: 29,335
Cumulative Timesteps: 489,306,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.70257
Policy Entropy: 1.07340
Value Function Loss: 1.34934

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.16104
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.08399

Collected Steps per Second: 8,503.32775
Overall Steps per Second: 7,403.78909

Timestep Collection Time: 5.88005
Timestep Consumption Time: 0.87325
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.75330

Cumulative Model Updates: 29,338
Cumulative Timesteps: 489,356,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 489356550...
Checkpoint 489356550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.87358
Policy Entropy: 1.08860
Value Function Loss: 1.39982

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.18778
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 8,605.24593
Overall Steps per Second: 7,663.22104

Timestep Collection Time: 5.81064
Timestep Consumption Time: 0.71429
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.52493

Cumulative Model Updates: 29,341
Cumulative Timesteps: 489,406,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.54626
Policy Entropy: 1.08070
Value Function Loss: 1.38617

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 8,905.72819
Overall Steps per Second: 7,724.63446

Timestep Collection Time: 5.61639
Timestep Consumption Time: 0.85874
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.47513

Cumulative Model Updates: 29,344
Cumulative Timesteps: 489,456,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489456570...
Checkpoint 489456570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.60718
Policy Entropy: 1.07508
Value Function Loss: 1.39881

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.20051
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 8,658.70179
Overall Steps per Second: 7,511.24272

Timestep Collection Time: 5.77592
Timestep Consumption Time: 0.88236
PPO Batch Consumption Time: 0.04576
Total Iteration Time: 6.65829

Cumulative Model Updates: 29,347
Cumulative Timesteps: 489,506,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.92954
Policy Entropy: 1.09094
Value Function Loss: 1.39520

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.17287
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.06504

Collected Steps per Second: 8,770.76090
Overall Steps per Second: 7,541.76273

Timestep Collection Time: 5.70327
Timestep Consumption Time: 0.92940
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.63267

Cumulative Model Updates: 29,350
Cumulative Timesteps: 489,556,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 489556604...
Checkpoint 489556604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.37901
Policy Entropy: 1.08998
Value Function Loss: 1.40183

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.07598

Collected Steps per Second: 8,715.92824
Overall Steps per Second: 7,552.72613

Timestep Collection Time: 5.73754
Timestep Consumption Time: 0.88364
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.62119

Cumulative Model Updates: 29,353
Cumulative Timesteps: 489,606,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.25089
Policy Entropy: 1.07442
Value Function Loss: 1.44555

Mean KL Divergence: 0.02659
SB3 Clip Fraction: 0.19173
Policy Update Magnitude: 0.07530
Value Function Update Magnitude: 0.07847

Collected Steps per Second: 8,616.00276
Overall Steps per Second: 7,559.27799

Timestep Collection Time: 5.80617
Timestep Consumption Time: 0.81166
PPO Batch Consumption Time: 0.04557
Total Iteration Time: 6.61783

Cumulative Model Updates: 29,356
Cumulative Timesteps: 489,656,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 489656638...
Checkpoint 489656638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.08541
Policy Entropy: 1.09493
Value Function Loss: 1.47957

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.19527
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 8,862.86912
Overall Steps per Second: 7,667.46592

Timestep Collection Time: 5.64309
Timestep Consumption Time: 0.87979
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.52289

Cumulative Model Updates: 29,359
Cumulative Timesteps: 489,706,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.85807
Policy Entropy: 1.10325
Value Function Loss: 1.50366

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.17852
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 9,120.05493
Overall Steps per Second: 7,885.87054

Timestep Collection Time: 5.48396
Timestep Consumption Time: 0.85827
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.34223

Cumulative Model Updates: 29,362
Cumulative Timesteps: 489,756,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 489756666...
Checkpoint 489756666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.17933
Policy Entropy: 1.09329
Value Function Loss: 1.45144

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.07451

Collected Steps per Second: 8,705.04607
Overall Steps per Second: 7,657.80718

Timestep Collection Time: 5.74517
Timestep Consumption Time: 0.78568
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.53085

Cumulative Model Updates: 29,365
Cumulative Timesteps: 489,806,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.18490
Policy Entropy: 1.08857
Value Function Loss: 1.43625

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.18417
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 9,115.21658
Overall Steps per Second: 7,881.63394

Timestep Collection Time: 5.48555
Timestep Consumption Time: 0.85856
PPO Batch Consumption Time: 0.03945
Total Iteration Time: 6.34412

Cumulative Model Updates: 29,368
Cumulative Timesteps: 489,856,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489856680...
Checkpoint 489856680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.89537
Policy Entropy: 1.10150
Value Function Loss: 1.51185

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.06039

Collected Steps per Second: 8,894.49936
Overall Steps per Second: 7,800.32308

Timestep Collection Time: 5.62393
Timestep Consumption Time: 0.78889
PPO Batch Consumption Time: 0.04307
Total Iteration Time: 6.41281

Cumulative Model Updates: 29,371
Cumulative Timesteps: 489,906,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.43530
Policy Entropy: 1.10200
Value Function Loss: 1.45821

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.06554
Value Function Update Magnitude: 0.05363

Collected Steps per Second: 8,769.07018
Overall Steps per Second: 7,589.99712

Timestep Collection Time: 5.70277
Timestep Consumption Time: 0.88590
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.58867

Cumulative Model Updates: 29,374
Cumulative Timesteps: 489,956,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 489956710...
Checkpoint 489956710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.92714
Policy Entropy: 1.09675
Value Function Loss: 1.39278

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.07504

Collected Steps per Second: 8,774.70729
Overall Steps per Second: 7,506.06282

Timestep Collection Time: 5.69842
Timestep Consumption Time: 0.96312
PPO Batch Consumption Time: 0.04509
Total Iteration Time: 6.66155

Cumulative Model Updates: 29,377
Cumulative Timesteps: 490,006,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.10544
Policy Entropy: 1.09172
Value Function Loss: 1.38483

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.06824
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 8,596.96136
Overall Steps per Second: 7,574.18539

Timestep Collection Time: 5.81740
Timestep Consumption Time: 0.78555
PPO Batch Consumption Time: 0.04252
Total Iteration Time: 6.60295

Cumulative Model Updates: 29,380
Cumulative Timesteps: 490,056,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 490056724...
Checkpoint 490056724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.85636
Policy Entropy: 1.09963
Value Function Loss: 1.41958

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.08193

Collected Steps per Second: 8,890.30439
Overall Steps per Second: 7,691.67276

Timestep Collection Time: 5.62658
Timestep Consumption Time: 0.87682
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.50340

Cumulative Model Updates: 29,383
Cumulative Timesteps: 490,106,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.81886
Policy Entropy: 1.09786
Value Function Loss: 1.41768

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.06076
Value Function Update Magnitude: 0.08103

Collected Steps per Second: 8,850.83456
Overall Steps per Second: 7,705.82034

Timestep Collection Time: 5.65054
Timestep Consumption Time: 0.83962
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.49016

Cumulative Model Updates: 29,386
Cumulative Timesteps: 490,156,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 490156758...
Checkpoint 490156758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.77778
Policy Entropy: 1.10659
Value Function Loss: 1.33437

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 8,868.78613
Overall Steps per Second: 7,700.03622

Timestep Collection Time: 5.63978
Timestep Consumption Time: 0.85603
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 6.49581

Cumulative Model Updates: 29,389
Cumulative Timesteps: 490,206,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.48103
Policy Entropy: 1.09676
Value Function Loss: 1.28437

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.07814

Collected Steps per Second: 8,508.02787
Overall Steps per Second: 7,428.14040

Timestep Collection Time: 5.87986
Timestep Consumption Time: 0.85480
PPO Batch Consumption Time: 0.05265
Total Iteration Time: 6.73466

Cumulative Model Updates: 29,392
Cumulative Timesteps: 490,256,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 490256802...
Checkpoint 490256802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.92379
Policy Entropy: 1.09033
Value Function Loss: 1.37486

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 8,697.67172
Overall Steps per Second: 7,723.05306

Timestep Collection Time: 5.75119
Timestep Consumption Time: 0.72578
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.47697

Cumulative Model Updates: 29,395
Cumulative Timesteps: 490,306,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.60489
Policy Entropy: 1.09531
Value Function Loss: 1.42697

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.06824

Collected Steps per Second: 8,825.70800
Overall Steps per Second: 7,681.69468

Timestep Collection Time: 5.66799
Timestep Consumption Time: 0.84412
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.51210

Cumulative Model Updates: 29,398
Cumulative Timesteps: 490,356,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490356848...
Checkpoint 490356848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.49438
Policy Entropy: 1.09707
Value Function Loss: 1.37227

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 8,769.21165
Overall Steps per Second: 7,636.64592

Timestep Collection Time: 5.70268
Timestep Consumption Time: 0.84575
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.54842

Cumulative Model Updates: 29,401
Cumulative Timesteps: 490,406,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.02519
Policy Entropy: 1.09531
Value Function Loss: 1.38387

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.07015
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 8,785.71546
Overall Steps per Second: 7,560.90674

Timestep Collection Time: 5.69402
Timestep Consumption Time: 0.92239
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.61640

Cumulative Model Updates: 29,404
Cumulative Timesteps: 490,456,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 490456882...
Checkpoint 490456882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.33856
Policy Entropy: 1.09473
Value Function Loss: 1.40947

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.06888
Value Function Update Magnitude: 0.07804

Collected Steps per Second: 8,635.90953
Overall Steps per Second: 7,442.96397

Timestep Collection Time: 5.79279
Timestep Consumption Time: 0.92846
PPO Batch Consumption Time: 0.04775
Total Iteration Time: 6.72125

Cumulative Model Updates: 29,407
Cumulative Timesteps: 490,506,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.07072
Policy Entropy: 1.08448
Value Function Loss: 1.48708

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.15480
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 8,763.66464
Overall Steps per Second: 7,648.56460

Timestep Collection Time: 5.70720
Timestep Consumption Time: 0.83206
PPO Batch Consumption Time: 0.04178
Total Iteration Time: 6.53927

Cumulative Model Updates: 29,410
Cumulative Timesteps: 490,556,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 490556924...
Checkpoint 490556924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.10693
Policy Entropy: 1.10350
Value Function Loss: 1.51234

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.07794

Collected Steps per Second: 8,846.40855
Overall Steps per Second: 7,698.81831

Timestep Collection Time: 5.65518
Timestep Consumption Time: 0.84296
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.49814

Cumulative Model Updates: 29,413
Cumulative Timesteps: 490,606,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.58283
Policy Entropy: 1.10249
Value Function Loss: 1.48552

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.08466

Collected Steps per Second: 8,895.76103
Overall Steps per Second: 7,695.52000

Timestep Collection Time: 5.62425
Timestep Consumption Time: 0.87719
PPO Batch Consumption Time: 0.04200
Total Iteration Time: 6.50144

Cumulative Model Updates: 29,416
Cumulative Timesteps: 490,656,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 490656984...
Checkpoint 490656984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.75575
Policy Entropy: 1.09667
Value Function Loss: 1.46329

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 8,672.05709
Overall Steps per Second: 7,625.32217

Timestep Collection Time: 5.76564
Timestep Consumption Time: 0.79146
PPO Batch Consumption Time: 0.04495
Total Iteration Time: 6.55710

Cumulative Model Updates: 29,419
Cumulative Timesteps: 490,706,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.06716
Policy Entropy: 1.09446
Value Function Loss: 1.40699

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.09288

Collected Steps per Second: 8,798.60646
Overall Steps per Second: 7,603.87629

Timestep Collection Time: 5.68590
Timestep Consumption Time: 0.89338
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.57928

Cumulative Model Updates: 29,422
Cumulative Timesteps: 490,757,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 490757012...
Checkpoint 490757012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.33266
Policy Entropy: 1.10347
Value Function Loss: 1.38845

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 8,727.61277
Overall Steps per Second: 7,628.87222

Timestep Collection Time: 5.73192
Timestep Consumption Time: 0.82553
PPO Batch Consumption Time: 0.04746
Total Iteration Time: 6.55746

Cumulative Model Updates: 29,425
Cumulative Timesteps: 490,807,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.10751
Policy Entropy: 1.09932
Value Function Loss: 1.37056

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.07404
Value Function Update Magnitude: 0.09680

Collected Steps per Second: 9,081.41727
Overall Steps per Second: 7,871.81408

Timestep Collection Time: 5.50905
Timestep Consumption Time: 0.84654
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 6.35559

Cumulative Model Updates: 29,428
Cumulative Timesteps: 490,857,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 490857068...
Checkpoint 490857068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.02177
Policy Entropy: 1.10355
Value Function Loss: 1.40933

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 8,893.51712
Overall Steps per Second: 7,703.19103

Timestep Collection Time: 5.62500
Timestep Consumption Time: 0.86920
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.49419

Cumulative Model Updates: 29,431
Cumulative Timesteps: 490,907,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.36150
Policy Entropy: 1.10263
Value Function Loss: 1.37720

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.08264
Value Function Update Magnitude: 0.09429

Collected Steps per Second: 8,530.69035
Overall Steps per Second: 7,464.69422

Timestep Collection Time: 5.86189
Timestep Consumption Time: 0.83711
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.69900

Cumulative Model Updates: 29,434
Cumulative Timesteps: 490,957,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 490957100...
Checkpoint 490957100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.23357
Policy Entropy: 1.10631
Value Function Loss: 1.34935

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.07991
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 8,985.87790
Overall Steps per Second: 7,756.81949

Timestep Collection Time: 5.56429
Timestep Consumption Time: 0.88165
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.44594

Cumulative Model Updates: 29,437
Cumulative Timesteps: 491,007,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.84733
Policy Entropy: 1.10390
Value Function Loss: 1.31504

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.07917

Collected Steps per Second: 8,900.20404
Overall Steps per Second: 7,787.57372

Timestep Collection Time: 5.62055
Timestep Consumption Time: 0.80302
PPO Batch Consumption Time: 0.04173
Total Iteration Time: 6.42357

Cumulative Model Updates: 29,440
Cumulative Timesteps: 491,057,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 491057124...
Checkpoint 491057124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.58626
Policy Entropy: 1.10578
Value Function Loss: 1.32837

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.06867
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 9,044.64965
Overall Steps per Second: 7,905.56030

Timestep Collection Time: 5.52813
Timestep Consumption Time: 0.79653
PPO Batch Consumption Time: 0.04216
Total Iteration Time: 6.32466

Cumulative Model Updates: 29,443
Cumulative Timesteps: 491,107,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.54285
Policy Entropy: 1.11173
Value Function Loss: 1.44896

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.07835
Value Function Update Magnitude: 0.08101

Collected Steps per Second: 8,634.04648
Overall Steps per Second: 7,437.28705

Timestep Collection Time: 5.79311
Timestep Consumption Time: 0.93219
PPO Batch Consumption Time: 0.04722
Total Iteration Time: 6.72530

Cumulative Model Updates: 29,446
Cumulative Timesteps: 491,157,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 491157142...
Checkpoint 491157142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.43582
Policy Entropy: 1.10910
Value Function Loss: 1.45916

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.08968
Value Function Update Magnitude: 0.08177

Collected Steps per Second: 8,702.95689
Overall Steps per Second: 7,641.07996

Timestep Collection Time: 5.74816
Timestep Consumption Time: 0.79882
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.54698

Cumulative Model Updates: 29,449
Cumulative Timesteps: 491,207,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.09843
Policy Entropy: 1.10344
Value Function Loss: 1.50664

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.09061
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 8,850.53586
Overall Steps per Second: 7,650.24136

Timestep Collection Time: 5.65164
Timestep Consumption Time: 0.88672
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 6.53836

Cumulative Model Updates: 29,452
Cumulative Timesteps: 491,257,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 491257188...
Checkpoint 491257188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.68644
Policy Entropy: 1.11289
Value Function Loss: 1.47535

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.07560
Value Function Update Magnitude: 0.08134

Collected Steps per Second: 8,805.11037
Overall Steps per Second: 7,553.00444

Timestep Collection Time: 5.68056
Timestep Consumption Time: 0.94170
PPO Batch Consumption Time: 0.04721
Total Iteration Time: 6.62227

Cumulative Model Updates: 29,455
Cumulative Timesteps: 491,307,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.90980
Policy Entropy: 1.10956
Value Function Loss: 1.37317

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 8,751.55136
Overall Steps per Second: 7,593.97867

Timestep Collection Time: 5.71579
Timestep Consumption Time: 0.87127
PPO Batch Consumption Time: 0.04259
Total Iteration Time: 6.58706

Cumulative Model Updates: 29,458
Cumulative Timesteps: 491,357,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 491357228...
Checkpoint 491357228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.14209
Policy Entropy: 1.12212
Value Function Loss: 1.42839

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.07666

Collected Steps per Second: 8,692.69008
Overall Steps per Second: 7,496.62244

Timestep Collection Time: 5.75357
Timestep Consumption Time: 0.91797
PPO Batch Consumption Time: 0.04704
Total Iteration Time: 6.67154

Cumulative Model Updates: 29,461
Cumulative Timesteps: 491,407,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.81191
Policy Entropy: 1.11988
Value Function Loss: 1.33476

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 8,857.21998
Overall Steps per Second: 7,778.36093

Timestep Collection Time: 5.64827
Timestep Consumption Time: 0.78342
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.43169

Cumulative Model Updates: 29,464
Cumulative Timesteps: 491,457,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 491457270...
Checkpoint 491457270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.94481
Policy Entropy: 1.12129
Value Function Loss: 1.43434

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.07267
Value Function Update Magnitude: 0.07687

Collected Steps per Second: 8,726.24339
Overall Steps per Second: 7,534.97401

Timestep Collection Time: 5.73259
Timestep Consumption Time: 0.90632
PPO Batch Consumption Time: 0.04127
Total Iteration Time: 6.63891

Cumulative Model Updates: 29,467
Cumulative Timesteps: 491,507,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.50871
Policy Entropy: 1.11560
Value Function Loss: 1.42382

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.07643
Value Function Update Magnitude: 0.07942

Collected Steps per Second: 8,998.73918
Overall Steps per Second: 7,783.13224

Timestep Collection Time: 5.55989
Timestep Consumption Time: 0.86837
PPO Batch Consumption Time: 0.04914
Total Iteration Time: 6.42826

Cumulative Model Updates: 29,470
Cumulative Timesteps: 491,557,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 491557326...
Checkpoint 491557326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.33273
Policy Entropy: 1.12898
Value Function Loss: 1.48928

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.06697
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 9,128.37641
Overall Steps per Second: 7,901.61172

Timestep Collection Time: 5.47830
Timestep Consumption Time: 0.85053
PPO Batch Consumption Time: 0.04513
Total Iteration Time: 6.32884

Cumulative Model Updates: 29,473
Cumulative Timesteps: 491,607,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.50101
Policy Entropy: 1.13657
Value Function Loss: 1.49677

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 8,864.71562
Overall Steps per Second: 7,689.54074

Timestep Collection Time: 5.64102
Timestep Consumption Time: 0.86210
PPO Batch Consumption Time: 0.04642
Total Iteration Time: 6.50312

Cumulative Model Updates: 29,476
Cumulative Timesteps: 491,657,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 491657340...
Checkpoint 491657340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.55626
Policy Entropy: 1.13611
Value Function Loss: 1.45942

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.09743

Collected Steps per Second: 9,086.29730
Overall Steps per Second: 7,864.15749

Timestep Collection Time: 5.50565
Timestep Consumption Time: 0.85561
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.36127

Cumulative Model Updates: 29,479
Cumulative Timesteps: 491,707,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.68793
Policy Entropy: 1.13039
Value Function Loss: 1.44666

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.07434
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 9,184.53980
Overall Steps per Second: 7,915.87239

Timestep Collection Time: 5.44546
Timestep Consumption Time: 0.87274
PPO Batch Consumption Time: 0.04526
Total Iteration Time: 6.31819

Cumulative Model Updates: 29,482
Cumulative Timesteps: 491,757,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 491757380...
Checkpoint 491757380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.32826
Policy Entropy: 1.12406
Value Function Loss: 1.40069

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.08960

Collected Steps per Second: 8,850.24046
Overall Steps per Second: 7,711.26106

Timestep Collection Time: 5.65228
Timestep Consumption Time: 0.83486
PPO Batch Consumption Time: 0.04349
Total Iteration Time: 6.48714

Cumulative Model Updates: 29,485
Cumulative Timesteps: 491,807,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.62234
Policy Entropy: 1.12714
Value Function Loss: 1.44181

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.08776

Collected Steps per Second: 8,345.86286
Overall Steps per Second: 7,352.99350

Timestep Collection Time: 5.99291
Timestep Consumption Time: 0.80922
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 6.80213

Cumulative Model Updates: 29,488
Cumulative Timesteps: 491,857,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 491857420...
Checkpoint 491857420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.79699
Policy Entropy: 1.14134
Value Function Loss: 1.50823

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.08602

Collected Steps per Second: 8,846.45283
Overall Steps per Second: 7,601.32660

Timestep Collection Time: 5.65402
Timestep Consumption Time: 0.92615
PPO Batch Consumption Time: 0.04321
Total Iteration Time: 6.58017

Cumulative Model Updates: 29,491
Cumulative Timesteps: 491,907,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.38349
Policy Entropy: 1.14117
Value Function Loss: 1.51081

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 8,915.54495
Overall Steps per Second: 7,758.01482

Timestep Collection Time: 5.61110
Timestep Consumption Time: 0.83720
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 6.44830

Cumulative Model Updates: 29,494
Cumulative Timesteps: 491,957,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 491957464...
Checkpoint 491957464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.45908
Policy Entropy: 1.13614
Value Function Loss: 1.53287

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.08513
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 9,339.13668
Overall Steps per Second: 8,032.11923

Timestep Collection Time: 5.35574
Timestep Consumption Time: 0.87151
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 6.22725

Cumulative Model Updates: 29,497
Cumulative Timesteps: 492,007,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.12378
Policy Entropy: 1.14434
Value Function Loss: 1.56098

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.08486
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 8,803.86704
Overall Steps per Second: 7,706.24950

Timestep Collection Time: 5.68250
Timestep Consumption Time: 0.80937
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.49187

Cumulative Model Updates: 29,500
Cumulative Timesteps: 492,057,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 492057510...
Checkpoint 492057510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.56846
Policy Entropy: 1.14936
Value Function Loss: 1.66883

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.08310
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 8,700.05138
Overall Steps per Second: 7,695.12583

Timestep Collection Time: 5.74985
Timestep Consumption Time: 0.75089
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.50074

Cumulative Model Updates: 29,503
Cumulative Timesteps: 492,107,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.53094
Policy Entropy: 1.15314
Value Function Loss: 1.60701

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.08295
Value Function Update Magnitude: 0.07755

Collected Steps per Second: 8,655.33506
Overall Steps per Second: 7,512.55070

Timestep Collection Time: 5.77979
Timestep Consumption Time: 0.87920
PPO Batch Consumption Time: 0.04909
Total Iteration Time: 6.65899

Cumulative Model Updates: 29,506
Cumulative Timesteps: 492,157,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 492157560...
Checkpoint 492157560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.77520
Policy Entropy: 1.16941
Value Function Loss: 1.58760

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.07044
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 8,726.54760
Overall Steps per Second: 7,758.07732

Timestep Collection Time: 5.73010
Timestep Consumption Time: 0.71531
PPO Batch Consumption Time: 0.04114
Total Iteration Time: 6.44541

Cumulative Model Updates: 29,509
Cumulative Timesteps: 492,207,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.46114
Policy Entropy: 1.16761
Value Function Loss: 1.54306

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 8,825.77597
Overall Steps per Second: 7,664.90845

Timestep Collection Time: 5.66658
Timestep Consumption Time: 0.85822
PPO Batch Consumption Time: 0.04521
Total Iteration Time: 6.52480

Cumulative Model Updates: 29,512
Cumulative Timesteps: 492,257,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 492257576...
Checkpoint 492257576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.84765
Policy Entropy: 1.15548
Value Function Loss: 1.55688

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 8,629.17650
Overall Steps per Second: 7,469.12807

Timestep Collection Time: 5.79731
Timestep Consumption Time: 0.90039
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 6.69770

Cumulative Model Updates: 29,515
Cumulative Timesteps: 492,307,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.07190
Policy Entropy: 1.14597
Value Function Loss: 1.53594

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 8,639.41153
Overall Steps per Second: 7,619.21488

Timestep Collection Time: 5.78905
Timestep Consumption Time: 0.77514
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.56419

Cumulative Model Updates: 29,518
Cumulative Timesteps: 492,357,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 492357616...
Checkpoint 492357616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.35664
Policy Entropy: 1.15727
Value Function Loss: 1.51912

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.10658

Collected Steps per Second: 8,720.64951
Overall Steps per Second: 7,531.96187

Timestep Collection Time: 5.73696
Timestep Consumption Time: 0.90540
PPO Batch Consumption Time: 0.04920
Total Iteration Time: 6.64236

Cumulative Model Updates: 29,521
Cumulative Timesteps: 492,407,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.32917
Policy Entropy: 1.16210
Value Function Loss: 1.50620

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.10274

Collected Steps per Second: 8,509.18830
Overall Steps per Second: 7,454.59964

Timestep Collection Time: 5.87647
Timestep Consumption Time: 0.83133
PPO Batch Consumption Time: 0.04587
Total Iteration Time: 6.70780

Cumulative Model Updates: 29,524
Cumulative Timesteps: 492,457,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 492457650...
Checkpoint 492457650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.93928
Policy Entropy: 1.13824
Value Function Loss: 1.55232

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.17484
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 9,060.07566
Overall Steps per Second: 7,844.78851

Timestep Collection Time: 5.52004
Timestep Consumption Time: 0.85515
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 6.37519

Cumulative Model Updates: 29,527
Cumulative Timesteps: 492,507,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.74403
Policy Entropy: 1.14198
Value Function Loss: 1.53524

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.08993

Collected Steps per Second: 8,529.56524
Overall Steps per Second: 7,445.79487

Timestep Collection Time: 5.86290
Timestep Consumption Time: 0.85337
PPO Batch Consumption Time: 0.04746
Total Iteration Time: 6.71627

Cumulative Model Updates: 29,530
Cumulative Timesteps: 492,557,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 492557670...
Checkpoint 492557670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.63750
Policy Entropy: 1.14539
Value Function Loss: 1.48174

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 8,635.85629
Overall Steps per Second: 7,582.00053

Timestep Collection Time: 5.79005
Timestep Consumption Time: 0.80478
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 6.59483

Cumulative Model Updates: 29,533
Cumulative Timesteps: 492,607,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.03518
Policy Entropy: 1.13762
Value Function Loss: 1.42089

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.09358

Collected Steps per Second: 8,761.26779
Overall Steps per Second: 7,645.24872

Timestep Collection Time: 5.70716
Timestep Consumption Time: 0.83311
PPO Batch Consumption Time: 0.04732
Total Iteration Time: 6.54027

Cumulative Model Updates: 29,536
Cumulative Timesteps: 492,657,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492657674...
Checkpoint 492657674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.66224
Policy Entropy: 1.13637
Value Function Loss: 1.44885

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15525
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.08749

Collected Steps per Second: 8,672.21954
Overall Steps per Second: 7,561.08537

Timestep Collection Time: 5.76877
Timestep Consumption Time: 0.84774
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.61651

Cumulative Model Updates: 29,539
Cumulative Timesteps: 492,707,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.40801
Policy Entropy: 1.14129
Value Function Loss: 1.52148

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11421
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.08840

Collected Steps per Second: 8,656.36998
Overall Steps per Second: 7,400.02074

Timestep Collection Time: 5.77702
Timestep Consumption Time: 0.98080
PPO Batch Consumption Time: 0.04986
Total Iteration Time: 6.75782

Cumulative Model Updates: 29,542
Cumulative Timesteps: 492,757,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 492757710...
Checkpoint 492757710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.22942
Policy Entropy: 1.14030
Value Function Loss: 1.43133

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.09653

Collected Steps per Second: 8,774.85154
Overall Steps per Second: 7,486.53868

Timestep Collection Time: 5.69810
Timestep Consumption Time: 0.98055
PPO Batch Consumption Time: 0.05032
Total Iteration Time: 6.67865

Cumulative Model Updates: 29,545
Cumulative Timesteps: 492,807,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.90976
Policy Entropy: 1.12116
Value Function Loss: 1.35849

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.09112

Collected Steps per Second: 8,730.29930
Overall Steps per Second: 7,686.16031

Timestep Collection Time: 5.72741
Timestep Consumption Time: 0.77805
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.50546

Cumulative Model Updates: 29,548
Cumulative Timesteps: 492,857,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492857712...
Checkpoint 492857712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.60660
Policy Entropy: 1.12494
Value Function Loss: 1.28471

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.16914
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 8,676.14119
Overall Steps per Second: 7,508.86819

Timestep Collection Time: 5.76362
Timestep Consumption Time: 0.89597
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.65959

Cumulative Model Updates: 29,551
Cumulative Timesteps: 492,907,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.61344
Policy Entropy: 1.12273
Value Function Loss: 1.35403

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 8,637.80308
Overall Steps per Second: 7,534.01460

Timestep Collection Time: 5.79082
Timestep Consumption Time: 0.84840
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.63922

Cumulative Model Updates: 29,554
Cumulative Timesteps: 492,957,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 492957738...
Checkpoint 492957738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.25325
Policy Entropy: 1.10880
Value Function Loss: 1.29166

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.17655
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 8,450.34786
Overall Steps per Second: 7,376.05651

Timestep Collection Time: 5.91976
Timestep Consumption Time: 0.86219
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.78194

Cumulative Model Updates: 29,557
Cumulative Timesteps: 493,007,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.81991
Policy Entropy: 1.10494
Value Function Loss: 1.33486

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.22131
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.11351

Collected Steps per Second: 8,657.65997
Overall Steps per Second: 7,561.88234

Timestep Collection Time: 5.77800
Timestep Consumption Time: 0.83728
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.61528

Cumulative Model Updates: 29,560
Cumulative Timesteps: 493,057,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 493057786...
Checkpoint 493057786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.20893
Policy Entropy: 1.10958
Value Function Loss: 1.22750

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 8,624.18382
Overall Steps per Second: 7,537.41335

Timestep Collection Time: 5.79858
Timestep Consumption Time: 0.83606
PPO Batch Consumption Time: 0.04260
Total Iteration Time: 6.63464

Cumulative Model Updates: 29,563
Cumulative Timesteps: 493,107,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.54640
Policy Entropy: 1.11964
Value Function Loss: 1.37637

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15623
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 8,676.22543
Overall Steps per Second: 7,517.94708

Timestep Collection Time: 5.76449
Timestep Consumption Time: 0.88813
PPO Batch Consumption Time: 0.04960
Total Iteration Time: 6.65261

Cumulative Model Updates: 29,566
Cumulative Timesteps: 493,157,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 493157808...
Checkpoint 493157808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.81199
Policy Entropy: 1.09507
Value Function Loss: 1.35403

Mean KL Divergence: 0.03691
SB3 Clip Fraction: 0.20935
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 8,690.73065
Overall Steps per Second: 7,564.40741

Timestep Collection Time: 5.75326
Timestep Consumption Time: 0.85665
PPO Batch Consumption Time: 0.04130
Total Iteration Time: 6.60990

Cumulative Model Updates: 29,569
Cumulative Timesteps: 493,207,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.38999
Policy Entropy: 1.10491
Value Function Loss: 1.41527

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.09999

Collected Steps per Second: 8,570.33844
Overall Steps per Second: 7,386.32838

Timestep Collection Time: 5.83548
Timestep Consumption Time: 0.93541
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.77089

Cumulative Model Updates: 29,572
Cumulative Timesteps: 493,257,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 493257820...
Checkpoint 493257820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.15610
Policy Entropy: 1.10208
Value Function Loss: 1.27383

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.17633
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.08980

Collected Steps per Second: 8,658.18420
Overall Steps per Second: 7,526.15737

Timestep Collection Time: 5.77558
Timestep Consumption Time: 0.86872
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.64429

Cumulative Model Updates: 29,575
Cumulative Timesteps: 493,307,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.86039
Policy Entropy: 1.08996
Value Function Loss: 1.30422

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 8,774.40576
Overall Steps per Second: 7,702.12186

Timestep Collection Time: 5.69908
Timestep Consumption Time: 0.79342
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 6.49250

Cumulative Model Updates: 29,578
Cumulative Timesteps: 493,357,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 493357832...
Checkpoint 493357832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.30469
Policy Entropy: 1.09787
Value Function Loss: 1.25864

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.06223

Collected Steps per Second: 8,935.29818
Overall Steps per Second: 7,635.74385

Timestep Collection Time: 5.59825
Timestep Consumption Time: 0.95279
PPO Batch Consumption Time: 0.04766
Total Iteration Time: 6.55103

Cumulative Model Updates: 29,581
Cumulative Timesteps: 493,407,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.04138
Policy Entropy: 1.09635
Value Function Loss: 1.32238

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17188
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.06471

Collected Steps per Second: 8,805.77511
Overall Steps per Second: 7,655.96183

Timestep Collection Time: 5.68036
Timestep Consumption Time: 0.85311
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 6.53347

Cumulative Model Updates: 29,584
Cumulative Timesteps: 493,457,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 493457874...
Checkpoint 493457874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.06372
Policy Entropy: 1.10084
Value Function Loss: 1.28467

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.20206
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.05391

Collected Steps per Second: 9,106.94682
Overall Steps per Second: 7,803.05855

Timestep Collection Time: 5.49273
Timestep Consumption Time: 0.91783
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.41056

Cumulative Model Updates: 29,587
Cumulative Timesteps: 493,507,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.21600
Policy Entropy: 1.04948
Value Function Loss: 1.24502

Mean KL Divergence: 0.09233
SB3 Clip Fraction: 0.35720
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.05235

Collected Steps per Second: 8,957.21947
Overall Steps per Second: 7,659.48325

Timestep Collection Time: 5.58499
Timestep Consumption Time: 0.94626
PPO Batch Consumption Time: 0.04668
Total Iteration Time: 6.53125

Cumulative Model Updates: 29,590
Cumulative Timesteps: 493,557,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 493557922...
Checkpoint 493557922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.77040
Policy Entropy: 1.07553
Value Function Loss: 1.19643

Mean KL Divergence: 0.04157
SB3 Clip Fraction: 0.26112
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.06248

Collected Steps per Second: 8,878.02172
Overall Steps per Second: 7,768.91878

Timestep Collection Time: 5.63369
Timestep Consumption Time: 0.80427
PPO Batch Consumption Time: 0.04382
Total Iteration Time: 6.43796

Cumulative Model Updates: 29,593
Cumulative Timesteps: 493,607,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.99144
Policy Entropy: 1.05025
Value Function Loss: 1.15853

Mean KL Divergence: 0.05635
SB3 Clip Fraction: 0.32150
Policy Update Magnitude: 0.04332
Value Function Update Magnitude: 0.06002

Collected Steps per Second: 8,784.32806
Overall Steps per Second: 7,441.71426

Timestep Collection Time: 5.69196
Timestep Consumption Time: 1.02693
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.71888

Cumulative Model Updates: 29,596
Cumulative Timesteps: 493,657,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 493657938...
Checkpoint 493657938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.04900
Policy Entropy: 1.06342
Value Function Loss: 1.17289

Mean KL Divergence: 0.02913
SB3 Clip Fraction: 0.21047
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.06693

Collected Steps per Second: 8,765.36647
Overall Steps per Second: 7,583.49536

Timestep Collection Time: 5.70632
Timestep Consumption Time: 0.88932
PPO Batch Consumption Time: 0.04586
Total Iteration Time: 6.59564

Cumulative Model Updates: 29,599
Cumulative Timesteps: 493,707,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.85947
Policy Entropy: 1.07198
Value Function Loss: 1.18163

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.19984
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 8,646.96801
Overall Steps per Second: 7,616.31172

Timestep Collection Time: 5.78469
Timestep Consumption Time: 0.78280
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.56748

Cumulative Model Updates: 29,602
Cumulative Timesteps: 493,757,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 493757976...
Checkpoint 493757976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.60737
Policy Entropy: 1.05234
Value Function Loss: 1.21466

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.17761
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 8,919.13982
Overall Steps per Second: 7,688.24008

Timestep Collection Time: 5.60861
Timestep Consumption Time: 0.89795
PPO Batch Consumption Time: 0.04129
Total Iteration Time: 6.50656

Cumulative Model Updates: 29,605
Cumulative Timesteps: 493,808,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.03004
Policy Entropy: 1.05554
Value Function Loss: 1.26345

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.05086

Collected Steps per Second: 8,805.30832
Overall Steps per Second: 7,700.39870

Timestep Collection Time: 5.68112
Timestep Consumption Time: 0.81517
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.49629

Cumulative Model Updates: 29,608
Cumulative Timesteps: 493,858,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 493858024...
Checkpoint 493858024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.76853
Policy Entropy: 1.06401
Value Function Loss: 1.25983

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 8,605.38239
Overall Steps per Second: 7,464.26807

Timestep Collection Time: 5.81125
Timestep Consumption Time: 0.88841
PPO Batch Consumption Time: 0.04218
Total Iteration Time: 6.69965

Cumulative Model Updates: 29,611
Cumulative Timesteps: 493,908,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.85127
Policy Entropy: 1.07223
Value Function Loss: 1.30744

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.05635

Collected Steps per Second: 8,799.27168
Overall Steps per Second: 7,647.80290

Timestep Collection Time: 5.68411
Timestep Consumption Time: 0.85581
PPO Batch Consumption Time: 0.04059
Total Iteration Time: 6.53992

Cumulative Model Updates: 29,614
Cumulative Timesteps: 493,958,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 493958048...
Checkpoint 493958048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.79420
Policy Entropy: 1.08269
Value Function Loss: 1.24772

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.18845
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.06527

Collected Steps per Second: 8,748.03131
Overall Steps per Second: 7,693.69214

Timestep Collection Time: 5.71877
Timestep Consumption Time: 0.78370
PPO Batch Consumption Time: 0.04863
Total Iteration Time: 6.50247

Cumulative Model Updates: 29,617
Cumulative Timesteps: 494,008,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.93674
Policy Entropy: 1.05844
Value Function Loss: 1.23764

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.18463
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 8,844.66365
Overall Steps per Second: 7,701.47074

Timestep Collection Time: 5.65652
Timestep Consumption Time: 0.83964
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.49616

Cumulative Model Updates: 29,620
Cumulative Timesteps: 494,058,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 494058106...
Checkpoint 494058106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.57474
Policy Entropy: 1.06410
Value Function Loss: 1.15741

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.18647
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 8,586.14395
Overall Steps per Second: 7,506.62532

Timestep Collection Time: 5.82567
Timestep Consumption Time: 0.83778
PPO Batch Consumption Time: 0.04891
Total Iteration Time: 6.66345

Cumulative Model Updates: 29,623
Cumulative Timesteps: 494,108,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.27804
Policy Entropy: 1.05650
Value Function Loss: 1.19282

Mean KL Divergence: 0.02347
SB3 Clip Fraction: 0.20087
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 8,456.80159
Overall Steps per Second: 7,466.94771

Timestep Collection Time: 5.91477
Timestep Consumption Time: 0.78409
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 6.69885

Cumulative Model Updates: 29,626
Cumulative Timesteps: 494,158,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 494158146...
Checkpoint 494158146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.39305
Policy Entropy: 1.04808
Value Function Loss: 1.24525

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.19953
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.08326

Collected Steps per Second: 8,581.30965
Overall Steps per Second: 7,422.10466

Timestep Collection Time: 5.82895
Timestep Consumption Time: 0.91038
PPO Batch Consumption Time: 0.05071
Total Iteration Time: 6.73933

Cumulative Model Updates: 29,629
Cumulative Timesteps: 494,208,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.30236
Policy Entropy: 1.04163
Value Function Loss: 1.33430

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.21137
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 8,667.42717
Overall Steps per Second: 7,668.99691

Timestep Collection Time: 5.77080
Timestep Consumption Time: 0.75130
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.52210

Cumulative Model Updates: 29,632
Cumulative Timesteps: 494,258,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 494258184...
Checkpoint 494258184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.39121
Policy Entropy: 1.05285
Value Function Loss: 1.25470

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15853
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.09131

Collected Steps per Second: 8,868.31520
Overall Steps per Second: 7,606.64093

Timestep Collection Time: 5.63918
Timestep Consumption Time: 0.93534
PPO Batch Consumption Time: 0.05279
Total Iteration Time: 6.57452

Cumulative Model Updates: 29,635
Cumulative Timesteps: 494,308,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.34456
Policy Entropy: 1.05843
Value Function Loss: 1.20424

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.18004
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.08942

Collected Steps per Second: 8,542.63539
Overall Steps per Second: 7,469.17498

Timestep Collection Time: 5.85487
Timestep Consumption Time: 0.84145
PPO Batch Consumption Time: 0.04189
Total Iteration Time: 6.69632

Cumulative Model Updates: 29,638
Cumulative Timesteps: 494,358,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494358210...
Checkpoint 494358210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.19528
Policy Entropy: 1.04511
Value Function Loss: 1.14001

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.17569
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 8,949.42989
Overall Steps per Second: 7,891.12120

Timestep Collection Time: 5.58963
Timestep Consumption Time: 0.74965
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 6.33928

Cumulative Model Updates: 29,641
Cumulative Timesteps: 494,408,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.30788
Policy Entropy: 1.03787
Value Function Loss: 1.17660

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.19482
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.09146

Collected Steps per Second: 8,735.22644
Overall Steps per Second: 7,613.10692

Timestep Collection Time: 5.72487
Timestep Consumption Time: 0.84381
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.56867

Cumulative Model Updates: 29,644
Cumulative Timesteps: 494,458,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494458242...
Checkpoint 494458242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.53149
Policy Entropy: 1.05131
Value Function Loss: 1.21632

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16966
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 8,950.10843
Overall Steps per Second: 7,852.29309

Timestep Collection Time: 5.58652
Timestep Consumption Time: 0.78104
PPO Batch Consumption Time: 0.05129
Total Iteration Time: 6.36757

Cumulative Model Updates: 29,647
Cumulative Timesteps: 494,508,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.77049
Policy Entropy: 1.05244
Value Function Loss: 1.20918

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.04033
Value Function Update Magnitude: 0.09245

Collected Steps per Second: 8,732.82278
Overall Steps per Second: 7,509.54692

Timestep Collection Time: 5.72713
Timestep Consumption Time: 0.93293
PPO Batch Consumption Time: 0.04984
Total Iteration Time: 6.66006

Cumulative Model Updates: 29,650
Cumulative Timesteps: 494,558,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 494558256...
Checkpoint 494558256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.71382
Policy Entropy: 1.02770
Value Function Loss: 1.22800

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.20223
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.09089

Collected Steps per Second: 8,581.56246
Overall Steps per Second: 7,500.02134

Timestep Collection Time: 5.82644
Timestep Consumption Time: 0.84020
PPO Batch Consumption Time: 0.04598
Total Iteration Time: 6.66665

Cumulative Model Updates: 29,653
Cumulative Timesteps: 494,608,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.67007
Policy Entropy: 1.03913
Value Function Loss: 1.16727

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.16168
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 8,731.64875
Overall Steps per Second: 7,580.42959

Timestep Collection Time: 5.72721
Timestep Consumption Time: 0.86978
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 6.59699

Cumulative Model Updates: 29,656
Cumulative Timesteps: 494,658,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494658264...
Checkpoint 494658264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.02597
Policy Entropy: 1.04217
Value Function Loss: 1.13876

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 8,746.80114
Overall Steps per Second: 7,615.39497

Timestep Collection Time: 5.71958
Timestep Consumption Time: 0.84975
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.56932

Cumulative Model Updates: 29,659
Cumulative Timesteps: 494,708,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.34988
Policy Entropy: 1.04649
Value Function Loss: 1.10942

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 8,611.75555
Overall Steps per Second: 7,646.04302

Timestep Collection Time: 5.80602
Timestep Consumption Time: 0.73331
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.53933

Cumulative Model Updates: 29,662
Cumulative Timesteps: 494,758,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 494758292...
Checkpoint 494758292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.39417
Policy Entropy: 1.02299
Value Function Loss: 1.15862

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.18388
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.05178

Collected Steps per Second: 8,594.29794
Overall Steps per Second: 7,470.21706

Timestep Collection Time: 5.81828
Timestep Consumption Time: 0.87551
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.69378

Cumulative Model Updates: 29,665
Cumulative Timesteps: 494,808,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.00822
Policy Entropy: 1.04217
Value Function Loss: 1.20254

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.04463

Collected Steps per Second: 8,707.03066
Overall Steps per Second: 7,441.14989

Timestep Collection Time: 5.74616
Timestep Consumption Time: 0.97753
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 6.72369

Cumulative Model Updates: 29,668
Cumulative Timesteps: 494,858,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 494858328...
Checkpoint 494858328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.56789
Policy Entropy: 1.03431
Value Function Loss: 1.23913

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.04399

Collected Steps per Second: 8,821.82570
Overall Steps per Second: 7,648.34766

Timestep Collection Time: 5.66912
Timestep Consumption Time: 0.86981
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.53893

Cumulative Model Updates: 29,671
Cumulative Timesteps: 494,908,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.65455
Policy Entropy: 1.03814
Value Function Loss: 1.26312

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.04576

Collected Steps per Second: 8,800.28906
Overall Steps per Second: 7,624.74152

Timestep Collection Time: 5.68459
Timestep Consumption Time: 0.87642
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 6.56101

Cumulative Model Updates: 29,674
Cumulative Timesteps: 494,958,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 494958366...
Checkpoint 494958366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.59945
Policy Entropy: 1.02845
Value Function Loss: 1.23747

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.16755
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 8,537.30632
Overall Steps per Second: 7,529.13085

Timestep Collection Time: 5.85688
Timestep Consumption Time: 0.78426
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.64114

Cumulative Model Updates: 29,677
Cumulative Timesteps: 495,008,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.08687
Policy Entropy: 1.04143
Value Function Loss: 1.22687

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.17885
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 8,522.00789
Overall Steps per Second: 7,406.28900

Timestep Collection Time: 5.86716
Timestep Consumption Time: 0.88386
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 6.75102

Cumulative Model Updates: 29,680
Cumulative Timesteps: 495,058,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 495058368...
Checkpoint 495058368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.92723
Policy Entropy: 1.04416
Value Function Loss: 1.20543

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 8,748.62839
Overall Steps per Second: 7,608.70175

Timestep Collection Time: 5.71838
Timestep Consumption Time: 0.85672
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.57510

Cumulative Model Updates: 29,683
Cumulative Timesteps: 495,108,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.64897
Policy Entropy: 1.03984
Value Function Loss: 1.31739

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 8,749.61351
Overall Steps per Second: 7,604.00858

Timestep Collection Time: 5.71614
Timestep Consumption Time: 0.86118
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.57732

Cumulative Model Updates: 29,686
Cumulative Timesteps: 495,158,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 495158410...
Checkpoint 495158410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.39236
Policy Entropy: 1.03752
Value Function Loss: 1.30237

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.06615

Collected Steps per Second: 8,991.76448
Overall Steps per Second: 7,725.57440

Timestep Collection Time: 5.56265
Timestep Consumption Time: 0.91169
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.47434

Cumulative Model Updates: 29,689
Cumulative Timesteps: 495,208,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.10518
Policy Entropy: 1.02098
Value Function Loss: 1.26205

Mean KL Divergence: 0.03134
SB3 Clip Fraction: 0.24850
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.07251

Collected Steps per Second: 8,813.19588
Overall Steps per Second: 7,734.21218

Timestep Collection Time: 5.67490
Timestep Consumption Time: 0.79169
PPO Batch Consumption Time: 0.04653
Total Iteration Time: 6.46659

Cumulative Model Updates: 29,692
Cumulative Timesteps: 495,258,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 495258442...
Checkpoint 495258442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.17701
Policy Entropy: 1.04484
Value Function Loss: 1.16210

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 9,061.66885
Overall Steps per Second: 7,813.16491

Timestep Collection Time: 5.51929
Timestep Consumption Time: 0.88195
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.40125

Cumulative Model Updates: 29,695
Cumulative Timesteps: 495,308,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.58847
Policy Entropy: 1.03976
Value Function Loss: 1.11593

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07359

Collected Steps per Second: 8,859.55260
Overall Steps per Second: 7,698.98294

Timestep Collection Time: 5.64543
Timestep Consumption Time: 0.85101
PPO Batch Consumption Time: 0.04256
Total Iteration Time: 6.49644

Cumulative Model Updates: 29,698
Cumulative Timesteps: 495,358,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 495358472...
Checkpoint 495358472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.31084
Policy Entropy: 1.03740
Value Function Loss: 1.08959

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.07847

Collected Steps per Second: 9,020.36779
Overall Steps per Second: 7,944.54351

Timestep Collection Time: 5.54589
Timestep Consumption Time: 0.75101
PPO Batch Consumption Time: 0.04385
Total Iteration Time: 6.29690

Cumulative Model Updates: 29,701
Cumulative Timesteps: 495,408,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.22227
Policy Entropy: 1.04366
Value Function Loss: 1.08177

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.17837
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 8,715.47978
Overall Steps per Second: 7,529.95841

Timestep Collection Time: 5.74013
Timestep Consumption Time: 0.90373
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.64386

Cumulative Model Updates: 29,704
Cumulative Timesteps: 495,458,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 495458526...
Checkpoint 495458526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.99500
Policy Entropy: 1.04910
Value Function Loss: 1.24394

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.18338
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 8,409.47668
Overall Steps per Second: 7,438.74624

Timestep Collection Time: 5.94758
Timestep Consumption Time: 0.77614
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.72371

Cumulative Model Updates: 29,707
Cumulative Timesteps: 495,508,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.15163
Policy Entropy: 1.03639
Value Function Loss: 1.24538

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.08953

Collected Steps per Second: 8,684.88153
Overall Steps per Second: 7,514.69110

Timestep Collection Time: 5.75897
Timestep Consumption Time: 0.89679
PPO Batch Consumption Time: 0.04525
Total Iteration Time: 6.65576

Cumulative Model Updates: 29,710
Cumulative Timesteps: 495,558,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 495558558...
Checkpoint 495558558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.56644
Policy Entropy: 1.02384
Value Function Loss: 1.26669

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.20615
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.08705

Collected Steps per Second: 8,690.19064
Overall Steps per Second: 7,684.93595

Timestep Collection Time: 5.75407
Timestep Consumption Time: 0.75268
PPO Batch Consumption Time: 0.04102
Total Iteration Time: 6.50676

Cumulative Model Updates: 29,713
Cumulative Timesteps: 495,608,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.95824
Policy Entropy: 1.02988
Value Function Loss: 1.17350

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.08558

Collected Steps per Second: 8,879.26477
Overall Steps per Second: 7,642.40756

Timestep Collection Time: 5.63335
Timestep Consumption Time: 0.91171
PPO Batch Consumption Time: 0.04607
Total Iteration Time: 6.54506

Cumulative Model Updates: 29,716
Cumulative Timesteps: 495,658,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 495658582...
Checkpoint 495658582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.25101
Policy Entropy: 1.02862
Value Function Loss: 1.24477

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.08107

Collected Steps per Second: 8,762.49354
Overall Steps per Second: 7,519.36417

Timestep Collection Time: 5.70614
Timestep Consumption Time: 0.94336
PPO Batch Consumption Time: 0.04228
Total Iteration Time: 6.64950

Cumulative Model Updates: 29,719
Cumulative Timesteps: 495,708,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.81853
Policy Entropy: 1.02593
Value Function Loss: 1.20379

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.24131
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.07857

Collected Steps per Second: 8,592.35958
Overall Steps per Second: 7,605.64540

Timestep Collection Time: 5.82192
Timestep Consumption Time: 0.75530
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 6.57722

Cumulative Model Updates: 29,722
Cumulative Timesteps: 495,758,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 495758606...
Checkpoint 495758606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.08703
Policy Entropy: 1.02935
Value Function Loss: 1.19342

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.20039
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07379

Collected Steps per Second: 8,777.52191
Overall Steps per Second: 7,575.86006

Timestep Collection Time: 5.69728
Timestep Consumption Time: 0.90369
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.60097

Cumulative Model Updates: 29,725
Cumulative Timesteps: 495,808,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.36015
Policy Entropy: 1.02583
Value Function Loss: 1.20774

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.18360
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.06261

Collected Steps per Second: 8,647.16445
Overall Steps per Second: 7,488.04324

Timestep Collection Time: 5.78432
Timestep Consumption Time: 0.89539
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.67972

Cumulative Model Updates: 29,728
Cumulative Timesteps: 495,858,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 495858632...
Checkpoint 495858632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.43468
Policy Entropy: 1.02439
Value Function Loss: 1.24204

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 8,456.33407
Overall Steps per Second: 7,420.73344

Timestep Collection Time: 5.91486
Timestep Consumption Time: 0.82545
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.74030

Cumulative Model Updates: 29,731
Cumulative Timesteps: 495,908,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.48293
Policy Entropy: 1.01064
Value Function Loss: 1.16200

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.22018
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.05937

Collected Steps per Second: 8,387.30077
Overall Steps per Second: 7,393.36306

Timestep Collection Time: 5.96282
Timestep Consumption Time: 0.80162
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.76445

Cumulative Model Updates: 29,734
Cumulative Timesteps: 495,958,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 495958662...
Checkpoint 495958662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.57133
Policy Entropy: 1.02199
Value Function Loss: 1.15384

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.19883
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 8,599.48379
Overall Steps per Second: 7,607.55942

Timestep Collection Time: 5.81756
Timestep Consumption Time: 0.75853
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.57609

Cumulative Model Updates: 29,737
Cumulative Timesteps: 496,008,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.90223
Policy Entropy: 1.01361
Value Function Loss: 1.13156

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.20865
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.05248

Collected Steps per Second: 8,634.82716
Overall Steps per Second: 7,216.56193

Timestep Collection Time: 5.79328
Timestep Consumption Time: 1.13855
PPO Batch Consumption Time: 0.04471
Total Iteration Time: 6.93183

Cumulative Model Updates: 29,740
Cumulative Timesteps: 496,058,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 496058714...
Checkpoint 496058714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.24250
Policy Entropy: 1.01035
Value Function Loss: 1.11785

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.18386
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.05256

Collected Steps per Second: 8,249.87276
Overall Steps per Second: 7,196.98104

Timestep Collection Time: 6.06385
Timestep Consumption Time: 0.88712
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 6.95097

Cumulative Model Updates: 29,743
Cumulative Timesteps: 496,108,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.12676
Policy Entropy: 0.99292
Value Function Loss: 1.11694

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.23897
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 8,869.46055
Overall Steps per Second: 7,574.61112

Timestep Collection Time: 5.63822
Timestep Consumption Time: 0.96383
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 6.60206

Cumulative Model Updates: 29,746
Cumulative Timesteps: 496,158,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 496158748...
Checkpoint 496158748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.09019
Policy Entropy: 1.02649
Value Function Loss: 1.17839

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.22441
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.06017

Collected Steps per Second: 8,395.88608
Overall Steps per Second: 7,149.90076

Timestep Collection Time: 5.95577
Timestep Consumption Time: 1.03789
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 6.99366

Cumulative Model Updates: 29,749
Cumulative Timesteps: 496,208,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.14292
Policy Entropy: 0.99700
Value Function Loss: 1.30566

Mean KL Divergence: 0.03611
SB3 Clip Fraction: 0.26461
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 8,366.44878
Overall Steps per Second: 7,445.19302

Timestep Collection Time: 5.97936
Timestep Consumption Time: 0.73988
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.71923

Cumulative Model Updates: 29,752
Cumulative Timesteps: 496,258,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 496258778...
Checkpoint 496258778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.34565
Policy Entropy: 1.02617
Value Function Loss: 1.24095

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.23688
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.07161

Collected Steps per Second: 8,747.12559
Overall Steps per Second: 7,514.78449

Timestep Collection Time: 5.71914
Timestep Consumption Time: 0.93787
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.65701

Cumulative Model Updates: 29,755
Cumulative Timesteps: 496,308,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.47044
Policy Entropy: 1.02041
Value Function Loss: 1.22087

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.21209
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 8,925.52533
Overall Steps per Second: 7,720.19973

Timestep Collection Time: 5.60348
Timestep Consumption Time: 0.87485
PPO Batch Consumption Time: 0.05271
Total Iteration Time: 6.47833

Cumulative Model Updates: 29,758
Cumulative Timesteps: 496,358,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 496358818...
Checkpoint 496358818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.77405
Policy Entropy: 1.01337
Value Function Loss: 1.13683

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.19599
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 8,210.11713
Overall Steps per Second: 7,233.63920

Timestep Collection Time: 6.09029
Timestep Consumption Time: 0.82214
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.91243

Cumulative Model Updates: 29,761
Cumulative Timesteps: 496,408,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.09562
Policy Entropy: 1.02932
Value Function Loss: 1.23317

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.05475

Collected Steps per Second: 8,756.90810
Overall Steps per Second: 7,629.10383

Timestep Collection Time: 5.71138
Timestep Consumption Time: 0.84431
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.55568

Cumulative Model Updates: 29,764
Cumulative Timesteps: 496,458,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 496458834...
Checkpoint 496458834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.34523
Policy Entropy: 1.03735
Value Function Loss: 1.24071

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.21507
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.06068

Collected Steps per Second: 8,901.06595
Overall Steps per Second: 7,746.58416

Timestep Collection Time: 5.61865
Timestep Consumption Time: 0.83735
PPO Batch Consumption Time: 0.04635
Total Iteration Time: 6.45601

Cumulative Model Updates: 29,767
Cumulative Timesteps: 496,508,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.41246
Policy Entropy: 1.01965
Value Function Loss: 1.31135

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 9,067.20248
Overall Steps per Second: 7,823.96590

Timestep Collection Time: 5.51614
Timestep Consumption Time: 0.87652
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 6.39267

Cumulative Model Updates: 29,770
Cumulative Timesteps: 496,558,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 496558862...
Checkpoint 496558862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.55741
Policy Entropy: 1.00997
Value Function Loss: 1.29190

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.22013
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 8,476.33018
Overall Steps per Second: 7,371.44984

Timestep Collection Time: 5.90208
Timestep Consumption Time: 0.88464
PPO Batch Consumption Time: 0.04887
Total Iteration Time: 6.78672

Cumulative Model Updates: 29,773
Cumulative Timesteps: 496,608,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.30831
Policy Entropy: 1.02712
Value Function Loss: 1.23893

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 8,743.25196
Overall Steps per Second: 7,762.81206

Timestep Collection Time: 5.71870
Timestep Consumption Time: 0.72227
PPO Batch Consumption Time: 0.04481
Total Iteration Time: 6.44096

Cumulative Model Updates: 29,776
Cumulative Timesteps: 496,658,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 496658890...
Checkpoint 496658890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.37806
Policy Entropy: 1.03341
Value Function Loss: 1.18371

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.05081

Collected Steps per Second: 8,542.70912
Overall Steps per Second: 7,413.92367

Timestep Collection Time: 5.85529
Timestep Consumption Time: 0.89148
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.74676

Cumulative Model Updates: 29,779
Cumulative Timesteps: 496,708,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.35743
Policy Entropy: 1.02230
Value Function Loss: 1.09010

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.04955

Collected Steps per Second: 8,543.28999
Overall Steps per Second: 7,454.52276

Timestep Collection Time: 5.85582
Timestep Consumption Time: 0.85527
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.71109

Cumulative Model Updates: 29,782
Cumulative Timesteps: 496,758,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 496758938...
Checkpoint 496758938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.38392
Policy Entropy: 1.01376
Value Function Loss: 1.09540

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.23860
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 8,438.12856
Overall Steps per Second: 7,440.35617

Timestep Collection Time: 5.92548
Timestep Consumption Time: 0.79462
PPO Batch Consumption Time: 0.05058
Total Iteration Time: 6.72011

Cumulative Model Updates: 29,785
Cumulative Timesteps: 496,808,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.65818
Policy Entropy: 1.02819
Value Function Loss: 1.12619

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.20332
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.06665

Collected Steps per Second: 8,502.10373
Overall Steps per Second: 7,404.02887

Timestep Collection Time: 5.88396
Timestep Consumption Time: 0.87264
PPO Batch Consumption Time: 0.04132
Total Iteration Time: 6.75659

Cumulative Model Updates: 29,788
Cumulative Timesteps: 496,858,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 496858964...
Checkpoint 496858964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.90976
Policy Entropy: 1.02201
Value Function Loss: 1.19178

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.20053
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.06797

Collected Steps per Second: 8,627.48604
Overall Steps per Second: 7,502.01734

Timestep Collection Time: 5.79821
Timestep Consumption Time: 0.86986
PPO Batch Consumption Time: 0.04690
Total Iteration Time: 6.66807

Cumulative Model Updates: 29,791
Cumulative Timesteps: 496,908,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.25594
Policy Entropy: 0.99515
Value Function Loss: 1.24373

Mean KL Divergence: 0.03051
SB3 Clip Fraction: 0.22509
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 8,948.97752
Overall Steps per Second: 7,723.06488

Timestep Collection Time: 5.58902
Timestep Consumption Time: 0.88717
PPO Batch Consumption Time: 0.04251
Total Iteration Time: 6.47619

Cumulative Model Updates: 29,794
Cumulative Timesteps: 496,959,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 496959004...
Checkpoint 496959004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.31321
Policy Entropy: 1.00847
Value Function Loss: 1.31485

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.19845
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 9,101.04572
Overall Steps per Second: 7,856.32767

Timestep Collection Time: 5.49519
Timestep Consumption Time: 0.87063
PPO Batch Consumption Time: 0.04386
Total Iteration Time: 6.36582

Cumulative Model Updates: 29,797
Cumulative Timesteps: 497,009,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.18007
Policy Entropy: 1.01958
Value Function Loss: 1.24417

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.20687
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 8,593.32592
Overall Steps per Second: 7,553.93375

Timestep Collection Time: 5.81940
Timestep Consumption Time: 0.80073
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 6.62013

Cumulative Model Updates: 29,800
Cumulative Timesteps: 497,059,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 497059024...
Checkpoint 497059024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.09232
Policy Entropy: 1.00202
Value Function Loss: 1.22381

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.18090
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.07289

Collected Steps per Second: 8,876.92253
Overall Steps per Second: 7,623.12199

Timestep Collection Time: 5.63484
Timestep Consumption Time: 0.92678
PPO Batch Consumption Time: 0.04168
Total Iteration Time: 6.56162

Cumulative Model Updates: 29,803
Cumulative Timesteps: 497,109,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.99483
Policy Entropy: 0.99217
Value Function Loss: 1.20954

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.23160
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.07025

Collected Steps per Second: 9,047.20421
Overall Steps per Second: 7,790.68618

Timestep Collection Time: 5.52767
Timestep Consumption Time: 0.89153
PPO Batch Consumption Time: 0.04733
Total Iteration Time: 6.41920

Cumulative Model Updates: 29,806
Cumulative Timesteps: 497,159,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 497159054...
Checkpoint 497159054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.65463
Policy Entropy: 1.00231
Value Function Loss: 1.27489

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.17553
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.08495

Collected Steps per Second: 8,774.39161
Overall Steps per Second: 7,742.00312

Timestep Collection Time: 5.69977
Timestep Consumption Time: 0.76006
PPO Batch Consumption Time: 0.05068
Total Iteration Time: 6.45983

Cumulative Model Updates: 29,809
Cumulative Timesteps: 497,209,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.72101
Policy Entropy: 1.01273
Value Function Loss: 1.20106

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.18540
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.09391

Collected Steps per Second: 8,742.12142
Overall Steps per Second: 7,595.00555

Timestep Collection Time: 5.72195
Timestep Consumption Time: 0.86422
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.58617

Cumulative Model Updates: 29,812
Cumulative Timesteps: 497,259,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497259088...
Checkpoint 497259088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.92934
Policy Entropy: 0.99875
Value Function Loss: 1.12466

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.09328

Collected Steps per Second: 8,679.12130
Overall Steps per Second: 7,574.16104

Timestep Collection Time: 5.76303
Timestep Consumption Time: 0.84074
PPO Batch Consumption Time: 0.04524
Total Iteration Time: 6.60377

Cumulative Model Updates: 29,815
Cumulative Timesteps: 497,309,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.69024
Policy Entropy: 0.98413
Value Function Loss: 1.09277

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.19425
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 8,824.22425
Overall Steps per Second: 7,663.39280

Timestep Collection Time: 5.66826
Timestep Consumption Time: 0.85861
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.52687

Cumulative Model Updates: 29,818
Cumulative Timesteps: 497,359,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 497359124...
Checkpoint 497359124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.80450
Policy Entropy: 1.00722
Value Function Loss: 1.10502

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 8,760.54908
Overall Steps per Second: 7,647.69079

Timestep Collection Time: 5.70832
Timestep Consumption Time: 0.83065
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 6.53897

Cumulative Model Updates: 29,821
Cumulative Timesteps: 497,409,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.94170
Policy Entropy: 1.01718
Value Function Loss: 1.15217

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.18360
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 8,699.08961
Overall Steps per Second: 7,666.81996

Timestep Collection Time: 5.74796
Timestep Consumption Time: 0.77391
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.52187

Cumulative Model Updates: 29,824
Cumulative Timesteps: 497,459,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497459134...
Checkpoint 497459134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.08766
Policy Entropy: 0.99597
Value Function Loss: 1.23833

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.19989
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.06145

Collected Steps per Second: 8,703.08407
Overall Steps per Second: 7,454.24107

Timestep Collection Time: 5.74785
Timestep Consumption Time: 0.96296
PPO Batch Consumption Time: 0.04399
Total Iteration Time: 6.71081

Cumulative Model Updates: 29,827
Cumulative Timesteps: 497,509,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.39002
Policy Entropy: 1.00698
Value Function Loss: 1.32104

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.18929
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 8,565.11499
Overall Steps per Second: 7,504.35559

Timestep Collection Time: 5.83997
Timestep Consumption Time: 0.82549
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.66546

Cumulative Model Updates: 29,830
Cumulative Timesteps: 497,559,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 497559178...
Checkpoint 497559178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.77590
Policy Entropy: 1.00473
Value Function Loss: 1.22159

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.18079
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.05763

Collected Steps per Second: 8,820.49753
Overall Steps per Second: 7,533.63404

Timestep Collection Time: 5.66975
Timestep Consumption Time: 0.96848
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.63823

Cumulative Model Updates: 29,833
Cumulative Timesteps: 497,609,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.62718
Policy Entropy: 1.02067
Value Function Loss: 1.16848

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.17707
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.06116

Collected Steps per Second: 8,862.70367
Overall Steps per Second: 7,597.49404

Timestep Collection Time: 5.64478
Timestep Consumption Time: 0.94002
PPO Batch Consumption Time: 0.04263
Total Iteration Time: 6.58480

Cumulative Model Updates: 29,836
Cumulative Timesteps: 497,659,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 497659216...
Checkpoint 497659216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.45531
Policy Entropy: 1.00436
Value Function Loss: 1.10245

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.04640
Value Function Update Magnitude: 0.06044

Collected Steps per Second: 8,607.15137
Overall Steps per Second: 7,632.29250

Timestep Collection Time: 5.81168
Timestep Consumption Time: 0.74232
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.55399

Cumulative Model Updates: 29,839
Cumulative Timesteps: 497,709,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.86278
Policy Entropy: 0.98288
Value Function Loss: 1.22312

Mean KL Divergence: 0.03296
SB3 Clip Fraction: 0.27851
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.07196

Collected Steps per Second: 8,396.55455
Overall Steps per Second: 7,351.54137

Timestep Collection Time: 5.95673
Timestep Consumption Time: 0.84674
PPO Batch Consumption Time: 0.04687
Total Iteration Time: 6.80347

Cumulative Model Updates: 29,842
Cumulative Timesteps: 497,759,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 497759254...
Checkpoint 497759254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.05098
Policy Entropy: 1.00788
Value Function Loss: 1.22027

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.19029
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.07611

Collected Steps per Second: 8,577.06034
Overall Steps per Second: 7,500.19916

Timestep Collection Time: 5.83207
Timestep Consumption Time: 0.83735
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.66942

Cumulative Model Updates: 29,845
Cumulative Timesteps: 497,809,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.07902
Policy Entropy: 0.99211
Value Function Loss: 1.33049

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.20945
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.06826

Collected Steps per Second: 8,894.42339
Overall Steps per Second: 7,764.00083

Timestep Collection Time: 5.62195
Timestep Consumption Time: 0.81854
PPO Batch Consumption Time: 0.03964
Total Iteration Time: 6.44049

Cumulative Model Updates: 29,848
Cumulative Timesteps: 497,859,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 497859280...
Checkpoint 497859280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.80596
Policy Entropy: 0.99567
Value Function Loss: 1.26764

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.21417
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 8,810.47586
Overall Steps per Second: 7,744.29815

Timestep Collection Time: 5.67801
Timestep Consumption Time: 0.78171
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.45972

Cumulative Model Updates: 29,851
Cumulative Timesteps: 497,909,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.60580
Policy Entropy: 1.00215
Value Function Loss: 1.31799

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.18161
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.06846

Collected Steps per Second: 8,806.11402
Overall Steps per Second: 7,620.53890

Timestep Collection Time: 5.68037
Timestep Consumption Time: 0.88373
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.56410

Cumulative Model Updates: 29,854
Cumulative Timesteps: 497,959,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497959328...
Checkpoint 497959328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.97683
Policy Entropy: 1.00727
Value Function Loss: 1.15207

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 8,838.26404
Overall Steps per Second: 7,699.20903

Timestep Collection Time: 5.65993
Timestep Consumption Time: 0.83736
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.49729

Cumulative Model Updates: 29,857
Cumulative Timesteps: 498,009,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.33689
Policy Entropy: 1.00522
Value Function Loss: 1.19757

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.16500
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 8,843.87425
Overall Steps per Second: 7,722.09095

Timestep Collection Time: 5.65454
Timestep Consumption Time: 0.82143
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 6.47597

Cumulative Model Updates: 29,860
Cumulative Timesteps: 498,059,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 498059360...
Checkpoint 498059360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.84110
Policy Entropy: 1.01037
Value Function Loss: 1.15014

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.06673

Collected Steps per Second: 8,803.13520
Overall Steps per Second: 7,697.23097

Timestep Collection Time: 5.68320
Timestep Consumption Time: 0.81654
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.49974

Cumulative Model Updates: 29,863
Cumulative Timesteps: 498,109,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.79361
Policy Entropy: 1.01316
Value Function Loss: 1.30523

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.15978
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 8,819.30104
Overall Steps per Second: 7,635.48178

Timestep Collection Time: 5.66961
Timestep Consumption Time: 0.87903
PPO Batch Consumption Time: 0.04782
Total Iteration Time: 6.54864

Cumulative Model Updates: 29,866
Cumulative Timesteps: 498,159,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 498159392...
Checkpoint 498159392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.59763
Policy Entropy: 1.00194
Value Function Loss: 1.30670

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.23175
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.05546

Collected Steps per Second: 8,282.53303
Overall Steps per Second: 7,341.33653

Timestep Collection Time: 6.03728
Timestep Consumption Time: 0.77401
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.81129

Cumulative Model Updates: 29,869
Cumulative Timesteps: 498,209,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.40279
Policy Entropy: 1.02456
Value Function Loss: 1.35405

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.17340
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 8,683.83158
Overall Steps per Second: 7,443.05196

Timestep Collection Time: 5.75944
Timestep Consumption Time: 0.96012
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 6.71956

Cumulative Model Updates: 29,872
Cumulative Timesteps: 498,259,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 498259410...
Checkpoint 498259410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.21162
Policy Entropy: 1.02508
Value Function Loss: 1.29618

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.17046
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 8,592.87247
Overall Steps per Second: 7,458.95932

Timestep Collection Time: 5.82157
Timestep Consumption Time: 0.88500
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.70657

Cumulative Model Updates: 29,875
Cumulative Timesteps: 498,309,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.04197
Policy Entropy: 1.00655
Value Function Loss: 1.25918

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.18495
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.06682

Collected Steps per Second: 8,860.74045
Overall Steps per Second: 7,685.85044

Timestep Collection Time: 5.64332
Timestep Consumption Time: 0.86266
PPO Batch Consumption Time: 0.04357
Total Iteration Time: 6.50598

Cumulative Model Updates: 29,878
Cumulative Timesteps: 498,359,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 498359438...
Checkpoint 498359438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.71962
Policy Entropy: 0.99851
Value Function Loss: 1.18358

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.17464
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 8,734.47368
Overall Steps per Second: 7,507.85156

Timestep Collection Time: 5.72628
Timestep Consumption Time: 0.93555
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.66183

Cumulative Model Updates: 29,881
Cumulative Timesteps: 498,409,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.72229
Policy Entropy: 1.00087
Value Function Loss: 1.18834

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.17932
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.06239

Collected Steps per Second: 8,347.15498
Overall Steps per Second: 7,341.28041

Timestep Collection Time: 5.99078
Timestep Consumption Time: 0.82083
PPO Batch Consumption Time: 0.04900
Total Iteration Time: 6.81162

Cumulative Model Updates: 29,884
Cumulative Timesteps: 498,459,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 498459460...
Checkpoint 498459460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.58881
Policy Entropy: 1.00649
Value Function Loss: 1.21547

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.21263
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.05654

Collected Steps per Second: 8,817.55551
Overall Steps per Second: 7,633.08440

Timestep Collection Time: 5.67232
Timestep Consumption Time: 0.88021
PPO Batch Consumption Time: 0.04468
Total Iteration Time: 6.55253

Cumulative Model Updates: 29,887
Cumulative Timesteps: 498,509,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.88235
Policy Entropy: 0.97106
Value Function Loss: 1.20238

Mean KL Divergence: 0.04133
SB3 Clip Fraction: 0.27982
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.05252

Collected Steps per Second: 8,549.41682
Overall Steps per Second: 7,482.12440

Timestep Collection Time: 5.85163
Timestep Consumption Time: 0.83471
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 6.68634

Cumulative Model Updates: 29,890
Cumulative Timesteps: 498,559,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 498559504...
Checkpoint 498559504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.05333
Policy Entropy: 0.99041
Value Function Loss: 1.18257

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.17675
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.05482

Collected Steps per Second: 9,026.56573
Overall Steps per Second: 7,794.07681

Timestep Collection Time: 5.54142
Timestep Consumption Time: 0.87627
PPO Batch Consumption Time: 0.04110
Total Iteration Time: 6.41769

Cumulative Model Updates: 29,893
Cumulative Timesteps: 498,609,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.92292
Policy Entropy: 0.99677
Value Function Loss: 1.14906

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.05269

Collected Steps per Second: 8,242.59499
Overall Steps per Second: 7,192.53012

Timestep Collection Time: 6.06945
Timestep Consumption Time: 0.88610
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.95555

Cumulative Model Updates: 29,896
Cumulative Timesteps: 498,659,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 498659552...
Checkpoint 498659552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.89503
Policy Entropy: 0.97626
Value Function Loss: 1.06806

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.19287
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 8,033.42202
Overall Steps per Second: 7,075.25561

Timestep Collection Time: 6.22699
Timestep Consumption Time: 0.84329
PPO Batch Consumption Time: 0.05129
Total Iteration Time: 7.07027

Cumulative Model Updates: 29,899
Cumulative Timesteps: 498,709,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.92172
Policy Entropy: 0.97482
Value Function Loss: 1.06437

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.24458
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.06466

Collected Steps per Second: 8,600.11517
Overall Steps per Second: 7,415.86555

Timestep Collection Time: 5.81713
Timestep Consumption Time: 0.92895
PPO Batch Consumption Time: 0.04627
Total Iteration Time: 6.74608

Cumulative Model Updates: 29,902
Cumulative Timesteps: 498,759,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 498759604...
Checkpoint 498759604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.33250
Policy Entropy: 0.98169
Value Function Loss: 1.02941

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.18175
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 9,093.21718
Overall Steps per Second: 7,854.81574

Timestep Collection Time: 5.50080
Timestep Consumption Time: 0.86726
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.36807

Cumulative Model Updates: 29,905
Cumulative Timesteps: 498,809,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.06906
Policy Entropy: 0.99176
Value Function Loss: 1.12965

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.07667

Collected Steps per Second: 9,190.98035
Overall Steps per Second: 7,815.72445

Timestep Collection Time: 5.44099
Timestep Consumption Time: 0.95740
PPO Batch Consumption Time: 0.04411
Total Iteration Time: 6.39838

Cumulative Model Updates: 29,908
Cumulative Timesteps: 498,859,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 498859632...
Checkpoint 498859632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.59940
Policy Entropy: 0.97655
Value Function Loss: 1.11642

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.19473
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.06741

Collected Steps per Second: 9,112.02533
Overall Steps per Second: 7,855.78392

Timestep Collection Time: 5.48901
Timestep Consumption Time: 0.87776
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 6.36677

Cumulative Model Updates: 29,911
Cumulative Timesteps: 498,909,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.68313
Policy Entropy: 0.96155
Value Function Loss: 1.15502

Mean KL Divergence: 0.02951
SB3 Clip Fraction: 0.25223
Policy Update Magnitude: 0.04122
Value Function Update Magnitude: 0.06041

Collected Steps per Second: 9,025.49256
Overall Steps per Second: 7,936.42533

Timestep Collection Time: 5.54208
Timestep Consumption Time: 0.76051
PPO Batch Consumption Time: 0.04650
Total Iteration Time: 6.30259

Cumulative Model Updates: 29,914
Cumulative Timesteps: 498,959,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 498959668...
Checkpoint 498959668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.58394
Policy Entropy: 0.98048
Value Function Loss: 1.14954

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.17100
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 9,076.25501
Overall Steps per Second: 7,884.16710

Timestep Collection Time: 5.50954
Timestep Consumption Time: 0.83304
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.34258

Cumulative Model Updates: 29,917
Cumulative Timesteps: 499,009,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.08592
Policy Entropy: 0.98469
Value Function Loss: 1.17356

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 8,723.27953
Overall Steps per Second: 7,641.56787

Timestep Collection Time: 5.73316
Timestep Consumption Time: 0.81157
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.54473

Cumulative Model Updates: 29,920
Cumulative Timesteps: 499,059,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 499059686...
Checkpoint 499059686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.34624
Policy Entropy: 0.94854
Value Function Loss: 1.11744

Mean KL Divergence: 0.03487
SB3 Clip Fraction: 0.25937
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.06625

Collected Steps per Second: 8,638.51684
Overall Steps per Second: 7,545.85677

Timestep Collection Time: 5.79104
Timestep Consumption Time: 0.83856
PPO Batch Consumption Time: 0.04864
Total Iteration Time: 6.62960

Cumulative Model Updates: 29,923
Cumulative Timesteps: 499,109,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.89334
Policy Entropy: 0.97890
Value Function Loss: 1.19089

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.22787
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.06152

Collected Steps per Second: 8,684.74665
Overall Steps per Second: 7,550.50935

Timestep Collection Time: 5.75998
Timestep Consumption Time: 0.86526
PPO Batch Consumption Time: 0.04822
Total Iteration Time: 6.62525

Cumulative Model Updates: 29,926
Cumulative Timesteps: 499,159,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499159736...
Checkpoint 499159736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.43545
Policy Entropy: 0.97503
Value Function Loss: 1.11110

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.21821
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.05834

Collected Steps per Second: 8,751.00648
Overall Steps per Second: 7,757.95431

Timestep Collection Time: 5.71363
Timestep Consumption Time: 0.73137
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.44500

Cumulative Model Updates: 29,929
Cumulative Timesteps: 499,209,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.77877
Policy Entropy: 0.97834
Value Function Loss: 1.08247

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.22657
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.05956

Collected Steps per Second: 8,734.50613
Overall Steps per Second: 7,622.20176

Timestep Collection Time: 5.72648
Timestep Consumption Time: 0.83566
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 6.56215

Cumulative Model Updates: 29,932
Cumulative Timesteps: 499,259,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499259754...
Checkpoint 499259754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.40402
Policy Entropy: 0.97472
Value Function Loss: 0.98023

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.25529
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.06300

Collected Steps per Second: 8,831.29109
Overall Steps per Second: 7,740.76537

Timestep Collection Time: 5.66327
Timestep Consumption Time: 0.79785
PPO Batch Consumption Time: 0.04115
Total Iteration Time: 6.46112

Cumulative Model Updates: 29,935
Cumulative Timesteps: 499,309,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.17252
Policy Entropy: 0.98339
Value Function Loss: 1.05826

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.19691
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 8,832.41087
Overall Steps per Second: 7,722.69021

Timestep Collection Time: 5.66369
Timestep Consumption Time: 0.81385
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.47754

Cumulative Model Updates: 29,938
Cumulative Timesteps: 499,359,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499359792...
Checkpoint 499359792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.70500
Policy Entropy: 0.99608
Value Function Loss: 1.12249

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.19237
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.06578

Collected Steps per Second: 8,595.78826
Overall Steps per Second: 7,493.22600

Timestep Collection Time: 5.81843
Timestep Consumption Time: 0.85613
PPO Batch Consumption Time: 0.04946
Total Iteration Time: 6.67456

Cumulative Model Updates: 29,941
Cumulative Timesteps: 499,409,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.88018
Policy Entropy: 0.97056
Value Function Loss: 1.11869

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.06522

Collected Steps per Second: 8,822.45780
Overall Steps per Second: 7,761.57555

Timestep Collection Time: 5.66985
Timestep Consumption Time: 0.77498
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.44483

Cumulative Model Updates: 29,944
Cumulative Timesteps: 499,459,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 499459828...
Checkpoint 499459828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.77238
Policy Entropy: 0.96133
Value Function Loss: 1.07765

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.21395
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 8,675.53188
Overall Steps per Second: 7,551.34018

Timestep Collection Time: 5.76541
Timestep Consumption Time: 0.85831
PPO Batch Consumption Time: 0.04540
Total Iteration Time: 6.62372

Cumulative Model Updates: 29,947
Cumulative Timesteps: 499,509,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.89098
Policy Entropy: 0.98060
Value Function Loss: 1.06869

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.16659
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.10772

Collected Steps per Second: 8,439.47083
Overall Steps per Second: 7,408.99070

Timestep Collection Time: 5.92549
Timestep Consumption Time: 0.82415
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 6.74964

Cumulative Model Updates: 29,950
Cumulative Timesteps: 499,559,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 499559854...
Checkpoint 499559854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.68137
Policy Entropy: 1.00040
Value Function Loss: 1.07995

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.23157
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.10591

Collected Steps per Second: 8,948.58621
Overall Steps per Second: 7,756.25664

Timestep Collection Time: 5.58882
Timestep Consumption Time: 0.85914
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.44796

Cumulative Model Updates: 29,953
Cumulative Timesteps: 499,609,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.38502
Policy Entropy: 0.98621
Value Function Loss: 1.13419

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 8,703.00776
Overall Steps per Second: 7,629.45007

Timestep Collection Time: 5.74790
Timestep Consumption Time: 0.80880
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.55670

Cumulative Model Updates: 29,956
Cumulative Timesteps: 499,659,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499659890...
Checkpoint 499659890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.82339
Policy Entropy: 0.97303
Value Function Loss: 1.13722

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.21743
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.08016

Collected Steps per Second: 8,734.84415
Overall Steps per Second: 7,664.88622

Timestep Collection Time: 5.72695
Timestep Consumption Time: 0.79944
PPO Batch Consumption Time: 0.04617
Total Iteration Time: 6.52639

Cumulative Model Updates: 29,959
Cumulative Timesteps: 499,709,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.62462
Policy Entropy: 0.99039
Value Function Loss: 1.16869

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.15374
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.08005

Collected Steps per Second: 8,845.70954
Overall Steps per Second: 7,706.15672

Timestep Collection Time: 5.65449
Timestep Consumption Time: 0.83616
PPO Batch Consumption Time: 0.04812
Total Iteration Time: 6.49065

Cumulative Model Updates: 29,962
Cumulative Timesteps: 499,759,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499759932...
Checkpoint 499759932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.07254
Policy Entropy: 0.98759
Value Function Loss: 1.22957

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.07836

Collected Steps per Second: 8,626.01256
Overall Steps per Second: 7,500.89558

Timestep Collection Time: 5.79781
Timestep Consumption Time: 0.86966
PPO Batch Consumption Time: 0.04095
Total Iteration Time: 6.66747

Cumulative Model Updates: 29,965
Cumulative Timesteps: 499,809,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.98133
Policy Entropy: 0.99297
Value Function Loss: 1.18542

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08689

Collected Steps per Second: 9,074.66439
Overall Steps per Second: 7,844.01828

Timestep Collection Time: 5.51117
Timestep Consumption Time: 0.86465
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.37581

Cumulative Model Updates: 29,968
Cumulative Timesteps: 499,859,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 499859956...
Checkpoint 499859956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.50068
Policy Entropy: 1.00739
Value Function Loss: 1.24245

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.17523
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09532

Collected Steps per Second: 8,897.14800
Overall Steps per Second: 7,696.57361

Timestep Collection Time: 5.62180
Timestep Consumption Time: 0.87693
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.49874

Cumulative Model Updates: 29,971
Cumulative Timesteps: 499,909,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.17818
Policy Entropy: 1.01215
Value Function Loss: 1.25795

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 8,644.91195
Overall Steps per Second: 7,584.68840

Timestep Collection Time: 5.78653
Timestep Consumption Time: 0.80887
PPO Batch Consumption Time: 0.04475
Total Iteration Time: 6.59539

Cumulative Model Updates: 29,974
Cumulative Timesteps: 499,959,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499959998...
Checkpoint 499959998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.25361
Policy Entropy: 1.01848
Value Function Loss: 1.29871

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.16141
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.08492

Collected Steps per Second: 8,728.04642
Overall Steps per Second: 7,492.11862

Timestep Collection Time: 5.72912
Timestep Consumption Time: 0.94510
PPO Batch Consumption Time: 0.04429
Total Iteration Time: 6.67421

Cumulative Model Updates: 29,977
Cumulative Timesteps: 500,010,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.76196
Policy Entropy: 1.00433
Value Function Loss: 1.26979

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 8,979.27905
Overall Steps per Second: 7,809.62417

Timestep Collection Time: 5.57038
Timestep Consumption Time: 0.83428
PPO Batch Consumption Time: 0.04645
Total Iteration Time: 6.40466

Cumulative Model Updates: 29,980
Cumulative Timesteps: 500,060,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500060020...
Checkpoint 500060020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.91628
Policy Entropy: 0.99092
Value Function Loss: 1.17230

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.20091
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 8,700.36210
Overall Steps per Second: 7,573.23566

Timestep Collection Time: 5.74919
Timestep Consumption Time: 0.85565
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.60484

Cumulative Model Updates: 29,983
Cumulative Timesteps: 500,110,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.26054
Policy Entropy: 1.00963
Value Function Loss: 1.29973

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.06039

Collected Steps per Second: 8,877.92496
Overall Steps per Second: 7,684.78917

Timestep Collection Time: 5.63375
Timestep Consumption Time: 0.87469
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 6.50844

Cumulative Model Updates: 29,986
Cumulative Timesteps: 500,160,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 500160056...
Checkpoint 500160056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.90354
Policy Entropy: 1.01004
Value Function Loss: 1.28484

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15262
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.06336

Collected Steps per Second: 8,805.95236
Overall Steps per Second: 7,736.19321

Timestep Collection Time: 5.68070
Timestep Consumption Time: 0.78553
PPO Batch Consumption Time: 0.04211
Total Iteration Time: 6.46623

Cumulative Model Updates: 29,989
Cumulative Timesteps: 500,210,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.21624
Policy Entropy: 1.02760
Value Function Loss: 1.32088

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.20920
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 8,691.62121
Overall Steps per Second: 7,574.08583

Timestep Collection Time: 5.75566
Timestep Consumption Time: 0.84923
PPO Batch Consumption Time: 0.04174
Total Iteration Time: 6.60489

Cumulative Model Updates: 29,992
Cumulative Timesteps: 500,260,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 500260106...
Checkpoint 500260106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.04488
Policy Entropy: 1.01119
Value Function Loss: 1.27818

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.06877

Collected Steps per Second: 8,666.66387
Overall Steps per Second: 7,549.83122

Timestep Collection Time: 5.77246
Timestep Consumption Time: 0.85391
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 6.62637

Cumulative Model Updates: 29,995
Cumulative Timesteps: 500,310,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.56085
Policy Entropy: 1.01183
Value Function Loss: 1.25774

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.06417

Collected Steps per Second: 9,075.93803
Overall Steps per Second: 7,879.70669

Timestep Collection Time: 5.51106
Timestep Consumption Time: 0.83664
PPO Batch Consumption Time: 0.04569
Total Iteration Time: 6.34770

Cumulative Model Updates: 29,998
Cumulative Timesteps: 500,360,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500360152...
Checkpoint 500360152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.21703
Policy Entropy: 1.03364
Value Function Loss: 1.16495

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.06025

Collected Steps per Second: 8,799.51743
Overall Steps per Second: 7,619.97971

Timestep Collection Time: 5.68327
Timestep Consumption Time: 0.87974
PPO Batch Consumption Time: 0.04847
Total Iteration Time: 6.56301

Cumulative Model Updates: 30,001
Cumulative Timesteps: 500,410,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.97229
Policy Entropy: 1.03987
Value Function Loss: 1.15666

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.06255

Collected Steps per Second: 8,545.58502
Overall Steps per Second: 7,445.99156

Timestep Collection Time: 5.85402
Timestep Consumption Time: 0.86450
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.71851

Cumulative Model Updates: 30,004
Cumulative Timesteps: 500,460,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 500460188...
Checkpoint 500460188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.86873
Policy Entropy: 1.02605
Value Function Loss: 1.16103

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16625
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.06982

Collected Steps per Second: 8,758.97058
Overall Steps per Second: 7,602.03981

Timestep Collection Time: 5.71163
Timestep Consumption Time: 0.86924
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 6.58087

Cumulative Model Updates: 30,007
Cumulative Timesteps: 500,510,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.24004
Policy Entropy: 1.01931
Value Function Loss: 1.28432

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.20569
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 8,952.82950
Overall Steps per Second: 7,725.95674

Timestep Collection Time: 5.58684
Timestep Consumption Time: 0.88718
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.47402

Cumulative Model Updates: 30,010
Cumulative Timesteps: 500,560,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500560234...
Checkpoint 500560234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.81645
Policy Entropy: 1.03292
Value Function Loss: 1.31421

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.17614
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.06967

Collected Steps per Second: 8,780.06252
Overall Steps per Second: 7,711.93020

Timestep Collection Time: 5.69609
Timestep Consumption Time: 0.78893
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 6.48502

Cumulative Model Updates: 30,013
Cumulative Timesteps: 500,610,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.64461
Policy Entropy: 1.03124
Value Function Loss: 1.31318

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.04214
Value Function Update Magnitude: 0.06949

Collected Steps per Second: 8,976.83922
Overall Steps per Second: 7,778.54286

Timestep Collection Time: 5.57078
Timestep Consumption Time: 0.85819
PPO Batch Consumption Time: 0.04087
Total Iteration Time: 6.42897

Cumulative Model Updates: 30,016
Cumulative Timesteps: 500,660,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500660254...
Checkpoint 500660254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.43532
Policy Entropy: 1.02148
Value Function Loss: 1.20755

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.17702
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 8,644.61925
Overall Steps per Second: 7,549.86878

Timestep Collection Time: 5.78580
Timestep Consumption Time: 0.83896
PPO Batch Consumption Time: 0.04646
Total Iteration Time: 6.62475

Cumulative Model Updates: 30,019
Cumulative Timesteps: 500,710,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.09451
Policy Entropy: 1.02175
Value Function Loss: 1.22045

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.19000
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 9,196.96978
Overall Steps per Second: 8,064.56463

Timestep Collection Time: 5.43810
Timestep Consumption Time: 0.76360
PPO Batch Consumption Time: 0.04784
Total Iteration Time: 6.20170

Cumulative Model Updates: 30,022
Cumulative Timesteps: 500,760,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 500760284...
Checkpoint 500760284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.74165
Policy Entropy: 1.02564
Value Function Loss: 1.23996

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16512
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 9,127.62226
Overall Steps per Second: 7,868.07304

Timestep Collection Time: 5.47832
Timestep Consumption Time: 0.87699
PPO Batch Consumption Time: 0.05020
Total Iteration Time: 6.35530

Cumulative Model Updates: 30,025
Cumulative Timesteps: 500,810,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.43305
Policy Entropy: 1.03671
Value Function Loss: 1.23191

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.19878
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.05274

Collected Steps per Second: 8,858.95284
Overall Steps per Second: 7,710.24978

Timestep Collection Time: 5.64469
Timestep Consumption Time: 0.84097
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 6.48565

Cumulative Model Updates: 30,028
Cumulative Timesteps: 500,860,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 500860294...
Checkpoint 500860294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.37584
Policy Entropy: 0.99562
Value Function Loss: 1.10953

Mean KL Divergence: 0.04871
SB3 Clip Fraction: 0.30310
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.05471

Collected Steps per Second: 9,001.05169
Overall Steps per Second: 7,792.88238

Timestep Collection Time: 5.55735
Timestep Consumption Time: 0.86158
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.41893

Cumulative Model Updates: 30,031
Cumulative Timesteps: 500,910,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.08613
Policy Entropy: 1.03386
Value Function Loss: 1.05722

Mean KL Divergence: 0.03202
SB3 Clip Fraction: 0.24176
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.05258

Collected Steps per Second: 8,502.65484
Overall Steps per Second: 7,448.59703

Timestep Collection Time: 5.88334
Timestep Consumption Time: 0.83256
PPO Batch Consumption Time: 0.04612
Total Iteration Time: 6.71590

Cumulative Model Updates: 30,034
Cumulative Timesteps: 500,960,340

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500960340...
Checkpoint 500960340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.52798
Policy Entropy: 1.00870
Value Function Loss: 1.09860

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.21723
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 8,574.24760
Overall Steps per Second: 7,550.04304

Timestep Collection Time: 5.83282
Timestep Consumption Time: 0.79125
PPO Batch Consumption Time: 0.04979
Total Iteration Time: 6.62407

Cumulative Model Updates: 30,037
Cumulative Timesteps: 501,010,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.08179
Policy Entropy: 1.02481
Value Function Loss: 1.31319

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.19719
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.06048

Collected Steps per Second: 9,007.30316
Overall Steps per Second: 7,764.14572

Timestep Collection Time: 5.55216
Timestep Consumption Time: 0.88899
PPO Batch Consumption Time: 0.04488
Total Iteration Time: 6.44115

Cumulative Model Updates: 30,040
Cumulative Timesteps: 501,060,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 501060362...
Checkpoint 501060362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.31262
Policy Entropy: 1.02388
Value Function Loss: 1.31794

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.18561
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.05950

Collected Steps per Second: 8,897.16858
Overall Steps per Second: 7,764.43061

Timestep Collection Time: 5.62179
Timestep Consumption Time: 0.82015
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.44194

Cumulative Model Updates: 30,043
Cumulative Timesteps: 501,110,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.78043
Policy Entropy: 1.00136
Value Function Loss: 1.28958

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.18323
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 8,806.39264
Overall Steps per Second: 7,774.27554

Timestep Collection Time: 5.68065
Timestep Consumption Time: 0.75417
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.43481

Cumulative Model Updates: 30,046
Cumulative Timesteps: 501,160,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 501160406...
Checkpoint 501160406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.18216
Policy Entropy: 1.00456
Value Function Loss: 1.14267

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.17707
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 8,875.53044
Overall Steps per Second: 7,709.75382

Timestep Collection Time: 5.63572
Timestep Consumption Time: 0.85217
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.48789

Cumulative Model Updates: 30,049
Cumulative Timesteps: 501,210,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.58379
Policy Entropy: 1.01772
Value Function Loss: 1.32909

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 8,742.87496
Overall Steps per Second: 7,554.56036

Timestep Collection Time: 5.72215
Timestep Consumption Time: 0.90008
PPO Batch Consumption Time: 0.04420
Total Iteration Time: 6.62223

Cumulative Model Updates: 30,052
Cumulative Timesteps: 501,260,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501260454...
Checkpoint 501260454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.57348
Policy Entropy: 1.02051
Value Function Loss: 1.31645

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.18842
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 8,729.83166
Overall Steps per Second: 7,534.37542

Timestep Collection Time: 5.72817
Timestep Consumption Time: 0.90887
PPO Batch Consumption Time: 0.04933
Total Iteration Time: 6.63705

Cumulative Model Updates: 30,055
Cumulative Timesteps: 501,310,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.99440
Policy Entropy: 1.01231
Value Function Loss: 1.30396

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.15874
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.05740

Collected Steps per Second: 8,793.60237
Overall Steps per Second: 7,636.13492

Timestep Collection Time: 5.68663
Timestep Consumption Time: 0.86197
PPO Batch Consumption Time: 0.04390
Total Iteration Time: 6.54860

Cumulative Model Updates: 30,058
Cumulative Timesteps: 501,360,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501360466...
Checkpoint 501360466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.14643
Policy Entropy: 1.00225
Value Function Loss: 1.15007

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.20971
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 8,577.13263
Overall Steps per Second: 7,577.86320

Timestep Collection Time: 5.83039
Timestep Consumption Time: 0.76884
PPO Batch Consumption Time: 0.04435
Total Iteration Time: 6.59922

Cumulative Model Updates: 30,061
Cumulative Timesteps: 501,410,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.69024
Policy Entropy: 1.01378
Value Function Loss: 1.17747

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.06107

Collected Steps per Second: 8,682.82632
Overall Steps per Second: 7,555.13885

Timestep Collection Time: 5.76126
Timestep Consumption Time: 0.85993
PPO Batch Consumption Time: 0.04632
Total Iteration Time: 6.62119

Cumulative Model Updates: 30,064
Cumulative Timesteps: 501,460,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 501460498...
Checkpoint 501460498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.01228
Policy Entropy: 1.02086
Value Function Loss: 1.13928

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.06439

Collected Steps per Second: 8,685.62858
Overall Steps per Second: 7,602.48473

Timestep Collection Time: 5.75963
Timestep Consumption Time: 0.82059
PPO Batch Consumption Time: 0.04190
Total Iteration Time: 6.58022

Cumulative Model Updates: 30,067
Cumulative Timesteps: 501,510,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.55807
Policy Entropy: 1.01405
Value Function Loss: 1.16280

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.05757

Collected Steps per Second: 9,011.66911
Overall Steps per Second: 7,804.69325

Timestep Collection Time: 5.54881
Timestep Consumption Time: 0.85811
PPO Batch Consumption Time: 0.04852
Total Iteration Time: 6.40691

Cumulative Model Updates: 30,070
Cumulative Timesteps: 501,560,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 501560528...
Checkpoint 501560528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.81495
Policy Entropy: 1.02582
Value Function Loss: 1.16830

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.18295
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 8,802.08455
Overall Steps per Second: 7,535.40262

Timestep Collection Time: 5.68184
Timestep Consumption Time: 0.95510
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 6.63694

Cumulative Model Updates: 30,073
Cumulative Timesteps: 501,610,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.56467
Policy Entropy: 1.02512
Value Function Loss: 1.25428

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.18231
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 8,674.61160
Overall Steps per Second: 7,665.33355

Timestep Collection Time: 5.76464
Timestep Consumption Time: 0.75902
PPO Batch Consumption Time: 0.04971
Total Iteration Time: 6.52366

Cumulative Model Updates: 30,076
Cumulative Timesteps: 501,660,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501660546...
Checkpoint 501660546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.16028
Policy Entropy: 1.01163
Value Function Loss: 1.32187

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.17687
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.06220

Collected Steps per Second: 8,834.60272
Overall Steps per Second: 7,701.74913

Timestep Collection Time: 5.66160
Timestep Consumption Time: 0.83277
PPO Batch Consumption Time: 0.04040
Total Iteration Time: 6.49437

Cumulative Model Updates: 30,079
Cumulative Timesteps: 501,710,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.62422
Policy Entropy: 1.00210
Value Function Loss: 1.31350

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.21899
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.06159

Collected Steps per Second: 8,824.20379
Overall Steps per Second: 7,640.87672

Timestep Collection Time: 5.66669
Timestep Consumption Time: 0.87759
PPO Batch Consumption Time: 0.05103
Total Iteration Time: 6.54428

Cumulative Model Updates: 30,082
Cumulative Timesteps: 501,760,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 501760568...
Checkpoint 501760568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.48350
Policy Entropy: 1.03031
Value Function Loss: 1.28687

Mean KL Divergence: 0.03039
SB3 Clip Fraction: 0.20481
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 8,718.48289
Overall Steps per Second: 7,598.14011

Timestep Collection Time: 5.73724
Timestep Consumption Time: 0.84595
PPO Batch Consumption Time: 0.04461
Total Iteration Time: 6.58319

Cumulative Model Updates: 30,085
Cumulative Timesteps: 501,810,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.47367
Policy Entropy: 1.01881
Value Function Loss: 1.16965

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.18517
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 8,406.89054
Overall Steps per Second: 7,294.82357

Timestep Collection Time: 5.95083
Timestep Consumption Time: 0.90718
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.85801

Cumulative Model Updates: 30,088
Cumulative Timesteps: 501,860,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501860616...
Checkpoint 501860616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.22503
Policy Entropy: 1.00988
Value Function Loss: 1.22781

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.21377
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.06387

Collected Steps per Second: 8,718.08775
Overall Steps per Second: 7,637.54367

Timestep Collection Time: 5.73658
Timestep Consumption Time: 0.81160
PPO Batch Consumption Time: 0.04664
Total Iteration Time: 6.54818

Cumulative Model Updates: 30,091
Cumulative Timesteps: 501,910,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.85515
Policy Entropy: 1.01786
Value Function Loss: 1.25637

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.18870
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.07084

Collected Steps per Second: 8,759.68303
Overall Steps per Second: 7,627.22285

Timestep Collection Time: 5.71048
Timestep Consumption Time: 0.84787
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.55835

Cumulative Model Updates: 30,094
Cumulative Timesteps: 501,960,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 501960650...
Checkpoint 501960650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.10922
Policy Entropy: 1.02782
Value Function Loss: 1.31452

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.18720
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 8,565.80782
Overall Steps per Second: 7,533.91950

Timestep Collection Time: 5.84020
Timestep Consumption Time: 0.79991
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.64010

Cumulative Model Updates: 30,097
Cumulative Timesteps: 502,010,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.27528
Policy Entropy: 1.01241
Value Function Loss: 1.25233

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.08244

Collected Steps per Second: 8,663.24961
Overall Steps per Second: 7,645.09390

Timestep Collection Time: 5.77405
Timestep Consumption Time: 0.76897
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 6.54302

Cumulative Model Updates: 30,100
Cumulative Timesteps: 502,060,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502060698...
Checkpoint 502060698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.67478
Policy Entropy: 1.00686
Value Function Loss: 1.25922

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 8,453.22765
Overall Steps per Second: 7,364.40064

Timestep Collection Time: 5.91774
Timestep Consumption Time: 0.87494
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.79268

Cumulative Model Updates: 30,103
Cumulative Timesteps: 502,110,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.51239
Policy Entropy: 1.02890
Value Function Loss: 1.21121

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.19580
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 8,630.94913
Overall Steps per Second: 7,537.41131

Timestep Collection Time: 5.79565
Timestep Consumption Time: 0.84084
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.63650

Cumulative Model Updates: 30,106
Cumulative Timesteps: 502,160,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502160744...
Checkpoint 502160744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.77541
Policy Entropy: 1.03091
Value Function Loss: 1.19401

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.19242
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 8,695.65308
Overall Steps per Second: 7,546.81470

Timestep Collection Time: 5.75299
Timestep Consumption Time: 0.87577
PPO Batch Consumption Time: 0.04510
Total Iteration Time: 6.62876

Cumulative Model Updates: 30,109
Cumulative Timesteps: 502,210,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.61586
Policy Entropy: 1.02076
Value Function Loss: 1.16753

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.08534

Collected Steps per Second: 8,806.41667
Overall Steps per Second: 7,637.36544

Timestep Collection Time: 5.68063
Timestep Consumption Time: 0.86953
PPO Batch Consumption Time: 0.04148
Total Iteration Time: 6.55016

Cumulative Model Updates: 30,112
Cumulative Timesteps: 502,260,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 502260796...
Checkpoint 502260796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.38364
Policy Entropy: 1.01799
Value Function Loss: 1.18530

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.17781
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.07843

Collected Steps per Second: 8,213.49356
Overall Steps per Second: 7,278.19723

Timestep Collection Time: 6.08998
Timestep Consumption Time: 0.78260
PPO Batch Consumption Time: 0.04929
Total Iteration Time: 6.87258

Cumulative Model Updates: 30,115
Cumulative Timesteps: 502,310,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.35045
Policy Entropy: 1.03831
Value Function Loss: 1.25292

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.17685
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 8,719.06201
Overall Steps per Second: 7,550.79701

Timestep Collection Time: 5.73731
Timestep Consumption Time: 0.88768
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.62500

Cumulative Model Updates: 30,118
Cumulative Timesteps: 502,360,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502360840...
Checkpoint 502360840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.72798
Policy Entropy: 1.03833
Value Function Loss: 1.32757

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15772
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 8,744.77279
Overall Steps per Second: 7,598.39826

Timestep Collection Time: 5.71930
Timestep Consumption Time: 0.86287
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.58218

Cumulative Model Updates: 30,121
Cumulative Timesteps: 502,410,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.81609
Policy Entropy: 1.02667
Value Function Loss: 1.30901

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.06271

Collected Steps per Second: 8,857.97996
Overall Steps per Second: 7,663.26368

Timestep Collection Time: 5.64779
Timestep Consumption Time: 0.88050
PPO Batch Consumption Time: 0.04197
Total Iteration Time: 6.52829

Cumulative Model Updates: 30,124
Cumulative Timesteps: 502,460,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 502460882...
Checkpoint 502460882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.24583
Policy Entropy: 1.01586
Value Function Loss: 1.19334

Mean KL Divergence: 0.02828
SB3 Clip Fraction: 0.22829
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.06661

Collected Steps per Second: 8,684.74345
Overall Steps per Second: 7,498.85009

Timestep Collection Time: 5.75837
Timestep Consumption Time: 0.91065
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.66902

Cumulative Model Updates: 30,127
Cumulative Timesteps: 502,510,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.90703
Policy Entropy: 1.02839
Value Function Loss: 1.12049

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 8,703.83664
Overall Steps per Second: 7,657.59083

Timestep Collection Time: 5.74620
Timestep Consumption Time: 0.78510
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.53130

Cumulative Model Updates: 30,130
Cumulative Timesteps: 502,560,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 502560906...
Checkpoint 502560906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.13806
Policy Entropy: 1.04546
Value Function Loss: 1.09478

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.21216
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 9,012.34899
Overall Steps per Second: 7,770.63646

Timestep Collection Time: 5.55083
Timestep Consumption Time: 0.88700
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.43783

Cumulative Model Updates: 30,133
Cumulative Timesteps: 502,610,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.62169
Policy Entropy: 1.03517
Value Function Loss: 1.13767

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 8,949.83027
Overall Steps per Second: 7,750.30612

Timestep Collection Time: 5.58759
Timestep Consumption Time: 0.86480
PPO Batch Consumption Time: 0.04727
Total Iteration Time: 6.45239

Cumulative Model Updates: 30,136
Cumulative Timesteps: 502,660,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 502660940...
Checkpoint 502660940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.03821
Policy Entropy: 1.04085
Value Function Loss: 1.13246

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.18155
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.07312

Collected Steps per Second: 8,512.96286
Overall Steps per Second: 7,411.92905

Timestep Collection Time: 5.87363
Timestep Consumption Time: 0.87252
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 6.74615

Cumulative Model Updates: 30,139
Cumulative Timesteps: 502,710,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.18009
Policy Entropy: 1.05838
Value Function Loss: 1.20000

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.07351

Collected Steps per Second: 8,517.09750
Overall Steps per Second: 7,423.43039

Timestep Collection Time: 5.87360
Timestep Consumption Time: 0.86534
PPO Batch Consumption Time: 0.04462
Total Iteration Time: 6.73893

Cumulative Model Updates: 30,142
Cumulative Timesteps: 502,760,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 502760968...
Checkpoint 502760968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.79290
Policy Entropy: 1.05499
Value Function Loss: 1.16268

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.06298

Collected Steps per Second: 8,846.99803
Overall Steps per Second: 7,672.07459

Timestep Collection Time: 5.65412
Timestep Consumption Time: 0.86589
PPO Batch Consumption Time: 0.04745
Total Iteration Time: 6.52001

Cumulative Model Updates: 30,145
Cumulative Timesteps: 502,810,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.24736
Policy Entropy: 1.05129
Value Function Loss: 1.10443

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 8,729.95771
Overall Steps per Second: 7,591.27751

Timestep Collection Time: 5.72786
Timestep Consumption Time: 0.85917
PPO Batch Consumption Time: 0.04556
Total Iteration Time: 6.58703

Cumulative Model Updates: 30,148
Cumulative Timesteps: 502,860,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 502860994...
Checkpoint 502860994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.28190
Policy Entropy: 1.03691
Value Function Loss: 1.12429

Mean KL Divergence: 0.03302
SB3 Clip Fraction: 0.23438
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 8,520.90054
Overall Steps per Second: 7,443.03368

Timestep Collection Time: 5.86957
Timestep Consumption Time: 0.85000
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.71957

Cumulative Model Updates: 30,151
Cumulative Timesteps: 502,911,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.99509
Policy Entropy: 1.05493
Value Function Loss: 1.21213

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.17223
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.07138

Collected Steps per Second: 8,617.17559
Overall Steps per Second: 7,639.49701

Timestep Collection Time: 5.80353
Timestep Consumption Time: 0.74272
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.54624

Cumulative Model Updates: 30,154
Cumulative Timesteps: 502,961,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 502961018...
Checkpoint 502961018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.06732
Policy Entropy: 1.05018
Value Function Loss: 1.23748

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 8,447.07359
Overall Steps per Second: 7,350.07992

Timestep Collection Time: 5.92229
Timestep Consumption Time: 0.88390
PPO Batch Consumption Time: 0.04408
Total Iteration Time: 6.80618

Cumulative Model Updates: 30,157
Cumulative Timesteps: 503,011,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.79024
Policy Entropy: 1.03125
Value Function Loss: 1.23451

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.06490

Collected Steps per Second: 8,716.43544
Overall Steps per Second: 7,737.62691

Timestep Collection Time: 5.73881
Timestep Consumption Time: 0.72596
PPO Batch Consumption Time: 0.04213
Total Iteration Time: 6.46477

Cumulative Model Updates: 30,160
Cumulative Timesteps: 503,061,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 503061066...
Checkpoint 503061066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.17202
Policy Entropy: 1.02735
Value Function Loss: 1.21730

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.21327
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 8,613.62016
Overall Steps per Second: 7,490.82631

Timestep Collection Time: 5.80615
Timestep Consumption Time: 0.87028
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.67643

Cumulative Model Updates: 30,163
Cumulative Timesteps: 503,111,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.89338
Policy Entropy: 1.03674
Value Function Loss: 1.35992

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.08414

Collected Steps per Second: 8,788.67480
Overall Steps per Second: 7,677.78851

Timestep Collection Time: 5.69210
Timestep Consumption Time: 0.82358
PPO Batch Consumption Time: 0.04550
Total Iteration Time: 6.51568

Cumulative Model Updates: 30,166
Cumulative Timesteps: 503,161,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503161104...
Checkpoint 503161104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.74870
Policy Entropy: 1.04606
Value Function Loss: 1.40845

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.09960

Collected Steps per Second: 8,437.21653
Overall Steps per Second: 7,367.78507

Timestep Collection Time: 5.92968
Timestep Consumption Time: 0.86069
PPO Batch Consumption Time: 0.04269
Total Iteration Time: 6.79037

Cumulative Model Updates: 30,169
Cumulative Timesteps: 503,211,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.49109
Policy Entropy: 1.03207
Value Function Loss: 1.37906

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.16824
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 8,456.66248
Overall Steps per Second: 7,359.05760

Timestep Collection Time: 5.91463
Timestep Consumption Time: 0.88217
PPO Batch Consumption Time: 0.04051
Total Iteration Time: 6.79679

Cumulative Model Updates: 30,172
Cumulative Timesteps: 503,261,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 503261152...
Checkpoint 503261152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.25518
Policy Entropy: 1.03582
Value Function Loss: 1.26085

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 8,528.28513
Overall Steps per Second: 7,571.65682

Timestep Collection Time: 5.86495
Timestep Consumption Time: 0.74100
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 6.60595

Cumulative Model Updates: 30,175
Cumulative Timesteps: 503,311,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.55760
Policy Entropy: 1.03683
Value Function Loss: 1.19644

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.18203
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.09658

Collected Steps per Second: 8,842.35873
Overall Steps per Second: 7,622.71054

Timestep Collection Time: 5.65754
Timestep Consumption Time: 0.90522
PPO Batch Consumption Time: 0.04265
Total Iteration Time: 6.56276

Cumulative Model Updates: 30,178
Cumulative Timesteps: 503,361,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503361196...
Checkpoint 503361196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.66716
Policy Entropy: 1.04270
Value Function Loss: 1.21065

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.19669
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 8,721.53016
Overall Steps per Second: 7,642.60019

Timestep Collection Time: 5.73615
Timestep Consumption Time: 0.80979
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.54594

Cumulative Model Updates: 30,181
Cumulative Timesteps: 503,411,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.94747
Policy Entropy: 1.01731
Value Function Loss: 1.17714

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.20733
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.06976

Collected Steps per Second: 8,620.25649
Overall Steps per Second: 7,560.23989

Timestep Collection Time: 5.80331
Timestep Consumption Time: 0.81368
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.61699

Cumulative Model Updates: 30,184
Cumulative Timesteps: 503,461,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503461250...
Checkpoint 503461250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.65797
Policy Entropy: 1.03745
Value Function Loss: 1.14851

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.18592
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 8,691.58894
Overall Steps per Second: 7,551.69110

Timestep Collection Time: 5.75361
Timestep Consumption Time: 0.86848
PPO Batch Consumption Time: 0.04402
Total Iteration Time: 6.62209

Cumulative Model Updates: 30,187
Cumulative Timesteps: 503,511,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.04145
Policy Entropy: 1.04004
Value Function Loss: 1.10035

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.19065
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 8,652.37099
Overall Steps per Second: 7,556.97885

Timestep Collection Time: 5.78131
Timestep Consumption Time: 0.83801
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.61931

Cumulative Model Updates: 30,190
Cumulative Timesteps: 503,561,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 503561280...
Checkpoint 503561280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.29568
Policy Entropy: 1.02500
Value Function Loss: 1.11057

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.17105
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 8,713.13929
Overall Steps per Second: 7,543.46033

Timestep Collection Time: 5.74053
Timestep Consumption Time: 0.89012
PPO Batch Consumption Time: 0.04497
Total Iteration Time: 6.63064

Cumulative Model Updates: 30,193
Cumulative Timesteps: 503,611,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.19906
Policy Entropy: 1.02470
Value Function Loss: 1.15151

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.17019
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.06206

Collected Steps per Second: 8,400.49903
Overall Steps per Second: 7,282.71745

Timestep Collection Time: 5.95393
Timestep Consumption Time: 0.91383
PPO Batch Consumption Time: 0.04308
Total Iteration Time: 6.86777

Cumulative Model Updates: 30,196
Cumulative Timesteps: 503,661,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 503661314...
Checkpoint 503661314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.19713
Policy Entropy: 1.03262
Value Function Loss: 1.24003

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.07071

Collected Steps per Second: 8,505.91770
Overall Steps per Second: 7,536.00836

Timestep Collection Time: 5.88061
Timestep Consumption Time: 0.75685
PPO Batch Consumption Time: 0.04636
Total Iteration Time: 6.63747

Cumulative Model Updates: 30,199
Cumulative Timesteps: 503,711,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.44240
Policy Entropy: 1.03829
Value Function Loss: 1.29334

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.17382
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 8,586.49702
Overall Steps per Second: 7,460.73769

Timestep Collection Time: 5.82589
Timestep Consumption Time: 0.87908
PPO Batch Consumption Time: 0.04577
Total Iteration Time: 6.70497

Cumulative Model Updates: 30,202
Cumulative Timesteps: 503,761,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 503761358...
Checkpoint 503761358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.40154
Policy Entropy: 1.02130
Value Function Loss: 1.26670

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06252

Collected Steps per Second: 8,851.19717
Overall Steps per Second: 7,663.73371

Timestep Collection Time: 5.65144
Timestep Consumption Time: 0.87567
PPO Batch Consumption Time: 0.04141
Total Iteration Time: 6.52711

Cumulative Model Updates: 30,205
Cumulative Timesteps: 503,811,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.43764
Policy Entropy: 1.00673
Value Function Loss: 1.18351

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.17680
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.05912

Collected Steps per Second: 8,504.05898
Overall Steps per Second: 7,494.63276

Timestep Collection Time: 5.88213
Timestep Consumption Time: 0.79224
PPO Batch Consumption Time: 0.04428
Total Iteration Time: 6.67438

Cumulative Model Updates: 30,208
Cumulative Timesteps: 503,861,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 503861402...
Checkpoint 503861402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.22489
Policy Entropy: 1.03039
Value Function Loss: 1.19498

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.19419
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.05446

Collected Steps per Second: 8,476.35208
Overall Steps per Second: 7,378.96140

Timestep Collection Time: 5.90136
Timestep Consumption Time: 0.87764
PPO Batch Consumption Time: 0.04320
Total Iteration Time: 6.77900

Cumulative Model Updates: 30,211
Cumulative Timesteps: 503,911,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.35177
Policy Entropy: 1.02880
Value Function Loss: 1.20866

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.19635
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.05991

Collected Steps per Second: 8,605.62400
Overall Steps per Second: 7,494.16931

Timestep Collection Time: 5.81318
Timestep Consumption Time: 0.86215
PPO Batch Consumption Time: 0.04358
Total Iteration Time: 6.67532

Cumulative Model Updates: 30,214
Cumulative Timesteps: 503,961,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503961450...
Checkpoint 503961450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.18728
Policy Entropy: 1.01542
Value Function Loss: 1.25125

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.18330
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.06179

Collected Steps per Second: 8,794.78917
Overall Steps per Second: 7,623.67681

Timestep Collection Time: 5.68814
Timestep Consumption Time: 0.87378
PPO Batch Consumption Time: 0.04494
Total Iteration Time: 6.56193

Cumulative Model Updates: 30,217
Cumulative Timesteps: 504,011,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.14555
Policy Entropy: 1.00674
Value Function Loss: 1.26334

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.23356
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 8,633.50446
Overall Steps per Second: 7,494.89122

Timestep Collection Time: 5.79139
Timestep Consumption Time: 0.87982
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.67121

Cumulative Model Updates: 30,220
Cumulative Timesteps: 504,061,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 504061476...
Checkpoint 504061476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.96265
Policy Entropy: 1.02305
Value Function Loss: 1.25026

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.05800

Collected Steps per Second: 8,456.79876
Overall Steps per Second: 7,462.57666

Timestep Collection Time: 5.91359
Timestep Consumption Time: 0.78785
PPO Batch Consumption Time: 0.04603
Total Iteration Time: 6.70144

Cumulative Model Updates: 30,223
Cumulative Timesteps: 504,111,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.13611
Policy Entropy: 1.03641
Value Function Loss: 1.20540

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.17365
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.05688

Collected Steps per Second: 8,606.25200
Overall Steps per Second: 7,456.17030

Timestep Collection Time: 5.81298
Timestep Consumption Time: 0.89663
PPO Batch Consumption Time: 0.04409
Total Iteration Time: 6.70961

Cumulative Model Updates: 30,226
Cumulative Timesteps: 504,161,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 504161514...
Checkpoint 504161514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.70346
Policy Entropy: 1.01883
Value Function Loss: 1.24327

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.05962

Collected Steps per Second: 8,467.52104
Overall Steps per Second: 7,398.55851

Timestep Collection Time: 5.90799
Timestep Consumption Time: 0.85360
PPO Batch Consumption Time: 0.04246
Total Iteration Time: 6.76159

Cumulative Model Updates: 30,229
Cumulative Timesteps: 504,211,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.79676
Policy Entropy: 1.01906
Value Function Loss: 1.13657

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.17197
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.06084

Collected Steps per Second: 9,317.77760
Overall Steps per Second: 7,954.09641

Timestep Collection Time: 5.36737
Timestep Consumption Time: 0.92020
PPO Batch Consumption Time: 0.04918
Total Iteration Time: 6.28758

Cumulative Model Updates: 30,232
Cumulative Timesteps: 504,261,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 504261552...
Checkpoint 504261552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.85158
Policy Entropy: 1.02484
Value Function Loss: 1.22910

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.19180
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.06648

Collected Steps per Second: 8,752.25977
Overall Steps per Second: 7,556.10942

Timestep Collection Time: 5.71418
Timestep Consumption Time: 0.90457
PPO Batch Consumption Time: 0.05040
Total Iteration Time: 6.61875

Cumulative Model Updates: 30,235
Cumulative Timesteps: 504,311,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.24090
Policy Entropy: 1.02534
Value Function Loss: 1.18636

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 8,787.31612
Overall Steps per Second: 7,701.27645

Timestep Collection Time: 5.69207
Timestep Consumption Time: 0.80270
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.49477

Cumulative Model Updates: 30,238
Cumulative Timesteps: 504,361,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 504361582...
Checkpoint 504361582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.83209
Policy Entropy: 1.00942
Value Function Loss: 1.33722

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.17832
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.07513

Collected Steps per Second: 9,174.96895
Overall Steps per Second: 7,909.26822

Timestep Collection Time: 5.45135
Timestep Consumption Time: 0.87237
PPO Batch Consumption Time: 0.04508
Total Iteration Time: 6.32372

Cumulative Model Updates: 30,241
Cumulative Timesteps: 504,411,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.75925
Policy Entropy: 1.01150
Value Function Loss: 1.31378

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.18862
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.07802

Collected Steps per Second: 8,883.66607
Overall Steps per Second: 7,673.65056

Timestep Collection Time: 5.63033
Timestep Consumption Time: 0.88782
PPO Batch Consumption Time: 0.04966
Total Iteration Time: 6.51815

Cumulative Model Updates: 30,244
Cumulative Timesteps: 504,461,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 504461616...
Checkpoint 504461616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.05202
Policy Entropy: 1.03046
Value Function Loss: 1.33025

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.07326

Collected Steps per Second: 8,561.82885
Overall Steps per Second: 7,451.86412

Timestep Collection Time: 5.83987
Timestep Consumption Time: 0.86986
PPO Batch Consumption Time: 0.04771
Total Iteration Time: 6.70973

Cumulative Model Updates: 30,247
Cumulative Timesteps: 504,511,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.69779
Policy Entropy: 1.04293
Value Function Loss: 1.24808

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.19583
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 8,505.38652
Overall Steps per Second: 7,378.66494

Timestep Collection Time: 5.87910
Timestep Consumption Time: 0.89774
PPO Batch Consumption Time: 0.04407
Total Iteration Time: 6.77684

Cumulative Model Updates: 30,250
Cumulative Timesteps: 504,561,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 504561620...
Checkpoint 504561620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.11176
Policy Entropy: 1.02878
Value Function Loss: 1.25889

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 8,779.88864
Overall Steps per Second: 7,760.85313

Timestep Collection Time: 5.69643
Timestep Consumption Time: 0.74797
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 6.44439

Cumulative Model Updates: 30,253
Cumulative Timesteps: 504,611,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.57261
Policy Entropy: 1.03719
Value Function Loss: 1.29540

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.16530
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 8,375.35332
Overall Steps per Second: 7,294.03594

Timestep Collection Time: 5.96990
Timestep Consumption Time: 0.88502
PPO Batch Consumption Time: 0.04395
Total Iteration Time: 6.85492

Cumulative Model Updates: 30,256
Cumulative Timesteps: 504,661,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 504661634...
Checkpoint 504661634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.77013
Policy Entropy: 1.04947
Value Function Loss: 1.27454

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.17164
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 8,423.79412
Overall Steps per Second: 7,398.40937

Timestep Collection Time: 5.93699
Timestep Consumption Time: 0.82284
PPO Batch Consumption Time: 0.03914
Total Iteration Time: 6.75983

Cumulative Model Updates: 30,259
Cumulative Timesteps: 504,711,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.54187
Policy Entropy: 1.05224
Value Function Loss: 1.30769

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.18855
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.05744

Collected Steps per Second: 8,574.83814
Overall Steps per Second: 7,597.65175

Timestep Collection Time: 5.83241
Timestep Consumption Time: 0.75015
PPO Batch Consumption Time: 0.04546
Total Iteration Time: 6.58256

Cumulative Model Updates: 30,262
Cumulative Timesteps: 504,761,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 504761658...
Checkpoint 504761658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.94970
Policy Entropy: 1.04987
Value Function Loss: 1.33406

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.16143
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.05596

Collected Steps per Second: 8,658.77329
Overall Steps per Second: 7,562.86478

Timestep Collection Time: 5.77703
Timestep Consumption Time: 0.83713
PPO Batch Consumption Time: 0.05297
Total Iteration Time: 6.61416

Cumulative Model Updates: 30,265
Cumulative Timesteps: 504,811,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.48876
Policy Entropy: 1.06597
Value Function Loss: 1.51486

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.20029
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.06426

Collected Steps per Second: 8,700.74398
Overall Steps per Second: 7,599.84479

Timestep Collection Time: 5.74870
Timestep Consumption Time: 0.83275
PPO Batch Consumption Time: 0.04207
Total Iteration Time: 6.58145

Cumulative Model Updates: 30,268
Cumulative Timesteps: 504,861,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 504861698...
Checkpoint 504861698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.18235
Policy Entropy: 1.06840
Value Function Loss: 1.45455

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.17222
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.06333

Collected Steps per Second: 8,892.82197
Overall Steps per Second: 7,722.32788

Timestep Collection Time: 5.62364
Timestep Consumption Time: 0.85239
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.47603

Cumulative Model Updates: 30,271
Cumulative Timesteps: 504,911,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.20627
Policy Entropy: 1.05774
Value Function Loss: 1.38411

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.05764

Collected Steps per Second: 8,677.64320
Overall Steps per Second: 7,549.91495

Timestep Collection Time: 5.76447
Timestep Consumption Time: 0.86104
PPO Batch Consumption Time: 0.04241
Total Iteration Time: 6.62551

Cumulative Model Updates: 30,274
Cumulative Timesteps: 504,961,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504961730...
Checkpoint 504961730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.92211
Policy Entropy: 1.04870
Value Function Loss: 1.29399

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.19366
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 8,534.75881
Overall Steps per Second: 7,584.06547

Timestep Collection Time: 5.85863
Timestep Consumption Time: 0.73440
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.59303

Cumulative Model Updates: 30,277
Cumulative Timesteps: 505,011,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.22654
Policy Entropy: 1.06043
Value Function Loss: 1.42000

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.06260

Collected Steps per Second: 8,667.52126
Overall Steps per Second: 7,545.90168

Timestep Collection Time: 5.77143
Timestep Consumption Time: 0.85786
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.62929

Cumulative Model Updates: 30,280
Cumulative Timesteps: 505,061,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 505061756...
Checkpoint 505061756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.43707
Policy Entropy: 1.06403
Value Function Loss: 1.48898

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 8,677.47427
Overall Steps per Second: 7,577.52410

Timestep Collection Time: 5.76228
Timestep Consumption Time: 0.83645
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 6.59873

Cumulative Model Updates: 30,283
Cumulative Timesteps: 505,111,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.75426
Policy Entropy: 1.05828
Value Function Loss: 1.48745

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.07035

Collected Steps per Second: 8,767.27574
Overall Steps per Second: 7,609.12351

Timestep Collection Time: 5.70485
Timestep Consumption Time: 0.86831
PPO Batch Consumption Time: 0.04640
Total Iteration Time: 6.57316

Cumulative Model Updates: 30,286
Cumulative Timesteps: 505,161,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 505161774...
Checkpoint 505161774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.47905
Policy Entropy: 1.05636
Value Function Loss: 1.45894

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.06921

Collected Steps per Second: 8,964.06641
Overall Steps per Second: 7,751.26837

Timestep Collection Time: 5.57783
Timestep Consumption Time: 0.87273
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.45056

Cumulative Model Updates: 30,289
Cumulative Timesteps: 505,211,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.22460
Policy Entropy: 1.05455
Value Function Loss: 1.39146

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.06518

Collected Steps per Second: 8,397.82992
Overall Steps per Second: 7,474.47900

Timestep Collection Time: 5.95559
Timestep Consumption Time: 0.73572
PPO Batch Consumption Time: 0.04625
Total Iteration Time: 6.69130

Cumulative Model Updates: 30,292
Cumulative Timesteps: 505,261,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 505261788...
Checkpoint 505261788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.58866
Policy Entropy: 1.06251
Value Function Loss: 1.34787

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.06932
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 8,694.00669
Overall Steps per Second: 7,534.56022

Timestep Collection Time: 5.75224
Timestep Consumption Time: 0.88518
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.63741

Cumulative Model Updates: 30,295
Cumulative Timesteps: 505,311,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.67462
Policy Entropy: 1.05799
Value Function Loss: 1.27564

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.07640
Value Function Update Magnitude: 0.08856

Collected Steps per Second: 8,894.95936
Overall Steps per Second: 7,690.73860

Timestep Collection Time: 5.62431
Timestep Consumption Time: 0.88066
PPO Batch Consumption Time: 0.04582
Total Iteration Time: 6.50497

Cumulative Model Updates: 30,298
Cumulative Timesteps: 505,361,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 505361826...
Checkpoint 505361826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.49828
Policy Entropy: 1.05629
Value Function Loss: 1.29749

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.07469
Value Function Update Magnitude: 0.10359

Collected Steps per Second: 8,728.69240
Overall Steps per Second: 7,691.79354

Timestep Collection Time: 5.73098
Timestep Consumption Time: 0.77257
PPO Batch Consumption Time: 0.04454
Total Iteration Time: 6.50355

Cumulative Model Updates: 30,301
Cumulative Timesteps: 505,411,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.90897
Policy Entropy: 1.03748
Value Function Loss: 1.32817

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.21642
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 8,435.25611
Overall Steps per Second: 7,366.34350

Timestep Collection Time: 5.92821
Timestep Consumption Time: 0.86023
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.78844

Cumulative Model Updates: 30,304
Cumulative Timesteps: 505,461,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 505461856...
Checkpoint 505461856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.53516
Policy Entropy: 1.05542
Value Function Loss: 1.39898

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15683
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.09120

Collected Steps per Second: 8,781.50884
Overall Steps per Second: 7,553.88435

Timestep Collection Time: 5.69401
Timestep Consumption Time: 0.92537
PPO Batch Consumption Time: 0.05142
Total Iteration Time: 6.61938

Cumulative Model Updates: 30,307
Cumulative Timesteps: 505,511,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.24499
Policy Entropy: 1.06003
Value Function Loss: 1.41448

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.09016

Collected Steps per Second: 8,313.26880
Overall Steps per Second: 7,228.83198

Timestep Collection Time: 6.01713
Timestep Consumption Time: 0.90266
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.91979

Cumulative Model Updates: 30,310
Cumulative Timesteps: 505,561,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 505561880...
Checkpoint 505561880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.79667
Policy Entropy: 1.04700
Value Function Loss: 1.38950

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.09505

Collected Steps per Second: 8,658.38517
Overall Steps per Second: 7,439.13730

Timestep Collection Time: 5.77637
Timestep Consumption Time: 0.94673
PPO Batch Consumption Time: 0.04691
Total Iteration Time: 6.72309

Cumulative Model Updates: 30,313
Cumulative Timesteps: 505,611,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.39683
Policy Entropy: 1.02867
Value Function Loss: 1.38362

Mean KL Divergence: 0.03004
SB3 Clip Fraction: 0.21113
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.09512

Collected Steps per Second: 8,652.44904
Overall Steps per Second: 7,613.03917

Timestep Collection Time: 5.78102
Timestep Consumption Time: 0.78928
PPO Batch Consumption Time: 0.04943
Total Iteration Time: 6.57031

Cumulative Model Updates: 30,316
Cumulative Timesteps: 505,661,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 505661914...
Checkpoint 505661914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.77500
Policy Entropy: 1.04575
Value Function Loss: 1.39817

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 8,592.15551
Overall Steps per Second: 7,448.56097

Timestep Collection Time: 5.82182
Timestep Consumption Time: 0.89384
PPO Batch Consumption Time: 0.04503
Total Iteration Time: 6.71566

Cumulative Model Updates: 30,319
Cumulative Timesteps: 505,711,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.96164
Policy Entropy: 1.05033
Value Function Loss: 1.43318

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.18879
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.08474

Collected Steps per Second: 8,486.21741
Overall Steps per Second: 7,383.75399

Timestep Collection Time: 5.89544
Timestep Consumption Time: 0.88024
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.77569

Cumulative Model Updates: 30,322
Cumulative Timesteps: 505,761,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 505761966...
Checkpoint 505761966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.75914
Policy Entropy: 1.03699
Value Function Loss: 1.31232

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.16721
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 8,722.51958
Overall Steps per Second: 7,539.28555

Timestep Collection Time: 5.73366
Timestep Consumption Time: 0.89986
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.63352

Cumulative Model Updates: 30,325
Cumulative Timesteps: 505,811,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.81952
Policy Entropy: 1.02981
Value Function Loss: 1.33499

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.21421
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 8,773.01509
Overall Steps per Second: 7,666.82064

Timestep Collection Time: 5.70157
Timestep Consumption Time: 0.82264
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.52422

Cumulative Model Updates: 30,328
Cumulative Timesteps: 505,861,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 505861998...
Checkpoint 505861998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.89398
Policy Entropy: 1.05105
Value Function Loss: 1.31424

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.06439

Collected Steps per Second: 8,331.75863
Overall Steps per Second: 7,367.22514

Timestep Collection Time: 6.00113
Timestep Consumption Time: 0.78568
PPO Batch Consumption Time: 0.04673
Total Iteration Time: 6.78682

Cumulative Model Updates: 30,331
Cumulative Timesteps: 505,911,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.63712
Policy Entropy: 1.05030
Value Function Loss: 1.37523

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 8,724.10048
Overall Steps per Second: 7,549.65140

Timestep Collection Time: 5.73217
Timestep Consumption Time: 0.89172
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 6.62388

Cumulative Model Updates: 30,334
Cumulative Timesteps: 505,962,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 505962006...
Checkpoint 505962006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.51997
Policy Entropy: 1.04124
Value Function Loss: 1.26774

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 8,656.76298
Overall Steps per Second: 7,536.58346

Timestep Collection Time: 5.77652
Timestep Consumption Time: 0.85858
PPO Batch Consumption Time: 0.04107
Total Iteration Time: 6.63510

Cumulative Model Updates: 30,337
Cumulative Timesteps: 506,012,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.30684
Policy Entropy: 1.04814
Value Function Loss: 1.25290

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 9,270.22869
Overall Steps per Second: 7,939.80901

Timestep Collection Time: 5.39361
Timestep Consumption Time: 0.90377
PPO Batch Consumption Time: 0.05292
Total Iteration Time: 6.29738

Cumulative Model Updates: 30,340
Cumulative Timesteps: 506,062,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 506062012...
Checkpoint 506062012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.68666
Policy Entropy: 1.06254
Value Function Loss: 1.24442

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.18009
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.08896

Collected Steps per Second: 8,997.86750
Overall Steps per Second: 7,761.74097

Timestep Collection Time: 5.55709
Timestep Consumption Time: 0.88502
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 6.44211

Cumulative Model Updates: 30,343
Cumulative Timesteps: 506,112,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.47241
Policy Entropy: 1.06093
Value Function Loss: 1.30021

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.05971
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 8,674.29961
Overall Steps per Second: 7,641.71061

Timestep Collection Time: 5.76715
Timestep Consumption Time: 0.77929
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.54644

Cumulative Model Updates: 30,346
Cumulative Timesteps: 506,162,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 506162040...
Checkpoint 506162040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.52120
Policy Entropy: 1.04876
Value Function Loss: 1.17001

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.06957
Value Function Update Magnitude: 0.07437

Collected Steps per Second: 9,040.84129
Overall Steps per Second: 7,788.14477

Timestep Collection Time: 5.53201
Timestep Consumption Time: 0.88980
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.42181

Cumulative Model Updates: 30,349
Cumulative Timesteps: 506,212,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.05192
Policy Entropy: 1.05465
Value Function Loss: 1.19317

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.17739
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.07521

Collected Steps per Second: 9,295.07353
Overall Steps per Second: 8,037.97411

Timestep Collection Time: 5.38048
Timestep Consumption Time: 0.84148
PPO Batch Consumption Time: 0.03951
Total Iteration Time: 6.22197

Cumulative Model Updates: 30,352
Cumulative Timesteps: 506,262,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 506262066...
Checkpoint 506262066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.20450
Policy Entropy: 1.06075
Value Function Loss: 1.27416

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 8,665.86452
Overall Steps per Second: 7,663.82945

Timestep Collection Time: 5.77207
Timestep Consumption Time: 0.75469
PPO Batch Consumption Time: 0.04759
Total Iteration Time: 6.52676

Cumulative Model Updates: 30,355
Cumulative Timesteps: 506,312,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.43721
Policy Entropy: 1.05148
Value Function Loss: 1.39241

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.06790

Collected Steps per Second: 8,567.05558
Overall Steps per Second: 7,424.14183

Timestep Collection Time: 5.83981
Timestep Consumption Time: 0.89901
PPO Batch Consumption Time: 0.04956
Total Iteration Time: 6.73883

Cumulative Model Updates: 30,358
Cumulative Timesteps: 506,362,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 506362116...
Checkpoint 506362116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.58068
Policy Entropy: 1.04286
Value Function Loss: 1.34060

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.21207
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 8,663.90002
Overall Steps per Second: 7,570.88442

Timestep Collection Time: 5.77130
Timestep Consumption Time: 0.83321
PPO Batch Consumption Time: 0.03993
Total Iteration Time: 6.60451

Cumulative Model Updates: 30,361
Cumulative Timesteps: 506,412,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.43049
Policy Entropy: 1.05650
Value Function Loss: 1.26006

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.17057
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 8,912.73317
Overall Steps per Second: 7,725.36520

Timestep Collection Time: 5.61062
Timestep Consumption Time: 0.86234
PPO Batch Consumption Time: 0.04534
Total Iteration Time: 6.47296

Cumulative Model Updates: 30,364
Cumulative Timesteps: 506,462,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 506462124...
Checkpoint 506462124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.62499
Policy Entropy: 1.06466
Value Function Loss: 1.19536

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 8,707.08810
Overall Steps per Second: 7,583.53544

Timestep Collection Time: 5.74497
Timestep Consumption Time: 0.85116
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.59613

Cumulative Model Updates: 30,367
Cumulative Timesteps: 506,512,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.20809
Policy Entropy: 1.04554
Value Function Loss: 1.22747

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.07729

Collected Steps per Second: 8,779.54695
Overall Steps per Second: 7,722.04838

Timestep Collection Time: 5.69619
Timestep Consumption Time: 0.78007
PPO Batch Consumption Time: 0.04270
Total Iteration Time: 6.47626

Cumulative Model Updates: 30,370
Cumulative Timesteps: 506,562,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 506562156...
Checkpoint 506562156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.38885
Policy Entropy: 1.03468
Value Function Loss: 1.15874

Mean KL Divergence: 0.03323
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 8,469.17044
Overall Steps per Second: 7,398.14372

Timestep Collection Time: 5.90684
Timestep Consumption Time: 0.85513
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.76197

Cumulative Model Updates: 30,373
Cumulative Timesteps: 506,612,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.10556
Policy Entropy: 1.04565
Value Function Loss: 1.25952

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.07962

Collected Steps per Second: 8,802.61984
Overall Steps per Second: 7,694.70237

Timestep Collection Time: 5.68217
Timestep Consumption Time: 0.81814
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.50032

Cumulative Model Updates: 30,376
Cumulative Timesteps: 506,662,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 506662200...
Checkpoint 506662200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.48473
Policy Entropy: 1.04390
Value Function Loss: 1.14374

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.08109

Collected Steps per Second: 8,761.48285
Overall Steps per Second: 7,672.45888

Timestep Collection Time: 5.70794
Timestep Consumption Time: 0.81018
PPO Batch Consumption Time: 0.03929
Total Iteration Time: 6.51812

Cumulative Model Updates: 30,379
Cumulative Timesteps: 506,712,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.35077
Policy Entropy: 1.02367
Value Function Loss: 1.15397

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.22612
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.07038

Collected Steps per Second: 8,614.96359
Overall Steps per Second: 7,488.58918

Timestep Collection Time: 5.80618
Timestep Consumption Time: 0.87332
PPO Batch Consumption Time: 0.04139
Total Iteration Time: 6.67950

Cumulative Model Updates: 30,382
Cumulative Timesteps: 506,762,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 506762230...
Checkpoint 506762230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.91107
Policy Entropy: 1.04280
Value Function Loss: 1.10598

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.16743
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.05591

Collected Steps per Second: 8,546.92425
Overall Steps per Second: 7,405.73933

Timestep Collection Time: 5.85053
Timestep Consumption Time: 0.90153
PPO Batch Consumption Time: 0.04957
Total Iteration Time: 6.75206

Cumulative Model Updates: 30,385
Cumulative Timesteps: 506,812,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.14188
Policy Entropy: 1.03591
Value Function Loss: 1.21653

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.05968

Collected Steps per Second: 8,742.00839
Overall Steps per Second: 7,570.27763

Timestep Collection Time: 5.72180
Timestep Consumption Time: 0.88562
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.60742

Cumulative Model Updates: 30,388
Cumulative Timesteps: 506,862,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 506862254...
Checkpoint 506862254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.32172
Policy Entropy: 1.03879
Value Function Loss: 1.27334

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 8,754.78405
Overall Steps per Second: 7,655.54855

Timestep Collection Time: 5.71390
Timestep Consumption Time: 0.82044
PPO Batch Consumption Time: 0.04100
Total Iteration Time: 6.53435

Cumulative Model Updates: 30,391
Cumulative Timesteps: 506,912,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.03251
Policy Entropy: 1.02888
Value Function Loss: 1.28461

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.05362

Collected Steps per Second: 8,745.17219
Overall Steps per Second: 7,697.06265

Timestep Collection Time: 5.71836
Timestep Consumption Time: 0.77867
PPO Batch Consumption Time: 0.04506
Total Iteration Time: 6.49702

Cumulative Model Updates: 30,394
Cumulative Timesteps: 506,962,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 506962286...
Checkpoint 506962286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.71979
Policy Entropy: 1.04963
Value Function Loss: 1.41361

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 8,829.34568
Overall Steps per Second: 7,677.13209

Timestep Collection Time: 5.66565
Timestep Consumption Time: 0.85032
PPO Batch Consumption Time: 0.04369
Total Iteration Time: 6.51597

Cumulative Model Updates: 30,397
Cumulative Timesteps: 507,012,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.03371
Policy Entropy: 1.04931
Value Function Loss: 1.31701

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.05268

Collected Steps per Second: 8,532.63151
Overall Steps per Second: 7,498.02520

Timestep Collection Time: 5.86173
Timestep Consumption Time: 0.80882
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.67056

Cumulative Model Updates: 30,400
Cumulative Timesteps: 507,062,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 507062326...
Checkpoint 507062326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.32037
Policy Entropy: 1.03589
Value Function Loss: 1.32750

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.16242
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 8,757.88773
Overall Steps per Second: 7,631.64147

Timestep Collection Time: 5.71234
Timestep Consumption Time: 0.84300
PPO Batch Consumption Time: 0.04138
Total Iteration Time: 6.55534

Cumulative Model Updates: 30,403
Cumulative Timesteps: 507,112,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.53325
Policy Entropy: 1.02749
Value Function Loss: 1.24160

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.18427
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.05270

Collected Steps per Second: 8,892.48933
Overall Steps per Second: 7,703.25956

Timestep Collection Time: 5.62475
Timestep Consumption Time: 0.86835
PPO Batch Consumption Time: 0.04326
Total Iteration Time: 6.49310

Cumulative Model Updates: 30,406
Cumulative Timesteps: 507,162,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 507162372...
Checkpoint 507162372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.56355
Policy Entropy: 1.04969
Value Function Loss: 1.20924

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.05393

Collected Steps per Second: 8,687.20839
Overall Steps per Second: 7,631.00325

Timestep Collection Time: 5.75582
Timestep Consumption Time: 0.79666
PPO Batch Consumption Time: 0.04430
Total Iteration Time: 6.55248

Cumulative Model Updates: 30,409
Cumulative Timesteps: 507,212,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.16718
Policy Entropy: 1.04241
Value Function Loss: 1.16125

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.05339

Collected Steps per Second: 8,689.17935
Overall Steps per Second: 7,484.09529

Timestep Collection Time: 5.75543
Timestep Consumption Time: 0.92674
PPO Batch Consumption Time: 0.04470
Total Iteration Time: 6.68217

Cumulative Model Updates: 30,412
Cumulative Timesteps: 507,262,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 507262384...
Checkpoint 507262384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.12098
Policy Entropy: 1.03181
Value Function Loss: 1.16060

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 8,683.81146
Overall Steps per Second: 7,565.56483

Timestep Collection Time: 5.76037
Timestep Consumption Time: 0.85143
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.61180

Cumulative Model Updates: 30,415
Cumulative Timesteps: 507,312,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.68184
Policy Entropy: 1.03523
Value Function Loss: 1.30620

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 8,732.71656
Overall Steps per Second: 7,663.29058

Timestep Collection Time: 5.72560
Timestep Consumption Time: 0.79902
PPO Batch Consumption Time: 0.04427
Total Iteration Time: 6.52461

Cumulative Model Updates: 30,418
Cumulative Timesteps: 507,362,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 507362406...
Checkpoint 507362406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.88654
Policy Entropy: 1.04368
Value Function Loss: 1.35789

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.16134
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 8,346.20828
Overall Steps per Second: 7,262.71946

Timestep Collection Time: 5.99122
Timestep Consumption Time: 0.89380
PPO Batch Consumption Time: 0.04584
Total Iteration Time: 6.88502

Cumulative Model Updates: 30,421
Cumulative Timesteps: 507,412,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.58266
Policy Entropy: 1.04134
Value Function Loss: 1.34373

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 8,591.76712
Overall Steps per Second: 7,521.67862

Timestep Collection Time: 5.82185
Timestep Consumption Time: 0.82826
PPO Batch Consumption Time: 0.04098
Total Iteration Time: 6.65011

Cumulative Model Updates: 30,424
Cumulative Timesteps: 507,462,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 507462430...
Checkpoint 507462430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.20246
Policy Entropy: 1.03265
Value Function Loss: 1.30292

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.06099

Collected Steps per Second: 8,506.95664
Overall Steps per Second: 7,310.17855

Timestep Collection Time: 5.87801
Timestep Consumption Time: 0.96231
PPO Batch Consumption Time: 0.04998
Total Iteration Time: 6.84033

Cumulative Model Updates: 30,427
Cumulative Timesteps: 507,512,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.45598
Policy Entropy: 1.03670
Value Function Loss: 1.24064

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.06092

Collected Steps per Second: 8,807.01819
Overall Steps per Second: 7,627.78937

Timestep Collection Time: 5.68047
Timestep Consumption Time: 0.87818
PPO Batch Consumption Time: 0.04629
Total Iteration Time: 6.55865

Cumulative Model Updates: 30,430
Cumulative Timesteps: 507,562,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 507562462...
Checkpoint 507562462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.98779
Policy Entropy: 1.03669
Value Function Loss: 1.20182

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.18426
Policy Update Magnitude: 0.06995
Value Function Update Magnitude: 0.06658

Collected Steps per Second: 8,396.36752
Overall Steps per Second: 7,452.54510

Timestep Collection Time: 5.95496
Timestep Consumption Time: 0.75416
PPO Batch Consumption Time: 0.04182
Total Iteration Time: 6.70912

Cumulative Model Updates: 30,433
Cumulative Timesteps: 507,612,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.72536
Policy Entropy: 1.04934
Value Function Loss: 1.09080

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 8,494.52803
Overall Steps per Second: 7,335.65609

Timestep Collection Time: 5.88661
Timestep Consumption Time: 0.92996
PPO Batch Consumption Time: 0.05138
Total Iteration Time: 6.81657

Cumulative Model Updates: 30,436
Cumulative Timesteps: 507,662,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 507662466...
Checkpoint 507662466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.21068
Policy Entropy: 1.04801
Value Function Loss: 1.20147

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.07201
Value Function Update Magnitude: 0.09377

Collected Steps per Second: 8,620.83190
Overall Steps per Second: 7,394.76422

Timestep Collection Time: 5.79990
Timestep Consumption Time: 0.96164
PPO Batch Consumption Time: 0.04865
Total Iteration Time: 6.76154

Cumulative Model Updates: 30,439
Cumulative Timesteps: 507,712,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.46377
Policy Entropy: 1.04728
Value Function Loss: 1.17585

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.08766

Collected Steps per Second: 8,615.17778
Overall Steps per Second: 7,587.27494

Timestep Collection Time: 5.80534
Timestep Consumption Time: 0.78649
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.59183

Cumulative Model Updates: 30,442
Cumulative Timesteps: 507,762,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 507762480...
Checkpoint 507762480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.32632
Policy Entropy: 1.03396
Value Function Loss: 1.26272

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.19144
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 8,574.36466
Overall Steps per Second: 7,440.53221

Timestep Collection Time: 5.83157
Timestep Consumption Time: 0.88865
PPO Batch Consumption Time: 0.04550
Total Iteration Time: 6.72022

Cumulative Model Updates: 30,445
Cumulative Timesteps: 507,812,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.18282
Policy Entropy: 1.05649
Value Function Loss: 1.31749

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.10173

Collected Steps per Second: 8,561.54288
Overall Steps per Second: 7,529.94129

Timestep Collection Time: 5.84334
Timestep Consumption Time: 0.80054
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.64388

Cumulative Model Updates: 30,448
Cumulative Timesteps: 507,862,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 507862510...
Checkpoint 507862510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.06492
Policy Entropy: 1.06680
Value Function Loss: 1.30831

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 9,190.33160
Overall Steps per Second: 7,900.77936

Timestep Collection Time: 5.44050
Timestep Consumption Time: 0.88799
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.32849

Cumulative Model Updates: 30,451
Cumulative Timesteps: 507,912,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.60813
Policy Entropy: 1.05755
Value Function Loss: 1.25968

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 8,569.58831
Overall Steps per Second: 7,428.85856

Timestep Collection Time: 5.83599
Timestep Consumption Time: 0.89614
PPO Batch Consumption Time: 0.04716
Total Iteration Time: 6.73212

Cumulative Model Updates: 30,454
Cumulative Timesteps: 507,962,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 507962522...
Checkpoint 507962522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.53378
Policy Entropy: 1.05568
Value Function Loss: 1.08939

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.15694
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.09972

Collected Steps per Second: 8,855.69432
Overall Steps per Second: 7,684.85814

Timestep Collection Time: 5.64879
Timestep Consumption Time: 0.86063
PPO Batch Consumption Time: 0.04220
Total Iteration Time: 6.50942

Cumulative Model Updates: 30,457
Cumulative Timesteps: 508,012,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.49474
Policy Entropy: 1.06189
Value Function Loss: 1.18482

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.08726

Collected Steps per Second: 9,022.20301
Overall Steps per Second: 7,737.88394

Timestep Collection Time: 5.54477
Timestep Consumption Time: 0.92031
PPO Batch Consumption Time: 0.04117
Total Iteration Time: 6.46508

Cumulative Model Updates: 30,460
Cumulative Timesteps: 508,062,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 508062572...
Checkpoint 508062572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.56304
Policy Entropy: 1.06364
Value Function Loss: 1.25675

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.07799

Collected Steps per Second: 8,544.68966
Overall Steps per Second: 7,560.26594

Timestep Collection Time: 5.85346
Timestep Consumption Time: 0.76218
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.61564

Cumulative Model Updates: 30,463
Cumulative Timesteps: 508,112,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.19530
Policy Entropy: 1.06133
Value Function Loss: 1.36808

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 8,798.92137
Overall Steps per Second: 7,546.66065

Timestep Collection Time: 5.68274
Timestep Consumption Time: 0.94297
PPO Batch Consumption Time: 0.04720
Total Iteration Time: 6.62571

Cumulative Model Updates: 30,466
Cumulative Timesteps: 508,162,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 508162590...
Checkpoint 508162590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.08392
Policy Entropy: 1.05624
Value Function Loss: 1.35619

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.07560
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 8,156.75384
Overall Steps per Second: 7,159.64113

Timestep Collection Time: 6.13185
Timestep Consumption Time: 0.85397
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 6.98583

Cumulative Model Updates: 30,469
Cumulative Timesteps: 508,212,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.36440
Policy Entropy: 1.05872
Value Function Loss: 1.38886

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.18125
Policy Update Magnitude: 0.06597
Value Function Update Magnitude: 0.08301

Collected Steps per Second: 8,690.13526
Overall Steps per Second: 7,690.25272

Timestep Collection Time: 5.75526
Timestep Consumption Time: 0.74830
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.50356

Cumulative Model Updates: 30,472
Cumulative Timesteps: 508,262,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 508262620...
Checkpoint 508262620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.77811
Policy Entropy: 1.07612
Value Function Loss: 1.47021

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.08268

Collected Steps per Second: 8,590.02491
Overall Steps per Second: 7,492.71759

Timestep Collection Time: 5.82327
Timestep Consumption Time: 0.85282
PPO Batch Consumption Time: 0.04311
Total Iteration Time: 6.67608

Cumulative Model Updates: 30,475
Cumulative Timesteps: 508,312,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.96810
Policy Entropy: 1.08952
Value Function Loss: 1.48060

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 8,643.36453
Overall Steps per Second: 7,543.29124

Timestep Collection Time: 5.78664
Timestep Consumption Time: 0.84389
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.63053

Cumulative Model Updates: 30,478
Cumulative Timesteps: 508,362,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 508362658...
Checkpoint 508362658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.66056
Policy Entropy: 1.07589
Value Function Loss: 1.40806

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 8,502.87723
Overall Steps per Second: 7,411.53162

Timestep Collection Time: 5.88271
Timestep Consumption Time: 0.86623
PPO Batch Consumption Time: 0.04080
Total Iteration Time: 6.74894

Cumulative Model Updates: 30,481
Cumulative Timesteps: 508,412,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.67069
Policy Entropy: 1.07469
Value Function Loss: 1.37578

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.08747

Collected Steps per Second: 8,700.76514
Overall Steps per Second: 7,613.46797

Timestep Collection Time: 5.74754
Timestep Consumption Time: 0.82082
PPO Batch Consumption Time: 0.04378
Total Iteration Time: 6.56836

Cumulative Model Updates: 30,484
Cumulative Timesteps: 508,462,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 508462686...
Checkpoint 508462686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.55157
Policy Entropy: 1.09724
Value Function Loss: 1.42874

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.07786

Collected Steps per Second: 8,450.20945
Overall Steps per Second: 7,506.99509

Timestep Collection Time: 5.91701
Timestep Consumption Time: 0.74344
PPO Batch Consumption Time: 0.04489
Total Iteration Time: 6.66045

Cumulative Model Updates: 30,487
Cumulative Timesteps: 508,512,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.68920
Policy Entropy: 1.10568
Value Function Loss: 1.44255

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.09704

Collected Steps per Second: 8,515.24394
Overall Steps per Second: 7,409.57731

Timestep Collection Time: 5.87347
Timestep Consumption Time: 0.87645
PPO Batch Consumption Time: 0.04275
Total Iteration Time: 6.74991

Cumulative Model Updates: 30,490
Cumulative Timesteps: 508,562,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 508562700...
Checkpoint 508562700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.62410
Policy Entropy: 1.09455
Value Function Loss: 1.36160

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.09853

Collected Steps per Second: 8,593.88540
Overall Steps per Second: 7,367.46291

Timestep Collection Time: 5.81856
Timestep Consumption Time: 0.96858
PPO Batch Consumption Time: 0.04634
Total Iteration Time: 6.78714

Cumulative Model Updates: 30,493
Cumulative Timesteps: 508,612,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.49966
Policy Entropy: 1.09472
Value Function Loss: 1.36928

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.07960

Collected Steps per Second: 8,404.33113
Overall Steps per Second: 7,417.08355

Timestep Collection Time: 5.95122
Timestep Consumption Time: 0.79213
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.74335

Cumulative Model Updates: 30,496
Cumulative Timesteps: 508,662,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 508662720...
Checkpoint 508662720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.34740
Policy Entropy: 1.10840
Value Function Loss: 1.49427

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.17061
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 8,605.96243
Overall Steps per Second: 7,491.69491

Timestep Collection Time: 5.81271
Timestep Consumption Time: 0.86455
PPO Batch Consumption Time: 0.04800
Total Iteration Time: 6.67726

Cumulative Model Updates: 30,499
Cumulative Timesteps: 508,712,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.76685
Policy Entropy: 1.11492
Value Function Loss: 1.58853

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 8,518.95144
Overall Steps per Second: 7,400.58340

Timestep Collection Time: 5.87115
Timestep Consumption Time: 0.88724
PPO Batch Consumption Time: 0.04981
Total Iteration Time: 6.75839

Cumulative Model Updates: 30,502
Cumulative Timesteps: 508,762,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 508762760...
Checkpoint 508762760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.84974
Policy Entropy: 1.10672
Value Function Loss: 1.62696

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.10021

Collected Steps per Second: 9,079.27939
Overall Steps per Second: 7,898.40572

Timestep Collection Time: 5.50925
Timestep Consumption Time: 0.82368
PPO Batch Consumption Time: 0.04157
Total Iteration Time: 6.33292

Cumulative Model Updates: 30,505
Cumulative Timesteps: 508,812,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.67822
Policy Entropy: 1.10398
Value Function Loss: 1.61812

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 8,378.99948
Overall Steps per Second: 7,320.26923

Timestep Collection Time: 5.96945
Timestep Consumption Time: 0.86336
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.83281

Cumulative Model Updates: 30,508
Cumulative Timesteps: 508,862,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 508862798...
Checkpoint 508862798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.77220
Policy Entropy: 1.11464
Value Function Loss: 1.62015

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07635

Collected Steps per Second: 8,747.97322
Overall Steps per Second: 7,733.60805

Timestep Collection Time: 5.71812
Timestep Consumption Time: 0.75001
PPO Batch Consumption Time: 0.05078
Total Iteration Time: 6.46813

Cumulative Model Updates: 30,511
Cumulative Timesteps: 508,912,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.05519
Policy Entropy: 1.12303
Value Function Loss: 1.55716

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 8,830.29734
Overall Steps per Second: 7,690.52872

Timestep Collection Time: 5.66504
Timestep Consumption Time: 0.83958
PPO Batch Consumption Time: 0.04091
Total Iteration Time: 6.50462

Cumulative Model Updates: 30,514
Cumulative Timesteps: 508,962,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 508962844...
Checkpoint 508962844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.54864
Policy Entropy: 1.08883
Value Function Loss: 1.52083

Mean KL Divergence: 0.04972
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 8,824.85836
Overall Steps per Second: 7,714.64302

Timestep Collection Time: 5.66921
Timestep Consumption Time: 0.81586
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.48507

Cumulative Model Updates: 30,517
Cumulative Timesteps: 509,012,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.88606
Policy Entropy: 1.12540
Value Function Loss: 1.52714

Mean KL Divergence: 0.04092
SB3 Clip Fraction: 0.20933
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.11253

Collected Steps per Second: 8,895.48921
Overall Steps per Second: 7,615.43920

Timestep Collection Time: 5.62263
Timestep Consumption Time: 0.94509
PPO Batch Consumption Time: 0.04623
Total Iteration Time: 6.56771

Cumulative Model Updates: 30,520
Cumulative Timesteps: 509,062,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 509062890...
Checkpoint 509062890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.87657
Policy Entropy: 1.11537
Value Function Loss: 1.48171

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 8,529.90843
Overall Steps per Second: 7,435.89639

Timestep Collection Time: 5.86431
Timestep Consumption Time: 0.86279
PPO Batch Consumption Time: 0.04554
Total Iteration Time: 6.72710

Cumulative Model Updates: 30,523
Cumulative Timesteps: 509,112,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.41188
Policy Entropy: 1.13318
Value Function Loss: 1.48237

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.16278
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 8,795.59365
Overall Steps per Second: 7,743.16035

Timestep Collection Time: 5.68489
Timestep Consumption Time: 0.77268
PPO Batch Consumption Time: 0.04024
Total Iteration Time: 6.45757

Cumulative Model Updates: 30,526
Cumulative Timesteps: 509,162,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 509162914...
Checkpoint 509162914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.32427
Policy Entropy: 1.14271
Value Function Loss: 1.52710

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.16437
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 8,716.08134
Overall Steps per Second: 7,517.76989

Timestep Collection Time: 5.73813
Timestep Consumption Time: 0.91464
PPO Batch Consumption Time: 0.04790
Total Iteration Time: 6.65277

Cumulative Model Updates: 30,529
Cumulative Timesteps: 509,212,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.19550
Policy Entropy: 1.13186
Value Function Loss: 1.64038

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.10423

Collected Steps per Second: 8,495.79133
Overall Steps per Second: 7,096.13162

Timestep Collection Time: 5.88833
Timestep Consumption Time: 1.16143
PPO Batch Consumption Time: 0.04646
Total Iteration Time: 7.04976

Cumulative Model Updates: 30,532
Cumulative Timesteps: 509,262,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 509262954...
Checkpoint 509262954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.77663
Policy Entropy: 1.13930
Value Function Loss: 1.66425

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.09352

Collected Steps per Second: 8,137.27873
Overall Steps per Second: 7,152.16163

Timestep Collection Time: 6.14481
Timestep Consumption Time: 0.84637
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.99117

Cumulative Model Updates: 30,535
Cumulative Timesteps: 509,312,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.61540
Policy Entropy: 1.14513
Value Function Loss: 1.70219

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.07243
Value Function Update Magnitude: 0.09517

Collected Steps per Second: 8,813.94453
Overall Steps per Second: 7,624.37109

Timestep Collection Time: 5.67487
Timestep Consumption Time: 0.88541
PPO Batch Consumption Time: 0.04893
Total Iteration Time: 6.56028

Cumulative Model Updates: 30,538
Cumulative Timesteps: 509,362,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 509362974...
Checkpoint 509362974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.55619
Policy Entropy: 1.13093
Value Function Loss: 1.61756

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.09792

Collected Steps per Second: 8,686.45789
Overall Steps per Second: 7,725.79066

Timestep Collection Time: 5.75793
Timestep Consumption Time: 0.71597
PPO Batch Consumption Time: 0.04520
Total Iteration Time: 6.47390

Cumulative Model Updates: 30,541
Cumulative Timesteps: 509,412,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.77508
Policy Entropy: 1.12966
Value Function Loss: 1.75966

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 8,631.63085
Overall Steps per Second: 7,519.50380

Timestep Collection Time: 5.79288
Timestep Consumption Time: 0.85676
PPO Batch Consumption Time: 0.04060
Total Iteration Time: 6.64964

Cumulative Model Updates: 30,544
Cumulative Timesteps: 509,462,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 509462992...
Checkpoint 509462992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.50529
Policy Entropy: 1.14654
Value Function Loss: 1.68017

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.08824

Collected Steps per Second: 8,626.58200
Overall Steps per Second: 7,444.76881

Timestep Collection Time: 5.79975
Timestep Consumption Time: 0.92068
PPO Batch Consumption Time: 0.05094
Total Iteration Time: 6.72042

Cumulative Model Updates: 30,547
Cumulative Timesteps: 509,513,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.36646
Policy Entropy: 1.14778
Value Function Loss: 1.67496

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09583

Collected Steps per Second: 8,894.23408
Overall Steps per Second: 7,681.99672

Timestep Collection Time: 5.62499
Timestep Consumption Time: 0.88764
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.51263

Cumulative Model Updates: 30,550
Cumulative Timesteps: 509,563,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 509563054...
Checkpoint 509563054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.20761
Policy Entropy: 1.12841
Value Function Loss: 1.49442

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 8,807.40896
Overall Steps per Second: 7,590.77206

Timestep Collection Time: 5.67863
Timestep Consumption Time: 0.91016
PPO Batch Consumption Time: 0.04118
Total Iteration Time: 6.58879

Cumulative Model Updates: 30,553
Cumulative Timesteps: 509,613,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.58520
Policy Entropy: 1.11913
Value Function Loss: 1.40891

Mean KL Divergence: 0.03034
SB3 Clip Fraction: 0.18729
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.09147

Collected Steps per Second: 9,185.17610
Overall Steps per Second: 7,935.60036

Timestep Collection Time: 5.44421
Timestep Consumption Time: 0.85727
PPO Batch Consumption Time: 0.04356
Total Iteration Time: 6.30148

Cumulative Model Updates: 30,556
Cumulative Timesteps: 509,663,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 509663074...
Checkpoint 509663074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.92253
Policy Entropy: 1.13328
Value Function Loss: 1.41369

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.08879

Collected Steps per Second: 8,707.40837
Overall Steps per Second: 7,544.44800

Timestep Collection Time: 5.74247
Timestep Consumption Time: 0.88519
PPO Batch Consumption Time: 0.04685
Total Iteration Time: 6.62766

Cumulative Model Updates: 30,559
Cumulative Timesteps: 509,713,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.92466
Policy Entropy: 1.13276
Value Function Loss: 1.32830

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 8,727.12594
Overall Steps per Second: 7,603.93641

Timestep Collection Time: 5.72949
Timestep Consumption Time: 0.84631
PPO Batch Consumption Time: 0.04578
Total Iteration Time: 6.57580

Cumulative Model Updates: 30,562
Cumulative Timesteps: 509,763,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 509763078...
Checkpoint 509763078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.28525
Policy Entropy: 1.10797
Value Function Loss: 1.35725

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.18875
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 9,105.62676
Overall Steps per Second: 7,826.51349

Timestep Collection Time: 5.49111
Timestep Consumption Time: 0.89743
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.38854

Cumulative Model Updates: 30,565
Cumulative Timesteps: 509,813,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.94424
Policy Entropy: 1.12991
Value Function Loss: 1.35112

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.12044

Collected Steps per Second: 9,243.42930
Overall Steps per Second: 8,015.11064

Timestep Collection Time: 5.41098
Timestep Consumption Time: 0.82923
PPO Batch Consumption Time: 0.04266
Total Iteration Time: 6.24021

Cumulative Model Updates: 30,568
Cumulative Timesteps: 509,863,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 509863094...
Checkpoint 509863094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.32218
Policy Entropy: 1.11315
Value Function Loss: 1.41243

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.11559

Collected Steps per Second: 8,943.35581
Overall Steps per Second: 7,908.19061

Timestep Collection Time: 5.59253
Timestep Consumption Time: 0.73205
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.32458

Cumulative Model Updates: 30,571
Cumulative Timesteps: 509,913,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.16612
Policy Entropy: 1.11274
Value Function Loss: 1.37886

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16364
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.09318

Collected Steps per Second: 8,922.40065
Overall Steps per Second: 7,760.89686

Timestep Collection Time: 5.60679
Timestep Consumption Time: 0.83912
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.44590

Cumulative Model Updates: 30,574
Cumulative Timesteps: 509,963,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 509963136...
Checkpoint 509963136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.09727
Policy Entropy: 1.08666
Value Function Loss: 1.35136

Mean KL Divergence: 0.04402
SB3 Clip Fraction: 0.26179
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 8,528.19696
Overall Steps per Second: 7,478.74010

Timestep Collection Time: 5.86595
Timestep Consumption Time: 0.82314
PPO Batch Consumption Time: 0.04285
Total Iteration Time: 6.68909

Cumulative Model Updates: 30,577
Cumulative Timesteps: 510,013,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.15245
Policy Entropy: 1.09633
Value Function Loss: 1.22832

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.17587
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.05937

Collected Steps per Second: 9,013.65864
Overall Steps per Second: 7,850.38624

Timestep Collection Time: 5.54825
Timestep Consumption Time: 0.82214
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.37039

Cumulative Model Updates: 30,580
Cumulative Timesteps: 510,063,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 510063172...
Checkpoint 510063172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.32922
Policy Entropy: 1.08666
Value Function Loss: 1.22971

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.17427
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 8,884.78725
Overall Steps per Second: 7,752.81479

Timestep Collection Time: 5.62940
Timestep Consumption Time: 0.82194
PPO Batch Consumption Time: 0.04300
Total Iteration Time: 6.45133

Cumulative Model Updates: 30,583
Cumulative Timesteps: 510,113,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.18991
Policy Entropy: 1.08476
Value Function Loss: 1.12621

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.17848
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.05970

Collected Steps per Second: 9,023.48828
Overall Steps per Second: 8,001.33393

Timestep Collection Time: 5.54132
Timestep Consumption Time: 0.70789
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.24921

Cumulative Model Updates: 30,586
Cumulative Timesteps: 510,163,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 510163190...
Checkpoint 510163190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.07470
Policy Entropy: 1.08171
Value Function Loss: 1.19878

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.21129
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.05494

Collected Steps per Second: 8,721.94123
Overall Steps per Second: 7,467.54700

Timestep Collection Time: 5.73404
Timestep Consumption Time: 0.96320
PPO Batch Consumption Time: 0.04670
Total Iteration Time: 6.69725

Cumulative Model Updates: 30,589
Cumulative Timesteps: 510,213,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.85096
Policy Entropy: 1.08339
Value Function Loss: 1.14021

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.19040
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.04430

Collected Steps per Second: 8,732.20402
Overall Steps per Second: 7,643.36016

Timestep Collection Time: 5.72616
Timestep Consumption Time: 0.81573
PPO Batch Consumption Time: 0.04350
Total Iteration Time: 6.54189

Cumulative Model Updates: 30,592
Cumulative Timesteps: 510,263,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 510263204...
Checkpoint 510263204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.10688
Policy Entropy: 1.05779
Value Function Loss: 1.19470

Mean KL Divergence: 0.04085
SB3 Clip Fraction: 0.23417
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.04270

Collected Steps per Second: 9,008.38024
Overall Steps per Second: 7,779.40416

Timestep Collection Time: 5.55350
Timestep Consumption Time: 0.87733
PPO Batch Consumption Time: 0.04376
Total Iteration Time: 6.43083

Cumulative Model Updates: 30,595
Cumulative Timesteps: 510,313,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.49081
Policy Entropy: 1.07322
Value Function Loss: 1.15514

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.04709

Collected Steps per Second: 8,902.13573
Overall Steps per Second: 7,805.14258

Timestep Collection Time: 5.61730
Timestep Consumption Time: 0.78950
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 6.40680

Cumulative Model Updates: 30,598
Cumulative Timesteps: 510,363,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 510363238...
Checkpoint 510363238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.75770
Policy Entropy: 1.06417
Value Function Loss: 1.19594

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 8,709.02365
Overall Steps per Second: 7,686.91232

Timestep Collection Time: 5.74370
Timestep Consumption Time: 0.76373
PPO Batch Consumption Time: 0.04802
Total Iteration Time: 6.50742

Cumulative Model Updates: 30,601
Cumulative Timesteps: 510,413,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.95018
Policy Entropy: 1.07171
Value Function Loss: 1.22382

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 8,844.95689
Overall Steps per Second: 7,672.93071

Timestep Collection Time: 5.65294
Timestep Consumption Time: 0.86348
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 6.51641

Cumulative Model Updates: 30,604
Cumulative Timesteps: 510,463,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 510463260...
Checkpoint 510463260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.99324
Policy Entropy: 1.05748
Value Function Loss: 1.18031

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.18921
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.06278

Collected Steps per Second: 8,795.25539
Overall Steps per Second: 7,644.27005

Timestep Collection Time: 5.68693
Timestep Consumption Time: 0.85627
PPO Batch Consumption Time: 0.04834
Total Iteration Time: 6.54320

Cumulative Model Updates: 30,607
Cumulative Timesteps: 510,513,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.12169
Policy Entropy: 1.05990
Value Function Loss: 1.20418

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 8,924.42785
Overall Steps per Second: 7,819.39957

Timestep Collection Time: 5.60484
Timestep Consumption Time: 0.79207
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.39691

Cumulative Model Updates: 30,610
Cumulative Timesteps: 510,563,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510563298...
Checkpoint 510563298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.28175
Policy Entropy: 1.05874
Value Function Loss: 1.08640

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.06919

Collected Steps per Second: 8,971.79363
Overall Steps per Second: 7,780.80614

Timestep Collection Time: 5.57369
Timestep Consumption Time: 0.85315
PPO Batch Consumption Time: 0.04302
Total Iteration Time: 6.42684

Cumulative Model Updates: 30,613
Cumulative Timesteps: 510,613,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.13702
Policy Entropy: 1.05363
Value Function Loss: 1.16406

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15769
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.07888

Collected Steps per Second: 9,099.15376
Overall Steps per Second: 7,895.41171

Timestep Collection Time: 5.49721
Timestep Consumption Time: 0.83811
PPO Batch Consumption Time: 0.04547
Total Iteration Time: 6.33533

Cumulative Model Updates: 30,616
Cumulative Timesteps: 510,663,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510663324...
Checkpoint 510663324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.60327
Policy Entropy: 1.05584
Value Function Loss: 1.05058

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 8,855.95377
Overall Steps per Second: 7,679.10300

Timestep Collection Time: 5.64615
Timestep Consumption Time: 0.86529
PPO Batch Consumption Time: 0.04391
Total Iteration Time: 6.51144

Cumulative Model Updates: 30,619
Cumulative Timesteps: 510,713,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.56798
Policy Entropy: 1.04832
Value Function Loss: 1.13540

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.17656
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.08480

Collected Steps per Second: 9,135.75218
Overall Steps per Second: 7,916.17193

Timestep Collection Time: 5.47629
Timestep Consumption Time: 0.84369
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.31997

Cumulative Model Updates: 30,622
Cumulative Timesteps: 510,763,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 510763356...
Checkpoint 510763356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.95923
Policy Entropy: 1.04018
Value Function Loss: 1.15108

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.19004
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.07701

Collected Steps per Second: 8,929.56014
Overall Steps per Second: 7,784.26705

Timestep Collection Time: 5.60162
Timestep Consumption Time: 0.82416
PPO Batch Consumption Time: 0.04620
Total Iteration Time: 6.42578

Cumulative Model Updates: 30,625
Cumulative Timesteps: 510,813,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.33224
Policy Entropy: 1.04736
Value Function Loss: 1.16942

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.08010

Collected Steps per Second: 8,878.92694
Overall Steps per Second: 7,689.77694

Timestep Collection Time: 5.63424
Timestep Consumption Time: 0.87128
PPO Batch Consumption Time: 0.04456
Total Iteration Time: 6.50552

Cumulative Model Updates: 30,628
Cumulative Timesteps: 510,863,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 510863402...
Checkpoint 510863402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.68791
Policy Entropy: 1.04877
Value Function Loss: 1.18766

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 8,838.70638
Overall Steps per Second: 7,684.27916

Timestep Collection Time: 5.66010
Timestep Consumption Time: 0.85033
PPO Batch Consumption Time: 0.04474
Total Iteration Time: 6.51044

Cumulative Model Updates: 30,631
Cumulative Timesteps: 510,913,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.37158
Policy Entropy: 1.03130
Value Function Loss: 1.17435

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.18352
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.09130

Collected Steps per Second: 8,976.45223
Overall Steps per Second: 7,834.86203

Timestep Collection Time: 5.57236
Timestep Consumption Time: 0.81193
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.38429

Cumulative Model Updates: 30,634
Cumulative Timesteps: 510,963,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510963450...
Checkpoint 510963450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.24857
Policy Entropy: 1.02401
Value Function Loss: 1.17533

Mean KL Divergence: 0.03133
SB3 Clip Fraction: 0.24321
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 9,003.49050
Overall Steps per Second: 7,791.44823

Timestep Collection Time: 5.55362
Timestep Consumption Time: 0.86392
PPO Batch Consumption Time: 0.04433
Total Iteration Time: 6.41755

Cumulative Model Updates: 30,637
Cumulative Timesteps: 511,013,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.94805
Policy Entropy: 1.03447
Value Function Loss: 1.13565

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.17471
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 8,660.72181
Overall Steps per Second: 7,701.66666

Timestep Collection Time: 5.77435
Timestep Consumption Time: 0.71905
PPO Batch Consumption Time: 0.04499
Total Iteration Time: 6.49340

Cumulative Model Updates: 30,640
Cumulative Timesteps: 511,063,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 511063462...
Checkpoint 511063462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.73265
Policy Entropy: 1.03405
Value Function Loss: 1.08596

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.17060
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 8,864.60043
Overall Steps per Second: 7,682.79529

Timestep Collection Time: 5.64109
Timestep Consumption Time: 0.86774
PPO Batch Consumption Time: 0.04541
Total Iteration Time: 6.50883

Cumulative Model Updates: 30,643
Cumulative Timesteps: 511,113,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.09774
Policy Entropy: 1.01124
Value Function Loss: 1.12093

Mean KL Divergence: 0.03846
SB3 Clip Fraction: 0.23647
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.08841

Collected Steps per Second: 8,620.02595
Overall Steps per Second: 7,543.56596

Timestep Collection Time: 5.80207
Timestep Consumption Time: 0.82795
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.63002

Cumulative Model Updates: 30,646
Cumulative Timesteps: 511,163,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 511163482...
Checkpoint 511163482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.20892
Policy Entropy: 1.03270
Value Function Loss: 1.05437

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.19025
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 8,996.70774
Overall Steps per Second: 7,736.96449

Timestep Collection Time: 5.56003
Timestep Consumption Time: 0.90529
PPO Batch Consumption Time: 0.04375
Total Iteration Time: 6.46533

Cumulative Model Updates: 30,649
Cumulative Timesteps: 511,213,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.87030
Policy Entropy: 1.04213
Value Function Loss: 1.14766

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.19001
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 8,601.53249
Overall Steps per Second: 7,497.42541

Timestep Collection Time: 5.81501
Timestep Consumption Time: 0.85635
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.67136

Cumulative Model Updates: 30,652
Cumulative Timesteps: 511,263,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511263522...
Checkpoint 511263522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.20360
Policy Entropy: 1.03900
Value Function Loss: 1.16138

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.17464
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 8,814.01144
Overall Steps per Second: 7,711.99280

Timestep Collection Time: 5.67437
Timestep Consumption Time: 0.81085
PPO Batch Consumption Time: 0.04856
Total Iteration Time: 6.48522

Cumulative Model Updates: 30,655
Cumulative Timesteps: 511,313,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.06105
Policy Entropy: 1.02654
Value Function Loss: 1.26721

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.06297

Collected Steps per Second: 8,596.17710
Overall Steps per Second: 7,428.46195

Timestep Collection Time: 5.81700
Timestep Consumption Time: 0.91440
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.73141

Cumulative Model Updates: 30,658
Cumulative Timesteps: 511,363,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 511363540...
Checkpoint 511363540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.75740
Policy Entropy: 1.04286
Value Function Loss: 1.17360

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.05575

Collected Steps per Second: 8,623.16872
Overall Steps per Second: 7,440.63940

Timestep Collection Time: 5.80204
Timestep Consumption Time: 0.92211
PPO Batch Consumption Time: 0.04339
Total Iteration Time: 6.72415

Cumulative Model Updates: 30,661
Cumulative Timesteps: 511,413,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.70268
Policy Entropy: 1.04378
Value Function Loss: 1.16416

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 8,976.86223
Overall Steps per Second: 7,757.39229

Timestep Collection Time: 5.57188
Timestep Consumption Time: 0.87591
PPO Batch Consumption Time: 0.04483
Total Iteration Time: 6.44779

Cumulative Model Updates: 30,664
Cumulative Timesteps: 511,463,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511463590...
Checkpoint 511463590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.15024
Policy Entropy: 1.03623
Value Function Loss: 1.15681

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.05793

Collected Steps per Second: 9,101.43873
Overall Steps per Second: 7,907.55959

Timestep Collection Time: 5.49539
Timestep Consumption Time: 0.82969
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 6.32509

Cumulative Model Updates: 30,667
Cumulative Timesteps: 511,513,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.83898
Policy Entropy: 1.02254
Value Function Loss: 1.21336

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.21277
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 9,286.15242
Overall Steps per Second: 8,139.45347

Timestep Collection Time: 5.38716
Timestep Consumption Time: 0.75895
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 6.14611

Cumulative Model Updates: 30,670
Cumulative Timesteps: 511,563,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 511563632...
Checkpoint 511563632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.01381
Policy Entropy: 1.05523
Value Function Loss: 1.11646

Mean KL Divergence: 0.02855
SB3 Clip Fraction: 0.20443
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 8,909.07068
Overall Steps per Second: 7,715.26584

Timestep Collection Time: 5.61316
Timestep Consumption Time: 0.86854
PPO Batch Consumption Time: 0.04436
Total Iteration Time: 6.48169

Cumulative Model Updates: 30,673
Cumulative Timesteps: 511,613,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.59969
Policy Entropy: 1.04104
Value Function Loss: 1.10698

Mean KL Divergence: 0.03073
SB3 Clip Fraction: 0.20414
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 9,014.22295
Overall Steps per Second: 7,845.78544

Timestep Collection Time: 5.54923
Timestep Consumption Time: 0.82642
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 6.37565

Cumulative Model Updates: 30,676
Cumulative Timesteps: 511,663,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 511663662...
Checkpoint 511663662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.59799
Policy Entropy: 1.04629
Value Function Loss: 1.08751

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.18151
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 9,155.81741
Overall Steps per Second: 7,911.96775

Timestep Collection Time: 5.46123
Timestep Consumption Time: 0.85857
PPO Batch Consumption Time: 0.04867
Total Iteration Time: 6.31979

Cumulative Model Updates: 30,679
Cumulative Timesteps: 511,713,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.02027
Policy Entropy: 1.06334
Value Function Loss: 1.20741

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.21409
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 8,818.62372
Overall Steps per Second: 7,697.88357

Timestep Collection Time: 5.67186
Timestep Consumption Time: 0.82577
PPO Batch Consumption Time: 0.04245
Total Iteration Time: 6.49763

Cumulative Model Updates: 30,682
Cumulative Timesteps: 511,763,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511763682...
Checkpoint 511763682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.57780
Policy Entropy: 1.07354
Value Function Loss: 1.18284

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 8,819.73809
Overall Steps per Second: 7,779.37980

Timestep Collection Time: 5.67092
Timestep Consumption Time: 0.75839
PPO Batch Consumption Time: 0.04286
Total Iteration Time: 6.42930

Cumulative Model Updates: 30,685
Cumulative Timesteps: 511,813,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.84737
Policy Entropy: 1.05557
Value Function Loss: 1.19919

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 8,524.42523
Overall Steps per Second: 7,458.23856

Timestep Collection Time: 5.86550
Timestep Consumption Time: 0.83850
PPO Batch Consumption Time: 0.04164
Total Iteration Time: 6.70400

Cumulative Model Updates: 30,688
Cumulative Timesteps: 511,863,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 511863698...
Checkpoint 511863698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.62425
Policy Entropy: 1.06137
Value Function Loss: 1.18417

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15244
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.06300

Collected Steps per Second: 8,807.72765
Overall Steps per Second: 7,604.70588

Timestep Collection Time: 5.67865
Timestep Consumption Time: 0.89833
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.57698

Cumulative Model Updates: 30,691
Cumulative Timesteps: 511,913,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.68196
Policy Entropy: 1.07027
Value Function Loss: 1.17874

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.05397

Collected Steps per Second: 8,818.72438
Overall Steps per Second: 7,714.38821

Timestep Collection Time: 5.67316
Timestep Consumption Time: 0.81213
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 6.48528

Cumulative Model Updates: 30,694
Cumulative Timesteps: 511,963,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 511963744...
Checkpoint 511963744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.87225
Policy Entropy: 1.08261
Value Function Loss: 1.16156

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.17069
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 8,726.05037
Overall Steps per Second: 7,636.74264

Timestep Collection Time: 5.73272
Timestep Consumption Time: 0.81772
PPO Batch Consumption Time: 0.04242
Total Iteration Time: 6.55044

Cumulative Model Updates: 30,697
Cumulative Timesteps: 512,013,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.84043
Policy Entropy: 1.07169
Value Function Loss: 1.20199

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.05365

Collected Steps per Second: 8,626.97970
Overall Steps per Second: 7,610.22697

Timestep Collection Time: 5.79693
Timestep Consumption Time: 0.77449
PPO Batch Consumption Time: 0.04459
Total Iteration Time: 6.57142

Cumulative Model Updates: 30,700
Cumulative Timesteps: 512,063,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 512063778...
Checkpoint 512063778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.43405
Policy Entropy: 1.07473
Value Function Loss: 1.24953

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16668
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.05385

Collected Steps per Second: 8,798.40137
Overall Steps per Second: 7,680.84828

Timestep Collection Time: 5.68376
Timestep Consumption Time: 0.82698
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 6.51074

Cumulative Model Updates: 30,703
Cumulative Timesteps: 512,113,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.77146
Policy Entropy: 1.08738
Value Function Loss: 1.27785

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 8,560.20501
Overall Steps per Second: 7,523.21908

Timestep Collection Time: 5.84215
Timestep Consumption Time: 0.80527
PPO Batch Consumption Time: 0.04037
Total Iteration Time: 6.64742

Cumulative Model Updates: 30,706
Cumulative Timesteps: 512,163,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 512163796...
Checkpoint 512163796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.57598
Policy Entropy: 1.09085
Value Function Loss: 1.23465

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.08250

Collected Steps per Second: 8,656.43866
Overall Steps per Second: 7,592.61283

Timestep Collection Time: 5.77605
Timestep Consumption Time: 0.80930
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 6.58535

Cumulative Model Updates: 30,709
Cumulative Timesteps: 512,213,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.12879
Policy Entropy: 1.07598
Value Function Loss: 1.24205

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.09092

Collected Steps per Second: 8,744.60124
Overall Steps per Second: 7,616.50903

Timestep Collection Time: 5.71941
Timestep Consumption Time: 0.84711
PPO Batch Consumption Time: 0.04446
Total Iteration Time: 6.56653

Cumulative Model Updates: 30,712
Cumulative Timesteps: 512,263,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 512263810...
Checkpoint 512263810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.14126
Policy Entropy: 1.07613
Value Function Loss: 1.21345

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.08865

Collected Steps per Second: 8,541.09644
Overall Steps per Second: 7,498.34256

Timestep Collection Time: 5.85616
Timestep Consumption Time: 0.81438
PPO Batch Consumption Time: 0.04657
Total Iteration Time: 6.67054

Cumulative Model Updates: 30,715
Cumulative Timesteps: 512,313,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.58446
Policy Entropy: 1.08393
Value Function Loss: 1.28001

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.08261

Collected Steps per Second: 8,842.01644
Overall Steps per Second: 7,744.11962

Timestep Collection Time: 5.65504
Timestep Consumption Time: 0.80173
PPO Batch Consumption Time: 0.04196
Total Iteration Time: 6.45677

Cumulative Model Updates: 30,718
Cumulative Timesteps: 512,363,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512363830...
Checkpoint 512363830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.99654
Policy Entropy: 1.08852
Value Function Loss: 1.26314

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 8,515.29777
Overall Steps per Second: 7,298.91523

Timestep Collection Time: 5.87319
Timestep Consumption Time: 0.97878
PPO Batch Consumption Time: 0.04777
Total Iteration Time: 6.85198

Cumulative Model Updates: 30,721
Cumulative Timesteps: 512,413,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.74976
Policy Entropy: 1.09374
Value Function Loss: 1.27780

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.08607

Collected Steps per Second: 8,498.02684
Overall Steps per Second: 7,503.01389

Timestep Collection Time: 5.88678
Timestep Consumption Time: 0.78068
PPO Batch Consumption Time: 0.04885
Total Iteration Time: 6.66745

Cumulative Model Updates: 30,724
Cumulative Timesteps: 512,463,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 512463868...
Checkpoint 512463868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.90752
Policy Entropy: 1.08546
Value Function Loss: 1.28260

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 8,587.26138
Overall Steps per Second: 7,465.92520

Timestep Collection Time: 5.82281
Timestep Consumption Time: 0.87455
PPO Batch Consumption Time: 0.04033
Total Iteration Time: 6.69736

Cumulative Model Updates: 30,727
Cumulative Timesteps: 512,513,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.44640
Policy Entropy: 1.10469
Value Function Loss: 1.30860

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 8,803.26616
Overall Steps per Second: 7,726.32834

Timestep Collection Time: 5.68039
Timestep Consumption Time: 0.79176
PPO Batch Consumption Time: 0.04890
Total Iteration Time: 6.47216

Cumulative Model Updates: 30,730
Cumulative Timesteps: 512,563,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 512563876...
Checkpoint 512563876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.92172
Policy Entropy: 1.10344
Value Function Loss: 1.42993

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.06947
Value Function Update Magnitude: 0.07624

Collected Steps per Second: 8,918.94080
Overall Steps per Second: 7,840.96641

Timestep Collection Time: 5.60896
Timestep Consumption Time: 0.77112
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.38008

Cumulative Model Updates: 30,733
Cumulative Timesteps: 512,613,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.83649
Policy Entropy: 1.09255
Value Function Loss: 1.42846

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.16636
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 8,861.57540
Overall Steps per Second: 7,672.66357

Timestep Collection Time: 5.64550
Timestep Consumption Time: 0.87479
PPO Batch Consumption Time: 0.04623
Total Iteration Time: 6.52029

Cumulative Model Updates: 30,736
Cumulative Timesteps: 512,663,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 512663930...
Checkpoint 512663930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.86858
Policy Entropy: 1.09205
Value Function Loss: 1.41093

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.08931

Collected Steps per Second: 8,828.17342
Overall Steps per Second: 7,777.56905

Timestep Collection Time: 5.66391
Timestep Consumption Time: 0.76509
PPO Batch Consumption Time: 0.04688
Total Iteration Time: 6.42900

Cumulative Model Updates: 30,739
Cumulative Timesteps: 512,713,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.74199
Policy Entropy: 1.09707
Value Function Loss: 1.39816

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 8,756.27233
Overall Steps per Second: 7,583.77062

Timestep Collection Time: 5.71225
Timestep Consumption Time: 0.88315
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.59540

Cumulative Model Updates: 30,742
Cumulative Timesteps: 512,763,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 512763950...
Checkpoint 512763950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.33813
Policy Entropy: 1.10174
Value Function Loss: 1.37696

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 8,912.98892
Overall Steps per Second: 7,908.05001

Timestep Collection Time: 5.61338
Timestep Consumption Time: 0.71334
PPO Batch Consumption Time: 0.04076
Total Iteration Time: 6.32672

Cumulative Model Updates: 30,745
Cumulative Timesteps: 512,813,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.03737
Policy Entropy: 1.10960
Value Function Loss: 1.43480

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 8,854.31725
Overall Steps per Second: 7,703.88288

Timestep Collection Time: 5.64787
Timestep Consumption Time: 0.84341
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.49127

Cumulative Model Updates: 30,748
Cumulative Timesteps: 512,863,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 512863990...
Checkpoint 512863990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.10709
Policy Entropy: 1.10302
Value Function Loss: 1.49382

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.06495
Value Function Update Magnitude: 0.07084

Collected Steps per Second: 8,821.11857
Overall Steps per Second: 7,683.33549

Timestep Collection Time: 5.67071
Timestep Consumption Time: 0.83974
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 6.51045

Cumulative Model Updates: 30,751
Cumulative Timesteps: 512,914,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.56581
Policy Entropy: 1.10787
Value Function Loss: 1.54618

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.07154
Value Function Update Magnitude: 0.08125

Collected Steps per Second: 8,737.64126
Overall Steps per Second: 7,563.79960

Timestep Collection Time: 5.72420
Timestep Consumption Time: 0.88835
PPO Batch Consumption Time: 0.04793
Total Iteration Time: 6.61255

Cumulative Model Updates: 30,754
Cumulative Timesteps: 512,964,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 512964028...
Checkpoint 512964028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.01629
Policy Entropy: 1.10820
Value Function Loss: 1.58766

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.08071

Collected Steps per Second: 8,724.84334
Overall Steps per Second: 7,597.54479

Timestep Collection Time: 5.73282
Timestep Consumption Time: 0.85062
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.58344

Cumulative Model Updates: 30,757
Cumulative Timesteps: 513,014,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.69779
Policy Entropy: 1.12914
Value Function Loss: 1.64183

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 8,483.48592
Overall Steps per Second: 7,404.41431

Timestep Collection Time: 5.89734
Timestep Consumption Time: 0.85944
PPO Batch Consumption Time: 0.04950
Total Iteration Time: 6.75678

Cumulative Model Updates: 30,760
Cumulative Timesteps: 513,064,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 513064076...
Checkpoint 513064076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.30081
Policy Entropy: 1.12896
Value Function Loss: 1.61118

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.16161
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 8,794.89537
Overall Steps per Second: 7,637.39299

Timestep Collection Time: 5.68716
Timestep Consumption Time: 0.86193
PPO Batch Consumption Time: 0.04025
Total Iteration Time: 6.54909

Cumulative Model Updates: 30,763
Cumulative Timesteps: 513,114,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.32226
Policy Entropy: 1.11791
Value Function Loss: 1.57397

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 8,645.51660
Overall Steps per Second: 7,524.11404

Timestep Collection Time: 5.78404
Timestep Consumption Time: 0.86206
PPO Batch Consumption Time: 0.04199
Total Iteration Time: 6.64610

Cumulative Model Updates: 30,766
Cumulative Timesteps: 513,164,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 513164100...
Checkpoint 513164100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.70583
Policy Entropy: 1.10662
Value Function Loss: 1.49860

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.18906
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 8,363.49596
Overall Steps per Second: 7,372.80344

Timestep Collection Time: 5.97884
Timestep Consumption Time: 0.80338
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.78222

Cumulative Model Updates: 30,769
Cumulative Timesteps: 513,214,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.97765
Policy Entropy: 1.13217
Value Function Loss: 1.48035

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 8,696.49047
Overall Steps per Second: 7,559.96421

Timestep Collection Time: 5.75290
Timestep Consumption Time: 0.86486
PPO Batch Consumption Time: 0.04233
Total Iteration Time: 6.61776

Cumulative Model Updates: 30,772
Cumulative Timesteps: 513,264,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 513264134...
Checkpoint 513264134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.50994
Policy Entropy: 1.11654
Value Function Loss: 1.38220

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 8,808.28753
Overall Steps per Second: 7,661.25088

Timestep Collection Time: 5.67693
Timestep Consumption Time: 0.84995
PPO Batch Consumption Time: 0.04325
Total Iteration Time: 6.52687

Cumulative Model Updates: 30,775
Cumulative Timesteps: 513,314,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.75658
Policy Entropy: 1.11456
Value Function Loss: 1.34078

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.09448

Collected Steps per Second: 9,306.68352
Overall Steps per Second: 7,908.42366

Timestep Collection Time: 5.37528
Timestep Consumption Time: 0.95038
PPO Batch Consumption Time: 0.05104
Total Iteration Time: 6.32566

Cumulative Model Updates: 30,778
Cumulative Timesteps: 513,364,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 513364164...
Checkpoint 513364164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.55389
Policy Entropy: 1.12613
Value Function Loss: 1.23769

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.10202

Collected Steps per Second: 9,086.53507
Overall Steps per Second: 7,771.16038

Timestep Collection Time: 5.50419
Timestep Consumption Time: 0.93166
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.43585

Cumulative Model Updates: 30,781
Cumulative Timesteps: 513,414,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.78266
Policy Entropy: 1.12711
Value Function Loss: 1.28933

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.10467

Collected Steps per Second: 9,097.68223
Overall Steps per Second: 7,942.53140

Timestep Collection Time: 5.49591
Timestep Consumption Time: 0.79932
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 6.29522

Cumulative Model Updates: 30,784
Cumulative Timesteps: 513,464,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 513464178...
Checkpoint 513464178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.51918
Policy Entropy: 1.12869
Value Function Loss: 1.34720

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.09552

Collected Steps per Second: 8,962.32907
Overall Steps per Second: 7,724.33627

Timestep Collection Time: 5.58225
Timestep Consumption Time: 0.89468
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.47693

Cumulative Model Updates: 30,787
Cumulative Timesteps: 513,514,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.44242
Policy Entropy: 1.11787
Value Function Loss: 1.51466

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 8,821.46669
Overall Steps per Second: 7,694.74322

Timestep Collection Time: 5.67139
Timestep Consumption Time: 0.83045
PPO Batch Consumption Time: 0.04608
Total Iteration Time: 6.50184

Cumulative Model Updates: 30,790
Cumulative Timesteps: 513,564,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 513564238...
Checkpoint 513564238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.99268
Policy Entropy: 1.13572
Value Function Loss: 1.55273

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 8,703.81513
Overall Steps per Second: 7,713.72746

Timestep Collection Time: 5.74622
Timestep Consumption Time: 0.73755
PPO Batch Consumption Time: 0.04192
Total Iteration Time: 6.48377

Cumulative Model Updates: 30,793
Cumulative Timesteps: 513,614,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.49693
Policy Entropy: 1.14093
Value Function Loss: 1.54881

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.11106

Collected Steps per Second: 8,365.08870
Overall Steps per Second: 7,325.18773

Timestep Collection Time: 5.98009
Timestep Consumption Time: 0.84895
PPO Batch Consumption Time: 0.04969
Total Iteration Time: 6.82904

Cumulative Model Updates: 30,796
Cumulative Timesteps: 513,664,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 513664276...
Checkpoint 513664276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.05690
Policy Entropy: 1.12544
Value Function Loss: 1.48826

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 8,597.81163
Overall Steps per Second: 7,597.63194

Timestep Collection Time: 5.81822
Timestep Consumption Time: 0.76593
PPO Batch Consumption Time: 0.04438
Total Iteration Time: 6.58416

Cumulative Model Updates: 30,799
Cumulative Timesteps: 513,714,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.00868
Policy Entropy: 1.12160
Value Function Loss: 1.42243

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.09392

Collected Steps per Second: 8,663.66036
Overall Steps per Second: 7,567.94654

Timestep Collection Time: 5.77123
Timestep Consumption Time: 0.83558
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.60681

Cumulative Model Updates: 30,802
Cumulative Timesteps: 513,764,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 513764300...
Checkpoint 513764300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.69783
Policy Entropy: 1.12483
Value Function Loss: 1.43255

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.09384

Collected Steps per Second: 8,577.82304
Overall Steps per Second: 7,512.34365

Timestep Collection Time: 5.83178
Timestep Consumption Time: 0.82712
PPO Batch Consumption Time: 0.04367
Total Iteration Time: 6.65891

Cumulative Model Updates: 30,805
Cumulative Timesteps: 513,814,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.03410
Policy Entropy: 1.12875
Value Function Loss: 1.40647

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.08321

Collected Steps per Second: 8,699.70070
Overall Steps per Second: 7,716.40139

Timestep Collection Time: 5.74916
Timestep Consumption Time: 0.73261
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.48178

Cumulative Model Updates: 30,808
Cumulative Timesteps: 513,864,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 513864340...
Checkpoint 513864340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.39286
Policy Entropy: 1.12433
Value Function Loss: 1.26549

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.08034

Collected Steps per Second: 8,184.93195
Overall Steps per Second: 7,164.76651

Timestep Collection Time: 6.11172
Timestep Consumption Time: 0.87023
PPO Batch Consumption Time: 0.04527
Total Iteration Time: 6.98194

Cumulative Model Updates: 30,811
Cumulative Timesteps: 513,914,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.81226
Policy Entropy: 1.11447
Value Function Loss: 1.25806

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.08428

Collected Steps per Second: 8,770.88683
Overall Steps per Second: 7,683.99200

Timestep Collection Time: 5.70387
Timestep Consumption Time: 0.80681
PPO Batch Consumption Time: 0.04050
Total Iteration Time: 6.51068

Cumulative Model Updates: 30,814
Cumulative Timesteps: 513,964,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 513964392...
Checkpoint 513964392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.84314
Policy Entropy: 1.13286
Value Function Loss: 1.29071

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.08655

Collected Steps per Second: 8,750.64887
Overall Steps per Second: 7,597.62351

Timestep Collection Time: 5.71432
Timestep Consumption Time: 0.86721
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.58153

Cumulative Model Updates: 30,817
Cumulative Timesteps: 514,014,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.20216
Policy Entropy: 1.12900
Value Function Loss: 1.39035

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 8,825.49178
Overall Steps per Second: 7,704.63057

Timestep Collection Time: 5.66858
Timestep Consumption Time: 0.82466
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.49324

Cumulative Model Updates: 30,820
Cumulative Timesteps: 514,064,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 514064424...
Checkpoint 514064424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.19456
Policy Entropy: 1.12522
Value Function Loss: 1.35289

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.07050

Collected Steps per Second: 8,351.46477
Overall Steps per Second: 7,395.84318

Timestep Collection Time: 5.98937
Timestep Consumption Time: 0.77389
PPO Batch Consumption Time: 0.04651
Total Iteration Time: 6.76326

Cumulative Model Updates: 30,823
Cumulative Timesteps: 514,114,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.54974
Policy Entropy: 1.11565
Value Function Loss: 1.37506

Mean KL Divergence: 0.02479
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 8,705.45820
Overall Steps per Second: 7,589.05335

Timestep Collection Time: 5.74651
Timestep Consumption Time: 0.84535
PPO Batch Consumption Time: 0.04397
Total Iteration Time: 6.59186

Cumulative Model Updates: 30,826
Cumulative Timesteps: 514,164,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 514164470...
Checkpoint 514164470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.67747
Policy Entropy: 1.12537
Value Function Loss: 1.35025

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.06944

Collected Steps per Second: 8,472.30592
Overall Steps per Second: 7,496.87212

Timestep Collection Time: 5.90441
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.04373
Total Iteration Time: 6.67265

Cumulative Model Updates: 30,829
Cumulative Timesteps: 514,214,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.53396
Policy Entropy: 1.12496
Value Function Loss: 1.33449

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 8,916.28198
Overall Steps per Second: 7,738.32466

Timestep Collection Time: 5.61108
Timestep Consumption Time: 0.85414
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 6.46522

Cumulative Model Updates: 30,832
Cumulative Timesteps: 514,264,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 514264524...
Checkpoint 514264524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.49015
Policy Entropy: 1.11114
Value Function Loss: 1.29322

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.07001

Collected Steps per Second: 8,699.92714
Overall Steps per Second: 7,597.62714

Timestep Collection Time: 5.75016
Timestep Consumption Time: 0.83426
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.58442

Cumulative Model Updates: 30,835
Cumulative Timesteps: 514,314,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.56132
Policy Entropy: 1.10082
Value Function Loss: 1.30075

Mean KL Divergence: 0.02848
SB3 Clip Fraction: 0.18696
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.06841

Collected Steps per Second: 8,530.32758
Overall Steps per Second: 7,569.44191

Timestep Collection Time: 5.86261
Timestep Consumption Time: 0.74422
PPO Batch Consumption Time: 0.04497
Total Iteration Time: 6.60683

Cumulative Model Updates: 30,838
Cumulative Timesteps: 514,364,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 514364560...
Checkpoint 514364560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.76535
Policy Entropy: 1.11358
Value Function Loss: 1.28961

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 8,576.27875
Overall Steps per Second: 7,461.56596

Timestep Collection Time: 5.83330
Timestep Consumption Time: 0.87146
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.70476

Cumulative Model Updates: 30,841
Cumulative Timesteps: 514,414,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.24149
Policy Entropy: 1.10275
Value Function Loss: 1.28509

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.06579

Collected Steps per Second: 8,763.55421
Overall Steps per Second: 7,667.35814

Timestep Collection Time: 5.70705
Timestep Consumption Time: 0.81593
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.52298

Cumulative Model Updates: 30,844
Cumulative Timesteps: 514,464,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 514464602...
Checkpoint 514464602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.94186
Policy Entropy: 1.08858
Value Function Loss: 1.29628

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.20406
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 8,869.23400
Overall Steps per Second: 7,708.15754

Timestep Collection Time: 5.64085
Timestep Consumption Time: 0.84968
PPO Batch Consumption Time: 0.04104
Total Iteration Time: 6.49053

Cumulative Model Updates: 30,847
Cumulative Timesteps: 514,514,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.16631
Policy Entropy: 1.10690
Value Function Loss: 1.30035

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.06851

Collected Steps per Second: 8,482.99701
Overall Steps per Second: 7,415.38123

Timestep Collection Time: 5.89485
Timestep Consumption Time: 0.84870
PPO Batch Consumption Time: 0.04000
Total Iteration Time: 6.74355

Cumulative Model Updates: 30,850
Cumulative Timesteps: 514,564,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 514564638...
Checkpoint 514564638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.99553
Policy Entropy: 1.10559
Value Function Loss: 1.36389

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.08706

Collected Steps per Second: 8,670.65534
Overall Steps per Second: 7,584.49118

Timestep Collection Time: 5.76911
Timestep Consumption Time: 0.82619
PPO Batch Consumption Time: 0.04862
Total Iteration Time: 6.59530

Cumulative Model Updates: 30,853
Cumulative Timesteps: 514,614,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.98514
Policy Entropy: 1.10297
Value Function Loss: 1.28080

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.09686

Collected Steps per Second: 8,698.95525
Overall Steps per Second: 7,593.78330

Timestep Collection Time: 5.75012
Timestep Consumption Time: 0.83685
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 6.58697

Cumulative Model Updates: 30,856
Cumulative Timesteps: 514,664,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 514664680...
Checkpoint 514664680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.20491
Policy Entropy: 1.10448
Value Function Loss: 1.39935

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.09317

Collected Steps per Second: 8,553.11186
Overall Steps per Second: 7,501.67565

Timestep Collection Time: 5.84816
Timestep Consumption Time: 0.81968
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 6.66784

Cumulative Model Updates: 30,859
Cumulative Timesteps: 514,714,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.76337
Policy Entropy: 1.10870
Value Function Loss: 1.33529

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 8,760.87107
Overall Steps per Second: 7,584.11669

Timestep Collection Time: 5.70811
Timestep Consumption Time: 0.88567
PPO Batch Consumption Time: 0.04537
Total Iteration Time: 6.59378

Cumulative Model Updates: 30,862
Cumulative Timesteps: 514,764,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 514764708...
Checkpoint 514764708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.72947
Policy Entropy: 1.11035
Value Function Loss: 1.35084

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 8,459.21297
Overall Steps per Second: 7,400.93579

Timestep Collection Time: 5.91190
Timestep Consumption Time: 0.84536
PPO Batch Consumption Time: 0.04414
Total Iteration Time: 6.75725

Cumulative Model Updates: 30,865
Cumulative Timesteps: 514,814,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.91445
Policy Entropy: 1.09746
Value Function Loss: 1.24906

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.08616

Collected Steps per Second: 8,778.73596
Overall Steps per Second: 7,722.67813

Timestep Collection Time: 5.69558
Timestep Consumption Time: 0.77886
PPO Batch Consumption Time: 0.04573
Total Iteration Time: 6.47444

Cumulative Model Updates: 30,868
Cumulative Timesteps: 514,864,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 514864718...
Checkpoint 514864718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.38489
Policy Entropy: 1.11001
Value Function Loss: 1.27081

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 8,633.94760
Overall Steps per Second: 7,535.06912

Timestep Collection Time: 5.79295
Timestep Consumption Time: 0.84482
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.63776

Cumulative Model Updates: 30,871
Cumulative Timesteps: 514,914,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.62902
Policy Entropy: 1.09909
Value Function Loss: 1.28394

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 8,550.55287
Overall Steps per Second: 7,450.42632

Timestep Collection Time: 5.84781
Timestep Consumption Time: 0.86348
PPO Batch Consumption Time: 0.04519
Total Iteration Time: 6.71129

Cumulative Model Updates: 30,874
Cumulative Timesteps: 514,964,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 514964736...
Checkpoint 514964736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.07347
Policy Entropy: 1.10252
Value Function Loss: 1.28092

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.06557
Value Function Update Magnitude: 0.08629

Collected Steps per Second: 8,837.90336
Overall Steps per Second: 7,677.62404

Timestep Collection Time: 5.65858
Timestep Consumption Time: 0.85515
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.51373

Cumulative Model Updates: 30,877
Cumulative Timesteps: 515,014,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.12480
Policy Entropy: 1.09307
Value Function Loss: 1.13393

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.17291
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.07265

Collected Steps per Second: 8,644.34663
Overall Steps per Second: 7,448.59422

Timestep Collection Time: 5.78575
Timestep Consumption Time: 0.92881
PPO Batch Consumption Time: 0.04787
Total Iteration Time: 6.71456

Cumulative Model Updates: 30,880
Cumulative Timesteps: 515,064,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 515064760...
Checkpoint 515064760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.08198
Policy Entropy: 1.10099
Value Function Loss: 1.18654

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.07057

Collected Steps per Second: 8,704.50351
Overall Steps per Second: 7,587.06858

Timestep Collection Time: 5.74622
Timestep Consumption Time: 0.84631
PPO Batch Consumption Time: 0.04361
Total Iteration Time: 6.59253

Cumulative Model Updates: 30,883
Cumulative Timesteps: 515,114,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.39657
Policy Entropy: 1.10293
Value Function Loss: 1.12968

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.06930

Collected Steps per Second: 8,937.38524
Overall Steps per Second: 7,696.65072

Timestep Collection Time: 5.59694
Timestep Consumption Time: 0.90225
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.49919

Cumulative Model Updates: 30,886
Cumulative Timesteps: 515,164,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 515164800...
Checkpoint 515164800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.44390
Policy Entropy: 1.09585
Value Function Loss: 1.21193

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 8,943.07705
Overall Steps per Second: 7,871.97803

Timestep Collection Time: 5.59315
Timestep Consumption Time: 0.76103
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.35418

Cumulative Model Updates: 30,889
Cumulative Timesteps: 515,214,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.65866
Policy Entropy: 1.08154
Value Function Loss: 1.14059

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.19689
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 8,694.09159
Overall Steps per Second: 7,544.55249

Timestep Collection Time: 5.75425
Timestep Consumption Time: 0.87676
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.63101

Cumulative Model Updates: 30,892
Cumulative Timesteps: 515,264,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 515264848...
Checkpoint 515264848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.45849
Policy Entropy: 1.09875
Value Function Loss: 1.21441

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 9,005.94468
Overall Steps per Second: 7,789.24955

Timestep Collection Time: 5.55389
Timestep Consumption Time: 0.86753
PPO Batch Consumption Time: 0.04830
Total Iteration Time: 6.42141

Cumulative Model Updates: 30,895
Cumulative Timesteps: 515,314,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.02271
Policy Entropy: 1.10340
Value Function Loss: 1.29915

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.08235

Collected Steps per Second: 9,035.51439
Overall Steps per Second: 7,873.24841

Timestep Collection Time: 5.53571
Timestep Consumption Time: 0.81719
PPO Batch Consumption Time: 0.05243
Total Iteration Time: 6.35291

Cumulative Model Updates: 30,898
Cumulative Timesteps: 515,364,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 515364884...
Checkpoint 515364884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.72982
Policy Entropy: 1.09250
Value Function Loss: 1.37299

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 8,633.11300
Overall Steps per Second: 7,487.59884

Timestep Collection Time: 5.79235
Timestep Consumption Time: 0.88616
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 6.67851

Cumulative Model Updates: 30,901
Cumulative Timesteps: 515,414,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.79201
Policy Entropy: 1.08374
Value Function Loss: 1.36615

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.07653

Collected Steps per Second: 8,380.86497
Overall Steps per Second: 7,335.51468

Timestep Collection Time: 5.96955
Timestep Consumption Time: 0.85069
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.82024

Cumulative Model Updates: 30,904
Cumulative Timesteps: 515,464,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 515464920...
Checkpoint 515464920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.08128
Policy Entropy: 1.10367
Value Function Loss: 1.32363

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.08161

Collected Steps per Second: 8,695.70734
Overall Steps per Second: 7,532.94421

Timestep Collection Time: 5.75295
Timestep Consumption Time: 0.88801
PPO Batch Consumption Time: 0.04317
Total Iteration Time: 6.64096

Cumulative Model Updates: 30,907
Cumulative Timesteps: 515,514,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.12046
Policy Entropy: 1.10324
Value Function Loss: 1.35925

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.10216

Collected Steps per Second: 8,576.26199
Overall Steps per Second: 7,490.51949

Timestep Collection Time: 5.83284
Timestep Consumption Time: 0.84546
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.67831

Cumulative Model Updates: 30,910
Cumulative Timesteps: 515,564,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 515564970...
Checkpoint 515564970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.94056
Policy Entropy: 1.09809
Value Function Loss: 1.37798

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 8,781.82393
Overall Steps per Second: 7,788.98734

Timestep Collection Time: 5.69540
Timestep Consumption Time: 0.72597
PPO Batch Consumption Time: 0.04116
Total Iteration Time: 6.42137

Cumulative Model Updates: 30,913
Cumulative Timesteps: 515,614,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.90477
Policy Entropy: 1.07902
Value Function Loss: 1.32902

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.17581
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.11937

Collected Steps per Second: 8,498.90766
Overall Steps per Second: 7,430.13831

Timestep Collection Time: 5.88617
Timestep Consumption Time: 0.84668
PPO Batch Consumption Time: 0.04066
Total Iteration Time: 6.73285

Cumulative Model Updates: 30,916
Cumulative Timesteps: 515,665,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 515665012...
Checkpoint 515665012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.76545
Policy Entropy: 1.09325
Value Function Loss: 1.24285

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 8,493.95434
Overall Steps per Second: 7,405.87071

Timestep Collection Time: 5.88819
Timestep Consumption Time: 0.86510
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.75329

Cumulative Model Updates: 30,919
Cumulative Timesteps: 515,715,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.33188
Policy Entropy: 1.08441
Value Function Loss: 1.30369

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.08800

Collected Steps per Second: 8,923.72035
Overall Steps per Second: 7,749.00272

Timestep Collection Time: 5.60461
Timestep Consumption Time: 0.84964
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 6.45425

Cumulative Model Updates: 30,922
Cumulative Timesteps: 515,765,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 515765040...
Checkpoint 515765040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.62758
Policy Entropy: 1.07813
Value Function Loss: 1.31363

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.06965
Value Function Update Magnitude: 0.08871

Collected Steps per Second: 8,573.45967
Overall Steps per Second: 7,506.16577

Timestep Collection Time: 5.83498
Timestep Consumption Time: 0.82967
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.66465

Cumulative Model Updates: 30,925
Cumulative Timesteps: 515,815,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.60761
Policy Entropy: 1.06616
Value Function Loss: 1.36757

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.17617
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.09248

Collected Steps per Second: 8,625.15927
Overall Steps per Second: 7,548.46333

Timestep Collection Time: 5.79815
Timestep Consumption Time: 0.82704
PPO Batch Consumption Time: 0.04572
Total Iteration Time: 6.62519

Cumulative Model Updates: 30,928
Cumulative Timesteps: 515,865,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 515865076...
Checkpoint 515865076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.07474
Policy Entropy: 1.07983
Value Function Loss: 1.28097

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.08476

Collected Steps per Second: 8,580.97875
Overall Steps per Second: 7,369.75097

Timestep Collection Time: 5.82987
Timestep Consumption Time: 0.95815
PPO Batch Consumption Time: 0.04591
Total Iteration Time: 6.78802

Cumulative Model Updates: 30,931
Cumulative Timesteps: 515,915,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.60261
Policy Entropy: 1.07123
Value Function Loss: 1.31999

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 8,747.51566
Overall Steps per Second: 7,657.15221

Timestep Collection Time: 5.71842
Timestep Consumption Time: 0.81429
PPO Batch Consumption Time: 0.04387
Total Iteration Time: 6.53272

Cumulative Model Updates: 30,934
Cumulative Timesteps: 515,965,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 515965124...
Checkpoint 515965124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.12236
Policy Entropy: 1.06627
Value Function Loss: 1.31104

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.07834

Collected Steps per Second: 8,801.21577
Overall Steps per Second: 7,672.49759

Timestep Collection Time: 5.68149
Timestep Consumption Time: 0.83582
PPO Batch Consumption Time: 0.04283
Total Iteration Time: 6.51730

Cumulative Model Updates: 30,937
Cumulative Timesteps: 516,015,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.84871
Policy Entropy: 1.06464
Value Function Loss: 1.31924

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.18773
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.07835

Collected Steps per Second: 8,977.73720
Overall Steps per Second: 7,829.06603

Timestep Collection Time: 5.57267
Timestep Consumption Time: 0.81762
PPO Batch Consumption Time: 0.04227
Total Iteration Time: 6.39029

Cumulative Model Updates: 30,940
Cumulative Timesteps: 516,065,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 516065158...
Checkpoint 516065158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.17533
Policy Entropy: 1.07070
Value Function Loss: 1.29266

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 8,967.73536
Overall Steps per Second: 7,804.98330

Timestep Collection Time: 5.57599
Timestep Consumption Time: 0.83069
PPO Batch Consumption Time: 0.05174
Total Iteration Time: 6.40668

Cumulative Model Updates: 30,943
Cumulative Timesteps: 516,115,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.38629
Policy Entropy: 1.07754
Value Function Loss: 1.19571

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.16985
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 8,638.41205
Overall Steps per Second: 7,584.43381

Timestep Collection Time: 5.78972
Timestep Consumption Time: 0.80457
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.59430

Cumulative Model Updates: 30,946
Cumulative Timesteps: 516,165,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 516165176...
Checkpoint 516165176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.36075
Policy Entropy: 1.03962
Value Function Loss: 1.12133

Mean KL Divergence: 0.06510
SB3 Clip Fraction: 0.26983
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 8,945.83078
Overall Steps per Second: 7,827.29409

Timestep Collection Time: 5.59210
Timestep Consumption Time: 0.79912
PPO Batch Consumption Time: 0.04119
Total Iteration Time: 6.39123

Cumulative Model Updates: 30,949
Cumulative Timesteps: 516,215,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.89963
Policy Entropy: 1.07523
Value Function Loss: 1.06838

Mean KL Divergence: 0.03725
SB3 Clip Fraction: 0.21946
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 8,941.42596
Overall Steps per Second: 7,919.55141

Timestep Collection Time: 5.59530
Timestep Consumption Time: 0.72197
PPO Batch Consumption Time: 0.04147
Total Iteration Time: 6.31728

Cumulative Model Updates: 30,952
Cumulative Timesteps: 516,265,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 516265232...
Checkpoint 516265232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.48259
Policy Entropy: 1.05159
Value Function Loss: 1.08368

Mean KL Divergence: 0.04253
SB3 Clip Fraction: 0.26868
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 9,036.04535
Overall Steps per Second: 7,824.69848

Timestep Collection Time: 5.53649
Timestep Consumption Time: 0.85711
PPO Batch Consumption Time: 0.04896
Total Iteration Time: 6.39360

Cumulative Model Updates: 30,955
Cumulative Timesteps: 516,315,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.24941
Policy Entropy: 1.07079
Value Function Loss: 1.22242

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.04138
Value Function Update Magnitude: 0.07692

Collected Steps per Second: 8,926.04563
Overall Steps per Second: 7,734.64511

Timestep Collection Time: 5.60360
Timestep Consumption Time: 0.86315
PPO Batch Consumption Time: 0.04992
Total Iteration Time: 6.46675

Cumulative Model Updates: 30,958
Cumulative Timesteps: 516,365,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516365278...
Checkpoint 516365278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.46082
Policy Entropy: 1.05914
Value Function Loss: 1.22205

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.07825

Collected Steps per Second: 8,778.52250
Overall Steps per Second: 7,623.42169

Timestep Collection Time: 5.69731
Timestep Consumption Time: 0.86326
PPO Batch Consumption Time: 0.04740
Total Iteration Time: 6.56057

Cumulative Model Updates: 30,961
Cumulative Timesteps: 516,415,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.81782
Policy Entropy: 1.04269
Value Function Loss: 1.25169

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.18393
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 8,753.71714
Overall Steps per Second: 7,607.93906

Timestep Collection Time: 5.71300
Timestep Consumption Time: 0.86039
PPO Batch Consumption Time: 0.04162
Total Iteration Time: 6.57340

Cumulative Model Updates: 30,964
Cumulative Timesteps: 516,465,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 516465302...
Checkpoint 516465302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.78188
Policy Entropy: 1.05968
Value Function Loss: 1.14334

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.20440
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.09035

Collected Steps per Second: 8,902.46259
Overall Steps per Second: 7,836.30074

Timestep Collection Time: 5.61687
Timestep Consumption Time: 0.76420
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.38107

Cumulative Model Updates: 30,967
Cumulative Timesteps: 516,515,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.52673
Policy Entropy: 1.05331
Value Function Loss: 1.10558

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.17327
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 8,786.68368
Overall Steps per Second: 7,678.87332

Timestep Collection Time: 5.69248
Timestep Consumption Time: 0.82124
PPO Batch Consumption Time: 0.04298
Total Iteration Time: 6.51372

Cumulative Model Updates: 30,970
Cumulative Timesteps: 516,565,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516565324...
Checkpoint 516565324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.10862
Policy Entropy: 1.04555
Value Function Loss: 1.11707

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.18059
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 8,669.21020
Overall Steps per Second: 7,628.62243

Timestep Collection Time: 5.76985
Timestep Consumption Time: 0.78704
PPO Batch Consumption Time: 0.04329
Total Iteration Time: 6.55688

Cumulative Model Updates: 30,973
Cumulative Timesteps: 516,615,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.34320
Policy Entropy: 1.02552
Value Function Loss: 1.14810

Mean KL Divergence: 0.02689
SB3 Clip Fraction: 0.22940
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.08855

Collected Steps per Second: 8,770.44637
Overall Steps per Second: 7,651.63094

Timestep Collection Time: 5.70324
Timestep Consumption Time: 0.83392
PPO Batch Consumption Time: 0.04419
Total Iteration Time: 6.53717

Cumulative Model Updates: 30,976
Cumulative Timesteps: 516,665,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 516665364...
Checkpoint 516665364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.40470
Policy Entropy: 1.04556
Value Function Loss: 1.16038

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.09311

Collected Steps per Second: 8,744.27550
Overall Steps per Second: 7,577.62100

Timestep Collection Time: 5.72009
Timestep Consumption Time: 0.88067
PPO Batch Consumption Time: 0.04624
Total Iteration Time: 6.60075

Cumulative Model Updates: 30,979
Cumulative Timesteps: 516,715,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.59907
Policy Entropy: 1.04126
Value Function Loss: 1.10941

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.10391

Collected Steps per Second: 8,680.90799
Overall Steps per Second: 7,685.66833

Timestep Collection Time: 5.76345
Timestep Consumption Time: 0.74633
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.50978

Cumulative Model Updates: 30,982
Cumulative Timesteps: 516,765,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 516765414...
Checkpoint 516765414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.09406
Policy Entropy: 1.02780
Value Function Loss: 1.10553

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 8,798.57043
Overall Steps per Second: 7,454.84486

Timestep Collection Time: 5.68388
Timestep Consumption Time: 1.02451
PPO Batch Consumption Time: 0.06128
Total Iteration Time: 6.70839

Cumulative Model Updates: 30,985
Cumulative Timesteps: 516,815,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.77878
Policy Entropy: 0.99585
Value Function Loss: 1.16504

Mean KL Divergence: 0.04534
SB3 Clip Fraction: 0.31179
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.07976

Collected Steps per Second: 8,709.52511
Overall Steps per Second: 7,568.72218

Timestep Collection Time: 5.74268
Timestep Consumption Time: 0.86557
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.60825

Cumulative Model Updates: 30,988
Cumulative Timesteps: 516,865,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 516865440...
Checkpoint 516865440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.32491
Policy Entropy: 1.01815
Value Function Loss: 1.10650

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.07391

Collected Steps per Second: 9,050.72856
Overall Steps per Second: 7,819.11742

Timestep Collection Time: 5.52574
Timestep Consumption Time: 0.87038
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 6.39612

Cumulative Model Updates: 30,991
Cumulative Timesteps: 516,915,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.53051
Policy Entropy: 0.99614
Value Function Loss: 1.06114

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.21258
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.06884

Collected Steps per Second: 8,908.36513
Overall Steps per Second: 7,776.52286

Timestep Collection Time: 5.61450
Timestep Consumption Time: 0.81717
PPO Batch Consumption Time: 0.04131
Total Iteration Time: 6.43167

Cumulative Model Updates: 30,994
Cumulative Timesteps: 516,965,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 516965468...
Checkpoint 516965468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.11704
Policy Entropy: 1.00291
Value Function Loss: 0.98465

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.19721
Policy Update Magnitude: 0.03867
Value Function Update Magnitude: 0.06669

Collected Steps per Second: 8,940.53707
Overall Steps per Second: 7,673.85041

Timestep Collection Time: 5.59586
Timestep Consumption Time: 0.92368
PPO Batch Consumption Time: 0.05283
Total Iteration Time: 6.51954

Cumulative Model Updates: 30,997
Cumulative Timesteps: 517,015,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.58583
Policy Entropy: 1.00640
Value Function Loss: 1.05252

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.17515
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.07212

Collected Steps per Second: 9,079.17474
Overall Steps per Second: 7,790.65692

Timestep Collection Time: 5.50931
Timestep Consumption Time: 0.91120
PPO Batch Consumption Time: 0.04219
Total Iteration Time: 6.42051

Cumulative Model Updates: 31,000
Cumulative Timesteps: 517,065,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517065518...
Checkpoint 517065518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.74448
Policy Entropy: 1.02289
Value Function Loss: 1.04345

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.17893
Policy Update Magnitude: 0.03962
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 9,172.82475
Overall Steps per Second: 7,914.28112

Timestep Collection Time: 5.45088
Timestep Consumption Time: 0.86681
PPO Batch Consumption Time: 0.04450
Total Iteration Time: 6.31769

Cumulative Model Updates: 31,003
Cumulative Timesteps: 517,115,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.74152
Policy Entropy: 0.96987
Value Function Loss: 1.09244

Mean KL Divergence: 0.04613
SB3 Clip Fraction: 0.27153
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.06370

Collected Steps per Second: 9,324.31940
Overall Steps per Second: 8,103.49232

Timestep Collection Time: 5.36447
Timestep Consumption Time: 0.80818
PPO Batch Consumption Time: 0.05053
Total Iteration Time: 6.17265

Cumulative Model Updates: 31,006
Cumulative Timesteps: 517,165,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517165538...
Checkpoint 517165538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.16447
Policy Entropy: 0.99091
Value Function Loss: 1.14452

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.17943
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.05678

Collected Steps per Second: 9,214.58544
Overall Steps per Second: 7,946.75872

Timestep Collection Time: 5.42900
Timestep Consumption Time: 0.86614
PPO Batch Consumption Time: 0.04718
Total Iteration Time: 6.29515

Cumulative Model Updates: 31,009
Cumulative Timesteps: 517,215,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.86074
Policy Entropy: 0.96577
Value Function Loss: 1.15936

Mean KL Divergence: 0.03031
SB3 Clip Fraction: 0.24537
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 8,838.68467
Overall Steps per Second: 7,601.00098

Timestep Collection Time: 5.65808
Timestep Consumption Time: 0.92131
PPO Batch Consumption Time: 0.05176
Total Iteration Time: 6.57940

Cumulative Model Updates: 31,012
Cumulative Timesteps: 517,265,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 517265574...
Checkpoint 517265574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.57172
Policy Entropy: 0.98271
Value Function Loss: 1.16899

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.19523
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 8,601.86168
Overall Steps per Second: 7,456.06162

Timestep Collection Time: 5.81595
Timestep Consumption Time: 0.89376
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.70971

Cumulative Model Updates: 31,015
Cumulative Timesteps: 517,315,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.47692
Policy Entropy: 0.98775
Value Function Loss: 1.09543

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.20181
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.06558

Collected Steps per Second: 8,862.69933
Overall Steps per Second: 7,685.99699

Timestep Collection Time: 5.64456
Timestep Consumption Time: 0.86416
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.50872

Cumulative Model Updates: 31,018
Cumulative Timesteps: 517,365,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 517365628...
Checkpoint 517365628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.52155
Policy Entropy: 0.97791
Value Function Loss: 1.04944

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.18952
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 8,757.51665
Overall Steps per Second: 7,750.09584

Timestep Collection Time: 5.71304
Timestep Consumption Time: 0.74263
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.45566

Cumulative Model Updates: 31,021
Cumulative Timesteps: 517,415,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.42706
Policy Entropy: 0.96493
Value Function Loss: 1.03140

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.24641
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.06104

Collected Steps per Second: 8,980.70361
Overall Steps per Second: 7,771.28520

Timestep Collection Time: 5.56972
Timestep Consumption Time: 0.86680
PPO Batch Consumption Time: 0.04545
Total Iteration Time: 6.43652

Cumulative Model Updates: 31,024
Cumulative Timesteps: 517,465,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517465680...
Checkpoint 517465680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.24383
Policy Entropy: 0.97532
Value Function Loss: 1.05016

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.17055
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.05851

Collected Steps per Second: 8,635.98614
Overall Steps per Second: 7,511.21345

Timestep Collection Time: 5.79297
Timestep Consumption Time: 0.86747
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.66044

Cumulative Model Updates: 31,027
Cumulative Timesteps: 517,515,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.14685
Policy Entropy: 0.98517
Value Function Loss: 1.07171

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.23571
Policy Update Magnitude: 0.04009
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 8,728.86250
Overall Steps per Second: 7,631.73135

Timestep Collection Time: 5.73064
Timestep Consumption Time: 0.82383
PPO Batch Consumption Time: 0.04061
Total Iteration Time: 6.55448

Cumulative Model Updates: 31,030
Cumulative Timesteps: 517,565,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 517565730...
Checkpoint 517565730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.04311
Policy Entropy: 0.94084
Value Function Loss: 1.04990

Mean KL Divergence: 0.06233
SB3 Clip Fraction: 0.29315
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 8,653.49315
Overall Steps per Second: 7,454.81176

Timestep Collection Time: 5.78171
Timestep Consumption Time: 0.92966
PPO Batch Consumption Time: 0.04868
Total Iteration Time: 6.71137

Cumulative Model Updates: 31,033
Cumulative Timesteps: 517,615,762

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.78572
Policy Entropy: 0.97628
Value Function Loss: 1.15997

Mean KL Divergence: 0.04948
SB3 Clip Fraction: 0.31299
Policy Update Magnitude: 0.03897
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 8,671.60565
Overall Steps per Second: 7,571.83815

Timestep Collection Time: 5.76802
Timestep Consumption Time: 0.83777
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 6.60579

Cumulative Model Updates: 31,036
Cumulative Timesteps: 517,665,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 517665780...
Checkpoint 517665780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.36436
Policy Entropy: 0.94372
Value Function Loss: 1.12174

Mean KL Divergence: 0.04843
SB3 Clip Fraction: 0.28984
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.05020

Collected Steps per Second: 8,613.43529
Overall Steps per Second: 7,496.14560

Timestep Collection Time: 5.80721
Timestep Consumption Time: 0.86556
PPO Batch Consumption Time: 0.04352
Total Iteration Time: 6.67276

Cumulative Model Updates: 31,039
Cumulative Timesteps: 517,715,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.25779
Policy Entropy: 0.97225
Value Function Loss: 1.16219

Mean KL Divergence: 0.03289
SB3 Clip Fraction: 0.23227
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.04399

Collected Steps per Second: 8,462.61564
Overall Steps per Second: 7,436.20613

Timestep Collection Time: 5.91141
Timestep Consumption Time: 0.81594
PPO Batch Consumption Time: 0.04460
Total Iteration Time: 6.72736

Cumulative Model Updates: 31,042
Cumulative Timesteps: 517,765,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 517765826...
Checkpoint 517765826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.96120
Policy Entropy: 0.95522
Value Function Loss: 1.12361

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.21107
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.03907

Collected Steps per Second: 8,517.16472
Overall Steps per Second: 7,528.26278

Timestep Collection Time: 5.87191
Timestep Consumption Time: 0.77133
PPO Batch Consumption Time: 0.04675
Total Iteration Time: 6.64323

Cumulative Model Updates: 31,045
Cumulative Timesteps: 517,815,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.02725
Policy Entropy: 0.94569
Value Function Loss: 1.15321

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.23159
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.04891

Collected Steps per Second: 8,577.10817
Overall Steps per Second: 7,520.88120

Timestep Collection Time: 5.83180
Timestep Consumption Time: 0.81901
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.65082

Cumulative Model Updates: 31,048
Cumulative Timesteps: 517,865,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517865858...
Checkpoint 517865858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.76189
Policy Entropy: 0.95346
Value Function Loss: 1.16682

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.17834
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 8,982.42399
Overall Steps per Second: 7,822.19893

Timestep Collection Time: 5.56888
Timestep Consumption Time: 0.82600
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 6.39488

Cumulative Model Updates: 31,051
Cumulative Timesteps: 517,915,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.70487
Policy Entropy: 0.96544
Value Function Loss: 1.10895

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.07626

Collected Steps per Second: 8,692.49121
Overall Steps per Second: 7,701.54646

Timestep Collection Time: 5.75416
Timestep Consumption Time: 0.74038
PPO Batch Consumption Time: 0.04978
Total Iteration Time: 6.49454

Cumulative Model Updates: 31,054
Cumulative Timesteps: 517,965,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 517965898...
Checkpoint 517965898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.83894
Policy Entropy: 0.93028
Value Function Loss: 1.20422

Mean KL Divergence: 0.03964
SB3 Clip Fraction: 0.27378
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 8,491.00781
Overall Steps per Second: 7,430.38453

Timestep Collection Time: 5.89023
Timestep Consumption Time: 0.84078
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.73101

Cumulative Model Updates: 31,057
Cumulative Timesteps: 518,015,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.16096
Policy Entropy: 0.95877
Value Function Loss: 1.18205

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.21088
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 8,799.45444
Overall Steps per Second: 7,701.20507

Timestep Collection Time: 5.68308
Timestep Consumption Time: 0.81045
PPO Batch Consumption Time: 0.04873
Total Iteration Time: 6.49353

Cumulative Model Updates: 31,060
Cumulative Timesteps: 518,065,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 518065920...
Checkpoint 518065920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.93803
Policy Entropy: 0.96084
Value Function Loss: 1.17497

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.18631
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 8,684.64999
Overall Steps per Second: 7,560.56683

Timestep Collection Time: 5.75751
Timestep Consumption Time: 0.85601
PPO Batch Consumption Time: 0.04443
Total Iteration Time: 6.61353

Cumulative Model Updates: 31,063
Cumulative Timesteps: 518,115,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.75968
Policy Entropy: 0.95789
Value Function Loss: 1.09094

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.07474

Collected Steps per Second: 8,674.36970
Overall Steps per Second: 7,527.30646

Timestep Collection Time: 5.76710
Timestep Consumption Time: 0.87883
PPO Batch Consumption Time: 0.04806
Total Iteration Time: 6.64594

Cumulative Model Updates: 31,066
Cumulative Timesteps: 518,165,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 518165948...
Checkpoint 518165948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.30763
Policy Entropy: 0.94521
Value Function Loss: 1.01976

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.17754
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 8,372.44163
Overall Steps per Second: 7,445.59513

Timestep Collection Time: 5.97484
Timestep Consumption Time: 0.74376
PPO Batch Consumption Time: 0.04140
Total Iteration Time: 6.71860

Cumulative Model Updates: 31,069
Cumulative Timesteps: 518,215,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.16893
Policy Entropy: 0.93752
Value Function Loss: 1.03375

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.17008
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.06691

Collected Steps per Second: 8,894.31397
Overall Steps per Second: 7,709.90098

Timestep Collection Time: 5.62179
Timestep Consumption Time: 0.86363
PPO Batch Consumption Time: 0.04281
Total Iteration Time: 6.48543

Cumulative Model Updates: 31,072
Cumulative Timesteps: 518,265,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 518265974...
Checkpoint 518265974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.83658
Policy Entropy: 0.94532
Value Function Loss: 0.99704

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 8,606.84811
Overall Steps per Second: 7,431.24292

Timestep Collection Time: 5.81165
Timestep Consumption Time: 0.91939
PPO Batch Consumption Time: 0.04613
Total Iteration Time: 6.73104

Cumulative Model Updates: 31,075
Cumulative Timesteps: 518,315,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.90527
Policy Entropy: 0.95378
Value Function Loss: 1.11371

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 8,929.24840
Overall Steps per Second: 7,715.17587

Timestep Collection Time: 5.60137
Timestep Consumption Time: 0.88144
PPO Batch Consumption Time: 0.04099
Total Iteration Time: 6.48281

Cumulative Model Updates: 31,078
Cumulative Timesteps: 518,366,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 518366010...
Checkpoint 518366010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.91426
Policy Entropy: 0.96146
Value Function Loss: 1.11951

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.18310
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 8,695.94617
Overall Steps per Second: 7,621.42531

Timestep Collection Time: 5.75280
Timestep Consumption Time: 0.81107
PPO Batch Consumption Time: 0.04451
Total Iteration Time: 6.56386

Cumulative Model Updates: 31,081
Cumulative Timesteps: 518,416,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.21995
Policy Entropy: 0.96450
Value Function Loss: 1.15679

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.18351
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 8,415.87568
Overall Steps per Second: 7,455.58129

Timestep Collection Time: 5.94115
Timestep Consumption Time: 0.76523
PPO Batch Consumption Time: 0.04460
Total Iteration Time: 6.70639

Cumulative Model Updates: 31,084
Cumulative Timesteps: 518,466,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 518466036...
Checkpoint 518466036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.16845
Policy Entropy: 0.95957
Value Function Loss: 1.12402

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.06270

Collected Steps per Second: 8,657.97269
Overall Steps per Second: 7,549.07886

Timestep Collection Time: 5.77757
Timestep Consumption Time: 0.84867
PPO Batch Consumption Time: 0.04238
Total Iteration Time: 6.62624

Cumulative Model Updates: 31,087
Cumulative Timesteps: 518,516,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.52193
Policy Entropy: 0.96030
Value Function Loss: 1.14775

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.21636
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 8,480.11353
Overall Steps per Second: 7,367.14615

Timestep Collection Time: 5.89780
Timestep Consumption Time: 0.89099
PPO Batch Consumption Time: 0.04480
Total Iteration Time: 6.78879

Cumulative Model Updates: 31,090
Cumulative Timesteps: 518,566,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 518566072...
Checkpoint 518566072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.65475
Policy Entropy: 0.97788
Value Function Loss: 1.13881

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.20081
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 8,556.91323
Overall Steps per Second: 7,525.55397

Timestep Collection Time: 5.84416
Timestep Consumption Time: 0.80093
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.64509

Cumulative Model Updates: 31,093
Cumulative Timesteps: 518,616,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.65647
Policy Entropy: 0.98619
Value Function Loss: 1.11818

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.20910
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 8,472.38064
Overall Steps per Second: 7,375.53541

Timestep Collection Time: 5.90271
Timestep Consumption Time: 0.87782
PPO Batch Consumption Time: 0.04206
Total Iteration Time: 6.78052

Cumulative Model Updates: 31,096
Cumulative Timesteps: 518,666,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 518666090...
Checkpoint 518666090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.68254
Policy Entropy: 0.96243
Value Function Loss: 1.18047

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.17947
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 8,707.31907
Overall Steps per Second: 7,581.33870

Timestep Collection Time: 5.74230
Timestep Consumption Time: 0.85285
PPO Batch Consumption Time: 0.04496
Total Iteration Time: 6.59514

Cumulative Model Updates: 31,099
Cumulative Timesteps: 518,716,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.40000
Policy Entropy: 0.97133
Value Function Loss: 1.18424

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.18213
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.07026

Collected Steps per Second: 8,717.41954
Overall Steps per Second: 7,539.67909

Timestep Collection Time: 5.73679
Timestep Consumption Time: 0.89612
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.63291

Cumulative Model Updates: 31,102
Cumulative Timesteps: 518,766,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 518766100...
Checkpoint 518766100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.35634
Policy Entropy: 0.98655
Value Function Loss: 1.26155

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.18017
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.06711

Collected Steps per Second: 8,765.65789
Overall Steps per Second: 7,588.68997

Timestep Collection Time: 5.70727
Timestep Consumption Time: 0.88517
PPO Batch Consumption Time: 0.05282
Total Iteration Time: 6.59244

Cumulative Model Updates: 31,105
Cumulative Timesteps: 518,816,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.86351
Policy Entropy: 1.00290
Value Function Loss: 1.21139

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.21053
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 8,902.52599
Overall Steps per Second: 7,857.77669

Timestep Collection Time: 5.61683
Timestep Consumption Time: 0.74680
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.36363

Cumulative Model Updates: 31,108
Cumulative Timesteps: 518,866,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518866132...
Checkpoint 518866132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.22860
Policy Entropy: 0.98944
Value Function Loss: 1.22644

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.18101
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.07231

Collected Steps per Second: 8,404.15668
Overall Steps per Second: 7,232.73974

Timestep Collection Time: 5.95063
Timestep Consumption Time: 0.96377
PPO Batch Consumption Time: 0.04703
Total Iteration Time: 6.91439

Cumulative Model Updates: 31,111
Cumulative Timesteps: 518,916,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.58693
Policy Entropy: 0.99791
Value Function Loss: 1.22593

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.21130
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.06956

Collected Steps per Second: 8,935.47223
Overall Steps per Second: 7,751.83214

Timestep Collection Time: 5.59769
Timestep Consumption Time: 0.85472
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 6.45241

Cumulative Model Updates: 31,114
Cumulative Timesteps: 518,966,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 518966160...
Checkpoint 518966160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.55679
Policy Entropy: 1.02014
Value Function Loss: 1.23728

Mean KL Divergence: 0.03039
SB3 Clip Fraction: 0.20295
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.06591

Collected Steps per Second: 8,600.80685
Overall Steps per Second: 7,587.87185

Timestep Collection Time: 5.81550
Timestep Consumption Time: 0.77633
PPO Batch Consumption Time: 0.04728
Total Iteration Time: 6.59184

Cumulative Model Updates: 31,117
Cumulative Timesteps: 519,016,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.90446
Policy Entropy: 1.03397
Value Function Loss: 1.30781

Mean KL Divergence: 0.02591
SB3 Clip Fraction: 0.21673
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 8,773.60575
Overall Steps per Second: 7,656.99656

Timestep Collection Time: 5.70096
Timestep Consumption Time: 0.83136
PPO Batch Consumption Time: 0.04203
Total Iteration Time: 6.53233

Cumulative Model Updates: 31,120
Cumulative Timesteps: 519,066,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 519066196...
Checkpoint 519066196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.70915
Policy Entropy: 1.01187
Value Function Loss: 1.27779

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.18121
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 8,374.96966
Overall Steps per Second: 7,314.97584

Timestep Collection Time: 5.97089
Timestep Consumption Time: 0.86523
PPO Batch Consumption Time: 0.04667
Total Iteration Time: 6.83611

Cumulative Model Updates: 31,123
Cumulative Timesteps: 519,116,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.67871
Policy Entropy: 1.01241
Value Function Loss: 1.22865

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.19858
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.05455

Collected Steps per Second: 8,946.61914
Overall Steps per Second: 7,743.07077

Timestep Collection Time: 5.58960
Timestep Consumption Time: 0.86882
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.45842

Cumulative Model Updates: 31,126
Cumulative Timesteps: 519,166,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 519166210...
Checkpoint 519166210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.21319
Policy Entropy: 1.02900
Value Function Loss: 1.18072

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.05806

Collected Steps per Second: 8,809.83667
Overall Steps per Second: 7,617.87984

Timestep Collection Time: 5.67888
Timestep Consumption Time: 0.88856
PPO Batch Consumption Time: 0.04453
Total Iteration Time: 6.56744

Cumulative Model Updates: 31,129
Cumulative Timesteps: 519,216,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.08621
Policy Entropy: 1.03904
Value Function Loss: 1.22800

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.06273

Collected Steps per Second: 8,815.53583
Overall Steps per Second: 7,766.03776

Timestep Collection Time: 5.67407
Timestep Consumption Time: 0.76679
PPO Batch Consumption Time: 0.04828
Total Iteration Time: 6.44086

Cumulative Model Updates: 31,132
Cumulative Timesteps: 519,266,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 519266260...
Checkpoint 519266260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.23201
Policy Entropy: 1.03240
Value Function Loss: 1.20475

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.18721
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 8,219.87081
Overall Steps per Second: 7,176.93808

Timestep Collection Time: 6.08355
Timestep Consumption Time: 0.88404
PPO Batch Consumption Time: 0.04231
Total Iteration Time: 6.96760

Cumulative Model Updates: 31,135
Cumulative Timesteps: 519,316,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.12211
Policy Entropy: 1.02083
Value Function Loss: 1.18302

Mean KL Divergence: 0.03150
SB3 Clip Fraction: 0.23985
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 8,410.36572
Overall Steps per Second: 7,300.39032

Timestep Collection Time: 5.94766
Timestep Consumption Time: 0.90430
PPO Batch Consumption Time: 0.05102
Total Iteration Time: 6.85196

Cumulative Model Updates: 31,138
Cumulative Timesteps: 519,366,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 519366288...
Checkpoint 519366288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.91243
Policy Entropy: 1.03653
Value Function Loss: 1.11278

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.06999

Collected Steps per Second: 8,674.20639
Overall Steps per Second: 7,645.93567

Timestep Collection Time: 5.76629
Timestep Consumption Time: 0.77548
PPO Batch Consumption Time: 0.04187
Total Iteration Time: 6.54178

Cumulative Model Updates: 31,141
Cumulative Timesteps: 519,416,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.07724
Policy Entropy: 1.03614
Value Function Loss: 1.22905

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.06716

Collected Steps per Second: 8,771.61325
Overall Steps per Second: 7,661.30560

Timestep Collection Time: 5.70249
Timestep Consumption Time: 0.82643
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.52891

Cumulative Model Updates: 31,144
Cumulative Timesteps: 519,466,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 519466326...
Checkpoint 519466326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.00890
Policy Entropy: 1.02212
Value Function Loss: 1.22486

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 8,610.36763
Overall Steps per Second: 7,493.25512

Timestep Collection Time: 5.80997
Timestep Consumption Time: 0.86616
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 6.67614

Cumulative Model Updates: 31,147
Cumulative Timesteps: 519,516,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.30932
Policy Entropy: 1.00857
Value Function Loss: 1.24100

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.17486
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 8,585.22365
Overall Steps per Second: 7,452.07570

Timestep Collection Time: 5.82396
Timestep Consumption Time: 0.88558
PPO Batch Consumption Time: 0.04726
Total Iteration Time: 6.70954

Cumulative Model Updates: 31,150
Cumulative Timesteps: 519,566,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 519566352...
Checkpoint 519566352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.00786
Policy Entropy: 1.00248
Value Function Loss: 1.10732

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.18874
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 8,803.40741
Overall Steps per Second: 7,592.24292

Timestep Collection Time: 5.68257
Timestep Consumption Time: 0.90652
PPO Batch Consumption Time: 0.04455
Total Iteration Time: 6.58909

Cumulative Model Updates: 31,153
Cumulative Timesteps: 519,616,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.50326
Policy Entropy: 1.00936
Value Function Loss: 1.16181

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15688
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.05695

Collected Steps per Second: 8,623.01930
Overall Steps per Second: 7,594.09367

Timestep Collection Time: 5.80191
Timestep Consumption Time: 0.78610
PPO Batch Consumption Time: 0.04611
Total Iteration Time: 6.58801

Cumulative Model Updates: 31,156
Cumulative Timesteps: 519,666,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 519666408...
Checkpoint 519666408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.12905
Policy Entropy: 1.02023
Value Function Loss: 1.17305

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.06283

Collected Steps per Second: 8,678.56525
Overall Steps per Second: 7,557.52273

Timestep Collection Time: 5.76363
Timestep Consumption Time: 0.85495
PPO Batch Consumption Time: 0.04113
Total Iteration Time: 6.61857

Cumulative Model Updates: 31,159
Cumulative Timesteps: 519,716,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.92333
Policy Entropy: 1.00231
Value Function Loss: 1.21467

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.16141
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 8,883.56521
Overall Steps per Second: 7,723.29509

Timestep Collection Time: 5.63152
Timestep Consumption Time: 0.84602
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 6.47755

Cumulative Model Updates: 31,162
Cumulative Timesteps: 519,766,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 519766456...
Checkpoint 519766456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.07032
Policy Entropy: 0.98962
Value Function Loss: 1.16331

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.21281
Policy Update Magnitude: 0.04356
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 8,760.78083
Overall Steps per Second: 7,623.49098

Timestep Collection Time: 5.71045
Timestep Consumption Time: 0.85190
PPO Batch Consumption Time: 0.04224
Total Iteration Time: 6.56235

Cumulative Model Updates: 31,165
Cumulative Timesteps: 519,816,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.28206
Policy Entropy: 0.99920
Value Function Loss: 1.11009

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 8,800.58179
Overall Steps per Second: 7,700.48912

Timestep Collection Time: 5.68394
Timestep Consumption Time: 0.81201
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.49595

Cumulative Model Updates: 31,168
Cumulative Timesteps: 519,866,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 519866506...
Checkpoint 519866506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.94697
Policy Entropy: 1.01398
Value Function Loss: 1.10703

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.20737
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.06683

Collected Steps per Second: 8,781.64776
Overall Steps per Second: 7,626.82641

Timestep Collection Time: 5.69620
Timestep Consumption Time: 0.86249
PPO Batch Consumption Time: 0.04383
Total Iteration Time: 6.55869

Cumulative Model Updates: 31,171
Cumulative Timesteps: 519,916,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.83841
Policy Entropy: 0.97768
Value Function Loss: 1.10021

Mean KL Divergence: 0.04629
SB3 Clip Fraction: 0.29758
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.06909

Collected Steps per Second: 8,828.62835
Overall Steps per Second: 7,670.78950

Timestep Collection Time: 5.66589
Timestep Consumption Time: 0.85522
PPO Batch Consumption Time: 0.04071
Total Iteration Time: 6.52110

Cumulative Model Updates: 31,174
Cumulative Timesteps: 519,966,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 519966550...
Checkpoint 519966550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.55806
Policy Entropy: 1.00655
Value Function Loss: 1.17590

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.19243
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.07074

Collected Steps per Second: 8,611.90727
Overall Steps per Second: 7,415.38532

Timestep Collection Time: 5.80708
Timestep Consumption Time: 0.93701
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.74409

Cumulative Model Updates: 31,177
Cumulative Timesteps: 520,016,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.31049
Policy Entropy: 0.99778
Value Function Loss: 1.15279

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.17177
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.07233

Collected Steps per Second: 8,993.04615
Overall Steps per Second: 7,777.66687

Timestep Collection Time: 5.56274
Timestep Consumption Time: 0.86926
PPO Batch Consumption Time: 0.04437
Total Iteration Time: 6.43201

Cumulative Model Updates: 31,180
Cumulative Timesteps: 520,066,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 520066586...
Checkpoint 520066586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.14538
Policy Entropy: 0.97939
Value Function Loss: 1.16243

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.07729

Collected Steps per Second: 8,793.57387
Overall Steps per Second: 7,624.44708

Timestep Collection Time: 5.68938
Timestep Consumption Time: 0.87241
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.56179

Cumulative Model Updates: 31,183
Cumulative Timesteps: 520,116,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.36188
Policy Entropy: 0.97126
Value Function Loss: 1.01942

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.21223
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 8,859.77686
Overall Steps per Second: 7,815.81536

Timestep Collection Time: 5.64642
Timestep Consumption Time: 0.75419
PPO Batch Consumption Time: 0.04297
Total Iteration Time: 6.40061

Cumulative Model Updates: 31,186
Cumulative Timesteps: 520,166,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 520166642...
Checkpoint 520166642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.10135
Policy Entropy: 0.98726
Value Function Loss: 1.05710

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.20019
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 8,778.73520
Overall Steps per Second: 7,589.37653

Timestep Collection Time: 5.69854
Timestep Consumption Time: 0.89304
PPO Batch Consumption Time: 0.04812
Total Iteration Time: 6.59158

Cumulative Model Updates: 31,189
Cumulative Timesteps: 520,216,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.10764
Policy Entropy: 0.99875
Value Function Loss: 1.06335

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.19677
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 8,342.24019
Overall Steps per Second: 7,338.87347

Timestep Collection Time: 5.99407
Timestep Consumption Time: 0.81951
PPO Batch Consumption Time: 0.04236
Total Iteration Time: 6.81358

Cumulative Model Updates: 31,192
Cumulative Timesteps: 520,266,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 520266672...
Checkpoint 520266672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.03492
Policy Entropy: 0.98329
Value Function Loss: 1.12107

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 8,826.19400
Overall Steps per Second: 7,704.99371

Timestep Collection Time: 5.66790
Timestep Consumption Time: 0.82477
PPO Batch Consumption Time: 0.04503
Total Iteration Time: 6.49267

Cumulative Model Updates: 31,195
Cumulative Timesteps: 520,316,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.19193
Policy Entropy: 0.95237
Value Function Loss: 1.12145

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.25478
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 8,535.26295
Overall Steps per Second: 7,464.07233

Timestep Collection Time: 5.86086
Timestep Consumption Time: 0.84111
PPO Batch Consumption Time: 0.04404
Total Iteration Time: 6.70197

Cumulative Model Updates: 31,198
Cumulative Timesteps: 520,366,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 520366722...
Checkpoint 520366722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.32952
Policy Entropy: 0.97727
Value Function Loss: 1.14776

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 8,618.67706
Overall Steps per Second: 7,602.83264

Timestep Collection Time: 5.80484
Timestep Consumption Time: 0.77561
PPO Batch Consumption Time: 0.04593
Total Iteration Time: 6.58044

Cumulative Model Updates: 31,201
Cumulative Timesteps: 520,416,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.66184
Policy Entropy: 0.98720
Value Function Loss: 1.15107

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.19715
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.06553

Collected Steps per Second: 8,568.02446
Overall Steps per Second: 7,385.96448

Timestep Collection Time: 5.83705
Timestep Consumption Time: 0.93417
PPO Batch Consumption Time: 0.04398
Total Iteration Time: 6.77122

Cumulative Model Updates: 31,204
Cumulative Timesteps: 520,466,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 520466764...
Checkpoint 520466764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.82366
Policy Entropy: 0.96767
Value Function Loss: 1.04753

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.19084
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.05580

Collected Steps per Second: 8,738.49195
Overall Steps per Second: 7,629.63698

Timestep Collection Time: 5.72410
Timestep Consumption Time: 0.83191
PPO Batch Consumption Time: 0.04089
Total Iteration Time: 6.55601

Cumulative Model Updates: 31,207
Cumulative Timesteps: 520,516,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.69906
Policy Entropy: 0.94318
Value Function Loss: 0.98505

Mean KL Divergence: 0.03652
SB3 Clip Fraction: 0.27701
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 8,615.45726
Overall Steps per Second: 7,574.82257

Timestep Collection Time: 5.80584
Timestep Consumption Time: 0.79761
PPO Batch Consumption Time: 0.04396
Total Iteration Time: 6.60346

Cumulative Model Updates: 31,210
Cumulative Timesteps: 520,566,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 520566804...
Checkpoint 520566804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.37204
Policy Entropy: 0.97208
Value Function Loss: 0.94106

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.18617
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.06159

Collected Steps per Second: 8,802.52884
Overall Steps per Second: 7,632.11001

Timestep Collection Time: 5.68087
Timestep Consumption Time: 0.87119
PPO Batch Consumption Time: 0.04661
Total Iteration Time: 6.55205

Cumulative Model Updates: 31,213
Cumulative Timesteps: 520,616,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.35071
Policy Entropy: 0.95205
Value Function Loss: 0.98610

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.05938

Collected Steps per Second: 9,190.12336
Overall Steps per Second: 7,964.93442

Timestep Collection Time: 5.44345
Timestep Consumption Time: 0.83733
PPO Batch Consumption Time: 0.04111
Total Iteration Time: 6.28078

Cumulative Model Updates: 31,216
Cumulative Timesteps: 520,666,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 520666836...
Checkpoint 520666836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.44237
Policy Entropy: 0.93735
Value Function Loss: 0.91375

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.21636
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 8,939.51887
Overall Steps per Second: 7,778.01173

Timestep Collection Time: 5.59337
Timestep Consumption Time: 0.83527
PPO Batch Consumption Time: 0.04142
Total Iteration Time: 6.42864

Cumulative Model Updates: 31,219
Cumulative Timesteps: 520,716,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.77813
Policy Entropy: 0.94818
Value Function Loss: 1.01169

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.17779
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.06059

Collected Steps per Second: 8,948.74679
Overall Steps per Second: 7,725.50569

Timestep Collection Time: 5.58916
Timestep Consumption Time: 0.88498
PPO Batch Consumption Time: 0.04319
Total Iteration Time: 6.47414

Cumulative Model Updates: 31,222
Cumulative Timesteps: 520,766,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520766854...
Checkpoint 520766854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.46330
Policy Entropy: 0.95905
Value Function Loss: 0.94689

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.21057
Policy Update Magnitude: 0.04055
Value Function Update Magnitude: 0.05970

Collected Steps per Second: 9,160.33343
Overall Steps per Second: 8,039.19073

Timestep Collection Time: 5.45832
Timestep Consumption Time: 0.76121
PPO Batch Consumption Time: 0.04222
Total Iteration Time: 6.21953

Cumulative Model Updates: 31,225
Cumulative Timesteps: 520,816,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.66284
Policy Entropy: 0.93422
Value Function Loss: 1.10008

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.17178
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 8,530.88405
Overall Steps per Second: 7,457.79740

Timestep Collection Time: 5.86176
Timestep Consumption Time: 0.84344
PPO Batch Consumption Time: 0.04280
Total Iteration Time: 6.70520

Cumulative Model Updates: 31,228
Cumulative Timesteps: 520,866,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 520866860...
Checkpoint 520866860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.20211
Policy Entropy: 0.89635
Value Function Loss: 1.04420

Mean KL Divergence: 0.05550
SB3 Clip Fraction: 0.34135
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.05834

Collected Steps per Second: 8,809.72000
Overall Steps per Second: 7,612.65358

Timestep Collection Time: 5.67782
Timestep Consumption Time: 0.89282
PPO Batch Consumption Time: 0.04272
Total Iteration Time: 6.57064

Cumulative Model Updates: 31,231
Cumulative Timesteps: 520,916,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.65313
Policy Entropy: 0.95438
Value Function Loss: 1.15320

Mean KL Divergence: 0.04773
SB3 Clip Fraction: 0.32079
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.06062

Collected Steps per Second: 8,538.58790
Overall Steps per Second: 7,569.97895

Timestep Collection Time: 5.85811
Timestep Consumption Time: 0.74957
PPO Batch Consumption Time: 0.04134
Total Iteration Time: 6.60768

Cumulative Model Updates: 31,234
Cumulative Timesteps: 520,966,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 520966900...
Checkpoint 520966900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.47837
Policy Entropy: 0.90958
Value Function Loss: 1.05445

Mean KL Divergence: 0.08051
SB3 Clip Fraction: 0.37991
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.06280

Collected Steps per Second: 8,659.86915
Overall Steps per Second: 7,532.29734

Timestep Collection Time: 5.77653
Timestep Consumption Time: 0.86474
PPO Batch Consumption Time: 0.04630
Total Iteration Time: 6.64127

Cumulative Model Updates: 31,237
Cumulative Timesteps: 521,016,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.23846
Policy Entropy: 0.94536
Value Function Loss: 1.15007

Mean KL Divergence: 0.05755
SB3 Clip Fraction: 0.33923
Policy Update Magnitude: 0.03568
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 8,712.46529
Overall Steps per Second: 7,585.88579

Timestep Collection Time: 5.74143
Timestep Consumption Time: 0.85266
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 6.59409

Cumulative Model Updates: 31,240
Cumulative Timesteps: 521,066,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 521066946...
Checkpoint 521066946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.18650
Policy Entropy: 0.90314
Value Function Loss: 1.10850

Mean KL Divergence: 0.07921
SB3 Clip Fraction: 0.37755
Policy Update Magnitude: 0.03825
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 8,795.45101
Overall Steps per Second: 7,627.62840

Timestep Collection Time: 5.68726
Timestep Consumption Time: 0.87074
PPO Batch Consumption Time: 0.04565
Total Iteration Time: 6.55800

Cumulative Model Updates: 31,243
Cumulative Timesteps: 521,116,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.03142
Policy Entropy: 0.93544
Value Function Loss: 1.17130

Mean KL Divergence: 0.05586
SB3 Clip Fraction: 0.35003
Policy Update Magnitude: 0.03329
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 8,643.21394
Overall Steps per Second: 7,571.10450

Timestep Collection Time: 5.78766
Timestep Consumption Time: 0.81956
PPO Batch Consumption Time: 0.04123
Total Iteration Time: 6.60723

Cumulative Model Updates: 31,246
Cumulative Timesteps: 521,166,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 521166992...
Checkpoint 521166992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.79548
Policy Entropy: 0.91428
Value Function Loss: 1.14976

Mean KL Divergence: 0.04866
SB3 Clip Fraction: 0.30343
Policy Update Magnitude: 0.03577
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 8,323.17586
Overall Steps per Second: 7,321.05697

Timestep Collection Time: 6.01093
Timestep Consumption Time: 0.82279
PPO Batch Consumption Time: 0.05264
Total Iteration Time: 6.83371

Cumulative Model Updates: 31,249
Cumulative Timesteps: 521,217,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.55779
Policy Entropy: 0.95894
Value Function Loss: 1.20797

Mean KL Divergence: 0.04955
SB3 Clip Fraction: 0.32126
Policy Update Magnitude: 0.03683
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 8,832.69413
Overall Steps per Second: 7,683.14477

Timestep Collection Time: 5.66305
Timestep Consumption Time: 0.84730
PPO Batch Consumption Time: 0.04469
Total Iteration Time: 6.51035

Cumulative Model Updates: 31,252
Cumulative Timesteps: 521,267,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 521267042...
Checkpoint 521267042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.44850
Policy Entropy: 0.93932
Value Function Loss: 1.21248

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.21933
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 8,548.38131
Overall Steps per Second: 7,461.73040

Timestep Collection Time: 5.85070
Timestep Consumption Time: 0.85204
PPO Batch Consumption Time: 0.04223
Total Iteration Time: 6.70273

Cumulative Model Updates: 31,255
Cumulative Timesteps: 521,317,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.98338
Policy Entropy: 0.96243
Value Function Loss: 1.17893

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.22793
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.06824

Collected Steps per Second: 8,914.07440
Overall Steps per Second: 7,732.60994

Timestep Collection Time: 5.61113
Timestep Consumption Time: 0.85732
PPO Batch Consumption Time: 0.04304
Total Iteration Time: 6.46845

Cumulative Model Updates: 31,258
Cumulative Timesteps: 521,367,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 521367074...
Checkpoint 521367074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.59924
Policy Entropy: 0.97711
Value Function Loss: 1.13455

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.21172
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 8,369.10710
Overall Steps per Second: 7,334.19266

Timestep Collection Time: 5.97698
Timestep Consumption Time: 0.84340
PPO Batch Consumption Time: 0.04514
Total Iteration Time: 6.82038

Cumulative Model Updates: 31,261
Cumulative Timesteps: 521,417,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.74257
Policy Entropy: 0.94616
Value Function Loss: 1.04089

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.21691
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.06015

Collected Steps per Second: 8,754.98519
Overall Steps per Second: 7,725.04989

Timestep Collection Time: 5.71195
Timestep Consumption Time: 0.76154
PPO Batch Consumption Time: 0.04595
Total Iteration Time: 6.47349

Cumulative Model Updates: 31,264
Cumulative Timesteps: 521,467,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 521467104...
Checkpoint 521467104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.20437
Policy Entropy: 0.97921
Value Function Loss: 1.06934

Mean KL Divergence: 0.04232
SB3 Clip Fraction: 0.27540
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 8,666.19910
Overall Steps per Second: 7,600.17868

Timestep Collection Time: 5.77000
Timestep Consumption Time: 0.80932
PPO Batch Consumption Time: 0.04057
Total Iteration Time: 6.57932

Cumulative Model Updates: 31,267
Cumulative Timesteps: 521,517,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.42634
Policy Entropy: 0.97771
Value Function Loss: 1.06542

Mean KL Divergence: 0.04175
SB3 Clip Fraction: 0.26680
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.05816

Collected Steps per Second: 8,697.18893
Overall Steps per Second: 7,611.22682

Timestep Collection Time: 5.74898
Timestep Consumption Time: 0.82026
PPO Batch Consumption Time: 0.04291
Total Iteration Time: 6.56924

Cumulative Model Updates: 31,270
Cumulative Timesteps: 521,567,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 521567108...
Checkpoint 521567108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.24445
Policy Entropy: 0.98527
Value Function Loss: 1.05532

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.20680
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.07351

Collected Steps per Second: 8,600.88958
Overall Steps per Second: 7,586.03594

Timestep Collection Time: 5.81707
Timestep Consumption Time: 0.77820
PPO Batch Consumption Time: 0.04796
Total Iteration Time: 6.59528

Cumulative Model Updates: 31,273
Cumulative Timesteps: 521,617,140

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.98459
Policy Entropy: 0.94459
Value Function Loss: 1.04044

Mean KL Divergence: 0.04878
SB3 Clip Fraction: 0.28965
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 8,642.79207
Overall Steps per Second: 7,553.33792

Timestep Collection Time: 5.78771
Timestep Consumption Time: 0.83479
PPO Batch Consumption Time: 0.04169
Total Iteration Time: 6.62250

Cumulative Model Updates: 31,276
Cumulative Timesteps: 521,667,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 521667162...
Checkpoint 521667162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.99224
Policy Entropy: 0.99369
Value Function Loss: 1.05531

Mean KL Divergence: 0.05782
SB3 Clip Fraction: 0.32141
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.07652

Collected Steps per Second: 8,829.33194
Overall Steps per Second: 7,671.44526

Timestep Collection Time: 5.66294
Timestep Consumption Time: 0.85473
PPO Batch Consumption Time: 0.04120
Total Iteration Time: 6.51768

Cumulative Model Updates: 31,279
Cumulative Timesteps: 521,717,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.25703
Policy Entropy: 0.98985
Value Function Loss: 1.17417

Mean KL Divergence: 0.05006
SB3 Clip Fraction: 0.25241
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.06295

Collected Steps per Second: 8,695.84952
Overall Steps per Second: 7,576.61760

Timestep Collection Time: 5.75010
Timestep Consumption Time: 0.84942
PPO Batch Consumption Time: 0.04309
Total Iteration Time: 6.59951

Cumulative Model Updates: 31,282
Cumulative Timesteps: 521,767,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 521767164...
Checkpoint 521767164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.26390
Policy Entropy: 1.00604
Value Function Loss: 1.19199

Mean KL Divergence: 0.04571
SB3 Clip Fraction: 0.23842
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.05549

Collected Steps per Second: 8,626.74432
Overall Steps per Second: 7,537.47028

Timestep Collection Time: 5.79918
Timestep Consumption Time: 0.83807
PPO Batch Consumption Time: 0.04155
Total Iteration Time: 6.63724

Cumulative Model Updates: 31,285
Cumulative Timesteps: 521,817,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.23684
Policy Entropy: 1.03037
Value Function Loss: 1.23939

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.22045
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.05464

Collected Steps per Second: 8,541.31327
Overall Steps per Second: 7,503.68526

Timestep Collection Time: 5.85460
Timestep Consumption Time: 0.80959
PPO Batch Consumption Time: 0.04368
Total Iteration Time: 6.66419

Cumulative Model Updates: 31,288
Cumulative Timesteps: 521,867,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 521867198...
Checkpoint 521867198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.77549
Policy Entropy: 1.04714
Value Function Loss: 1.32093

Mean KL Divergence: 0.03291
SB3 Clip Fraction: 0.22210
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 8,760.36600
Overall Steps per Second: 7,585.39588

Timestep Collection Time: 5.70867
Timestep Consumption Time: 0.88427
PPO Batch Consumption Time: 0.04493
Total Iteration Time: 6.59293

Cumulative Model Updates: 31,291
Cumulative Timesteps: 521,917,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.89004
Policy Entropy: 1.06382
Value Function Loss: 1.40818

Mean KL Divergence: 0.03273
SB3 Clip Fraction: 0.23403
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 8,850.56220
Overall Steps per Second: 7,652.22089

Timestep Collection Time: 5.65230
Timestep Consumption Time: 0.88515
PPO Batch Consumption Time: 0.05031
Total Iteration Time: 6.53745

Cumulative Model Updates: 31,294
Cumulative Timesteps: 521,967,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 521967234...
Checkpoint 521967234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.20365
Policy Entropy: 1.05709
Value Function Loss: 1.51114

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.17523
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.09596

Collected Steps per Second: 8,700.48843
Overall Steps per Second: 7,540.53365

Timestep Collection Time: 5.74933
Timestep Consumption Time: 0.88442
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.63375

Cumulative Model Updates: 31,297
Cumulative Timesteps: 522,017,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.33945
Policy Entropy: 1.05158
Value Function Loss: 1.67044

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.18111
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.08889

Collected Steps per Second: 8,459.85383
Overall Steps per Second: 7,389.78206

Timestep Collection Time: 5.91240
Timestep Consumption Time: 0.85614
PPO Batch Consumption Time: 0.04062
Total Iteration Time: 6.76854

Cumulative Model Updates: 31,300
Cumulative Timesteps: 522,067,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 522067274...
Checkpoint 522067274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.59878
Policy Entropy: 1.06673
Value Function Loss: 1.67109

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 8,559.79037
Overall Steps per Second: 7,544.31311

Timestep Collection Time: 5.84243
Timestep Consumption Time: 0.78640
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.62883

Cumulative Model Updates: 31,303
Cumulative Timesteps: 522,117,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.14756
Policy Entropy: 1.08315
Value Function Loss: 1.69837

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.19822
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.07882

Collected Steps per Second: 8,663.98602
Overall Steps per Second: 7,525.64744

Timestep Collection Time: 5.77286
Timestep Consumption Time: 0.87321
PPO Batch Consumption Time: 0.04362
Total Iteration Time: 6.64607

Cumulative Model Updates: 31,306
Cumulative Timesteps: 522,167,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 522167300...
Checkpoint 522167300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.25962
Policy Entropy: 1.07728
Value Function Loss: 1.46406

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.16281
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.07311

Collected Steps per Second: 8,572.47844
Overall Steps per Second: 7,453.62350

Timestep Collection Time: 5.83612
Timestep Consumption Time: 0.87605
PPO Batch Consumption Time: 0.04792
Total Iteration Time: 6.71217

Cumulative Model Updates: 31,309
Cumulative Timesteps: 522,217,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.41688
Policy Entropy: 1.07275
Value Function Loss: 1.53629

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.18650
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 8,763.36260
Overall Steps per Second: 7,728.01694

Timestep Collection Time: 5.70831
Timestep Consumption Time: 0.76476
PPO Batch Consumption Time: 0.04517
Total Iteration Time: 6.47307

Cumulative Model Updates: 31,312
Cumulative Timesteps: 522,267,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 522267354...
Checkpoint 522267354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.14540
Policy Entropy: 1.10307
Value Function Loss: 1.54684

Mean KL Divergence: 0.03654
SB3 Clip Fraction: 0.24565
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 8,360.09723
Overall Steps per Second: 7,267.13011

Timestep Collection Time: 5.98390
Timestep Consumption Time: 0.89997
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.88387

Cumulative Model Updates: 31,315
Cumulative Timesteps: 522,317,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.46182
Policy Entropy: 1.10084
Value Function Loss: 1.65517

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.17810
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 8,692.18665
Overall Steps per Second: 7,565.45303

Timestep Collection Time: 5.75482
Timestep Consumption Time: 0.85707
PPO Batch Consumption Time: 0.04133
Total Iteration Time: 6.61190

Cumulative Model Updates: 31,318
Cumulative Timesteps: 522,367,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 522367402...
Checkpoint 522367402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.36057
Policy Entropy: 1.10072
Value Function Loss: 1.76277

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.18663
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 8,743.63499
Overall Steps per Second: 7,531.89945

Timestep Collection Time: 5.72096
Timestep Consumption Time: 0.92039
PPO Batch Consumption Time: 0.04618
Total Iteration Time: 6.64135

Cumulative Model Updates: 31,321
Cumulative Timesteps: 522,417,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.24914
Policy Entropy: 1.10091
Value Function Loss: 1.90845

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 8,985.45747
Overall Steps per Second: 7,803.25844

Timestep Collection Time: 5.56766
Timestep Consumption Time: 0.84350
PPO Batch Consumption Time: 0.04832
Total Iteration Time: 6.41117

Cumulative Model Updates: 31,324
Cumulative Timesteps: 522,467,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 522467452...
Checkpoint 522467452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.31012
Policy Entropy: 1.13351
Value Function Loss: 2.10196

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.18154
Policy Update Magnitude: 0.07076
Value Function Update Magnitude: 0.08862

Collected Steps per Second: 9,018.06761
Overall Steps per Second: 7,879.27753

Timestep Collection Time: 5.54686
Timestep Consumption Time: 0.80169
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.34855

Cumulative Model Updates: 31,327
Cumulative Timesteps: 522,517,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.56403
Policy Entropy: 1.14016
Value Function Loss: 2.08561

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.07992
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 8,959.46593
Overall Steps per Second: 7,766.11016

Timestep Collection Time: 5.58404
Timestep Consumption Time: 0.85805
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.44209

Cumulative Model Updates: 31,330
Cumulative Timesteps: 522,567,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 522567504...
Checkpoint 522567504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.06586
Policy Entropy: 1.14587
Value Function Loss: 2.02988

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.08435
Value Function Update Magnitude: 0.09035

Collected Steps per Second: 8,591.88564
Overall Steps per Second: 7,474.77454

Timestep Collection Time: 5.82270
Timestep Consumption Time: 0.87021
PPO Batch Consumption Time: 0.04442
Total Iteration Time: 6.69291

Cumulative Model Updates: 31,333
Cumulative Timesteps: 522,617,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.73790
Policy Entropy: 1.13416
Value Function Loss: 1.89330

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.07987
Value Function Update Magnitude: 0.09504

Collected Steps per Second: 8,786.00826
Overall Steps per Second: 7,614.43505

Timestep Collection Time: 5.69223
Timestep Consumption Time: 0.87582
PPO Batch Consumption Time: 0.04672
Total Iteration Time: 6.56805

Cumulative Model Updates: 31,336
Cumulative Timesteps: 522,667,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 522667544...
Checkpoint 522667544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.71160
Policy Entropy: 1.13231
Value Function Loss: 1.91181

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 8,802.20394
Overall Steps per Second: 7,654.53402

Timestep Collection Time: 5.68130
Timestep Consumption Time: 0.85182
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.53312

Cumulative Model Updates: 31,339
Cumulative Timesteps: 522,717,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.24433
Policy Entropy: 1.14443
Value Function Loss: 1.81403

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.12660

Collected Steps per Second: 8,208.97734
Overall Steps per Second: 7,283.68477

Timestep Collection Time: 6.09309
Timestep Consumption Time: 0.77404
PPO Batch Consumption Time: 0.04814
Total Iteration Time: 6.86713

Cumulative Model Updates: 31,342
Cumulative Timesteps: 522,767,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 522767570...
Checkpoint 522767570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.30044
Policy Entropy: 1.14712
Value Function Loss: 1.85291

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.07886
Value Function Update Magnitude: 0.12608

Collected Steps per Second: 8,590.79809
Overall Steps per Second: 7,448.30366

Timestep Collection Time: 5.82274
Timestep Consumption Time: 0.89315
PPO Batch Consumption Time: 0.04422
Total Iteration Time: 6.71589

Cumulative Model Updates: 31,345
Cumulative Timesteps: 522,817,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.50674
Policy Entropy: 1.13632
Value Function Loss: 1.89794

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.08304
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 8,749.67669
Overall Steps per Second: 7,755.28179

Timestep Collection Time: 5.71633
Timestep Consumption Time: 0.73296
PPO Batch Consumption Time: 0.04149
Total Iteration Time: 6.44928

Cumulative Model Updates: 31,348
Cumulative Timesteps: 522,867,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 522867608...
Checkpoint 522867608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.92129
Policy Entropy: 1.14097
Value Function Loss: 1.93524

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.07522
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 8,735.81319
Overall Steps per Second: 7,592.05158

Timestep Collection Time: 5.72402
Timestep Consumption Time: 0.86234
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.58636

Cumulative Model Updates: 31,351
Cumulative Timesteps: 522,917,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.94826
Policy Entropy: 1.14584
Value Function Loss: 1.93952

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 8,382.23389
Overall Steps per Second: 7,332.12704

Timestep Collection Time: 5.96547
Timestep Consumption Time: 0.85437
PPO Batch Consumption Time: 0.04365
Total Iteration Time: 6.81985

Cumulative Model Updates: 31,354
Cumulative Timesteps: 522,967,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522967616...
Checkpoint 522967616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.71190
Policy Entropy: 1.15055
Value Function Loss: 1.92033

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.06979
Value Function Update Magnitude: 0.10242

Collected Steps per Second: 8,533.76222
Overall Steps per Second: 7,529.21957

Timestep Collection Time: 5.86049
Timestep Consumption Time: 0.78190
PPO Batch Consumption Time: 0.03969
Total Iteration Time: 6.64239

Cumulative Model Updates: 31,357
Cumulative Timesteps: 523,017,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.17628
Policy Entropy: 1.13466
Value Function Loss: 1.92475

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 8,522.03690
Overall Steps per Second: 7,436.00112

Timestep Collection Time: 5.86761
Timestep Consumption Time: 0.85697
PPO Batch Consumption Time: 0.04888
Total Iteration Time: 6.72458

Cumulative Model Updates: 31,360
Cumulative Timesteps: 523,067,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 523067632...
Checkpoint 523067632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.14983
Policy Entropy: 1.12698
Value Function Loss: 1.77268

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.16074
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 8,419.44937
Overall Steps per Second: 7,470.56482

Timestep Collection Time: 5.94053
Timestep Consumption Time: 0.75455
PPO Batch Consumption Time: 0.04334
Total Iteration Time: 6.69508

Cumulative Model Updates: 31,363
Cumulative Timesteps: 523,117,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.88223
Policy Entropy: 1.13581
Value Function Loss: 1.79363

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 8,804.10202
Overall Steps per Second: 7,714.25634

Timestep Collection Time: 5.68122
Timestep Consumption Time: 0.80262
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 6.48384

Cumulative Model Updates: 31,366
Cumulative Timesteps: 523,167,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 523167666...
Checkpoint 523167666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.23518
Policy Entropy: 1.13673
Value Function Loss: 1.74870

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.06104

Collected Steps per Second: 8,494.41424
Overall Steps per Second: 7,488.36416

Timestep Collection Time: 5.88881
Timestep Consumption Time: 0.79115
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 6.67996

Cumulative Model Updates: 31,369
Cumulative Timesteps: 523,217,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.43626
Policy Entropy: 1.11568
Value Function Loss: 1.73176

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 8,693.41730
Overall Steps per Second: 7,625.11436

Timestep Collection Time: 5.75424
Timestep Consumption Time: 0.80619
PPO Batch Consumption Time: 0.04044
Total Iteration Time: 6.56043

Cumulative Model Updates: 31,372
Cumulative Timesteps: 523,267,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 523267712...
Checkpoint 523267712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.51836
Policy Entropy: 1.10518
Value Function Loss: 1.67725

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.07541

Collected Steps per Second: 8,577.75888
Overall Steps per Second: 7,548.60444

Timestep Collection Time: 5.83136
Timestep Consumption Time: 0.79503
PPO Batch Consumption Time: 0.04126
Total Iteration Time: 6.62639

Cumulative Model Updates: 31,375
Cumulative Timesteps: 523,317,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.43570
Policy Entropy: 1.11788
Value Function Loss: 1.61266

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.07004

Collected Steps per Second: 8,662.84444
Overall Steps per Second: 7,643.79184

Timestep Collection Time: 5.77316
Timestep Consumption Time: 0.76966
PPO Batch Consumption Time: 0.05055
Total Iteration Time: 6.54283

Cumulative Model Updates: 31,378
Cumulative Timesteps: 523,367,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 523367744...
Checkpoint 523367744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.28509
Policy Entropy: 1.11654
Value Function Loss: 1.72067

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 8,521.77004
Overall Steps per Second: 7,361.93773

Timestep Collection Time: 5.86920
Timestep Consumption Time: 0.92466
PPO Batch Consumption Time: 0.04564
Total Iteration Time: 6.79386

Cumulative Model Updates: 31,381
Cumulative Timesteps: 523,417,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.26140
Policy Entropy: 1.10640
Value Function Loss: 1.64339

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16853
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.05891

Collected Steps per Second: 8,652.61433
Overall Steps per Second: 7,556.60878

Timestep Collection Time: 5.78161
Timestep Consumption Time: 0.83856
PPO Batch Consumption Time: 0.04336
Total Iteration Time: 6.62017

Cumulative Model Updates: 31,384
Cumulative Timesteps: 523,467,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 523467786...
Checkpoint 523467786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.10787
Policy Entropy: 1.09884
Value Function Loss: 1.69377

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.18296
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.05889

Collected Steps per Second: 9,010.74912
Overall Steps per Second: 7,725.54239

Timestep Collection Time: 5.55004
Timestep Consumption Time: 0.92329
PPO Batch Consumption Time: 0.04484
Total Iteration Time: 6.47333

Cumulative Model Updates: 31,387
Cumulative Timesteps: 523,517,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.92526
Policy Entropy: 1.10238
Value Function Loss: 1.63795

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 8,782.17843
Overall Steps per Second: 7,610.43692

Timestep Collection Time: 5.69585
Timestep Consumption Time: 0.87696
PPO Batch Consumption Time: 0.04549
Total Iteration Time: 6.57282

Cumulative Model Updates: 31,390
Cumulative Timesteps: 523,567,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 523567818...
Checkpoint 523567818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.09525
Policy Entropy: 1.10634
Value Function Loss: 1.54453

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.08758

Collected Steps per Second: 8,809.18748
Overall Steps per Second: 7,711.14968

Timestep Collection Time: 5.67862
Timestep Consumption Time: 0.80861
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.48723

Cumulative Model Updates: 31,393
Cumulative Timesteps: 523,617,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.79865
Policy Entropy: 1.07392
Value Function Loss: 1.45041

Mean KL Divergence: 0.05089
SB3 Clip Fraction: 0.27075
Policy Update Magnitude: 0.06935
Value Function Update Magnitude: 0.09456

Collected Steps per Second: 8,636.50518
Overall Steps per Second: 7,563.34326

Timestep Collection Time: 5.79216
Timestep Consumption Time: 0.82185
PPO Batch Consumption Time: 0.04093
Total Iteration Time: 6.61401

Cumulative Model Updates: 31,396
Cumulative Timesteps: 523,667,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 523667866...
Checkpoint 523667866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.95962
Policy Entropy: 1.09677
Value Function Loss: 1.42805

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.10370

Collected Steps per Second: 8,845.91440
Overall Steps per Second: 7,782.51202

Timestep Collection Time: 5.65255
Timestep Consumption Time: 0.77236
PPO Batch Consumption Time: 0.04225
Total Iteration Time: 6.42492

Cumulative Model Updates: 31,399
Cumulative Timesteps: 523,717,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.40845
Policy Entropy: 1.08271
Value Function Loss: 1.44179

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.10427

Collected Steps per Second: 8,625.56417
Overall Steps per Second: 7,512.34706

Timestep Collection Time: 5.79881
Timestep Consumption Time: 0.85930
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.65811

Cumulative Model Updates: 31,402
Cumulative Timesteps: 523,767,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 523767886...
Checkpoint 523767886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.90114
Policy Entropy: 1.06931
Value Function Loss: 1.42631

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.18270
Policy Update Magnitude: 0.07000
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 8,616.75499
Overall Steps per Second: 7,511.66432

Timestep Collection Time: 5.80451
Timestep Consumption Time: 0.85394
PPO Batch Consumption Time: 0.05152
Total Iteration Time: 6.65844

Cumulative Model Updates: 31,405
Cumulative Timesteps: 523,817,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.31960
Policy Entropy: 1.04980
Value Function Loss: 1.39093

Mean KL Divergence: 0.03864
SB3 Clip Fraction: 0.26560
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.08604

Collected Steps per Second: 8,368.46040
Overall Steps per Second: 7,387.05595

Timestep Collection Time: 5.97720
Timestep Consumption Time: 0.79410
PPO Batch Consumption Time: 0.04128
Total Iteration Time: 6.77130

Cumulative Model Updates: 31,408
Cumulative Timesteps: 523,867,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 523867922...
Checkpoint 523867922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.99904
Policy Entropy: 1.05927
Value Function Loss: 1.39015

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.19214
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 8,637.43467
Overall Steps per Second: 7,459.91637

Timestep Collection Time: 5.79061
Timestep Consumption Time: 0.91402
PPO Batch Consumption Time: 0.04596
Total Iteration Time: 6.70463

Cumulative Model Updates: 31,411
Cumulative Timesteps: 523,917,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.36183
Policy Entropy: 1.05894
Value Function Loss: 1.43725

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.18357
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 8,665.00922
Overall Steps per Second: 7,535.01868

Timestep Collection Time: 5.77357
Timestep Consumption Time: 0.86583
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 6.63940

Cumulative Model Updates: 31,414
Cumulative Timesteps: 523,967,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 523967966...
Checkpoint 523967966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.99951
Policy Entropy: 1.05254
Value Function Loss: 1.29241

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.18650
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.06153

Collected Steps per Second: 8,921.87755
Overall Steps per Second: 7,691.37437

Timestep Collection Time: 5.60667
Timestep Consumption Time: 0.89698
PPO Batch Consumption Time: 0.04500
Total Iteration Time: 6.50365

Cumulative Model Updates: 31,417
Cumulative Timesteps: 524,017,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.64071
Policy Entropy: 1.03418
Value Function Loss: 1.28722

Mean KL Divergence: 0.03844
SB3 Clip Fraction: 0.25662
Policy Update Magnitude: 0.07096
Value Function Update Magnitude: 0.05384

Collected Steps per Second: 8,529.58169
Overall Steps per Second: 7,421.87011

Timestep Collection Time: 5.86500
Timestep Consumption Time: 0.87535
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.74035

Cumulative Model Updates: 31,420
Cumulative Timesteps: 524,068,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 524068014...
Checkpoint 524068014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.76880
Policy Entropy: 1.04547
Value Function Loss: 1.13287

Mean KL Divergence: 0.02665
SB3 Clip Fraction: 0.20414
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.04628

Collected Steps per Second: 8,351.12703
Overall Steps per Second: 7,379.10044

Timestep Collection Time: 5.99009
Timestep Consumption Time: 0.78906
PPO Batch Consumption Time: 0.04729
Total Iteration Time: 6.77915

Cumulative Model Updates: 31,423
Cumulative Timesteps: 524,118,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.55474
Policy Entropy: 1.03446
Value Function Loss: 1.16948

Mean KL Divergence: 0.03097
SB3 Clip Fraction: 0.22661
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 8,847.01203
Overall Steps per Second: 7,709.27867

Timestep Collection Time: 5.65253
Timestep Consumption Time: 0.83420
PPO Batch Consumption Time: 0.04183
Total Iteration Time: 6.48673

Cumulative Model Updates: 31,426
Cumulative Timesteps: 524,168,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 524168046...
Checkpoint 524168046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.80375
Policy Entropy: 1.03181
Value Function Loss: 1.05596

Mean KL Divergence: 0.02441
SB3 Clip Fraction: 0.19399
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.05432

Collected Steps per Second: 8,675.69585
Overall Steps per Second: 7,503.28263

Timestep Collection Time: 5.76346
Timestep Consumption Time: 0.90056
PPO Batch Consumption Time: 0.04833
Total Iteration Time: 6.66402

Cumulative Model Updates: 31,429
Cumulative Timesteps: 524,218,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.42040
Policy Entropy: 1.01217
Value Function Loss: 1.09125

Mean KL Divergence: 0.03559
SB3 Clip Fraction: 0.26663
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.06792

Collected Steps per Second: 9,145.43500
Overall Steps per Second: 7,907.07397

Timestep Collection Time: 5.46918
Timestep Consumption Time: 0.85655
PPO Batch Consumption Time: 0.04533
Total Iteration Time: 6.32573

Cumulative Model Updates: 31,432
Cumulative Timesteps: 524,268,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 524268066...
Checkpoint 524268066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.71465
Policy Entropy: 1.01655
Value Function Loss: 1.02598

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.19233
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 8,768.18241
Overall Steps per Second: 7,521.88183

Timestep Collection Time: 5.70335
Timestep Consumption Time: 0.94499
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 6.64834

Cumulative Model Updates: 31,435
Cumulative Timesteps: 524,318,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.90414
Policy Entropy: 1.00535
Value Function Loss: 1.07016

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.20721
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.06813

Collected Steps per Second: 8,981.82274
Overall Steps per Second: 7,864.96193

Timestep Collection Time: 5.56836
Timestep Consumption Time: 0.79073
PPO Batch Consumption Time: 0.04381
Total Iteration Time: 6.35909

Cumulative Model Updates: 31,438
Cumulative Timesteps: 524,368,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 524368088...
Checkpoint 524368088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.15565
Policy Entropy: 0.98558
Value Function Loss: 1.05856

Mean KL Divergence: 0.03356
SB3 Clip Fraction: 0.24123
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.06380

Collected Steps per Second: 9,202.14117
Overall Steps per Second: 7,872.02627

Timestep Collection Time: 5.43547
Timestep Consumption Time: 0.91842
PPO Batch Consumption Time: 0.04600
Total Iteration Time: 6.35389

Cumulative Model Updates: 31,441
Cumulative Timesteps: 524,418,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.52244
Policy Entropy: 0.97384
Value Function Loss: 1.04188

Mean KL Divergence: 0.03532
SB3 Clip Fraction: 0.26869
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 8,942.51105
Overall Steps per Second: 7,721.67401

Timestep Collection Time: 5.59261
Timestep Consumption Time: 0.88422
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.47683

Cumulative Model Updates: 31,444
Cumulative Timesteps: 524,468,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 524468118...
Checkpoint 524468118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.18411
Policy Entropy: 0.97692
Value Function Loss: 0.99903

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.21193
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.07365

Collected Steps per Second: 8,738.39451
Overall Steps per Second: 7,707.86540

Timestep Collection Time: 5.72439
Timestep Consumption Time: 0.76534
PPO Batch Consumption Time: 0.04553
Total Iteration Time: 6.48973

Cumulative Model Updates: 31,447
Cumulative Timesteps: 524,518,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.78329
Policy Entropy: 0.96244
Value Function Loss: 0.98917

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.22182
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 8,611.01907
Overall Steps per Second: 7,529.49076

Timestep Collection Time: 5.80930
Timestep Consumption Time: 0.83444
PPO Batch Consumption Time: 0.04380
Total Iteration Time: 6.64374

Cumulative Model Updates: 31,450
Cumulative Timesteps: 524,568,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 524568164...
Checkpoint 524568164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.19284
Policy Entropy: 0.91900
Value Function Loss: 1.05937

Mean KL Divergence: 0.05166
SB3 Clip Fraction: 0.30547
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.06614

Collected Steps per Second: 8,712.00601
Overall Steps per Second: 7,591.24294

Timestep Collection Time: 5.74081
Timestep Consumption Time: 0.84757
PPO Batch Consumption Time: 0.05045
Total Iteration Time: 6.58838

Cumulative Model Updates: 31,453
Cumulative Timesteps: 524,618,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.56400
Policy Entropy: 0.94162
Value Function Loss: 1.04519

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.22935
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.08121

Collected Steps per Second: 8,939.51141
Overall Steps per Second: 7,835.60283

Timestep Collection Time: 5.59628
Timestep Consumption Time: 0.78842
PPO Batch Consumption Time: 0.04747
Total Iteration Time: 6.38470

Cumulative Model Updates: 31,456
Cumulative Timesteps: 524,668,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 524668206...
Checkpoint 524668206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.13516
Policy Entropy: 0.92746
Value Function Loss: 1.03555

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.24811
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.08951

Collected Steps per Second: 8,929.68694
Overall Steps per Second: 7,735.83622

Timestep Collection Time: 5.60199
Timestep Consumption Time: 0.86454
PPO Batch Consumption Time: 0.04821
Total Iteration Time: 6.46653

Cumulative Model Updates: 31,459
Cumulative Timesteps: 524,718,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.00351
Policy Entropy: 0.92627
Value Function Loss: 0.96403

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.20907
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 8,825.89046
Overall Steps per Second: 7,777.51940

Timestep Collection Time: 5.66696
Timestep Consumption Time: 0.76388
PPO Batch Consumption Time: 0.04797
Total Iteration Time: 6.43084

Cumulative Model Updates: 31,462
Cumulative Timesteps: 524,768,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 524768246...
Checkpoint 524768246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.69547
Policy Entropy: 0.89601
Value Function Loss: 0.93123

Mean KL Divergence: 0.02963
SB3 Clip Fraction: 0.26561
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 8,374.22850
Overall Steps per Second: 7,335.09711

Timestep Collection Time: 5.97094
Timestep Consumption Time: 0.84588
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.81682

Cumulative Model Updates: 31,465
Cumulative Timesteps: 524,818,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.75962
Policy Entropy: 0.92835
Value Function Loss: 0.90824

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.20863
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 8,792.97713
Overall Steps per Second: 7,669.35345

Timestep Collection Time: 5.68931
Timestep Consumption Time: 0.83353
PPO Batch Consumption Time: 0.04273
Total Iteration Time: 6.52284

Cumulative Model Updates: 31,468
Cumulative Timesteps: 524,868,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 524868274...
Checkpoint 524868274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.79743
Policy Entropy: 0.90888
Value Function Loss: 0.99150

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.19633
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.07933

Collected Steps per Second: 9,112.33309
Overall Steps per Second: 7,778.85139

Timestep Collection Time: 5.48773
Timestep Consumption Time: 0.94073
PPO Batch Consumption Time: 0.04444
Total Iteration Time: 6.42846

Cumulative Model Updates: 31,471
Cumulative Timesteps: 524,918,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.05793
Policy Entropy: 0.90522
Value Function Loss: 1.08290

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.21760
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.09409

Collected Steps per Second: 8,770.72454
Overall Steps per Second: 7,667.55341

Timestep Collection Time: 5.70078
Timestep Consumption Time: 0.82020
PPO Batch Consumption Time: 0.05115
Total Iteration Time: 6.52098

Cumulative Model Updates: 31,474
Cumulative Timesteps: 524,968,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 524968280...
Checkpoint 524968280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.65416
Policy Entropy: 0.92044
Value Function Loss: 1.06643

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.18522
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 8,641.81655
Overall Steps per Second: 7,639.98765

Timestep Collection Time: 5.78813
Timestep Consumption Time: 0.75900
PPO Batch Consumption Time: 0.04243
Total Iteration Time: 6.54713

Cumulative Model Updates: 31,477
Cumulative Timesteps: 525,018,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.19566
Policy Entropy: 0.91463
Value Function Loss: 1.06951

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.18527
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.08950

Collected Steps per Second: 8,880.84866
Overall Steps per Second: 7,708.39276

Timestep Collection Time: 5.63212
Timestep Consumption Time: 0.85665
PPO Batch Consumption Time: 0.04075
Total Iteration Time: 6.48877

Cumulative Model Updates: 31,480
Cumulative Timesteps: 525,068,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 525068318...
Checkpoint 525068318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.05891
Policy Entropy: 0.89104
Value Function Loss: 0.99567

Mean KL Divergence: 0.03141
SB3 Clip Fraction: 0.24559
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 9,002.23895
Overall Steps per Second: 7,732.19773

Timestep Collection Time: 5.55640
Timestep Consumption Time: 0.91266
PPO Batch Consumption Time: 0.04333
Total Iteration Time: 6.46905

Cumulative Model Updates: 31,483
Cumulative Timesteps: 525,118,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.72310
Policy Entropy: 0.91010
Value Function Loss: 1.01655

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.23405
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 8,925.12552
Overall Steps per Second: 7,910.37727

Timestep Collection Time: 5.60395
Timestep Consumption Time: 0.71888
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 6.32283

Cumulative Model Updates: 31,486
Cumulative Timesteps: 525,168,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 525168354...
Checkpoint 525168354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.93673
Policy Entropy: 0.90746
Value Function Loss: 1.04348

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.20057
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.07679

Collected Steps per Second: 9,045.07231
Overall Steps per Second: 7,874.32851

Timestep Collection Time: 5.52964
Timestep Consumption Time: 0.82214
PPO Batch Consumption Time: 0.04405
Total Iteration Time: 6.35178

Cumulative Model Updates: 31,489
Cumulative Timesteps: 525,218,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.09468
Policy Entropy: 0.91638
Value Function Loss: 1.13492

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.17983
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.06907

Collected Steps per Second: 8,648.81907
Overall Steps per Second: 7,582.67230

Timestep Collection Time: 5.78275
Timestep Consumption Time: 0.81307
PPO Batch Consumption Time: 0.04255
Total Iteration Time: 6.59583

Cumulative Model Updates: 31,492
Cumulative Timesteps: 525,268,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525268384...
Checkpoint 525268384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.22051
Policy Entropy: 0.90421
Value Function Loss: 1.12534

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.19142
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 9,131.68086
Overall Steps per Second: 7,958.73648

Timestep Collection Time: 5.47895
Timestep Consumption Time: 0.80748
PPO Batch Consumption Time: 0.04022
Total Iteration Time: 6.28642

Cumulative Model Updates: 31,495
Cumulative Timesteps: 525,318,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.18362
Policy Entropy: 0.91763
Value Function Loss: 1.10069

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.19993
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 8,741.29037
Overall Steps per Second: 7,583.62723

Timestep Collection Time: 5.72021
Timestep Consumption Time: 0.87321
PPO Batch Consumption Time: 0.04621
Total Iteration Time: 6.59341

Cumulative Model Updates: 31,498
Cumulative Timesteps: 525,368,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 525368418...
Checkpoint 525368418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.75913
Policy Entropy: 0.90992
Value Function Loss: 1.05010

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 8,674.01452
Overall Steps per Second: 7,568.97830

Timestep Collection Time: 5.76688
Timestep Consumption Time: 0.84194
PPO Batch Consumption Time: 0.04074
Total Iteration Time: 6.60882

Cumulative Model Updates: 31,501
Cumulative Timesteps: 525,418,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.22655
Policy Entropy: 0.91183
Value Function Loss: 0.98107

Mean KL Divergence: 0.02522
SB3 Clip Fraction: 0.21294
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.07714

Collected Steps per Second: 8,670.56358
Overall Steps per Second: 7,442.20732

Timestep Collection Time: 5.76687
Timestep Consumption Time: 0.95184
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.71871

Cumulative Model Updates: 31,504
Cumulative Timesteps: 525,468,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 525468442...
Checkpoint 525468442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.86986
Policy Entropy: 0.90231
Value Function Loss: 1.04273

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.25877
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 8,779.41277
Overall Steps per Second: 7,673.52700

Timestep Collection Time: 5.69810
Timestep Consumption Time: 0.82119
PPO Batch Consumption Time: 0.04314
Total Iteration Time: 6.51930

Cumulative Model Updates: 31,507
Cumulative Timesteps: 525,518,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.18730
Policy Entropy: 0.92860
Value Function Loss: 1.17132

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.20852
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 8,810.85411
Overall Steps per Second: 7,772.99981

Timestep Collection Time: 5.67595
Timestep Consumption Time: 0.75786
PPO Batch Consumption Time: 0.04528
Total Iteration Time: 6.43381

Cumulative Model Updates: 31,510
Cumulative Timesteps: 525,568,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 525568478...
Checkpoint 525568478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.62808
Policy Entropy: 0.93700
Value Function Loss: 1.30172

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.16170
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.08370

Collected Steps per Second: 8,991.29415
Overall Steps per Second: 7,812.21210

Timestep Collection Time: 5.56427
Timestep Consumption Time: 0.83980
PPO Batch Consumption Time: 0.04230
Total Iteration Time: 6.40408

Cumulative Model Updates: 31,513
Cumulative Timesteps: 525,618,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.62667
Policy Entropy: 0.93604
Value Function Loss: 1.24531

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.20011
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.07273

Collected Steps per Second: 8,686.59452
Overall Steps per Second: 7,613.53667

Timestep Collection Time: 5.75761
Timestep Consumption Time: 0.81148
PPO Batch Consumption Time: 0.04346
Total Iteration Time: 6.56909

Cumulative Model Updates: 31,516
Cumulative Timesteps: 525,668,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525668522...
Checkpoint 525668522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.21004
Policy Entropy: 0.92645
Value Function Loss: 1.06324

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 8,678.30658
Overall Steps per Second: 7,621.68074

Timestep Collection Time: 5.76149
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.04388
Total Iteration Time: 6.56023

Cumulative Model Updates: 31,519
Cumulative Timesteps: 525,718,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.54510
Policy Entropy: 0.93937
Value Function Loss: 1.10046

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.21483
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 8,749.63790
Overall Steps per Second: 7,560.85925

Timestep Collection Time: 5.71567
Timestep Consumption Time: 0.89866
PPO Batch Consumption Time: 0.04439
Total Iteration Time: 6.61433

Cumulative Model Updates: 31,522
Cumulative Timesteps: 525,768,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 525768532...
Checkpoint 525768532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.10530
Policy Entropy: 0.95132
Value Function Loss: 1.10487

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.24272
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 8,606.03746
Overall Steps per Second: 7,567.81634

Timestep Collection Time: 5.81359
Timestep Consumption Time: 0.79756
PPO Batch Consumption Time: 0.04198
Total Iteration Time: 6.61115

Cumulative Model Updates: 31,525
Cumulative Timesteps: 525,818,564

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.76709
Policy Entropy: 0.92430
Value Function Loss: 1.22037

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.21650
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 8,664.37782
Overall Steps per Second: 7,586.07743

Timestep Collection Time: 5.77145
Timestep Consumption Time: 0.82037
PPO Batch Consumption Time: 0.04743
Total Iteration Time: 6.59181

Cumulative Model Updates: 31,528
Cumulative Timesteps: 525,868,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 525868570...
Checkpoint 525868570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.37281
Policy Entropy: 0.96068
Value Function Loss: 1.14742

Mean KL Divergence: 0.02969
SB3 Clip Fraction: 0.24121
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 8,808.08599
Overall Steps per Second: 7,586.16567

Timestep Collection Time: 5.67955
Timestep Consumption Time: 0.91482
PPO Batch Consumption Time: 0.05126
Total Iteration Time: 6.59437

Cumulative Model Updates: 31,531
Cumulative Timesteps: 525,918,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.93629
Policy Entropy: 0.94210
Value Function Loss: 1.08952

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.21837
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 8,652.29047
Overall Steps per Second: 7,509.44705

Timestep Collection Time: 5.78136
Timestep Consumption Time: 0.87985
PPO Batch Consumption Time: 0.04058
Total Iteration Time: 6.66121

Cumulative Model Updates: 31,534
Cumulative Timesteps: 525,968,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 525968618...
Checkpoint 525968618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.90939
Policy Entropy: 0.96002
Value Function Loss: 1.02505

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.21213
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.06470

Collected Steps per Second: 8,814.50447
Overall Steps per Second: 7,637.19568

Timestep Collection Time: 5.67542
Timestep Consumption Time: 0.87489
PPO Batch Consumption Time: 0.04555
Total Iteration Time: 6.55031

Cumulative Model Updates: 31,537
Cumulative Timesteps: 526,018,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.72979
Policy Entropy: 0.95210
Value Function Loss: 0.99372

Mean KL Divergence: 0.03197
SB3 Clip Fraction: 0.25744
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 8,803.99987
Overall Steps per Second: 7,647.59966

Timestep Collection Time: 5.68219
Timestep Consumption Time: 0.85921
PPO Batch Consumption Time: 0.04083
Total Iteration Time: 6.54140

Cumulative Model Updates: 31,540
Cumulative Timesteps: 526,068,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 526068670...
Checkpoint 526068670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.48521
Policy Entropy: 0.98029
Value Function Loss: 1.04296

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.19532
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 8,724.00019
Overall Steps per Second: 7,666.73301

Timestep Collection Time: 5.73269
Timestep Consumption Time: 0.79056
PPO Batch Consumption Time: 0.04601
Total Iteration Time: 6.52325

Cumulative Model Updates: 31,543
Cumulative Timesteps: 526,118,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.64216
Policy Entropy: 0.98614
Value Function Loss: 0.98550

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.20013
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.08888

Collected Steps per Second: 7,876.60880
Overall Steps per Second: 6,934.58380

Timestep Collection Time: 6.34918
Timestep Consumption Time: 0.86250
PPO Batch Consumption Time: 0.04294
Total Iteration Time: 7.21168

Cumulative Model Updates: 31,546
Cumulative Timesteps: 526,168,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 526168692...
Checkpoint 526168692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.97549
Policy Entropy: 0.96537
Value Function Loss: 1.00984

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.19203
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.08373

Collected Steps per Second: 9,161.49609
Overall Steps per Second: 7,979.49576

Timestep Collection Time: 5.45762
Timestep Consumption Time: 0.80844
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.26606

Cumulative Model Updates: 31,549
Cumulative Timesteps: 526,218,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.36894
Policy Entropy: 0.96769
Value Function Loss: 1.02027

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.20470
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 9,307.84908
Overall Steps per Second: 8,044.74175

Timestep Collection Time: 5.37374
Timestep Consumption Time: 0.84373
PPO Batch Consumption Time: 0.04384
Total Iteration Time: 6.21748

Cumulative Model Updates: 31,552
Cumulative Timesteps: 526,268,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 526268710...
Checkpoint 526268710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.69953
Policy Entropy: 0.98037
Value Function Loss: 1.13119

Mean KL Divergence: 0.02696
SB3 Clip Fraction: 0.21735
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.09229

Collected Steps per Second: 8,908.67391
Overall Steps per Second: 7,730.79394

Timestep Collection Time: 5.61588
Timestep Consumption Time: 0.85565
PPO Batch Consumption Time: 0.04240
Total Iteration Time: 6.47152

Cumulative Model Updates: 31,555
Cumulative Timesteps: 526,318,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.27032
Policy Entropy: 0.98398
Value Function Loss: 1.14437

Mean KL Divergence: 0.02920
SB3 Clip Fraction: 0.23808
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.09258

Collected Steps per Second: 8,678.99596
Overall Steps per Second: 7,673.54474

Timestep Collection Time: 5.76127
Timestep Consumption Time: 0.75489
PPO Batch Consumption Time: 0.04416
Total Iteration Time: 6.51615

Cumulative Model Updates: 31,558
Cumulative Timesteps: 526,368,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 526368742...
Checkpoint 526368742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.61376
Policy Entropy: 0.95322
Value Function Loss: 1.06809

Mean KL Divergence: 0.04994
SB3 Clip Fraction: 0.29148
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 8,404.83898
Overall Steps per Second: 7,352.62913

Timestep Collection Time: 5.94919
Timestep Consumption Time: 0.85137
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 6.80056

Cumulative Model Updates: 31,561
Cumulative Timesteps: 526,418,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.05170
Policy Entropy: 0.97352
Value Function Loss: 1.03430

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.21103
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.09232

Collected Steps per Second: 8,823.50071
Overall Steps per Second: 7,678.13756

Timestep Collection Time: 5.66737
Timestep Consumption Time: 0.84541
PPO Batch Consumption Time: 0.04288
Total Iteration Time: 6.51278

Cumulative Model Updates: 31,564
Cumulative Timesteps: 526,468,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 526468750...
Checkpoint 526468750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.97208
Policy Entropy: 0.96918
Value Function Loss: 1.08262

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.22478
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 9,006.97838
Overall Steps per Second: 7,808.34167

Timestep Collection Time: 5.55236
Timestep Consumption Time: 0.85233
PPO Batch Consumption Time: 0.04342
Total Iteration Time: 6.40469

Cumulative Model Updates: 31,567
Cumulative Timesteps: 526,518,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.84962
Policy Entropy: 0.97502
Value Function Loss: 1.15653

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.20075
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 8,873.97619
Overall Steps per Second: 7,698.51068

Timestep Collection Time: 5.63445
Timestep Consumption Time: 0.86031
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 6.49476

Cumulative Model Updates: 31,570
Cumulative Timesteps: 526,568,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 526568760...
Checkpoint 526568760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.41475
Policy Entropy: 0.96388
Value Function Loss: 1.12658

Mean KL Divergence: 0.03419
SB3 Clip Fraction: 0.26185
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.05982

Collected Steps per Second: 8,271.02990
Overall Steps per Second: 7,335.31868

Timestep Collection Time: 6.04592
Timestep Consumption Time: 0.77123
PPO Batch Consumption Time: 0.04523
Total Iteration Time: 6.81715

Cumulative Model Updates: 31,573
Cumulative Timesteps: 526,618,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.87733
Policy Entropy: 0.98673
Value Function Loss: 1.14418

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.19319
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 8,830.71076
Overall Steps per Second: 7,585.12154

Timestep Collection Time: 5.66455
Timestep Consumption Time: 0.93020
PPO Batch Consumption Time: 0.04535
Total Iteration Time: 6.59475

Cumulative Model Updates: 31,576
Cumulative Timesteps: 526,668,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 526668788...
Checkpoint 526668788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.62028
Policy Entropy: 0.98904
Value Function Loss: 1.18502

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.17863
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.05316

Collected Steps per Second: 8,634.85479
Overall Steps per Second: 7,548.72586

Timestep Collection Time: 5.79373
Timestep Consumption Time: 0.83362
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.62734

Cumulative Model Updates: 31,579
Cumulative Timesteps: 526,718,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.26989
Policy Entropy: 0.98482
Value Function Loss: 1.21316

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.16572
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.05483

Collected Steps per Second: 8,846.59180
Overall Steps per Second: 7,697.30766

Timestep Collection Time: 5.65280
Timestep Consumption Time: 0.84402
PPO Batch Consumption Time: 0.04193
Total Iteration Time: 6.49682

Cumulative Model Updates: 31,582
Cumulative Timesteps: 526,768,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 526768824...
Checkpoint 526768824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.84917
Policy Entropy: 0.98791
Value Function Loss: 1.23268

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.20551
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.05573

Collected Steps per Second: 8,723.53458
Overall Steps per Second: 7,570.53941

Timestep Collection Time: 5.73414
Timestep Consumption Time: 0.87331
PPO Batch Consumption Time: 0.04261
Total Iteration Time: 6.60746

Cumulative Model Updates: 31,585
Cumulative Timesteps: 526,818,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.75918
Policy Entropy: 0.99564
Value Function Loss: 1.18655

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.19772
Policy Update Magnitude: 0.06231
Value Function Update Magnitude: 0.05602

Collected Steps per Second: 8,400.94425
Overall Steps per Second: 7,457.49066

Timestep Collection Time: 5.95409
Timestep Consumption Time: 0.75326
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.70735

Cumulative Model Updates: 31,588
Cumulative Timesteps: 526,868,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 526868866...
Checkpoint 526868866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.38694
Policy Entropy: 1.00213
Value Function Loss: 1.22438

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.21249
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.05908

Collected Steps per Second: 8,997.78148
Overall Steps per Second: 7,751.94639

Timestep Collection Time: 5.55937
Timestep Consumption Time: 0.89346
PPO Batch Consumption Time: 0.04683
Total Iteration Time: 6.45283

Cumulative Model Updates: 31,591
Cumulative Timesteps: 526,918,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.53364
Policy Entropy: 0.99674
Value Function Loss: 1.25819

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.21812
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.06333

Collected Steps per Second: 8,535.08604
Overall Steps per Second: 7,386.55757

Timestep Collection Time: 5.86028
Timestep Consumption Time: 0.91121
PPO Batch Consumption Time: 0.05316
Total Iteration Time: 6.77149

Cumulative Model Updates: 31,594
Cumulative Timesteps: 526,968,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 526968906...
Checkpoint 526968906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.16228
Policy Entropy: 1.02704
Value Function Loss: 1.33426

Mean KL Divergence: 0.02913
SB3 Clip Fraction: 0.21251
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 9,019.76017
Overall Steps per Second: 7,806.34058

Timestep Collection Time: 5.54627
Timestep Consumption Time: 0.86211
PPO Batch Consumption Time: 0.04364
Total Iteration Time: 6.40838

Cumulative Model Updates: 31,597
Cumulative Timesteps: 527,018,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.59462
Policy Entropy: 1.03432
Value Function Loss: 1.43901

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.20643
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 8,454.47853
Overall Steps per Second: 7,367.47092

Timestep Collection Time: 5.91592
Timestep Consumption Time: 0.87284
PPO Batch Consumption Time: 0.04722
Total Iteration Time: 6.78876

Cumulative Model Updates: 31,600
Cumulative Timesteps: 527,068,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527068948...
Checkpoint 527068948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.07984
Policy Entropy: 1.01561
Value Function Loss: 1.37842

Mean KL Divergence: 0.03324
SB3 Clip Fraction: 0.21927
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.10507

Collected Steps per Second: 8,730.90100
Overall Steps per Second: 7,716.05974

Timestep Collection Time: 5.72770
Timestep Consumption Time: 0.75333
PPO Batch Consumption Time: 0.04457
Total Iteration Time: 6.48103

Cumulative Model Updates: 31,603
Cumulative Timesteps: 527,118,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.83214
Policy Entropy: 1.00539
Value Function Loss: 1.38465

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.21567
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.10026

Collected Steps per Second: 8,607.56709
Overall Steps per Second: 7,465.08219

Timestep Collection Time: 5.81047
Timestep Consumption Time: 0.88926
PPO Batch Consumption Time: 0.04538
Total Iteration Time: 6.69973

Cumulative Model Updates: 31,606
Cumulative Timesteps: 527,168,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 527168970...
Checkpoint 527168970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.59082
Policy Entropy: 1.01774
Value Function Loss: 1.26872

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.09922

Collected Steps per Second: 8,756.86362
Overall Steps per Second: 7,597.58178

Timestep Collection Time: 5.71163
Timestep Consumption Time: 0.87151
PPO Batch Consumption Time: 0.04516
Total Iteration Time: 6.58315

Cumulative Model Updates: 31,609
Cumulative Timesteps: 527,218,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.61669
Policy Entropy: 1.02887
Value Function Loss: 1.27940

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.10106

Collected Steps per Second: 8,872.95249
Overall Steps per Second: 7,585.08793

Timestep Collection Time: 5.63691
Timestep Consumption Time: 0.95708
PPO Batch Consumption Time: 0.04850
Total Iteration Time: 6.59399

Cumulative Model Updates: 31,612
Cumulative Timesteps: 527,269,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527269002...
Checkpoint 527269002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.16792
Policy Entropy: 1.00749
Value Function Loss: 1.16163

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16812
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.09795

Collected Steps per Second: 8,521.13777
Overall Steps per Second: 7,443.29610

Timestep Collection Time: 5.86964
Timestep Consumption Time: 0.84997
PPO Batch Consumption Time: 0.04303
Total Iteration Time: 6.71960

Cumulative Model Updates: 31,615
Cumulative Timesteps: 527,319,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.93423
Policy Entropy: 1.00185
Value Function Loss: 1.18706

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.17874
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.09029

Collected Steps per Second: 8,671.26170
Overall Steps per Second: 7,636.13728

Timestep Collection Time: 5.76733
Timestep Consumption Time: 0.78180
PPO Batch Consumption Time: 0.04663
Total Iteration Time: 6.54912

Cumulative Model Updates: 31,618
Cumulative Timesteps: 527,369,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 527369028...
Checkpoint 527369028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.66440
Policy Entropy: 1.00998
Value Function Loss: 1.19133

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.08583

Collected Steps per Second: 8,479.58783
Overall Steps per Second: 7,368.04148

Timestep Collection Time: 5.89840
Timestep Consumption Time: 0.88984
PPO Batch Consumption Time: 0.04758
Total Iteration Time: 6.78824

Cumulative Model Updates: 31,621
Cumulative Timesteps: 527,419,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.14577
Policy Entropy: 1.01655
Value Function Loss: 1.24084

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.20800
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.08358

Collected Steps per Second: 8,825.99420
Overall Steps per Second: 7,693.39254

Timestep Collection Time: 5.66712
Timestep Consumption Time: 0.83430
PPO Batch Consumption Time: 0.04445
Total Iteration Time: 6.50142

Cumulative Model Updates: 31,624
Cumulative Timesteps: 527,469,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 527469062...
Checkpoint 527469062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.62000
Policy Entropy: 1.00139
Value Function Loss: 1.14924

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.18104
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.07905

Collected Steps per Second: 8,492.78461
Overall Steps per Second: 7,438.70697

Timestep Collection Time: 5.88853
Timestep Consumption Time: 0.83441
PPO Batch Consumption Time: 0.04226
Total Iteration Time: 6.72294

Cumulative Model Updates: 31,627
Cumulative Timesteps: 527,519,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.94174
Policy Entropy: 1.02725
Value Function Loss: 1.10485

Mean KL Divergence: 0.03046
SB3 Clip Fraction: 0.23001
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 8,882.56047
Overall Steps per Second: 7,746.31282

Timestep Collection Time: 5.63103
Timestep Consumption Time: 0.82597
PPO Batch Consumption Time: 0.04331
Total Iteration Time: 6.45701

Cumulative Model Updates: 31,630
Cumulative Timesteps: 527,569,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 527569090...
Checkpoint 527569090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.71104
Policy Entropy: 1.02670
Value Function Loss: 1.11625

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.20603
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07760

Collected Steps per Second: 8,455.57951
Overall Steps per Second: 7,511.14722

Timestep Collection Time: 5.91515
Timestep Consumption Time: 0.74376
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.65890

Cumulative Model Updates: 31,633
Cumulative Timesteps: 527,619,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.08663
Policy Entropy: 1.01732
Value Function Loss: 1.21361

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 8,712.02110
Overall Steps per Second: 7,535.89970

Timestep Collection Time: 5.74195
Timestep Consumption Time: 0.89614
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.63809

Cumulative Model Updates: 31,636
Cumulative Timesteps: 527,669,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 527669130...
Checkpoint 527669130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.86244
Policy Entropy: 0.99745
Value Function Loss: 1.18265

Mean KL Divergence: 0.03025
SB3 Clip Fraction: 0.22451
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 8,671.63709
Overall Steps per Second: 7,569.24998

Timestep Collection Time: 5.76685
Timestep Consumption Time: 0.83988
PPO Batch Consumption Time: 0.04780
Total Iteration Time: 6.60673

Cumulative Model Updates: 31,639
Cumulative Timesteps: 527,719,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.68937
Policy Entropy: 1.01683
Value Function Loss: 1.10734

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.19519
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.08799

Collected Steps per Second: 8,370.40969
Overall Steps per Second: 7,435.21977

Timestep Collection Time: 5.97557
Timestep Consumption Time: 0.75160
PPO Batch Consumption Time: 0.04479
Total Iteration Time: 6.72717

Cumulative Model Updates: 31,642
Cumulative Timesteps: 527,769,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 527769156...
Checkpoint 527769156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.56506
Policy Entropy: 1.01724
Value Function Loss: 1.08289

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15249
Policy Update Magnitude: 0.07371
Value Function Update Magnitude: 0.07953

Collected Steps per Second: 8,564.49423
Overall Steps per Second: 7,429.67053

Timestep Collection Time: 5.83852
Timestep Consumption Time: 0.89179
PPO Batch Consumption Time: 0.04542
Total Iteration Time: 6.73031

Cumulative Model Updates: 31,645
Cumulative Timesteps: 527,819,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.04726
Policy Entropy: 1.03035
Value Function Loss: 1.15596

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.07181

Collected Steps per Second: 8,798.91842
Overall Steps per Second: 7,680.55267

Timestep Collection Time: 5.68252
Timestep Consumption Time: 0.82743
PPO Batch Consumption Time: 0.04101
Total Iteration Time: 6.50995

Cumulative Model Updates: 31,648
Cumulative Timesteps: 527,869,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 527869160...
Checkpoint 527869160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.25381
Policy Entropy: 1.02122
Value Function Loss: 1.23461

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.18747
Policy Update Magnitude: 0.06883
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 8,890.02482
Overall Steps per Second: 7,793.29632

Timestep Collection Time: 5.62631
Timestep Consumption Time: 0.79177
PPO Batch Consumption Time: 0.04372
Total Iteration Time: 6.41808

Cumulative Model Updates: 31,651
Cumulative Timesteps: 527,919,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.26463
Policy Entropy: 1.02735
Value Function Loss: 1.30692

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.08305

Collected Steps per Second: 8,978.48641
Overall Steps per Second: 7,741.23592

Timestep Collection Time: 5.57020
Timestep Consumption Time: 0.89026
PPO Batch Consumption Time: 0.04823
Total Iteration Time: 6.46047

Cumulative Model Updates: 31,654
Cumulative Timesteps: 527,969,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 527969190...
Checkpoint 527969190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.50988
Policy Entropy: 1.03089
Value Function Loss: 1.19874

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.17098
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.08342

Collected Steps per Second: 8,621.63699
Overall Steps per Second: 7,441.42692

Timestep Collection Time: 5.80029
Timestep Consumption Time: 0.91993
PPO Batch Consumption Time: 0.04941
Total Iteration Time: 6.72022

Cumulative Model Updates: 31,657
Cumulative Timesteps: 528,019,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.33034
Policy Entropy: 1.03439
Value Function Loss: 1.11626

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.08035

Collected Steps per Second: 8,427.84025
Overall Steps per Second: 7,423.28236

Timestep Collection Time: 5.93390
Timestep Consumption Time: 0.80301
PPO Batch Consumption Time: 0.04809
Total Iteration Time: 6.73691

Cumulative Model Updates: 31,660
Cumulative Timesteps: 528,069,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 528069208...
Checkpoint 528069208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.79042
Policy Entropy: 1.03462
Value Function Loss: 1.08103

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.06730

Collected Steps per Second: 8,844.54265
Overall Steps per Second: 7,595.49882

Timestep Collection Time: 5.65433
Timestep Consumption Time: 0.92983
PPO Batch Consumption Time: 0.04498
Total Iteration Time: 6.58416

Cumulative Model Updates: 31,663
Cumulative Timesteps: 528,119,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.27037
Policy Entropy: 1.03322
Value Function Loss: 1.14638

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.07491

Collected Steps per Second: 8,647.69028
Overall Steps per Second: 7,552.95190

Timestep Collection Time: 5.78189
Timestep Consumption Time: 0.83804
PPO Batch Consumption Time: 0.04323
Total Iteration Time: 6.61993

Cumulative Model Updates: 31,666
Cumulative Timesteps: 528,169,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 528169218...
Checkpoint 528169218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.59690
Policy Entropy: 1.03056
Value Function Loss: 1.19048

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 8,680.80022
Overall Steps per Second: 7,537.18359

Timestep Collection Time: 5.76191
Timestep Consumption Time: 0.87425
PPO Batch Consumption Time: 0.04750
Total Iteration Time: 6.63617

Cumulative Model Updates: 31,669
Cumulative Timesteps: 528,219,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.03559
Policy Entropy: 1.04276
Value Function Loss: 1.14203

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 8,583.18166
Overall Steps per Second: 7,497.91504

Timestep Collection Time: 5.82604
Timestep Consumption Time: 0.84328
PPO Batch Consumption Time: 0.04247
Total Iteration Time: 6.66932

Cumulative Model Updates: 31,672
Cumulative Timesteps: 528,269,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 528269242...
Checkpoint 528269242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.23164
Policy Entropy: 1.04431
Value Function Loss: 1.19935

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.07588

Collected Steps per Second: 8,655.64949
Overall Steps per Second: 7,661.23904

Timestep Collection Time: 5.77796
Timestep Consumption Time: 0.74997
PPO Batch Consumption Time: 0.04293
Total Iteration Time: 6.52793

Cumulative Model Updates: 31,675
Cumulative Timesteps: 528,319,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.14131
Policy Entropy: 1.05469
Value Function Loss: 1.18759

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.18263
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 8,609.11468
Overall Steps per Second: 7,525.54603

Timestep Collection Time: 5.80942
Timestep Consumption Time: 0.83647
PPO Batch Consumption Time: 0.04287
Total Iteration Time: 6.64590

Cumulative Model Updates: 31,678
Cumulative Timesteps: 528,369,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 528369268...
Checkpoint 528369268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.81976
Policy Entropy: 1.05091
Value Function Loss: 1.21075

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.17085
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 8,506.84251
Overall Steps per Second: 7,371.44065

Timestep Collection Time: 5.87997
Timestep Consumption Time: 0.90568
PPO Batch Consumption Time: 0.04284
Total Iteration Time: 6.78565

Cumulative Model Updates: 31,681
Cumulative Timesteps: 528,419,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.22062
Policy Entropy: 1.05158
Value Function Loss: 1.33276

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.18520
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.07596

Collected Steps per Second: 8,630.36891
Overall Steps per Second: 7,534.72447

Timestep Collection Time: 5.79581
Timestep Consumption Time: 0.84278
PPO Batch Consumption Time: 0.04669
Total Iteration Time: 6.63860

Cumulative Model Updates: 31,684
Cumulative Timesteps: 528,469,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 528469308...
Checkpoint 528469308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.82625
Policy Entropy: 1.06961
Value Function Loss: 1.33224

Mean KL Divergence: 0.02419
SB3 Clip Fraction: 0.19559
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 8,821.47780
Overall Steps per Second: 7,699.05112

Timestep Collection Time: 5.66957
Timestep Consumption Time: 0.82655
PPO Batch Consumption Time: 0.04671
Total Iteration Time: 6.49613

Cumulative Model Updates: 31,687
Cumulative Timesteps: 528,519,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.31241
Policy Entropy: 1.07654
Value Function Loss: 1.42500

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.17900
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.07009

Collected Steps per Second: 8,812.16315
Overall Steps per Second: 7,798.01416

Timestep Collection Time: 5.67534
Timestep Consumption Time: 0.73809
PPO Batch Consumption Time: 0.04232
Total Iteration Time: 6.41343

Cumulative Model Updates: 31,690
Cumulative Timesteps: 528,569,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 528569334...
Checkpoint 528569334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.41954
Policy Entropy: 1.07688
Value Function Loss: 1.38263

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 8,610.78715
Overall Steps per Second: 7,466.73418

Timestep Collection Time: 5.80783
Timestep Consumption Time: 0.88988
PPO Batch Consumption Time: 0.04217
Total Iteration Time: 6.69771

Cumulative Model Updates: 31,693
Cumulative Timesteps: 528,619,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.65418
Policy Entropy: 1.08644
Value Function Loss: 1.41723

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.07078
Value Function Update Magnitude: 0.08445

Collected Steps per Second: 8,440.32228
Overall Steps per Second: 7,370.85430

Timestep Collection Time: 5.92513
Timestep Consumption Time: 0.85970
PPO Batch Consumption Time: 0.04271
Total Iteration Time: 6.78483

Cumulative Model Updates: 31,696
Cumulative Timesteps: 528,669,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 528669354...
Checkpoint 528669354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.45124
Policy Entropy: 1.08115
Value Function Loss: 1.43620

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.06878
Value Function Update Magnitude: 0.08900

Collected Steps per Second: 8,585.99117
Overall Steps per Second: 7,595.09608

Timestep Collection Time: 5.82600
Timestep Consumption Time: 0.76009
PPO Batch Consumption Time: 0.04604
Total Iteration Time: 6.58609

Cumulative Model Updates: 31,699
Cumulative Timesteps: 528,719,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.06214
Policy Entropy: 1.07720
Value Function Loss: 1.39361

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.07081
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 8,882.52276
Overall Steps per Second: 7,617.93015

Timestep Collection Time: 5.62993
Timestep Consumption Time: 0.93458
PPO Batch Consumption Time: 0.04961
Total Iteration Time: 6.56451

Cumulative Model Updates: 31,702
Cumulative Timesteps: 528,769,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 528769384...
Checkpoint 528769384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.60081
Policy Entropy: 1.09963
Value Function Loss: 1.54146

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.09543

Collected Steps per Second: 8,895.79207
Overall Steps per Second: 7,682.63519

Timestep Collection Time: 5.62266
Timestep Consumption Time: 0.88787
PPO Batch Consumption Time: 0.04423
Total Iteration Time: 6.51053

Cumulative Model Updates: 31,705
Cumulative Timesteps: 528,819,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.40426
Policy Entropy: 1.09693
Value Function Loss: 1.46766

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 8,800.06214
Overall Steps per Second: 7,595.69220

Timestep Collection Time: 5.68382
Timestep Consumption Time: 0.90122
PPO Batch Consumption Time: 0.04530
Total Iteration Time: 6.58505

Cumulative Model Updates: 31,708
Cumulative Timesteps: 528,869,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 528869420...
Checkpoint 528869420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.03149
Policy Entropy: 1.10197
Value Function Loss: 1.50368

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.08546

Collected Steps per Second: 8,853.28710
Overall Steps per Second: 7,682.20868

Timestep Collection Time: 5.64988
Timestep Consumption Time: 0.86127
PPO Batch Consumption Time: 0.04295
Total Iteration Time: 6.51115

Cumulative Model Updates: 31,711
Cumulative Timesteps: 528,919,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.39669
Policy Entropy: 1.09902
Value Function Loss: 1.39270

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.07666
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 8,431.36690
Overall Steps per Second: 7,399.23852

Timestep Collection Time: 5.93190
Timestep Consumption Time: 0.82745
PPO Batch Consumption Time: 0.04296
Total Iteration Time: 6.75934

Cumulative Model Updates: 31,714
Cumulative Timesteps: 528,969,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 528969454...
Checkpoint 528969454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.30827
Policy Entropy: 1.10130
Value Function Loss: 1.40845

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.07451
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 8,893.86790
Overall Steps per Second: 7,688.28004

Timestep Collection Time: 5.62343
Timestep Consumption Time: 0.88180
PPO Batch Consumption Time: 0.04394
Total Iteration Time: 6.50523

Cumulative Model Updates: 31,717
Cumulative Timesteps: 529,019,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.08192
Policy Entropy: 1.09384
Value Function Loss: 1.37954

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.07472
Value Function Update Magnitude: 0.07922

Collected Steps per Second: 8,529.24163
Overall Steps per Second: 7,389.06763

Timestep Collection Time: 5.86219
Timestep Consumption Time: 0.90457
PPO Batch Consumption Time: 0.04532
Total Iteration Time: 6.76675

Cumulative Model Updates: 31,720
Cumulative Timesteps: 529,069,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 529069468...
Checkpoint 529069468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.64730
Policy Entropy: 1.08144
Value Function Loss: 1.33149

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.08899

Collected Steps per Second: 8,689.41616
Overall Steps per Second: 7,588.14653

Timestep Collection Time: 5.75758
Timestep Consumption Time: 0.83560
PPO Batch Consumption Time: 0.04210
Total Iteration Time: 6.59318

Cumulative Model Updates: 31,723
Cumulative Timesteps: 529,119,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.46813
Policy Entropy: 1.09935
Value Function Loss: 1.35761

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.10912

Collected Steps per Second: 8,656.90844
Overall Steps per Second: 7,575.72384

Timestep Collection Time: 5.77689
Timestep Consumption Time: 0.82446
PPO Batch Consumption Time: 0.04152
Total Iteration Time: 6.60135

Cumulative Model Updates: 31,726
Cumulative Timesteps: 529,169,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 529169508...
Checkpoint 529169508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.45970
Policy Entropy: 1.10058
Value Function Loss: 1.34917

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.09069

Collected Steps per Second: 8,859.05917
Overall Steps per Second: 7,668.92900

Timestep Collection Time: 5.64755
Timestep Consumption Time: 0.87644
PPO Batch Consumption Time: 0.04676
Total Iteration Time: 6.52399

Cumulative Model Updates: 31,729
Cumulative Timesteps: 529,219,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.43555
Policy Entropy: 1.08170
Value Function Loss: 1.38277

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.16968
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.08333

Collected Steps per Second: 8,838.62902
Overall Steps per Second: 7,678.49277

Timestep Collection Time: 5.66061
Timestep Consumption Time: 0.85526
PPO Batch Consumption Time: 0.04486
Total Iteration Time: 6.51586

Cumulative Model Updates: 31,732
Cumulative Timesteps: 529,269,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 529269572...
Checkpoint 529269572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.17992
Policy Entropy: 1.07350
Value Function Loss: 1.29470

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.19537
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 8,669.85467
Overall Steps per Second: 7,370.67769

Timestep Collection Time: 5.76942
Timestep Consumption Time: 1.01693
PPO Batch Consumption Time: 0.05206
Total Iteration Time: 6.78635

Cumulative Model Updates: 31,735
Cumulative Timesteps: 529,319,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.45769
Policy Entropy: 1.07981
Value Function Loss: 1.16473

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.07736

Collected Steps per Second: 8,679.48571
Overall Steps per Second: 7,635.14919

Timestep Collection Time: 5.76163
Timestep Consumption Time: 0.78808
PPO Batch Consumption Time: 0.05056
Total Iteration Time: 6.54971

Cumulative Model Updates: 31,738
Cumulative Timesteps: 529,369,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 529369600...
Checkpoint 529369600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.61407
Policy Entropy: 1.07625
Value Function Loss: 1.10878

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.18001
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.07397

Collected Steps per Second: 8,858.21168
Overall Steps per Second: 7,550.14308

Timestep Collection Time: 5.64719
Timestep Consumption Time: 0.97838
PPO Batch Consumption Time: 0.04928
Total Iteration Time: 6.62557

Cumulative Model Updates: 31,741
Cumulative Timesteps: 529,419,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.08870
Policy Entropy: 1.06082
Value Function Loss: 1.13869

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 8,633.64119
Overall Steps per Second: 7,512.23874

Timestep Collection Time: 5.79408
Timestep Consumption Time: 0.86492
PPO Batch Consumption Time: 0.04370
Total Iteration Time: 6.65900

Cumulative Model Updates: 31,744
Cumulative Timesteps: 529,469,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 529469648...
Checkpoint 529469648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.32474
Policy Entropy: 1.04027
Value Function Loss: 1.21655

Mean KL Divergence: 0.02995
SB3 Clip Fraction: 0.23552
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 8,817.29390
Overall Steps per Second: 7,647.93048

Timestep Collection Time: 5.67249
Timestep Consumption Time: 0.86732
PPO Batch Consumption Time: 0.04749
Total Iteration Time: 6.53981

Cumulative Model Updates: 31,747
Cumulative Timesteps: 529,519,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.87313
Policy Entropy: 1.05444
Value Function Loss: 1.19485

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.16649
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.06908

Collected Steps per Second: 8,371.13475
Overall Steps per Second: 7,270.04102

Timestep Collection Time: 5.97458
Timestep Consumption Time: 0.90489
PPO Batch Consumption Time: 0.04529
Total Iteration Time: 6.87947

Cumulative Model Updates: 31,750
Cumulative Timesteps: 529,569,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 529569678...
Checkpoint 529569678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.45855
Policy Entropy: 1.05205
Value Function Loss: 1.23113

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.17812
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.07165

Collected Steps per Second: 8,660.85391
Overall Steps per Second: 7,586.10251

Timestep Collection Time: 5.77495
Timestep Consumption Time: 0.81816
PPO Batch Consumption Time: 0.04464
Total Iteration Time: 6.59311

Cumulative Model Updates: 31,753
Cumulative Timesteps: 529,619,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.00948
Policy Entropy: 1.03508
Value Function Loss: 1.14378

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.18605
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 8,826.91107
Overall Steps per Second: 7,651.91956

Timestep Collection Time: 5.66699
Timestep Consumption Time: 0.87020
PPO Batch Consumption Time: 0.04258
Total Iteration Time: 6.53718

Cumulative Model Updates: 31,756
Cumulative Timesteps: 529,669,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 529669716...
Checkpoint 529669716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.01413
Policy Entropy: 1.00758
Value Function Loss: 1.13631

Mean KL Divergence: 0.04318
SB3 Clip Fraction: 0.28275
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 9,040.22417
Overall Steps per Second: 7,789.21206

Timestep Collection Time: 5.53415
Timestep Consumption Time: 0.88883
PPO Batch Consumption Time: 0.04897
Total Iteration Time: 6.42299

Cumulative Model Updates: 31,759
Cumulative Timesteps: 529,719,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.74287
Policy Entropy: 1.01940
Value Function Loss: 1.03745

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07405

Collected Steps per Second: 8,778.05575
Overall Steps per Second: 7,594.35476

Timestep Collection Time: 5.69853
Timestep Consumption Time: 0.88821
PPO Batch Consumption Time: 0.04709
Total Iteration Time: 6.58673

Cumulative Model Updates: 31,762
Cumulative Timesteps: 529,769,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 529769768...
Checkpoint 529769768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.15974
Policy Entropy: 1.01214
Value Function Loss: 1.07951

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.07547

Collected Steps per Second: 8,982.78775
Overall Steps per Second: 7,758.48062

Timestep Collection Time: 5.56731
Timestep Consumption Time: 0.87854
PPO Batch Consumption Time: 0.04425
Total Iteration Time: 6.44585

Cumulative Model Updates: 31,765
Cumulative Timesteps: 529,819,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.80863
Policy Entropy: 1.00423
Value Function Loss: 1.05546

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 8,886.86925
Overall Steps per Second: 7,694.17745

Timestep Collection Time: 5.62785
Timestep Consumption Time: 0.87239
PPO Batch Consumption Time: 0.04166
Total Iteration Time: 6.50024

Cumulative Model Updates: 31,768
Cumulative Timesteps: 529,869,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 529869792...
Checkpoint 529869792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.44267
Policy Entropy: 1.00671
Value Function Loss: 1.06932

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.17646
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 8,982.73572
Overall Steps per Second: 7,717.63006

Timestep Collection Time: 5.56668
Timestep Consumption Time: 0.91251
PPO Batch Consumption Time: 0.04738
Total Iteration Time: 6.47919

Cumulative Model Updates: 31,771
Cumulative Timesteps: 529,919,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.89053
Policy Entropy: 1.01362
Value Function Loss: 1.05658

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.16751
Policy Update Magnitude: 0.06464
Value Function Update Magnitude: 0.05914

Collected Steps per Second: 8,592.37864
Overall Steps per Second: 7,505.80153

Timestep Collection Time: 5.82051
Timestep Consumption Time: 0.84261
PPO Batch Consumption Time: 0.04938
Total Iteration Time: 6.66311

Cumulative Model Updates: 31,774
Cumulative Timesteps: 529,969,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 529969808...
Checkpoint 529969808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.21073
Policy Entropy: 1.02023
Value Function Loss: 1.05574

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.05677

Collected Steps per Second: 8,094.83194
Overall Steps per Second: 7,184.78525

Timestep Collection Time: 6.17925
Timestep Consumption Time: 0.78268
PPO Batch Consumption Time: 0.05077
Total Iteration Time: 6.96193

Cumulative Model Updates: 31,777
Cumulative Timesteps: 530,019,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.48716
Policy Entropy: 1.01885
Value Function Loss: 0.94703

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.06023

Collected Steps per Second: 8,848.42967
Overall Steps per Second: 7,710.78572

Timestep Collection Time: 5.65253
Timestep Consumption Time: 0.83397
PPO Batch Consumption Time: 0.04163
Total Iteration Time: 6.48650

Cumulative Model Updates: 31,780
Cumulative Timesteps: 530,069,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 530069844...
Checkpoint 530069844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.91208
Policy Entropy: 1.02402
Value Function Loss: 0.95884

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 8,689.32444
Overall Steps per Second: 7,573.11440

Timestep Collection Time: 5.75534
Timestep Consumption Time: 0.84829
PPO Batch Consumption Time: 0.04393
Total Iteration Time: 6.60362

Cumulative Model Updates: 31,783
Cumulative Timesteps: 530,119,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.01915
Policy Entropy: 1.00914
Value Function Loss: 1.05057

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.23393
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.06069

Collected Steps per Second: 8,794.41213
Overall Steps per Second: 7,686.14113

Timestep Collection Time: 5.68748
Timestep Consumption Time: 0.82008
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 6.50756

Cumulative Model Updates: 31,786
Cumulative Timesteps: 530,169,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 530169872...
Checkpoint 530169872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.21688
Policy Entropy: 1.03138
Value Function Loss: 1.09851

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 8,737.92762
Overall Steps per Second: 7,612.92284

Timestep Collection Time: 5.72241
Timestep Consumption Time: 0.84563
PPO Batch Consumption Time: 0.04619
Total Iteration Time: 6.56804

Cumulative Model Updates: 31,789
Cumulative Timesteps: 530,219,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.77775
Policy Entropy: 1.03261
Value Function Loss: 1.01609

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.07208

Collected Steps per Second: 8,329.94720
Overall Steps per Second: 7,433.83470

Timestep Collection Time: 6.00340
Timestep Consumption Time: 0.72368
PPO Batch Consumption Time: 0.04253
Total Iteration Time: 6.72708

Cumulative Model Updates: 31,792
Cumulative Timesteps: 530,269,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 530269882...
Checkpoint 530269882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.48252
Policy Entropy: 1.01752
Value Function Loss: 1.03279

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 8,716.82113
Overall Steps per Second: 7,585.55561

Timestep Collection Time: 5.73925
Timestep Consumption Time: 0.85592
PPO Batch Consumption Time: 0.04707
Total Iteration Time: 6.59517

Cumulative Model Updates: 31,795
Cumulative Timesteps: 530,319,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.78891
Policy Entropy: 1.00088
Value Function Loss: 1.07664

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.18781
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 8,687.42399
Overall Steps per Second: 7,574.33308

Timestep Collection Time: 5.75752
Timestep Consumption Time: 0.84610
PPO Batch Consumption Time: 0.04558
Total Iteration Time: 6.60362

Cumulative Model Updates: 31,798
Cumulative Timesteps: 530,369,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 530369928...
Checkpoint 530369928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.40019
Policy Entropy: 1.01419
Value Function Loss: 1.10038

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.06977

Collected Steps per Second: 8,511.08683
Overall Steps per Second: 7,540.59978

Timestep Collection Time: 5.87634
Timestep Consumption Time: 0.75629
PPO Batch Consumption Time: 0.04424
Total Iteration Time: 6.63263

Cumulative Model Updates: 31,801
Cumulative Timesteps: 530,419,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.74095
Policy Entropy: 1.02089
Value Function Loss: 1.05750

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.19430
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 8,358.92141
Overall Steps per Second: 7,262.30159

Timestep Collection Time: 5.98498
Timestep Consumption Time: 0.90374
PPO Batch Consumption Time: 0.04279
Total Iteration Time: 6.88873

Cumulative Model Updates: 31,804
Cumulative Timesteps: 530,469,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 530469970...
Checkpoint 530469970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.99991
Policy Entropy: 1.00831
Value Function Loss: 0.95216

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.06529

Collected Steps per Second: 8,636.10195
Overall Steps per Second: 7,555.10538

Timestep Collection Time: 5.78988
Timestep Consumption Time: 0.82843
PPO Batch Consumption Time: 0.04042
Total Iteration Time: 6.61831

Cumulative Model Updates: 31,807
Cumulative Timesteps: 530,519,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.80119
Policy Entropy: 0.99510
Value Function Loss: 0.99318

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.20583
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.06017

Collected Steps per Second: 9,019.81259
Overall Steps per Second: 7,751.72617

Timestep Collection Time: 5.54513
Timestep Consumption Time: 0.90711
PPO Batch Consumption Time: 0.04478
Total Iteration Time: 6.45224

Cumulative Model Updates: 31,810
Cumulative Timesteps: 530,569,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 530569988...
Checkpoint 530569988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.53028
Policy Entropy: 1.01538
Value Function Loss: 0.98771

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 8,744.08775
Overall Steps per Second: 7,507.50379

Timestep Collection Time: 5.72181
Timestep Consumption Time: 0.94246
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 6.66427

Cumulative Model Updates: 31,813
Cumulative Timesteps: 530,620,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.21340
Policy Entropy: 1.01393
Value Function Loss: 1.02510

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.04431
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 9,088.38811
Overall Steps per Second: 7,976.99074

Timestep Collection Time: 5.50219
Timestep Consumption Time: 0.76659
PPO Batch Consumption Time: 0.04012
Total Iteration Time: 6.26878

Cumulative Model Updates: 31,816
Cumulative Timesteps: 530,670,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 530670026...
Checkpoint 530670026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.36179
Policy Entropy: 1.00377
Value Function Loss: 0.97737

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.17174
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 8,927.86528
Overall Steps per Second: 7,652.83053

Timestep Collection Time: 5.60380
Timestep Consumption Time: 0.93365
PPO Batch Consumption Time: 0.05779
Total Iteration Time: 6.53745

Cumulative Model Updates: 31,819
Cumulative Timesteps: 530,720,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.82105
Policy Entropy: 1.00228
Value Function Loss: 0.91093

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.21962
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07919

Collected Steps per Second: 5,679.74038
Overall Steps per Second: 5,119.30158

Timestep Collection Time: 8.80357
Timestep Consumption Time: 0.96378
PPO Batch Consumption Time: 0.04324
Total Iteration Time: 9.76735

Cumulative Model Updates: 31,822
Cumulative Timesteps: 530,770,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 530770058...
Checkpoint 530770058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.03843
Policy Entropy: 1.02100
Value Function Loss: 0.93758

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 8,743.66064
Overall Steps per Second: 7,432.18366

Timestep Collection Time: 5.72026
Timestep Consumption Time: 1.00939
PPO Batch Consumption Time: 0.04841
Total Iteration Time: 6.72965

Cumulative Model Updates: 31,825
Cumulative Timesteps: 530,820,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.52639
Policy Entropy: 1.03309
Value Function Loss: 0.96770

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 9,113.86152
Overall Steps per Second: 7,891.72585

Timestep Collection Time: 5.48878
Timestep Consumption Time: 0.85001
PPO Batch Consumption Time: 0.04700
Total Iteration Time: 6.33879

Cumulative Model Updates: 31,828
Cumulative Timesteps: 530,870,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 530870098...
Checkpoint 530870098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.37253
Policy Entropy: 1.02037
Value Function Loss: 0.96442

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 8,703.43786
Overall Steps per Second: 7,677.26701

Timestep Collection Time: 5.74555
Timestep Consumption Time: 0.76797
PPO Batch Consumption Time: 0.03904
Total Iteration Time: 6.51352

Cumulative Model Updates: 31,831
Cumulative Timesteps: 530,920,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 530920104...
Checkpoint 530920104 saved!
