{
    "cumulative_timesteps": 530870098,
    "cumulative_model_updates": 31828,
    "policy_average_reward": 1162.5263879109123,
    "epoch": 10610,
    "ts_since_last_save": 100040,
    "reward_running_stats": {
        "mean": [
            19.613476543894393
        ],
        "var": [
            2408109380.8651395
        ],
        "shape": [
            1
        ],
        "count": 1592100
    },
    "wandb_run_id": "3dxm0so3",
    "wandb_project": "rlgym-ppo",
    "wandb_entity": "trexxxxxxxxxxy-rl",
    "wandb_group": "unnamed-runs",
    "wandb_config": {
        "n_proc": 32,
        "min_inference_size": 29,
        "timestep_limit": 1000000000,
        "exp_buffer_size": 150000,
        "ts_per_iteration": 50000,
        "standardize_returns": true,
        "standardize_obs": false,
        "policy_layer_sizes": [
            256,
            256,
            256
        ],
        "critic_layer_sizes": [
            256,
            256,
            256
        ],
        "ppo_epochs": 1,
        "ppo_batch_size": 50000,
        "ppo_minibatch_size": 50000,
        "ppo_ent_coef": 0.001,
        "ppo_clip_range": 0.2,
        "gae_lambda": 0.95,
        "gae_gamma": 0.99,
        "policy_lr": 0.0003,
        "critic_lr": 0.0003,
        "shm_buffer_size": 8192
    }
}